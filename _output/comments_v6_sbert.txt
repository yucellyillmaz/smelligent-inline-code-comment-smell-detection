clean_comment;v1;v2;v3;v4;v5;v6;label
usr bin python;-3.5545452;-3.6137733;-1.9954637;-2.9699554;-3.8459373;-5.1681294;CODE
copyright 2014 google inc all rights reserved;-5.7061577;-3.0676205;1.3447374;0.13210899;-0.50383484;-1.2042238;IRRE
copyright 2015 tim rae;-4.5352507;-3.3004754;1.5250454;0.7980326;0.067209035;-1.8180028;-
licensed under the apache license version 2 0 the license;-5.611165;-1.8895702;-1.3389499;-1.0758823;1.7591724;-0.32319254;META
you may not use this file except in compliance with the license;-7.0957212;-2.7139256;-3.5462215;-1.2694259;0.96327156;0.23771167;CODE
you may obtain a copy of the license at;-4.786196;-2.8652675;-1.8078988;-0.2909642;2.2038243;1.3846152;-
http www apache org licenses license 2 0;-4.70777;-2.688903;-0.5419212;-2.021672;1.8333395;-1.4423686;CODE
unless required by applicable law or agreed to in writing software;-4.2566733;-1.3080602;-1.1548618;2.70869;2.9817903;-1.3585562;CODE
distributed under the license is distributed on an as is basis;-2.3052208;-1.0496962;-1.2731843;-1.3630604;5.534951;1.6938909;META
without warranties or conditions of any kind either express or implied;-2.729525;2.9662635;0.24017125;1.5149791;3.5001798;-1.2568364;-
see the license for the specific language governing permissions and;-6.6814823;-3.8379023;-0.49216104;-1.0821717;2.3763936;-0.9840524;CODE
limitations under the license;-3.7086895;-1.744466;-1.671981;0.2825808;3.2682338;-0.20457575;-
usr bin env python;-4.4434023;-3.2804286;-2.2293885;-2.92909;-3.937616;-3.571847;CODE
copyright 2006 2007 google inc all rights reserved;-5.8579483;-3.293187;0.5197158;-0.035483893;0.9019597;-1.0450547;IRRE
author danderson google com david anderson;-2.5977037;-4.6705623;0.6988587;-0.36912647;0.018011604;-1.1742408;META
script for uploading files to a google code project;-2.9153366;-2.686047;0.21846095;0.7582314;-2.0615149;-0.6483255;CODE
this is intended to be both a useful script for people who want to;-4.7120895;-3.3421075;3.53355;1.3868606;-0.41309038;-0.3915949;CODE
streamline project uploads and a reference implementation for;-2.6811566;-4.8213077;1.0094814;2.1374013;1.1658803;3.224166;CODE
uploading files to google code projects;-3.4596965;-4.502;-0.26990986;0.6017086;-1.9588397;-0.24423526;CODE
to upload a file to google code you need to provide a path to the;-6.3157425;-2.7833183;-0.4144253;-0.2575749;-2.2766554;0.10312034;CODE
file on your local machine a small summary of what the file is a;-2.954743;-3.8537328;0.65359336;-0.95091593;0.17747049;-1.0151037;-
project name and a valid account that is a member or owner of that;-4.508349;-3.640335;0.6167609;-0.6848647;1.8919704;-0.5581068;-
project you can optionally provide a list of labels that apply to;-0.14468788;-4.9343944;1.6430115;1.2124045;5.480107;0.65054;-
the file the file will be uploaded under the same name that it has;-4.6372585;-1.415232;1.6658038;-0.12576602;1.2071123;2.2397108;CODE
in your local filesystem that is the basename or last path;-5.2786813;-1.6452031;1.4092617;-2.0462632;0.04847666;1.2312336;CODE
component run the script with help to get the exact syntax;-4.6810226;1.4614308;0.75367206;0.8163606;0.5635112;-0.38151473;CODE
and available options;-2.6846159;-3.3397615;4.7045164;2.0993712;3.2731388;0.4512274;-
note that the upload script requests that you enter your;-5.3513374;-2.2277853;2.4247417;1.6300298;-3.0401247;1.4601339;CODE
googlecode com password this is not your gmail account password;-3.8043377;-0.3418897;-1.0910269;-1.3485036;-1.3532215;-2.2874622;CODE
this is the password you use on googlecode com for committing to;-6.030381;-2.2393737;0.06950738;-1.5018582;-0.3399996;-2.2106705;CODE
subversion and uploading files you can find your password by going;-2.4616923;-4.2132735;2.0724566;-0.4126374;-1.4258022;-0.11780323;META
to http code google com hosting settings when logged in with your;-5.2151794;-0.48863938;2.2570508;-0.2051647;-1.5065815;2.128119;IRRE
gmail account if you have already committed to your project s;-3.583636;-3.5272472;3.191651;1.5210251;-0.39772457;-0.47092712;CODE
subversion repository the script will automatically retrieve your;-3.0042918;-2.729827;0.1473916;1.823212;-1.9939282;0.68975306;IRRE
credentials from there unless disabled see the output of help;-6.7479496;0.3823974;-0.20952874;0.92618906;-2.8005106;-0.13942435;IRRE
for details;-2.0900033;-3.1439378;4.9187965;0.97230077;-0.22379869;-1.5384201;CODE
if you are looking at this script as a reference for implementing;-3.1310384;-2.297166;2.4481394;0.50241923;2.2653792;-0.3526875;CODE
your own google code file uploader then you should take a look at;-3.709751;-3.5802047;0.839459;-0.33821478;0.16526401;1.2869883;CODE
the upload function which is the meat of the uploader you;-3.1747096;-1.922349;3.5214684;0.46204263;-0.77668864;1.7736366;CODE
basically need to build a multipart form data post request with the;-1.1996367;-0.76700956;3.943641;0.26134333;2.8381245;1.6705157;CODE
right fields and send it to https project googlecode com files;-4.357644;-1.8337225;0.34567657;-0.71493113;-2.2094984;0.5948478;CODE
authenticate the request using http basic authentication as is;-3.2744968;0.7741496;1.1128541;-0.13337067;-0.6473143;1.7250354;CODE
shown below;-3.2490938;-2.2017806;7.432038;-3.754085;0.7291159;-1.9629003;-
licensed under the terms of the apache software license 2 0;-5.2562265;-3.724406;-1.2777694;-0.55046767;2.4906633;-0.2762121;-
http www apache org licenses license 2 0;-4.7077703;-2.688903;-0.54192066;-2.021671;1.8333399;-1.4423686;CODE
questions comments feature requests and patches are most welcome;-4.5132456;-3.8076813;0.86578375;3.3058536;-0.7983436;0.5986661;TASK
please direct all of these to the google code users group;-5.4093227;-4.7699413;0.46915126;1.2045677;1.1625539;-3.0778131;IRRE
http groups google com group google code hosting;-3.9453738;-1.1008458;1.0743614;-0.21606278;-0.63977146;0.2070816;CODE
the login is the user part of user gmail com if the login provided;-3.6753905;-0.8903981;1.6199588;-0.7343827;0.022652242;-0.40706733;-
is in the full user domain form strip it down;-5.7428346;0.2260156;2.4432561;-1.2554576;-1.2038984;1.4386226;CODE
add the metadata about the upload first;-3.5778244;-1.1227653;1.9536794;1.3852414;0.8654157;4.4038997;TASK
now add the file itself;-7.377215;-2.8183508;3.046162;0.37348938;-0.75429803;0.29518157;TASK
the upload server determines the mime type no need to set it;-3.8925312;0.17571853;-1.2580721;0.53277373;-1.8357949;4.069955;TASK
finalize the form body;-3.2760968;1.1634147;3.1146948;1.2986616;1.8922743;1.5980579;CODE
read username if not specified or loaded from svn config or on;-2.297394;-1.6384295;-0.027869029;0.5755605;-0.918351;1.9427878;CODE
subsequent tries;-1.7374394;2.8982155;5.23437;6.29127;1.25306;-2.815287;-
read password if not loaded from svn config or on subsequent tries;-2.2080202;0.17143632;-0.8695218;2.02851;-1.8685572;1.9844555;CODE
returns 403 forbidden instead of 401 unauthorized for bad;-3.1438992;2.629871;-1.941769;-0.024524745;-4.580076;-0.10371782;CODE
credentials as of 2007 07 17;-3.004071;-4.660932;-1.464841;0.03779495;1.5669503;-1.4969736;-
rest for another try;-3.8609838;3.5898685;2.7200534;2.1911345;-2.8026245;-4.111534;CODE
we re done;-2.844766;-0.6582548;3.5174725;1.7275912;-1.9321761;-0.92835104;CODE
force loading of kivy modules;-4.098401;-0.86235243;0.07346534;2.6039042;-3.1921737;3.676329;CODE
check for silenced build;-4.4823895;-0.28513816;-2.217074;3.728685;-0.9849737;0.62746686;CODE
force loading of all classes from factory;-1.5160172;0.6193304;-0.29436916;4.4770904;2.3427107;3.991972;CODE
directory of doc;-4.920886;-4.03546;2.5433574;-0.06514335;0.65182847;-1.2076713;CODE
check touch file;-4.437154;0.14356087;2.991195;2.0334544;-2.9292147;-1.1584233;-
avoid to rewrite the file if the content didn t change;-3.3888466;3.2900398;1.6941342;2.7239926;-2.198796;1.4724087;CODE
activate kivy modules;-5.3668942;-3.3474348;0.21882129;0.9018903;-2.8610876;2.3774424;CODE
search all kivy module;-3.0789042;-3.2064705;-0.03484241;1.0757444;-1.4472448;0.3507849;CODE
extract packages from modules;-0.9677547;-3.289519;-0.61001265;-0.28870672;1.5417024;0.29606837;CODE
create index;0.9473103;1.719702;2.7898324;-3.8625546;3.1620257;-1.5576147;IRRE
create index for all packages;0.42468214;-0.644089;-0.25255013;-1.7459781;2.9896443;1.0329677;IRRE
note on displaying inherited members;-4.7093325;-0.016017457;2.065133;-0.48858786;5.2031984;0.971117;TASK
adding the directive inherited members to automodule achieves this;-5.4260244;0.8350352;-0.761247;2.1126883;1.4275038;5.8927913;CODE
but is not always desired please see;-3.1781938;0.49617627;4.9757605;0.72484225;-0.545594;1.9459513;META
https github com kivy kivy pull 3870;-4.6417637;-4.6522803;0.16746219;-0.35258543;-3.4980795;-1.4548682;CODE
template examples ref ref jump directly to examples;-3.6492274;0.22440168;0.44916138;3.3077836;0.8270912;2.8219323;-
don t take empty line;-2.4757707;4.412761;1.61329;-1.8098187;-1.205579;-2.8530345;CODE
ref mark;-3.7982862;1.3835857;4.148634;1.5625167;0.65060985;-1.0986552;-
search packages;-1.9312286;-5.1413455;0.9296406;1.2954239;1.4770172;-2.0430427;-
search modules;-1.8834713;-3.8964512;0.8171491;1.3481095;1.9733808;-0.95668983;CODE
create index for all module;-0.6072824;1.2363471;-0.04833729;-2.2626896;1.5199587;1.3638939;CODE
search examples;0.12841892;-4.1551776;3.5666766;1.3998146;3.4468496;-3.340321;-
try to found any example in framework directory;-6.9591856;-4.2311788;-0.42132035;0.14140499;-1.614;1.2699705;CODE
extract filename without directory;-1.6507536;-0.08028903;1.9268813;-0.26920187;-0.21644059;-0.115625486;-
add a section;-4.4164243;-1.1918747;6.701803;-0.24613966;2.39878;1.0449177;TASK
put the file in;-5.5889997;-2.1908772;3.046985;-1.535781;-1.508692;-1.3970003;-
generation finished;-3.5141425;-1.3629278;3.6136327;2.2562566;0.57064515;-2.9898782;TASK
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
kivy documentation build configuration file created by;-5.57053;-4.879302;-0.6783408;1.0963067;-2.5698874;0.81087965;IRRE
sphinx quickstart on wed jan 21 22 37 12 2009;-4.3952036;-3.7221859;-0.05891282;1.422646;-0.36510557;-0.3982554;-
this file is execfile d with the current directory set to its containing;-4.9612036;-0.14045793;0.4323286;-1.3912196;0.18530786;-0.46917725;IRRE
dir;-4.2818923;-1.8943379;5.443149;0.14097983;1.2263892;-2.9519448;-
the contents of this file are pickled so don t put values in the namespace;-4.4768753;0.47563073;-2.9701207;-1.7683398;-0.9707647;0.4966394;CODE
that aren t pickleable module imports are okay they re removed;-5.389686;-2.8492172;-3.1418757;0.8709286;0.24893564;1.2391471;CODE
automatically;-2.2970617;-3.8250043;7.040182;4.705111;1.9133338;-0.72195166;IRRE
all configuration values have a default value values that are commented out;-3.2640662;3.2663457;-1.7298008;0.22941226;-0.60950416;2.4009285;IRRE
serve to show the default value;-4.70848;4.64199;2.972512;1.2437246;-0.13082379;2.4986386;IRRE
if your extensions are in another directory add it here if the directory;-6.695442;-0.8333636;0.82858115;-0.41198504;-1.0354707;2.3236432;TASK
is relative to the documentation root use os path abspath to make it;-6.846311;-3.8536847;-1.1764064;0.57921505;-0.8715704;1.742568;CODE
absolute like shown here;-0.4831996;0.46452823;5.54197;-1.4618489;-1.4760778;-0.021415636;-
general configuration;-1.6665144;-1.8953097;4.9528403;-0.7313499;3.1215398;2.6917934;-
add any sphinx extension module names here as strings they can be;-5.6855083;-1.3969464;-3.0940416;-0.3708499;1.3559302;2.1287222;CODE
extensions coming with sphinx named sphinx ext or your custom ones;-6.0428095;-2.9165895;-1.7922026;0.28836215;0.71328247;2.3521852;-
in 4 0 and above has been added the support to substitute by s in the caption;-4.0344152;-0.07148679;0.07688027;-1.500205;0.18807387;1.1378602;TASK
in 6 0 if the caption is a string it must contain s exactly once;-1.9363568;3.6646817;-0.07215024;-2.6480594;1.0981492;-3.2956953;CODE
repo extlink caption s;-5.156887;-2.817365;0.45519403;0.94223434;-0.89219695;2.7856655;-
repo extlink caption;-5.5231457;-2.1803336;0.51872593;1.0719552;-1.3085665;3.2626765;-
todo configuration;-4.9110985;0.19103625;4.172806;2.0846205;0.36527392;1.6994582;TASK
xxx hack mathieu monkey patch the autodoc module to give a better priority;-4.229191;-2.1715872;-1.7126116;3.1162193;-0.9851928;0.8595186;CODE
for classdocumenter or the cython class will be documented as attributeclass;-4.5213737;-5.3108487;-2.6837394;1.3625759;3.6729555;1.0421644;CODE
add any paths that contain templates here relative to this directory;-2.8526237;-0.7756221;1.2785109;-0.37860417;1.0185225;2.385932;CODE
the suffix of source filenames;-3.4956007;-3.615554;-1.516908;-0.2901678;1.8410093;1.1498793;CODE
the master toctree document;-3.6820295;-5.8695035;0.5764255;1.1128042;2.8388803;0.09762363;CODE
general substitutions;-2.0847433;-0.11239358;3.2116253;-0.21102679;1.3495169;-1.5162184;-
the default replacements for version and release also used in various;-4.813822;-4.647839;0.24248907;2.0176764;1.9003859;1.8216455;CODE
other places throughout the built documents;-4.955497;-4.0100875;3.258961;0.69555414;5.433813;1.4717444;CODE
there are two options for replacing today either you set today to some;-4.4408827;0.47666615;1.9736682;1.6618247;-1.4712563;1.3690233;CODE
non false value then it is used;-1.9278315;6.877767;-0.6251047;0.2014954;1.0674958;-5.4338937;IRRE
today;-3.8903816;-2.2541597;5.503705;1.0546299;-0.34318042;-1.2506064;-
else today fmt is used as the format for a strftime call;-4.163191;-0.337088;-0.8317748;0.37311697;0.32002407;-0.32606488;IRRE
suppress exclusion warnings;-1.4567865;4.9604087;-2.5399182;4.4081388;0.60930276;-1.1757712;-
the rest default role used for this markup text to use for all documents;-6.963354;-2.8729227;1.5179492;0.16019839;1.7637701;2.7833004;CODE
default role none;-6.7737517;0.58125097;-0.38524544;-0.91764396;-1.8721962;0.9601222;CODE
if true will be appended to func etc cross reference text;-3.0234392;3.9349806;-0.3798046;3.5039823;2.231236;-2.854845;CODE
add function parentheses true;-3.70908;2.5333688;0.79642147;-0.0007021395;0.69493544;-2.1100404;TASK
if true the current module name will be prepended to all description;-5.7625747;0.91821414;-0.9203459;3.2490382;2.4089832;2.312538;CODE
unit titles such as function;-1.8826323;-1.1285205;2.9309309;-0.67404896;4.142305;-0.4230408;CODE
add module names true;-5.7788076;-0.38980773;-1.4111986;0.6478277;0.5100571;0.051174298;TASK
if true sectionauthor and moduleauthor directives will be shown in the;-5.7278366;-1.2794098;-1.1175059;0.6747716;-0.45736352;2.076527;META
output they are ignored by default;-1.6826385;4.1260333;-1.967709;-0.040238615;-2.7251017;-0.50741875;IRRE
show authors false;-1.0726886;1.2062253;-1.7555493;1.1189109;-0.90513533;-3.6091504;META
the name of the pygments syntax highlighting style to use;-4.293606;-4.3571095;-0.9378605;-1.8235326;-0.3931547;0.5665542;CODE
options for html output;-2.103958;-1.6871557;3.9995558;-0.3469148;0.12951207;0.301062;IRRE
the style sheet to use for html and html help pages a file of that name;-5.0295362;-3.2969701;1.4198383;-1.1295073;1.4135574;1.0544412;CODE
must exist either in sphinx static path or in one of the custom paths;-6.475151;-0.32997727;-2.695649;-0.023045775;0.5040545;2.2343073;CODE
given in html static path;-4.930094;-0.3470327;3.6663682;-0.46678138;0.84224325;0.5016223;CODE
check for theme remove if when switched to rtd;-4.120596;2.2837365;0.30704632;2.0921245;-0.08828994;2.3969722;CODE
the name for this set of sphinx documents if none it defaults to;-4.8452806;-1.2810842;-0.16310202;0.81097585;3.1778915;1.8357023;CODE
project v release documentation;-5.1252556;-6.5939956;-0.71911734;1.599466;0.26715338;0.018383637;CODE
html title none;-6.9493237;0.3297406;0.9405743;-0.2949359;-1.5806875;-1.5854825;-
a shorter title for the navigation bar default is the same as html title;-4.9117556;-1.1420512;1.1637268;0.35273474;-0.0108044995;2.4887555;CODE
html short title none;-6.0126605;0.49723396;0.8293653;0.14079161;-1.2020118;-1.5799385;-
the name of an image file within the static path to place at the top of;-4.1167693;-0.52910197;3.9821901;-1.7434344;-0.8545702;3.6767082;CODE
the sidebar;-4.1154246;-4.7110457;7.1309614;-0.9098669;-1.1512374;-0.583155;IRRE
the name of an image file within the static path to use as favicon of the;-3.7721124;-1.0641137;2.4746397;-1.624857;-0.7352832;3.7811909;CODE
docs this file should be a windows icon file ico being 16x16 or 32x32;-4.9541354;-1.6981038;-1.3921285;-4.2825117;0.0662233;3.3182108;CODE
pixels large;-0.2168085;-0.19993682;3.4460833;-3.6162596;-2.8632224;1.9278531;-
html favicon none;-4.8601146;0.054795306;1.5173441;-1.3250257;-3.508683;1.7623168;-
add any paths that contain custom static files such as style sheets here;-2.7412045;-1.6984082;0.69596213;-0.6475392;1.2742815;3.5764132;TASK
relative to this directory they are copied after the builtin static files;-4.098321;-1.8378862;0.20292112;-0.3266008;-0.99920005;2.1655002;CODE
so a file named default css will overwrite the builtin default css;-4.867566;-0.06870737;-0.3100391;0.5236358;-0.2800345;3.5906715;CODE
if not a last updated on timestamp is inserted at every page bottom;-3.380057;2.6072443;2.4290144;2.8160796;-2.1691465;2.4662707;CODE
using the given strftime format;-2.488044;0.19074644;-1.1781349;-1.4962364;-1.2541511;-0.8357097;CODE
if true smartypants will be used to convert quotes and dashes to;-1.6201993;0.4646741;-2.0583513;0.28860337;1.9917585;-3.298613;OUTD
typographically correct entities;-3.1627734;0.6653861;-0.6478671;2.030628;3.3413355;-1.8596458;IRRE
html use smartypants true;-4.818183;-0.7134939;-0.3429455;2.152146;0.7630237;0.8657575;-
custom sidebar templates maps document names to template names;-3.412569;-1.7360795;0.35863417;-1.4760963;2.0999503;3.4815526;IRRE
html sidebars;-3.13452;-3.2089121;4.8983374;-2.8209512;-0.085925244;1.4437124;IRRE
additional templates that should be rendered to pages maps page names to;-3.0131454;-1.1686357;1.2176815;-0.24789006;2.9469469;3.8362076;TASK
template names;-4.1525016;-2.8298311;2.2120767;-1.4921225;4.0623903;1.102052;-
html additional pages;-3.935382;-1.7367023;4.864411;-0.72439694;2.3089595;2.8390627;TASK
if false no module index is generated;-3.1675184;4.9843183;-3.7643316;2.307938;0.32542804;-0.87721264;CODE
html use modindex true;-3.532082;2.302854;1.0383239;0.18057248;-0.028106738;1.5365434;-
if false no index is generated;0.39303786;7.091204;-1.9115977;1.5683416;1.3675897;-3.015084;-
html use index true;-3.595222;2.1236522;2.4619625;1.012533;-0.542303;1.031466;-
if true the index is split into individual pages for each letter;-0.087239206;2.9804232;1.2558324;-0.5887486;3.8742518;-0.63464457;CODE
html split index false;-2.4282398;3.416298;0.73216456;-1.0301149;-1.0371392;0.4317811;-
if true the rest sources are included in the html build as sources name;-5.883049;-2.8492873;-1.0635096;2.5216703;0.25037634;2.5752723;CODE
html copy source true;-4.368434;-0.9494259;0.064278446;1.3676702;-1.7178903;0.9911084;-
if true an opensearch description file will be output and all pages will;-3.0695522;-1.2580266;-1.2844832;2.9611807;0.2864455;0.9312004;CODE
contain a link tag referring to it the value of this option must be the;-5.455162;1.0130816;1.7377074;0.8511398;1.8736529;1.8221148;TASK
base url from which the finished html is served;-5.415811;-0.27632585;5.6719785;0.42478263;0.12980822;2.660977;TASK
html use opensearch;-3.9420555;-3.6845467;0.3021387;1.690645;-1.1141138;0.47765982;CODE
if nonempty this is the file name suffix for html files e g xhtml;-6.1274166;-1.1160071;-0.29491523;-1.0881088;0.5384132;0.94837815;CODE
html file suffix;-3.9564006;-1.7042165;1.4910685;-1.3157401;0.8793558;1.1045588;-
output file base name for html help builder;-4.9878926;-1.440643;1.4644278;-0.1134215;0.63345915;1.0862094;IRRE
options for latex output;-0.77418786;-2.2475128;3.2142375;-1.305479;1.1200869;-0.6471188;IRRE
the paper size letter or a4;-2.231188;-0.21892355;1.9646636;-2.6766465;1.2792828;-1.2685877;CODE
latex paper size letter;-2.2266185;0.41976997;2.0221777;-4.106744;1.1973165;-0.3088318;CODE
the font size 10pt 11pt or 12pt;-1.6750573;-1.8809988;2.1688702;-2.4704711;-1.3557582;0.9013865;-
latex font size 10pt;-1.3745627;-0.08498525;1.6189244;-2.7129822;-1.7448955;1.492932;-
grouping the document tree into latex files list of tuples;2.3023336;-3.2386596;1.6762784;-1.7814533;2.390899;-0.30725157;CODE
source start file target name title author document class manual;-4.8220415;-4.4664035;-2.3880947;1.0447123;1.3501847;0.7529254;CODE
the name of an image file relative to this directory to place at the top of;-3.2403562;-1.0557871;4.64193;-2.400165;-0.27819473;3.0401764;CODE
the title page;-5.557601;-5.0801597;6.191794;-0.4119689;0.5428871;-1.3154346;-
latex logo none;-4.6795306;1.0058596;1.4209571;-1.7388471;-1.7230723;-0.6875967;-
for manual documents if this is true then toplevel headings are parts;-4.174113;-2.4654324;0.16238014;1.2022654;4.7083106;1.2685717;CODE
not chapters;-3.0543485;-3.0068347;4.246442;1.6989915;1.0943677;-1.1838619;-
deprecated later use parts true;-5.83426;-0.47036827;-1.6365994;4.59195;2.1632147;0.9559432;OUTD
see sphinx builder latex validate config values;-3.5386868;1.1091791;-3.6445515;0.66262543;2.2126205;0.83842444;IRRE
additional stuff for the latex preamble;-4.0489483;-5.061996;2.841277;0.6048962;3.489292;1.0690844;TASK
latex preamble;-4.517231;-2.7110853;2.4132338;0.54277045;1.827817;-0.31383896;-
documents to append as an appendix to all manuals;-4.516932;-2.821942;1.8482372;2.1152828;2.3311944;2.5015357;CODE
latex appendices;-4.149909;-0.12736826;2.8013353;-2.003273;1.6174774;1.6572853;CODE
if false no module index is generated;-3.1675184;4.9843183;-3.7643316;2.307938;0.32542804;-0.87721264;CODE
latex use modindex true;-3.1217325;2.5694668;-0.5273679;-0.3194798;0.65521413;0.8328125;-
if used in a code block the block has to be marked with;-5.9476967;3.663273;-1.9046005;1.0803437;1.8077464;-0.9645643;-
parse literal otherwise it won t be replaced;-3.0711572;3.5977442;-1.6926366;0.45468795;0.9602674;-2.435708;IRRE
doesn t work for code or code block;-7.348304;1.485216;-0.2884429;-0.60780007;-1.498653;-3.3388574;CODE
coding utf 8;-2.2597027;-0.29598817;0.8125681;-3.4921541;-0.7222952;-2.8706045;-
add inheritance info if wanted;-4.85656;-0.7456187;1.9107051;0.10677314;5.387723;0.91756314;TASK
kivy pygments style based on flask tango style;-2.4307494;-2.9185045;-0.25571066;-2.917453;-3.6877897;2.0237646;CODE
the background color is set in kivystyle sty;-4.6240783;-3.3547342;2.8501031;-1.2876577;-2.3957136;2.0277512;IRRE
no corresponding class for the following;-2.5372412;0.99017274;-1.4770709;-2.3371007;3.9594057;-2.2499042;CODE
text class;-1.8484664;-3.30638;3.6516757;0.12770832;4.058162;-4.130752;IRRE
whitespace underline ffffff class w;-1.8374987;0.24998765;-0.83292943;-2.2399902;-0.36600783;0.31891873;IRRE
error ff0000 border ff0000 class err;-4.6943636;0.50926584;-2.2828019;-4.3165727;-1.5598915;-0.8068855;IRRE
other ff0000 class x;-2.385283;-2.3464224;-0.6154257;-2.0506644;3.6976829;-0.9808288;IRRE
comment italic 666385 class c;-5.1551595;-1.6577432;-1.4711024;-0.9932388;1.394964;-2.29258;IRRE
comment preproc noitalic class cp;-5.108899;1.0963951;-1.3763653;0.10311517;2.1568298;-1.1871436;IRRE
keyword bold 000000 class k;-2.899165;-2.353589;-3.638393;-1.7349867;3.7479298;-2.0160298;IRRE
keyword constant bold 000000 class kc;-2.5394654;-1.7669071;-4.9420505;-1.3625946;1.4998107;-1.5562402;CODE
keyword declaration bold 000000 class kd;-4.872573;-2.1808038;-5.5588303;-2.07606;4.9491224;-0.95926034;IRRE
keyword namespace bold 000000 class kn;-4.618058;-3.0072017;-4.6515975;-1.7543334;2.946386;-0.3276356;IRRE
keyword pseudo bold 000000 class kp;-2.4787543;-1.8378363;-4.8386364;-2.6506286;3.7779768;-0.14972727;CODE
keyword reserved bold 000000 class kr;-5.61106;-1.5774199;-5.9948287;-1.1692526;2.5042257;-0.22226451;IRRE
keyword type bold 000000 class kt;-3.033373;-2.1636384;-4.4635143;-1.106041;3.1673815;-1.0489184;IRRE
operator 582800 class o;-1.469907;-0.28317228;-3.1538887;-2.7168956;2.1789572;-3.0776234;IRRE
operator word bold 000000 class ow like keywords;-2.5368936;-1.1111672;-2.3321128;-1.738808;4.8935847;-1.2907456;IRRE
punctuation bold 000000 class p;-4.0830765;0.533991;-2.4650204;-0.94171715;2.884444;-1.744001;IRRE
because special names such as name class name function etc;-4.993439;-3.4266117;-2.8106313;0.2049985;3.1875203;0.5724752;CODE
are not recognized as such later in the parsing we choose them;-2.559535;-1.8288808;-3.1832726;1.5263866;4.287773;-1.4470218;CODE
to look the same as ordinary variables;1.4705883;0.4666463;3.318799;-2.8491142;-0.25992444;-0.12401174;IRRE
name 000000 class n;-2.134369;-2.466637;-0.6145282;-1.9342564;5.0768967;-4.4702954;IRRE
name attribute c4a000 class na to be revised;-1.5688767;-0.16095282;-2.7993438;-0.3622593;3.0245404;0.7810699;IRRE
name builtin 000000 class nb;-4.548651;-3.1097467;-2.7882576;-2.2866576;4.3920484;-2.060182;IRRE
name builtin pseudo aa1105 class bp;-4.627964;-1.8329612;-2.0032847;-2.8769708;5.016338;-1.3908066;CODE
name class db6500 class nc to be revised;-1.70372;-1.5687646;-4.2401047;-0.27276838;4.669166;-1.4219496;IRRE
name constant 000000 class no to be revised;-4.06879;0.10125401;-5.555875;0.5614034;3.7130797;-2.0118332;CODE
name decorator 888 class nd to be revised;-4.776733;-2.5384748;-2.3161614;0.5733215;4.9349337;0.73468935;CODE
name entity ce5c00 class ni;-3.3530867;-1.9970942;-2.5433123;-1.6052718;4.3163815;-1.3273174;IRRE
name exception bold cc0000 class ne;-5.629317;1.4938352;-5.8027067;-0.39773977;3.2234094;-2.117771;CODE
name function db6500 class nf;-2.6353567;-1.1690098;-4.2121696;-2.0851028;3.6482537;-1.5880567;CODE
name property 000000 class py;-4.5594506;-0.65762115;-3.29892;-1.1885905;1.0608058;-1.1639446;IRRE
name label f57900 class nl;-2.938137;-1.8693945;-1.8837434;-1.7359506;4.089223;-0.64516324;IRRE
name namespace 000000 class nn to be revised;-3.6368597;-2.7464116;-3.2756264;-0.453021;4.385762;0.3695128;IRRE
name other 000000 class nx;-2.861942;-2.5017483;-1.1505483;-2.6652136;6.0818334;-1.545139;IRRE
name tag bold 004461 class nt like a keyword;-3.8623986;-2.8988042;-1.5591748;-1.6412086;6.608468;-1.4895004;IRRE
name variable 000000 class nv to be revised;-1.9222016;-0.32891682;-3.99558;-1.3917058;4.500105;-1.0490841;IRRE
name variable class 000000 class vc to be revised;-2.3665752;-1.1542686;-3.6385243;0.26235932;4.0821066;-0.4819687;IRRE
name variable global 000000 class vg to be revised;-2.5049074;0.45638356;-3.2598464;-0.30592215;3.240073;0.63407296;IRRE
name variable instance 000000 class vi to be revised;-3.0649617;0.68730146;-2.9466326;0.28562862;2.9717276;-0.45555854;IRRE
number 990000 class m;-0.046732996;-0.73706526;-0.86101705;-1.8232347;3.4745402;-4.245004;IRRE
literal 000000 class l;-2.025212;0.55377835;-2.592584;-2.5183482;3.1558855;-3.5938678;IRRE
literal date 000000 class ld;-3.4372985;-0.63846403;-4.152238;-0.64852875;2.0456378;-2.366261;IRRE
string 74171b class s;-2.8887715;0.5301603;-2.0558975;-2.315493;3.7545488;-5.0535808;CODE
string backtick 4e9a06 class sb;-4.1988535;1.3064884;-2.0539906;-2.6207843;2.3051114;-1.9012446;CODE
string char 4e9a06 class sc;-3.5121362;-0.22624029;-2.2358074;-2.6140532;1.8072457;-3.1714532;CODE
string doc italic 640000 class sd like a comment;-4.473918;-2.0907233;-2.9068663;-1.1832572;1.6502202;-0.94185776;CODE
string double 74171b class s2;-2.4224784;1.0635625;-2.8081882;-2.4275665;2.7178643;-3.8366723;CODE
string escape 74171b class se;-5.8684654;0.70064265;-3.4148982;-1.500849;2.1168272;-2.634458;CODE
string heredoc 74171b class sh;-4.371483;0.13527662;-2.550791;-0.9831305;0.4974362;-4.0843167;CODE
string interpol 74171b class si;0.027060134;1.7080284;-3.2964675;-4.169749;1.4441922;-2.2611794;CODE
string other 74171b class sx;-3.3518832;1.532769;-2.47834;-2.9314892;5.611472;-1.9437058;CODE
string regex 74171b class sr;-3.457369;1.0370783;-2.7593281;-1.5252131;2.9995701;-2.6963756;CODE
string single 74171b class s1;-2.3060577;1.2650182;-2.6698952;-1.7023501;4.2513323;-3.5925202;CODE
string symbol 74171b class ss;-3.9760458;0.31640172;-3.4966614;-3.6405716;2.937264;-4.0847826;CODE
generic 000000 class g;-1.7846513;0.8109179;-2.182258;-1.4361299;1.8660216;-0.48387983;IRRE
generic deleted a40000 class gd;-2.5613766;0.06728438;-3.7974584;-0.64551014;0.338104;1.2592224;CODE
generic emph italic 000000 class ge;-2.6315272;-0.97404516;-2.5116875;-0.28015414;2.2480195;0.5582159;IRRE
generic error ef2929 class gr;-1.5760784;0.23012774;-4.1372576;0.477085;-0.890133;0.27652344;IRRE
generic heading bold 000080 class gh;-3.5367851;-0.25353393;-2.7110057;-0.6352487;2.691554;0.9284786;IRRE
generic inserted 00a000 class gi;-3.9737833;0.99595344;-4.7231135;-1.1412491;1.10774;-1.1196669;CODE
generic output 888 class go;-3.472094;0.4035319;-1.2664051;1.0393152;1.8343871;-0.90839154;IRRE
generic prompt 745334 class gp;-5.6201077;-0.16669436;-3.565325;0.23229131;3.0541046;-2.2574358;IRRE
generic strong bold 000000 class gs;-0.6528551;-0.050736386;-3.3942885;0.58011425;3.2513177;0.38276356;IRRE
generic subheading bold 800080 class gu;-2.6831036;-0.25330445;-2.302159;-0.2644468;3.553213;1.6797129;IRRE
generic traceback bold a40000 class gt;-2.2102258;-0.4845861;-4.5746126;0.027669791;0.33074883;1.2739073;IRRE
xxx i don t understand the impact of having a priority more than the;-2.800872;1.5732317;3.6404662;2.600606;2.7159371;2.2282133;CODE
attribute or instance method but the thing is if it s a cython module;-3.3580358;0.14496924;-0.923515;1.7561969;1.956073;0.17144445;META
the attribute will be preferred over method;-0.09628032;1.4953053;0.14669818;2.5149138;3.8886073;2.4778247;META
try to check if the first line of the doc is a signature;-7.0661116;0.15525122;-4.3599153;0.91574365;-0.40937513;-1.6492438;CODE
an identifier starts with a letter or underscore;-3.7392676;-1.4269134;-1.8217517;-1.0549555;5.449916;-2.0589652;CODE
followed by optional numbers or letters or underscores;-3.126725;0.24997063;0.48494703;-2.54739;5.0619755;-3.3143196;CODE
test for cython cpdef;-0.38144988;2.7963095;-2.88463;0.8959488;-1.161688;-4.410393;CODE
match identifier identifier anything;-0.88904727;2.3522441;-2.251114;-1.095695;7.5264416;-3.6572983;-
test for cython class;0.47610968;3.241801;-1.3231851;1.6654509;0.29523635;-6.117658;IRRE
match identifier anything;-0.98600364;2.0892134;-1.6625282;-0.9023043;7.701648;-3.9450412;-
test for python method in cython class;-0.62147933;2.4696014;-2.3412268;2.2552073;-2.3528821;-5.344981;CODE
match identifier anything where;-1.1871512;2.4208698;-1.4685123;-0.501548;7.684757;-3.4246993;-
remove empty lines;-2.0918727;4.260011;1.6752955;-2.078801;-0.88704056;-1.5661246;-
if we still have lines remove the title;-5.011483;0.2963874;3.4175713;0.91696113;-0.045836177;0.89536256;TASK
if the title is followed by a separator remove it;-5.688876;2.2781134;1.9734745;0.44438675;2.1809244;-0.96859074;-
trick to realign the first line to the second one;-2.255743;2.4185917;4.4929223;-3.3821735;-1.1032333;-0.85681385;CODE
fixme fail if we finishing with;-4.8081703;1.8186668;0.6219138;5.1931314;-1.9455545;-1.4982184;TASK
calculate the minimum space available;2.1429842;2.806893;1.8807336;-4.4998984;0.9171825;-1.0787758;-
remove that kind of space now;-3.0966752;1.4006733;2.7896137;-1.669545;-0.95144755;0.87953925;CODE
remove the first self argument because python autodoc don t;-4.5028863;1.7245209;-3.2151108;2.9673493;-2.6541855;-0.8059679;CODE
add it for python method class so do the same for cython class;-2.9932966;-0.709318;-1.8489834;0.13084692;-1.6223619;-0.2711688;CODE
get normal components;1.4222697;1.5318153;0.69509536;-4.4878745;2.0772183;1.2691982;-
get texture coordinate components;-0.15927151;-1.5276812;1.0898181;-4.6166396;-0.27314273;3.1273692;-
get vertex components;0.138386;-1.3982635;0.4105928;-3.936438;1.6835155;1.3772212;-
mesh calculate normals;1.6100092;1.8601072;1.5083278;-4.8795085;-2.09763;0.7775069;-
read the magnetic sensor from the hardware class;-1.3949294;-1.747474;0.12627542;-0.75059754;0.009180539;-1.6897006;CODE
calculate the angle;-3.3432176;-0.103175424;4.8212414;-1.941852;-2.0693767;-2.8246758;-
fix animation transition around the unit circle;-1.9720951;0.9983111;3.9014986;-1.0699184;-3.6529148;3.9873004;-
add the number of revolutions to the result;0.21288586;2.2840717;5.7380915;-3.977604;-2.105543;-2.3787918;TASK
animate the needle;-1.4162973;0.2753729;6.7280483;-1.0272989;-1.3963633;-1.0164831;-
when you are going on pause don t forget to stop the sensor;-2.877767;1.2973453;3.1228669;1.7720815;-2.5657318;1.1018777;CODE
reactivate the sensor when you are back to the app;-3.6206262;-0.22859485;3.8290527;3.2086911;-2.0451567;3.5519319;-
create an animation object this object could be stored;-2.0579689;-0.8271027;5.3338304;-1.2792585;1.9967256;2.8794284;IRRE
and reused each call or reused across different widgets;-2.5048;-1.2590375;4.4576235;2.0033278;3.3075478;4.389751;IRRE
is a sequential step while is in parallel;-0.9009923;1.8202574;3.2805095;0.95242757;1.3789868;-0.3331525;CODE
apply the animation on the button passed in the instance argument;-3.6097739;1.3825405;3.1815484;1.653113;-0.43057045;4.4157343;META
notice that default click animation changing the button;-5.412863;-0.15073486;2.1495874;1.1034547;-3.6081655;5.1238933;CODE
color while the mouse is down is unchanged;-3.7678277;1.1394193;4.376953;0.16463324;-3.0390506;2.1949527;CODE
create a button and attach animate method as a on press handler;-4.302245;-0.41643307;4.5709696;1.3254962;-1.2424488;2.7922027;IRRE
kivy require 1 8 0 1 8 is when kv directory became part of app;-4.418496;-1.1322405;-1.0050385;-0.47643104;-2.417671;1.0461206;CODE
note that importing floatlayout causes kivy to execute including;-3.7384255;-1.2297682;-1.3005692;-0.27299684;-4.5698595;2.9903283;CODE
starting up the logger and some other messages;-5.1047263;-0.9773448;2.289853;2.806842;-1.7111368;0.38702112;IRRE
the name idiom executes when run from command line but not from import;-5.126166;-0.8774398;-4.6566772;2.3691256;-2.2634597;-0.14257124;CODE
else help;-3.8811345;0.6688371;4.0251374;-0.25547928;-0.7463064;-2.1838293;-
return a button as a root widget;-5.0761633;0.41812906;3.6709638;0.6095583;-2.7963521;3.2611308;IRRE
we don t actually need to set asyncio as the lib because it is;-5.0106583;-2.80183;-1.342321;2.6615713;-1.7718081;2.4881701;TASK
the default but it doesn t hurt to be explicit;-4.9253163;-1.7068183;1.4914639;0.82130104;1.1812599;3.5321188;CODE
get some sleep;-1.6411917;1.5895777;1.392473;0.7584966;-1.1582346;-1.0330142;-
when canceled print that it finished;-5.303712;-0.29250446;1.8065075;2.3784022;-3.182213;-0.9482792;CODE
we don t actually need to set asyncio as the lib because it is the;-5.114464;-2.9123917;-1.2059418;2.5092707;-1.5195416;2.6655498;TASK
default but it doesn t hurt to be explicit;-4.7688255;-0.8332946;1.0007706;1.1589168;1.2287176;3.1104567;CODE
await async runtouchapp root async lib asyncio run kivy;-3.8370867;-1.7059258;-0.11515904;2.643321;-5.716481;1.8016561;CODE
now cancel all the other tasks that may be running;-4.087772;1.3108922;3.036421;4.6163206;-1.5865095;-0.07259749;TASK
when canceled print that it finished;-5.303712;-0.29250446;1.8065075;2.3784022;-3.182213;-0.9482792;CODE
root builder load string kv root widget;-4.504058;-0.7819319;0.21421775;-0.33106264;-1.23288;2.4495196;CODE
trio needs to be set so that it ll be used for the event loop;-4.411875;1.6649554;2.1549795;0.3619324;-0.2996246;1.5205935;IRRE
get some sleep;-1.6411917;1.5895777;1.392473;0.7584966;-1.1582346;-1.0330142;-
when canceled print that it finished;-5.303712;-0.29250446;1.8065075;2.3784022;-3.182213;-0.9482792;CODE
trio needs to be set so that it ll be used for the event loop;-4.411875;1.6649554;2.1549795;0.3619324;-0.2996246;1.5205935;IRRE
await async runtouchapp root async lib trio run kivy;-4.902297;-1.5854872;0.2959162;2.2648098;-4.434454;1.9662707;CODE
now cancel all the other tasks that may be running;-4.087772;1.3108922;3.036421;4.6163206;-1.5865095;-0.07259749;TASK
when canceled print that it finished;-5.303712;-0.29250446;1.8065075;2.3784022;-3.182213;-0.9482792;CODE
root builder load string kv root widget;-4.504058;-0.7819319;0.21421775;-0.33106264;-1.23288;2.4495196;CODE
stop the sound if it s currently playing;-3.7854927;1.6055257;3.504019;3.2631147;-1.756789;0.7670175;-
encoding utf8;-2.5075014;-1.0010331;0.21731055;-2.9542918;-0.8343528;-0.8265264;-
uncomment these lines to see all the messages;-5.6259594;1.4407232;1.8425436;0.41443643;-1.2953116;-0.3657929;-
from kivy logger import logger;-3.3219059;-3.6691563;-1.058472;0.30676672;-3.1804674;0.6436393;CODE
import logging;-2.9548366;-2.8349946;-0.11955055;1.510946;-1.8561347;-0.6332319;CODE
logger setlevel logging trace;-2.502649;0.8183695;-0.24022713;1.826951;-1.9571092;3.6875687;IRRE
elf d 10 pixel tolerance when clicking on a point;-2.115602;0.82993144;-0.053016134;-1.1214781;-4.1205215;2.4468777;CODE
elf current point none index of point being dragged;-1.8177412;2.0731008;-0.8469634;-2.1101456;-3.6134548;1.5512804;CODE
effect to reduce length while increase offset;1.1482285;2.7833812;3.990153;-1.3161047;-1.871067;3.5031781;IRRE
effect to reduce length while increase offset;1.1482285;2.7833812;3.990153;-1.3161047;-1.871067;3.5031781;IRRE
pacman;-2.2153196;-2.3549788;2.4622953;1.7999002;-0.4866305;-1.0576994;-
wait that all the instructions are in the canvas to set texture;-4.010892;-2.0718436;3.6409495;-0.2796888;-3.3996341;2.5446184;CODE
trick to attach graphics instruction to fbo instead of canvas;-3.720948;-1.3987838;3.1155074;-0.89374584;-3.6670687;3.7975516;CODE
fun result with low segments;2.8523285;2.1975071;4.0986223;-2.970454;0.71636736;-1.1049044;IRRE
setting shader fs to new source code automatically compiles it;-3.589521;-3.5435035;-4.621919;1.442091;-2.9397295;2.2062573;IRRE
here we are binding a custom texture at index 1;-2.2353537;0.06162552;2.3047292;-2.6752436;-0.16458097;6.090798;-
this will be used as texture1 in shader;-2.8874636;-2.6691735;1.0849634;-3.6336396;1.1392417;3.217876;CODE
the filenames are misleading they do not correspond to the;-5.1017284;-2.4680727;-3.6169589;-2.1681807;-0.38438353;-0.3593592;META
index here or in the shader;-0.27485162;-1.8737109;1.7044761;-4.676319;0.40924722;0.49370182;CODE
create a rectangle with texture will be at index 0;-0.6730554;3.2822196;2.9742875;-4.98099;-1.6655866;2.0095067;IRRE
set the texture1 to use texture index 1;-1.0616324;2.4758275;1.3506218;-3.1640902;0.5774875;3.6878364;IRRE
call the constructor of parent;-6.024414;1.0669562;2.535378;0.8486325;2.5670543;0.81770205;CODE
if they are any graphics objects they will be added on our new;-4.231982;-4.9019403;3.772744;0.21518333;2.009983;2.5267367;CODE
canvas;-2.5204036;-2.2431827;8.342898;-2.2614915;-2.5918052;-0.15314566;-
we ll update our glsl variables in a clock;-2.6647727;-1.3207636;0.5287582;0.42780036;0.56760925;1.119448;CODE
this is needed for the default vertex shader;-4.108639;-3.29295;-1.0123168;-3.045324;-0.2655288;5.908366;CODE
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
rectangle of default size 100x100;-1.1519651;2.665034;3.3012438;-5.194062;-1.5293477;3.8555315;CODE
roundedrectangles of default size 100x100;0.14617425;1.2704568;1.4625808;-4.3571534;-1.6939479;3.9872622;CODE
textured;-1.5820744;-3.1013727;4.6805468;-1.111283;1.2833213;0.008467272;-
colored;-1.7340553;-0.8987289;6.361367;-0.7080706;1.7714655;-4.1208034;-
textured colored;-1.0414186;-0.36107937;2.830427;-2.2649136;0.04941288;0.08878605;-
color 3 3 3 1;-2.6631255;-0.38874295;3.8772657;-5.330109;3.2222598;-3.1914847;-
possible radius arguments;-0.4390455;3.030307;2.9685562;-1.9684271;-0.6891504;-2.3418422;-
1 same value for each corner;1.3460872;3.7428145;5.41507;-6.762524;0.9639532;-0.47895166;CODE
with same radius 20x20;-0.30526537;1.8438524;5.9542127;-4.028519;0.5724868;0.8780255;-
with same radius dimensions 20x40;0.13937876;1.29389;5.170434;-4.085982;0.38526058;1.6489272;-
2 different values for each corner;0.8915042;3.1348884;5.7331076;-7.3291955;0.35202765;-0.7469832;IRRE
with different radiuses nxn;1.34366;1.6420133;4.2516603;-5.930322;0.40639114;-0.081787616;-
with different radiuses;0.9040568;1.1014273;6.491808;-3.4628644;0.31731468;-0.6472895;-
default ellipses;-1.8526338;-0.9486295;2.439043;-2.5666852;-2.4794862;2.3620734;CODE
radius dimensions can t be bigger than half of the figure side;-0.87184525;2.230087;2.1657798;-3.191208;-4.1500454;0.99571127;-
segments parameter defines how many segments each corner has;-0.080071;2.5022275;2.1603975;-4.8347;1.9310596;1.2727479;IRRE
more segments more roundness;1.3492844;0.78602713;4.8040857;-1.8615702;-1.0986006;2.0385535;-
various sizes;0.19072708;-1.5886211;4.9407396;-3.251522;2.6327903;-1.8772581;CODE
you can cut corners by setting segments to 1;-1.8781724;0.13476299;4.3680315;-3.5641232;-0.06515684;2.819959;IRRE
you can set different segment count to corners;0.7098019;1.3168225;3.8696806;-4.0811343;1.119643;2.2682922;IRRE
by using a list useful for lowering vertex count;3.2865627;0.14270107;1.1130058;-1.5792384;2.245052;-0.27163324;CODE
by using small amount on small corners while using;-1.3128374;-0.1894706;4.1662827;-1.2229124;-1.6414064;1.408178;CODE
bigger amount on bigger corners;-0.2422137;1.001566;4.7426996;-1.8311044;-2.6075826;0.5614517;-
if radius dimension is 0 then the corner will be sharp;-1.2100337;1.9940712;0.46744254;-2.7726827;-3.1630723;1.3542045;-
90 degrees it is also possible to mix tuple values;3.1653922;2.3957798;2.832102;-6.544735;-0.27232656;-1.2018603;IRRE
with numeric;1.839432;0.20078337;3.9400299;-4.8599367;0.57417774;-5.674439;-
the hollow square shape;-0.34589112;-1.4496332;5.469754;-3.8617234;-0.829644;0.45247424;-
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
loading the content of root kv;-4.8931923;-0.88819736;1.8918948;-0.114390284;-1.337714;1.4330614;CODE
unload the content of the kv file;-4.6187406;-0.23344202;0.637502;0.10713587;-1.7263836;2.4540653;CODE
reason it could have data from previous calls;-2.584807;1.5089304;1.7102749;3.1199002;-0.7715793;0.575159;IRRE
clear the container;-4.6419687;1.8935826;3.7331665;1.2580109;-1.9465942;0.32128805;-
load the content of the kv file;-3.3040788;-1.2774622;1.0374097;-1.039732;-0.92561054;1.6223053;CODE
add the content of the kv file to the container;-4.077162;-0.9933254;1.1008772;-0.71544933;-0.62891537;2.8595195;TASK
node puzzlenode texture subtexture;-2.7014272;0.029993666;0.8211766;-2.0122688;1.2802722;2.747023;-
size bs bs pos bx by;-0.25867677;2.049216;-0.49409422;-4.3703623;1.7079206;-1.6646539;-
config set graphics width 1024;-2.9123452;1.3546791;0.8084561;-3.3927364;-3.048125;4.607509;IRRE
config set graphics height 768;-3.4203691;1.7200747;1.0352749;-3.3468614;-3.1451104;4.705013;IRRE
keycodes on osx;-4.2341943;-3.8121068;-0.21584067;-4.2396803;1.2912552;-0.63833666;-
this allows either ctrl or cmd but not both;-7.3146367;-1.5085863;2.2856293;0.15163235;-1.3348444;3.1290808;META
reset undo redo history;-4.9091153;1.8434784;2.3220434;0.8990205;-1.3609725;2.4950237;CODE
local libraries;-3.151992;-7.11214;0.46710914;0.8154151;0.6508427;0.0021091849;IRRE
if g in self recognizer db not needed for testing;0.57945013;2.0343587;-5.7071266;4.3735876;2.5655756;-1.6088628;CODE
local libraries;-3.151992;-7.11214;0.46710914;0.8154151;0.6508427;0.0021091849;IRRE
refuse heap permute for gestures with more strokes than 3;-2.1908643;2.5186129;2.213521;-0.9834302;1.0753351;1.5455837;CODE
you can increase it but 4 strokes 384 templates 5 3840;-2.7163556;-0.42916262;2.4675379;-2.8369942;2.5739863;2.1300871;META
recognize can block the ui with max gpf 100 show a message;-2.2482553;1.1069659;-1.0103608;2.2473783;-0.74309725;1.8365749;-
get a reference to the original gesturecontainer object;-2.3424823;0.7428184;2.9077694;1.2120395;0.38251966;4.9118333;CODE
reanalyze the candidate strokes using current database;3.3049474;-0.038613547;-0.2877729;2.9032774;4.014755;-2.03773;IRRE
tag the result with the gesture object it didn t change;-2.259856;1.9669299;4.3693485;3.6759698;-0.685003;2.0910246;IRRE
tag the selected item with the updated progresstracker;-1.4753066;-0.124291025;3.5941825;2.7176008;1.3475728;2.6015635;CODE
create a gesturevisualizer that draws the gesture on canvas;-1.1156621;-1.2305907;5.7342157;-0.8796298;-3.3444102;4.80786;IRRE
tag it with the result object so addgestureform load visualizer;-2.1047182;-0.20686321;4.459071;3.1651454;-0.15683919;4.832024;CODE
has the results to build labels in the scrollview;-0.0040061492;-3.1905062;2.6030676;0.13553387;0.79079086;2.3671856;IRRE
add the visualizer to the list of gestures in history screen;-2.644274;-2.069662;5.44396;0.9949449;-1.9623978;4.8269696;TASK
make sure the top is visible;-5.31499;1.0624402;4.147498;-0.44966424;-3.8355918;1.8728806;-
fixme this seems inefficient is there a better way;0.6710485;1.2417897;2.4206262;0.22384351;0.2259207;3.7360802;CODE
local libraries;-3.151992;-7.11214;0.46710914;0.8154151;0.6508427;0.0021091849;IRRE
don t bother creating label if it s not going to be drawn;-1.6712362;-0.79300743;4.819241;-1.352924;1.5289972;0.33320373;CODE
don t bother creating label if it s not going to be drawn;-1.6712362;-0.79300743;4.819241;-1.352924;1.5289972;0.33320373;CODE
setting notransition breaks the history screen possibly related;-5.429976;3.4043252;0.7112458;2.8634822;-4.096113;3.7901073;IRRE
to some inexplicable rendering bugs on my particular system;-3.1759346;0.94277614;-1.2392325;0.86683697;-2.924103;0.27426407;CODE
setup the gesturesurface and bindings to our recognizer;-1.7738452;-3.8619816;0.86579084;-0.24890977;-0.77222425;5.9202228;IRRE
history is the list of gestures drawn on the surface;-3.09307;-3.693808;6.981015;-0.49783033;-1.4546105;2.0602942;-
database is the list of gesture templates in recognizer;-0.96138865;-4.786691;0.8584297;-0.4445346;3.4058552;1.512232;CODE
settings screen;-4.371546;-0.38265148;6.6902714;-1.5457089;-2.2195098;2.4210157;IRRE
wrap in a gridlayout so the main menu is always visible;-2.822088;1.9152143;4.9826655;0.26731598;-1.1157956;5.349114;CODE
the root is created in pictures kv;-5.137062;-3.2882984;3.4342024;-3.360294;-1.4642932;-0.05385019;IRRE
get any files into images directory;-0.7404872;-0.23792402;3.13329;-0.9005216;-1.2932551;0.4908635;CODE
load the image;-3.4747384;-1.4852306;6.890506;-1.0240378;-2.8022964;1.510647;CODE
add to the main field;-5.5470757;-0.753831;6.065776;-0.33818004;1.4664484;0.60501003;TASK
ifdef gl es;-2.3761165;1.4200331;1.5646051;2.1244857;0.15261132;-1.5679303;CODE
endif;-2.5042036;0.32218668;2.8978314;0.36728838;-0.5615267;-1.6890813;CODE
ifdef gl es;-2.3761165;1.4200331;1.5646051;2.1244857;0.15261132;-1.5679303;CODE
endif;-2.5042036;0.32218668;2.8978314;0.36728838;-0.5615267;-1.6890813;CODE
import random random random;0.5750452;-3.3207858;-0.4529794;0.034678284;-0.091446005;-2.6724524;IRRE
this might mean we are on a device whose pressure value is;-0.9756698;-0.34269604;2.6649332;0.6059586;-1.5650438;0.39101937;IRRE
incorrectly reported by sdl3 like recent ios devices;-4.15219;-0.5461544;-4.2730656;0.8891646;-2.053463;1.5441537;-
if pressure changed create a new point instruction;-1.689897;2.3788989;1.5432426;0.80102956;-0.38020232;0.1628838;CODE
install twisted rector must be called before importing the reactor;-4.7845736;-1.9609194;-3.400092;0.73822266;-2.2462537;2.3993173;CODE
a simple client that send messages to the echo server;-3.7314327;-0.40770587;4.2663207;-0.36022186;-1.0233454;0.58968127;CODE
a simple kivy app with a textbox to enter messages and;-3.35335;-3.3050082;4.1859713;1.0922927;-2.4112506;-0.27975965;-
a large label to display all the messages received from;-0.135625;-1.7160473;5.470611;-1.2260832;1.7267196;-0.21347146;CODE
the server;-4.0787525;-4.089521;7.257871;0.5014898;-1.0893631;-2.6748486;-
install twisted rector must be called before importing and using the reactor;-4.591065;-2.143749;-3.522314;0.6952624;-2.2643085;2.2895494;CODE
reactor is already running so we just start the service collection;-4.5847015;-3.2212281;1.6418767;3.307272;-0.13347948;1.1831399;CODE
add pre recorded gestures to database;-1.5609176;-1.4582286;3.706539;1.2169589;0.43565324;3.382924;TASK
start collecting points in touch ud;-1.5923953;-1.154907;4.443936;-0.04443651;-0.26569304;-1.2410554;CODE
create a line to display the points;0.21746983;1.0827038;7.2515135;-6.0294375;-1.1590571;-1.5986346;IRRE
store points of the touch movement;0.11554968;-1.6288397;7.4509754;-1.0196425;-1.7383366;3.0914347;CODE
touch is over display information and check if it matches some;-3.4528391;3.0300825;2.8957484;0.75355107;-3.0518954;0.5557729;IRRE
known gesture;-2.1263285;-1.9397082;5.0995855;0.55715626;-0.9621128;1.3185726;-
gestures to my gestures py;-2.7733567;-2.2641323;2.8428361;-0.6398371;-3.875151;1.1552402;-
print match scores between all known gestures;2.0935755;-0.086650126;2.1376905;-0.51078224;0.17997399;-1.1190586;CODE
use database to find the more alike gesture if any;2.042591;-0.11492061;5.662464;0.2477315;2.9221513;-1.1586709;IRRE
erase the lines on the screen this is a bit quick dirty since we;-4.2907686;0.04152007;4.3419747;-0.6566265;-2.7795193;0.5920355;IRRE
can have another touch event on the way;-4.928503;-0.66449374;8.224593;2.522842;-0.48202303;2.636074;-
kivy require 1 0 6 replace with your current kivy version;-3.695311;0.007758329;-0.77405614;-0.5292173;-2.3154166;-0.40316945;META
author zen code;-5.2381496;-3.9221718;1.1048276;-0.5533332;-0.577888;-1.7813965;META
this example uses features introduced in kivy 1 8 0 namely being able;-2.7057402;-3.6765573;-0.3606332;0.6576158;-0.34458536;1.4489003;CODE
to load custom json files from the app folder;-2.3435426;-1.4030906;2.0088942;0.43800917;-2.4842455;3.442056;CODE
just a space taker to allow for the popup keyboard;-4.7986183;-2.894645;3.8808863;-1.2988813;-1.2821352;1.4317049;CODE
p3 b color ff0000 warning color b this is a system wide;-3.117941;0.54880106;-0.3963754;-3.1274319;1.6903871;-0.14381124;CODE
add the file in our app directory the json extension is required;-5.1183453;-1.6653222;1.3436347;0.34535146;-3.1302571;2.8581986;TASK
system keyboard keycode 122 z;-4.265862;-1.3926225;-0.5362541;-5.1137185;1.1685095;-1.2494276;CODE
dock keyboard keycode z;-4.8556056;-1.5839336;1.1714264;-3.1326776;-0.76467144;1.1092176;CODE
m none the root screen manager;-5.123708;-2.6957235;3.1977265;-1.1771384;-1.8899767;0.8505397;-
ifdef gl es;-2.3761165;1.4200331;1.5646051;2.1244857;0.15261132;-1.5679303;CODE
endif;-2.5042036;0.32218668;2.8978314;0.36728838;-0.5615267;-1.6890813;CODE
change the default canvas to rendercontext we can change the shader;-3.937237;-0.14505096;2.3211539;-0.70198184;-3.583299;6.367252;CODE
add kinect depth provider and start the thread;-3.0150216;-2.507055;1.4963979;0.130285;-2.8622844;4.306623;TASK
parent init;-6.1613035;0.2432503;3.220176;1.9440104;1.1190692;1.5314579;IRRE
allocate texture for pushing depth;-0.9897292;0.22087666;3.5085962;-2.3645098;-2.9646535;5.2461376;CODE
create default canvas element;-4.282935;1.7394593;4.591197;-2.426806;-2.3042839;4.878047;IRRE
add a little clock to update our glsl;-4.393703;-1.386594;1.9705757;1.2538922;-0.039656803;1.7594599;TASK
update projection mat and uvsize;1.5060787;1.4714093;-0.37337497;-3.1695707;-2.695652;6.440004;CODE
print out the given parameter;-0.8988203;3.5492985;2.7748744;-3.6149569;-0.45002404;-5.6282306;IRRE
check the status of the switch by referring on the id;-4.319625;3.4219162;1.8211159;1.3220134;1.8253667;0.092836484;CODE
set the text of the label by referring on the id;-2.3487504;0.79768413;1.8788159;-1.092214;3.9346788;1.3759502;IRRE
set the text of the label by referring on the id;-2.3487504;0.79768413;1.8788159;-1.092214;3.9346788;1.3759502;IRRE
import clipboard kivy core clipboard clipboard;-3.006022;-3.3741562;-1.1216394;-0.85592693;-3.497842;1.3613536;CODE
save an image into bytesio;-2.2549047;-0.42925403;0.30122834;-2.2372909;-2.2236907;1.587495;CODE
joystick gamepad example;-3.0188282;-0.25343916;4.048101;-2.8547091;-1.1846529;-0.7352182;-
stop fire from https wiki libsdl org sdl joyaxisevent;-7.326809;-1.9375172;-1.2633144;1.3382384;-2.3939393;0.47852495;CODE
fire trigger axis;-0.4453935;-0.10429331;4.290063;-2.6768386;-2.424881;2.1099513;-
min value for user to actually trigger axis;1.8100952;3.1781197;2.1499114;-2.724866;-2.2032373;2.5941522;IRRE
current values event instance;-1.5288033;1.8568547;4.5943766;2.719213;1.163532;-0.57049894;IRRE
get joystick events first;-3.4654012;2.0378416;4.5757456;0.8832043;0.36733988;1.0425198;-
show values in console;-2.0244067;3.1220324;5.3149877;-1.929168;-1.3451821;-2.8559265;IRRE
hat first returns max values;1.2238394;4.7236085;0.46414694;-0.84758306;-1.704705;-0.9679191;IRRE
unschedule if at zero or at minimum fire;-1.4141638;3.6003633;0.48418364;2.847017;-0.3348247;-0.3520441;-
schedule if over offset to prevent accidental event with low value;-0.19024706;5.220836;2.1273336;3.7893248;-0.6807639;0.5964558;IRRE
replace window instance with identifier;-4.7262993;0.54274803;1.1801119;0.40953386;4.093428;2.79751;CODE
get app instance to add function from widget;-3.1260207;0.5237881;3.0855696;1.7319201;-2.642368;3.2116926;CODE
add function to the list;-0.93621606;0.86690325;5.0156507;-0.47029674;0.03293282;-2.7530296;TASK
a function catching a dropped file;-1.1093894;3.6654632;1.0695552;3.8108072;-2.795201;-1.4726547;CODE
if it s dropped in the widget s area;-3.3479054;1.4143763;5.2165565;1.7578392;-1.9670744;2.0091271;CODE
on drop file s filename is bytes py3;-3.748193;0.4875963;-3.007551;-1.9836812;-3.4669678;-0.28748202;-
set an empty list that will be later populated;-1.0567257;3.8007305;3.525431;2.7441733;1.8321637;0.2551899;IRRE
with functions from widgets themselves;-2.033355;-2.5348651;3.739907;-0.1292687;-0.9115547;1.8339368;CODE
bind handling function to on drop file;-2.7176402;3.2985432;1.5024712;2.2564335;-0.07056266;2.5240874;CODE
this will execute each function from list with arguments from;-0.73587674;0.6923323;4.3743486;0.5133106;1.4613814;-2.2972448;CODE
window on drop file;-4.559867;0.193364;3.9499676;0.9410761;-2.4092312;2.2033408;CODE
make sure window on drop file works on your system first;-5.428937;0.39314625;0.30756322;1.0910869;-4.747093;2.4128246;CODE
otherwise the example won t work at all;-3.3545978;3.3561924;0.60569525;2.280187;0.6182115;-0.43153372;IRRE
coding utf 8;-2.2597027;-0.29598817;0.8125681;-3.4921541;-0.7222952;-2.8706045;-
import window kivy core window window;-4.4114084;-3.6877925;0.11803124;0.22772473;-4.586769;3.3087764;CODE
this is a simple demo for advanced collisions and mesh creation from a set;0.47721335;-1.5290092;2.2300165;-2.1894317;1.1043085;0.58902556;CODE
of points its purpose is only to give an idea on how to make complex stuff;0.10869408;-4.6706195;5.003223;0.11144288;1.7738221;-0.62986255;META
check garden collider for better performance;-0.62479573;-0.7470841;1.0295111;3.081843;-2.841428;-0.54535466;CODE
cloud polygon 67 vertices custom origin 150 50;-2.627389;0.22611402;0.59725356;-3.9794345;-1.4492589;2.114596;-
keep references for offset;0.68329704;3.316577;2.0537467;0.41583288;0.6392841;2.950272;CODE
shape properties;2.257756;-2.0978544;4.4016643;-2.432533;0.88026303;1.2201449;-
position changed by touch;-4.140446;1.280213;6.534004;-0.18571422;-3.782231;2.8830278;-
position changed by call shape pos x;-3.0834591;2.6723497;2.8886268;-2.3073158;-3.0450156;2.693659;IRRE
move polygon points by offset;-0.09338498;1.2001946;3.5809035;-3.3573852;-2.8884938;2.1703484;IRRE
stick label to bounding box widget;-2.4195073;0.4580305;3.8868597;-2.0839872;-1.200464;3.9552321;-
move debug collider if available;-4.132191;1.1834061;0.21518034;2.3720722;-3.801097;1.9299363;-
return if no mesh available;-1.7786641;6.8697834;0.5525277;3.2851534;-0.5160943;-0.5618729;IRRE
move mesh vertices by offset;-1.0235368;0.9921797;3.2592952;-2.8508825;-3.5367758;3.3247688;IRRE
grab single touch for shape;-1.273791;0.11938337;5.9959183;-0.02735909;-1.7603995;2.8271408;CODE
get touches;-2.963771;0.11729721;6.686776;1.589866;-0.7589294;-1.2602303;-
get offsets move trigger on pos event;-1.0854868;1.729717;2.6251636;0.18415411;-1.8117411;1.3476504;IRRE
ignore if no polygon area is set;0.0013737659;7.002086;1.1265875;1.451132;0.06710563;1.1134765;IRRE
compare point pairs via pip algo too long read;2.4940083;1.567114;-3.4552305;-0.8290059;-2.8995733;-2.8268127;CODE
https en wikipedia org wiki point in polygon;-3.4631093;-3.3246107;3.2839124;-2.2766147;-0.3714702;-0.34561265;CODE
get points within a circle with radius of r x r y;0.6497832;1.0721053;4.296632;-1.8628917;-3.0601165;-0.96469283;CODE
add uv layout zeros for mesh see mesh docs;-2.540739;1.355294;-0.70398206;-3.5521088;-0.8577525;4.5473104;CODE
draw mesh shape from generated poly points;0.75069165;-0.31232008;3.2163544;-3.5247917;-1.8166624;1.9939387;CODE
first point has to be the center of the convex shape s mass;-0.54672474;0.70097274;1.7333387;-2.4844484;-2.7085867;2.9085348;CODE
that s where the triangle fan starts from;-2.3386233;-1.3490248;4.5586176;-1.4206027;-2.2367544;0.42591292;CODE
make the polygon smaller to fit 100x100 bounding box;0.35872132;2.0592787;1.985494;-3.1268005;-1.3655069;4.1850457;-
create list of vertices get edges of the polygon;-0.44602203;0.1939611;3.053097;-2.602288;0.56041574;-0.22448026;IRRE
add uv layout zeros for mesh;-1.5139793;2.1335227;-0.2547174;-3.6729228;-1.1564229;4.8526316;TASK
get center of poly from edges;-0.07328403;1.324228;3.4652565;-3.2786179;-1.531176;2.9911308;CODE
get distance from the widget s center and push the points to;0.12966853;0.7472668;6.279762;-1.8754059;-4.449083;2.8130949;CODE
the widget s origin so that min x and min y for the poly would;-2.414387;0.08281553;3.2571537;-5.3927646;-0.94877434;2.8850408;CODE
result in 0 i e points moved as close as possible to 0 0;1.6509922;4.3225365;1.4384241;-5.4290395;-5.76261;-1.4488184;CODE
no editor gives poly points moved to the origin directly;-4.9711757;0.29307792;-0.3666176;-2.7284305;-4.5037236;3.4018054;OUTD
move polygon points to the bounding box touch;-1.7434133;0.8501373;4.75246;-2.4363155;-3.1426427;3.9867911;CODE
move mesh points to the bounding box image;-0.48265743;0.6304946;4.2670693;-2.6387696;-4.53312;6.1554856;CODE
has to contain the same points as polygon;0.9037283;3.7202108;2.388614;-3.440108;1.9620879;-0.8192359;CODE
draw mesh shape from generated poly points;0.75069165;-0.31232008;3.2163544;-3.5247917;-1.8166624;1.9939387;CODE
debug polygon points with line to see the origin point;-1.1124128;2.4211445;1.2678677;-1.3610207;-4.271495;-0.9799979;CODE
and intersections with the other points;-0.1910018;0.20577769;5.700159;-2.1654277;1.559633;0.021000996;CODE
line points poly;0.32125044;0.27671626;4.0888176;-5.451239;0.3170223;-1.309405;CODE
register an event for collision;-3.2445223;-0.123620115;3.7840688;2.4816484;2.1606877;-0.70738196;CODE
get all combinations from all available shapes;2.3279715;-0.28909323;3.91411;-2.567725;2.557207;-0.5509451;CODE
dispatch a custom event if the objects collide;-2.3627868;0.586678;3.6712408;3.6135106;0.82416034;0.68224657;IRRE
draw collider only if debugging;-2.7496936;2.494503;1.2079355;2.8509727;-4.3374577;0.31727022;-
add circle collider only if the shape doesn t have one;-1.1021576;3.232415;2.203164;0.30563152;-0.37384322;0.98890746;TASK
the environment for all 2d shapes;1.887477;-4.1228814;4.21884;-3.0484588;-0.027865674;3.075934;CODE
list of 2d shapes starting with regular ones;1.0542141;-1.8914566;4.0849857;-4.4827313;0.9127471;0.41591465;-
move shapes to some random position;1.6751055;-1.0836439;5.6803184;-1.9250969;-0.74219453;1.679723;IRRE
check for simple collisions between the shapes;1.9525843;0.8287194;2.141487;-0.87634546;-0.7506748;-2.2786536;CODE
enable shaped window;-4.492892;-0.3950423;5.041658;-1.1302725;-1.7313147;4.908548;CODE
set the window background color to transparent;-4.2957993;0.09747096;2.7958941;-0.41100168;-1.5631276;2.8313642;IRRE
define the kv layout;-1.839083;-3.183685;3.5534065;-4.301482;2.4561167;2.704141;CODE
list of image paths to cycle through;-0.66871226;-1.2360185;5.3576074;-2.089509;0.12061884;1.7179129;CODE
move to the next image in the list;-1.513506;0.3357087;6.866542;-0.971224;-1.9901828;1.8782599;CODE
import json json;-1.6245835;-1.765237;1.2966369;0.09662914;-2.2310543;-0.72751015;CODE
import c kivy utils get color from hex;-3.711353;-2.1755712;-1.8613728;-3.059874;-2.7849293;-0.90856314;CODE
we first define our gui;-3.9656267;-3.7326677;4.8314905;0.5004205;1.2866127;0.85843396;CODE
this json defines entries we want to appear in our app configuration screen;-4.54273;-0.42607006;2.0567908;-0.0914875;-0.61367255;3.5134125;CODE
the line below is optional you could leave it out or use one of the;-6.1614776;1.9439069;1.5580301;1.0289989;1.390388;3.5842462;-
standard options such as settingswithsidebar settingswithspinner;-3.1944637;-2.4910798;2.8835537;-0.40323472;0.2571387;5.666126;IRRE
etc;-2.475695;-3.394726;4.0116262;1.5110282;0.81959635;-0.79704964;-
we apply the saved configuration settings or the defaults;-5.356225;-2.1783137;1.7708427;2.2414544;-1.1052916;5.9902625;CODE
we use the string defined above for our json but it could also be;-4.947987;1.1683561;0.010362589;1.0464405;-0.2763425;0.8295252;CODE
loaded from a file as follows;-2.786061;1.0094558;3.0401466;-0.5282589;-0.09685256;1.0432914;CODE
settings add json panel my label self config settings json;-2.8865685;-0.043198306;1.1276394;-1.0209038;-1.9326656;4.014538;IRRE
plasma shader;-1.7638857;-4.10996;1.9049907;-2.2876945;-1.0438768;0.17304282;-
property to set the source code for fragment shader;-4.125214;-1.3866923;-2.7026796;-0.16685961;1.3803542;5.036935;CODE
instead of using canvas we will use a rendercontext;-3.9445708;0.6190216;4.4902954;-0.27079535;-4.2857313;6.160396;CODE
and change the default shader used;-4.4811373;-2.1791403;0.70940715;-1.4113463;-2.5835595;5.0257564;CODE
call the constructor of parent;-6.024414;1.0669562;2.535378;0.8486325;2.5670543;0.81770205;CODE
if they are any graphics object they will be added on our new canvas;-4.341963;-3.629633;4.6089435;-1.0814154;0.3859291;3.076139;CODE
we ll update our glsl variables in a clock;-2.6647727;-1.3207636;0.5287582;0.42780036;0.56760925;1.119448;CODE
set the fragment shader to our source code;-4.3128023;-2.2076225;-1.5883507;-1.3861779;-1.5482181;4.4308324;IRRE
this is needed for the default vertex shader;-4.108639;-3.29295;-1.0123168;-3.045324;-0.2655288;5.908366;CODE
imported early for side effects needed for shader;-3.571799;-2.6534588;-2.5729396;1.9662619;-1.8805937;2.7723424;CODE
property to set the source code for fragment shader;-4.125214;-1.3866923;-2.7026796;-0.16685961;1.3803542;5.036935;CODE
instead of using canvas we will use a rendercontext;-3.9445708;0.6190216;4.4902954;-0.27079535;-4.2857313;6.160396;CODE
and change the default fragment shader used;-4.71863;-1.2643543;0.54970336;-1.241331;-1.6447413;6.1015964;CODE
call the constructor of parent;-6.024414;1.0669562;2.535378;0.8486325;2.5670543;0.81770205;CODE
if they are any graphics object they will be added on our new canvas;-4.341963;-3.629633;4.6089435;-1.0814154;0.3859291;3.076139;CODE
we ll update our glsl variables in a clock;-2.6647727;-1.3207636;0.5287582;0.42780036;0.56760925;1.119448;CODE
set the fragment shader to our source code;-4.3128033;-2.2076228;-1.5883508;-1.3861793;-1.5482185;4.4308324;IRRE
from kivy core window import window side effects needed by shader;-3.98724;-3.7014246;-1.2386652;1.492062;-5.05162;3.90525;CODE
pulse danguafer silexars 2010;-1.8039035;-2.1602345;0.009668344;-0.5065507;0.48147705;-1.0375541;-
post processing by iq 2009;2.7615664;-1.0447031;1.901855;0.031551067;1.322388;-3.7929273;-
property to set the source code for fragment shader;-4.1252155;-1.3866919;-2.7026799;-0.16685888;1.3803558;5.0369363;CODE
texture of the framebuffer;-1.143234;-0.68316025;2.3870752;-3.4610033;-2.3092213;3.5291855;-
instead of using canvas we will use a rendercontext;-3.9445732;0.6190228;4.490295;-0.27079403;-4.2857323;6.1603947;CODE
and change the default shader used;-4.4811378;-2.1791403;0.709407;-1.4113468;-2.58356;5.0257554;CODE
call the constructor of parent;-6.024414;1.0669562;2.535378;0.8486325;2.5670543;0.81770205;CODE
if they are any graphics object they will be added on our new canvas;-4.341963;-3.629633;4.6089435;-1.0814154;0.3859291;3.076139;CODE
we ll update our glsl variables in a clock;-2.6647718;-1.3207631;0.5287574;0.42780238;0.5676097;1.1194478;CODE
set the fragment shader to our source code;-4.3128023;-2.2076225;-1.5883507;-1.3861779;-1.5482181;4.4308324;IRRE
now if we have new widget to add;-4.5444536;-2.8606374;5.0926695;1.2614928;-0.86347634;2.8057573;TASK
add their graphics canvas to our framebuffer not the usual canvas;-3.2223856;-0.2597842;3.8136437;-1.5205898;-4.275877;5.521005;TASK
prepare shader list;0.03751139;-2.0359583;-0.82739973;-2.2574198;1.467059;0.4199381;-
kivy 1 8 0;-1.475574;-0.11466699;2.3687901;-2.4190712;-2.7154033;-3.1465735;-
from kivy uix image import image;-3.0995677;-2.5757582;0.8008819;-2.29321;-4.9958444;2.3358889;CODE
root add widget image source data logo kivy icon 512 png;-3.283499;-2.0908017;1.1355139;-3.3021657;-3.6480677;3.5182474;TASK
size 800 600;-0.15620215;0.30132696;3.0194442;-2.5290585;-0.8035769;0.7515923;-
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
import f kivy factory factory;-2.4871616;-2.4544315;-0.4282102;-0.42172116;-2.1562903;0.75643545;CODE
width sv width 25 don t draw below scrollbar;-2.2255404;-0.04552271;1.0325885;-3.5479054;-4.739602;2.6331954;IRRE
halign;-3.0233984;-0.7798449;4.5122094;-1.2155942;1.4686062;-2.1591775;-
not supported by textinput;-3.2817008;-1.1828794;-0.8809537;0.39501995;-3.8160431;-1.002828;CODE
halignbutton;-4.654145;-1.3684778;4.0966697;-1.7228523;0.77770454;0.43756515;META
text justify;-1.1804378;0.89070106;4.0143085;-0.9029277;-0.2522252;-0.6555393;-
base direction;-1.748093;-0.53909594;5.164613;-3.0120497;0.07515637;-0.19259125;-
font context;-4.0695953;-2.1357968;4.0722427;-0.35233352;1.3164072;2.1925063;-
font size;-1.2944857;-0.54212874;3.200095;-2.7622068;-1.0956657;0.04685135;-
boxlayout;-3.7076905;-0.8258499;7.1364164;-4.0368037;-0.17733836;2.4478683;-
orientation horizontal;-2.151189;0.40186158;5.250533;-4.45322;0.089162596;0.7842082;-
size hint y none;-1.0709482;0.68804955;3.331555;-1.779836;-1.3277588;-2.9774144;CODE
height 30dp;-1.8969295;-0.8959505;2.820409;-3.1812162;-1.8642831;0.60240006;-
button;-4.9695673;-0.957573;7.838456;0.09697056;-0.27947402;-0.708381;META
color 0 1 0 1;-0.8706737;0.9796794;2.0654967;-5.277619;0.645269;-2.6837304;-
text add font user;-5.151162;-1.7658483;2.3432899;-0.7406899;-0.46749672;0.26038268;TASK
button;-4.9695673;-0.957573;7.838456;0.09697056;-0.27947402;-0.708381;META
color 0 1 0 1;-0.8706737;0.9796794;2.0654967;-5.277619;0.645269;-2.6837304;-
text add font system user;-5.208398;-2.7091088;2.240354;-0.8826942;-0.42088184;0.36847615;TASK
togglebutton;-3.4332397;-0.21053165;4.3272457;-0.041932445;-0.8592256;1.3813559;META
text enable markup;-5.5627804;-0.30768153;3.3161843;-0.29061934;-0.28516635;1.0221301;-
state down;-2.1315677;0.874;4.236861;1.2318465;-0.20904753;-1.2383673;CODE
on state;-2.7002409;-0.43464985;4.120565;0.8676931;2.3639917;-1.3744267;-
for c in boxes children c markup self state down;-2.508189;2.7185628;3.138744;-3.2118979;0.8165283;-2.1261206;CODE
bounce ball off paddles;-1.1591243;-0.024905434;3.3644216;0.6306115;-1.2218862;-1.5654103;TASK
bounce ball off bottom or top;-1.982136;0.8340567;4.8706093;0.65578645;-1.485687;-0.1262796;-
went off a side to score point;-1.8747243;2.6271298;3.7503822;0.14775002;-2.27781;-2.2040923;CODE
bounce off top and bottom;-1.4265074;0.5171902;5.2953324;0.11091482;-1.6158843;-0.85960734;-
bounce off left and right;-2.0938764;0.86386657;5.448173;-0.16734648;-1.0134842;-2.2093096;-
bounce off paddles;-0.7210378;-0.34773585;3.2711086;0.64364296;-1.4380074;-1.5043417;TASK
bounce ball off bottom or top;-1.982136;0.8340567;4.8706093;0.65578645;-1.485687;-0.1262796;-
went off to a side to score point;-2.0040088;2.7147892;3.7397015;0.15927137;-2.3772378;-1.9673973;CODE
kivy require 1 0 6 replace with your current kivy version;-3.695311;0.007758329;-0.77405614;-0.5292173;-2.3154166;-0.40316945;META
kivy 1 0;-1.4029053;0.04636393;2.796707;-1.5439909;-2.6861467;-2.9736822;-
import os os;-2.617769;-4.279652;-0.074816234;-1.560605;-0.6216884;-1.1522621;CODE
each time a picture is created the image can delay the loading;-3.2349412;1.3993332;4.2094474;1.6164984;-2.7504735;3.8672318;CODE
as soon as the image is loaded ensure that the center is changed;-3.3884566;2.066202;4.670786;1.3080356;-4.9317145;6.4702415;CODE
to the center of the screen;-4.4868927;-0.9171572;8.141254;-2.28783;-3.8322108;2.1339602;-
create initial image to be 400 pixels width;-0.645156;2.1231616;3.571524;-4.191464;-1.6581093;4.1130476;IRRE
add shadow background;-4.5456667;-0.9774892;4.7437363;-1.506565;-0.43443725;2.1998856;TASK
the client area in which all editing is done;-4.6037655;-4.588048;4.911059;1.7875061;0.44820037;2.4396431;CODE
we will be accessing this later as app main root widget;-5.963336;-4.6568575;5.0044994;0.17962211;-2.2200096;3.426124;CODE
start searching after the last selected node;-1.6930203;1.8659754;3.6734107;1.0393976;1.1133459;0.46187305;CODE
example for doing a triangle;-1.0346174;-0.434993;6.7678995;-3.9666557;-0.20705858;-2.913127;CODE
this will automatically recalculate px from pos size;-0.27520415;2.336806;1.8681217;-1.0945216;0.20272377;2.6346946;CODE
if you use a widget instead of scatter as base class you need that;-0.43260497;-1.9016207;2.306503;-1.3834783;-1.4494121;5.2818627;CODE
p1 self pos;-3.3459163;-0.097639106;0.77506113;0.73127127;0.31191167;-0.95166844;CODE
p2 self right self y;-4.107097;0.16659273;0.9041558;-0.9092683;-1.0355027;-0.86120737;CODE
p3 self center x self top;-3.599376;1.259694;2.398481;-4.5161467;-1.5538008;3.8268347;CODE
draw something;-2.436045;-1.1242559;8.511478;-1.9629221;-2.1010253;-1.7115432;-
import vector kivy vector vector;0.3832889;-3.6768882;-1.3085629;-4.502352;-3.759608;-0.69741213;CODE
the effect string is glsl code defining an effect function;-4.3112535;0.34130868;-0.83291405;-1.5116042;-0.59739316;0.43035212;CODE
needed to create fbo must be resolved in future kivy version;-4.1658297;-2.9829767;-1.9780189;0.7741697;-4.5354238;1.4238367;TASK
wait that all the instructions are in the canvas to set texture;-4.010892;-2.0718436;3.6409495;-0.2796888;-3.3996341;2.5446184;CODE
trick to attach graphics instruction to fbo instead of canvas;-3.720948;-1.3987838;3.1155074;-0.89374584;-3.6670687;3.7975516;CODE
test with fbofloatlayout or floatlayout;0.14458847;3.146932;0.43786484;0.118411005;-2.7871625;0.29150242;CODE
comment uncomment to test it;-4.0057907;4.664851;1.357409;5.752314;-0.094103895;-6.253406;IRRE
root floatlayout;-3.2581096;-0.46061227;3.2744534;-5.238705;-3.0325348;3.9676237;CODE
this part of creation can be slow try to optimize the loop a;1.9019039;2.4165165;1.287704;-0.5624135;-0.5391112;-2.0099747;CODE
little bit;-2.1502953;-2.2026753;3.453375;-0.64083666;-1.5210966;-1.7618338;-
make elements 29 9 un focusable the widgets are displayed in;-2.5505078;0.8222593;2.9013948;-1.4447824;-2.9700701;3.1949258;CODE
reverse order so 9 39 10;-3.105747;1.8654827;3.0536644;-3.0280352;2.268687;-2.4325442;-
similarly make 39 14 25 and 5 un focusable;-0.093064964;0.4011698;3.7343805;-0.66134876;0.7677768;-1.2563013;-
don t move focus passed this element;-3.3318956;2.6116376;3.5012424;0.31205228;-3.1414287;3.5836363;CODE
exchange the links between the sides so that it ll skip to the other;-3.4720633;1.027992;7.209429;-1.1196129;-0.6835222;3.880825;-
side in the middle remember that children are displayed reversed;-3.9851544;0.65525705;6.9672155;-2.0588975;-1.216798;-0.14208125;CODE
in layouts;-4.679713;-3.734354;6.7805223;-1.9752508;2.533181;1.7320334;-
if it exists this widget is a vkeyboard object which you can use;-4.095934;-1.2764734;3.4453757;-1.7290046;-1.0644965;2.7524776;CODE
to change the keyboard layout;-3.3555362;-2.3742125;4.3975296;-3.643196;0.15718189;2.181854;-
keycode is composed of an integer a string;-2.1880534;1.4587232;-1.2423544;-4.176354;2.8791993;-2.9470377;CODE
if we hit escape release the keyboard;-4.2940965;-1.903149;3.7467718;1.6818845;-1.357396;-0.3541093;IRRE
return true to accept the key otherwise it will be used by;-4.7316465;4.8389287;-0.17404227;1.4269689;-0.8984273;-0.9495562;IRRE
the system;-1.6570615;-2.504155;7.0063763;1.0511956;0.561185;-2.635305;CODE
copied from https en wikipedia org wiki a tale of two cities;-3.2336414;-2.4443238;3.5379074;-0.5145371;-2.321141;-0.4756205;CODE
published in 1859 and public domain;-4.040247;-3.3094242;0.67814714;-0.21686634;0.65326947;-0.70174044;CODE
the newline after the title will help demonstrate halign;-5.393244;-1.5145097;3.0831177;-0.043914016;1.5092916;-1.2514926;CODE
note many of the widgets stacklayout togglebutton spinner have;-3.4059918;-2.5665507;2.5842469;-1.4897443;-1.173172;3.2499466;TASK
defaults set at the bottom of the kv where demolabel and headinglabel;-4.2426653;-1.6090765;0.84407085;-0.01129846;0.24449688;3.253666;IRRE
are also defined;-2.2320411;0.16423951;1.4000343;1.0549423;4.168383;0.24930076;CODE
all labels use these properties set to label defaults;-2.3842988;-0.5506827;-1.1639909;-0.29688257;2.384096;4.192553;IRRE
initialize words generator;-2.1980329;0.2636079;1.1050587;-0.5874248;2.2611809;-1.5146013;IRRE
dynamic kv classes;0.6157026;-2.2119892;0.45052677;0.40090963;4.913115;1.4948334;IRRE
import rgba kivy utils rgba;-2.2712173;-2.843217;-1.741182;-2.8714309;-2.0734224;-0.15553509;CODE
magic value for the default height of the message;-3.0544407;3.7822156;1.4235982;-0.95686305;-0.7628678;2.510119;CODE
bg color 223344;-3.9622881;-0.71795887;0.89119107;-3.892842;2.9065084;-2.2038548;-
create a message for the recycleview;-4.870141;-0.1561241;2.9410198;1.2102793;-0.23670515;1.5584364;IRRE
when the label is updated we want to make sure the displayed size is;-1.411972;0.87863433;2.2547596;-0.42130738;0.08582869;2.5716681;CODE
proper;-3.5174139;-0.75854856;5.5149207;2.5311074;0.34317783;-1.5192271;-
one line dp 50 a bit of hack ymmv;-3.383919;-1.0407314;-0.51105833;-2.1482873;-0.16285014;-1.4586757;-
if the texture is too big limit its size;-0.16421129;1.2882462;2.4297254;-0.15118498;-0.52695996;2.8390856;-
if it was limited but is now too small to be limited raise the limit;-2.0672886;1.7402437;1.5747164;3.1327944;0.5215071;2.1727722;IRRE
just set the size;-1.2367413;1.2500311;5.5201635;-1.9515595;-1.332239;1.6023513;IRRE
elf add message text right 223344;-7.8158283;-0.7987692;-0.009706131;-2.1089168;-0.9311796;-2.6221747;TASK
elf add message do you really think so left 332211;-7.2438345;-0.9398673;-0.62863666;-1.0014219;-0.3579039;-3.187827;TASK
button widget for inner vertical recycleviews;-3.0016;-0.16244897;3.2878478;-2.3952355;-1.1181864;3.9403315;META
panel container holds a vertical recycleview;-3.3195975;0.94167924;2.0702345;-2.2508788;-2.1929977;3.837834;CODE
header label;-4.239048;-1.527364;2.615521;-2.2970068;3.5596402;-0.12520055;CODE
inner vertical recycleview with 50 buttons;-2.5626113;1.2128885;3.6467378;-2.6725838;0.6048994;2.8167257;META
main layout;-4.453265;-2.5115435;7.952819;-3.4908655;0.99425095;2.4345372;CODE
instructions;-3.9721498;-3.6656492;5.4707294;0.307393;0.3937467;-2.696944;CODE
outer horizontal recycleview;-2.6229925;1.2897654;3.1818678;-2.7208517;-0.013265093;3.557696;-
do scroll x true important to set do scroll attributes;-2.7637107;0.5224742;1.2237527;0.57858706;-2.1414578;4.345133;CODE
populate outer recycleview with 20 panels;-1.1251332;1.4967597;2.7882125;-1.0711523;0.29500067;3.695137;-
using a thread to do a potentially long operation without blocking;-2.0191967;1.884856;3.025586;3.5305781;-0.60840565;1.6131438;CODE
the ui;-3.7078478;-5.998243;8.693124;1.2113701;-0.43195733;-1.772935;-
sync one animated property to the value in the proxy;-3.4657717;1.7976797;4.515066;2.4167156;0.0032520283;6.2904425;IRRE
when we are assigned an animation proxy sync our properties to;-4.457526;-0.3622922;2.547506;3.3501213;-0.311815;7.019928;IRRE
the animated version;-3.4594624;-4.269527;6.1818953;0.16687499;-0.6102452;-1.373199;META
if we lose our animation proxy we need to reset the animated;-5.99448;-0.6803916;3.3193128;2.1543186;-2.742984;5.1819754;TASK
property to their default values;-0.8308896;3.3723304;1.7942512;0.82577974;2.8432806;1.8235252;IRRE
the triggered decorator allows delaying the animation until after the;-5.461971;0.2956754;3.1531441;3.4381304;-0.906704;4.5192533;CODE
blue effect on the button is removed to avoid a flash as widgets gets;-5.9755697;-0.3827234;1.7110046;0.14085889;-3.594073;3.1257105;OUTD
reordered when that happens;-4.1648874;1.3886638;2.349309;1.5218142;0.4932746;1.2180171;-
the animation we actually want to do on the item note that any;-4.8907843;-2.7107046;5.1612864;1.468593;-0.84537095;2.736433;TASK
property animated here needs to be synchronized from the proxy to the;-5.789917;0.7952092;3.5019133;2.6200328;-2.5152419;6.136949;TASK
animated widget in on animation proxy and using methods for each;-3.1578684;-0.6401519;3.8792922;1.0948603;-0.92792886;5.6178746;CODE
animation;-1.9125633;-3.5311043;9.386807;-2.0876439;-0.9866269;-0.61565155;-
animation is complete widget should be garbage collected;-3.7134686;1.3637717;1.2719531;1.933123;-3.926524;4.2703743;CODE
my item number one;-1.6652702;1.6828909;5.2674594;-0.76077753;2.8746889;-2.6957457;-
my item number two with some more content;-1.8251108;2.7143667;5.6980615;-2.1612797;4.0962086;-1.3689011;-
my third item;-3.7355196;0.0137235625;5.4559803;-0.9165052;3.0257604;-0.7344836;-
my four item;-2.6049738;0.5485535;5.7053375;-1.4267751;2.9219453;-0.8387315;-
import random random random;0.5750452;-3.3207858;-0.4529794;0.034678284;-0.091446005;-2.6724524;IRRE
import slidetransition kivy uix screenmanager slidetransition;-4.7769833;-2.587433;-1.1231222;-1.6715609;-2.9804254;4.1642833;CODE
import swaptransition kivy uix screenmanager swaptransition;-4.655301;-1.6208413;-1.4714643;-1.638966;-2.1158228;3.9195585;CODE
import wipetransition kivy uix screenmanager wipetransition;-5.2405787;-2.1506045;-1.8197976;-1.3183695;-2.2799182;3.1865702;CODE
import fadetransition kivy uix screenmanager fadetransition;-5.4171047;-1.9850185;-1.3277439;-0.85665506;-3.405632;4.791618;CODE
import riseintransition kivy uix screenmanager riseintransition;-5.394964;-2.2717414;-0.8988952;-1.3743323;-3.8138678;4.4484034;CODE
import fallouttransition kivy uix screenmanager fallouttransition;-5.6762524;-2.4107025;-1.6830634;-0.97476125;-2.8130324;3.460322;CODE
import notransition kivy uix screenmanager notransition;-5.305067;-0.51631564;-2.3169525;0.20854652;-4.157609;3.9787626;CODE
create a default grid layout with custom width height;-0.5456339;1.1591334;2.6999576;-4.372742;0.09798635;5.105183;IRRE
when we add children to the grid layout its size doesn t change at;-2.147919;2.1234984;3.162032;-2.9849093;-2.415355;3.8298764;TASK
all we need to ensure that the height will be the minimum required;-0.37272963;1.0096047;2.8329117;0.3343896;0.09239314;2.6615667;TASK
to contain all the childs otherwise we ll child outside the;-3.4179294;0.6814953;4.4861403;0.76357824;3.1334949;0.60597515;CODE
bounding box of the childs;-0.7785648;2.0144956;5.7320557;-2.4411736;0.72758406;1.1705216;-
add button into that grid;-2.741485;-0.33548144;6.1917143;-2.4849539;-0.30343857;2.496358;TASK
create a scroll view with a size size of the grid;-0.016642274;-0.17121352;4.7164555;-3.680471;-2.3025706;4.3254223;IRRE
kv string defining the layout structure;-2.4419978;-0.8535623;0.7980855;-5.1391644;3.6017268;1.7525042;CODE
inner horizontal scrollview;-2.228596;-0.66759527;4.26254;-3.0589345;-1.0382848;3.1230345;-
inner vertical scrollview;-2.2319686;-1.2756352;3.9161847;-2.7845845;-1.4530274;3.4516654;-
main layout;-4.453266;-2.511544;7.9528184;-3.4908657;0.99425036;2.4345372;CODE
left side vertical outer with horizontal inner scrollviews;-1.8194859;-0.69136673;3.5175695;-3.087894;-0.59438777;3.379271;-
right side horizontal outer with vertical inner scrollviews;-2.0708215;-0.9485224;3.7172933;-3.0825791;-0.7783405;3.1872597;-
add row label;-0.3102902;0.8475842;3.2343383;-4.0227447;2.139651;0.1349798;TASK
add 15 buttons;-3.4527638;-0.80926967;6.2274885;-2.4399881;1.346603;0.013426185;TASK
add column label;-0.038160507;-0.26978463;2.544489;-4.2245097;1.5984306;-0.39183804;TASK
add 20 buttons;-3.4361715;0.2085646;5.835365;-1.7336704;1.4402673;0.3888323;TASK
kv string defining the layout structure;-2.4419978;-0.8535623;0.7980855;-5.1391644;3.6017268;1.7525042;CODE
header row;-2.2786798;1.1927931;4.716442;-4.0002217;2.2450984;-1.0161968;CODE
inner vertical scroll centered with spacers;-1.2272499;0.09976206;2.593331;-3.8792515;-2.3814168;4.235703;-
label left spacer;-1.6196245;0.041577112;2.017585;-4.8806195;1.5087693;0.49285772;-
label right spacer;-1.2541599;-0.12465836;2.0212824;-4.666819;1.2148442;0.5496241;-
main layout;-4.453266;-2.511544;7.9528184;-3.4908657;0.99425036;2.4345372;CODE
info label at the top;-3.24425;-4.2674365;5.0347457;-2.150834;2.1235502;0.07761426;-
add 30 labels to make it scrollable;-1.0506741;-0.43079677;4.32413;-3.435296;0.62738764;1.7400311;TASK
color 0 2 0 6 1 1 blue color to distinguish inner items;1.3550073;1.4609321;2.1862328;-6.3666806;4.251137;-2.3771944;-
size label to fit text;1.2737935;0.23354787;3.4342077;-3.04349;1.0981449;0.86988515;-
bind scrollview width to content width so it centers properly;-1.3070521;0.6585245;1.9131294;-1.1323358;-2.940529;5.461652;-
initialize variables;-3.1073725;2.9584568;2.0572822;-0.8381858;0.74314195;-1.1456863;IRRE
setup layouts;-3.2231562;-2.287554;5.398722;-4.137781;1.8011382;3.606978;IRRE
setup buttons in left frame;-3.7583506;-0.29475486;4.8993096;-2.9765456;-1.3068883;4.108853;IRRE
handle button press release;-6.9466333;-0.4686438;3.6311269;2.5543852;-1.4993203;1.9178323;META
position scatter;2.7785385;-0.7176477;5.7368155;-5.4552464;-4.256302;1.5751244;-
bind function on on release;-5.5692196;0.438035;1.1856921;3.0715268;0.14643174;3.2007785;CODE
add widgets to left frame;-3.2090707;-1.1668065;5.128107;-3.1705933;-3.1943467;3.936325;TASK
set remove border for borderless widgets 16 16 16 16 by default;-3.8793542;1.6396925;2.017614;-2.3517232;-2.8689692;4.792354;CODE
add widgets to the main layout;-3.298794;-1.6345199;5.130826;-2.2052145;-1.7169511;4.7474303;TASK
add main layout to root;-5.3244643;-0.8684319;4.6583066;-2.3841376;-0.72631496;4.405664;TASK
borderimage border by default is;-4.5105743;0.2704755;2.5403605;-1.6677381;-2.9019194;4.604874;CODE
image to display depending on state;-0.88813573;2.491896;7.6536226;-0.65960544;0.25036988;2.277335;TASK
reset animation if anim delay is changed;-3.6987913;3.4998229;2.0526922;1.3603412;-3.1048348;3.3501496;IRRE
update self texture when image texture changes;-1.3599403;1.2720811;1.5287718;0.4925639;-1.3574914;4.850798;CODE
update image source when background image is changed;-2.9663618;0.5561829;3.195658;0.7181284;-1.626836;4.3462677;CODE
replace the default tab with our custom tab class;-3.5018742;0.23138349;2.0603259;0.67841095;0.109245054;3.4009366;CODE
variable tab width;-1.6957736;1.2548947;3.3777678;-3.0773025;-0.52839106;1.3055507;CODE
replace the default tab with our custom tab;-3.2943628;0.5194753;3.2858565;-0.010978219;-1.439517;4.4612308;CODE
allow variable tab width;-3.0691497;2.4183674;1.4003137;-1.7438685;-0.5626904;2.6790895;CODE
override tab switching method to animate on tab switch;-3.8664231;0.95149595;2.5903087;0.5042283;-1.9299406;4.8637795;CODE
use dock virtual keyboard one instance;-2.9016426;-1.0584745;1.515416;0.25996608;-1.7867724;2.3675985;CODE
use multi users virtual keyboard multiples instance;-2.517984;-1.4277381;1.0472876;0.06748891;0.6304814;1.2886254;-
use system keyboard one instance;-2.8157313;-1.9548671;1.6782349;0.59649396;0.55799097;2.0582833;CODE
use automatic detection from current platform;-0.37599996;-3.6623218;-0.46644557;3.330941;0.7964898;0.26415128;CODE
create a button to release everything;-5.128597;-0.8083783;6.1637025;2.6172578;0.19514573;3.246162;IRRE
show current configuration;-3.3101082;0.9210719;4.02553;0.7415252;0.2744816;2.330028;-
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
import utils kivy;-3.4518697;-4.1549516;-0.21778935;-0.6952838;-2.9152453;-1.1573241;CODE
import os os;-2.617769;-4.279651;-0.07481588;-1.5606052;-0.62168795;-1.1522626;CODE
import factory kivy factory factory;-2.861122;-1.9342978;-0.104994364;-0.15817167;-1.1954715;1.4245754;CODE
check what formats are supported for your targeted devices;-3.6645863;-2.0958693;-3.297674;-1.4118543;-0.86178285;1.656373;CODE
for example try h264 video and acc audo for android using an mp4;-2.272866;-2.425756;0.24394548;-0.5996358;-1.9840798;2.819547;CODE
container;-2.807707;-1.5365554;5.5959606;0.12710631;0.54490083;-1.3172313;-
internals for post configuration;-4.4526453;-0.554637;3.4784353;1.3913205;2.115471;2.7834141;CODE
user version;-4.9582453;-3.5698376;3.020111;0.062710464;-0.51395077;-2.328838;META
current version;-4.693153;-3.4741857;2.6525524;1.3556457;0.46582654;-1.8775356;META
not tag rev alpha 1 beta x allowed;-5.4819946;-0.7272828;-0.38243037;-0.08027624;0.303585;-0.49315155;-
finally checking revision;-4.589023;0.42020926;0.47573337;3.5267966;-1.9027503;-3.982153;CODE
global settings options for kivy;-3.5986526;-2.915221;3.0175602;1.2619232;-2.7173452;4.5363584;IRRE
read environment;-4.1704726;-3.2196047;1.6080219;2.3701935;-0.06682611;-1.1933485;CODE
extract all needed path in kivy;-1.7771419;-0.9629012;1.4518837;0.57180613;-1.7331383;0.7781844;-
kivy directory;-4.1257863;-4.406433;1.8459923;0.07578218;-2.8073778;0.030937508;-
kivy modules directory;-4.3811846;-4.319163;-0.07666386;-0.21268845;-2.5440154;1.0583435;CODE
kivy data directory;-2.7458103;-3.8545735;0.97584486;-0.5444141;-2.6350791;0.60644346;-
kivy binary deps directory;-3.963069;-4.017214;-1.6052862;-1.5184994;-1.2182896;-0.17175107;-
kivy glsl shader directory;-4.168995;-4.788896;-1.1997688;-1.2810211;-2.7524607;1.7491344;-
kivy icons config path don t remove the last;-4.2969065;-0.23799315;1.6165534;-0.08959824;-3.8422325;4.803453;CODE
kivy user home storage directory;-3.1307878;-3.1217563;1.5529634;-0.46037605;-2.5226295;1.0146116;-
kivy configuration filename;-4.6587353;-2.5314567;0.6768495;-0.25445879;-2.3188055;1.776027;-
kivy user modules directory;-4.5227;-4.2286124;0.15826511;-0.41838503;-2.8702981;0.98954904;CODE
kivy examples directory;-4.2351704;-5.2950835;0.69197106;0.45178914;-1.9883087;-0.03447078;-
if there are deps import them so they can do their magic;-2.0479898;-1.4026321;0.6892573;2.538498;2.51108;1.2876941;CODE
don t go further if we generate documentation;-4.611228;-5.8413215;0.7872699;3.7242095;3.0337703;-1.450096;CODE
configuration management;-1.7142617;-2.4234514;4.7821136;1.617806;2.3362215;1.7342252;-
detection if venv being used with the framework;-0.054147784;-1.7304835;-2.7774127;3.720306;-0.15303653;0.32330182;-
configuration;-4.1031885;-1.3360456;6.3362236;-1.2590386;1.8317149;0.42964208;-
set level of logger;-2.7090855;1.2951236;1.7184132;0.8190344;-0.112109326;2.8731103;IRRE
can be overridden in command line;-6.8872576;2.5977242;-0.90445405;0.9274735;-0.33227202;1.1626676;CODE
save sys argv otherwise gstreamer use it and display help;-4.0654454;-0.8787608;0.557024;0.25508484;-2.1621974;3.7657294;CODE
set argv to the non read args;-2.3881772;2.9315603;-1.397734;0.8087377;-2.0424104;2.0022023;IRRE
needs to be first opt for support freeze to work;-5.194092;0.15720029;-0.07470537;1.9130266;-2.8003314;2.7472727;TASK
when we are doing an executable on macosx with;-7.0718393;-2.3826373;-0.5013324;-0.50554353;-2.7683425;-0.22645457;CODE
pyinstaller they are passing information with p so;-4.7330914;-2.8703635;-2.140228;0.41364643;-2.1730654;-0.5891839;CODE
it will conflict with our current p option since the;-5.039696;0.6348;0.90651745;3.5910966;1.8162494;4.544089;-
format is not the same just avoid it;-3.0909293;1.2645836;-1.8942019;-1.4434423;1.0285797;0.91160774;CODE
configure all activated modules;-3.5893915;-0.39957398;-0.020142054;-0.24449381;1.2188835;4.054863;CODE
android hooks force fullscreen and add android touch input provider;-3.0880435;0.89710647;1.2686114;1.4978307;-3.0457575;4.718638;CODE
this file is imported from init py and exec d from setup py;-5.4292793;-1.8604431;-1.7859125;-2.4902537;-2.353749;0.25182548;CODE
if it s a rcx release it s not proceeded by a period if it is a;-4.404988;0.4148766;1.2077037;1.9066019;0.5288583;2.2000318;-
devx release it must start with a period;-5.3375826;-2.5127194;0.49993905;0.06459726;-0.67029816;-0.076900765;-
initialize;-4.5158615;1.929728;2.6293106;0.2203562;1.0241725;-1.9811429;IRRE
and later;-2.201772;-2.0195792;5.9220166;3.9571943;1.1892352;-0.3216324;-
and later;-2.201772;-2.0195792;5.9220166;3.9571943;1.1892352;-0.3216324;-
no more properties to animation kill the animation;-4.4684434;0.57665384;1.5174336;1.1029217;-2.4551177;3.1476018;-
no more properties to animation kill the animation;-4.4684434;0.57665384;1.5174336;1.1029217;-2.4551177;3.1476018;-
private;-3.4954188;-1.6864076;5.220953;0.23000242;0.40702155;-2.3223498;CODE
get current values;0.33591115;3.6765082;4.5115004;-0.90262157;0.042774532;-4.018377;IRRE
install clock;-4.3983703;-2.2517738;1.7923017;-1.2009932;-1.5471768;-0.38192138;-
empty proxy widget is gone ref 2458;-6.349926;0.756629;0.7969511;0.73024493;-4.3440313;2.666223;-
calculate progression;1.4722612;1.2867986;5.027606;-3.5545878;0.19248024;-4.9778056;-
apply progression on widget;-0.44894183;0.7218553;4.6975365;-1.2053275;-0.5976178;1.9953306;-
time to stop;-1.648296;0.96019244;4.5483165;1.5541906;-1.1842508;-1.1577413;-
user requested to animate only part of the dict;-4.824123;0.31117532;1.8944731;-1.0359277;-2.711188;0.9841284;CODE
copy the rest;-3.6728423;-1.7519845;4.6542563;-0.38276023;-0.46872976;-2.0306504;-
default handlers;-6.7036915;-0.997621;2.0041447;3.4783216;-0.6706651;4.503354;CODE
this property is impossible to implement;-2.8608534;5.481624;2.5202124;0.7608391;2.9510708;2.3061967;CODE
repeat the sequence see repeating animation in the header;-3.9408004;1.1360754;4.634769;-1.5097498;0.7057837;0.7760463;CODE
documentation;-5.275622;-7.480966;3.7151163;2.304026;2.9932058;-2.7141862;CODE
and more;-1.2416573;-2.8050458;4.186868;2.4025908;1.1309555;-1.5531658;-
will search for the path to myatlas atlas and get the image id;-2.4605725;-0.97630066;1.7384964;-1.5354334;-0.63187206;1.6543945;CODE
late import to prevent recursion;-2.8442428;1.2719353;-2.7202787;3.445093;-0.7638118;-0.6748135;CODE
late import to prevent recursive import;-2.6860008;0.76327187;-2.7685204;3.5927658;-0.92574805;0.6925021;CODE
must be a name finished by atlas;-3.340596;-2.6166177;1.5683395;0.033893142;0.78620565;0.22222678;TASK
load the image;-3.4747384;-1.4852306;6.890506;-1.0240378;-2.8022964;1.510647;CODE
for all the uid load the image get the region and put;-2.5035267;0.60795635;4.469296;-1.541542;-0.9947591;4.053676;CODE
it in our dict;-2.815058;-2.1764185;2.9200618;-0.31143737;0.1568553;-3.4547338;-
thanks to;-2.59586;-1.7325928;1.4748455;0.8640522;-0.3585273;0.46279442;-
omnisaurusgames com 2011 06 texture atlas generation using python;-0.35050654;-5.0589705;-1.384915;-3.9516497;-2.521064;-0.2899276;CODE
for its initial implementation;-1.8292576;-2.4420881;2.3865259;0.28864992;2.2370048;-0.6280334;TASK
open all of the images;-1.7234247;-1.2922575;6.5131397;-0.75392276;-0.6200322;2.4690437;CODE
sort by image area;1.3207155;1.0951219;5.116397;-3.3049908;-0.37932184;2.2872267;-
free boxes are empty space in our output image set;-1.156805;1.866311;1.1028807;-3.6086774;-3.0142372;1.7153654;IRRE
the freebox tuple format is outidx x y w h;-4.667075;-0.39105698;-2.052377;-4.91095;1.1006008;-0.95580435;CODE
full boxes are areas where we have placed images in the atlas;-2.2471375;-2.5540116;4.907031;-2.286684;0.51101625;3.4532833;CODE
the full box tuple format is image outidx x y w h filename;-4.346279;-0.6798485;-0.52693903;-6.4398217;-0.04829448;0.8310379;CODE
do the actual atlasing by sticking the largest images we can;2.1980307;-2.0149193;4.2084804;-1.4186405;-0.69088465;5.8292465;CODE
have into the smallest valid free boxes;1.0880468;2.7186036;0.8696455;-2.8344245;4.1978235;-2.0131495;CODE
find the smallest free box that will contain this image;-0.20104149;1.466222;4.0546412;-4.4070973;0.433703;0.18336721;CODE
we found a valid spot remove the current;-4.1095066;3.087567;0.28656882;0.7522147;-2.3407555;1.046367;-
freebox and split the leftover space into up to;-0.19309102;1.4286985;3.8660667;-2.3875122;2.2415323;2.8248568;CODE
two new freeboxes;-3.0374885;-0.64699996;2.6146595;0.24704188;2.6210368;-0.012243077;CODE
keep this sorted;-1.8707008;0.702853;2.5297952;0.65589887;0.21081015;-1.3328077;CODE
oh crap there isn t room in any of our free;-1.0846505;0.7855541;1.0641316;-0.85534567;-0.49776062;0.73925805;-
boxes so we have to add a new output image;-2.169956;-0.63172656;6.559574;-2.4375498;0.7607018;2.3043046;TASK
now that we ve figured out where everything goes make the output;-1.3190576;-2.911085;2.898823;0.49311328;-1.9047883;-1.19919;IRRE
images and blit the source images to the appropriate locations;-1.4095435;-1.7886951;4.1849174;-2.4165325;-1.0045121;3.4845746;-
save the output images;-0.82324123;-1.0804241;4.4121757;-0.87263125;-2.3741267;2.168732;IRRE
write out an json file that says where everything ended up;-1.2662263;0.586453;4.3661995;1.0565449;-2.099912;-1.1598641;CODE
fb 6 contain the filename;-5.12258;-0.719139;0.08519172;-0.9002721;1.2152481;-0.22306263;CODE
use the path with separators replaced by;-4.2706447;0.50252277;1.5730112;-2.0182166;0.1775491;0.59932935;IRRE
example data tiles green grass png becomes;-2.138569;0.7665158;2.1081111;-2.759156;-2.285261;2.7083867;-
data tiles green grass;1.1726005;-1.9536351;3.1473994;-3.5661469;0.49308017;1.0265487;-
remove leading dots and slashes;-4.5407104;0.10738764;1.6142924;-3.050661;-1.6875662;-1.5158302;CODE
replace remaining slashes with;-3.9631922;0.6001149;2.5190094;-2.1259074;-0.26087138;-1.3563228;CODE
for example data tiles green grass png;-0.49630243;-2.930084;4.2689414;-3.5782301;0.28841665;2.1585283;CODE
just get only green grass as the uniq id;-1.4329342;0.64998233;0.53724724;-1.8940729;4.107319;-0.13045596;-
earlier import of kivy has already called getopt to remove kivy system;-5.0702105;-2.1602182;-1.1868382;2.2978516;-4.558629;2.310774;CODE
arguments from this line that is all arguments up to the first;-2.9463127;2.4821532;2.6846464;-1.855141;0.72110885;-3.5707488;CODE
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
private vars;-3.2766802;0.4103502;1.4344977;1.1398185;0.93062234;-1.0153666;CODE
instance of a class exceptionmanagerbase implementation;-1.6281327;0.17551066;-0.8047915;3.8150988;1.3156025;1.9711863;CODE
import kivy core window noqa;-4.86513;-3.7660232;-0.7179528;-0.09089655;-4.871817;2.2966905;CODE
xxx stop in reverse order that we started them like push;-4.6506805;2.862157;4.3141527;-0.3850671;-1.0063188;-0.15377946;-
pop very important because e g wm touch and wm pen both;-3.5376818;-0.5949585;4.765934;2.028009;-1.7069433;0.9313394;CODE
store old window proc and the restore if order is messed big;-2.695694;2.178818;0.7495999;0.5276428;0.52967995;3.5355294;CODE
problem happens crashing badly without error;-2.940458;1.6031914;-2.5710726;1.7663295;-2.7655232;-2.155301;-
ensure any restart will not break anything later;-3.6735427;1.9765766;1.623392;5.9130397;-1.0038422;0.7580672;CODE
update available list;-1.6601787;-0.0681779;2.9127603;2.3513908;1.845753;0.07308063;CODE
dispatch to listeners;-3.7275991;-1.9042513;3.3245926;4.328118;2.424451;3.4790199;-
dispatch grabbed touch;-5.7620134;-0.17501737;4.859371;2.9276247;-1.453795;0.64036345;-
non touch event must be handled by the event manager;-5.7369003;0.867045;2.8939178;3.0025702;-2.3252275;4.541942;TASK
weak widget is a weak reference to widget;-2.952593;-0.97885895;-1.145366;2.6448312;-1.5601892;3.6667438;CODE
object is gone stop;-6.0604057;2.8694327;4.004961;1.9563531;-3.0542963;-0.7950454;IRRE
don t dispatch again touch in on touch down;-6.3243074;1.3005345;3.468236;4.1801643;-1.0222495;2.600112;CODE
a down event are nearly uniq here;0.07907736;0.89593023;3.9677093;1.8872273;1.9361379;-0.44253713;CODE
wid dispatch on touch down touch;-4.7297354;-0.9841743;2.5038428;1.8891473;0.19474867;3.8316264;CODE
remove the save event for the touch if exist;-4.8480086;3.2724445;4.5241694;4.8225746;-2.6056383;2.2280164;CODE
first acquire input events;-2.9689353;-0.050118286;4.586811;3.2040145;2.137563;-0.38272417;CODE
execute post processing modules;-4.277893;0.048287164;0.3371051;2.4609046;0.5745301;1.0338459;CODE
real dispatch input;-1.6251227;-1.1960937;3.1226337;1.828528;1.1040099;0.5477165;CODE
use exception manager first;-3.4310977;2.0997543;1.0301158;5.5333943;0.17191014;1.8361133;CODE
use exception manager first;-3.4310977;2.0997543;1.0301158;5.5333943;0.17191014;1.8361133;CODE
update dt;-3.1558573;-1.4926195;1.59697;0.8756115;-0.4605377;-1.5069017;CODE
read and dispatch input from providers;-1.7655624;-1.08058;1.5543752;2.9307299;2.883794;3.2055573;CODE
flush all the canvas operation;-4.6580524;2.9448342;4.655132;0.011689964;-4.0185795;3.1988206;-
tick before draw;-2.7480292;2.901203;6.743513;-0.6048628;-1.6783425;-0.9048611;CODE
flush all the canvas operation;-4.6580524;2.9448342;4.655132;0.011689964;-4.0185795;3.1988206;-
don t loop if we don t have listeners;-0.53024286;3.221633;3.348138;3.5243454;0.7191132;-0.19367962;CODE
update dt;-3.1558573;-1.4926195;1.59697;0.8756115;-0.4605377;-1.5069017;CODE
read and dispatch input from providers;-1.7655624;-1.08058;1.5543752;2.9307299;2.883794;3.2055573;CODE
flush all the canvas operation;-4.6580524;2.9448342;4.655132;0.011689964;-4.0185795;3.1988206;-
tick before draw;-2.7480292;2.901203;6.743513;-0.6048628;-1.6783425;-0.9048611;CODE
flush all the canvas operation;-4.6580524;2.9448342;4.655132;0.011689964;-4.0185795;3.1988206;-
don t loop if we don t have listeners;-0.53024286;3.221633;3.348138;3.5243454;0.7191132;-0.19367962;CODE
eventloop instance;-4.3540535;-1.557048;3.416458;3.9303918;0.57038414;1.8706175;IRRE
ok we got one widget and we are not in embedded mode;-6.3049097;-0.38687623;3.117747;-0.90493816;-2.9149165;3.3884487;CODE
so user don t create the window let s create it for him;-6.9967394;-1.0130956;3.2142403;0.66394764;-1.6031468;0.93270236;CODE
instance all configured input;-1.4233867;0.46616253;1.414496;2.0145552;0.23924753;0.93551993;CODE
split value;2.3669827;3.5169947;3.596384;-3.9796293;3.4188645;-4.180214;IRRE
create provider;-4.543962;-1.1502278;2.065958;-1.1177258;2.59852;2.390919;IRRE
add postproc modules;-4.8848987;-1.5491716;-0.6906928;0.46345225;0.092015006;1.0976278;TASK
add main widget;-4.4421663;-1.1635308;5.8067665;-0.97393775;-1.8749716;3.6866627;TASK
start event loop;-2.8570483;1.8962075;6.427058;2.0643802;-0.3981697;-1.554223;IRRE
remove presplash on the next frame;-5.595763;2.6192806;2.3310227;-1.0735276;-1.7857816;2.3599694;-
in non embedded mode there are 2 issues;-5.9738817;0.62879676;-0.7741964;0.12276095;-1.2674495;3.134157;-
1 if user created a window call the mainloop from window;-5.1728916;2.2264469;4.418054;2.1794848;-0.5638576;0.6685854;CODE
this is due to glut it need to be called with;-4.6066074;2.0403893;0.70933986;0.8294491;-3.657654;2.0357563;TASK
glutmainloop only freeglut got a glumainloopevent;-3.7205684;0.42081586;-0.46911612;0.5524121;-3.3660533;2.520686;IRRE
so we are executing the dispatching function inside;-5.1513853;0.037012774;1.7316;2.676011;0.33122253;1.071822;CODE
a redisplay event;-4.2214217;-0.73737794;5.0549517;2.0013547;1.2353005;1.3117548;-
2 if no window is created we are dispatching event loop;-5.825313;2.5882556;3.7162962;2.668027;-0.5823551;0.0012572258;IRRE
ourself previous behavior;-3.2162778;1.0469716;3.2278929;4.47996;-1.6986036;0.44131106;CODE
we are in embedded mode don t do dispatching;-6.969678;-0.82659787;-0.15690094;2.3835566;-1.6561732;3.7885597;CODE
we are in embedded mode don t do dispatching;-6.969678;-0.82659787;-0.15690094;2.3835566;-1.6561732;3.7885597;CODE
register a new cache;-3.1230876;-0.8080626;1.3352487;2.035173;1.2195029;3.0421772;CODE
create an object id;-2.7776773;0.618271;2.3112235;-1.9780289;5.559351;-0.65694404;IRRE
retrieve the cached object;-2.8180137;1.3455354;2.2067897;2.3126693;0.12391173;1.7602535;CODE
check whether obj should not be cached first;-1.2502873;2.8614902;-1.9183445;3.5269265;-0.03720273;2.2928338;-
this check is added because of the case when key is none and;-6.384592;5.174562;-3.7989235;1.5475384;0.6350021;-2.2390077;CODE
one of purge methods gets called then loop in purge method will;-3.3387198;3.7417758;-1.5120155;3.416266;-1.1176424;1.0947336;IRRE
call cache remove with key none which then clears entire;-4.427797;3.9089162;0.811961;1.24619;-1.6087452;4.184291;IRRE
category from cache making next iteration of loop to raise a;-0.45532125;0.46379274;2.5234005;2.736444;1.1679454;0.7701673;CODE
keyerror because next key will not exist;-3.602653;2.875266;-1.8364185;-0.48196778;-3.15325;-4.4415045;TASK
see https github com kivy kivy pull 6950;-4.469632;-5.2475085;0.20095171;-0.71528804;-2.301594;0.19984956;CODE
xxx got a lag that may be because the frame take lot of;-2.266342;2.1888943;1.8874317;-1.5323489;-3.9841564;2.1222649;IRRE
time to draw and the timeout is not adapted to the current;-2.7063143;1.760511;3.67734;1.8562477;-3.8228984;0.8627145;-
framerate so increase the timeout by two;-1.104989;2.2755466;3.1965926;0.6261544;-2.176698;1.3748671;IRRE
ie if the timeout is 1 sec and framerate go to 0 7 newly;-1.98512;1.3656273;2.8888316;1.8460803;-2.1212578;0.22827365;CODE
object added will be automatically trashed;-4.7998214;1.6628585;-0.7439931;3.265563;-1.3566704;2.4336758;IRRE
take the object timeout if available;-1.84467;3.8580642;3.9476564;5.0490336;0.4263135;-0.49053198;IRRE
no timeout cancel;-4.9977226;2.1079466;0.8906731;2.5248077;-3.428095;-0.6562138;-
install the schedule clock for purging;-4.114628;-1.0305252;1.1393588;1.3407038;-0.5205618;1.4521588;CODE
dt means delta time;-1.2874514;-0.99886876;1.7760628;-0.21583664;-1.6588683;-0.25576594;-
call my callback every 0 5 seconds;-4.1108427;1.9856778;3.8875184;2.420937;-2.1480758;-0.014703557;IRRE
call my callback in 5 seconds;-4.4023247;1.3768631;4.8726788;3.204203;-1.4326113;0.07810922;IRRE
call my callback as soon as possible usually next frame;-5.0579286;2.2997954;4.7774215;3.2899399;-2.0454254;2.4891098;IRRE
http docs python org library functools html functools partial python;-5.338917;-3.6468856;-1.4982129;0.95910317;-1.9824059;-0.03248553;CODE
http docs python org 2 reference expressions html lambda expression;-4.7485504;-0.8860375;-2.2136614;-0.61904985;-0.7427053;-0.413578;CODE
a foo object is created and the method start is called;-5.151991;0.7836668;1.9626273;3.9383607;1.2160418;-0.7159431;IRRE
because no reference is kept to the instance returned from foo;-4.131589;2.8078659;-1.3959221;4.9225545;-0.37807652;0.65138954;CODE
the object will be collected by the python garbage collector and;-0.8859327;-1.2469351;0.43054792;0.07461131;-0.2031897;-1.6866606;IRRE
your callback will be never called;-6.0819993;3.060325;2.365452;5.3178296;-2.528515;0.8194967;IRRE
so you should do the following and keep a reference to the instance;-3.6402357;-0.10026064;1.6108551;4.461824;2.7921503;1.9576043;CODE
of foo until you don t need it anymore;-2.3366477;1.7023647;2.0074832;2.8894303;2.25374;-1.2248597;IRRE
clock schedule once my callback 0 call after the next frame;-4.338564;2.2118015;2.8343601;1.390628;-2.951287;1.6363589;IRRE
clock schedule once my callback 1 call before the next frame;-3.892897;1.9717779;3.6252477;2.013969;-2.000895;1.9452814;IRRE
will run the callback twice before the next frame;-4.9693494;3.5842054;3.6205337;3.720796;-3.0433052;1.7541429;CODE
will run the callback once before the next frame;-5.211604;2.9412377;4.4642906;3.909648;-3.0071564;1.9418575;CODE
will also run the callback only once before the next frame;-5.4724503;2.8891246;3.9970253;3.6555963;-3.105088;2.4313834;CODE
event clock schedule once my callback now it s already scheduled;-4.7149086;0.90163106;2.951497;2.815215;-2.5089145;2.139211;IRRE
event won t be scheduled again;-4.996134;1.1482488;2.4944313;2.8024285;-2.3194828;0.4131537;-
call my callback every 0 5 seconds;-4.1108427;1.9856776;3.8875182;2.420937;-2.148076;-0.014703676;IRRE
call my callback in 5 seconds;-4.4023247;1.3768631;4.8726788;3.204203;-1.4326113;0.07810922;IRRE
unschedule using cancel;-4.8412347;3.619261;0.31290066;3.1886444;-1.002872;1.1797096;-
unschedule using clock unschedule;-3.391928;0.89081585;-0.43691385;0.6825623;-0.4480324;1.6912149;-
unschedule using clock unschedule with the callback;-4.4725246;1.2831528;0.5593179;2.7354388;-1.7826738;2.8761306;IRRE
not recommended;-3.8296695;-2.0265896;4.8678293;1.8753933;-0.8425432;0.4875024;CODE
some reading http gameprogrammingpatterns com game loop html;-4.7032056;-1.6816374;4.6275225;0.63964283;0.74151444;-2.4531727;CODE
win32 sleep function is only 10 millisecond resolution so;-2.9118888;0.65232646;-2.8148172;-0.5058454;-2.7208874;2.298141;CODE
instead use a waitable timer object which has up to;-3.6083684;2.0806773;3.513454;3.810367;0.2808589;2.7099319;CODE
100 nanosecond resolution hardware and implementation;-0.403059;-1.5981824;0.38581368;-3.0037258;-2.0819488;1.2526809;TASK
dependent of course;-1.4929851;-1.7679791;4.537836;2.5550508;1.780762;-0.76532316;CODE
def get sleep obj noqa f811;-1.8402641;-0.8752052;0.15109053;0.094665974;0.31037846;-1.7139883;CODE
clockid 4 clock monotonic raw linux specific;-1.3250134;1.0904543;-2.6430285;-2.5016026;1.1925359;1.3003453;-
clockid constants from sys time h;-1.6884148;-0.044091303;-2.8218524;-3.5537343;-0.7586381;1.0260437;CODE
clockid 4 clock monotonic freebsd specific;-1.5997846;2.2507427;-2.6424448;-4.5188136;3.1554859;0.5957966;-
11 clock monotonic precise freebsd known ok for 10 2;-1.1340995;0.687078;-2.6351848;-2.5751913;1.5152534;-2.74987;CODE
clockid 12;-3.3897083;-1.8411785;2.4010174;-2.0642748;1.8097285;-2.9572327;-
12 clock monotonic fast freebsd specific;0.3390398;0.13836008;-0.11177003;-3.9255838;2.1732557;-0.7185063;-
clockid 3 clock monotonic;-1.8699085;2.5365896;0.028334612;-3.7700927;1.1804013;-0.12134343;-
clockid 1 clock monotonic;-1.2365198;2.3904445;0.29326558;-2.8892698;0.72679484;-0.24147321;-
default time libc clock gettime wrapper noqa f811;-4.339648;-1.1934043;-2.9063835;-1.7966937;-0.787651;0.3999045;CODE
importerror ctypes is not available on python for android;-2.6368198;-2.411465;-4.7002754;-0.0025219289;-5.155991;-0.5770714;CODE
attributeerror ctypes is now available on python for android but;-2.940715;-2.987262;-5.469246;1.2386514;-4.9243445;-0.76529586;META
undefined symbol clock gettime cf 3797;-5.541354;0.034475606;-3.1955297;-1.8046676;-2.174092;-2.5180068;CODE
oserror if the libc cannot be read like with buildbot invalid elf;-4.292121;-1.2767243;-6.029854;-0.494883;-2.7149265;-2.40304;OUTD
header;-6.419937;-2.13438;5.8168955;-0.8260167;1.9629447;-1.5636332;CODE
tick the current time;-2.4340394;-0.21903111;6.5554605;-0.6697102;-1.6253678;-1.8538314;-
compute how long the event processing takes;1.9208448;-0.63268536;3.564637;1.4045609;0.32054767;-0.8683423;-
calculate fps things;2.2760136;-0.7812054;3.9156213;-2.1196795;-1.6335374;-1.2437897;-
process event;-3.5091836;-0.60575855;5.7280884;3.152616;0.44314775;-1.4840137;-
we don t know if this is called after things have already been;-5.5260305;-0.5138195;3.5130856;4.7021565;0.42331046;2.505395;CODE
scheduled so don t delay for a full frame before processing;-2.345117;1.6518817;2.4077356;2.1119595;-1.1862633;3.137647;CODE
events;-1.648435;-3.0223384;8.38084;3.0188284;1.4053758;-2.7022028;-
1 fps remaining time;-1.1295904;0.9847142;3.661042;-1.3382839;-1.900105;-0.21075071;CODE
self time self last tick elapsed time;-1.2080767;1.1568336;3.625857;-0.03925463;-1.3775651;-0.3866314;CODE
4 5 self get resolution resolution fudge factor;-0.412403;1.3408093;-0.22535162;-2.5914347;-1.905439;2.330417;CODE
anything scheduled from now on if scheduled for the upcoming frame;-2.6267135;0.3832865;3.1219282;3.3789244;-0.6215959;-0.12457582;CODE
will cause a timeout of the event on the next idle due to on schedule;-3.6847823;0.34500054;2.4583762;3.7428467;-1.4215348;0.8271059;-
self last tick current must happen before clear otherwise the;-3.400467;4.3515887;0.8129482;0.33104387;-2.9365277;0.62198436;CODE
on schedule computation is wrong when exec between the clear and;-2.4262447;3.0136638;-1.8873802;1.7830068;-1.8178489;-0.099355265;IRRE
the self last tick current bytecode;-3.7889888;-1.4412752;0.71879;-0.4662531;0.30221134;-0.8560395;CODE
anything scheduled from now on if scheduled for the upcoming frame;-2.6267135;0.3832865;3.1219282;3.3789244;-0.6215959;-0.12457582;CODE
will cause a timeout of the event on the next idle due to on schedule;-3.6847813;0.3449997;2.4583762;3.7428465;-1.4215338;0.8271079;-
self last tick current must happen before clear otherwise the;-3.400467;4.3515887;0.8129482;0.33104387;-2.9365277;0.62198436;CODE
on schedule computation is wrong when exec between the clear and;-2.4262447;3.0136638;-1.8873802;1.7830068;-1.8178489;-0.099355265;IRRE
the self last tick current bytecode;-3.7889893;-1.441275;0.71878976;-0.46625382;0.3022111;-0.8560388;CODE
if not event free only wake up for free events;-3.159053;-0.79224074;2.4473302;2.1176174;0.5501719;1.7060903;TASK
free events should use real time not frame time;-1.9718568;-0.82513195;2.0052469;2.0608451;-0.95064735;2.5084372;-
event clear this needs to stay after last tick;-5.1777825;3.5297296;4.922956;2.647787;-0.9482774;2.3806949;TASK
event clear this needs to stay after last tick;-5.1777825;3.5297296;4.922956;2.647787;-0.9482774;2.3806949;TASK
instance of class clockbasebehavior;-2.8225796;-1.4143904;-1.0111254;1.6798481;3.5574672;0.8253595;IRRE
example of input provider instance;-3.495037;-2.276499;1.6870388;0.41120237;2.6664526;1.4621917;CODE
example for tuio provider;-3.7942216;-3.6790302;1.9072165;-0.32194075;2.4851024;1.867155;CODE
version number of current configuration format;-2.9418926;0.08390141;-1.389762;-1.1048783;2.1751764;0.45979518;META
if we try to open directly the configuration file in utf 8;-5.4059544;0.31616682;-1.8839017;-0.5294579;-2.4545043;2.0383744;CODE
we correctly get the unicode value by default;-4.147495;1.9328765;-2.618898;-2.1324565;-0.841495;-0.12834987;IRRE
but when we try to save it again all the values we didn t changed;-2.086461;2.721752;1.6764458;1.4256433;-2.7505734;0.09529294;IRRE
are still unicode and then the pythonconfigparser internal do;-4.837602;-1.7989964;-4.252008;-0.19922477;-2.4452236;0.7019491;CODE
a str conversion fail;-2.2731655;3.8416767;-4.099207;-2.464879;-3.2038572;-3.6329608;META
instead we currently to the conversion to utf 8 when value are;-2.1691277;3.0305026;-0.78155935;-0.90042025;-0.78661996;-0.6427804;IRRE
get but we internally store them in ascii;-3.7444358;-1.6467135;1.2369629;-2.7878761;0.70488554;-1.5010298;META
with codecs open filename r encoding utf 8 as f;-2.8632932;-0.21408735;-2.08636;-3.5857325;-1.4378052;-0.10233684;META
self readfp f;-0.42543545;-1.762562;0.61384183;-0.57513696;-1.5080043;-2.1243095;CODE
when reading new file sections keys are only increased not removed;-4.338676;1.1092392;-0.7680946;0.041189026;-0.571385;2.5767276;CODE
if section not in old vals new section;-3.2155712;5.2239823;1.6768911;1.6033739;2.840329;-0.36314017;CODE
for k v in self items section just update new changed keys;-3.5032194;-0.32305464;0.38102645;-0.5551931;1.2033603;2.2267401;CODE
might be boolean int etc;-3.5351958;2.372897;-1.6465149;-2.112867;0.6115884;-5.771254;CODE
if config and widget associate this config with property;-2.8811154;2.4809067;0.23302919;2.4016438;0.47201115;4.023918;CODE
keys are configparser names values are 2 tuple of ref configparser;-3.9320295;2.1579788;-3.9884703;-1.0151273;0.5774316;0.71603215;IRRE
widget ref where widget ref is same as in register named property;-4.4214206;1.7147143;0.3386593;1.8429294;0.9070247;3.9826672;-
if old name disconnect this parser from previously connected props;-4.58448;1.9386009;-0.28151658;2.9235106;1.7418938;2.8667216;CODE
if given new name connect it with property that used this name;-4.239087;1.1516577;1.4191172;2.2178476;5.299107;1.6561495;CODE
read analyse configuration file;-2.266906;-0.5812111;0.10765996;-0.50989497;-0.7888408;-0.7084482;CODE
support upgrade of older config file versions;-3.0155103;-0.8980351;-1.6770042;0.47647583;-0.061527457;3.7439456;TASK
create default configuration;-2.9580393;0.82539034;1.5335845;-0.38173598;1.1282743;4.512261;IRRE
read config file if exist;-2.8524718;2.6605713;-0.5570923;1.1020216;-0.2912552;0.25025898;CODE
add defaults section;-4.818678;-0.6056897;3.4442453;-0.25579947;0.9798611;4.581662;TASK
upgrade default configuration until we have the current version;-2.8103805;0.74555224;1.359419;2.6144588;-0.034699883;4.4303446;TASK
log level;-0.65351737;0.16561376;3.3111203;-0.7833516;0.19551435;-3.0463793;-
default graphics parameters;-2.281187;0.3499172;2.041434;-2.4111114;-0.7159038;5.0540843;IRRE
input configuration;-1.8897022;0.3645166;3.6933687;-2.190347;1.2147994;-0.11981733;CODE
activate native input provider in configuration;-4.1204853;-2.0067625;-1.2901336;0.92394483;-0.51420254;4.6502566;CODE
from 1 0 9 don t activate mactouch by default or app are;-4.4925585;0.009058516;0.02165016;-0.099512875;-2.916006;2.172027;CODE
unusable;-3.6166303;-0.8399307;3.4777434;4.179347;0.78869885;-1.3068272;-
input postprocessing configuration;-2.9594686;0.9879634;1.2693313;1.9974221;0.7138836;0.92415977;CODE
default configuration for keyboard repetition;-1.8636675;0.10359182;1.7266606;0.43261087;2.5679681;3.1033769;CODE
was a version to automatically copy windows icon in the user;-3.9946513;-1.9817643;0.78280514;0.16184741;-1.4083456;3.4057245;CODE
directory but it s now not used anymore user can still change;-6.571469;0.22950767;2.2720213;-0.33280292;-2.0119638;1.2075793;OUTD
the window icon by touching the config;-6.1378;-1.6321974;5.1135464;-0.007248309;-1.8433244;5.044537;CODE
add token for scrollview;-5.162435;-2.465548;2.068445;-0.6659602;-0.4626586;3.2959862;TASK
remove old list token;-4.0697694;1.2482607;-0.020654967;0.16936904;-0.5029276;-0.08175872;-
add keyboard token;-4.8916626;-2.611175;1.8347391;-1.5333003;0.58671135;-0.29359996;TASK
if the timeout is still the default value change it;-3.5580952;4.5730042;1.7315938;3.724473;-2.0989494;1.5320457;TASK
desktop bool indicating whether to use desktop specific features;-2.6826246;2.2405407;-0.72124654;1.37926;2.223205;1.0007358;TASK
warning when adding a new version migration here;-4.3281517;0.7662255;-2.7933078;2.3252807;-2.392986;0.23217729;TASK
don t forget to increment kivy config version;-4.859336;-1.4620885;-0.29021046;0.6839993;-2.2454655;2.68802;CODE
for future;-3.5710104;-4.122896;4.442624;1.8043164;-0.4759887;-2.4960346;TASK
pass to the next version;-5.53684;-0.42814937;2.2330701;4.0045104;1.3976114;-0.31826073;META
indicate to the config that we ve upgrade to the latest version;-2.9793534;-0.57409483;1.2409908;1.7923144;0.07554356;1.8185105;TASK
now activate log file;-6.0079184;-1.2418259;1.1808959;1.6634194;-1.7960867;1.3524696;-
if no configuration exist write the default one;-5.030013;2.6617932;0.057113193;1.1760001;0.5121261;1.8354843;CODE
load configuration from env;-3.9780495;-0.14040051;0.8336369;0.11323935;-0.55634326;4.3795285;CODE
extract and check section;-1.8938217;2.207954;0.42291713;1.1306022;2.862645;-2.4682803;-
extract and check the option name;-2.4825766;2.037871;0.0943949;0.6612878;3.480117;-2.2964966;-
we don t avoid to set an unknown option because maybe;-2.646947;0.7998378;0.46777526;5.0589404;0.68081087;1.2491119;CODE
an external modules or widgets in garden may want to;-3.5829957;-5.343046;4.714141;0.31292713;0.30652025;2.5467768;CODE
save its own configuration here;-5.2672334;-0.36465088;2.7491477;0.91522455;-0.73128515;5.4937315;CODE
after popping context from stack update proxy s obj with;-6.578294;-0.33354342;-0.22168888;2.8006315;-1.8185177;3.897541;CODE
instances in current context;-1.402287;-1.2525506;3.1812005;4.587382;5.644824;1.6905187;-
module activated in config;-5.9873805;0.43804345;-0.22790584;-0.26736802;-0.651626;2.4866433;CODE
import module;-4.118389;-2.9067836;-0.2638697;-1.093138;-1.070341;-1.1941212;CODE
module activated in config;-5.9873805;0.43804345;-0.22790584;-0.26736802;-0.651626;2.4866433;CODE
import module;-4.118389;-2.9067836;-0.2638697;-1.093138;-1.070341;-1.1941212;CODE
get the full expected path to the compiled pyd file;-2.019737;0.17026585;-2.0099258;-0.839217;-2.3809183;0.43783692;CODE
filename is debug cp major minor platform pyd;-5.4169664;-1.3587435;-3.816753;-2.151267;-3.758083;-2.0785582;CODE
https github com python cpython blob master doc whatsnew 3 5 rst;-5.047914;-5.35704;-3.0910861;-3.5692456;-2.3378806;-3.6408892;CODE
if hasattr sys gettotalrefcount debug;-3.7379072;3.6755738;-1.6801308;3.2922482;-1.047856;-2.0946805;-
does the compiled pyd exist at all;-3.7536354;-3.6066735;-3.2587385;-1.5096856;-1.7985296;-0.7756336;CODE
tell user to provide dependency walker;-4.777206;-0.35383382;-0.08287651;2.568263;1.7134712;3.290558;CODE
make file for the resultant log;-1.0206972;0.43165424;2.3765533;-1.324923;-1.08045;-0.5236022;IRRE
little trick here don t activate gstreamer on window;-5.8269024;0.52593094;0.63537174;1.705134;-1.595727;5.481525;CODE
seem to have lot of crackle or something;-1.1255214;-0.051501248;1.2262979;1.68767;-3.1363864;-2.32541;-
from kivy lib gstplayer import gstplayer noqa;-4.1857023;-1.3551393;-2.2267964;-0.66915494;-3.5299299;0.8322724;CODE
taken from https goo gl 015kvu;-5.633581;-1.1204836;0.90190095;-1.7266673;-0.80125874;-1.379418;CODE
ff opts vn true sn true only audio;-1.6670151;1.0761878;-2.9798129;-0.3771547;-1.3473616;2.0033472;-
wait until loaded or failed shouldn t take long but just to make;-3.8887491;2.2642646;1.2248164;5.871518;-1.1210542;0.9973576;CODE
sure metadata is available;-4.243892;-5.045441;0.80316544;1.6913549;2.3794744;1.3962716;-
we need to set the volume everytime it seems that stopping playing;-2.96635;1.1693971;2.6110337;2.2413661;-3.5970984;1.1817585;TASK
the sound reset the volume;-2.8977988;-0.109456934;3.294966;0.6402872;-2.5219152;0.76609343;IRRE
load the appropriate providers;-2.5966694;-2.1907535;1.8422256;1.5928308;1.6486375;3.70055;CODE
self android camera setdisplayorientation;-2.3876672;0.9010394;2.7077405;-1.7467692;-0.8852468;6.614335;IRRE
assert pf imageformat nv21 default format is nv21;-2.8192065;3.305318;-6.941263;-0.89886993;-1.6834626;0.82926124;CODE
extension gl oes egl image external require;-4.4269495;-0.6692534;-1.1234103;0.15947127;-0.89909965;5.7538486;CODE
ifdef gl es;-2.3761163;1.420033;1.5646039;2.1244845;0.15261166;-1.5679301;CODE
endif;-2.5042036;0.32218668;2.8978314;0.36728838;-0.5615267;-1.6890813;CODE
clear texture and it ll be reset in update pointing to new fbo;-3.5503454;0.37926492;0.6973222;0.91089123;-2.2186327;3.9656968;CODE
add buffer back for reuse;-4.5585794;1.3236909;3.2244203;1.7766671;-1.3480949;3.6586146;TASK
check if frame grabbing works;-2.337446;3.7863786;2.2140076;2.0034275;-4.0543184;-0.4374786;IRRE
print self buffer len self frame data;0.09949847;0.44116625;1.1752076;-4.9074636;-2.781023;-0.6025894;CODE
for k in range 2 double buffer;1.748874;1.5993297;1.6980532;-4.5928025;-1.0128182;-2.4925916;CODE
buffer queue cleared as well to be recreated on next start;-4.0121;2.5209093;2.2440765;1.8983184;-1.4462754;2.6496673;IRRE
arr cvtcolor arr 93 nv21 bgr;-3.2866213;0.5857325;-2.4100559;-3.1630194;0.28608972;-0.28430313;-
initialize the camera gi if the older version is used don t use camera gi;-4.8433037;1.7015213;0.9533038;1.39984;-1.0872558;3.5496378;IRRE
we don t care about the rest;-0.9387387;1.3690647;3.46658;0.23472986;0.46375805;1.3956591;CODE
todo this doesn t work when camera resolution is resized at runtime;-2.387893;3.2027872;0.46417183;-0.4634867;-4.3074207;6.7757854;CODE
there must be some other way to release the camera;-4.805582;-0.28634873;3.3540404;0.96894056;-2.2686973;4.218364;TASK
try to get the camera image size;-2.1480625;1.0557504;1.7907206;-2.123467;-3.5924222;2.37981;CODE
decode sample;3.4371521;1.3325639;-1.324407;-2.4823413;2.3076766;-2.7035213;-
read the data from the buffer memory;-0.583065;0.12148773;3.4780781;-2.034233;-1.8493303;-1.2550917;CODE
we cannot get the data out of mapinfo using gst 1 0 6 gi 3 8 0;-2.2364452;0.6793503;-1.7481686;-0.7062133;-1.3740509;0.7089063;CODE
related bug report;-5.359068;-1.0586374;-2.538039;2.50597;-1.0860959;-1.3662883;-
https bugzilla gnome org show bug cgi id 6t8663;-7.105626;-0.41915888;-2.9576972;0.32353175;-3.6682837;-0.08022772;CODE
ie mapinfo data is normally a char but here we have an int;-3.1320627;1.9539745;0.2141952;-3.1233659;-0.63267815;-1.0064336;CODE
so right now we use ctypes instead to read the mapinfo ourself;-2.0215867;-3.8425868;-0.81999296;0.382425;-0.49122754;0.58364564;CODE
now get the memory;-2.9529731;-0.8467771;4.6879663;1.0596455;0.72430956;-1.2082937;-
if we leave the python process with some video running we can hit a;-3.083666;-2.515389;2.1059446;3.3792558;-3.8003829;-1.4255396;CODE
segfault this is forcing the stop unload of all remaining videos before;-3.8293777;1.6610429;0.008715295;1.2379273;-2.87865;2.2644238;CODE
exiting the python process;-4.279587;-0.95101523;0.9596326;1.382845;-4.5883546;-2.0648413;CODE
todo make usage of thread or multiprocess;-2.5643573;-2.3857684;2.1852005;2.8249722;-0.3593727;0.38351917;CODE
opencv 1 case;-0.81307364;-0.21235366;0.43080366;-3.5895915;1.295783;0.69151664;CODE
opencv 2 case and also opencv 3 because it still uses cv2 module name;-3.6520894;-1.246773;-3.0041;-1.8932086;1.9822457;2.156809;CODE
here missing this osx specific highgui thing;-6.0480022;-3.1887615;-0.45120317;-1.9769759;-2.5912883;2.1050365;CODE
i m not on osx so don t know if it is still valid in opencv 2;-3.8789437;-0.5275498;-3.6758049;-1.8521875;-1.0347959;1.5539979;CODE
we will need it because constants have;-2.1094291;-0.6557124;1.9235922;2.3939753;-1.3364918;1.0056704;CODE
different access paths between ver 2 and 3;-4.8208227;0.23776366;-0.25732523;-2.664573;0.93997914;1.5536257;IRRE
consts have changed locations between versions 2 and 3;-4.622912;-0.8982374;-0.6049929;-0.3594096;-1.6952162;2.1897373;META
create the device;-4.311327;-4.229491;4.3542953;-1.1593102;0.9938772;0.040744193;IRRE
set preferred resolution;-0.49514043;2.2220447;1.3670247;-0.42125636;-1.4401832;6.713749;IRRE
and get frame to check if it s ok;-3.6899898;2.446017;3.184484;0.3651256;-3.8859508;0.38981497;IRRE
just set the resolution to the frame we just got but don t use;-4.383226;0.13248573;2.45406;-1.257792;-4.871027;4.4875665;IRRE
self resolution for that as that would cause an infinite;-1.0771923;1.0114722;2.1964507;0.82473797;-1.2309331;2.4111152;CODE
recursion with self init camera but slowly as we d have to;-1.4769778;0.6130579;3.7310672;1.3878325;0.6065655;2.071032;IRRE
always get a frame;-1.7712638;-0.5598733;3.914504;0.8554208;-2.02702;2.0259137;-
get fps;-0.64727026;-1.3306167;4.0331135;-0.20206487;-1.6690385;-0.9026531;-
create the device;-4.3113275;-4.229491;4.3542957;-1.1593105;0.99387795;0.040743828;IRRE
set preferred resolution;-0.49514043;2.2220447;1.3670247;-0.42125636;-1.4401832;6.713749;IRRE
and get frame to check if it s ok;-3.6899898;2.446017;3.184484;0.3651256;-3.8859508;0.38981497;IRRE
source;-2.2619658;-3.1215603;2.3306668;1.8303374;-0.32553855;-1.3675551;-
http stackoverflow com questions 32468371 video capture propid parameters in opencv noqa;-2.896693;0.18385856;-3.357315;-3.5544884;0.5316092;1.88477;CODE
get fps;-0.64727026;-1.3306167;4.0331135;-0.20206487;-1.6690385;-0.9026531;-
create the texture;-2.5227406;-2.8980634;5.2996354;-3.851509;-0.021903422;1.0692196;IRRE
frame is already of type ndarray;-2.087084;-0.20835678;-2.189445;-5.0953774;-4.018345;2.8383255;CODE
which can be reshaped to 1 d;2.141898;-0.5193446;3.9189053;-6.0128484;-0.33695304;3.4631443;-
todo make usage of thread or multiprocess;-2.5643573;-2.3857684;2.1852005;2.8249722;-0.3593727;0.38351917;CODE
see https picamera readthedocs io en release 1 13 recipes2 html capturing to a numpy array;-0.7901772;-2.831148;-0.4999888;-3.433146;-4.6790915;0.4935519;CODE
noqa;-2.805702;-0.3154861;4.1303587;-1.4183314;0.5269386;-1.4486395;-
create the texture;-2.5227406;-2.8980634;5.2996354;-3.851509;-0.021903422;1.0692196;IRRE
trim the buffer to fit the actual requested resolution;-0.73296124;3.4505427;0.9109859;-0.7481913;-3.2905295;4.5600595;CODE
todo is there a simpler way to do all this reshuffling;-1.6916908;0.9951735;5.1659594;2.3243723;0.6626152;2.2946231;CODE
import clipboard kivy core clipboard clipboard;-3.006022;-3.3741562;-1.1216394;-0.85592693;-3.497842;1.3613536;CODE
windows clipboard uses a utf 16 little endian encoding;-4.0000896;-0.50937295;-2.02856;-2.7040753;-4.09801;1.573823;CODE
decode only if we don t have unicode;-1.5513077;1.7867401;-1.8747549;-2.4805465;0.45356536;-0.015283234;CODE
we would still need to decode from utf 16 windows;-2.9568071;-1.5084321;-0.37336916;-1.0155138;-0.64926136;1.5806371;CODE
data is of type bytes in py3;-2.4478772;0.3284361;-3.2536416;-5.844108;-1.5141581;-1.7213129;-
remove null strings mostly a windows issue;-4.0358562;4.1436825;-1.1057265;-0.1069538;-0.791178;0.10957433;CODE
load clipboard implementation;-2.8639166;-1.7774738;1.5597442;-1.0996324;-0.36933264;1.8653339;TASK
versions previous to honeycomb;-4.161174;-2.9692595;0.31066078;0.016832892;0.6824942;0.46707937;META
put text data onto clipboard;-1.5974863;-1.0006032;3.1167877;-2.224899;-1.3375382;-0.64512503;CODE
getclipboarddata returns a handle to the clipboard data;-3.608096;0.6384657;0.6531803;0.014886121;-1.8400592;1.2928642;CODE
which is a memory object containing the data;-0.64938915;-1.6554997;1.9098462;-1.1541802;3.341487;-0.6896674;IRRE
see https docs microsoft com en us windows win32 api winuser nf winuser getclipboarddata noqa e501;-3.8725314;-2.192525;-0.27674535;-3.0561922;-0.14623073;-0.16154085;CODE
if someone pastes a file the content is none for scf 13;-5.7324867;-0.32532936;-2.1105394;0.23387231;-3.2060246;-0.09323566;CODE
and the clipboard is locked if not closed properly;-6.0288076;-0.281971;1.7856241;0.5550916;-2.7140527;1.3698322;CODE
the handle returned by getclipboarddata is a memory object;-5.861887;0.19075857;0.8348254;-0.18501121;-1.0821878;1.5187064;CODE
and needs to be locked to get the actual pointer to the data;-4.332649;-0.68000484;1.0954667;-1.2281834;-0.08391031;1.4137174;CODE
the wsclen function returns the number of;0.007093398;0.7871495;-1.0850639;-1.963184;-0.47839764;-4.0399833;CODE
wide characters in a string not including the null character;-2.0493946;2.714236;-1.3589742;-2.3890202;-1.3972542;-1.9658948;CODE
according to the docs regarding setclipboarddatam if the hmem;-5.442434;0.71350855;0.56718796;0.21634656;0.60334015;2.1893873;CODE
parameter identifies a memory object the object must have;-2.2017822;2.5313697;-1.6089487;0.4737515;4.2425723;0.38637137;IRRE
been allocated using the gmem moveable flag;-3.2373557;1.9187813;-1.2625369;-0.45656776;1.2691387;3.053648;-
see https docs microsoft com en us windows win32 api winuser nf winuser setclipboarddata noqa e501;-4.5027676;-2.0377848;-0.3343572;-3.0743122;-0.32418063;1.3739144;CODE
the size of the memory object is the number of wide characters in;-0.4893232;-0.686227;1.4860852;-2.9907508;2.082513;-1.5359422;CODE
the string plus one for the terminating null character;-4.4568777;3.2263951;-0.6825933;-1.8473644;0.37996158;-3.6591964;CODE
since the memory object is allocated with gmem moveable should be;-2.8936775;1.5456407;-2.3115275;0.22613606;-0.015072073;4.303133;IRRE
locked to get the actual pointer to the data;-3.5896246;0.72469836;1.1227738;-0.8223414;-1.4469951;0.17741181;CODE
finally set the clipboard data and then close the clipboard;-4.8393145;0.018191958;1.6355813;-0.3726085;-3.128046;1.6692809;CODE
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
let the user know if his graphics hardware drivers are too old;-3.97308;-0.7780245;0.62773293;0.2674549;-2.3123968;0.14336973;CODE
xxx in the android emulator latest version at 22 march 2013;-6.525666;-0.22503202;0.18917099;-1.6844958;-0.0026009337;1.139201;IRRE
this call was segfaulting the gl stack;-5.2922926;1.6122284;-1.5269248;0.7344565;-2.401708;1.0691857;IRRE
to be able to use our gl provider we must have a window;-6.6188874;-2.0863678;2.629153;0.49439347;-0.82156944;4.7312856;CODE
automatically import window auto to ensure the default window creation;-2.8072844;-0.0030426583;0.05183569;2.224214;-0.8138494;5.0400605;CODE
import kivy core window noqa;-4.86513;-3.7660232;-0.7179528;-0.09089655;-4.871817;2.2966905;CODE
late binding;-4.9451237;-0.10720669;1.5873692;3.3027117;-0.3361053;2.281941;-
register image caching only for keep data true;-0.60006857;3.557237;1.5058361;1.9245914;-0.6995098;5.3100543;CODE
decoded image format one of a available texture format;0.25650328;-0.5553192;-0.3967321;-4.5195785;0.6889906;2.0623946;CODE
data for each mipmap;4.2405;-0.26616338;1.2837425;-2.5437458;1.8427044;0.94327676;CODE
image source if available;-2.6783693;-1.1877544;3.3118343;0.35281897;-1.2012559;0.7720145;-
indicate if the texture will need to be vertically flipped;-0.75901985;1.3617729;2.0321343;-1.7522184;-0.4325786;2.3005428;TASK
the original image which we might need to save if it is a memoryview;-3.085983;-1.1118199;3.6255734;-0.25923726;-1.5510552;4.1234336;TASK
first check if a texture with the same name already exist in the;-2.769849;3.32252;-0.6163491;0.51743007;1.54195;0.3702792;CODE
cache;-2.7960098;-1.6838348;5.424056;2.6105695;0.45832926;0.080084994;-
if not create it and append to the cache;-6.269159;1.5762957;2.7060194;2.4672582;-0.11914834;3.1130385;CODE
set as our current texture;-2.073797;-0.6930854;4.7804947;-0.16847521;-0.15383139;5.693507;IRRE
release data if ask;-1.2950283;0.005494381;3.053127;3.9538093;1.3563793;-2.1315026;-
read zip in memory for faster access;-0.38233775;-0.75772995;1.1792759;-0.04567891;0.363807;0.34128863;CODE
read all images inside the zip;-1.4913228;-0.16284882;2.8000019;-0.81106776;-0.44240716;0.5887689;CODE
sort filename list;0.5472869;-0.34065062;2.158564;-0.2958586;0.6235566;-0.80309945;-
read file and store it in mem with fileio struct around it;-1.3603697;0.54953295;0.17843515;-1.6156365;-0.88705367;1.0328076;CODE
loader failed continue trying;-3.9511473;3.0197465;-0.2346456;1.4538196;-3.5017889;0.32706064;CODE
append imagedata to local variable before its;-1.6916095;1.9786099;3.6779015;-0.18677053;-1.5651692;3.4160006;CODE
overwritten;-2.933214;-0.5588774;3.5449774;0.7643033;-0.7945199;-1.6073958;-
else if not image file skip to next;-2.9112797;3.9368718;3.8584325;0.55899227;-1.0797659;-0.62941843;-
replace image data with the array of all the images in the zip;1.2468507;1.1890836;2.769275;-1.785798;-1.2673416;0.9162345;CODE
atlas;-1.7882665;-3.4222271;4.1945267;-0.76985246;0.92150337;0.17007817;-
remove the url;-5.333636;0.39047518;4.257356;0.52455556;-2.5609512;0.22132853;-
last field is the id;-3.5980484;1.5147506;2.5243165;-2.0349874;2.9264677;-1.0850703;-
search if we already got the atlas loaded;-3.5880806;-2.2849648;1.439652;1.2469825;-0.6768958;1.1199027;CODE
atlas already loaded so reupload the missing texture in cache;-3.8391838;0.32757273;0.26417702;0.9291508;-3.4088843;2.595846;CODE
because when it s not in use the texture can be removed from the;-4.578311;0.8172508;0.1942665;0.8833328;-1.8289388;4.403461;IRRE
kv texture cache;-1.0544283;-2.258562;0.9101098;-0.28951797;-0.7053468;3.4330673;-
search with resource;-1.8689582;-1.8059672;3.595112;2.174117;2.5534267;0.46780872;-
first time fill our texture cache;-2.2290866;-1.3990306;3.3883748;0.3996842;-0.9869712;2.7697754;-
extract extensions;-1.3716245;-2.0809538;0.49299398;0.53834075;3.7116067;0.5666346;-
prevent url querystrings;-4.124711;1.8763511;0.66758305;2.2864099;0.40723333;2.2384527;CODE
get actual image format instead of extension if possible;-2.161472;1.4003751;0.47658378;-1.5015361;-1.4873514;2.200617;CODE
special case when we are trying to load a zip file with image we;-5.0210567;0.42843094;-0.1514481;-1.3086349;-0.4760363;1.0011454;CODE
will use the special zip loader in imageloader this might return a;-3.1952202;-0.06011464;-0.19764563;0.5461656;0.4796532;2.8529913;CODE
sequence of images contained in the zip;0.65949667;0.3970823;2.9946153;-2.2913349;1.8778093;0.2251667;CODE
this event should be fired on animation of sequenced img s;-4.1121492;0.8637145;4.50467;0.92082393;-0.84928954;2.1884184;CODE
indicator of images having been loded in cache;-0.4078346;1.3845251;3.2824237;1.7145712;-1.4042187;3.3462653;-
do something;-2.8416312;-0.30672824;4.477125;1.5262327;-0.80520046;-2.8079178;CODE
this time image will be re loaded from disk;-4.0577683;-0.34413245;3.319967;-0.19208157;-3.1824791;2.6133142;CODE
start reset animation;-4.7141657;1.105467;3.6257024;-0.3661079;-2.3187137;3.62096;IRRE
or stop the animation;-4.5165434;-0.22093941;5.04907;1.6861824;-3.139483;2.9147248;-
set to 20 fps;-2.5947173;-0.035073582;3.9106295;-0.40176824;-3.3964193;1.9391434;IRRE
stop animation;-4.2165;0.84514403;4.346176;-0.107690275;-3.3671942;2.4141653;-
construct uid as a key for cache;-3.8197234;-0.1717011;-0.84745383;0.050212745;3.0469813;3.3853872;CODE
in case of image have been asked with keep data;-0.30498785;1.8024414;4.839161;1.1985666;1.1968814;2.0692708;CODE
check the kv image cache instead of texture;-2.0853662;1.1825198;-0.39295316;1.2760464;-2.577852;3.11558;CODE
we found an image yeah but reset the texture now;-3.741862;-0.20236352;1.4909357;-0.2124293;-3.5831788;2.9763677;IRRE
if image class is core image then it s a texture;-2.1100173;-0.4163331;0.2767327;-0.28311414;0.13942388;2.634408;IRRE
from atlas or other sources and has no data so skip;-0.5792246;-3.136389;-0.4433856;0.32535535;-1.4154198;0.64309317;CODE
if we already got a texture it will be automatically reloaded;-3.9834297;-2.833348;2.6767902;3.246698;0.05384967;4.4302716;CODE
if image not already in cache then load;-3.1278036;3.7142847;3.9472811;2.3363085;-1.9150314;2.300909;CODE
put the image into the cache if needed;-4.4826117;0.5534385;3.9142873;0.8505715;-2.603436;5.046002;CODE
see if there is a available loader for it;-4.1579895;-0.34403616;0.8365161;-0.64629817;-0.95012134;3.6657896;CODE
save an core image object;-1.709043;-0.32413834;3.1880105;1.3699087;-1.5038526;4.454389;CODE
save a texture;-1.5097868;-1.0721796;3.5024207;-0.8260195;-1.5694655;2.551013;CODE
bytesio like rawio rawiobase bytesio;-2.3700309;-1.9379938;-0.8986893;-2.7335348;1.8629857;-1.0753626;-
we might have a imagedata object to use;-1.6614853;-1.9946321;3.6936944;-0.025835227;-0.17965457;3.4876664;IRRE
fast path use the raw data when keep data is used;2.1372976;-0.8193654;1.3634152;1.0963022;-0.13702038;3.5178792;IRRE
the format is not rgba we need to convert it;-1.6621871;-0.842412;-0.5878466;-4.9833674;-0.5365592;0.37329894;TASK
use texture for that;-1.5626261;-2.996405;5.3757973;-2.0501292;-0.46608987;3.0355604;IRRE
use the texture pixels;-1.2523181;-1.9547029;3.6603422;-3.983907;-1.6095898;3.230992;IRRE
can t use this function without imagedata;-2.2719312;2.841919;1.2649709;-1.477403;-3.4271758;0.27812123;CODE
check bounds;-0.092146724;5.003503;4.1218452;-0.96571743;-1.4718907;-5.801979;-
color reverse bgra;-3.1309931;0.25658736;2.3870838;-2.5841243;0.7234326;0.7178958;-
color reverse rgba;-1.3286006;0.45023492;2.1838295;-3.5209615;0.20621172;0.9424968;-
conversion for bgr rgb bgra rgba format;-1.640944;0.33344868;-1.8745286;-5.673063;0.4623327;1.2043672;CODE
load image loaders;-1.6224372;-1.035876;3.2976499;-0.36544305;-1.2322365;4.684639;CODE
resolve binding;-5.4055505;1.5929022;1.5324503;1.3753971;0.6966687;3.8854318;-
from kivy graphics texture import texture textureregion noqa f811;-3.5157225;-3.3483818;-0.5595199;-3.0365086;-3.8357337;2.141984;CODE
register;-4.0666265;-1.0109429;2.4953463;-0.017534148;3.0009463;-1.7640147;-
see https www ffmpeg org general html image formats;-2.3488362;-2.9946551;0.9591332;-4.635535;-1.9606299;2.280982;CODE
update internals;-5.221472;-2.0107064;2.4797528;2.1953554;0.6628246;1.078136;CODE
register;-4.0666265;-1.0109429;2.4953463;-0.017534148;3.0009463;-1.7640147;-
for python3;-3.309231;-7.2606854;0.9464416;-2.5916343;-1.8528434;-4.0212817;CODE
pillow;-2.3461456;-0.7048048;4.970289;-0.32879162;-0.94179744;-1.5194157;-
pil;-3.1890566;-1.0360616;5.3035955;-0.6954201;-0.37384257;-3.191594;-
monkey patch frombytes and tobytes methods refs;-1.3978946;-1.7401451;-2.087256;2.4146318;0.009837006;0.24465516;CODE
https github com kivy kivy issues 5460;-5.6738253;-3.6084216;-1.3966095;-0.47965854;-5.341834;-0.5903273;CODE
image loader work only with rgb rgba image;-2.8010604;2.2099485;-1.6603178;-1.1818473;-2.6440752;2.6660502;CODE
read all images inside;-0.9174502;0.66433614;5.268213;-0.60807025;-0.5559322;1.0434389;CODE
paste new frame over old so as to handle;-3.835654;0.7025914;3.0083268;-1.6395949;-1.8525441;3.7620735;CODE
transparency properly;-2.3889754;0.6872497;3.0364044;-1.1137182;-2.6903174;1.1275502;-
update internals;-5.221472;-2.0107064;2.4797528;2.1953554;0.6628246;1.078136;CODE
returns an array of type imagedata len 1 if not a sequence image;1.4059483;4.1708055;0.9616297;-1.5540906;-0.19938672;-1.3610746;IRRE
register;-4.0666265;-1.0109429;2.4953463;-0.017534148;3.0009463;-1.7640147;-
update internals;-5.221472;-2.0107064;2.4797528;2.1953554;0.6628246;1.078136;CODE
register;-4.0666265;-1.0109429;2.4953463;-0.017534148;3.0009463;-1.7640147;-
register;-4.0666265;-1.0109429;2.4953463;-0.017534148;3.0009463;-1.7640147;-
if no language was specified we just use the first one;-5.4595203;-2.2083762;0.48379028;0.7257294;2.9039638;-0.71948445;IRRE
that is available;-4.168699;-2.6590922;2.5589395;-0.75227267;0.8783333;0.73153114;-
note we do not return enchant list dicts because that also returns;-4.065371;0.2605647;-0.12605083;0.84824145;-0.61554986;-0.6068628;CODE
the enchant dict objects and not only the language identifiers;-3.359824;-3.6937006;-1.174979;0.19467567;2.6836717;-0.2965237;IRRE
don t show suggestions that are invalid;-2.2667687;2.0858097;-1.040285;4.4787307;-0.75047374;-1.5498892;OUTD
todo implement this;-3.0302622;-0.582129;6.032235;1.8808043;3.6572635;0.11220813;TASK
nsspellchecker provides several functions that look like what we;-1.2035007;-2.6235883;0.3675488;0.21056005;-0.29770687;-0.30948514;CODE
need but they re a slooow and b return a strange result;-2.3122203;2.2498815;0.9504524;0.8786661;0.35517538;-1.2479919;IRRE
might be a snow leopard bug have to test further;-3.3676555;0.027847568;-1.3532403;-0.069711804;-3.391365;-1.2594608;IRRE
see http paste pocoo org show 217968;-4.351409;-2.4287913;1.2655185;-0.5468111;0.23708749;-2.4004486;CODE
xxx both ways below work on osx 10 6 it has not been tested on any;-6.339057;1.1171273;-1.2101698;-3.2232165;-0.45930812;1.9241604;IRRE
other version but it should work;-6.7785697;-1.7116747;0.16025257;0.31251568;-1.303809;2.2353609;META
this is deprecated as of osx 10 6 hence the try except;-5.66385;1.5397952;-1.7489125;3.624123;-2.3564472;0.7937587;CODE
from 10 6 onwards you re supposed to do it like this;-1.6989359;-0.97431123;4.667287;0.041859332;1.251927;0.141499;CODE
right this was much easier apple;-0.85845584;-2.2485507;4.6580114;0.012012306;-1.1316084;0.7871061;CODE
the label is usually not drawn until needed so force it to draw;-2.7033072;1.5794294;2.4937787;-0.61522436;-1.5311875;1.0990832;CODE
now access the texture of the label and use it wherever and;-2.5011969;-1.8045311;2.7482524;-1.1870091;0.58947676;3.5406795;IRRE
however you may please;-2.1873739;-1.8506833;4.4332623;0.30524072;0.6699627;-1.3007337;-
create a font context containing system fonts one custom ttf;-2.8304493;-0.6111669;0.12878627;-0.53053194;0.70362884;4.3872476;IRRE
these are now interchangeable ways to refer to the custom font;-4.4646235;-0.67543447;0.7397823;-0.49649742;2.9800189;3.5689902;CODE
you could also refer to a system font by family since this is a;-3.9613278;-1.150212;1.1932;-2.1277468;3.213857;0.7650194;CODE
system font context;-4.4705405;-2.077356;1.5214686;-0.5882852;1.1200552;3.087726;CODE
include system fonts dir in resource paths;-3.9507349;-2.4145038;-0.74147123;0.35661227;0.51756847;3.4867287;CODE
this allows us to specify a font from those dirs;-4.9964223;-3.188758;0.69162744;-1.6973661;3.0115082;2.6997254;CODE
elf internal size 0 0 the real computed text size inclds pad;-2.7907693;0.5962179;-2.4362583;-3.7633586;-3.0731857;0.054010525;CODE
fonts append fonts 0 add regular font to list again;-2.798877;1.6349852;0.66052216;-0.124426685;-1.69859;1.7247937;CODE
is the font registered;-4.4065084;-2.2819905;0.722013;-1.6874882;2.5533612;0.023289368;-
return the preferred font for the current bold italic combination;-0.7365252;1.5255725;-0.58058405;1.3944215;1.3406968;1.9064778;CODE
xxx for compatibility check directly in the data dir;-2.2817395;1.9180416;-5.4280763;0.36492577;2.7775333;-0.7466327;CODE
register the font dirs;-4.7579546;-3.107467;0.6708031;-1.2208309;1.4982076;1.9114735;-
if larger it won t fit so don t even try extents;-0.82239807;1.574762;1.047675;-1.301807;-0.6972982;5.5847077;CODE
now find the first and last word;-3.138703;0.34502885;5.3252583;-0.35377932;1.7371391;-3.0172203;-
if dir l center or right;-2.198733;4.178335;5.354359;-2.0737293;0.5435197;-2.4073954;-
no split or the first word doesn t even fit;-1.5486948;0.4286136;1.3668762;-0.53837556;2.2283936;-0.8585461;CODE
at this point we do char by char so e1 must be zero;-1.9979792;2.9576483;-1.1552824;-3.3591514;-0.1941475;-2.1041148;CODE
both word fits and there s at least on split str;-1.5650125;-0.30367208;0.07083737;0.26713288;2.4865313;0.42549092;-
if s2 e1 there s only on split str;-1.6994542;0.7024659;0.84703344;-0.58717406;2.2313187;-0.21235338;IRRE
both the first and last word fits and they start end at diff pos;-2.1396177;0.64158434;2.6071076;-0.2149356;0.81734866;-0.91287947;CODE
else left;-3.9294326;0.9657457;3.3698857;-0.7750377;-0.67218405;-2.563529;-
no split or the last word doesn t even fit;-1.6775169;0.53947145;1.3786427;-0.3880668;1.6828566;-0.71796477;CODE
if split str;-0.44676945;4.426909;2.110216;-1.2982187;1.7441003;-5.4661555;-
both word fits and there s at least on split str;-1.5650125;-0.30367208;0.07083737;0.26713288;2.4865313;0.42549092;-
if s2 e1 there s only on split str;-1.6994531;0.70246506;0.8470339;-0.58717364;2.2313194;-0.21235332;IRRE
both the first and last word fits and they start end at diff pos;-2.1396177;0.64158434;2.6071076;-0.2149356;0.81734866;-0.91287947;CODE
if len line words get opts from first line first word;-0.03781044;3.2134879;-0.24411097;-0.25042605;-0.4323074;-2.2472558;CODE
fixme this should possibly use a config value and possibly we should;-6.4261885;0.22576396;-1.8932292;1.8178886;-2.4037173;5.632936;IRRE
expose pango unichar direction pango bidi type for unichar;-0.7243833;-1.0756922;-0.44885176;-2.6115081;0.80112094;3.2823577;CODE
uww uw padding left padding right real width of just text;-2.2820487;-0.30792642;0.7656476;-2.5165477;-1.8854406;1.6218253;TASK
for layout line in lines for plain label each line has only one str;-2.60379;2.034216;-0.9224738;-4.32753;0.12599055;0.09003845;CODE
right align rtl text;-3.543093;0.64139885;1.7448398;-3.0032618;-1.318944;0.59933174;-
right left justify;-1.6788731;0.4532509;4.5419526;-0.13780275;-0.054110516;-1.0483592;-
divide left over space between spaces;0.47093785;1.5958235;3.5394495;-4.755057;0.8289064;-1.4773519;-
todo implement a better method of stretching glyphs;-0.112882994;-0.24171127;2.1833043;-2.974915;-1.2772853;2.479568;TASK
number spaces needed to fill and remainder;-0.5222824;2.77928;2.9501526;-4.9397473;1.9088602;-4.312934;CODE
there s no trailing space when justify is selected;-1.5436952;3.1900566;-0.020841008;-0.5367386;-0.95481604;1.26529;CODE
words every even index is spaces just add ltr n spaces;-1.3911631;0.8016301;-0.79244536;-3.2294438;0.84182495;-1.8938848;TASK
render the last word at the edge also add it to line;-4.160668;1.5304691;5.246867;-2.2080739;-0.24319449;1.3300416;TASK
last word lw uww ext 0 word was stretched;-2.8109744;0.96248883;0.40394598;-0.95992213;-1.9803417;-0.0406024;-
last word lw uww word was stretched;-2.6651106;0.3191684;1.5234673;0.104284555;-1.3462653;0.8381196;-
layout line w uww the line occupies full width;-3.402523;1.6846814;2.3139355;-3.9676037;-1.4770682;2.8445308;CODE
if options is none there was no text to render;-6.15306;4.466459;1.4097434;0.63709253;-2.6747437;-1.5082705;TASK
ih self internal size 1 the real size of text not texture;-2.5571275;1.2633567;0.47838163;-2.7062154;-3.1148694;2.37623;CODE
get data from provider;-1.9006586;1.1464268;2.9588177;-0.12938604;0.8368031;1.7280742;CODE
if the text is 1px width usually the data is black;-1.5283899;2.1743453;-0.9678033;-3.8947277;-2.748536;-0.19755486;-
don t blit that kind of data otherwise you have a little black bar;0.45107916;-0.32554242;2.020605;-3.9615483;-0.7692526;-0.4250875;CODE
center 1 pos of newline;-1.9685178;1.7720432;4.298886;-4.5371375;-2.074446;-0.5926141;CODE
if a newline split text render from center down and up til uh;-1.6776825;1.4726552;4.6908245;-1.7156233;-1.1350427;2.2244487;CODE
layout from center down until half uh;-2.219153;0.26117405;7.618169;-5.0102487;-0.797221;2.9566665;CODE
now layout from center upwards until uh is reached;-3.904811;0.50448865;6.6883802;-3.5359066;-1.318441;3.5522237;CODE
else if there s no new line layout everything;-3.9045765;0.9096639;4.4927397;-1.2532846;0.23509064;2.0102324;CODE
else top or bottom;-2.6388469;1.4744703;6.2623568;-1.8759776;1.1360112;-1.3876964;IRRE
second pass render for real;-2.4743917;2.9903738;1.5764534;1.5669217;-0.7620026;2.5669851;CODE
first pass calculating width height;0.11161818;3.1775987;1.7355168;-4.4125657;-0.83873075;-0.78226644;-
if no text are rendered return nothing;-4.220663;5.984406;0.991521;2.7252042;-3.0228121;-2.1423736;CODE
create a delayed texture;-2.28573;0.43900123;3.9971743;0.2598367;-0.79973924;3.9535913;IRRE
load the appropriate provider;-4.0794554;-0.70371944;2.1866076;1.0066603;1.6038554;3.7678268;CODE
fixme better way to do this;-4.2042418;-0.22945301;3.8970084;2.0136323;0.20605934;1.0042969;CODE
for the first initialization register the default font;-4.3418584;0.072125115;-0.043618865;-0.8656976;0.5772407;3.0625486;CODE
color color color;-0.628102;-1.3002455;3.4028184;-2.4266443;1.53129;-1.4494807;-
we need to do this trick when documentation is generated;-6.225463;-2.9794762;-0.8278675;4.4904685;2.458411;2.3972518;CODE
split markup words and lines;-0.7975766;-1.0434701;3.875829;-2.0997872;3.3731422;-1.074554;-
result list of word with position and width height;0.6027587;0.52344507;3.9388525;-2.2886;1.1257505;-0.8866252;IRRE
during the first pass we don t care about h valign;-2.1880333;1.8054085;-0.30836022;2.2404513;0.5623861;1.1782157;CODE
if shorten then don t split lines to fit uw because it will be;-0.49593258;1.7837112;0.14227341;-0.6783141;0.58794206;1.8066757;CODE
flattened later when shortening and broken up lines if broken;-1.9714804;3.0546105;0.34303966;-0.95925957;-3.051964;1.6077447;-
mid word will have space mid word when lines are joined;-2.7065322;1.7657037;1.959123;-1.4324223;-0.3734689;-0.13280652;-
if len lines remove any trailing spaces from the last line;-0.64408827;3.4534307;0.94593483;-1.4966432;-1.7838272;-3.385868;CODE
options ref none no refs for you;-5.188964;1.9464403;2.1203513;2.3138351;-1.7572317;-0.30933124;CODE
when valign is not top for markup we layout everything text size 1;-1.9285342;2.0664625;1.9017726;-2.497326;-0.3584452;3.5773458;CODE
is temporarily set to none and after layout cut to size if too tall;-4.590774;3.455149;0.8763801;-1.2090338;-2.0782404;4.383825;IRRE
else middle;-1.8057323;2.208621;6.011988;-0.67552954;-0.367603;-1.2842156;-
top int h 2 uh 2 remove extra top portion;-3.214765;3.0855067;4.176036;-4.2215652;1.1828544;0.7445028;CODE
i len lines 1 remove remaining bottom portion;-1.8635783;2.5261295;3.4431312;-5.4514785;-0.7449027;-1.5140897;CODE
now justify the text;-3.1582525;-0.09718358;4.3444653;1.8474457;-0.15740475;-1.2037235;-
xxx update refs to justified pos;-4.1050153;1.0800527;-0.8957964;2.9475086;0.31494525;1.7496394;CODE
when justify each line should ve been stripped already;-0.58447766;3.9874136;0.6528121;0.8457214;-0.24343303;0.5160514;CODE
if there s nothing to justify we re done;-1.3769841;1.8439292;2.681547;2.9229758;-2.510834;0.56122124;CODE
parts none len words contains words split by space;-1.7072146;0.37712786;0.11825257;-2.5417352;2.0274305;-2.2613068;-
idxs none len words indices of the space in parts;-1.2219527;1.8855023;-1.9168853;-5.5698457;1.9836586;-1.0673579;-
break each word into spaces and add spaces until it s full;-0.8765447;0.47535297;3.561383;-1.6461025;0.8784017;-2.280485;CODE
do first round of split in case we don t need to split all;0.9882472;2.0685866;3.5400617;1.8763576;2.946661;0.78946674;CODE
now we have the indices of the spaces in split list;1.1827103;-0.22706817;1.25495;-3.2558513;2.5730875;-1.3249629;-
try to add single space at each space;-2.0154696;3.0242794;0.5057811;-3.550285;-1.9493695;-0.18588762;TASK
there s not a single space in the line;-3.8029354;3.0281956;1.6038356;-3.2659376;-1.7025602;-2.0873969;CODE
now keep adding spaces to already split words until done;-1.8206105;0.63091993;1.7246627;0.21962896;1.8228639;-1.1019516;CODE
try to add single space at each space;-2.0154696;3.0242794;0.5057811;-3.550285;-1.9493695;-0.18588762;TASK
if not completely full push last words to right edge;-2.7973564;0.555777;3.787648;0.9907917;0.73969656;-0.030364797;CODE
find the last word that had a space;-2.0432675;0.7703379;4.7628784;-1.6968294;0.65614265;-3.492848;-
split that word into left right and push right till uww;-3.2233288;-0.27372667;2.8200982;-0.5786316;0.64989334;0.17931034;CODE
now put words back together with right left inserted;-4.555449;0.30975935;4.049444;-2.301287;0.7344602;-1.3856744;CODE
for layout line in lines for plain label each line has only one str;-2.60379;2.034216;-0.9224738;-4.32753;0.12599055;0.09003845;CODE
the word height is not scaled by line height only lh was;-1.9549468;2.6011364;-0.0836289;-3.5188994;-2.960751;1.8467506;-
calculate sub super script pos;1.1138283;1.9571697;0.92881095;-1.2469844;0.2765207;-3.020296;CODE
should we record refs;-0.5497285;0.66306823;3.6449034;3.243369;-0.104310654;1.6853765;-
should we record anchors;-0.10192853;-1.0632199;2.9528368;2.5979905;0.63141733;3.5228915;-
yield 1 1 total w this should never be reached really;-1.909319;2.350872;1.3221784;0.07876766;-0.9967225;-4.0254455;CODE
yield 1 1 total w this should never be reached really;-1.909319;2.350872;1.3221784;0.07876766;-0.9967225;-4.0254455;CODE
if i 1 and total w ww uw found and it fits;0.07053673;2.5992877;1.1300998;-1.598646;2.7319953;0.21486391;-
if total w ww uw wasn t found and all fits;0.092758894;2.5043962;2.369485;0.47533023;1.319055;0.3385711;-
now just find whatever amount of the word does fit;0.4405501;1.2286342;2.0805738;0.35164285;1.6607951;-1.7207303;CODE
if i 1 and total w ww uw found and it fits;0.07053673;2.5992877;1.1300998;-1.598646;2.7319953;0.21486391;-
if total w ww uw wasn t found and all fits;0.092758894;2.5043962;2.369485;0.47533023;1.319055;0.3385711;-
now just find whatever amount of the word does fit;0.4405501;1.2286342;2.0805738;0.35164285;1.6607951;-1.7207303;CODE
flatten lines into single line;1.5668049;0.939869;2.8663433;-4.568801;-1.2988853;0.76380765;CODE
concatenate non empty inside lines with a space;-0.95661354;2.6635292;2.631466;-3.7577477;0.2681574;-2.6019473;-
if that fits just return the flattened line;-0.58815646;5.2315416;1.4465271;-3.0215576;-3.0063207;1.1120356;IRRE
set new opts for ellipsis;-0.37605402;0.6744748;0.6098609;-0.7227022;-0.81624866;3.5207248;CODE
find the size of ellipsis that ll fit;1.2827475;1.1871293;3.565225;-3.4673166;-1.4760336;-0.68117046;-
if elps s 0 uw even ellipsis didn t fit;-1.2891078;0.8821139;-1.2054749;-0.038763236;-0.8636999;1.6135508;-
restore old opts;-4.1002088;0.79052925;-1.052367;-0.36446884;-0.7063218;2.50976;CODE
now find the first left and right words that fit;-0.66967344;-0.26302704;4.0465655;-2.3679519;2.9634573;-2.2580395;-
if dir l center or right;-2.198733;4.178335;5.354359;-2.0737293;0.5435197;-2.4073954;-
if either was clipped or both don t fit just take first;-1.9599898;2.687434;2.3831804;-0.04840907;-0.89116436;1.8965952;CODE
elif w1 e1 1 1 this shouldn t occur;-3.037557;2.4370973;-1.5216905;0.27666262;-0.38998067;-2.7879963;CODE
now we know that both the first and last word fit and that;-1.0751884;-0.83319604;2.9526217;2.5942492;1.7839633;1.1321279;-
there s at least one instances of the split str in the line;-2.1386127;1.844672;-0.4925986;-2.7793553;1.8834224;-3.4499464;CODE
if w1 e1 w2 s2 more than one split str;0.19692868;2.455038;1.1123133;-1.9245553;4.4799757;-2.6536171;-
f n line c iterator;-0.032785717;1.4109548;2.506508;-3.28935;-0.54424304;-3.7457314;-
assert next f 1 w1 e1 first word should match;0.2711577;5.5926375;-0.8615338;2.375101;2.7424004;-3.8323717;CODE
else center;-2.391605;2.1303484;6.597782;-1.3485955;-1.1240327;-0.67701674;-
f n line c iterator;-0.032785717;1.4109548;2.506508;-3.28935;-0.54424304;-3.7457314;-
f inv p line c iterator;-0.59247184;2.5586736;1.0584979;-3.6667995;-1.2503107;-2.7451363;-
ww1 ee1 l1 next f hypothesize that next fit;1.1066933;0.63229126;-0.05817593;1.626551;1.1729902;2.89815;-
else left;-3.9294326;0.9657457;3.3698857;-0.7750377;-0.67218405;-2.563529;-
if either was clipped or both don t fit just take last;-1.756288;2.9860876;2.3868835;0.21966952;-0.8669967;1.6840639;CODE
elif w1 e1 1 1 this shouldn t occur;-3.0375571;2.4370968;-1.5216912;0.27666235;-0.38998023;-2.7879958;CODE
now we know that both the first and last word fit and that;-1.0751884;-0.83319604;2.9526217;2.5942492;1.7839633;1.1321279;-
there s at least one instances of the split str in the line;-2.1386127;1.844672;-0.4925986;-2.7793553;1.8834224;-3.4499464;CODE
if w1 e1 w2 s2 more than one split str;0.19692868;2.455038;1.1123133;-1.9245553;4.4799757;-2.6536171;-
f inv p line c iterator;-0.59247184;2.5586736;1.0584979;-3.6667995;-1.2503107;-2.7451363;-
assert next f inv 1 w2 s2 last word should match;0.01302859;4.936784;-1.0172089;0.90428257;1.642012;-3.3857474;CODE
now add back the left half;-4.2326555;2.4840899;5.188154;-3.3817549;-0.63395846;-1.4600457;TASK
now add back the right half;-3.930362;2.389734;5.002634;-3.3872252;-0.67975026;-1.9470904;TASK
from kivy core window import window opengl must be initialized;-4.502987;-2.186984;-1.9236642;-0.22692603;-5.9323583;3.2643857;CODE
used for fetching extends before creature image surface;-3.3546472;-1.4504199;1.6867193;1.3535551;-0.2014827;4.631788;CODE
create a surface context font;-3.539451;-2.328274;2.3037467;-3.4402099;-0.49444625;4.0102177;IRRE
adjust x and y position to avoid text cutoff;-0.91960186;1.4616842;3.7086952;-3.8743172;-2.9853654;1.9361154;CODE
load the appropriate provider;-4.0794554;-0.70371944;2.1866076;1.0066603;1.6038554;3.7678268;CODE
from kivy lib gstplayer import gstplayer noqa;-4.1857023;-1.3551393;-2.2267964;-0.66915494;-3.5299299;0.8322724;CODE
surfacetexture surface;-1.7712349;-2.0012825;1.5217379;-2.855948;-0.7561181;3.3634863;-
fbo for kivy texture;0.104053676;-3.4215758;1.1854441;-1.6209495;-2.9559345;2.718677;CODE
extension gl oes egl image external require;-4.4269495;-0.6692534;-1.1234103;0.15947127;-0.89909965;5.7538486;CODE
ifdef gl es;-2.3761165;1.4200331;1.5646051;2.1244857;0.15261132;-1.5679303;CODE
endif;-2.5042036;0.32218668;2.8978314;0.36728838;-0.5615267;-1.6890813;CODE
safely release mediaplayer;-5.1516666;-0.86910504;0.44934893;2.3101835;-1.5061088;2.2166152;-
property overrides;-3.8990061;1.737824;1.0538231;5.1410975;2.069476;2.913016;CODE
controls;-3.7240274;-3.0259106;7.950903;-0.35719255;0.28994057;-0.18010597;-
self unload;-4.849212;0.020205537;3.477832;3.062171;-1.4574131;0.9771078;CODE
called automatically by videobase;-3.4208915;-0.9185284;2.0525467;3.2435424;0.3788015;3.7548404;IRRE
first time we got a frame we know that video is read now;-2.112767;-1.738428;3.4095228;1.0822891;-3.8517148;1.2042001;CODE
this is only used when building ff opts to prevent starting;-6.854023;0.08336774;-0.9105137;2.4108305;0.03790622;4.0318995;CODE
player paused and can probably be removed as soon as the eof;-6.46595;0.39873165;1.5741028;1.640344;-1.410084;1.4307853;OUTD
receiving issue is solved;-4.0538917;2.3339388;0.79822576;0.20523587;-1.6792979;-1.3427302;-
see https github com matham ffpyplayer issues 142;-4.2600574;-1.9723619;-4.264482;-2.5776362;-5.311449;-1.044567;CODE
this causes a seek to zero;-0.8665002;4.305742;0.5097037;1.5002092;-4.453107;-1.0769156;CODE
once setup is done we make sure player state matches what user;-3.6712189;0.724122;1.1684389;2.9155865;1.110596;1.3708364;CODE
could have requested while player was being setup and it was in limbo;-6.849617;1.233674;0.17986456;2.3370423;-0.33725503;2.667297;CODE
also thread starts player in internal paused mode so this unpauses;-5.8690596;0.4997704;1.1042778;2.7130713;-1.6743231;4.888618;CODE
it if user didn t request pause meanwhile;-5.7278423;2.6517842;3.2555516;5.1120143;-1.3994786;0.53370637;CODE
xxx fixme;-4.2114716;-0.0035864464;3.3307204;-1.0448025;-0.07209363;-0.46256652;-
self texture add reload observer self reload buffer;-5.1671863;0.63663155;0.9157495;2.152681;-2.7480283;5.0153728;CODE
video starts in internal paused state;-3.4847243;2.140105;1.9097148;0.8583528;-2.650503;3.1783566;CODE
fast path if the source video is yuv420p we ll use a glsl shader;-1.3920318;-3.29961;0.8802683;-1.6424247;-1.6366087;2.8769283;-
for buffer conversion to rgba;0.3297647;-1.239128;2.048971;-3.2436397;-0.8370557;0.8596358;META
wait until we get frame metadata;-4.2670813;-2.8585455;0.5058632;1.8943801;-0.88363236;3.529346;-
ffpyplayer reports src pix fmt as bytes this may or may not;-2.9298568;1.4183056;-4.9420185;-2.6651168;-2.9346051;-0.122102425;IRRE
change in future so we check for both bytes and str;-4.6096926;2.5357401;-2.4550726;-0.384257;-0.5667257;-4.42522;TASK
now we ll be in internal paused state and loop will wait until;-3.8173397;0.9328237;2.87003;3.3293324;-1.9408765;-0.22687028;IRRE
mainthread unpauses us when finishing setup;-3.2432797;0.048639324;0.07332238;3.6787438;-2.2917385;3.1702967;CODE
get next frame if paused;-2.2344108;3.2108285;5.169178;-0.59449804;-2.5289323;0.73968065;-
ffplayer set volume 0 0 try to do it silently;-3.6926858;2.359246;-0.31863108;-0.72419965;-3.6892216;1.7299067;CODE
we don t know concrete number of frames to skip;-0.47170433;1.6603673;2.7956452;-0.28143752;-1.0522712;-0.20176254;CODE
this number worked fine on couple of tested videos;-1.5405407;1.9113044;-2.8765075;-0.16870576;-1.5067387;-2.468204;IRRE
exit loop on invalid val;-1.5545001;6.403398;-0.9685595;1.0680351;-2.587774;-4.3355284;IRRE
exit loop on seek queue updated;-2.4296906;4.130032;0.8273036;3.105113;-2.4990723;-0.15467738;IRRE
wait for next frame;-3.0444918;1.2922921;4.933695;0.7047166;-2.340378;-0.30414087;CODE
wait until we skipped enough frames;-1.5060922;1.0909836;3.3817213;1.0615839;-2.861655;1.0774702;-
assuming last frame is actual just get it;-1.1333779;1.9370154;3.8664296;-0.9907992;-0.3132526;0.95365393;-
todo this is not safe because user could have updated;-4.7697773;0.04516844;1.5589204;3.7277102;-1.4936535;0.2130755;CODE
volume between us reading it and setting it;-0.48379257;0.23380499;5.8548;-0.95439094;-2.2403886;0.33081323;IRRE
get next frame regular;-1.1075665;2.3543918;4.143896;-2.2920656;-0.99036556;2.9219487;-
still save seek while thread is setting up;-2.9960697;1.2046717;1.5110824;4.4304934;-2.7852616;3.4719415;CODE
if state hasn t been set empty there s no player if it s;-2.8125458;5.0112867;1.8388897;1.9897634;1.6591899;-1.2248224;IRRE
paused nothing to do so just handle playing;-5.8739386;1.5215403;2.787649;1.5766134;-3.3345416;0.2668172;TASK
we could be in limbo while player is setting up so check player;-5.340174;0.8657422;1.1774441;1.9351238;-2.0539086;-0.6643318;IRRE
will pause when finishing setting up;-4.715419;0.6479062;3.8516586;2.6003115;-2.5472348;0.9068107;TASK
even in limbo indicate to start in paused state;-4.4832683;3.0188844;2.268458;2.191325;-0.92764395;2.074669;-
state starts empty and is empty again after unloading;-4.810257;4.819135;0.8350275;2.3304381;-1.5292237;1.4128226;CODE
player is already setup just handle unpausing;-5.9350243;0.07495455;-0.55601454;2.0624237;0.840773;4.299066;IRRE
we re now either in limbo state waiting for thread to setup;-5.090818;-0.5582379;0.8895377;2.0799828;-2.1643512;1.4190453;CODE
or no thread has been started;-4.335065;-0.24598238;3.231572;3.3831477;-2.1783192;0.5034127;CODE
in limbo just wait for thread to setup player;-5.935018;-0.7390973;1.298796;2.1064894;-0.67133117;1.959562;CODE
in limbo still unpause for when player becomes ready;-4.892184;1.3375785;1.6456426;4.28153;0.5901381;1.9689487;CODE
load first unloads;-4.1280484;2.4355516;3.1495073;2.6824114;-0.8783269;2.4761128;CODE
if no stream it starts internally paused but unpauses itself;-4.9215937;1.6245432;1.5598402;2.7399817;-2.5676868;3.1229067;CODE
if stream and we start paused we sometimes receive eof after a;-3.4406638;0.9977824;1.3853993;2.398656;-2.0061357;0.46313655;-
few frames depending on the stream producer;0.8398864;0.5981664;2.5108485;0.5001772;-0.8220654;2.3621798;TASK
xxx this probably needs to be figured out in ffpyplayer using;-3.463627;-0.639028;-0.7485706;-5.360164;-3.4973857;0.20881437;CODE
ffplay directly works;-4.6679945;-1.602891;0.6284893;-0.10801339;-2.4120536;1.9469482;-
disabled as an attempt to fix kivy issue 6210;-6.2665925;-1.4320372;-0.6809927;0.6309833;-4.471527;1.0570903;-
self ffplayer set volume self volume;-2.2711184;0.9370043;0.68400115;-1.9555087;-1.8162265;2.3099556;CODE
todo remove;-5.016966;1.8281866;3.3708837;1.6361125;-0.7379984;-0.43345845;TASK
start in playing mode but ffplayer isn t set until ready we re;-5.376335;1.7042974;1.4771198;0.37024835;-2.851898;1.6210417;IRRE
now in a limbo state;-2.7653196;1.0483315;3.0603638;0.7615928;0.60125715;0.15920554;-
no need to call self trigger cancel because ffplayer is set;-5.8729877;2.4493291;0.21919858;2.459085;-2.8273728;2.3801298;IRRE
to none below and it s not safe to call clock stuff from del;-4.844558;-0.6271897;1.4538392;0.70627385;1.1450999;-0.072839096;IRRE
if thread is still alive set it to exit and wake it;-3.8986552;1.3158828;4.173359;3.0976815;-1.8124597;0.6238613;TASK
wait until it exits;-4.884533;1.6722136;5.287347;3.545874;-1.6772372;-1.470128;-
todo use callback don t block here;-6.399951;3.8515337;3.128403;5.0429616;-4.1615653;2.0005238;CODE
reset for next load since thread is dead for sure;-4.557522;2.5979693;1.6310431;2.8708715;-3.2562752;0.4308007;CODE
if we still receive the video but no more player remove it;-4.039977;0.32741803;2.654515;0.8467019;-2.015748;3.155387;TASK
texture is not allocated yet create it first;-4.348357;1.3900464;-0.039113827;-1.3864895;-1.946563;2.706818;TASK
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
late import;-4.0945706;-3.581447;-0.51266605;1.3972251;-2.0508587;-1.7724062;CODE
keycodes mapping between str int these keycodes are;-2.490771;0.80981463;-0.809381;-5.497881;3.6394656;-1.4067453;CODE
currently taken from pygame key but when a new provider will be;-6.2667246;-2.6404755;0.7843893;0.212874;-0.5167737;2.4232638;CODE
used it must do the translation to these keycodes too;-4.1129146;-3.6293895;0.10753792;-1.6755016;1.1489193;0.73219925;CODE
specials keys;-1.427224;-0.5050141;2.449169;-3.3131838;2.110232;-1.5008575;-
a z keys;-1.6571869;0.5111111;4.8807077;-3.0312278;1.789043;-2.274168;-
0 9 keys;-2.3020995;0.81420684;1.479195;-4.6795034;0.010200565;-3.6093729;-
numpad;0.09451859;-1.7287171;2.7661793;-5.230332;-2.5010538;-2.3427665;-
f1 15;-1.7326148;-1.9698999;3.1579576;0.01377936;1.3305808;-3.2419512;-
other keys;-3.047983;-1.9494954;3.3411498;-2.5665455;1.6040808;-1.7374195;-
35 36;-1.9192737;0.112786554;3.6854641;-2.2105029;-0.12250976;-3.8663116;-
window which the keyboard is attached too;-5.5602593;-1.9444648;5.996609;-1.5927824;-0.9492996;1.7451001;CODE
callback that will be called when the keyboard is released;-6.150725;-1.3813287;4.072322;3.5568633;-1.2036986;1.9055047;IRRE
target that have requested the keyboard;-4.9426584;-2.4431665;2.7170322;1.7123158;-0.6309393;1.5405563;CODE
vkeyboard widget if allowed by the configuration;-4.0862265;1.4833689;0.3962944;-0.76031756;-1.4935857;3.1219578;-
private properties;-2.7616332;0.25638387;2.1949973;0.7350792;2.825774;0.21134855;CODE
the size is the same no need to resize anything;-1.3213205;0.4256895;2.6966522;-2.4356024;-0.5411544;6.151669;TASK
red background color;-3.6671882;-0.7344061;4.7953725;-1.200126;-0.56842536;-0.054527387;-
don t clear background at all;-4.180273;0.48091468;3.844093;0.06703903;-1.2026215;2.1926935;CODE
make some property read only;-2.893916;3.1100543;0.80337054;4.0922794;1.785544;3.52883;CODE
if use sdl3 placeholder until the sdl3 bootstrap supports this;-5.440919;-0.62404805;-2.4071856;-0.32977104;2.2662787;6.0978856;CODE
internal;-4.3479714;-2.1410604;5.6249447;1.7275206;1.4071658;-1.545764;CODE
don t init window 2 times;-5.6578555;2.0915058;2.579737;3.2805831;-0.28846076;1.3208958;CODE
except if force is specified;-2.1100392;3.9782813;0.13675565;3.7281299;-0.15771952;-1.1844524;CODE
create a trigger for update create the window when one of window;-3.470262;0.33350644;4.7655373;1.3020586;0.51824087;2.0471733;CODE
property changes;-2.8160303;1.1328137;3.0864348;3.1713908;1.5212815;2.309634;-
create a trigger for updating the keyboard height;-2.3478596;0.39377376;2.7739356;0.13894309;-1.0543425;2.037567;IRRE
set the default window parameter according to the configuration;-3.2429645;3.0679963;2.272312;1.3716322;-0.9915013;6.5735083;IRRE
bind all the properties that need to recreate the window;-4.2913165;0.77245724;4.229654;1.4740157;1.7403822;5.4607654;TASK
init privates;-5.1777744;-1.5148807;1.8397716;1.3035327;0.5818329;-0.012411803;IRRE
before creating the window;-6.439997;-0.85711867;5.2840624;1.3876483;-0.9375184;1.8098307;CODE
import kivy core gl noqa;-4.095433;-3.29868;-2.758635;-0.7433704;-3.6663387;0.705065;CODE
configure the window;-5.1530356;-0.9780745;5.7097597;-0.95452315;-1.5057843;2.987773;CODE
manage keyboard s;-1.9571414;-3.9763944;4.094599;-0.6389686;0.5445941;0.7408744;-
assign the default context of the widget creation;-4.611041;-0.24601449;1.8817626;0.78956854;-0.31268445;6.851857;IRRE
because window is created as soon as imported if we bound earlier;-5.641368;0.70904016;-0.09600771;1.7191095;-2.6954732;3.0960689;CODE
metrics would be imported when dp is set during window creation;-0.9724345;-1.2222773;-2.4693651;0.36935794;-1.2040919;4.8292055;CODE
instead don t process dpi changes until everything is set;-0.7180628;3.4008918;-0.110742874;0.08991569;-2.6855228;6.2613893;TASK
mark as initialized;-5.7354097;3.4426868;0.91510785;1.1511453;1.7973037;-0.24097319;IRRE
attach modules listener event;-5.660816;-1.5701987;2.4402378;2.6512003;-0.7500256;2.9641294;CODE
prevent any leftover that can crash the app later;-4.043145;2.1112425;1.7832564;5.7713704;-1.2430083;2.8866234;-
like if there is still some gl referenced values;-1.5902456;2.1901977;-0.17991295;1.0643587;3.2621737;1.5128286;IRRE
they may be collected later but because it was already;-1.6734607;0.5910626;1.8064648;4.1272397;1.9691626;0.65554386;META
gone in the system it may collect invalid gl resources;-6.048728;-0.3311871;-2.38495;2.0265055;-1.6670414;2.3628414;CODE
just clear everything to force reloading later on;-5.84953;1.0020287;3.046109;4.736501;-1.8935146;4.430418;CODE
just to be sure if the trigger is set and if this method is;-2.9974825;2.557515;1.0622327;5.20676;0.35773164;-0.22342972;IRRE
manually called unset the trigger;-3.4233572;1.9386278;-0.14354324;2.504322;-2.0849097;3.1114273;IRRE
ensure the window creation will not be called twice;-5.3653893;3.6134996;1.6824378;4.1804266;-0.036749095;3.308447;IRRE
create the render context and canvas only the first time;-4.082281;2.771229;5.66482;1.16945;-1.596348;5.591368;IRRE
if we get initialized more than once then reload opengl state;-2.800427;3.0107052;0.37931308;1.391729;-0.6705527;3.5524292;CODE
after the second time;-4.305881;0.36764252;4.7242317;2.2430105;-0.19753727;-0.89753175;-
xxx check how it s working on embed platform;-5.822133;-1.2357359;0.4638645;-1.3526417;-2.1408873;0.6018786;CODE
on linux it s safe for just sending a resize;-3.9098973;-1.5881474;1.1257018;0.08849837;-2.8166676;3.5876565;CODE
on other platform window are recreated we need to reload;-6.9082403;-1.0603023;1.5841774;0.9250005;-3.481671;4.4018893;CODE
ensure the gl viewport is correct;-5.1769967;2.5450997;-0.5230001;-0.3727296;-3.9272041;4.931456;-
xxx fixme use late binding;-6.8082676;1.7973635;-0.5492498;2.2632456;-0.8935037;3.5113735;-
when using inner window an app have grab the touch;-5.5600786;-0.4452552;4.9753075;2.1007485;-3.2572792;3.2944489;CODE
but app is removed the touch can t access;-5.8697906;0.4534789;4.8587446;0.5146821;-3.9881053;1.9076525;OUTD
to one of the parent i e self parent will be none;-4.1988707;2.3344975;1.446468;-0.29122376;1.1070982;-0.26235336;CODE
and bam the bug happen;-4.145957;-1.0691016;0.19114691;2.6786458;-1.5558192;-1.3259045;-
todo use me push me pop methods because me is transformed;-3.9070318;0.31741706;3.4658744;1.6532565;-2.8603547;2.018756;CODE
clock execution of partial scrollview on touch up method and;-3.1959624;0.061445992;3.0562527;1.8539292;-1.8174273;3.459114;-
other similar cases should be changed so that me push me pop can;-5.310953;1.403325;1.9612454;2.3670125;-0.4520483;0.9591949;CODE
be used restore previous values of event s attributes;-2.1214674;2.2461402;2.7534792;1.4751815;1.1935477;3.2277684;IRRE
me push;-3.1368146;-2.0183303;5.647009;0.3338761;-2.493903;-1.2535359;-
me pop;-2.6118512;-0.938386;5.0459075;0.24471733;-1.257313;-2.6448762;-
prepare the viewport;-4.757687;-1.9890087;5.6257887;-0.44427207;-0.6972589;2.7585857;-
do projection matrix;1.9394052;-0.9946651;1.4884266;-3.1604552;-2.1459513;4.032904;CODE
do modelview matrix;2.7212303;-2.2610695;1.6317154;-1.5449098;-0.28630254;4.269705;CODE
redraw canvas;-3.4049897;-0.78515774;6.4705625;-1.9338344;-2.2518795;2.7360568;-
and update childs;-3.8015778;-2.0672195;3.6738718;2.664793;2.0833962;0.3986082;CODE
quit if user presses esc or the typical osx shortcuts cmd q or cmd w;-5.1062675;0.10503804;1.5210212;2.1844437;-1.9712455;1.0384228;-
on android a back key gesture is mapped to 27 and initiates a pause;-3.6346557;1.4143069;2.5423677;-0.57183945;-1.4697044;1.1965258;IRRE
consume the event and tell android to pause;-4.0501;0.974873;5.4766383;3.5517178;-0.37241563;2.287705;-
todo if just cmd w is pressed only the window should be closed;-5.5824823;1.242156;2.9185798;1.6921566;-0.95489454;1.6845129;CODE
4999 https github com kivy kivy issues 4999 for;-4.4610558;-3.1459417;-1.9308022;-0.96937734;-4.0751977;-2.0902293;CODE
configure how to provide keyboards virtual or not;-4.057687;-0.86290234;0.18109646;-1.0964428;0.101638235;2.3477843;-
register system keyboard to listening keys from window;-2.9776251;-2.7959812;0.92517614;-1.663418;0.44073966;2.324922;CODE
use the device s real keyboard;-3.3102877;-2.6570985;1.9849867;-1.662494;-2.0161426;0.21004544;IRRE
use the device s real keyboard;-3.3102877;-2.6570985;1.9849867;-1.662494;-2.0161426;0.21004544;IRRE
one single vkeyboard shared between all widgets;-1.6458299;-0.9407552;2.0146148;-1.5977234;0.14538804;3.8647122;-
the single vkeyboard is always sitting at the same position;-3.2352707;2.1774228;0.7782448;-1.9589819;-2.1110141;0.8734932;-
now read the configuration;-5.892707;-1.0655122;2.837774;-0.7340245;-0.13636722;1.609722;CODE
adapt mode according to the configuration;-2.8809369;1.151422;0.62125164;-1.354419;0.45028988;4.253497;-
release any previous keyboard attached;-4.60949;-0.5473191;3.4379609;0.5032498;0.26279253;1.7778691;-
if we can use virtual vkeyboard activate it;-4.6156044;-2.9285967;2.1633525;0.037730757;-0.31180844;2.2572439;-
late import;-4.0945706;-3.581447;-0.51266605;1.3972251;-2.0508587;-1.7724062;CODE
if the keyboard doesn t exist create it;-5.8576107;-0.6616051;1.2835724;-0.5195921;-0.5281318;-1.1772637;IRRE
configure vkeyboard;-3.9369905;-1.2959074;0.4374488;-3.6067061;-0.82234;1.5642582;-
add to the window;-7.131627;-1.9790101;7.490644;0.18852964;-0.5904107;0.48068202;TASK
only after add do dock mode;-6.480891;1.560509;2.504979;1.4085745;-3.5554473;2.7746382;CODE
sets vkeyboard position according to window softinput mode;-2.4306386;-0.012437363;0.63742286;-1.478763;-1.7054887;3.7944584;CODE
system keyboard just register the callback;-5.319763;-1.0899416;1.8649584;1.1751877;-1.5282749;1.8992791;IRRE
use system hardware keyboard according to flag;-2.9206007;0.66151243;-0.6087124;-0.38632843;2.6506164;-0.041717686;CODE
this way will prevent possible recursion;-3.853603;3.1104777;2.1144629;3.566343;2.7665381;-0.6835907;CODE
instance of a class windowbase implementation;-3.2194862;-2.8379545;0.43175238;1.832579;3.0670433;2.576522;TASK
default display ids;-3.522637;0.73844665;0.9785882;-2.9544642;2.4341524;2.9245057;CODE
found a way to include it more easily;-4.1824594;-3.3884852;3.5259488;0.299117;2.7003772;2.3931575;CODE
sdl keycode h https wiki libsdl org sdl keymod;-6.89898;-2.9800017;-3.7670214;-3.3801258;1.5867454;0.69127333;CODE
xxx ios keyboard suck when backspace is hit the delete;-3.9053314;0.71953684;-1.041281;-1.2121748;-3.0751317;1.7755122;CODE
keycode is sent fix it;-5.6208057;0.09293071;-0.1309819;-1.5725924;-2.481899;-1.161551;-
map android back button to escape;-4.442997;1.6399162;3.848686;-0.0549491;-0.9701349;2.8277721;META
on ios the did enter foreground is launched at the start;-6.1607094;-0.4233313;4.078166;1.2858776;-2.9388237;2.750681;CODE
of the application in our case we want it only when the app;-4.064051;-0.4951097;4.170879;4.951776;1.3394128;5.0875278;CODE
is resumed;-4.869068;1.0285712;4.6975875;3.292726;0.5298973;0.5497867;-
force kivy to render the frame now so that the canvas is drawn;-3.8509166;0.86399156;3.7962868;0.8312298;-6.4974675;4.3512406;CODE
use custom behavior;-3.0431604;0.9564948;3.7384193;5.47082;3.554004;2.8200712;-
to handle aero snapping and rounded corners;-1.3641498;-2.3457477;3.34658;-1.0299655;-2.465786;4.0678062;-
ensure we have an event filter;-1.9025817;1.659793;2.4433634;6.0877466;1.0223356;2.324315;-
setup window;-4.9988575;-0.92049396;6.103305;-1.1324681;-0.63312787;2.1321964;IRRE
we don t have a density or dpi yet set so let s ask for an update;-1.3290591;-1.6017109;-0.260787;-1.0609833;-2.9861257;2.4463882;CODE
never stay with a none pos application using w center;-3.6509082;1.1012499;0.8724174;0.9154588;-2.4533134;3.2957993;-
will be fired;-2.4827423;-0.10283681;2.7913263;2.884573;-1.4635748;-2.8763468;-
set mouse visibility;-3.4438345;-0.15823852;4.4156003;-1.4309916;-2.8814313;4.601662;IRRE
auto add input provider;-3.5387545;-1.0268446;2.015042;1.1599704;1.6875689;2.8257;TASK
set window icon before calling set mode;-4.487805;2.2670014;3.359;0.8370049;-1.3804717;5.743277;IRRE
transparent window background;-4.537471;-0.49194774;4.298608;-1.0896863;-1.0073564;2.634823;CODE
twb end;-4.0105863;-0.4774908;2.179315;-0.2153768;-0.14963642;-2.4815059;CODE
for android ios we don t want to have any event nor executing our;-4.4458933;-1.1263947;3.7342849;2.935966;-1.9074347;3.2717156;CODE
main loop while the pause is going on this loop wait any event not;-3.8649395;2.0682857;3.9635584;1.8247327;-1.7956227;-0.7144882;CODE
handled by the event filter and remove them from the queue;-1.3072307;2.4259686;3.302636;3.7211494;2.349431;4.114263;IRRE
nothing happen during the pause on ios except gyroscope value sent;-3.4987438;1.4175262;1.2708292;0.7024062;-5.339852;1.3039768;CODE
over joystick so it s safe;-4.9864435;0.48205715;4.207234;-0.08937868;-1.5449488;0.849352;-
a drop is send while the app is still in pause loop;-4.1245527;2.8062775;3.3877327;3.680614;-3.6408913;1.3730009;CODE
we need to dispatch it;-4.6561136;-1.7629874;3.3689554;3.3222322;0.16648069;1.2186191;TASK
app terminating event might be received while the app is paused;-4.182332;1.5499835;1.6450754;2.7115161;-3.173032;2.086424;CODE
in this case eventloop quit will be set at event filter;-4.2374835;2.400224;1.0602627;3.5346613;-2.6739533;2.977713;CODE
for finger pass the raw event to sdl motion event provider;-4.814664;-0.9904797;1.7571871;-0.0045403396;0.53602326;4.735274;CODE
xxx this is problematic on osx it generates touches with 0;-5.412771;1.2241224;0.7927832;-3.0333514;-4.345524;-0.5371774;IRRE
0 coordinates at the same times as mouse but it works;-3.4342492;2.5252407;1.9915117;-4.3285995;-5.872142;1.2962354;META
we have a conflict of using either the mouse or the finger;-5.4127903;-1.0787684;4.631918;1.5982138;-3.5299318;1.5013311;-
right now we have no mechanism that we could use to know;-2.1470277;-2.8213007;4.200892;4.2483745;-1.3624364;0.44020075;IRRE
which is the preferred one for the application;-1.7293904;-3.370457;2.511666;1.8095231;2.2755997;1.4053427;CODE
don t dispatch motion if no button are pressed;-5.0891805;2.4674196;1.1406336;2.5910115;-0.50117815;2.2468607;META
ignore if the cursor position is on the window title bar;-2.980142;2.6616104;2.292463;1.4811286;-2.014998;1.7991587;IRRE
or on its edges;-2.45215;-0.6171531;5.84787;0.84111446;-0.8621786;1.9950935;-
times x if y 0 else y;-0.17026639;2.7951455;3.839142;-4.6415405;-0.2876397;-5.39977;-
times min abs times 100;1.5098096;2.422493;3.0523777;0.46557254;-1.095258;-1.38632;-
for k in range times;2.932291;-0.580638;3.3985033;-3.5480614;0.2085334;-3.0358872;CODE
video resize;-1.2014886;-0.04812405;4.4759684;-2.2234669;-2.914498;4.7683725;-
don t use trigger here we want to delay the resize event;-2.346186;2.8494842;3.3758333;2.1619387;-2.4841704;3.9581747;IRRE
the display has changed so the density and dpi;-2.8034146;1.1351254;2.0784438;-1.8653593;-4.1848974;2.8223622;-
may have changed too;-2.6189175;-0.22372644;1.3462803;2.7151675;-2.1089227;1.1806421;-
maybe in sdl3 this is not needed anymore;-7.0690694;-1.0093225;-2.0759356;0.8580991;1.9838587;6.22942;OUTD
ignore the key it has been released;-5.521924;-0.25681743;0.54837435;1.5497116;-2.2863941;0.9000232;-
if mod in self meta keys;-4.072893;3.5155966;0.27914116;1.079347;0.8159308;-0.72311133;CODE
on android there is no encoding attribute;-4.332485;-0.0055618337;-2.0022721;-2.3307347;-0.84288067;1.1242273;META
on other platforms if stdout is redirected;-3.523341;1.0582485;0.30237743;3.4662535;-4.040759;-0.023457214;CODE
encoding may be none;-4.585858;-0.5782974;-3.5030313;-3.396964;-1.3848956;-2.3351173;-
if shift in self modifiers and key;-2.4877636;3.4106376;-1.1177154;-0.8721256;1.6624012;-0.71114653;CODE
not in self command keys keys;-6.3217545;0.12138317;-0.8550245;-1.0155402;-0.23422024;-0.18793352;CODE
return;-3.9340985;3.4810014;5.3758297;1.501449;-1.2204145;-4.110536;IRRE
don t dispatch more key if down event is accepted;-4.0005107;3.028908;1.3364862;3.5618472;0.6934523;2.757187;CODE
unhandled event;-5.2432704;0.5724096;3.9282787;4.602694;-1.0808345;-0.07059418;-
x y are relative to window left top position;-1.8485339;1.3520727;5.017391;-5.1770024;-3.915229;2.381822;CODE
should go to app pause mode desktop style;-4.8658075;-0.32084838;3.4925616;-0.43439046;-1.74611;3.4659514;-
xxx fixme wait for sdl resume;-5.899057;-0.17232598;-2.026767;2.2827625;-0.65835595;3.0927005;CODE
why does this need to be rounded for now refactored it;-3.3127358;0.009530644;1.3178228;2.038837;-2.6193817;1.4090446;CODE
why abs needs a comment;-2.5552309;-0.04410844;2.0372164;2.0944877;-0.245806;-0.6431097;TASK
this is a jumping module required for python for android project;-5.132435;-2.9688299;1.7161325;-1.339831;-0.8687753;-0.8975984;CODE
because we are putting all the module into the same so there can be name;-7.031532;-1.7085664;-1.3580272;0.7439526;1.555787;2.0013843;CODE
conflict we have one conflict with pygame event and kivy event both are;-5.1682134;-0.64175576;1.1838554;1.4278613;-3.2729065;-0.16827069;-
python extension and have the same initevent symbol so right now just;-5.5780067;-2.6766632;0.18437135;0.341972;0.5800588;-0.51998377;IRRE
rename this one;-3.6366885;-0.44470808;2.6868818;0.81303805;0.5929142;-2.032841;CODE
create additional resources bind callbacks to self window;-6.4713964;0.4486241;3.1989524;3.0845177;-0.8279709;6.9397306;IRRE
handle touch event;-4.744032;0.273075;6.758516;3.0597029;-2.3297;2.1074986;CODE
handle hover event;-3.5500004;-0.11228304;5.237567;1.4670271;-1.9346572;1.7384746;-
release resources;-4.17518;-6.192286;3.3226554;3.4301429;1.269033;0.43733764;-
r comment preproc;-1.8111676;0.50068307;1.9609979;-1.0842091;-0.22721907;-2.8786826;-
r using pythonlexer;-1.079061;-0.81810015;-2.3809662;-4.1055923;-3.5425339;-1.4868189;CODE
r punctuation pop;-2.706333;0.9197219;1.951908;-1.4361056;-1.187608;-2.8147316;-
if trying to access attributes like checking for bind;-5.37199;3.0683105;-0.8786311;2.4806826;1.5696766;-0.43965957;CODE
then raise attributeerror;-1.6791285;3.4622588;-3.8865032;4.130215;-2.5324576;-0.77876;META
no class to return import the module;-4.6580725;-0.8873507;-2.792775;0.22046372;-2.0703652;-1.2244078;CODE
level 0 force absolute;-1.9711242;2.1340997;1.4807993;-1.8718166;-2.1261997;0.36130315;CODE
factory instance to use for getting new classes;-1.529244;-1.7798548;1.654042;3.1232443;3.9057338;2.3560061;CODE
now import the file with all registers;-3.3172908;-0.39192742;-1.4048077;-1.1642996;0.2223061;0.86219;CODE
automatically generated by build factory;-1.9315225;-2.0747573;0.4846518;3.3291733;3.159105;2.0514202;IRRE
import kivy factory registers noqa;-3.733013;-1.0053245;-2.5253093;-1.9057894;-1.3902662;0.9601425;CODE
auto generated file by setup py build factory;-2.6832223;-2.0606523;-1.2928518;1.2593535;-1.5906692;2.0144734;IRRE
https kivy garden github io guideformigratingflowersfromlegacystructure;-5.294422;-3.434969;-0.31015387;0.1354385;-0.09262311;1.8897103;CODE
to your pip conf https pip pypa io en stable user guide config file;-4.9281335;-1.6780272;-3.5009377;-0.068440706;-4.112453;1.1898813;CODE
installing a garden package;-3.8151746;-3.0331054;2.2840743;-0.8738599;-0.296438;-0.18186153;-
upgrade a garden package;-3.233086;-1.8668112;1.9177238;0.47305173;0.062582724;0.57095253;TASK
uninstall a garden package;-4.8716087;-0.7877245;1.3066387;0.025288943;-1.5145835;0.73497105;-
list all the garden packages installed;-2.1085954;-3.6057224;2.5619972;-0.51006925;1.627893;-1.0871521;-
search new packages;-2.0654976;-3.6455526;0.32168615;2.0975442;1.1565444;-1.4630803;CODE
search all the packages that contain graph;0.46656895;-2.2417626;1.5247582;-2.0595431;0.38281682;-0.8453351;-
show the help;-4.115882;0.44616058;6.0297794;-0.9262288;-0.90131885;-3.365755;-
system path where garden modules can be installed;-3.6322706;-3.6594465;2.1625643;-0.83661336;0.8018518;2.4139147;CODE
application path where garden modules can be installed;-3.8395846;-4.0783315;2.2437446;-1.0859836;0.4836214;2.8440585;CODE
fixes issue 4030 in kivy where garden path is incorrect on ios;-5.5032053;-0.91536295;-0.40124193;0.2788745;-5.4233704;0.5458787;CODE
insert the garden importer as ultimate importer;-4.725913;-1.6054549;-0.0141485995;1.553331;0.088491075;3.4214091;CODE
determine a point p with the smallest y value;1.4108313;3.1770852;2.4175494;-3.72717;-3.1869113;-1.2251445;IRRE
find a point q such that the angle of the line segment;-2.6544259;1.4303889;3.5750144;-1.3800982;-1.6036146;0.693387;CODE
pq with the x axis is minimal;0.92285776;4.5275087;0.63715947;-5.064536;-2.673042;4.2325816;-
return 1e10 max val if the same to skip;1.0335022;8.036088;0.016014168;0.6150006;-0.07956677;-2.1390264;IRRE
find r such that angle prq is minimal;0.21752015;3.6460474;1.4036086;-3.3384504;-0.7711459;0.65541166;-
return 1e10 max val if the same to skip;1.0335022;8.036088;0.016014168;0.6150006;-0.07956677;-2.1390264;IRRE
check for case 1 angle prq is obtuse the circle is determined;-2.4865377;4.364302;1.5176048;-0.96520644;0.38180876;-2.958127;CODE
by two points p and q radius p q 2 center p q 2;-1.5526574;1.7868202;4.5391808;-3.7830672;-1.3359749;0.50215465;CODE
if angle rpq is obtuse make p r and try again;-3.3678248;4.191117;-0.8407881;-1.7999724;-1.5810397;-0.2940909;IRRE
if angle pqr is obtuse make q r and try again;-4.0425606;3.8904626;-0.30674243;-2.246427;-1.8804343;-0.5858131;IRRE
all angles were acute we just need the circle through the;-3.077882;0.5191882;3.7301896;0.3842782;-2.4307716;0.6518203;CODE
two points furthest apart;1.1072652;1.7762399;5.448328;-3.3750749;-0.19225457;-1.8912542;CODE
find the circumcenter for triangle given by p q r;-2.4779065;2.1934593;3.9381106;-3.4286609;-1.7937757;0.18452395;CODE
create a gesture;-2.3475082;-1.3747046;7.335312;-1.43179;-0.8166427;1.7633712;IRRE
add it to the database;-4.4074697;-2.4414139;3.0296967;0.3970504;2.1395848;-0.017743662;TASK
and for the next gesture try to find it;-3.1681798;0.26575994;5.094183;2.6466844;-0.6997632;0.519233;CODE
these return the min and max coordinates of the stroke;0.35725474;1.4020247;2.5887325;-4.357696;-1.6109768;-0.07117508;IRRE
if len point list 1 if there is only one point no length;2.087991;3.704331;2.7556403;-4.6587706;-0.02324837;-4.5877557;CODE
if there is only one point or the length is 0 don t normalize;2.406285;4.6258917;2.0776079;-5.94673;-2.7707312;1.1103555;CODE
calculate how long each point should be in the stroke;1.5885623;2.4308422;4.317726;-2.4695017;-1.4337673;-1.6489891;CODE
we loop on the points;3.189974;0.91602534;7.583432;-3.0731218;-0.52544063;-2.6924896;IRRE
the new point need to be inserted into the;-4.7709217;2.1823082;2.3760774;-1.5287956;-2.1881719;1.093674;CODE
segment prev curr;-0.6732137;2.026078;1.563104;-4.3217354;-0.41199192;-0.6050118;-
if this happens we are into troubles;-4.530439;1.746016;2.8170264;1.2659591;-2.2246249;-1.5857419;CODE
tolerance for evaluation using the operator;2.0475633;4.5723004;-1.2456454;3.6737356;0.7685177;-1.0782967;CODE
map creates a list of min max coordinates of the strokes;1.5757339;0.82570744;3.1628265;-4.272358;-0.09256641;1.3651015;IRRE
in the gesture and min max pulls the lowest highest value;-0.45938653;1.5155673;2.981404;-1.2356794;-0.63865954;1.8118926;IRRE
adds up all the points inside the stroke;0.71519995;1.6170866;3.7746396;-1.6693875;-0.2940993;0.24094315;TASK
average to get the offset;3.679067;2.6266115;5.3344474;-2.0708857;-2.696195;-0.37814796;IRRE
apply the offset to the strokes;-0.42895406;0.9267964;4.3033247;-2.5909517;-1.3485582;2.5161693;IRRE
get orientation;-2.7611144;-1.2276058;3.9566166;-1.7103564;0.14969459;2.613044;-
rotate the gesture to be in the same frame;-2.1803617;0.51664805;4.06289;-1.797038;-2.6821406;3.6214666;CODE
this is the normal orientation code;-3.5582712;-0.51525086;1.5245215;-5.0402284;1.5109488;0.5940137;CODE
if the gestures don t have the same number of strokes its;-1.4409676;1.016319;4.1361074;-0.1252675;0.3345745;1.4298018;CODE
definitely not the same gesture;-2.6356177;0.36545295;3.875059;0.93449134;-1.439888;2.0767663;IRRE
add a red color;-3.560791;-0.86801267;4.896164;-1.5354638;0.69852096;-0.82535887;TASK
add a rectangle;-2.1260107;1.1259751;7.6616154;-4.940646;-0.39040354;0.20730145;TASK
very hacky way to avoid pyflakes warning;-2.1098106;0.8062125;-3.4262407;0.99798673;-4.424398;-0.9852042;CODE
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
me push save current type id and other values;-2.9299827;1.6625147;1.4994186;0.990778;1.5888231;2.173129;IRRE
dispatch mouse touch event to widgets which registered;-4.016425;-1.9211619;2.9073417;0.97762424;-1.7763073;4.112759;IRRE
to receive mouse touch;-5.165435;-2.580725;6.0459394;-0.22857922;-3.209976;1.5805879;IRRE
me pop restore;-5.6417694;-0.5761815;3.8882372;1.3472785;-1.9296817;-0.28586084;-
will receive all motion events;-3.7353952;-2.097962;4.8383713;1.14297;0.7520243;0.34146076;-
current position in 0 1 range;-0.25666183;3.6329312;2.9900045;-4.1812835;-1.7550687;-1.0456953;-
first position set in 0 1 range;0.9228366;3.7309697;3.929043;-5.191905;0.28765175;-0.5021737;IRRE
last position set in 0 1 range;0.7760894;4.015968;4.918618;-5.2918773;-0.2509505;-1.4657501;IRRE
delta from the last position and current one in 0 1 range;-0.028570728;3.5252564;4.1534824;-3.5928247;-2.152732;-1.0968691;CODE
current position in screen range;-2.062123;1.567862;5.6657696;-2.7109828;-2.8107755;1.3129566;-
first position set in screen range;-2.5549529;2.2280807;5.501135;-3.586509;-2.3094838;2.617494;IRRE
last position set in 0 1 range;0.7760894;4.015968;4.918618;-5.2918773;-0.2509505;-1.4657501;IRRE
delta from the last position and current one in screen range;-0.9773926;2.5840986;6.461465;-2.8258834;-2.6666725;1.2192645;CODE
true if the motionevent is a touch;-3.5117888;0.5568381;4.1070557;2.0668027;-2.1697547;1.0580237;-
experimental string to identify event type;-0.9097295;0.014152805;-0.51008296;2.600667;1.7402471;-3.4448721;CODE
versionadded 2 1 0;-5.124447;-0.19845156;-0.73588806;0.24544837;1.216944;-1.405504;TASK
experimental used by a event manager or a widget to assign;-0.9655566;-3.947666;4.7355366;3.143838;1.6769817;2.4901726;IRRE
the dispatching mode defaults to;-6.290185;-0.69674104;0.61177886;2.7979562;-0.3724687;5.3701777;CODE
const kivy eventmanager mode default dispatch see;-5.884767;-1.6328536;-0.21174823;2.5889666;-3.3377347;4.7305713;CODE
mod kivy eventmanager for available modes;-4.1987996;-1.7839043;1.3733922;2.1087155;-1.2165257;4.99852;CODE
versionadded 2 1 0;-5.124447;-0.19845156;-0.73588806;0.24544837;1.216944;-1.405504;TASK
attributes to push by default when we use meth push x y z;-2.258209;1.0815722;0.8086391;0.17039657;-0.13791493;4.404185;IRRE
dx dy dz ox oy oz px py pz;-2.2733715;1.3935901;0.8558269;-3.6766043;0.8256028;-0.8881295;-
uniq id of the event you can safely use this property it will be;-1.1018634;2.054003;2.4795558;2.2576091;6.1363354;2.5584478;CODE
never the same across all existing events;-1.13346;1.4457641;3.864672;5.140035;1.726388;2.0757003;-
device used for creating this event;-4.2802124;-4.286288;5.997365;1.0931642;1.8915796;0.7556627;CODE
for grab;-2.5034473;-1.1418576;5.404211;2.0591345;0.3724322;-1.745766;CODE
used to determine which widget the event is being dispatched to;-4.212043;-2.5555403;4.316594;1.8490579;-0.22129145;2.1664317;OUTD
check the meth grab function for more information;-1.3570001;2.2280471;2.1745136;0.5623265;-2.3050747;-1.3161527;CODE
currently pressed button;-5.8640976;-0.24263786;6.93109;1.2728289;-0.7656031;0.41226196;META
profiles currently used in the event;-2.0327857;-3.5484488;3.7284648;0.9677047;1.958892;3.3978648;CODE
id of the event not unique this is generally the id set by the;-2.5146153;0.6862251;1.1845211;0.6038708;3.8653014;0.28754312;CODE
input provider like id in tuio if you have multiple tuio sources;-2.0680969;-0.2857813;-0.46459538;-1.5603939;4.7549715;1.7767555;CODE
then same id can be used prefer to use attr uid attribute;-2.4969838;1.3042704;-0.39562497;-0.6284017;5.2524514;4.4318757;META
instead;-3.4498208;-1.8747259;4.7573843;1.0487124;-1.2410853;-0.27382374;-
shape of the touch event subclass of;-2.467139;-2.5723872;5.2265406;0.5562252;0.28131554;3.1074636;IRRE
class kivy input shape shape;0.5893838;-2.6470106;2.1628497;-2.606079;-1.3582978;0.5283026;CODE
by default the property is set to none;-5.796714;4.1536107;-0.21442205;2.0077958;-0.8624323;3.2968535;IRRE
x position in 0 1 range;0.3250494;3.6691535;3.721626;-6.9916472;-1.8987005;-1.4191893;-
y position in 0 1 range;0.3489949;2.6377666;3.6939194;-6.5074735;-4.0614314;-2.146693;-
z position in 0 1 range;-0.016889201;4.4929466;2.3331423;-6.357765;-1.8247787;-0.65285385;-
origin x position in 0 1 range;-0.5848602;3.1007202;2.690726;-6.8088107;-3.5344377;1.3286757;-
origin y position in 0 1 range;-0.3671869;2.2492096;3.1060379;-6.4265103;-5.4796896;-0.09798683;-
origin z position in 0 1 range;-0.6752411;3.4487584;1.8756291;-6.471637;-3.2389877;1.1272041;-
previous x position in 0 1 range;-0.002818467;4.2595806;4.2822623;-5.749249;-2.0162876;-0.3816808;-
previous y position in 0 1 range;-0.020622017;3.4073632;4.1514;-5.3428245;-3.8818674;-1.1588848;-
previous z position in 0 1 range;-0.2857892;4.9592366;2.7826476;-5.4647684;-1.736645;0.09186272;-
delta between self sx and self psx in 0 1 range;0.24918658;2.5641322;-2.0217192;-3.100771;-1.9132702;2.2076106;CODE
delta between self sy and self psy in 0 1 range;0.217571;1.3813349;-2.5705564;-1.8964926;-3.6023;0.56254244;CODE
delta between self sz and self psz in 0 1 range;0.29851073;2.7056134;-1.3444527;-2.2082841;-2.4548473;1.2803146;CODE
x position in window range;-1.4874187;2.1672058;5.296402;-4.6184754;-2.1895125;1.4785935;CODE
y position in window range;-1.6664898;1.570187;5.2784505;-4.679488;-4.4684525;0.7686445;CODE
z position in window range;-1.9854331;2.96403;3.8472607;-4.457877;-2.2824256;1.9380215;CODE
origin x position in window range;-2.4637759;1.7907007;4.1303387;-4.5448146;-3.4025817;3.8488607;CODE
origin y position in window range;-2.2010303;1.4708848;4.6651907;-4.6653438;-5.2637243;2.5559433;CODE
origin z position in window range;-2.57327;2.318435;3.292766;-4.7524505;-3.186834;3.4357939;CODE
previous x position in window range;-1.7907823;2.905028;5.8915567;-3.2272367;-2.2005692;2.161345;CODE
previous y position in window range;-1.8975756;2.424776;5.7594476;-3.248736;-4.0458546;1.3974962;CODE
previous z position in window range;-2.1611621;3.556152;4.3055916;-3.4907498;-2.1459992;2.377614;CODE
delta between self x and self px in window range;-0.46701998;2.4127362;-0.13113533;-2.7797308;-2.75488;3.8519287;CODE
delta between self y and self py in window range;-0.05334652;0.87920123;-0.23554555;-2.8038344;-6.082011;1.9661103;CODE
delta between self z and self pz in window range;-0.5037791;2.6759303;0.22869226;-2.5265026;-2.9995782;3.113493;CODE
position x y in window range;-1.3521918;1.579385;5.731428;-5.12707;-3.2447484;1.0668159;CODE
initial time of the event creation;-3.4699218;-0.5047862;4.038133;1.6324457;-0.009499873;0.79901713;IRRE
time of the last update;-3.326522;-3.473221;3.7865632;1.5892905;-1.2852209;-1.4851469;CODE
time of the end event last event usage;-2.2040772;0.79222757;4.0167727;1.4904164;-0.70064276;0.4145546;CODE
indicate if the touch event is a double tap or not;-2.5758026;2.1381633;4.2870665;2.9705853;-0.45307672;0.60961837;CODE
indicate if the touch event is a triple tap or not;-2.6863222;2.0561728;4.67144;1.7260268;1.0538248;0.43318617;CODE
versionadded 1 7 0;-4.3432045;-0.20836686;-0.51561993;0.22962505;0.43775633;-2.0005407;TASK
if the touch is a attr is double tap this is the time;-4.429771;1.0107055;4.885105;2.2757738;-1.3994803;1.0054677;CODE
between the previous tap and the current touch;-3.3454697;0.7213684;8.213046;1.6035342;-1.1265986;1.3839062;-
if the touch is a attr is triple tap this is the time;-4.2181525;0.7058343;5.484845;1.4699565;0.18178864;0.9942145;CODE
between the first tap and the current touch;-3.106767;0.31939942;7.948351;0.6327193;-1.223913;0.51371807;-
versionadded 1 7 0;-4.3432045;-0.20836686;-0.51561993;0.22962505;0.43775633;-2.0005407;TASK
user data dictionary use this dictionary to save your own data on;-1.0964226;-2.4684112;1.5316089;-0.78810006;0.4794614;-0.47740602;CODE
the event;-2.6720064;-2.7949793;8.028373;2.898919;1.3369968;-2.6841993;-
if set to true default keeps first previous position;-1.766468;6.33099;2.3984387;0.982444;-0.61204547;-0.1849237;IRRE
x y z in 0 1 range and ignore all other until;1.9732873;5.5286098;1.9699955;-3.797796;-0.82078743;-2.5732782;CODE
meth motionevent dispatch done is called from the eventloop;-4.2903886;-2.5519016;2.3323772;2.4367442;-0.16924068;3.485149;IRRE
this attribute is needed because event provider can make many calls;-4.4485636;0.17436229;1.2692516;3.0178757;3.4330683;4.83905;IRRE
to meth motionevent move but for all those calls event is;-4.1023993;-0.07578715;3.0903676;2.4331012;-0.8944631;2.9583101;IRRE
dispatched to the listeners only once assigning false will keep;-3.2559583;4.5884733;-0.5790292;4.8630195;0.63640296;2.3079438;IRRE
latest previous position see meth motionevent move;-3.1265018;0.3744643;3.3564992;-0.2733013;-3.2045577;2.4435163;IRRE
versionadded 2 1 0;-5.124447;-0.19845156;-0.73588806;0.24544837;1.216944;-1.405504;TASK
keep first previous position if attr sync with dispatch is;-3.0649965;3.9303563;2.5910552;1.8586044;0.4549494;3.9974775;-
true;-0.6604863;-0.90942127;1.8119599;3.378718;0.206395;-0.28846526;-
flag that first dispatch of this event is done;-4.6806746;2.457869;4.228467;4.18711;1.7835727;2.072899;CODE
sync origin previous current positions until the first;-1.427446;2.5118468;5.6994944;-1.5395826;-1.191724;3.8628087;-
dispatch etype begin is done;-4.3438253;-2.868124;-0.725902;2.3638294;0.123096205;1.1618336;CODE
update the delta;-1.5455959;-0.19742699;2.395102;1.3457214;-1.3920093;-0.43661553;CODE
i received my grabbed touch;-4.266896;0.2691889;5.1618395;2.0643752;-1.9240735;-0.68311244;-
it s a normal touch;-3.212416;-0.0077242455;5.196986;0.039919946;-3.04005;1.2278942;-
i receive my grabbed touch i must ungrab it;-4.6670747;1.0222152;4.193879;1.9335204;-1.7224271;0.567284;-
it s a normal touch;-3.212416;-0.0077242455;5.196986;0.039919946;-3.04005;1.2278942;-
adjust y for keyboard height;-2.3703916;-0.18156971;2.151584;-4.3049655;-3.9215455;1.3759729;CODE
update delta values;1.6969126;3.158396;1.9995202;-1.3804997;-1.7893057;-0.7429787;IRRE
cache position;-1.4771909;0.6203616;4.1170425;-0.022329208;-0.41099736;3.642861;-
facilities;-2.8956578;-1.801719;6.3015757;-0.44284555;1.6946111;-1.469453;-
mapping of id to module;-2.9850795;0.75338495;0.35020104;-2.3918233;4.159037;1.5363287;CODE
don t go further if we generate documentation;-4.611228;-5.8413215;0.7872699;3.7242095;3.0337703;-1.450096;CODE
the right screen is just a display;-4.2994356;0.3654503;4.943392;-1.9939699;-2.4951534;0.60093135;-
avoid doing any processing if there is no device to calibrate at all;1.7297974;0.61964244;-1.29753;2.8630142;-3.8637526;0.6358388;CODE
frame based logic below doesn t account for;-1.0802331;5.7385955;1.4862287;-1.5059621;-0.70217484;-1.3345187;CODE
end events having been already processed;-5.2149577;2.780867;2.5446484;4.82227;-0.2596905;1.6541463;CODE
some providers use the same event to update and end;-5.0894694;0.7844481;2.5993056;4.3130836;0.722257;3.698652;CODE
get the taxicab manhattan citiblock distance for efficiency reasons;2.0811293;0.15163015;2.7871392;-0.6111889;-0.5168927;0.99959254;CODE
check whether the touch moved more than the jitter distance;0.89143264;2.7313607;3.478397;1.285261;-4.5657516;-0.18157926;-
only if the touch has moved more than the jitter dist we take;-1.0858077;1.6205392;5.0905848;2.5146372;-3.061604;2.2935386;-
it into account and dispatch it otherwise suppress it;-5.2479987;1.7728829;1.5829858;5.256473;1.7177296;3.945513;CODE
first check if a touch down have a double tap;-3.911804;2.9041402;4.3393846;2.6717777;-2.0876517;-0.27302343;CODE
add the touch internally;-6.2766423;-0.40833697;6.8747416;0.12743074;-1.9331915;2.2784665;TASK
second check if up touch is timeout for double tap;-3.3505502;4.0824304;2.7600977;3.8413682;-2.9719625;-1.1253113;CODE
format xmin ymin xmax ymax;-1.0304021;2.2956178;2.1402764;-7.6549215;-0.6094015;-2.083458;CODE
check if module is disabled;-5.448943;3.4368117;-1.0124395;2.965969;-2.0894578;-0.44426408;IRRE
new touch found the nearest one;-2.20554;-1.8579088;5.4907722;1.4397099;-1.8542782;1.2067059;CODE
eligible for continuation;-3.8917239;2.7206905;1.3662025;3.749359;2.7706516;0.34152618;CODE
first check if a touch down have a triple tap;-3.7430398;2.7473855;5.0618753;1.8971066;-0.18939947;-0.14443068;CODE
add the touch internally;-6.2766423;-0.40833697;6.8747416;0.12743074;-1.9331915;2.2784665;TASK
second check if up touch is timeout for triple tap;-3.5165102;3.9767666;3.1620877;3.214847;-1.8236854;-0.94057435;CODE
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
import kivy input providers leapfinger noqa;-3.7185433;-3.652006;-1.354449;-1.8183049;-3.2014198;0.480824;CODE
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
import android noqa;-4.3931637;-0.6696238;-0.8953736;-1.8922331;-0.45365527;0.16679649;CODE
python for android do 1000;-2.309187;-3.8471925;0.66081613;-0.64842767;-3.1427348;-2.646556;CODE
new touch;-3.8696826;-2.8999324;6.9116297;1.612744;-2.3768575;0.4031463;CODE
update touch;-5.083187;-1.5138521;5.119445;1.9951767;-2.8690712;1.2589427;CODE
avoid same touch position;-1.9508071;2.730155;5.4110394;0.43369183;-1.4476846;3.4577973;CODE
disappear;-3.9916227;1.974938;6.3325644;0.13674435;-1.4433489;-0.68582445;-
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
devicename hidinput dev input eventxx;-4.5496273;-2.424681;-0.20252341;-0.53003997;-0.80064493;0.73378175;CODE
example with stantum mtp4 3 screen;-4.76264;-2.119752;0.60819;-2.4156175;-1.1987945;2.2801034;-
late imports;-3.8360555;-2.6040723;0.2517241;2.134504;-0.800327;-1.0688827;CODE
documentation hack;-5.784853;-5.748391;1.17219;3.3991477;1.3460644;-2.565557;CODE
this part is taken from linux source 2 6 32 include linux input h;-4.9908705;-3.7380164;-1.5853097;-4.7076397;1.1587262;-0.9458565;CODE
event types;-2.3270323;-2.7015355;4.3958554;1.9688238;2.8251832;-0.6464554;-
synchronization events;-1.3544757;-1.551996;5.50298;3.4543135;1.0667589;1.6885911;-
misc events;-1.9072287;-1.1783583;3.1749692;2.6549742;0.37622043;-1.3645163;-
abs mt touch major 0x30 major axis of touching ellipse;-1.6176667;0.7853282;1.5789374;-4.094005;-5.067049;1.6660696;-
abs mt touch minor 0x31 minor axis omit if circular;-1.1242512;4.804398;1.4306699;-3.8707724;-3.9492903;1.3905346;-
abs mt width major 0x32 major axis of approaching ellipse;-0.49999136;1.1825919;0.51312643;-4.609667;-4.9744596;2.6924314;-
abs mt width minor 0x33 minor axis omit if circular;-0.016410323;4.8520465;0.29659033;-4.939828;-2.8347576;2.1925526;-
abs mt orientation 0x34 ellipse orientation;-1.4087151;0.917103;-0.39175835;-5.424172;-2.855059;1.715293;-
abs mt position x 0x35 center x ellipse position;-0.13892221;1.8605367;1.4575391;-5.0465198;-4.263239;1.741343;-
abs mt position y 0x36 center y ellipse position;-0.7833669;2.0183153;2.453145;-4.8588824;-5.5906625;0.4834294;-
abs mt tool type 0x37 type of touching device;-3.224253;0.15847217;1.6188582;-1.7837849;-1.4373322;0.7503149;-
abs mt blob id 0x38 group a set of packets as a blob;0.30771273;1.1897848;-1.1274923;-4.932527;1.7006005;1.3690242;IRRE
abs mt tracking id 0x39 unique id of initiated contact;-0.92350644;3.435537;-0.88762444;-1.9272053;2.9920526;2.0751872;IRRE
abs mt pressure 0x3a pressure on contact area;-2.1749198;3.2528536;0.15351309;-2.951137;-2.6873333;1.4759954;-
some ioctl base with 0 value;-3.6728039;4.584792;-2.6128833;-1.3926476;0.39807987;0.86551845;IRRE
0x04 3;-3.10789;1.4011433;1.8243567;-7.797435;1.8084974;-2.1228778;-
todo combinations;0.05980825;0.116305776;5.8908973;0.49465162;4.0864534;-3.7759938;TASK
e0 37 prtscr;-3.7421653;-0.6101105;0.073463015;-3.272316;0.64562446;-3.7150943;-
e0 46 ctrl break;-6.6091547;0.4376471;1.5281959;-1.7538831;-0.9610444;-3.2235987;CODE
e0 5b lwin usb lgui;-5.185647;-1.2209779;-0.6869379;-2.8314877;-0.29907784;0.23872913;-
e0 5c rwin usb rgui;-5.01056;-1.0533514;-0.4236977;-2.3693237;-0.98117;0.5665539;-
e0 5d menu;-5.454649;-0.7151085;3.8066099;-2.443633;-0.07336196;1.6291429;-
e0 5f sleep;-1.8775976;-0.00010706986;0.8749261;0.13963333;-1.6706293;-0.47627378;-
e0 5e power;-3.3955286;-0.32788017;1.8418196;-0.6771473;0.95933896;-1.0242212;-
e0 63 wake;-3.970309;-1.8259774;1.4904429;-1.2897211;-0.0013680414;-1.2234939;-
e0 38 ralt;-3.4791963;0.8147264;1.9647695;-2.639098;0.59130794;-2.3007154;-
e0 1d rctrl;-2.8705218;-0.4036017;1.0633601;-3.2943382;0.88240397;0.016945042;-
e0 52 insert;-4.340375;1.2170715;1.9833678;-2.607565;2.3892496;-3.2800317;CODE
e0 53 delete;-4.9409857;1.6691926;0.10986953;-2.0290415;1.3191621;-2.4718647;CODE
e0 47 home;-3.3012197;-0.56102157;2.260927;-2.3834863;0.040247712;-2.8272264;-
e0 4f end;-4.0340605;0.8730974;2.0189054;-2.0193634;-1.2810076;-1.8243057;CODE
e0 49 pgup;-2.6183138;0.24637309;1.6675283;-3.9562836;1.1385309;-4.0106277;-
e0 51 pgdn;-3.7474236;-1.0593884;0.5636046;-3.9772582;0.50796145;-3.996716;-
e0 4b left;-4.722959;1.1791515;2.647827;-3.6307108;0.9263707;-2.2551782;-
e0 48 up;-3.5002725;0.27162737;2.9277382;-1.9581544;0.20891467;-1.8654212;-
e0 50 down;-1.81732;0.55486447;3.1878514;-1.3552026;-0.3450843;-1.8802625;CODE
e0 4d right;-2.5993354;0.5591889;2.0662014;-3.186972;0.8931833;-0.467018;-
e0 35 kp;-1.3322015;-0.46013418;2.210574;-2.4655948;0.53177357;-0.9815483;-
e0 1c kp enter;-3.1173558;0.3553678;1.4976987;-3.3982155;0.9021538;-2.3786707;-
e1 1d 45 77 pause;-4.1704755;1.4610829;1.8194559;-2.2843642;0.09169858;-1.9349476;-
sizeof struct input event;-0.8190968;2.4660895;2.019947;-1.223415;-0.6796827;-0.16779713;CODE
split arguments;-0.64692104;2.4272316;2.734676;-1.34173;3.9361951;-1.6885074;-
read filename;-2.9260557;-1.0905697;2.381076;-0.9210473;-0.6611841;-2.0573907;CODE
read parameters;-0.93765837;2.2086718;1.4106275;-0.8491151;0.5884658;-1.0168422;IRRE
ensure it s a key value;-3.457377;4.3591948;0.34560013;0.08099907;1.6350098;-2.2871752;IRRE
ensure the key exist;-4.0863953;3.5004098;0.32370764;1.029108;1.2273247;-2.5698817;-
ensure the value;-0.88929063;7.0405927;2.5181444;1.7340602;0.7034628;-5.812135;IRRE
all good;-4.552293;-1.5731685;2.056553;-0.5457817;-0.30199873;-0.087717906;-
prepare some vars to get limit of some component;0.8586149;3.8311408;1.2002217;0.7607797;1.6925194;0.16623871;CODE
limit it to the screen area 0 1;-4.7857227;2.4839325;4.2485995;-1.4859859;-2.7198312;2.7652993;-
sync event;-2.7652485;-0.83963144;6.589981;3.155356;-1.0530838;1.385272;-
compute multitouch track;1.7935126;0.0032763877;4.0642433;-2.6626015;-0.9938049;0.9048176;-
for scrolls we need to remove it as there is;-6.7352037;0.18934295;2.8406403;-0.19222963;-2.5310743;2.843831;TASK
no up key;-4.9780087;-0.23567154;3.1207097;-1.6164494;-1.2983272;-2.6860433;-
elif ev code 8 wheel;-3.7572062;-2.3709927;0.08943307;-3.0591376;0.81602436;-1.6515746;-
translates the wheel move to a button;-4.359289;-1.1913239;4.4252806;-2.1323245;-1.8504283;0.34504104;IRRE
or if it is not in this lut;-2.8702314;2.9199195;1.4412708;1.8402903;0.00494132;-0.14270662;CODE
open the input;-3.7770092;-0.7623644;6.295801;-1.0050523;-0.84434605;-3.3559887;CODE
get the controller name eviocgname;-4.992532;-0.11097463;2.0359828;0.7228823;1.2516938;1.5442853;-
get abs infos;1.2587097;0.032429617;1.8296483;-0.027506229;0.4872976;-0.7116036;-
preserve this we may want other things than ev abs;-2.690187;-1.1425011;1.8879247;2.1571991;2.3747733;1.7179941;CODE
ev abs available for this device;-2.4711597;-1.6449327;1.3734375;-0.5493382;1.8069948;1.1056658;CODE
ask abs info keys to the devices;-2.297551;-1.4647065;0.96718305;-1.585133;1.0509565;0.30734706;-
init the point;-2.817728;-0.53022707;3.0312903;2.5400856;-0.29847613;-0.15246317;IRRE
read until the end;-2.1395433;-0.70007676;5.2902374;2.6484723;-1.7162105;-3.5549622;CODE
extract each event;0.8193188;-0.83584976;4.963435;0.5765073;2.376817;-1.7710521;-
extract timeval event infos;0.30102414;-0.95992637;2.6130998;0.25306964;-0.20342787;-0.7526298;-
dispatch all events from threads;-2.2677462;-1.02897;3.944492;3.7112799;0.11021585;3.2212095;CODE
don t do the import at start or the error will be always displayed;-5.08235;2.0188925;-3.189496;1.8610846;-3.5923803;-0.15593694;CODE
for user who don t have leap;-2.5992115;-1.7007313;4.455762;-0.5951689;-0.29464772;-3.2450585;CODE
print hand id finger id finger tip;-3.7429843;0.2994752;1.922102;-3.3947234;1.8185542;-1.0918769;CODE
registers;-2.3976533;-0.5143097;2.8855088;-2.309239;3.8414595;-2.258032;-
documentation hack;-5.784853;-5.748391;1.17219;3.3991477;1.3460644;-2.565557;CODE
this part is taken from linux source 2 6 32 include linux input h;-4.9908705;-3.7380164;-1.5853097;-4.7076397;1.1587262;-0.9458565;CODE
event types;-2.3270314;-2.7015355;4.395854;1.9688232;2.8251812;-0.64645505;-
synchronization events;-1.3544757;-1.551996;5.50298;3.4543135;1.0667589;1.6885911;-
misc events;-1.907228;-1.1783596;3.1749694;2.654975;0.37621984;-1.3645179;-
abs misc 0x28 if 0 it s touch up;-1.5604138;4.3458586;0.47933042;-2.0200782;-3.3386862;-1.6397322;-
abs mt touch major 0x30 major axis of touching ellipse;-1.6176667;0.7853282;1.5789374;-4.094005;-5.067049;1.6660696;-
abs mt touch minor 0x31 minor axis omit if circular;-1.1242508;4.804396;1.4306709;-3.8707738;-3.949292;1.3905343;-
abs mt width major 0x32 major axis of approaching ellipse;-0.49999136;1.1825919;0.51312643;-4.609667;-4.9744596;2.6924314;-
abs mt width minor 0x33 minor axis omit if circular;-0.016411023;4.8520465;0.29658958;-4.939828;-2.8347578;2.1925547;-
abs mt orientation 0x34 ellipse orientation;-1.4087151;0.917103;-0.39175835;-5.424172;-2.855059;1.715293;-
abs mt position x 0x35 center x ellipse position;-0.13892221;1.8605367;1.4575391;-5.0465198;-4.263239;1.741343;-
abs mt position y 0x36 center y ellipse position;-0.7833669;2.0183153;2.453145;-4.8588824;-5.5906625;0.4834294;-
abs mt tool type 0x37 type of touching device;-3.224253;0.15847217;1.6188582;-1.7837849;-1.4373322;0.7503149;-
abs mt blob id 0x38 group a set of packets as a blob;0.30771273;1.1897848;-1.1274923;-4.932527;1.7006005;1.3690242;IRRE
abs mt tracking id 0x39 unique id of initiated contact;-0.92350644;3.435537;-0.88762444;-1.9272053;2.9920526;2.0751872;IRRE
abs mt pressure 0x3a pressure on contact area;-2.1749198;3.2528536;0.15351309;-2.951137;-2.6873333;1.4759954;-
some ioctl base with 0 value;-3.6728039;4.584792;-2.6128833;-1.3926476;0.39807987;0.86551845;IRRE
sizeof struct input event;-0.8190968;2.4660895;2.019947;-1.223415;-0.6796827;-0.16779713;CODE
split arguments;-0.64692104;2.4272316;2.734676;-1.34173;3.9361951;-1.6885074;-
read filename;-2.9260557;-1.0905697;2.381076;-0.9210473;-0.6611841;-2.0573907;CODE
read parameters;-0.93765837;2.2086718;1.4106275;-0.8491151;0.5884658;-1.0168422;IRRE
ensure it s a key value;-3.457377;4.3591948;0.34560013;0.08099907;1.6350098;-2.2871752;IRRE
ensure the key exist;-4.0863953;3.5004098;0.32370764;1.029108;1.2273247;-2.5698817;-
ensure the value;-0.88929063;7.0405927;2.5181444;1.7340602;0.7034628;-5.812135;IRRE
all good;-4.552293;-1.5731685;2.056553;-0.5457817;-0.30199873;-0.087717906;-
prepare some vars to get limit of some component;0.8586149;3.8311408;1.2002217;0.7607797;1.6925194;0.16623871;CODE
open the input;-3.7770092;-0.7623644;6.295801;-1.0050523;-0.84434605;-3.3559887;CODE
get the controller name eviocgname;-4.992532;-0.11097463;2.0359828;0.7228823;1.2516938;1.5442853;-
get abs infos;1.2587097;0.032429617;1.8296483;-0.027506229;0.4872976;-0.7116036;-
preserve this we may want other things than ev abs;-2.690187;-1.1425011;1.8879247;2.1571991;2.3747733;1.7179941;CODE
ev abs available for this device;-2.4711597;-1.6449327;1.3734375;-0.5493382;1.8069948;1.1056658;CODE
ask abs info keys to the devices;-2.297551;-1.4647065;0.96718305;-1.585133;1.0509565;0.30734706;-
read until the end;-2.1395433;-0.70007676;5.2902374;2.6484723;-1.7162105;-3.5549622;CODE
extract each event;0.8193188;-0.83584976;4.963435;0.5765073;2.376817;-1.7710521;-
extract timeval event infos;0.30102414;-0.95992637;2.6130998;0.25306964;-0.20342787;-0.7526298;-
dispatch all event from threads;-2.43683;-0.9063761;4.020668;3.684719;-0.056971636;3.1552534;CODE
current state of unknown meaning;-1.0894411;0.10401706;1.2450742;4.6957135;0.91139555;0.018852487;-
normalized position and vector of the touch 0 to 1;0.90998787;0.52776545;3.2747505;-5.169784;-2.4433973;4.0703998;-
the area of the touch;-2.4227273;-1.1651665;8.697513;-0.5770846;-2.2240276;0.7564781;-
the following three define the ellipsoid of a finger;-2.2716634;-0.49486652;3.2374227;-3.1047692;0.22335884;1.6465182;CODE
global uid;-3.8555114;-0.90660596;1.4897324;-0.103822395;2.870239;1.9958323;-
touches will be per devices;-1.5562723;-1.3989761;5.251167;0.200486;0.8880736;1.631927;-
lock needed to access on uid;-5.528931;0.36918834;0.31617457;-0.10033488;0.93795574;1.2271945;-
event queue to dispatch in main thread;-3.4755783;-1.1666602;3.7973883;3.0111442;0.91993374;3.7501216;CODE
ok listing devices and attach;-3.470121;-3.2494311;3.7159488;-0.9289152;2.1611493;0.2554687;-
create touch dict for this device;-3.742617;-2.6757882;2.6716383;-2.6010149;-0.8016401;-0.79599464;CODE
start;-2.99452;-0.47055933;5.379502;-0.17179027;-0.21995223;-2.8973765;-
dispatch all event from threads;-2.43683;-0.9063761;4.020668;3.684719;-0.056971636;3.1552534;CODE
i don t known how to stop it;-4.79778;0.9660634;3.0286758;1.4166049;-3.5938277;1.3082213;CODE
xxx create live touch we get one case that;-5.6402807;-0.46570066;4.510055;-0.34637725;1.8794477;1.019194;IRRE
the device announced by macosx don t match the device;-3.234563;-1.2868927;-2.7777553;-0.63055617;-1.7217023;0.8560503;CODE
in mts callback;-5.8982086;-0.23601529;3.297942;3.4096198;-0.9619666;2.2817118;IRRE
get pointer on data;-0.44064164;1.2846322;3.3987267;-0.96540487;0.46117315;-1.4053875;CODE
add this touch as an active touch;-4.5697603;-1.0481339;5.588155;0.8600109;-0.8294233;2.915359;TASK
extract identifier;-0.8174627;-0.2806543;-1.299473;-2.4255161;7.214335;-2.680285;-
prepare argument position;-2.85333;3.6007264;2.371055;1.6066049;1.2618693;-2.762987;-
increment uid;-2.6541712;2.6587157;1.5075767;-2.9840899;3.2723663;-2.6597524;-
create a touch;-4.4956975;-1.8199387;7.876339;0.1311726;-1.810478;0.19536164;IRRE
create event;-4.3152037;-1.4775242;6.8902197;1.9726564;1.2612807;-0.7003946;IRRE
store touch;-3.5863676;-0.8105566;6.5457067;0.9579002;-0.9754378;1.3580916;-
check if he really moved;-1.1183639;2.4543147;2.4647439;1.4177262;-2.8053358;-2.5245333;IRRE
delete old touchs;-4.5202637;0.9512114;3.3725815;0.33947557;-1.6927464;1.769962;CODE
late binding;-4.9451237;-0.10720669;1.5873692;3.3027117;-0.3361053;2.281941;-
don t overwrite previous profile;-2.4968727;1.4295264;1.7282001;0.47314656;-1.7461402;3.5673199;CODE
create automatically touch on the surface;-3.1821291;-2.307857;5.688512;0.1250937;-1.5652074;2.62011;IRRE
use same logic as windowbase on motion so we get correct;-3.8155699;0.83604956;2.1866338;0.60308546;-0.5368046;2.8771951;CODE
coordinates when density 1;0.5646191;1.6718152;2.0454772;-5.9325347;-2.928493;0.7600697;CODE
split arguments;-0.64692104;2.4272316;2.734676;-1.34173;3.9361951;-1.6885074;-
trying to get if we currently have other touch than us;-1.793164;1.3974369;4.855079;1.7821445;-0.020691749;-2.0447087;CODE
discard touches generated from kinetic;-1.729404;-1.1903017;2.5858886;-0.4585848;-3.5343137;4.287151;CODE
discard all kinetic touch;-2.5996764;0.038883608;2.9616044;1.4339782;-3.0116436;4.1620483;-
not our instance stop mouse;-4.7905836;-1.3119062;4.3932304;3.3324103;-3.9981043;2.2945237;-
args append modifiers always adds modifiers;-3.504451;1.1403499;-2.9093683;0.71708876;-0.026112389;0.97666353;CODE
only draw red circle if multitouch is not disabled and;-4.0692735;2.7251103;4.799201;0.081457764;-3.005112;2.6842258;-
if the multitouch on demand feature is not enable;-4.0361404;0.5066533;1.3863472;3.1276646;-2.072457;4.008994;TASK
because in that case we wait to see if multitouch sim;-4.0145864;0.5056932;2.7461426;3.4622233;-1.3287637;2.9321404;CODE
is true or not before doing the multitouch;-2.0623453;0.35845366;3.7138271;3.2324433;-0.7026039;2.2783427;CODE
divide by density because it s used by mouse pos;0.8274744;-0.5485259;3.0595844;-2.724093;-1.83694;1.1281558;-
alt just released;-3.6867802;-3.001423;3.2172997;0.5640354;-1.3938416;-0.17741174;-
special case if button is all;-3.8907256;4.507961;3.764095;1.0581318;2.8008244;-1.2544066;META
then remove all the current touches;-2.838885;1.6267254;6.586131;0.06507373;-1.1030396;1.7928234;-
registers;-2.3976533;-0.5143097;2.8855088;-2.309239;3.8414595;-2.258032;-
devicename hidinput dev input eventxx;-4.5496283;-2.4246814;-0.20252287;-0.530039;-0.80064493;0.7337798;CODE
example for inverting touch events;-2.9029973;-1.9892876;6.7828636;0.58941084;-1.1992743;1.8123953;CODE
documentation hack;-5.784853;-5.748391;1.17219;3.3991477;1.3460644;-2.565557;CODE
split arguments;-0.64692193;2.4272304;2.7346761;-1.341729;3.9361947;-1.6885074;-
read filename;-2.9260578;-1.0905703;2.381077;-0.9210469;-0.66118354;-2.057391;CODE
read parameters;-0.9376587;2.2086713;1.4106277;-0.84911424;0.5884662;-1.0168422;IRRE
ensure it s a key value;-3.457377;4.3591948;0.34560013;0.08099907;1.6350098;-2.2871752;IRRE
ensure the key exist;-4.0863953;3.5004098;0.32370764;1.029108;1.2273247;-2.5698817;-
ensure the value;-0.88929063;7.0405927;2.5181444;1.7340602;0.7034628;-5.812135;IRRE
all good;-4.552293;-1.5731685;2.056553;-0.5457817;-0.30199873;-0.087717906;-
this can happen if we have a touch going on already at;-3.0882685;1.860918;4.659847;4.472053;-2.7320058;1.5833834;CODE
the start of the app;-4.808608;-3.8701332;7.382636;2.752892;-0.93659526;0.4954233;-
except zerodivisionerror it s both in py2 and py3;-3.4957201;-0.30228677;-5.4717855;-2.0029292;-5.909738;-0.35918045;CODE
open mtdev device;-3.5570695;-2.8522494;1.1761096;-0.49798843;-2.4098504;0.73220557;CODE
if e errno 13 permission denied;-6.8034983;1.3690323;-1.5192422;-0.66647166;-3.368101;-3.5504994;-
prepare some vars to get limit of some component;0.8586149;3.8311408;1.2002217;0.7607797;1.6925194;0.16623871;CODE
if device have disconnected lets try to connect;-2.4864547;1.471647;3.5721896;0.79010975;-2.9524233;-2.7697875;CODE
input device is back online let s recreate device;-3.8387482;-0.25321776;3.1000483;-0.5928227;-2.64663;1.3761091;CODE
idle as much as we can;-1.7515032;-1.5800831;4.2130995;2.1577919;-1.8207006;-0.9134456;-
got data read all without redoing idle;-1.4957364;0.6526448;1.3602841;1.4298643;-2.9222481;0.66688;CODE
set the working slot;-4.9779644;0.7422421;4.834585;0.33615014;0.69394314;0.78150463;IRRE
fill the slot;-3.1826684;1.4716849;6.8523593;-1.8895637;1.6254227;-2.283288;-
unrecognized command ignore;-4.242212;4.882454;-3.9416087;3.3353777;-3.0506027;-0.9105307;CODE
push all changes;-3.6555543;-1.1850619;5.5416946;3.2587829;-1.148581;2.1578028;-
dispatch all event from threads;-2.43683;-0.9063761;4.020668;3.684719;-0.056971636;3.1552534;CODE
using mtdev;-2.2734308;-4.2616687;0.76113504;-0.23020002;-2.0203903;0.22005244;-
using hidinput;-3.3945875;-2.3458157;0.8869821;-0.04607412;-2.2918177;0.43567383;CODE
using mtdev with a match on name;-1.5639832;1.3537123;-0.81399685;0.800894;2.0727055;0.30882472;-
using hidinput with custom parameters to hidinput all on one line;-1.7651601;1.7243583;0.16574764;-0.2095727;-0.0035530583;2.1782649;CODE
you can also match your wacom touchscreen;-1.7480229;-1.0931083;3.8842385;-0.7106825;-1.8307685;2.876649;-
and your wacom pen;-2.4942946;-0.90124726;4.120087;-0.9669331;-1.9181323;-0.20981573;-
see linux input h;-3.7219822;-2.9574015;1.214434;-3.1760786;-0.8215082;-3.252143;CODE
hack to not return an instance of this provider;-3.5191276;3.3624804;-0.031877227;3.2749157;-0.43375418;1.6921566;CODE
ensure it s a key value;-3.457377;4.3591948;0.34560013;0.08099907;1.6350098;-2.2871752;IRRE
must ignore;-2.5881016;2.239917;1.1803735;3.6687071;-0.5603187;0.34214804;-
name tuio ip port;-4.400605;-0.92238873;2.338315;-2.8683214;-0.9443243;-0.84088624;-
you can also add a second tuio listener;-4.288237;-1.4867502;3.843468;1.1313868;0.6037532;2.9324164;TASK
config set input source2 tuio 0 0 0 0 3334;-2.3477633;1.5310302;-2.2816894;-4.4295363;-1.444984;0.15024795;IRRE
then do the usual things;-1.6409426;-0.12311977;4.096039;2.8591895;-0.07366126;0.32163963;CODE
create a class to handle the new tuio type path;-3.0883818;-1.1235209;-0.102916904;0.5343476;2.8342583;1.4861491;CODE
replace newpath with the pathname you want to handle;-4.3075523;0.99132687;0.8885258;0.6946926;-1.2371736;2.9734013;CODE
in this method implement unpacking for the received;-2.7254133;0.7539143;0.34304953;-0.31204784;4.5188375;0.4427886;CODE
arguments you basically translate from tuio args to kivy;-2.8157425;-2.7726247;1.0117985;1.0631716;-1.4789932;-0.5153533;IRRE
motionevent variables if all you receive are x and y;-1.5087528;1.7388965;3.397012;-2.6564293;-0.309203;-0.6941005;IRRE
values you can do it like this;2.9714963;1.8190393;6.711233;-3.8440914;2.5073266;-3.4463897;IRRE
register it with the tuio motionevent provider;-4.771779;-2.7170846;0.7718825;-0.42886168;0.07661433;3.556302;-
you obviously need to replace the path placeholders appropriately;-7.246565;1.1684648;-1.1407727;0.4566725;-2.4165857;1.9661931;IRRE
read the queue with event;-3.2893243;0.93364346;5.3922076;3.7101836;1.0388538;0.6116889;CODE
queue is empty we re done for now;-3.9367647;1.4524093;2.574795;1.0586964;-1.7118963;-0.14698966;CODE
verify commands;-3.9958684;3.1462572;-0.18743858;2.6600559;0.7834336;-6.2588844;CODE
move or create a new touch;-3.9632535;-1.3688614;6.654587;0.86073726;-2.3768346;3.6408877;IRRE
new touch;-3.8696826;-2.8999324;6.9116297;1.612744;-2.3768575;0.4031463;CODE
update a current touch;-4.864047;-0.21382521;5.584573;2.4331923;-1.5363572;1.9915699;CODE
alive event check for deleted touch;-3.877983;2.1169634;3.1742978;3.3952346;-1.6972623;1.299939;CODE
touch up;-3.5220068;-1.0706351;6.589954;1.186469;-1.7915671;-1.3167427;-
default argument for tuio touches;-4.868388;0.40522298;1.7098972;1.0984795;-1.0494301;2.3497963;CODE
fixme 3d shape are not supported;-4.714767;-1.0023623;-1.9125828;-2.3879972;-3.8911788;2.199787;-
registers;-2.3976533;-0.5143097;2.8855088;-2.309239;3.8414595;-2.258032;-
check availability of registertouchwindow;-4.7059355;0.16375451;0.6801385;3.504682;-0.9046113;2.5467012;CODE
documentation hack;-5.784853;-5.748391;1.17219;3.3991477;1.3460644;-2.565557;CODE
it s a touch or a pen;-4.4402723;-1.3571424;6.701064;0.16645475;-1.8275256;-0.96886826;-
inject our own wndproc to handle messages;-4.3876925;-0.88026613;-0.075020395;2.485384;-0.29517242;3.8919811;-
before window manager does;-6.1419215;-1.1627231;2.8496227;3.8878636;-0.40226355;4.205778;CODE
documentation hack;-5.784853;-5.748391;1.17219;3.3991477;1.3460644;-2.565557;CODE
get window handle and register to receive wm touch messages;-5.697179;0.027621308;3.5039155;1.5845503;-1.1107695;3.8355784;CODE
inject our own wndproc to handle messages;-4.3876925;-0.88026613;-0.075020395;2.485384;-0.29517242;3.8919811;-
before window manager does;-6.1419215;-1.1627231;2.8496227;3.8878636;-0.40226355;4.205778;CODE
adjust x y to window coordinates 0 0 to 1 0;-1.4840797;1.3243985;2.1456196;-6.6267676;-4.7217026;2.9330947;IRRE
actually dispatch input;-3.7057712;-1.8846383;3.8139384;2.5383048;0.93983024;-0.1449882;META
we inject this wndproc into our main window to process;-5.43839;-2.059511;2.3415804;1.2101147;-0.7766506;3.7956238;CODE
wm touch and mouse messages before the window manager does;-5.19808;0.3666344;3.1093335;2.7429152;-3.1039793;4.4417133;CODE
this on pushes wm touch messages onto our event stack;-6.451351;-1.7981448;4.746013;3.0930858;-2.392912;4.0479813;CODE
filter fake mouse events because touch and stylus;-1.7013677;1.2818356;2.9063888;2.7986388;-3.1945128;2.7567568;IRRE
also make mouse events;-4.0843267;-4.7289276;6.671605;0.11984393;-2.422561;2.0926304;-
its a touch or a pen;-4.332076;-1.3888917;6.7932305;0.1301609;-1.9027474;-0.9680624;-
internals;-4.0143366;-2.3030775;5.733412;1.019813;1.5179479;-1.3261786;CODE
manually set the current window;-4.6319556;0.66411763;4.5858307;2.4632049;-1.5681632;3.3777003;IRRE
generate a record filename;-1.2663418;0.31422767;1.4311813;-1.4423666;2.9352376;-1.0624844;-
elf record fd write recorder1 0 n;-3.3047855;-0.1908371;-0.65837675;-2.8342838;1.0406914;-3.0030227;TASK
needed for acting as an input provider;-2.976585;-2.6616752;2.3898737;0.83613753;2.7234805;1.5544494;CODE
if data 0 recorder1 0;0.5773011;6.3691363;1.1648402;-1.2951394;1.5831083;-4.824608;-
decompile data;2.8274195;-0.8658226;-0.306421;-2.8867908;0.8793814;0.64146876;CODE
width of the rect;-0.88691366;0.91955966;3.4827383;-3.0654588;-1.837188;-0.8266721;-
height of the rect;-1.5324149;1.208903;3.3310866;-2.0830173;-2.994857;-0.7184928;-
i press tab to list attributes of the app;-5.193693;-2.327049;3.0063393;0.7154183;-1.2723955;1.7463537;META
i root press tab to list attributes of the root widget;-4.4384646;-1.6644781;2.8143227;-0.48052782;-2.0694063;1.9322957;META
app is boring attach a new widget;-4.9284954;-2.3499854;4.0163383;1.165698;-3.990915;2.523556;CODE
the application is now blocked;-5.427237;0.39472207;1.6419979;0.5999735;-2.4247944;0.22160353;-
click on the screen several times;-5.7045884;-0.56807846;5.606583;1.295482;-1.6005584;0.5020011;CODE
the clicks will show up now;-4.863199;-1.9199537;3.9424741;1.6701297;-2.3555202;1.9574915;CODE
erase artwork and start over;-3.825545;2.1597362;3.7824714;0.06472097;0.8190025;2.4917717;-
mynewobject is unsafe;-4.4649963;-0.3737551;-0.48940682;2.1932466;0.6013794;0.11632623;CODE
mynewobject is now safe call at will;-4.5919104;0.26391694;0.4353814;3.355588;0.6014658;0.66483206;IRRE
everything from this point on is just a series of thread safing proxy;-3.4343822;-3.2896283;2.4211318;3.3416274;-0.5310952;3.3822217;CODE
methods that make calls against ref and threadsafe whenever data will be;0.074620426;1.4940751;2.7136176;6.4302607;0.12580621;1.2528533;IRRE
written to or if a method will be called safemembrane instances should;-3.697969;-0.8052532;-1.3282877;4.9636874;0.87214214;1.1165321;IRRE
be unwrapped whenever passing them into the thread;-3.0805423;-0.0888248;1.8016902;2.8800936;-0.40926415;3.4241643;CODE
use type to determine if an object is a safemembrane while debugging;-2.4944055;1.0203524;-3.4809077;1.8018502;-0.051730152;-1.6504356;CODE
proxy behavior starts after this is set before this point attaching;-5.1538534;1.7701815;1.1354971;3.231007;-2.2235014;4.9335465;CODE
widgets etc can only be done through the launcher s app attribute;-5.3352327;-1.4087353;1.0494423;0.49891418;-3.7356312;3.2233105;IRRE
act like the app instance even before ref is set;-4.5697727;2.4198647;2.6176946;6.3494563;-1.4313563;3.3183606;IRRE
kivy 1 0;-1.4029053;0.04636393;2.796707;-1.5439909;-2.6861467;-2.9736822;-
content here;-2.2265937;-2.4615002;3.9198475;-0.27614954;-0.12563094;-2.1487434;-
syntax of a rule definition note that several rules can share the same;-2.7479293;0.65854067;-0.13392413;0.6936758;5.9030037;0.52030265;IRRE
definition as in css note the braces they are part of the definition;-4.4308405;-1.4221463;2.1439564;-1.1388044;3.6321273;1.4215958;IRRE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
syntax for creating a root widget;-4.936015;-2.0021076;2.5170028;-1.8478346;0.6802005;2.0111406;CODE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
syntax for creating a dynamic class;-2.2270474;-1.0235909;1.8811203;0.88970876;7.065756;-0.017761901;CODE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
syntax for creating a template;-3.7599576;-1.0559442;2.626692;-1.9723388;4.808999;0.40315503;CODE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
with the braces it s a rule without them it s a root widget;-6.3248997;-1.5688345;2.4642296;-0.49005347;1.2795426;1.5129434;-
kivy 1 0;-1.4029053;0.04636393;2.796707;-1.5439909;-2.6861467;-2.9736822;-
or as an alternative syntax;-3.8926525;-1.0418811;1.1591965;1.5759317;4.6602793;-1.2196802;-
simple inheritance;-4.2289762;-0.48852867;3.1019251;0.64955676;4.290463;-0.5725806;-
kv code here;-2.7228487;-1.5521519;1.9171935;-1.8801106;0.9610808;-4.394236;-
multiple inheritance;-3.2748897;-0.025620969;2.4839303;0.14450508;6.324188;0.8653499;-
kv code here;-2.7228487;-1.5521519;1.9171935;-1.8801106;0.9610808;-4.394236;-
simple inheritance;-4.2289762;-0.48852867;3.1019251;0.64955676;4.290463;-0.5725806;-
multiple inheritance;-3.2748897;-0.025620969;2.4839303;0.14450508;6.324188;0.8653499;-
let s use the new classes in another rule;-2.5225105;0.20814826;0.36239487;2.433314;5.9578476;-0.24702355;CODE
a context to pass for the context will be ctx inside template;-5.626199;1.7884753;1.216538;1.4011537;2.4428732;5.293691;CODE
a kv definition of the template;-1.3121552;-2.7308314;0.52566606;-1.0673115;4.7248716;3.286462;IRRE
with only one base class;-0.80036485;-0.5589142;1.7725188;0.2671634;6.137411;-0.37587512;IRRE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
with more than one base class;-0.04393417;-1.3890635;1.7468241;0.30037755;7.483843;-0.90705526;IRRE
definitions;-1.2520639;-1.3017522;4.0329933;1.5874093;4.365552;-0.28933913;IRRE
create a template with hello world an image;-4.178651;-1.1015754;4.2215524;-2.2568693;-0.099314384;2.71593;IRRE
the context values should be passed as kwargs to the builder template;-4.2725706;0.27740267;-2.1485715;1.3925749;1.4705617;5.471431;IRRE
function;-1.2390599;1.4956939;6.532339;-1.7183864;-0.46752357;-4.8876433;CODE
create a second template with other information;-1.7614927;0.22511162;4.656472;-1.1846199;5.5449233;2.667122;IRRE
and use icon1 and icon2 as other widget;-2.8585727;-0.8859427;4.312587;-1.7778965;0.47164568;4.5540757;-
this is the same as before;-3.821049;0.26064536;3.8264658;1.0373065;1.1108036;1.3052293;CODE
now we are using the ctx for the variable part of the template;-4.251705;0.96621877;0.78659177;-1.3259953;2.994163;3.866249;CODE
you cannot use references other than root;-6.3420563;-1.1431775;-2.1658547;0.48965162;0.05329186;0.5967582;CODE
ctxkey mywidget value fail this references the id;-4.128438;3.2915366;-1.4091798;-1.7828541;-0.49612454;1.340568;CODE
mywidget;-2.9714742;-2.5214083;6.784916;-1.3335236;-2.2981021;0.43511245;-
not all of the dynamic parts will be understood;-0.5979448;-2.834478;2.672218;2.2191231;4.2900815;1.2221409;-
ctxkey value 1 if root prop1 else value2 even if;-2.9054036;5.333238;-0.77454233;-1.4077021;2.5414195;-1.580806;IRRE
root prop1 is a property if it changes value ctxkey;-5.381209;2.1763384;-1.4851812;0.57906306;0.94884795;2.0238087;IRRE
will not be updated;-6.05484;-3.2473776;1.4018795;2.0847778;-2.6703997;-1.1445618;CODE
directivename options;-5.872877;-0.15416107;1.6301476;-0.19493201;2.6948702;3.95373;-
import alias package;-3.733036;-2.5552692;-1.3949914;-1.1443143;0.4976364;0.19840805;CODE
import os os;-2.617769;-4.279651;-0.07481588;-1.5606052;-0.62168795;-1.1522626;CODE
import ut kivy utils;-3.2084215;-2.9751575;-0.36939347;-1.4831624;-1.9388144;-1.429838;CODE
import animation kivy animation animation;-3.332969;-3.6039858;0.72436684;-1.5342017;-3.7486358;2.3958182;CODE
set key expr;-5.229514;1.8042883;1.761694;-2.231266;0.9445853;-0.8576726;IRRE
set my color 4 3 4;-2.681135;0.5071856;4.135752;-3.4108887;1.6705331;-0.75000894;IRRE
set my color hl 5 4 5;-3.06772;0.4870122;2.9526265;-3.0463614;1.6077375;-0.16948563;IRRE
include force file;-5.103731;-1.7170733;-0.51670307;2.466978;-1.4069362;2.011205;CODE
test kv;-0.021401228;1.5209584;1.233633;2.198688;-0.5757498;-7.163669;IRRE
include mycomponent kv;-3.6856642;-0.8014084;-0.35416958;-0.8653168;2.4757254;2.3313766;CODE
include force mybutton kv;-4.610649;0.531745;1.7474078;1.2675456;-0.9020133;2.6065254;CODE
mycomponent kv;-3.2926273;-0.71205777;2.111862;-1.9957682;1.3984209;-0.7093888;-
include mybutton kv;-4.228697;-1.0817575;2.4233305;-0.3504598;0.920161;1.9497904;CODE
mybutton kv;-3.6471088;-0.8718727;4.5650024;-1.0786147;-0.2776736;-0.7951327;META
late import;-4.0945683;-3.581448;-0.5126651;1.3972255;-2.050858;-1.7724074;CODE
delayed calls are canvas expression triggered during an loop it is one;-3.9887145;3.4113965;3.0675943;1.5669519;-2.5727017;0.2840319;IRRE
directional linked list of args to call call fn with each element is a list;-2.3716147;1.5046848;1.0379797;-1.2312275;0.14319634;0.1348409;IRRE
whose last element points to the next list of args to execute when;-2.222881;3.3619;3.7936485;1.7405182;1.3625277;-1.6326624;CODE
builder sync is called;-4.5137153;-2.336204;2.4177506;2.632618;0.74651897;2.5213656;IRRE
it s already on the list;-4.000556;-4.044581;1.6387155;2.0530515;-0.07003494;0.1446646;CODE
first remove all the old bound functions from s and down;-0.09819409;1.9881155;-0.49872243;-2.8439264;-2.7694309;0.78730965;CODE
find the first attr from which we need to start rebinding;-3.357882;2.5800598;2.5331004;-1.5888901;2.3691044;2.64522;TASK
bind all attrs except last to update intermediates;-3.0551655;4.1952467;1.7956039;1.756452;2.8820875;2.2865994;CODE
if we need to dynamically rebind bindm otherwise just;-3.646196;1.3773261;1.6574893;2.6637702;3.013523;7.0053396;TASK
add the attr to the list;-3.3029044;-0.038110096;3.2995484;0.07233168;0.20251092;0.49123552;TASK
fbind should not dispatch otherwise;-6.040619;-0.33487484;-1.5039568;2.2939687;-0.9701155;1.02681;-
update intermediates might be called in the middle;-4.407668;0.83738214;1.8919249;2.675899;1.7305865;0.9503076;CODE
here messing things up;-3.8073952;-0.49571165;3.0564911;-0.071744174;-2.0926082;-1.1563836;-
for the last attr we bind directly to the setting function;-3.8351667;2.0351655;3.0961888;0.7130253;1.1488137;4.5235763;CODE
because that attr sets the value of the rule;-3.3206563;2.2990277;-0.62709683;-0.35467124;0.03206681;0.6184626;IRRE
when we rebind we have to update the;-7.4685183;-1.0723033;1.5129015;2.09461;0.36005867;3.617795;CODE
rule with the most recent value otherwise the value might be wrong;1.1449049;3.3646853;2.1167555;0.9725842;1.4033747;-2.847317;IRRE
and wouldn t be updated since we might not have tracked it before;-2.802682;-2.4221992;-0.40200567;3.1851134;-1.4327111;1.404651;CODE
this only happens for a callback when rebind was true for the prop;-6.383176;3.68691;0.10134833;3.9310427;-3.489724;3.7383685;CODE
we need a hash for when delayed so we don t execute duplicate canvas;-4.009697;3.8181415;2.9903486;2.5112307;-0.2541679;2.8930154;CODE
callbacks from the same handler during a sync op;-4.1213374;2.7657268;2.99245;4.3413367;-1.4039841;4.2623167;IRRE
args element key value rule idmap none see delayed start;-4.2666583;3.0825288;-0.69447535;-0.15195253;-0.21009298;2.3414693;IRRE
bind every key value;-1.7989694;2.517498;3.7497475;-1.9521841;3.576223;-0.103452966;IRRE
bind all attrs except last to update intermediates;-3.0551655;4.1952467;1.7956039;1.756452;2.8820875;2.2865994;CODE
if we need to dynamically rebind bindm otherwise;-3.6120842;1.8320413;1.6275855;2.7051525;2.8504016;6.9374423;TASK
just add the attr to the list;-3.9865844;-0.48993108;2.5773635;0.5464378;0.38704562;1.9415827;TASK
fbind should not dispatch otherwise;-6.040619;-0.33487484;-1.5039568;2.2939687;-0.9701155;1.02681;-
update intermediates might be called in the middle;-4.407668;0.83738214;1.8919249;2.675899;1.7305865;0.9503076;CODE
here messing things up;-3.8073952;-0.49571165;3.0564911;-0.071744174;-2.0926082;-1.1563836;-
for the last attr we bind directly to the setting;-5.218315;0.59419626;2.8539019;1.5286943;2.023973;5.322434;IRRE
function because that attr sets the value of the rule;-2.505872;2.0502667;2.1459897;-0.4425375;-0.17623034;-1.0172449;IRRE
uid f fbind keys 1 fn args f is not none;-4.928692;1.5400219;-2.7607865;-3.978777;0.3441371;-2.885705;IRRE
remove rules and templates;-3.1307158;-0.07864796;1.1805036;1.120448;2.5534794;1.2042581;-
unregister all the dynamic classes;-2.6271923;-0.5947576;-1.4283619;2.0211968;3.427918;3.5530815;IRRE
put a warning if a file is loaded multiple times;-2.9199107;3.2117867;1.3301665;6.168548;0.15574186;1.5259737;CODE
parse the string;-1.5890136;1.5856278;3.5679133;-1.1430253;0.5609771;-4.87791;IRRE
merge rules with our rules;-1.5781562;0.33478358;3.4332876;1.4366226;5.644459;-0.5511766;-
add the template found by the parser into ours;-4.5906925;-0.33185288;-0.36963406;0.29020828;2.2246344;2.1952248;TASK
register all the dynamic classes;-1.0073261;-0.6717858;0.4826181;1.4199895;6.416833;1.6936663;IRRE
create root object is exist;-6.1832466;1.4844365;-0.95541555;-0.025542613;1.2430565;-0.9459115;IRRE
save the loaded files only if there is a root without;-3.5862691;2.3380706;1.6504573;3.2302547;-1.510509;2.3662784;CODE
template dynamic classes;-0.9576106;-1.2308278;2.285394;0.5480703;5.8493795;2.3881643;IRRE
prevent naming clash with whatever the user might be putting into the;-4.526768;1.0180877;-0.48213875;2.7347426;3.7928474;0.16978912;CODE
ctx as key;-4.660812;-0.7048222;1.4414343;-2.9080317;2.4699774;1.2673048;-
in previous versions ctx is passed as is as template ctx;-7.283038;1.5312451;-3.4537308;0.4067669;1.101475;3.8409905;META
preventing widgets in it from be collected by the gc this was;-3.46334;-0.29802266;0.5325286;2.9647136;-1.6661115;3.8716516;CODE
especially relevant to accordionitem s title template;-3.139786;-3.5330245;1.5444646;1.2759126;2.683124;2.8356817;CODE
widget the current instantiated widget;-4.469718;-0.32596883;3.516953;1.1675133;-1.678128;4.283527;-
rule the current rule;-3.1632307;0.82818013;3.716039;2.1017346;2.0821826;-2.1276133;CODE
rootrule the current root rule for children of a rule;-3.8272445;0.8954803;1.4003392;0.5266385;2.8174725;0.5058646;CODE
will collect reference to all the id in children;-1.79552;0.44692037;2.6062248;0.7707496;5.8348093;-0.75173897;CODE
extract the context of the rootrule not rule;-3.4743156;3.2048461;-1.2161834;-0.2061033;1.9745488;1.3159288;-
if a template context is passed put it as ctx;-5.356658;3.4064825;0.37366363;2.4481373;2.845665;3.8576493;-
if we got an id put it in the root rule for a later global usage;-5.373146;-0.07183363;-0.34277868;1.7477838;4.7445407;2.7892904;CODE
use only the first word as id discard the rest;-3.3161385;2.991267;1.6497446;-0.43228626;4.5867376;-0.460881;-
rule id rule id split 1 0 strip;-2.3402581;2.9185555;0.3427413;-3.854055;4.3487964;-1.3482373;-
set id name as a attribute for root widget so one can in python;-3.7263317;-1.2344928;-0.7760214;-1.4243464;-0.0608201;2.0917718;CODE
code simply access root widget id name;-5.629646;-0.26131317;0.9930854;-1.3121616;-0.6680934;1.5036482;-
skip on self;-3.4631727;1.9869554;3.008407;3.1233907;-1.151355;-0.74547875;CODE
first ensure that the widget have all the properties used in;-4.32987;1.5320082;1.0969735;1.228254;-3.288552;4.18317;-
the rule if not they will be created as objectproperty;-3.1139784;-0.5554299;-2.4632626;3.6524522;5.1336384;2.880026;IRRE
build the widget canvas;-3.420217;-2.614247;5.746787;-2.6032386;-3.7776344;2.5675917;-
create children tree;-1.5645546;-1.7116804;4.1556177;-1.6539763;3.9036908;-0.7699945;IRRE
depending if the child rule is a template or not we are not;-3.2653716;0.0379703;0.5607904;2.2391183;4.304269;2.5983534;TASK
having the same approach;-1.0782129;0.46867952;5.634808;3.5603664;1.9272583;0.045482382;-
we got a template so extract all the properties and;-2.5128872;-2.176194;2.2789035;-0.7290455;3.6813433;1.0987866;-
handlers and push them in a ctx dictionary;-4.216584;-0.6017604;1.1223774;1.5190164;1.4216974;2.9227338;-
create the template with an explicit ctx;-3.6864736;0.46072897;0.62081724;-2.396719;2.7128115;4.197539;IRRE
reference it on our root rule context;-5.1158004;-1.2334889;0.6986798;2.073165;3.1463292;0.81132686;CODE
we got a normal rule construct it manually;-1.7819053;1.4715264;-1.4259136;-0.49825123;2.5400002;1.0575733;CODE
we can t construct it without no builder true because the;-4.708928;0.24269968;0.2505763;1.7565413;2.7217546;0.7458432;CODE
previous implementation was doing the add widget before;-5.906463;0.16443215;0.25123477;1.9263685;-2.676548;3.763753;TASK
apply and so we could use self parent;-4.0955186;-1.578397;3.082798;2.2612336;3.840925;1.3335599;CODE
append the properties and handlers to our final resolution task;-4.394146;0.28299072;3.3622336;3.224632;1.1163175;5.892209;CODE
clear previously applied rules if asked;-3.0398524;3.3607256;0.5123161;4.530601;2.387019;1.0552396;-
if we are applying another rule that the root one then it s done for;-5.163912;1.5494418;0.12946957;2.8041902;1.9895234;0.92465633;CODE
normally we can apply a list of properties with a proper context;-1.3199959;-1.7381116;0.70792866;3.8158152;5.9777;2.6420016;-
if there s a rule;-2.9409804;1.888706;3.7753842;2.454211;2.4907792;-3.072278;-
build handlers;-6.8871493;-3.4863703;1.5613714;4.976792;0.16619273;2.4420047;-
hack for on parent;-5.317751;-0.10236668;3.1357973;1.5403258;0.14036418;-0.009865314;CODE
rule finished forget it;-4.1210327;1.296056;2.7594297;2.9941792;0.5288934;-1.2666893;TASK
is this try except still needed yes in case widget died in this;-5.561352;3.1265996;0.9517564;3.677577;-1.8144251;2.0325298;CODE
frame after the call was scheduled;-4.2853365;1.9344978;4.4060116;2.2108765;-2.0497272;1.4684215;IRRE
if fn is none it s not a kivy prop;-2.665835;-1.2232211;1.5300322;0.237549;-1.7485938;0.036208168;-
proxy widget is already gone that s cool;-5.733323;-1.8778721;3.4073613;0.6597716;-3.7487586;3.6187437;CODE
if fn is none it s not a kivy prop;-2.665835;-1.2232211;1.5300322;0.237549;-1.7485938;0.036208168;-
proxy widget is already gone that s cool;-5.733323;-1.8778721;3.4073613;0.6597716;-3.7487586;3.6187437;CODE
main instance of a class builderbase;-2.311947;-2.2579482;0.69159216;1.9143434;3.9997122;2.0866163;CODE
import kivy lang builder imported as absolute to avoid circular import;-2.466077;-0.10578679;-0.6578245;0.25905687;-2.0099864;3.0258422;CODE
register cache for creating new classtype template;-2.1804872;-0.9062222;-1.9854631;1.5422232;2.5659935;3.7418866;CODE
all previously included files;-2.597265;-1.3394418;1.5263896;1.9988978;0.30306038;1.6491286;CODE
precompile regexp expression;-2.2829359;0.038397532;-1.7547104;0.21889946;2.2695816;-0.71061385;CODE
all the widget handlers used to correctly unbind all the callbacks then the;-5.7107544;1.2841066;0.92773277;2.7120934;-4.7808294;4.928932;IRRE
widget is deleted;-5.6271763;0.06861962;2.402954;-0.6244605;-4.1404185;2.2217236;CODE
proxy app object;-4.400489;-1.484608;3.500641;1.8304168;0.25202498;2.7877698;IRRE
taken from http code activestate com recipes 496741 object proxying;-4.0565586;-1.1916876;-1.7146226;1.2359072;1.7276797;2.5943222;CODE
clear cached application instance when it stops;-3.3548794;2.6136434;2.2211976;3.95848;-1.6692413;3.196549;-
associated parser;-0.9233292;-2.6442266;-0.034206904;0.8874368;5.349011;0.11290412;IRRE
line of the rule;-3.320486;1.6049159;4.2481413;-1.2150065;1.5323366;-1.8005301;-
name of the property;-3.337033;0.43658867;3.4721944;-0.09856385;4.53084;0.5754395;-
value of the property;-2.513716;3.9764974;3.6280205;-0.3700611;2.1674387;-3.2030408;IRRE
compiled value;-2.1768901;0.9445352;-3.038745;0.48221692;2.442321;-3.1764212;IRRE
compilation mode;-4.0926366;-2.4919848;0.57633585;1.3554671;1.2461323;-0.88801265;-
watched keys;-1.1940347;-2.497199;3.67297;0.41032144;-0.7007702;-2.5386305;-
stats;1.5693202;-1.5354623;5.494952;1.5312687;-0.5664825;-5.8879886;-
whether previous rules targeting name should be cleared;-3.526028;1.9244757;-1.4822841;4.522295;2.1472385;1.4596456;-
first remove all the string from the value;-1.7236046;5.1728306;2.559581;-0.864978;0.1481153;-3.546134;CODE
detecting how to handle the value according to the key name;-0.7117367;4.4370017;1.1177154;0.6528274;4.226046;-3.5886445;IRRE
if we don t detect any string key in it we can eval and give the;-4.4163737;1.4500583;-1.1286787;1.4067143;1.7304007;-2.6361501;CODE
result;-2.7007558;0.35232732;5.4700537;1.0012369;-0.33399722;-6.441594;IRRE
ok we can compile;-4.64783;-2.8675363;0.73202056;0.6720473;0.6937093;-4.5773087;CODE
for exec mode we don t need to watch any keys;-5.6028776;-1.1631684;0.028967554;1.7540306;-1.1256831;2.1173701;CODE
now detect obj prop;-2.538216;-0.89961857;-0.3356596;2.587172;0.92980474;0.13485698;-
find all the fstrings in the value;0.8455475;2.0976887;3.1203866;-2.4119508;-0.08258339;-5.927977;CODE
first remove all the string from the value;-1.7236046;5.1728306;2.559581;-0.864978;0.1481153;-3.546134;CODE
idx tmp find;-2.3087265;-0.5152929;-1.4895464;-2.9538178;0.2331312;-1.0213466;-
detect key value inside value and split them;2.808943;4.1816435;2.2415407;-2.2982302;4.229253;-3.7797086;IRRE
build full dotted attribute path e g root object property;-3.3626385;-1.9845665;1.6706752;-0.21744877;1.9988174;3.563068;CODE
level of the rule in the kv;-1.1062008;-0.09559771;1.546944;-1.0248047;2.5901966;-1.125544;CODE
associated parser;-0.9233292;-2.6442266;-0.034206904;0.8874368;5.349011;0.11290412;IRRE
line of the rule;-3.320486;1.6049159;4.2481413;-1.2150065;1.5323366;-1.8005301;-
name of the rule;-2.330768;0.5501325;3.2325785;0.92727035;3.9494598;-0.37563637;-
list of children to create;-1.8041072;-1.1229511;4.665243;-1.4929277;4.4973106;-2.474754;IRRE
id given to the rule;-3.1364846;2.0147998;1.5919298;-1.5282041;5.572232;-3.405756;-
properties associated to the rule;-1.7400006;0.63497204;1.5493754;1.6108625;4.788522;0.9408368;-
canvas normal;-2.3212242;0.36995783;5.299898;-3.2609324;-2.9473927;2.095801;-
canvas before;-4.606158;-0.022854304;6.5743895;-0.051194545;-3.0301836;1.7862389;CODE
canvas after;-4.8270683;0.33574468;7.645732;-0.546909;-2.955742;1.1304622;-
handlers associated to the rule;-5.1237965;-0.14230128;1.431027;3.4705548;2.584812;2.9754646;-
properties cache list mark which class have already been checked;-2.5484328;2.1168723;-0.5884251;4.113065;3.1322608;1.7990223;CODE
indicate if any previous rules should be avoided;-1.7236372;2.887359;0.7378569;6.465791;2.913211;0.17848502;CODE
check first if the widget class already been processed by this rule;-2.533114;3.6054041;-0.13815811;4.1788564;1.4267493;0.72379375;CODE
if the very first name start with a avoid previous rules;-2.581011;2.1613286;1.4132453;2.667027;3.7172558;-0.34697923;CODE
new class creation;-2.7713492;-3.3201501;1.955267;0.73747593;5.520514;-1.0549332;CODE
ensure the name is correctly written;-4.2698355;0.82221895;-1.2683163;1.8646202;1.7394257;-2.428398;-
save the name in the dynamic classes dict;-1.6880287;-1.763337;-0.5193742;0.99026924;2.8904805;-0.3243621;CODE
classical selectors;-1.5151706;-2.2907062;3.024751;1.7047794;5.7530937;0.69271505;CODE
if include force path with quotes around;-4.419409;2.8256004;-0.93117577;2.8619547;-0.33698353;-0.7260696;CODE
resolve the whole thing;-3.8049662;0.6232743;4.179889;1.8724562;-0.25053796;-0.08319259;CODE
read and parse the lines of the file;-0.16508481;-0.26896;2.5880382;-2.7008476;-1.2847279;-2.0998697;IRRE
strip all comments;-2.4316614;1.1395376;3.5515559;0.5687179;-1.1812345;0.5748405;-
execute directives;-6.290596;0.97043914;2.0543258;1.6041744;1.7305694;2.0471005;CODE
get object from the first level;-1.9131174;2.2890146;4.0698404;1.1870604;2.2248588;0.9775041;CODE
precompile rules tree;-2.6053941;-2.535004;-1.5507246;2.1318998;4.079246;-1.3344768;CODE
after parsing there should be no remaining lines;-3.382557;4.167297;-0.63825476;-1.6815828;-1.5659602;-2.1912751;CODE
or there s an error we did not catch earlier;-4.5624495;3.3270054;-1.4105653;5.203896;-2.7776802;-1.4413551;CODE
i e a comment line s first non whitespace character must be a;-5.56012;0.5336376;-0.3049448;-0.88981426;-1.2828368;-1.7915646;TASK
extract directives;-3.0383852;-1.1227933;0.97677475;0.3603448;3.5495508;1.8605548;-
if stripped 2;-2.4332292;3.4969354;2.8644474;0.3317614;2.1020858;-3.6723769;-
if stripped 1;-1.8899512;4.7522745;2.5380113;0.37806565;1.6142073;-4.4718413;-
get the number of space;0.0805766;2.2099278;3.5006032;-4.4391017;0.8363315;-4.8363004;-
replace any tab with 4 spaces;-2.8793635;1.1677573;3.064639;-2.566918;-0.027271029;0.5487183;-
first indent designates the indentation;-5.04019;0.60049075;0.47691774;-1.1428558;1.9697664;-1.1955407;IRRE
level finished;-3.5124505;-0.90240186;5.285983;0.03630406;0.4425361;-2.9761562;TASK
current level create an object;-2.3592951;0.36298725;3.851095;-0.12500718;3.715256;0.36299145;IRRE
not x 1 lstrip startswith;-2.8738155;4.872771;1.0058148;-2.329761;-0.5767237;-0.54930115;-
if it s not a root rule then we got some restriction;-5.359548;1.031338;-1.8653244;1.1474698;1.4197121;1.77855;CODE
aka a valid name without point or everything else;-2.7932692;-0.9021987;0.1425367;0.29298687;2.835167;-0.5954137;CODE
next level is it a property or an object;-3.405739;-1.5684468;3.3479037;1.6478856;4.488192;-0.69023424;IRRE
it s a class add to the current object as a children;-5.9973035;-3.136163;3.6371596;1.0792462;4.0772967;-0.8089927;IRRE
it s a property;-3.9710286;-0.7488826;3.1684742;1.6165739;3.2458327;-0.17195697;-
if ignore prev it wasn t consumed;-4.123603;5.969237;1.2382418;5.3302865;0.022196058;2.6086245;-
two more levels;-1.6051161;-1.1120958;5.0639477;-1.1367227;2.904154;-2.903016;-
too much indentation invalid;-4.296212;2.2262688;-1.4223889;-1.469092;-0.062023636;-3.010198;OUTD
check the next line;-3.513747;3.7806323;4.3104534;-0.64135796;-1.4039831;-6.6319547;-
ruff noqa;-2.4534037;1.1729168;2.287785;-1.8612963;0.97860295;-0.51314807;-
ddsurfacedesc2 dwflags;-2.914503;-3.3598847;-3.8490288;-2.6142612;-0.51018876;1.8092571;-
ddpixelformat dwflags;-4.118436;-0.44700515;-3.4024627;-3.420698;0.88521355;3.962533;CODE
ddscaps2 dwcaps1;-4.031662;-1.9219534;-1.2559874;-1.5087236;-0.83689696;0.84867656;-
ddscaps2 dwcaps2;-3.8165796;-2.6630828;-1.144489;-1.2992195;-0.9514178;1.248575;-
common fourcc codes;-1.6244347;-0.85747993;-1.1464047;-3.8621943;3.8394825;-2.136015;-
read header;-5.4292293;-0.72891873;2.3971968;-0.2597516;-0.16914818;-1.0831287;CODE
depack;-2.9077232;-2.0155518;2.0571373;-1.6801977;0.9533841;-2.5660112;-
check header validity;-3.2025847;5.352629;-2.0512326;3.06435;1.2138568;-2.8303404;CODE
first image set defaults;-2.538319;1.914468;3.09247;-0.7460304;-0.7789813;5.677657;IRRE
ruff noqa;-2.4534037;1.1729168;2.287785;-1.8612963;0.97860295;-0.51314807;-
load library;-4.5472617;-4.3440924;1.1697814;0.8496394;-0.24855205;1.4707983;CODE
from linux input h;-3.0541685;-2.3245144;1.6152418;-4.561609;0.12841924;-3.397009;CODE
mtdev code slot 0x2f mt slot being modified;-3.8011272;0.8107219;-3.2164493;-2.1679938;-0.4675017;1.7030183;-
mtdev code touch major 0x30 major axis of touching ellipse;-2.4149435;-0.77294;-0.1772953;-5.1434293;-5.7074413;1.1938484;-
mtdev code touch minor 0x31 minor axis omit if circular;-2.955342;3.543827;-0.120068334;-4.00438;-4.691107;1.8595637;-
mtdev code width major 0x32 major axis of approaching ellipse;-1.2298;-0.33355248;-1.4935633;-5.7326384;-5.3689547;2.0767102;-
mtdev code width minor 0x33 minor axis omit if circular;-1.734338;3.3325837;-1.9043578;-5.206904;-3.5843759;2.3080564;-
mtdev code orientation 0x34 ellipse orientation;-3.1701975;-0.8097408;-2.308466;-5.040775;-3.290506;1.8893781;-
mtdev code position x 0x35 center x ellipse position;-2.1584864;0.03544895;-0.88877434;-5.588384;-3.9171083;2.0157843;-
mtdev code position y 0x36 center y ellipse position;-2.7417648;0.11758176;-0.004593706;-5.6055236;-4.8763533;0.9732794;-
mtdev code tool type 0x37 type of touching device;-4.3762984;-1.0885415;-0.8620831;-2.0040627;-1.5649054;-0.03199871;-
mtdev code blob id 0x38 group a set of packets as a blob;-1.491337;0.1477151;-2.6371272;-4.006987;0.903863;1.1683342;IRRE
mtdev code tracking id 0x39 unique id of initiated contact;-2.0923932;1.6705492;-2.7825787;-1.2929039;2.4957802;0.97513294;IRRE
mtdev code pressure 0x3a pressure on contact area;-1.9236666;1.5076399;-2.3305702;-3.2854123;-2.3797102;1.1271088;-
mtdev code btn tool quadtap 0x14f four fingers on trackpad;-3.116079;-1.5496057;-0.5785412;-4.2898245;-2.3754635;1.4380875;-
binding;-3.552392;-1.4257219;5.520849;0.39355475;2.0376344;0.91177785;-
linux kernel creates input devices then hands permission changes;-3.4410038;-0.7538424;-0.46091962;-0.38393396;-2.4897444;1.1443323;IRRE
off to udev this results in a period of time when the device is;-0.8010063;0.32244995;1.027587;2.040544;-0.74298877;2.176576;CODE
readable only by root device reconnects can be processed by;-2.977834;-0.97567594;0.72211665;2.2415493;0.48402017;3.740787;CODE
mtdmotioneventprovider faster than udev can get a chance to run;-0.6097947;-0.09967675;-1.5300492;2.2918365;-0.44765815;4.084035;CODE
so we spin for a period of time to allow udev to fix permissions;-4.0997214;-2.830758;0.8534953;1.7323717;0.8741986;2.425456;CODE
we limit the loop time in case the system is misconfigured and;-0.2842178;2.5127745;0.23152633;3.0857506;-1.0787642;1.330226;IRRE
the user really does not and will not have permission to access;-6.1036386;1.4918324;0.60038084;-0.14708042;-3.6181872;-2.6226413;CODE
the device;-2.4395587;-4.466502;6.7301626;1.5865638;0.24877506;-1.4501411;-
note udev takes about 0 6 s on a raspberry pi 4;-1.2099013;0.6401967;-1.6749064;-1.5282861;-2.7636325;0.25142643;TASK
register a cache for loader;-3.007252;-0.13196541;0.95810777;2.7023928;0.81343263;4.875444;CODE
you can either add ext at the end of the url or use this array;-4.0789638;0.88485307;1.9327393;-0.7567022;-2.7752512;2.7004442;CODE
if blank filename then return;-3.528464;5.4622254;0.66166884;1.724995;-0.85757905;-3.6742845;IRRE
with recent changes to coreimage we must keep data otherwise;-0.08848177;-1.397269;1.835971;2.687044;-2.3465776;6.7219534;-
we might be unable to recreate the texture afterwise;-3.0925565;-0.5947373;1.6940867;-1.8278039;-2.9044192;2.8301516;IRRE
note it s important to load smbhandler every time;-2.5337186;-3.1637805;0.43780655;3.1801488;-1.7531127;2.297074;CODE
otherwise the data is occasionally not loaded;-1.8833913;2.7734964;1.7487348;3.806981;-2.2043624;1.8623663;IRRE
read from samba shares;-1.7854835;-1.541672;1.9342932;-0.35509977;-0.556297;-0.14420454;CODE
read from internet;-2.2055447;-4.0017276;4.8181014;0.5685093;-0.8369476;-1.7974203;CODE
a custom context is only needed on android and ios;-5.4883137;-2.600223;0.7731734;1.8321902;-0.18364367;6.1348786;CODE
as we need to use the certs provided via certifi;-2.3454907;-2.4529655;-1.7248436;1.2003787;3.031109;1.3254365;TASK
if in filename;-2.8471828;3.6304562;1.6656034;0.80974627;0.68085474;-4.7282076;-
allow extension override from url fragment;-5.25494;2.0516667;0.54130566;2.744207;-0.5222076;5.7384934;CODE
uffix filename split 1;-2.9473083;0.48021796;-1.0159949;-2.4171495;1.6671513;0.8145273;-
strip query string and split on path;-2.465527;1.8623236;1.9911418;0.268507;1.3331329;0.6599136;CODE
strip out blanks from;-1.172179;2.483845;1.8567829;-2.866027;0.9175765;-1.7404321;CODE
we don t want com net etc as the extension;-5.832155;-1.2994013;0.16148478;0.71369493;1.1438729;3.793418;CODE
write to local filename;-3.9275804;-0.88517696;1.8025768;-0.30618048;-2.515827;0.6332796;TASK
load data;0.93180233;-0.1247594;5.3618517;-0.54225874;0.7679921;0.048613176;TASK
fixme create a clean api for that;-5.7104893;-1.190789;-0.49623287;4.147342;-0.1028113;3.4551263;CODE
close file when remote file not found or download error;-4.6195984;1.0656294;0.7014406;2.514579;-3.409131;1.049676;CODE
update client;-4.7167253;-1.8901496;2.5220659;0.9552793;-1.1983695;0.639933;CODE
got one client to update;-4.327327;-2.1550558;1.8329493;0.7657523;-1.9323874;-0.5218572;CODE
want to start it;-2.722768;-2.5686102;5.8917537;1.2317185;0.03493998;-3.1753917;-
in pause mode don t unqueue anything;-5.9090757;3.8429782;1.4433984;2.1839142;-2.3210654;3.0320373;CODE
create the image;-3.6199143;-2.14904;7.564773;-3.0441828;-0.8873778;0.40822962;IRRE
image data proxyimage data;0.3154683;-1.5657471;3.1871595;-1.3734325;0.2221125;4.2168603;-
update client;-4.7167253;-1.8901496;2.5220659;0.9552793;-1.1983695;0.639933;CODE
got one client to update;-4.327327;-2.1550558;1.8329493;0.7657523;-1.9323874;-0.5218572;CODE
found image if data is not here need to reload;-2.199451;3.3029025;3.3019555;0.80491114;-3.4639974;0.1258119;TASK
if data is none this is really the first time;1.1379583;2.0427315;1.2336596;0.9711048;-0.31963795;-3.017499;CODE
already queued for loading;-4.9328623;1.348261;2.1302376;3.5639682;-0.5124507;1.9916713;CODE
loader implementation;-1.4754117;-1.549207;1.9944847;0.87713957;1.8086724;3.1908236;TASK
get path to log directory;-3.2200086;-0.2982781;2.2579894;0.40252078;-2.4825556;1.2023722;-
if maxfiles 0 no log file limit set;-0.24868558;3.4686353;-0.4785967;1.797721;-1.670096;-0.0029049367;IRRE
get all files from log directory and corresponding creation timestamps;0.1401569;-0.6920278;1.7039207;1.0801556;-0.9173184;0.61801225;CODE
sort files by ascending timestamp;1.2060164;-0.018101385;2.2548676;-1.4214357;-0.62681353;0.7784196;CODE
more log files than allowed maximum;-1.0945388;1.1563509;0.43461326;1.0639125;-0.65704066;-0.19628984;-
delete files starting with oldest creation timestamp;-1.7583481;1.20501;0.6498082;0.026987333;-0.4987298;0.95180774;CODE
or edit timestamp on linux;-3.099762;-4.038295;1.9336756;0.23814791;-1.5367875;0.829456;-
if n 10000 prevent maybe flooding;0.030942319;0.94248813;1.7579962;1.9206451;-0.22773065;-1.6242722;-
during the startup store the message in the history;-6.330153;0.20291252;2.5021327;2.0611973;-1.1984255;1.8729444;CODE
startup done if the logfile is not activated avoid history;-3.3919902;2.4249513;1.7820202;5.063842;-2.5363138;3.5956457;CODE
deactivate filehandler;-6.5215845;1.5244437;0.8560239;3.1716995;-2.6447446;3.8144112;-
this message was scraped from stderr;-4.801136;-1.367168;-1.7632059;0.5870896;-1.8501809;-0.9494268;CODE
emit it without formatting;-3.7418375;-0.70515686;1.851462;-1.1826643;-0.8637973;1.0453043;CODE
don t pass it to the formatted emitter;-3.2685199;1.3800278;-2.8927665;-0.8783133;-3.0532272;0.38680792;CODE
included for backward compatibility only;-5.6271105;-3.1821764;-1.2137908;0.95564383;1.7118645;1.9133365;CODE
could be used to override colors;-1.8231139;-2.3452044;4.66474;0.7889896;2.4851515;2.147439;OUTD
kivy default logger instance;-3.1565275;-2.1169913;0.17776251;2.1235867;-2.7766564;3.0703235;CODE
versionchanged 2 2 0;-5.1187563;0.29014483;-0.045275398;0.2632706;-1.1978061;0.5873639;META
issue 7891 describes an undocumented feature that was since removed;-6.5316133;-2.3665237;-3.7996998;2.4630017;1.115101;1.1539727;TASK
detect if a client was depending on it;-0.8777761;3.124513;1.5710646;3.7508001;2.008091;-1.1276453;CODE
versionchanged 2 2 0;-5.1187563;0.29014483;-0.045275398;0.2632706;-1.1978061;0.5873639;META
add default kivy logger;-3.840597;-2.0312426;0.35913146;1.3545514;-2.8776903;3.3267632;TASK
use the custom handler instead of streaming one;-5.0761642;0.28651047;2.6685169;3.5073347;-0.740116;6.0539317;IRRE
don t output to stderr if it is set to none;-2.375181;5.4601855;-0.47503763;0.89402485;-1.8604159;-1.1332134;IRRE
stderr is set to none by pythonw and pyinstaller 5 7;-4.4888053;-0.66094756;-4.746775;-0.84188247;-5.1304836;-0.27294305;CODE
no additional control characters will be inserted inside the;-8.05304;1.1527271;-0.57510376;-0.30182868;0.3289415;0.8743463;CODE
levelname field 7 chars will fit warning;-1.5597005;2.7111752;-2.0709295;-0.7183711;2.5157006;-0.8356497;CODE
levelname field width need to take into account the length of;-0.4009518;2.4392214;0.80583227;-3.3821654;1.4311817;1.0013843;TASK
the color control codes 7 4 chars for bold color and reset;-3.4648135;-0.92535347;-0.39893726;-2.8083663;1.8428552;-1.358883;IRRE
add the kivy handlers to the root logger so they will be used;-4.871624;-1.9098074;0.76010364;2.1726968;-3.9184227;3.4336457;TASK
for all propagated log messages;-1.7442598;-2.4043689;1.0088925;2.8964934;0.92353684;0.8377378;CODE
root logger defaults to warning let logger be the limiting factor;-3.4577856;1.6074917;-2.4849772;2.5601337;-2.7301333;1.5783345;CODE
install stderr handlers;-6.3667483;-2.3310504;-0.9486084;1.1114113;-1.8055022;2.7125242;CODE
caution if any logging handlers output to sys stderr they should be;-4.0709276;-0.61567205;-2.6495998;1.9632951;-2.7149308;0.77771646;IRRE
configured before this reconfiguration is done to avoid loops;-2.1658494;3.2071798;-0.19057178;1.8649505;-1.1002707;3.2080286;CODE
sends all messages written to stderr to the logger after prefixing it;-3.9162872;1.2108244;0.58271015;2.4489343;-0.9738224;2.019885;CODE
with stderr;-2.5200999;-1.7173576;3.20866;0.8636113;-0.3171343;-1.2373217;CODE
add the kivy handlers to the kivy logger so they will be used;-4.6368017;-2.3074172;0.8590099;1.9364432;-2.9170306;3.6906085;TASK
for all messages sent through logger only;-2.531066;1.0782036;1.7299432;2.1883836;-0.45193318;1.5465146;CODE
don t spread kivy related log messages to the root logger;-2.840425;-1.0811193;0.583048;2.8247986;-3.267328;2.8108404;CODE
don t set stderr redirection it is too likely to cause loops with other;-3.1306565;4.157102;0.45767963;1.4275736;-1.6060867;-1.299782;IRRE
handlers client can manually add it if desired;-6.656423;1.3340406;1.1079181;4.348543;-0.17386177;5.2752957;TASK
else kivy log mode python;-3.0076592;-1.0459208;-0.42131156;0.16763079;-4.050456;-1.3628608;CODE
don t add handlers or redirect stderr client can manually add if desired;-6.408371;3.219425;-1.0267636;4.890726;-1.7127883;3.5844965;CODE
kivy 1 5 0;-1.264042;0.12694629;2.6883967;-2.086038;-2.4856734;-3.4026506;-
for all other platforms;-2.9492452;-7.251535;2.484339;-0.22879966;-1.3453716;-0.24801324;CODE
because dp prop binds to dpi etc its getter will be executed;-5.454523;1.5281814;-1.4789206;1.3165681;-1.3996124;4.3664565;CODE
before dispatch pixel scale bound to dpi was called so we need to;-2.3820064;0.18324034;-1.6970602;-1.2199799;-3.4883795;6.7992373;TASK
call this to make sure it s updated;-6.414771;0.40856826;1.541454;3.3447685;-2.6178255;0.49596632;CODE
we bind to all dpi density fontscale even though not all may be;-0.8318156;0.0970485;-1.0047324;-1.4501365;-1.0823048;5.5664735;-
used for a specific suffix because we don t want to rely on the;-4.7753525;-0.9208065;-0.43191785;2.0085688;2.1187954;0.75031054;CODE
internal details of dpi2px but it will be one of the three but it s;-3.6993089;-0.7689011;1.6649675;-3.7676399;2.3252246;1.9866672;META
an issue since it won t trigger the prop if the value doesn t change;-3.3635533;4.5022826;-0.032480903;3.857331;-0.8928066;0.673509;IRRE
uncomment to activate;-6.665935;0.7339944;1.6403481;1.4851358;0.42268282;2.0472655;-
monitor;-1.8121159;-0.9205271;6.4886174;-0.9981043;-2.1140182;-1.0924413;-
keybinding;-3.6082346;-2.1804984;3.8682883;-0.7795655;3.0923262;2.544024;-
activate the touchring module;-6.4896097;-0.16664447;3.513275;0.86244094;-2.2522292;1.7071136;CODE
accept only python extensions;-3.992533;-1.2951782;-2.7441874;0.8213665;-2.1094258;0.60876787;CODE
protect against missing module dependency crash;-4.0915256;-0.18801223;-3.3144863;2.8998303;-0.9480368;1.7850722;CODE
basic check on module;-4.2501526;3.4724371;0.0010359077;1.8011048;0.86947817;-4.6727204;CODE
ensure the module has been configured;-4.6231422;2.8932812;-0.90591127;3.2357032;-1.9200017;1.6800665;CODE
convert configuration like;-0.7253244;0.9337438;2.9521587;-3.521101;2.6226099;1.5615952;-
m mjpegserver port 8080 fps 8;-3.4513896;-0.46817133;1.1425632;-0.5741032;-2.282423;2.2220907;-
and pass it in context config token;-6.1608925;0.119491346;0.718386;2.3084755;1.414956;5.1958413;-
call configure if module have one;-4.2516227;4.071176;-0.89801353;2.4898677;0.24959326;1.172576;IRRE
ignore modules without docstring;-4.5744343;1.0844405;-3.4505804;3.7907786;0.581106;2.167693;CODE
make sure we don t get indexerror along the way;0.90804625;2.4848533;-3.706795;0.73656285;-4.0451593;-2.7349606;CODE
then pretty format the header;-5.0569477;-1.0233905;2.335854;-2.1251106;1.5105932;0.8606777;CODE
n 12s s 12 spaces;-0.9694164;-0.5132485;3.1897745;-4.892179;2.9943726;-3.303244;-
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
ruff noqa;-2.4534037;1.1729168;2.287785;-1.8612963;0.97860295;-0.51314807;-
data files;0.6789554;-4.40455;2.7854562;-2.7657113;0.9142373;-1.6554354;-
color eee;-2.1894898;-1.2683159;3.4577086;-0.46310848;1.5013845;-1.8539108;-
background url f background jpg repeat x 718693;-5.02462;0.98497486;4.160386;-2.2710867;-0.65610534;1.475653;-
background color bccad5;-3.7348673;-2.0672884;0.7048965;-2.857255;1.1654086;1.7148058;-
color 516673;-3.3361337;-0.9435698;2.2070475;-3.5703979;2.5549812;-3.7300918;-
error html connection lost show;-5.206704;1.2940018;1.9074001;-0.0864878;-4.213818;0.289493;CODE
error hide;-5.5634313;4.0252333;-0.04916174;-0.2302877;-3.4232843;0.21806748;-
div class panel panel rid div id r rid div div appendto metrics;-1.6136237;0.84686095;1.1717806;-2.6996932;-0.19929618;1.828626;CODE
h ids key html key data key i 1;-4.142662;-0.31189346;-0.32241505;-5.2465224;3.1874983;0.10031949;-
function a b function cy a return f iswindow a a a nodetype 9 a defaultview a parentwindow 1 function cv a if ck a var b c body d f a appendto b e d css display d remove if e none e cl cl c createelement iframe cl frameborder cl width cl height 0 b appendchild cl if cm cl createelement cm cl contentwindow cl contentdocument document cm write c compatmode css1compat doctype html html body cm close d cm createelement a cm body appendchild d e f css d display b removechild cl ck a e return ck a function cu a b var c f each cq concat apply cq slice 0 b function c this a return c function ct cr b function cs settimeout ct 0 return cr f now function cj try return new a activexobject microsoft xmlhttp catch b function ci try return new a xmlhttprequest catch b function cc a c a datafilter c a datafilter c a datatype var d a datatypes e g h i d length j k d 0 l m n o p for g 1 g i g if g 1 for h in a converters typeof h string e h tolowercase a converters h l k k d g if k k l else if l l k m l k n e m e k if n p b for o in e j o split if j 0 l j 0 p e j 1 k if p o e o o 0 n p p 0 n o break n p f error no conversion from m replace to n 0 c n n c p o c return c function cb a c d var e a contents f a datatypes g a responsefields h i j k for i in g i in d c g i d i while f 0 f shift h b h a mimetype c getresponseheader content type if h for i in e if e i e i test h f unshift i break if f 0 in d j f 0 else for i in d if f 0 a converters i f 0 j i break k k i j j k if j j f 0 f unshift j return d j function ca a b c d if f isarray b f each b function b e c be test a d a e ca a typeof e object f isarray e b e c d else if c b null typeof b object for var e in b ca a e b e c d else d a b function b a c var d e g f ajaxsettings flatoptions for d in c c d b g d a e e d c d e f extend 0 a e function b a c d e f g f f c datatypes 0 g g g f 0 var h a f i 0 j h h length 0 k a bt l for i j k l i l h i c d e typeof l string k g l l b c datatypes unshift l l b a c d e l g k l g l b a c d e g return l function bz a return function b c typeof b string c b b if f isfunction c var d b tolowercase split bp e 0 g d length h i j for e g e h d e j test h j h h substr 1 i a h a h i j unshift push c function bc a b c var d b width a offsetwidth a offsetheight e b width bx by g 0 h e length if d 0 if c border for g h g c d parsefloat f css a padding e g 0 c margin d parsefloat f css a c e g 0 d parsefloat f css a border e g width 0 return d px d bz a b b if d 0 d null d a style b 0 d parsefloat d 0 if c for g h g d parsefloat f css a padding e g 0 c padding d parsefloat f css a border e g width 0 c margin d parsefloat f css a c e g 0 return d px function bp a b b src f ajax url b src async 1 datatype script f globaleval b text b textcontent b innerhtml replace bf 0 b parentnode b parentnode removechild b function bo a var b c createelement div bh appendchild b b innerhtml a outerhtml return b firstchild function bn a var b a nodename tolowercase b input bm a b script typeof a getelementsbytagname undefined f grep a getelementsbytagname input bm function bm a if a type checkbox a type radio a defaultchecked a checked function bl a return typeof a getelementsbytagname undefined a getelementsbytagname typeof a queryselectorall undefined a queryselectorall function bk a b var c if b nodetype 1 b clearattributes b clearattributes b mergeattributes b mergeattributes a c b nodename tolowercase if c object b outerhtml a outerhtml else if c input a type checkbox a type radio if c option b selected a defaultselected else if c input c textarea b defaultvalue a defaultvalue else a checked b defaultchecked b checked a checked b value a value b value a value b removeattribute f expando function bj a b if b nodetype 1 f hasdata a var c d e g f data a h f data b g i g events if i delete h handle h events for c in i for d 0 e i c length d e d f event add b c i c d namespace i c d namespace i c d i c d data h data h data f extend h data function bi a b return f nodename a table a getelementsbytagname tbody 0 a appendchild a ownerdocument createelement tbody a function u a var b v split c a createdocumentfragment if c createelement while b length c createelement b pop return c function t a b c b b 0 if f isfunction b return f grep a function a d var e b call a d a return e c if b nodetype return f grep a function a d return a b c if typeof b string var d f grep a function a return a nodetype 1 if o test b return f filter b d c b f filter b d return f grep a function a d return f inarray a b 0 c function s a return a a parentnode a parentnode nodetype 11 function k return 0 function j return 1 function n a b c var d b defer e b queue g b mark h f data a d h c queue f data a e c mark f data a g settimeout function f data a e f data a g f removedata a d 0 h fire 0 function m a for var b in a if b data f isemptyobject a b continue if b tojson return 1 return 0 function l a c d if d b a nodetype 1 var e data c replace k 1 tolowercase d a getattribute e if typeof d string try d d true 0 d false 1 d null null f isnumeric d parsefloat d j test d f parsejson d d catch g f data a c d else d b return d function h a var b g a c d a a split s for c 0 d a length c d c b a c 0 return b var c a document d a navigator e a location f function function j if e isready try c documentelement doscroll left catch a settimeout j 1 return e ready var e function a b return new e fn init a b h f a jquery g a h i w w w j s k s l s m w s 1 n s o bfnrt u 0 9a fa f 4 g p n r true false null d d ee d g q s g r webkit w s opera version w t msie w u mozilla rv w v a z 0 9 ig w ms x function a b return b touppercase y d useragent z a b c object prototype tostring d object prototype hasownproperty e array prototype push f array prototype slice g string prototype trim h array prototype indexof i e fn e prototype constructor e init function a d f var g h j k if a return this if a nodetype this context this 0 a this length 1 return this if a body d c body this context c this 0 c body this selector a this length 1 return this if typeof a string a charat 0 a charat a length 1 a length 3 g i exec a g null a null if g g 1 d if g 1 d d instanceof e d 0 d k d d ownerdocument d c j m exec a j e isplainobject d a c createelement j 1 e fn attr call a d 0 a k createelement j 1 j e buildfragment g 1 k a j cacheable e clone j fragment j fragment childnodes return e merge this a h c getelementbyid g 2 if h h parentnode if h id g 2 return f find a this length 1 this 0 h this context c this selector a return this return d d jquery d f find a this constructor d find a if e isfunction a return f ready a a selector b this selector a selector this context a context return e makearray a this selector jquery 1 7 1 length 0 size function return this length toarray function return f call this 0 get function a return a null this toarray a 0 this this length a this a pushstack function a b c var d this constructor e isarray a e apply d a e merge d a d prevobject this d context this context b find d selector this selector this selector c b d selector this selector b c return d each function a b return e each this a b ready function a e bindready a add a return this eq function a a a return a 1 this slice a this slice a a 1 first function return this eq 0 last function return this eq 1 slice function return this pushstack f apply this arguments slice f call arguments join map function a return this pushstack e map this function b c return a call b c b end function return this prevobject this constructor null push e sort sort splice splice e fn init prototype e fn e extend e fn extend function var a c d f g h i arguments 0 j 1 k arguments length l 1 typeof i boolean l i i arguments 1 j 2 typeof i object e isfunction i i k j i this j for j k j if a arguments j null for c in a d i c f a c if i f continue l f e isplainobject f g e isarray f g g 1 h d e isarray d d h d e isplainobject d d i c e extend l h f f b i c f return i e extend noconflict function b a e a g b a jquery e a jquery f return e isready 1 readywait 1 holdready function a a e readywait e ready 0 ready function a if a 0 e readywait a 0 e isready if c body return settimeout e ready 1 e isready 0 if a 0 e readywait 0 return a firewith c e e fn trigger e c trigger ready off ready bindready function if a a e callbacks once memory if c readystate complete return settimeout e ready 1 if c addeventlistener c addeventlistener domcontentloaded b 1 a addeventlistener load e ready 1 else if c attachevent c attachevent onreadystatechange b a attachevent onload e ready var b 1 try b a frameelement null catch d c documentelement doscroll b j isfunction function a return e type a function isarray array isarray function a return e type a array iswindow function a return a typeof a object setinterval in a isnumeric function a return isnan parsefloat a isfinite a type function a return a null string a i c call a object isplainobject function a if a e type a object a nodetype e iswindow a return 1 try if a constructor d call a constructor d call a constructor prototype isprototypeof return 1 catch c return 1 var d for d in a return d b d call a d isemptyobject function a for var b in a return 1 return 0 error function a throw new error a parsejson function b if typeof b string b return null b e trim b if a json a json parse return a json parse b if n test b replace o replace p replace q return new function return b e error invalid json b parsexml function c var d f try a domparser f new domparser d f parsefromstring c text xml d new activexobject microsoft xmldom d async false d loadxml c catch g d b d d documentelement d getelementsbytagname parsererror length e error invalid xml c return d noop function globaleval function b b j test b a execscript function b a eval call a b b camelcase function a return a replace w ms replace v x nodename function a b return a nodename a nodename touppercase b touppercase each function a c d var f g 0 h a length i h b e isfunction a if d if i for f in a if c apply a f d 1 break else for g h if c apply a g d 1 break else if i for f in a if c call a f f a f 1 break else for g h if c call a g g a g 1 break return a trim g function a return a null g call a function a return a null a replace k replace l makearray function a b var c b if a null var d e type a a length null d string d function d regexp e iswindow a e call c a e merge c a return c inarray function a b c var d if b if h return h call b a c d b length c c c 0 math max 0 d c c 0 for c d c if c in b b c a return c return 1 merge function a c var d a length e 0 if typeof c length number for var f c length e f e a d c e else while c e b a d c e a length d return a grep function a b c var d e c c for var f 0 g a length f g f e b a f f c e d push a f return d map function a c d var f g h i 0 j a length k a instanceof e j b typeof j number j 0 a 0 a j 1 j 0 e isarray a if k for i j i f c a i i d f null h h length f else for g in a f c a g g d f null h h length f return h concat apply h guid 1 proxy function a c if typeof c string var d a c c a a d if e isfunction a return b var f f call arguments 2 g function return a apply c f concat f call arguments g guid a guid a guid g guid e guid return g access function a c d f g h var i a length if typeof c object for var j in c e access a j c j f g d return a if d b f h f e isfunction d for var k 0 k i k g a k c f d call a k k g a k c d h return a return i g a 0 c b now function return new date gettime uamatch function a a a tolowercase var b r exec a s exec a t exec a a indexof compatible 0 u exec a return browser b 1 version b 2 0 sub function function a b c return new a fn init b c e extend 0 a this a superclass this a fn a prototype this a fn constructor a a sub this sub a fn init function d f f f instanceof e f instanceof a f a f return e fn init call this d f b a fn init prototype a fn var b a c return a browser e each boolean number string function array date regexp object split function a b i object b b tolowercase z e uamatch y z browser e browser z browser 0 e browser version z version e browser webkit e browser safari 0 j test k s xa0 l s xa0 h e c c addeventlistener b function c removeeventlistener domcontentloaded b 1 e ready c attachevent b function c readystate complete c detachevent onreadystatechange b e ready return e g f callbacks function a a a g a h a var c d e i j k l m function b var d e g h i for d 0 e b length d e d g b d h f type g h array m g h function a unique o has g c push g n function b f f f e a memory b f i 0 l j 0 j 0 k c length for c l k l if c l apply b f 1 a stoponfalse e 0 break i 1 c a once e 0 o disable c d d length e d shift o firewith e 0 e 1 o add function if c var a c length m arguments i k c length e e 0 j a n e 0 e 1 return this remove function if c var b arguments d 0 e b length for d e d for var f 0 f c length f if b d c f i f k k f l l c splice f 1 if a unique break return this has function a if c var b 0 d c length for b d b if a c b return 0 return 1 empty function c return this disable function c d e b return this disabled function return c lock function d b e e 0 o disable return this locked function return d firewith function b c d i a once d push b c a once e n b c return this fire function o firewith this arguments return this fired function return e return o var i slice f extend deferred function a var b f callbacks once memory c f callbacks once memory d f callbacks memory e pending g resolve b reject c notify d h done b add fail c add progress d add state function return e isresolved b fired isrejected c fired then function a b c i done a fail b progress c return this always function i done apply i arguments fail apply i arguments return this pipe function a b c return f deferred function d f each done a resolve fail b reject progress c notify function a b var c b 0 e b 1 g f isfunction c i a function g c apply this arguments g f isfunction g promise g promise then d resolve d reject d notify d e with this i d this g i a d e promise promise function a if a null a h else for var b in h a b h b return a i h promise j for j in g i j g j fire i j with g j firewith i done function e resolved c disable d lock fail function e rejected b disable d lock a a call i i return i when function a function m a return function b e a arguments length 1 i call arguments 0 b j notifywith k e function l a return function c b a arguments length 1 i call arguments 0 c g j resolvewith j b var b i call arguments 0 c 0 d b length e array d g d h d j d 1 a f isfunction a promise a f deferred k j promise if d 1 for c d c b c b c promise f isfunction b c promise b c promise then l c j reject m c g g j resolvewith j b else j a j resolvewith j d a return k f support function var b d e g h i j k l m n o p q c createelement div r c documentelement q setattribute classname t q innerhtml link table table a href a style top 1px float left opacity 55 a a input type checkbox d q getelementsbytagname e q getelementsbytagname a 0 if d d length e return g c createelement select h g appendchild c createelement option i q getelementsbytagname input 0 b leadingwhitespace q firstchild nodetype 3 tbody q getelementsbytagname tbody length htmlserialize q getelementsbytagname link length style top test e getattribute style hrefnormalized e getattribute href a opacity 0 55 test e style opacity cssfloat e style cssfloat checkon i value on optselected h selected getsetattribute q classname t enctype c createelement form enctype html5clone c createelement nav clonenode 0 outerhtml nav nav submitbubbles 0 changebubbles 0 focusinbubbles 1 deleteexpando 0 nocloneevent 0 inlineblockneedslayout 1 shrinkwrapblocks 1 reliablemarginright 0 i checked 0 b noclonechecked i clonenode 0 checked g disabled 0 b optdisabled h disabled try delete q test catch s b deleteexpando 1 q addeventlistener q attachevent q fireevent q attachevent onclick function b nocloneevent 1 q clonenode 0 fireevent onclick i c createelement input i value t i setattribute type radio b radiovalue i value t i setattribute checked checked q appendchild i k c createdocumentfragment k appendchild q lastchild b checkclone k clonenode 0 clonenode 0 lastchild checked b appendchecked i checked k removechild i k appendchild q q innerhtml a getcomputedstyle j c createelement div j style width 0 j style marginright 0 q style width 2px q appendchild j b reliablemarginright parseint a getcomputedstyle j null marginright 0 marginright 10 0 0 if q attachevent for o in submit 1 change 1 focusin 1 n on o p n in q p q setattribute n return p typeof q n function b o bubbles p k removechild q k g h j q i null f function var a d e g h i j k m n o r c getelementsbytagname body 0 r j 1 k position absolute top 0 left 0 width 1px height 1px margin 0 m visibility hidden border 0 n style k border 5px solid 000 padding 0 o div n div div div table n cellpadding 0 cellspacing 0 tr td td tr table a c createelement div a style csstext m width 0 height 0 position static top 0 margin top j px r insertbefore a r firstchild q c createelement div a appendchild q q innerhtml table tr td style padding 0 border 0 display none td td t td tr table l q getelementsbytagname td p l 0 offsetheight 0 l 0 style display l 1 style display none b reliablehiddenoffsets p l 0 offsetheight 0 q innerhtml q style width q style paddingleft 1px f boxmodel b boxmodel q offsetwidth 2 typeof q style zoom undefined q style display inline q style zoom 1 b inlineblockneedslayout q offsetwidth 2 q style display q innerhtml div style width 4px div b shrinkwrapblocks q offsetwidth 2 q style csstext k m q innerhtml o d q firstchild e d firstchild h d nextsibling firstchild firstchild i doesnotaddborder e offsettop 5 doesaddborderfortableandcells h offsettop 5 e style position fixed e style top 20px i fixedposition e offsettop 20 e offsettop 15 e style position e style top d style overflow hidden d style position relative i subtractsborderforoverflownotvisible e offsettop 5 i doesnotincludemargininbodyoffset r offsettop j r removechild a q a null f extend b i return b var j k a z g f extend cache uuid 0 expando jquery f fn jquery math random replace d g nodata embed 0 object clsid d27cdb6e ae6d 11cf 96b8 444553540000 applet 0 hasdata function a a a nodetype f cache a f expando a f expando return a m a data function a c d e if f acceptdata a var g h i j f expando k typeof c string l a nodetype m l f cache a n l a j a j j o c events if n m n o e m n data k d b return n l a j n f uuid n j m n m n l m n tojson f noop if typeof c object typeof c function e m n f extend m n c m n data f extend m n data c g h m n e h data h data h h data d b h f camelcase c d if o h c return g events k i h c i null i h f camelcase c i h return i removedata function a b c if f acceptdata a var d e g h f expando i a nodetype j i f cache a k i a h h if j k return if b d c j k j k data if d f isarray b b in d b b b f camelcase b b in d b b b b split for e 0 g b length e g e delete d b e if c m f isemptyobject d return if c delete j k data if m j k return f support deleteexpando j setinterval delete j k j k null i f support deleteexpando delete a h a removeattribute a removeattribute h a h null data function a b c return f data a b c 0 acceptdata function a if a nodename var b f nodata a nodename tolowercase if b return b 0 a getattribute classid b return 0 f fn extend data function a c var d e g h null if typeof a undefined if this length h f data this 0 if this 0 nodetype 1 f data this 0 parsedattrs e this 0 attributes for var i 0 j e length i j i g e i name g indexof data 0 g f camelcase g substring 5 l this 0 g h g f data this 0 parsedattrs 0 return h if typeof a object return this each function f data this a d a split d 1 d 1 d 1 if c b h this triggerhandler getdata d 1 d 0 h b this length h f data this 0 a h l this 0 a h return h b d 1 this data d 0 h return this each function var b f this e d 0 c b triggerhandler setdata d 1 e f data this a c b triggerhandler changedata d 1 e removedata function a return this each function f removedata this a f extend mark function a b a b b fx mark f data a b f data a b 0 1 unmark function a b c a 0 c b b a a 1 if b c c fx var d c mark e a 0 f data b d 1 1 e f data b d e f removedata b d 0 n b c mark queue function a b c var d if a b b fx queue d f data a b c d f isarray c d f data a b f makearray c d push c return d dequeue function a b b b fx var c f queue a b d c shift e d inprogress d c shift d b fx c unshift inprogress f data a b run e d call a function f dequeue a b e c length f removedata a b queue b run 0 n a b queue f fn extend queue function a c typeof a string c a a fx if c b return f queue this 0 a return this each function var b f queue this a c a fx b 0 inprogress f dequeue this a dequeue function a return this each function f dequeue this a delay function a b a f fx f fx speeds a a a b b fx return this queue b function b c var d settimeout b a c stop function cleartimeout d clearqueue function a return this queue a fx promise function a c function m h d resolvewith e e typeof a string c a a b a a fx var d f deferred e this g e length h 1 i a defer j a queue k a mark l while g if l f data e g i b 0 f data e g j b 0 f data e g k b 0 f data e g i f callbacks once memory 0 h l add m m return d promise var o n t r g p s q r g r button input i s button input object select textarea i t a rea i u autofocus autoplay async checked controls defer disabled hidden loop multiple open readonly required scoped selected i v f support getsetattribute w x y f fn extend attr function a b return f access this a b 0 f attr removeattr function a return this each function f removeattr this a prop function a b return f access this a b 0 f prop removeprop function a a f propfix a a return this each function try this a b delete this a catch c addclass function a var b c d e g h i if f isfunction a return this each function b f this addclass a call this b this classname if a typeof a string b a split p for c 0 d this length c d c e this c if e nodetype 1 if e classname b length 1 e classname a else g e classname for h 0 i b length h i h g indexof b h g b h e classname f trim g return this removeclass function a var c d e g h i j if f isfunction a return this each function b f this removeclass a call this b this classname if a typeof a string a b c a split p for d 0 e this length d e d g this d if g nodetype 1 g classname if a h g classname replace o for i 0 j c length i j i h h replace c i g classname f trim h else g classname return this toggleclass function a b var c typeof a d typeof b boolean if f isfunction a return this each function c f this toggleclass a call this c this classname b b return this each function if c string var e g 0 h f this i b j a split p while e j g i d i h hasclass e h i addclass removeclass e else if c undefined c boolean this classname f data this classname this classname this classname this classname a 1 f data this classname hasclass function a var b a c 0 d this length for c d c if this c nodetype 1 this c classname replace o indexof b 1 return 0 return 1 val function a var c d e g this 0 if arguments length e f isfunction a return this each function d var g f this h if this nodetype 1 e h a call this d g val h a h null h typeof h number h f isarray h h f map h function a return a null a c f valhooks this nodename tolowercase f valhooks this type if c set in c c set this h value b this value h if g c f valhooks g nodename tolowercase f valhooks g type if c get in c d c get g value b return d d g value return typeof d string d replace q d null d f extend valhooks option get function a var b a attributes value return b b specified a value a text select get function a var b c d e g a selectedindex h i a options j a type select one if g 0 return null c j g 0 d j g 1 i length for c d c e i c if e selected f support optdisabled e disabled e getattribute disabled null e parentnode disabled f nodename e parentnode optgroup b f e val if j return b h push b if j h length i length return f i g val return h set function a b var c f makearray b f a find option each function this selected f inarray f this val c 0 c length a selectedindex 1 return c attrfn val 0 css 0 html 0 text 0 data 0 width 0 height 0 offset 0 attr function a c d e var g h i j a nodetype if a j 3 j 8 j 2 if e c in f attrfn return f a c d if typeof a getattribute undefined return f prop a c d i j 1 f isxmldoc a i c c tolowercase h f attrhooks c u test c x w if d b if d null f removeattr a c return if h set in h i g h set a d c b return g a setattribute c d return d if h get in h i g h get a c null return g g a getattribute c return g null b g removeattr function a b var c d e g h 0 if b a nodetype 1 d b tolowercase split p g d length for h g h e d h e c f propfix e e f attr a e a removeattribute v e c u test e c in a a c 1 attrhooks type set function a b if r test a nodename a parentnode f error type property can t be changed else if f support radiovalue b radio f nodename a input var c a value a setattribute type b c a value c return b value get function a b if w f nodename a button return w get a b return b in a a value null set function a b c if w f nodename a button return w set a b c a value b propfix tabindex tabindex readonly readonly for htmlfor class classname maxlength maxlength cellspacing cellspacing cellpadding cellpadding rowspan rowspan colspan colspan usemap usemap frameborder frameborder contenteditable contenteditable prop function a c d var e g h i a nodetype if a i 3 i 8 i 2 h i 1 f isxmldoc a h c f propfix c c g f prophooks c return d b g set in g e g set a d c b e a c d g get in g e g get a c null e a c prophooks tabindex get function a var c a getattributenode tabindex return c c specified parseint c value 10 s test a nodename t test a nodename a href 0 b f attrhooks tabindex f prophooks tabindex x get function a c var d e f prop a c return e 0 typeof e boolean d a getattributenode c d nodevalue 1 c tolowercase b set function a b c var d b 1 f removeattr a c d f propfix c c d in a a d 0 a setattribute c c tolowercase return c v y name 0 id 0 w f valhooks button get function a c var d d a getattributenode c return d y c d nodevalue d specified d nodevalue b set function a b d var e a getattributenode d e e c createattribute d a setattributenode e return e nodevalue b f attrhooks tabindex set w set f each width height function a b f attrhooks b f extend f attrhooks b set function a c if c a setattribute b auto return c f attrhooks contenteditable get w get set function a b c b b false w set a b c f support hrefnormalized f each href src width height function a c f attrhooks c f extend f attrhooks c get function a var d a getattribute c 2 return d null b d f support style f attrhooks style get function a return a style csstext tolowercase b set function a b return a style csstext b f support optselected f prophooks selected f extend f prophooks selected get function a var b a parentnode b b selectedindex b parentnode b parentnode selectedindex return null f support enctype f propfix enctype encoding f support checkon f each radio checkbox function f valhooks this get function a return a getattribute value null on a value f each radio checkbox function f valhooks this f extend f valhooks this set function a b if f isarray b return a checked f inarray f a val b 0 var z textarea input select i a b bhover s b c key d mouse contextmenu click e focusinfocus focusoutblur f w w w g function a var b f exec a b b 1 b 1 tolowercase b 3 b 3 new regexp s b 3 s return b h function a b var c a attributes return b 1 a nodename tolowercase b 1 b 2 c id value b 2 b 3 b 3 test c class value i function a return f event special hover a a replace b mouseenter 1 mouseleave 1;-0.90546376;2.0253522;-1.3128252;-3.4841983;2.4730458;1.0201598;CODE
f event add function a c d e g var h i j k l m n o p q r s if a nodetype 3 a nodetype 8 c d h f data a d handler p d d p handler d guid d guid f guid j h events j h events j i h handle i h handle i function a return typeof f undefined a f event triggered a type f event dispatch apply i elem arguments b i elem a c f trim i c split for k 0 k c length k l a exec c k m l 1 n l 2 split sort s f event special m m g s delegatetype s bindtype m s f event special m o f extend type m origtype l 1 data e handler d guid d guid selector g quick g g namespace n join p r j m if r r j m r delegatecount 0 if s setup s setup call a e n i 1 a addeventlistener a addeventlistener m i 1 a attachevent a attachevent on m i s add s add call a o o handler guid o handler guid d guid g r splice r delegatecount 0 o r push o f event global m 0 a null global remove function a b c d e var g f hasdata a f data a h i j k l m n o p q r s if g o g events b f trim i b split for h 0 h b length h i a exec b h j k i 1 l i 2 if j for j in o f event remove a j b h c d 0 continue p f event special j j d p delegatetype p bindtype j r o j m r length l l new regexp l split sort join null for n 0 n r length n s r n e k s origtype c c guid s guid l l test s namespace d d s selector d s selector r splice n 1 s selector r delegatecount p remove p remove call a s r length 0 m r length p teardown p teardown call a l 1 f removeevent a j g handle delete o j f isemptyobject o q g handle q q elem null f removedata a events handle 0 customevent getdata 0 setdata 0 changedata 0 trigger function c d e g if e e nodetype 3 e nodetype 8 var h c type c i j k l m n o p q r s if e test h f event triggered return h indexof 0 h h slice 0 1 k 0 h indexof 0 i h split h i shift i sort if e f event customevent h f event global h return c typeof c object c f expando c new f event h c new f event h c type h c istrigger 0 c exclusive k c namespace i join c namespace re c namespace new regexp i join null o h indexof 0 on h if e j f cache for l in j j l events j l events h f event trigger c d j l handle elem 0 return c result b c target c target e d d null f makearray d d unshift c p f event special h if p trigger p trigger apply e d 1 return r e p bindtype h if g p nobubble f iswindow e s p delegatetype h m e test s h e e parentnode n null for m m m parentnode r push m s n m n n e ownerdocument r push n defaultview n parentwindow a s for l 0 l r length c ispropagationstopped l m r l 0 c type r l 1 q f data m events c type f data m handle q q apply m d q o m o q f acceptdata m q apply m d 1 c preventdefault c type h g c isdefaultprevented p default p default apply e ownerdocument d 1 h click f nodename e a f acceptdata e o e h h focus h blur c target offsetwidth 0 f iswindow e n e o n e o null f event triggered h e h f event triggered b n e o n return c result dispatch function c c f event fix c a event var d f data this events c type e d delegatecount g slice call arguments 0 h c exclusive c namespace i j k l m n o p q r s t g 0 c c delegatetarget this if e c target disabled c button c type click m f this m context this ownerdocument this for l c target l this l l parentnode this o q m 0 l for j 0 j e j r d j s r selector o s b o s r quick h l r quick m is s o s q push r q length i push elem l matches q d length e i push elem this matches d slice e for j 0 j i length c ispropagationstopped j p i j c currenttarget p elem for k 0 k p matches length c isimmediatepropagationstopped k r p matches k if h c namespace r namespace c namespace re c namespace re test r namespace c data r data c handleobj r n f event special r origtype handle r handler apply p elem g n b c result n n 1 c preventdefault c stoppropagation return c result props attrchange attrname relatednode srcelement altkey bubbles cancelable ctrlkey currenttarget eventphase metakey relatedtarget shiftkey target timestamp view which split fixhooks keyhooks props char charcode key keycode split filter function a b a which null a which b charcode null b charcode b keycode return a mousehooks props button buttons clientx clienty fromelement offsetx offsety pagex pagey screenx screeny toelement split filter function a d var e f g h d button i d fromelement a pagex null d clientx null e a target ownerdocument c f e documentelement g e body a pagex d clientx f f scrollleft g g scrollleft 0 f f clientleft g g clientleft 0 a pagey d clienty f f scrolltop g g scrolltop 0 f f clienttop g g clienttop 0 a relatedtarget i a relatedtarget i a target d toelement i a which h b a which h 1 1 h 2 3 h 4 2 0 return a fix function a if a f expando return a var d e g a h f event fixhooks a type i h props this props concat h props this props a f event g for d i length d e i d a e g e a target a target g srcelement c a target nodetype 3 a target a target parentnode a metakey b a metakey a ctrlkey return h filter h filter a g a special ready setup f bindready load nobubble 0 focus delegatetype focusin blur delegatetype focusout beforeunload setup function a b c f iswindow this this onbeforeunload c teardown function a b this onbeforeunload b this onbeforeunload null simulate function a b c d var e f extend new f event c type a issimulated 0 originalevent d f event trigger e null b f event dispatch call b e e isdefaultprevented c preventdefault f event handle f event dispatch f removeevent c removeeventlistener function a b c a removeeventlistener a removeeventlistener b c 1 function a b c a detachevent a detachevent on b c f event function a b if this instanceof f event return new f event a b a a type this originalevent a this type a type this isdefaultprevented a defaultprevented a returnvalue 1 a getpreventdefault a getpreventdefault k j this type a b f extend this b this timestamp a a timestamp f now this f expando 0 f event prototype preventdefault function this isdefaultprevented k var a this originalevent a a preventdefault a preventdefault a returnvalue 1 stoppropagation function this ispropagationstopped k var a this originalevent a a stoppropagation a stoppropagation a cancelbubble 0 stopimmediatepropagation function this isimmediatepropagationstopped k this stoppropagation isdefaultprevented j ispropagationstopped j isimmediatepropagationstopped j f each mouseenter mouseover mouseleave mouseout function a b f event special a delegatetype b bindtype b handle function a var c this d a relatedtarget e a handleobj g e selector h if d d c f contains c d a type e origtype h e handler apply this arguments a type b return h f support submitbubbles f event special submit setup function if f nodename this form return 1 f event add this click submit keypress submit function a var c a target d f nodename c input f nodename c button c form b d d submit attached f event add d submit submit function a this parentnode a istrigger f event simulate submit this parentnode a 0 d submit attached 0 teardown function if f nodename this form return 1 f event remove this submit f support changebubbles f event special change setup function if z test this nodename if this type checkbox this type radio f event add this propertychange change function a a originalevent propertyname checked this just changed 0 f event add this click change function a this just changed a istrigger this just changed 1 f event simulate change this a 0 return 1 f event add this beforeactivate change function a var b a target z test b nodename b change attached f event add b change change function a this parentnode a issimulated a istrigger f event simulate change this parentnode a 0 b change attached 0 handle function a var b a target if this b a issimulated a istrigger b type radio b type checkbox return a handleobj handler apply this arguments teardown function f event remove this change return z test this nodename f support focusinbubbles f each focus focusin blur focusout function a b var d 0 e function a f event simulate b a target f event fix a 0 f event special b setup function d 0 c addeventlistener a e 0 teardown function d 0 c removeeventlistener a e 0 f fn extend on function a c d e g var h i if typeof a object typeof c string d c c b for i in a this on i c d a i g return this d null e null e c d c b e null typeof c string e d d b e d d c c b if e 1 e j else if e return this g 1 h e e function a f off a return h apply this arguments e guid h guid h guid f guid return this each function f event add this a e d c one function a b c d return this on call this a b c d 1 off function a c d if a a preventdefault a handleobj var e a handleobj f a delegatetarget off e namespace e type e namespace e type e selector e handler return this if typeof a object for var g in a this off g c a g return this if c 1 typeof c function d c c b d 1 d j return this each function f event remove this a d c bind function a b c return this on a null b c unbind function a b return this off a null b live function a b c f this context on a this selector b c return this die function a b f this context off a this selector b return this delegate function a b c d return this on b a c d undelegate function a b c return arguments length 1 this off a this off b a c trigger function a b return this each function f event trigger a b this triggerhandler function a b if this 0 return f event trigger a b this 0 0 toggle function a var b arguments c a guid f guid d 0 e function c var e f data this lasttoggle a guid 0 d f data this lasttoggle a guid e 1 c preventdefault return b e apply this arguments 1 e guid c while d b length b d guid c return this click e hover function a b return this mouseenter a mouseleave b a f each blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu split function a b f fn b function a c c null c a a null return arguments length 0 this on b null a c this trigger b f attrfn f attrfn b 0 c test b f event fixhooks b f event keyhooks d test b f event fixhooks b f event mousehooks function function x a b c e f g for var h 0 i e length h i h var j e h if j var k 1 j j a while j if j d c k e j sizset break if j nodetype 1 g j d c j sizset h if typeof b string if j b k 0 break else if m filter b j length 0 k j break j j a e h k function w a b c e f g for var h 0 i e length h i h var j e h if j var k 1 j j a while j if j d c k e j sizset break j nodetype 1 g j d c j sizset h if j nodename tolowercase b k j break j j a e h k var a s s r n g d sizcache math random replace e 0 g object prototype tostring h 1 i 0 j g k r n g l w 0 0 sort function i 1 return 0 var m function b d e f e e d d c var h d if d nodetype 1 d nodetype 9 return if b typeof b string return e var i j k l n q r t u 0 v m isxml d w x b do a exec i a exec x if i x i 3 w push i 1 if i 2 l i 3 break while i if w length 1 p exec b if w length 2 o relative w 0 j y w 0 w 1 d f else j o relative w 0 d m w shift d while w length b w shift o relative b b w shift j y b j f else f w length 1 d nodetype 9 v o match id test w 0 o match id test w w length 1 n m find w shift d v d n expr m filter n expr n set 0 n set 0 if d n f expr w pop set s f m find w pop w length 1 w 0 w 0 d parentnode d parentnode d v j n expr m filter n expr n set n set w length 0 k s j u 1 while w length q w pop r q o relative q r w pop q r null r d o relative q k r v else k w k k j k m error q b if g call k object array if u e push apply e k else if d d nodetype 1 for t 0 k t null t k t k t 0 k t nodetype 1 m contains d k t e push j t else for t 0 k t null t k t k t nodetype 1 e push j t else s k e l m l h e f m uniquesort e return e m uniquesort function a if u h i a sort u if h for var b 1 b a length b a b a b 1 a splice b 1 return a m matches function a b return m a null null b m matchesselector function a b return m b null null a length 0 m find function a b c var d e f g h i if a return for e 0 f o order length e f e h o order e if g o leftmatch h exec a i g 1 g splice 1 1 if i substr i length 1 g 1 g 1 replace j d o find h g b c if d null a a replace o match h break d d typeof b getelementsbytagname undefined b getelementsbytagname return set d expr a m filter function a c d e var f g h i j k l n p q a r s c t c c 0 m isxml c 0 while a c length for h in o filter if f o leftmatch h exec a null f 2 k o filter h l f 1 g 1 f splice 1 1 if l substr l length 1 continue s r r if o prefilter h f o prefilter h f s d r e t if f g i 0 else if f 0 continue if f for n 0 j s n null n j i k j f n s p e i d i null p g 0 s n 1 p r push j g 0 if i b d s r a a replace o match h if g return break if a q if g null m error a else break q a return s m error function a throw new error syntax error unrecognized expression a var n m gettext function a var b c d a nodetype e if d if d 1 d 9 if typeof a textcontent string return a textcontent if typeof a innertext string return a innertext replace k for a a firstchild a a a nextsibling e n a else if d 3 d 4 return a nodevalue else for b 0 c a b b c nodetype 8 e n c return e o m selectors order id name tag match id w u00c0 uffff class w u00c0 uffff name name w u00c0 uffff attr s w u00c0 uffff s s s 3 w u00c0 uffff s tag w u00c0 uffff child only nth last first child s even odd d d n s s d s pos nth eq gt lt first last even odd d pseudo w u00c0 uffff 2 leftmatch attrmap class classname for htmlfor attrhandle href function a return a getattribute href type function a return a getattribute type relative function a b var c typeof b string d c l test b e c d d b b tolowercase for var f 0 g a length h f g f if h a f while h h previoussibling h nodetype 1 a f e h h nodename tolowercase b h 1 h b e m filter b a 0 function a b var c d typeof b string e 0 f a length if d l test b b b tolowercase for e f e c a e if c var g c parentnode a e g nodename tolowercase b g 1 else for e f e c a e c a e d c parentnode c parentnode b d m filter b a 0 function a b c var d f e g x typeof b string l test b b b tolowercase d b g w g parentnode b f a d c function a b c var d f e g x typeof b string l test b b b tolowercase d b g w g previoussibling b f a d c find id function a b c if typeof b getelementbyid undefined c var d b getelementbyid a 1 return d d parentnode d name function a b if typeof b getelementsbyname undefined var c d b getelementsbyname a 1 for var e 0 f d length e f e d e getattribute name a 1 c push d e return c length 0 null c tag function a b if typeof b getelementsbytagname undefined return b getelementsbytagname a 1 prefilter class function a b c d e f a a 1 replace j if f return a for var g 0 h h b g null g h e h classname h classname replace t n r g indexof a 0 c d push h c b g 1 return 1 id function a return a 1 replace j tag function a b return a 1 replace j tolowercase child function a if a 1 nth a 2 m error a 0 a 2 a 2 replace s g var b d n d exec a 2 even 2n a 2 odd 2n 1 d test a 2 0n a 2 a 2 a 2 b 1 b 2 1 0 a 3 b 3 0 else a 2 m error a 0 a 0 e return a attr function a b c d e f var g a 1 a 1 replace j f o attrmap g a 1 o attrmap g a 4 a 4 a 5 replace j a 2 a 4 a 4 return a pseudo function b c d e f if b 1 not if a exec b 3 length 1 w test b 3 b 3 m b 3 null null c else var g m filter b 3 c d 0 f d e push apply e g return 1 else if o match pos test b 0 o match child test b 0 return 0 return b pos function a a unshift 0 return a filters enabled function a return a disabled 1 a type hidden disabled function a return a disabled 0 checked function a return a checked 0 selected function a a parentnode a parentnode selectedindex return a selected 0 parent function a return a firstchild empty function a return a firstchild has function a b c return m c 3 a length header function a return h d i test a nodename text function a var b a getattribute type c a type return a nodename tolowercase input text c b c b null radio function a return a nodename tolowercase input radio a type checkbox function a return a nodename tolowercase input checkbox a type file function a return a nodename tolowercase input file a type password function a return a nodename tolowercase input password a type submit function a var b a nodename tolowercase return b input b button submit a type image function a return a nodename tolowercase input image a type reset function a var b a nodename tolowercase return b input b button reset a type button function a var b a nodename tolowercase return b input button a type b button input function a return input select textarea button i test a nodename focus function a return a a ownerdocument activeelement setfilters first function a b return b 0 last function a b c d return b d length 1 even function a b return b 2 0 odd function a b return b 2 1 lt function a b c return b c 3 0 gt function a b c return b c 3 0 nth function a b c return c 3 0 b eq function a b c return c 3 0 b filter pseudo function a b c d var e b 1 f o filters e if f return f a c b d if e contains return a textcontent a innertext n a indexof b 3 0 if e not var g b 3 for var h 0 i g length h i h if g h a return 1 return 0 m error e child function a b var c e f g h i j k b 1 l a switch k case only case first while l l previoussibling if l nodetype 1 return 1 if k first return 0 l a case last while l l nextsibling if l nodetype 1 return 1 return 0 case nth c b 2 e b 3 if c 1 e 0 return 0 f b 0 g a parentnode if g g d f a nodeindex i 0 for l g firstchild l l l nextsibling l nodetype 1 l nodeindex i g d f j a nodeindex e return c 0 j 0 j c 0 j c 0 id function a b return a nodetype 1 a getattribute id b tag function a b return b a nodetype 1 a nodename a nodename tolowercase b class function a b return a classname a getattribute class indexof b 1 attr function a b var c b 1 d m attr m attr a c o attrhandle c o attrhandle c a a c null a c a getattribute c e d f b 2 g b 4 return d null f f m attr d null f e g f e indexof g 0 f e indexof g 0 g f e g f e indexof g 0 f e substr e length g length g f e g e substr 0 g length 1 g 1 e d 1 pos function a b c d var e b 2 f o setfilters e if f return f a c b d p o match pos q function a b return b 0 1 for var r in o match o match r new regexp o match r source source o leftmatch r new regexp r n source o match r source replace d g q var s function a b a array prototype slice call a 0 if b b push apply b a return b return a try array prototype slice call c documentelement childnodes 0 0 nodetype catch t s function a b var c 0 d b if g call a object array array prototype push apply d a else if typeof a length number for var e a length c e c d push a c else for a c c d push a c return d var u v c documentelement comparedocumentposition u function a b if a b h 0 return 0 if a comparedocumentposition b comparedocumentposition return a comparedocumentposition 1 1 return a comparedocumentposition b 4 1 1 u function a b if a b h 0 return 0 if a sourceindex b sourceindex return a sourceindex b sourceindex var c d e f g a parentnode i b parentnode j g if g i return v a b if g return 1 if i return 1 while j e unshift j j j parentnode j i while j f unshift j j j parentnode c e length d f length for var k 0 k c k d k if e k f k return v e k f k return k c v a f k 1 v e k b 1 v function a b c if a b return c var d a nextsibling while d if d b return 1 d d nextsibling return 1 function var a c createelement div d script new date gettime e c documentelement a innerhtml a name d e insertbefore a e firstchild c getelementbyid d o find id function a c d if typeof c getelementbyid undefined d var e c getelementbyid a 1 return e e id a 1 typeof e getattributenode undefined e getattributenode id nodevalue a 1 e b o filter id function a b var c typeof a getattributenode undefined a getattributenode id return a nodetype 1 c c nodevalue b e removechild a e a null function var a c createelement div a appendchild c createcomment a getelementsbytagname length 0 o find tag function a b var c b getelementsbytagname a 1 if a 1 var d for var e 0 c e e c e nodetype 1 d push c e c d return c a innerhtml a href a a firstchild typeof a firstchild getattribute undefined a firstchild getattribute href o attrhandle href function a return a getattribute href 2 a null c queryselectorall function var a m b c createelement div d sizzle b innerhtml p class test p if b queryselectorall b queryselectorall test length 0 m function b e f g e e c if g m isxml e var h w w w exec b if h e nodetype 1 e nodetype 9 if h 1 return s e getelementsbytagname b f if h 2 o find class e getelementsbyclassname return s e getelementsbyclassname h 2 f if e nodetype 9 if b body e body return s e body f if h h 3 var i e getelementbyid h 3 if i i parentnode return s f if i id h 3 return s i f try return s e queryselectorall b f catch j else if e nodetype 1 e nodename tolowercase object var k e l e getattribute id n l d p e parentnode q s test b l n n replace g e setattribute id n q p e e parentnode try if q p return s e queryselectorall id n b f catch r finally l k removeattribute id return a b e f g for var e in a m e a e b null function var a c documentelement b a matchesselector a mozmatchesselector a webkitmatchesselector a msmatchesselector if b var d b call c createelement div div e 1 try b call c documentelement test sizzle catch f e 0 m matchesselector function a c c c replace s s g 1 if m isxml a try if e o match pseudo test c test c var f b call a c if f d a document a document nodetype 11 return f catch g return m c null null a length 0 function var a c createelement div a innerhtml div class test e div div class test div if a getelementsbyclassname a getelementsbyclassname e length 0 a lastchild classname e if a getelementsbyclassname e length 1 return o order splice 1 0 class o find class function a b c if typeof b getelementsbyclassname undefined c return b getelementsbyclassname a 1 a null c documentelement contains m contains function a b return a b a contains a contains b 0 c documentelement comparedocumentposition m contains function a b return a comparedocumentposition b 16 m contains function return 1 m isxml function a var b a a ownerdocument a 0 documentelement return b b nodename html 1 var y function a b c var d e f g b nodetype b b while d o match pseudo exec a f d 0 a a replace o match pseudo a o relative a a a for var h 0 i g length h i h m a g h e c return m filter f e m attr f attr m selectors attrmap f find m f expr m selectors f expr f expr filters f unique m uniquesort f text m gettext f isxmldoc m isxml f contains m contains var l until m parents prevuntil prevall n o p array prototype slice q f expr match pos r children 0 contents 0 next 0 prev 0 f fn extend find function a var b this c d if typeof a string return f a filter function for c 0 d b length c d c if f contains b c this return 0 var e this pushstack find a g h i for c 0 d this length c d c g e length f find a this c e if c 0 for h g h e length h for i 0 i g i if e i e h e splice h 1 break return e has function a var b f a return this filter function for var a 0 c b length a c a if f contains this b a return 0 not function a return this pushstack t this a 1 not a filter function a return this pushstack t this a 0 filter a is function a return a typeof a string q test a f a this context index this 0 0 f filter a this length 0 this filter a length 0 closest function a b var c d e g this 0 if f isarray a var h 1 while g g ownerdocument g b for d 0 d a length d f g is a d c push selector a d elem g level h g g parentnode h return c var i q test a typeof a string f a b this context 0 for d 0 e this length d e d g this d while g if i i index g 1 f find matchesselector g a c push g break g g parentnode if g g ownerdocument g b g nodetype 11 break c c length 1 f unique c c return this pushstack c closest a index function a if a return this 0 this 0 parentnode this prevall length 1 if typeof a string return f inarray this 0 f a return f inarray a jquery a 0 a this add function a b var c typeof a string f a b f makearray a a nodetype a a d f merge this get c return this pushstack s c 0 s d 0 d f unique d andself function return this add this prevobject f each parent function a var b a parentnode return b b nodetype 11 b null parents function a return f dir a parentnode parentsuntil function a b c return f dir a parentnode c next function a return f nth a 2 nextsibling prev function a return f nth a 2 previoussibling nextall function a return f dir a nextsibling prevall function a return f dir a previoussibling nextuntil function a b c return f dir a nextsibling c prevuntil function a b c return f dir a previoussibling c siblings function a return f sibling a parentnode firstchild a children function a return f sibling a firstchild contents function a return f nodename a iframe a contentdocument a contentwindow document f makearray a childnodes function a b f fn a function c d var e f map this b c l test a d c d typeof d string e f filter d e e this length 1 r a f unique e e this length 1 n test d m test a e e reverse return this pushstack e a p call arguments join f extend filter function a b c c a not a return b length 1 f find matchesselector b 0 a b 0 f find matches a b dir function a c d var e g a c while g g nodetype 9 d b g nodetype 1 f g is d g nodetype 1 e push g g g c return e nth function a b c d b b 1 var e 0 for a a a c if a nodetype 1 e b break return a sibling function a b var c for a a a nextsibling a nodetype 1 a b c push a return c var v abbr article aside audio canvas datalist details figcaption figure footer header hgroup mark meter nav output progress section summary time video w jquery d d null g x s y area br col embed hr img input link meta param w ig z w tbody i w ba script style i bb script object embed option style i bc new regexp v i bd checked s s checked i be java ecma script i bf s cdata bg option 1 select multiple multiple select legend 1 fieldset fieldset thead 1 table table tr 2 table tbody tbody table td 3 table tbody tr tr tbody table col 2 table tbody tbody colgroup colgroup table area 1 map map default 0 bh u c bg optgroup bg option bg tbody bg tfoot bg colgroup bg caption bg thead bg th bg td f support htmlserialize bg default 1 div div div f fn extend text function a if f isfunction a return this each function b var c f this c text a call this b c text if typeof a object a b return this empty append this 0 this 0 ownerdocument c createtextnode a return f text this wrapall function a if f isfunction a return this each function b f this wrapall a call this b if this 0 var b f a this 0 ownerdocument eq 0 clone 0 this 0 parentnode b insertbefore this 0 b map function var a this while a firstchild a firstchild nodetype 1 a a firstchild return a append this return this wrapinner function a if f isfunction a return this each function b f this wrapinner a call this b return this each function var b f this c b contents c length c wrapall a b append a wrap function a var b f isfunction a return this each function c f this wrapall b a call this c a unwrap function return this parent each function f nodename this body f this replacewith this childnodes end append function return this dommanip arguments 0 function a this nodetype 1 this appendchild a prepend function return this dommanip arguments 0 function a this nodetype 1 this insertbefore a this firstchild before function if this 0 this 0 parentnode return this dommanip arguments 1 function a this parentnode insertbefore a this if arguments length var a f clean arguments a push apply a this toarray return this pushstack a before arguments after function if this 0 this 0 parentnode return this dommanip arguments 1 function a this parentnode insertbefore a this nextsibling if arguments length var a this pushstack this after arguments a push apply a f clean arguments return a remove function a b for var c 0 d d this c null c if a f filter a d length b d nodetype 1 f cleandata d getelementsbytagname f cleandata d d parentnode d parentnode removechild d return this empty function;-2.3027344;-0.09104323;-2.2879822;-0.12233104;3.1405203;1.6451625;CODE
for var a 0 b b this a null a b nodetype 1 f cleandata b getelementsbytagname while b firstchild b removechild b firstchild return this clone function a b a a null 1 a b b null a b return this map function return f clone this a b html function a if a b return this 0 this 0 nodetype 1 this 0 innerhtml replace w null if typeof a string ba test a f support leadingwhitespace x test a bg z exec a 1 tolowercase a a replace y 1 2 try for var c 0 d this length c d c this c nodetype 1 f cleandata this c getelementsbytagname this c innerhtml a catch e this empty append a else f isfunction a this each function b var c f this c html a call this b c html this empty append a return this replacewith function a if this 0 this 0 parentnode if f isfunction a return this each function b var c f this d c html c replacewith a call this b d typeof a string a f a detach return this each function var b this nextsibling c this parentnode f this remove b f b before a f c append a return this length this pushstack f f isfunction a a a replacewith a this detach function a return this remove a 0 dommanip function a c d var e g h i j a 0 k if f support checkclone arguments length 3 typeof j string bd test j return this each function f this dommanip a c d 0 if f isfunction j return this each function e var g f this a 0 j call this e c g html b g dommanip a c d if this 0 i j j parentnode f support parentnode i i nodetype 11 i childnodes length this length e fragment i e f buildfragment a this k h e fragment h childnodes length 1 g h h firstchild g h firstchild if g c c f nodename g tr for var l 0 m this length n m 1 l m l d call c bi this l g this l e cacheable m 1 l n f clone h 0 0 h k length f each k bp return this f buildfragment function a b d var e g h i j a 0 b b 0 i b 0 ownerdocument b 0 i createdocumentfragment i c a length 1 typeof j string j length 512 i c j charat 0 bb test j f support checkclone bd test j f support html5clone bc test j g 0 h f fragments j h h 1 e h e e i createdocumentfragment f clean a i e d g f fragments j h e 1 return fragment e cacheable g f fragments f each appendto append prependto prepend insertbefore before insertafter after replaceall replacewith function a b f fn a function c var d e f c g this length 1 this 0 parentnode if g g nodetype 11 g childnodes length 1 e length 1 e b this 0 return this for var h 0 i e length h i h var j h 0 this clone 0 this get f e h b j d d concat j return this pushstack d a e selector f extend clone function a b c var d e g h f support html5clone bc test a nodename a clonenode 0 bo a if f support nocloneevent f support noclonechecked a nodetype 1 a nodetype 11 f isxmldoc a bk a h d bl a e bl h for g 0 d g g e g bk d g e g if b bj a h if c d bl a e bl h for g 0 d g g bj d g e g d e null return h clean function a b d e var g b b c typeof b createelement undefined b b ownerdocument b 0 b 0 ownerdocument c var h i for var j 0 k k a j null j typeof k number k if k continue if typeof k string if test k k b createtextnode k else k k replace y 1 2 var l z exec k 1 tolowercase m bg l bg default n m 0 o b createelement div b c bh appendchild o u b appendchild o o innerhtml m 1 k m 2 while n o o lastchild if f support tbody var p test k q l table p o firstchild o firstchild childnodes m 1 table p o childnodes for i q length 1 i 0 i f nodename q i tbody q i childnodes length q i parentnode removechild q i f support leadingwhitespace x test k o insertbefore b createtextnode x exec k 0 o firstchild k o childnodes var r if f support appendchecked if k 0 typeof r k length number for i 0 i r i bn k i else bn k k nodetype h push k h f merge h k if d g function a return a type be test a type for j 0 h j j if e f nodename h j script h j type h j type tolowercase text javascript e push h j parentnode h j parentnode removechild h j h j else if h j nodetype 1 var s f grep h j getelementsbytagname script g h splice apply h j 1 0 concat s d appendchild h j return h cleandata function a var b c d f cache e f event special g f support deleteexpando for var h 0 i i a h null h if i nodename f nodata i nodename tolowercase continue c i f expando if c b d c if b b events for var j in b events e j f event remove i j f removeevent i j b handle b handle b handle elem null g delete i f expando i removeattribute i removeattribute f expando delete d c var bq alpha i br opacity bs a z ms g bt d px i bu d bv de bw position absolute visibility hidden display block bx left right by top bottom bz ba bb f fn css function a c if arguments length 2 c b return this return f access this a c 0 function a c d return d b f style a c d f css a c f extend csshooks opacity get function a b if b var c bz a opacity opacity return c 1 c return a style opacity cssnumber fillopacity 0 fontweight 0 lineheight 0 opacity 0 orphans 0 widows 0 zindex 0 zoom 0 cssprops float f support cssfloat cssfloat stylefloat style function a c d e if a a nodetype 3 a nodetype 8 a style var g h i f camelcase c j a style k f csshooks i c f cssprops i i if d b if k get in k g k get a 1 e b return g return j c h typeof d h string g bv exec d d g 1 1 g 2 parsefloat f css a c h number if d null h number isnan d return h number f cssnumber i d px if k set in k d k set a d b try j c d catch l css function a c d var e g c f camelcase c g f csshooks c c f cssprops c c c cssfloat c float if g get in g e g get a 0 d b return e if bz return bz a c swap function a b c var d for var e in b d e a style e a style e b e c call a for e in b a style e d e f curcss f css f each height width function a b f csshooks b get function a c d var e if c if a offsetwidth 0 return bc a b d f swap a bw function e bc a b d return e set function a b if bt test b return b b parsefloat b if b 0 return b px f support opacity f csshooks opacity get function a b return br test b a currentstyle a currentstyle filter a style filter parsefloat regexp 1 100 b 1 set function a b var c a style d a currentstyle e f isnumeric b alpha opacity b 100 g d d filter c filter c zoom 1 if b 1 f trim g replace bq c removeattribute filter if d d filter return c filter bq test g g replace bq e g e f function f support reliablemarginright f csshooks marginright get function a b var c f swap a display inline block function b c bz a margin right marginright c a style marginright return c c defaultview c defaultview getcomputedstyle ba function a b var c d e b b replace bs 1 tolowercase d a ownerdocument defaultview e d getcomputedstyle a null c e getpropertyvalue b c f contains a ownerdocument documentelement a c f style a b return c c documentelement currentstyle bb function a b var c d e f a currentstyle a currentstyle b g a style f null g e g b f e bt test f bu test f c g left d a runtimestyle a runtimestyle left d a runtimestyle left a currentstyle left g left b fontsize 1em f 0 f g pixelleft px g left c d a runtimestyle left d return f auto f bz ba bb f expr f expr filters f expr filters hidden function a var b a offsetwidth c a offsetheight return b 0 c 0 f support reliablehiddenoffsets a style a style display f css a display none f expr filters visible function a return f expr filters hidden a var bd 20 g be bf r n g bg bh t r n r mg bi color date datetime datetime local email hidden month number password range search tel text time url week i bj about app app storage extension file res widget bk get head bl bm bn script b script script gi bo select textarea i bp s bq br w d bs f fn load bt bu bv bw bx try bv e href catch by bv c createelement a bv href bv bv href bw br exec bv tolowercase f fn extend load function a c d if typeof a string bs return bs apply this arguments if this length return this var e a indexof if e 0 var g a slice e a length a a slice 0 e var h get c f isfunction c d c c b typeof c object c f param c f ajaxsettings traditional h post var i this f ajax url a type h datatype html data c complete function a b c c a responsetext a isresolved a done function a c a i html g f div append c replace bn find g c d i each d c b a return this serialize function return f param this serializearray serializearray function return this map function return this elements f makearray this elements this filter function return this name this disabled this checked bo test this nodename bi test this type map function a b var c f this val return c null null f isarray c f map c function a c return name b name value a replace bf r n name b name value c replace bf r n get f each ajaxstart ajaxstop ajaxcomplete ajaxerror ajaxsuccess ajaxsend split function a b f fn b function a return this on b a f each get post function a c f c function a d e g f isfunction d g g e e d d b return f ajax type c url a data d success e datatype g f extend getscript function a c return f get a b c script getjson function a b c return f get a b c json ajaxsetup function a b b b a f ajaxsettings b a a f ajaxsettings b a b return a ajaxsettings url bv islocal bj test bw 1 global 0 type get contenttype application x www form urlencoded processdata 0 async 0 accepts xml application xml text xml html text html text text plain json application json text javascript bx contents xml xml html html json json responsefields xml responsexml text responsetext converters text a string text html 0 text json f parsejson text xml f parsexml flatoptions context 0 url 0 ajaxprefilter bz bt ajaxtransport bz bu ajax function a c function w a c l m if s 2 s 2 q cleartimeout q p b n m v readystate a 0 4 0 var o r u w c x l cb d v l b y z if a 200 a 300 a 304 if d ifmodified if y v getresponseheader last modified f lastmodified k y if z v getresponseheader etag f etag k z if a 304 w notmodified o 0 else try r cc d x w success o 0 catch a w parsererror u a else u w if w a w error a 0 a 0 v status a v statustext c w o h resolvewith e r w v h rejectwith e v w u v statuscode j j b t g trigger ajax o success error v d o r u i firewith e v w t g trigger ajaxcomplete v d f active f event trigger ajaxstop typeof a object c a a b c c var d f ajaxsetup c e d context d g e d e nodetype e instanceof f f e f event h f deferred i f callbacks once memory j d statuscode k l m n o p q r s 0 t u v readystate 0 setrequestheader function a b if s var c a tolowercase a m c m c a l a b return this getallresponseheaders function return s 2 n null getresponseheader function a var c if s 2 if o o while c bh exec n o c 1 tolowercase c 2 c o a tolowercase return c b null c overridemimetype function a s d mimetype a return this abort function a a a abort p p abort a w 0 a return this h promise v v success v done v error v fail v complete i add v statuscode function a if a var b if s 2 for b in a j b j b a b else b a v status v then b b return this d url a d url replace bg replace bl bw 1 d datatypes f trim d datatype tolowercase split bp d crossdomain null r br exec d url tolowercase d crossdomain r r 1 bw 1 r 2 bw 2 r 3 r 1 http 80 443 bw 3 bw 1 http 80 443 d data d processdata typeof d data string d data f param d data d traditional b bt d c v if s 2 return 1 t d global d type d type touppercase d hascontent bk test d type t f active 0 f event trigger ajaxstart if d hascontent d data d url bm test d url d data delete d data k d url if d cache 1 var x f now y d url replace bq 1 x d url y y d url bm test d url x d data d hascontent d contenttype 1 c contenttype v setrequestheader content type d contenttype d ifmodified k k d url f lastmodified k v setrequestheader if modified since f lastmodified k f etag k v setrequestheader if none match f etag k v setrequestheader accept d datatypes 0 d accepts d datatypes 0 d accepts d datatypes 0 d datatypes 0 bx q 0 01 d accepts for u in d headers v setrequestheader u d headers u if d beforesend d beforesend call e v d 1 s 2 v abort return 1 for u in success 1 error 1 complete 1 v u d u p b bu d c v if p w 1 no transport else v readystate 1 t g trigger ajaxsend v d d async d timeout 0 q settimeout function v abort timeout d timeout try s 1 p send l w catch z if s 2 w 1 z else throw z return v param function a c var d e function a b b f isfunction b b b d d length encodeuricomponent a encodeuricomponent b c b c f ajaxsettings traditional if f isarray a a jquery f isplainobject a f each a function e this name this value else for var g in a ca g a g c e return d join replace bd f extend active 0 lastmodified etag var cd f now ce i f ajaxsetup jsonp callback jsonpcallback function return f expando cd f ajaxprefilter json jsonp function b c d var e b contenttype application x www form urlencoded typeof b data string if b datatypes 0 jsonp b jsonp 1 ce test b url e ce test b data var g h b jsonpcallback f isfunction b jsonpcallback b jsonpcallback b jsonpcallback i a h j b url k b data l 1 h 2 b jsonp 1 j j replace ce l b url j e k k replace ce l b data k j test j b jsonp h b url j b data k a h function a g a d always function a h i g f isfunction i a h g 0 b converters script json function g f error h was not called return g 0 b datatypes 0 json return script f ajaxsetup accepts script text javascript application javascript application ecmascript application x ecmascript contents script javascript ecmascript converters text script function a f globaleval a return a f ajaxprefilter script function a a cache b a cache 1 a crossdomain a type get a global 1 f ajaxtransport script function a if a crossdomain var d e c head c getelementsbytagname head 0 c documentelement return send function f g d c createelement script d async async a scriptcharset d charset a scriptcharset d src a url d onload d onreadystatechange function a c if c d readystate loaded complete test d readystate d onload d onreadystatechange null e d parentnode e removechild d d b c g 200 success e insertbefore d e firstchild abort function d d onload 0 1 var cf a activexobject function for var a in ch ch a 0 1 1 cg 0 ch f ajaxsettings xhr a activexobject function return this islocal ci cj ci function a f extend f support ajax a cors a withcredentials in a f ajaxsettings xhr f support ajax f ajaxtransport function c if c crossdomain f support cors var d return send function e g var h c xhr i j c username h open c type c url c async c username c password h open c type c url c async if c xhrfields for j in c xhrfields h j c xhrfields j c mimetype h overridemimetype h overridemimetype c mimetype c crossdomain e x requested with e x requested with xmlhttprequest try for j in e h setrequestheader j e j catch k h send c hascontent c data null d function a e var j k l m n try if d e h readystate 4 d b i h onreadystatechange f noop cf delete ch i if e h readystate 4 h abort else j h status l h getallresponseheaders m n h responsexml n n documentelement m xml n m text h responsetext try k h statustext catch o k j c islocal c crossdomain j m text 200 404 j 1223 j 204 catch p e g 1 p m g j k m l c async h readystate 4 d i cg cf ch ch f a unload cf ch i d h onreadystatechange d abort function d d 0 1 var ck cl cm cn toggle show hide co d a z i cp cq height margintop marginbottom paddingtop paddingbottom width marginleft marginright paddingleft paddingright opacity cr f fn extend show function a b c var d e if a a 0 return this animate cu show 3 a b c for var g 0 h this length g h g d this g d style e d style display f data d olddisplay e none e d style display e f css d display none f data d olddisplay cv d nodename for g 0 g h g d this g if d style e d style display if e e none d style display f data d olddisplay return this hide function a b c if a a 0 return this animate cu hide 3 a b c var d e g 0 h this length for g h g d this g d style e f css d display e none f data d olddisplay f data d olddisplay e for g 0 g h g this g style this g style display none return this toggle f fn toggle toggle function a b c var d typeof a boolean f isfunction a f isfunction b this toggle apply this arguments a null d this each function var b d a f this is hidden f this b show hide this animate cu toggle 3 a b c return this fadeto function a b c d return this filter hidden css opacity 0 show end animate opacity b a c d animate function a b c d function g e queue 1 f mark this var b f extend e c this nodetype 1 d c f this is hidden g h i j k l m n o b animatedproperties for i in a g f camelcase i i g a g a i delete a i h a g f isarray h b animatedproperties g h 1 h a g h 0 b animatedproperties g b specialeasing b specialeasing g b easing swing if h hide d h show d return b complete call this c g height g width b overflow this style overflow this style overflowx this style overflowy f css this display inline f css this float none f support inlineblockneedslayout cv this nodename inline this style display inline block this style zoom 1 b overflow null this style overflow hidden for i in a j new f fx this b i h a i cn test h o f data this toggle i h toggle d show hide 0 o f data this toggle i o show hide show j o j h k co exec h l j cur k m parsefloat k 2 n k 3 f cssnumber i px n px f style this i m 1 n l m 1 j cur l f style this i l n k 1 m k 1 1 1 m l j custom l m n j custom l h return 0 var e f speed b c d if f isemptyobject a return this each e complete 1 a f extend a return e queue 1 this each g this queue e queue g stop function a c d typeof a string d c c a a b c a 1 this queue a fx return this each function function h a b c var e b c f removedata a c 0 e stop d var b c 1 e f timers g f data this d f unmark 0 this if a null for b in g g b g b stop b indexof run b length 4 h this g b else g b a run g b stop h this g b for b e length b e b elem this a null e b queue a d e b 0 e b savestate c 0 e splice b 1 d c f dequeue this a f each slidedown cu show 1 slideup cu hide 1 slidetoggle cu toggle 1 fadein opacity show fadeout opacity hide fadetoggle opacity toggle function a b f fn a function a c d return this animate b a c d f extend speed function a b c var d a typeof a object f extend a complete c c b f isfunction a a duration a easing c b b f isfunction b b d duration f fx off 0 typeof d duration number d duration d duration in f fx speeds f fx speeds d duration f fx speeds default if d queue null d queue 0 d queue fx d old d complete d complete function a f isfunction d old d old call this d queue f dequeue this d queue a 1 f unmark this return d easing linear function a b c d return c d a swing function a b c d return math cos a math pi 2 5 d c timers fx function a b c this options b this elem a this prop c b orig b orig f fx prototype update function this options step this options step call this elem this now this f fx step this prop f fx step default this cur function if this elem this prop null this elem style this elem style this prop null return this elem this prop var a b f css this elem this prop return isnan a parsefloat b b b auto 0 b a custom function a c d function h a return e step a var e this g f fx this starttime cr cs this end c this now this start a this pos this state 0 this unit d this unit f cssnumber this prop px h queue this options queue h elem this elem h savestate function e options hide f data e elem fxshow e prop b f data e elem fxshow e prop e start h f timers push h cp cp setinterval g tick g interval show function var a f data this elem fxshow this prop this options orig this prop a f style this elem this prop this options show 0 a b this custom this cur a this custom this prop width this prop height 1 0 this cur f this elem show hide function this options orig this prop f data this elem fxshow this prop f style this elem this prop this options hide 0 this custom this cur 0 step function a var b c d e cr cs g 0 h this elem i this options if a e i duration this starttime this now this end this pos this state 1 this update i animatedproperties this prop 0 for b in i animatedproperties i animatedproperties b 0 g 1 if g i overflow null f support shrinkwrapblocks f each x y function a b h style overflow b i overflow a i hide f h hide if i hide i show for b in i animatedproperties f style h b i orig b f removedata h fxshow b 0 f removedata h toggle b 0 d i complete d i complete 1 d call h return 1 i duration infinity this now e c e this starttime this state c i duration this pos f easing i animatedproperties this prop this state c 0 1 i duration this now this start this end this start this pos this update return 0 f extend f fx tick function var a b f timers c 0 for c b length c a b c a b c a b splice c 1 b length f fx stop interval 13 stop function clearinterval cp cp null speeds slow 600 fast 200 default 400 step opacity function a f style a elem opacity a now default function a a elem style a elem style a prop null a elem style a prop a now a unit a elem a prop a now f each width height function a b f fx step b function a f style a elem b math max 0 a now a unit f expr f expr filters f expr filters animated function a return f grep f timers function b return a b elem length var cw t able d h i cx body html i getboundingclientrect in c documentelement f fn offset function a var b this 0 c if a return this each function b f offset setoffset this a b if b b ownerdocument return null if b b ownerdocument body return f offset bodyoffset b try c b getboundingclientrect catch d var e b ownerdocument g e documentelement if c f contains g b return c top c top left c left top 0 left 0 var h e body i cy e j g clienttop h clienttop 0 k g clientleft h clientleft 0 l i pageyoffset f support boxmodel g scrolltop h scrolltop m i pagexoffset f support boxmodel g scrollleft h scrollleft n c top l j o c left m k return top n left o f fn offset function a var b this 0 if a return this each function b f offset setoffset this a b if b b ownerdocument return null if b b ownerdocument body return f offset bodyoffset b var c d b offsetparent e b g b ownerdocument h g documentelement i g body j g defaultview k j j getcomputedstyle b null b currentstyle l b offsettop m b offsetleft while b b parentnode b i b h if f support fixedposition k position fixed break c j j getcomputedstyle b null b currentstyle l b scrolltop m b scrollleft b d l b offsettop m b offsetleft f support doesnotaddborder f support doesaddborderfortableandcells cw test b nodename l parsefloat c bordertopwidth 0 m parsefloat c borderleftwidth 0 e d d b offsetparent f support subtractsborderforoverflownotvisible c overflow visible l parsefloat c bordertopwidth 0 m parsefloat c borderleftwidth 0 k c if k position relative k position static l i offsettop m i offsetleft f support fixedposition k position fixed l math max h scrolltop i scrolltop m math max h scrollleft i scrollleft return top l left m f offset bodyoffset function a var b a offsettop c a offsetleft f support doesnotincludemargininbodyoffset b parsefloat f css a margintop 0 c parsefloat f css a marginleft 0 return top b left c setoffset function a b c var d f css a position d static a style position relative var e f a g e offset h f css a top i f css a left j d absolute d fixed f inarray auto h i 1 k l m n j l e position m l top n l left m parsefloat h 0 n parsefloat i 0 f isfunction b b b call a c g b top null k top b top g top m b left null k left b left g left n using in b b using call a k e css k f fn extend position function if this 0 return null var a this 0 b this offsetparent c this offset d cx test b 0 nodename top 0 left 0 b offset c top parsefloat f css a margintop 0 c left parsefloat f css a marginleft 0 d top parsefloat f css b 0 bordertopwidth 0 d left parsefloat f css b 0 borderleftwidth 0 return top c top d top left c left d left offsetparent function return this map function var a this offsetparent c body while a cx test a nodename f css a position static a a offsetparent return a f each left top function a c var d scroll c f fn d function c var e g if c b e this 0 if e return null g cy e return g pagexoffset in g g a pageyoffset pagexoffset f support boxmodel g document documentelement d g document body d e d return this each function g cy this g g scrollto a f g scrollleft c a c f g scrolltop this d c f each height width function a c var d c tolowercase f fn inner c function var a this 0 return a a style parsefloat f css a d padding this d null f fn outer c function a var b this 0 return b b style parsefloat f css b d a margin border this d null f fn d function a var e this 0 if e return a null null this if f isfunction a return this each function b var c f this c d a call this b c d if f iswindow e var g e document documentelement client c h e document body return e document compatmode css1compat g h h client c g if e nodetype 9 return math max e documentelement client c e body scroll c e documentelement scroll c e body offset c e documentelement offset c if a b var i f css e d j parsefloat i return f isnumeric j j i return this css d typeof a string a a px a jquery a f typeof define function define amd define amd jquery define jquery function return f window;-1.8324921;1.558641;-2.623651;-0.8334251;3.6448061;-0.33266008;CODE
raphael el popup function d k h g var c this paper this 0 paper f j b e a if c return switch this type case text case circle case ellipse b true break default b false d d null up d k k 5 f this getbbox h typeof h number h b f x f width 2 f x g typeof g number g b f y f height 2 f y e math max f width 2 k 0 a math max f height 2 k 0 this translate h f x b f width 2 0 g f y b f height 2 0 f this getbbox var i up m h g l k k e 0 a k k 0 0 1 k k l 0 f height a k k 0 0 1 k k l k 2 e 2 0 a k k 0 0 1 k k l 0 f height a k k 0 0 1 k k l e 0 z join down m h g l k k e 0 a k k 0 0 1 k k l 0 f height a k k 0 0 1 k k l k 2 e 2 0 a k k 0 0 1 k k l 0 f height a k k 0 0 1 k k l e 0 z join left m h g l k k 0 a a k k 0 0 1 k k l f width 0 a k k 0 0 1 k k l 0 k 2 a 2 a k k 0 0 1 k k l f width 0 a k k 0 0 1 k k l 0 a z join right m h g l k k 0 a a k k 0 0 1 k k l f width 0 a k k 0 0 1 k k l 0 k 2 a 2 a k k 0 0 1 k k l f width 0 a k k 0 0 1 k k l 0 a z join j up x b f width 2 y k 2 b f height 2 f height down x b f width 2 y k 2 b f height 2 f height left x k 2 b f width 2 f width y b f height 2 right x k 2 b f width 2 f width y b f height 2 d this translate j x j y return c path i d attr fill 000 stroke none insertbefore this node this this 0 raphael el tag function f b l k var i 3 e this paper this 0 paper if e return var c e path attr fill 000 stroke 000 j this getbbox m h a g switch this type case text case circle case ellipse a true break default a false f f 0 l typeof l number l a j x j width 2 j x k typeof k number k a j y j height 2 j y b b null 5 b h 0 5522 b if j height b 2 c attr path m l k b a b b 0 1 1 0 b 2 b b 0 1 1 0 b 2 m 0 b 2 i a b i b i 0 1 0 0 b i 2 l l b i k j height 2 i l j width 2 i 0 0 j height 2 i j width 2 i 0 l l k b i join else m math sqrt math pow b i 2 math pow j height 2 i 2 c attr path m l k b c h 0 b h b b b 0 h b h b b b h 0 b b h b b 0 h h b b b b m l m k j height 2 i a b i b i 0 1 0 0 j height 2 i l b i m j width 2 i 0 0 j height 2 i l l m k j height 2 i join f 360 f c rotate f l k if this attrs this attr this attrs x x cx l b i a this type text j width 0 j width 2 attr y a k k j height 2 this rotate f l k f 90 f 270 this attr this attrs x x cx l b i a j width j width 2 rotate 180 l k else if f 90 f 270 this translate l j x j width b i k j y j height 2 this rotate f 180 j x j width b i j y j height 2 else this translate l j x b i k j y j height 2 this rotate f j x b i j y j height 2 return c insertbefore this node this this 0 raphael el drop function d g f var e this getbbox c this paper this 0 paper a j b i h if c return switch this type case text case circle case ellipse a true break default a false d d 0 g typeof g number g a e x e width 2 e x f typeof f number f a e y e height 2 e y j math max e width e height math min e width e height b c path m g f l j 0 a j 0 4 j 0 4 0 1 0 g j 0 7 f j 0 7 z attr fill 000 stroke none rotate 22 5 d g f d d 90 math pi 180 i g j math sin d a 0 e width 2 h f j math cos d a 0 e height 2 this attrs this attr this attrs x x cx i attr this attrs y y cy h this translate i e x h e y return b insertbefore this node this this 0 raphael el flag function e k j var g 3 c this paper this 0 paper if c return var b c path attr fill 000 stroke 000 i this getbbox f i height 2 a switch this type case text case circle case ellipse a true break default a false e e 0 k typeof k number k a i x i width 2 i x j typeof j number j a i y i height 2 i y b attr path m k j l f g f g i width 2 g 0 0 i height 2 g i width 2 g 0 z join e 360 e b rotate e k j if this attrs this attr this attrs x x cx k f g a this type text i width 0 i width 2 attr y a j j i height 2 this rotate e k j e 90 e 270 this attr this attrs x x cx k f g a i width i width 2 rotate 180 k j else if e 90 e 270 this translate k i x i width f g j i y i height 2 this rotate e 180 i x i width f g i y i height 2 else this translate k i x f g j i y i height 2 this rotate e i x f g i y i height 2 return b insertbefore this node this this 0 raphael el label function var c this getbbox b this paper this 0 paper a math min 20 c width 10 c height 10 2 if b return return b rect c x a 2 c y a 2 c width a c height a a attr stroke none fill 000 insertbefore this node this this 0 raphael el blob function z j i var g this getbbox b math pi 180 n this paper this 0 paper r a q if n return switch this type case text case circle case ellipse a true break default a false r n path attr fill 000 stroke none z z 1 z 45 90 q math min g height g width j typeof j number j a g x g width 2 g x i typeof i number i a g y g height 2 g y var m math max g width q q 25 12 t math max g height q q 25 12 u j q math sin z 22 5 b b i q math cos z 22 5 b v j q math sin z 22 5 b d i q math cos z 22 5 b o v u 2 l d b 2 f m 2 e t 2 s math sqrt math abs f f e e f f l l e e o o f f l l e e o o c s f l e v u 2 a s e o f d b 2 r attr x c y a path m j i l v d a f e 0 1 1 u b z join this translate c g x g width 2 a g y g height 2 return r insertbefore this node this this 0 raphael fn label function a d b var c this set b this text a d b attr raphael g txtattr return c push b label b raphael fn popup function a f d b c var e this set d this text a f d attr raphael g txtattr return e push d popup b c d raphael fn tag function a f d c b var e this set d this text a f d attr raphael g txtattr return e push d tag c b d raphael fn flag function a e c b var d this set c this text a e c attr raphael g txtattr return d push c flag b c raphael fn drop function a e c b var d this set c this text a e c attr raphael g txtattr return d push c drop b c raphael fn blob function a e c b var d this set c this text a e c attr raphael g txtattr return d push c blob b c raphael el lighter function b b b 2 var a this attrs fill this attrs stroke this fs this fs a 0 a 1 a 0 raphael rgb2hsb raphael getrgb a 0 hex a 1 raphael rgb2hsb raphael getrgb a 1 hex a 0 b math min a 0 b b 1 a 0 s a 0 s b a 1 b math min a 1 b b 1 a 1 s a 1 s b this attr fill hsb a 0 h a 0 s a 0 b stroke hsb a 1 h a 1 s a 1 b return this raphael el darker function b b b 2 var a this attrs fill this attrs stroke this fs this fs a 0 a 1 a 0 raphael rgb2hsb raphael getrgb a 0 hex a 1 raphael rgb2hsb raphael getrgb a 1 hex a 0 s math min a 0 s b 1 a 0 b a 0 b b a 1 s math min a 1 s b 1 a 1 b a 1 b b this attr fill hsb a 0 h a 0 s a 0 b stroke hsb a 1 h a 1 s a 1 b return this raphael el resetbrightness function if this fs this attr fill this fs 0 stroke this fs 1 delete this fs return this function var c lighter darker resetbrightness a popup tag flag label drop blob for var b in a function d raphael st d function return raphael el d apply this arguments a b for var b in c function d raphael st d function for var e 0 e this length e this e d apply this e arguments return this c b raphael g shim stroke none fill 000 fill opacity 0 txtattr font 12px arial sans serif fill fff colors function var c 0 6 0 2 0 05 0 1333 0 75 0 a for var b 0 b 10 b if b c length a push hsb c b 75 75 else a push hsb c b c length 1 5 return a snapends function j k h var e j l k if e l return from e to l power 0 function m d return math abs d 0 5 0 25 d 0 5 math round d var g l e h a g c a b 0 if a while c b c g math pow 10 b math pow 10 b b else while a b b 1 a g math pow 10 b math pow 10 b b b b l m k math pow 10 b math pow 10 b if l k l m k 0 5 math pow 10 b math pow 10 b e m j b 0 0 0 5 math pow 10 b math pow 10 b return from e to l power b axis function p o k d e g g j h a q a a null 2 a h h t g g 10 q arguments arguments length 1 var c h h m p 0 5 o l 0 0 001 g 1 g 3 m p 0 5 o l 0 k m p o 0 5 l k 0 s this snapends d e g h s from z s to f s power e 0 w font 11px fontin sans fontin sans sans serif v q set i i z h g var n h m f 0 f 0 r k g if g 1 g 3 var b o u g 1 1 1 a 3 g 1 while b o k h h c c concat m p h h a g 1 a 2 b 0 5 l a 2 1 0 v push q text p u b j j e math round n n n n tofixed m attr w attr text anchor g 1 start end n i b r if math round b r o k h h c c concat m p h h a g 1 a 2 o k 0 5 l a 2 1 0 v push q text p u o k j j e math round n n n n tofixed m attr w attr text anchor g 1 start end else n h m f 0 f u g 1 1 a 9 g var c p r k g a 0 b 0 while c p k h h c c concat m c 0 5 o h a g a 2 l 0 a 2 1 v push a q text c o u j j e math round n n n n tofixed m attr w var l a getbbox if b l x 5 v pop v length 1 remove else b l x l width n i c r if math round c r p k h h c c concat m p k 0 5 o h a g a 2 l 0 a 2 1 v push q text p k o u j j e math round n n n n tofixed m attr w var k q path c k text v k all q set k v k remove function this text remove this constructor prototype remove call this return k labelise function a c b if a return a replace g function d f e if f return c tofixed f replace g length if e return c 100 b tofixed e replace g length else return c tofixed 0;1.2859802;0.95515525;1.5628513;-8.922824;-1.5152901;-0.37987494;CODE
function function a g n var f g length n h 0 e f m 0 i while h g length e if e 0 m g h 1 e i push m f m g h e e f else m g h return i function d f e p n k j var h p f 2 g k p 2 q math atan p f math abs n e o math atan k p math abs n j q e n math pi q q o j n math pi o o var i math pi 2 q o math pi 2 2 s h math sin i q m h math cos i q r g math sin i o l g math cos i o return x1 p s y1 n m x2 p r y2 n l function b f p o e h a z j var s this j j if f raphael is a 0 array a a if f raphael is z 0 array z z var q j gutter 10 b math max a 0 length z 0 length t j symbol s j colors s colors v null p null ad f set t for var ac 0 l z length ac l ac b math max b z ac length var ae f set for ac 0 l z length ac l ac if j shade ae push f path attr stroke none fill s ac opacity j nostroke 1 0 3 if z ac length e 2 q z ac a z ac e 2 q b e 2 q if a ac a ac length e 2 q a ac a a ac e 2 q var w array prototype concat apply a u array prototype concat apply z u s snapends math min apply math w math max apply math w a 0 length 1 e u from o u to n s snapends math min apply math u math max apply math u z 0 length 1 c n from n n to z e q 2 o e 1 v h q 2 n c 1 var g f set if j axis var m j axis split s m 0 g push s axis p q o q e 2 q e o j axisxstep math floor e 2 q 20 2 f m 1 g push s axis p e q o h q h 2 q c n j axisystep math floor h 2 q 20 3 f m 2 g push s axis p q o h q e 2 q e o j axisxstep math floor e 2 q 20 0 f m 3 g push s axis p q o h q h 2 q c n j axisystep math floor h 2 q 20 1 f var m f set aa f set r for ac 0 l z length ac l ac if j nostroke m push r f path attr stroke s ac stroke width j width 2 stroke linejoin round stroke linecap round stroke dasharray j dash var g raphael is t array t ac t h f set t for var ab 0 w z ac length ab w ab var l p q a ac a 0 ab e z k o h q z ac ab c v raphael is g array g ab g h push f raphael is g array g ab g l k j width 2 3 attr fill s ac stroke none if j smooth if ab ab w 1 var r p q a ac a 0 ab 1 e z f o h q z ac ab 1 c v q p q a ac a 0 ab 1 e z d o h q z ac ab 1 c v af d r f l k q d t t concat af x1 af y1 l k af x2 af y2 if ab t m l k c l k else t t concat ab l m l k if j smooth t t concat l k l k aa push h if j shade ae ac attr path t concat l l o h q l p q a ac a 0 0 e z o h q z join j nostroke r attr path t join function k an var ak for var al 0 ap a length al ap al ak ak concat a al ak sort var aq ah for al 0 ap ak length al ap al ak al ak al 1 aq push ak al ah push p q ak al e z ak aq ap ak length var ag an f set for al 0 al ap al var y ah al ah al ah al 1 p 2 ao ah al 1 p e ah al 2 ah al ah al 1 p 2 x an x ag push x f rect y 1 o math max ao 1 1 h attr stroke none fill 000 opacity 0 x values x symbols f set x y x x ah al x axis ak al for var aj 0 am z length aj am aj aq a aj a 0 for var ai 0 y aq length ai y ai if aq ai ak al x values push z aj ai x y push o h q z aj ai c v x symbols push ad symbols aj ai an an call x an v ag function i al var ah al f set x for var aj 0 an z length aj an aj for var ai 0 ak z aj length ai ak ai var ag p q a aj a 0 ai e z am p q a aj a 0 ai ai 1 1 e z y o h q z aj ai c v al x ah push x f circle ag y math abs am ag 2 attr stroke none fill 000 opacity 0 x x ag x y y x value z aj ai x line ad lines aj x shade ad shades aj x symbol ad symbols aj ai x symbols ad symbols aj x axis a aj a 0 ai al al call x al p ah ad push m ae aa g v p ad lines m ad shades ae ad symbols aa ad axis g ad hovercolumn function j i v k v mouseover j mouseout i return this ad clickcolumn function i v k v click i return this ad hrefcolumn function y var ag f raphael is arguments 0 array arguments 0 arguments if arguments length 1 typeof y object for var j in y for var y 0 x v length y x y if v y axis j v y attr href y j v k for y 0 x ag length y x y v y v y attr href ag y return this ad hover function j i p i p mouseover j mouseout i return this ad click function i p i p click i return this ad each function i i i return this ad eachcolumn function i k i return this return ad var c function c prototype raphael g b prototype new c raphael fn linechart function f k g e j i h return new b this f k g e j i h;2.3149347;2.1762311;-1.3849357;-6.3024945;-0.43745103;-1.2892853;CODE
function a var b 0 3 4 c hasownproperty d e f function g function a b return a b h i j n k function a b var c j d i e array prototype slice call arguments 2 f k listeners a l 0 m 1 n o p q r h s h a i 0 for var t 0 u f length t u t zindex in f t o push f t zindex f t zindex 0 p f t zindex f t o sort g while o l 0 n p o l q push n apply b e if i i d return q for t 0 t u t n f t if zindex in n if n zindex o l q push n apply b e if i break do l n p o l n q push n apply b e if i break while n else p n zindex n else q push n apply b e if i break i d h r return q length q null k listeners function a var b a split d c j f g h i k l m n o c p for i 0 k b length i k i n for l 0 m o length l m l c o l n g c b i c e h 2 while h f g h f n push f p p concat f f o n return p k on function a b var c a split d e j for var g 0 h c length g h g e e n e c g e c g n e e c g e f e f for g 0 h e f length g h g if e f g b return f e f push b return function a a a b zindex a k stop function i 1 k nt function a if a return new regexp a test h return h k off k unbind function a b var f a split d g h i k l m n o j for k 0 l f length k l k for m 0 m o length m i length 2 i m 1 g o m n if f k e g f k i push g f k else for h in g g c h i push g h o splice apply o i for k 0 l o length k l k g o k while g n if b if g f for m 0 n g f length m n m if g f m b g f splice m 1 break g f length delete g f for h in g n if g n c h g n h f var p g n h f for m 0 n p length m n m if p m b p splice m 1 break p length delete g n h f else delete g f for h in g n g n c h g n h f delete g n h f g g n k once function a b var c function var d b apply this arguments k unbind a c return d return k on a c k version b k tostring function return you are running eve b typeof module undefined module exports module exports k typeof define undefined define eve function return k a eve k this function function cf a for var b 0 b cy length b cy b el paper a cy splice b 1 function ce b d e f h i e q e var j k l m o p q t b ms u v w if f for y 0 z cy length y z y var x cy y if x el id d id x anim b x percent e cy splice y 1 l 1 k x d attr x totalorigin break else f v for var y 0 z b percents length y z y if b percents y e b percents y f b top e b percents y p b percents y 1 0 t t b top e p o b percents y 1 j b anim e break f d attr b anim b percents y if j if k for var a in j if j g a if u g a d paper customattributes g a u a d attr a u a null u a t a v a j a switch u a case c w a v a u a t break case colour u a a getrgb u a var b a getrgb v a w a r b r u a r t g b g u a g t b b b u a b t break case path var d br u a v a e d 1 u a d 0 w a for y 0 z u a length y z y w a y 0 for var f 1 g u a y length f g f w a y f e y f u a y f t break case transform var h d i ca h a v a if i u a i from v a i to w a w a real 0 for y 0 z u a length y z y w a y u a y 0 for f 1 g u a y length f g f w a y f v a y f u a y f t else var j d matrix new cb k transform h transform getbbox function return d getbbox 1 u a j a j b j c j d j e j f b k v a v a k transform w a k matrix a j a t k matrix b j b t k matrix c j c t k matrix d j d t k matrix e j e t k matrix f j f t break case csv var l r j a s c m r u a s c if a clip rect u a m w a y m length while y w a y l y u a y t v a l break default l n j a m n u a w a y d paper customattributes a length while y w a y l y 0 m y 0 t var o j easing p a easing formulas o if p p r o match n if p p length 5 var r p p function a return cc a r 1 r 2 r 3 r 4 t else p bf q j start b start new date x anim b percent e timestamp q start q b del 0 status 0 initstatus f 0 stop 1 ms t easing p from u diff w to v el d callback j callback prev p next o repeat i b times origin d attr totalorigin h cy push x if f k l x stop 0 x start new date t f if cy length 1 return ca l x start new date x ms f cy length 1 cz ca else k initstatus f k start new date k ms f eve raphael anim start d id d b function cd a b var c d this ms b this times 1 if a for var e in a a g e d q e a e c push q e c sort bd this anim d this top c c length 1 this percents c function cc a b c d e f function o a b var c d e f j k for e a k 0 k 8 k f m e a if z f b return e j 3 i e 2 h e g if z j 1e 6 break e e f j c 0 d 1 e a if e c return c if e d return d while c d f m e if z f a b return e a f c e d e e d c 2 c return e function n a b var c o a b return l c k c j c function m a return i a h a g a var g 3 b h 3 d b g i 1 g h j 3 c k 3 e c j l 1 j k return n a 1 200 f function cq return this x q this y q this width this height function cp return this x q this y function cb a b c d e f a null this a a this b b this c c this d d this e e this f f this a 1 this b 0 this c 0 this d 1 this e 0 this f 0 function bh b c d b a path2curve b c a path2curve c var e f g h i j k l m n o d 0 for var p 0 q b length p q p var r b p if r 0 m e i r 1 f j r 2 else r 0 c m e f concat r slice 1 e m 6 f m 7 m e f e f i j i j e i f j for var s 0 t c length s t s var u c s if u 0 m g k u 1 h l u 2 else u 0 c n g h concat u slice 1 g n 6 h n 7 n g h g h k l k l g k h l var v bg m n d if d o v else for var w 0 x v length w x w v w segment1 p v w segment2 s v w bez1 m v w bez2 n o o concat v return o function bg b c d var e a bezierbbox b f a bezierbbox c if a isbboxintersect e f return d 0 var g bb apply 0 b h bb apply 0 c i g 5 j h 5 k l m n d 0 for var o 0 o i 1 o var p a finddotsatsegment apply a b concat o i k push x p x y p y t o i for o 0 o j 1 o p a finddotsatsegment apply a c concat o j l push x p x y p y t o j for o 0 o i o for var q 0 q j q var r k o s k o 1 t l q u l q 1 v z s x r x 001 y x w z u x t x 001 y x x bd r x r y s x s y t x t y u x u y if x if m x x tofixed 4 x y tofixed 4 continue m x x tofixed 4 x y tofixed 4 var y r t z x v r v s v r v s t r t a t t z x w t w u w t w u t t t y 0 y 1 a 0 a 1 d n n push x x x y x y t1 y t2 a return n function bf a b return bg a b 1 function be a b return bg a b function bd a b c d e f g h if x a c y e g y a c x e g x b d y f h y b d x f h var i a d b c e g a c e h f g j a d b c f h b d e h f g k a c f h b d e g if k return var l i k m j k n l tofixed 2 o m tofixed 2 if n y a c tofixed 2 n x a c tofixed 2 n y e g tofixed 2 n x e g tofixed 2 o y b d tofixed 2 o x b d tofixed 2 o y f h tofixed 2 o x f h tofixed 2 return return x l y m function bc a b c d e f g h i if i 0 bb a b c d e f g h i var j 1 k j 2 l j k m n 01 m bb a b c d e f g h l while z m i n k 2 l m i 1 1 k m bb a b c d e f g h l return l function bb a b c d e f g h i i null i 1 i i 1 1 i 0 0 i var j i 2 k 12 l 0 1252 1252 0 3678 3678 0 5873 5873 0 7699 7699 0 9041 9041 0 9816 9816 m 2491 2491 2335 2335 2032 2032 1601 1601 1069 1069 0472 0472 n 0 for var o 0 o k o var p j l o j q ba p a c e g r ba p b d f h s q q r r n m o w sqrt s return j n function ba a b c d e var f 3 b 9 c 9 d 3 e g a f 6 b 12 c 6 d return a g 3 b 3 c function by a b var c for var d 0 e a length e 2 b d d 2 var f x a d 2 y a d 1 x a d y a d 1 x a d 2 y a d 3 x a d 4 y a d 5 b d e 4 d f 3 x a 0 y a 1 e 2 d f 2 x a 0 y a 1 f 3 x a 2 y a 3 f 0 x a e 2 y a e 1 e 4 d f 3 f 2 d f 0 x a d y a d 1 c push c f 0 x 6 f 1 x f 2 x 6 f 0 y 6 f 1 y f 2 y 6 f 1 x 6 f 2 x f 3 x 6 f 1 y 6 f 2 y f 3 y 6 f 2 x f 2 y return c function bx return this hex function bv a b c function d var e array prototype slice call arguments 0 f e join h d cache d cache i d count d count if h g f bu i f return c c h f h f i length 1e3 delete h i shift i push f h f a m b e return c c h f h f return d function bu a b for var c 0 d a length c d c if a c b return a push a splice c 1 0 function bm a if object a a return a var b new a constructor for var c in a a g c b c bm a c return b function a c if a is c function return b c eve on raphael domload c if a is c e return a engine create m a c splice 0 3 a is c 0 c add c var d array prototype slice call arguments 0 if a is d d length 1 function var e d pop return b e call a engine create m a d eve on raphael domload function e call a engine create m a d return a engine create m a arguments a version 2 1 0 a eve eve var b c d circle 1 rect 1 path 1 ellipse 1 text 1 image 1 e d g f prototype g hasownproperty h doc document win window i was object prototype g call h win raphael is h win raphael j function this ca this customattributes k l appendchild m apply n concat o createtouch in h doc p q r string s split t click dblclick mousedown mousemove mouseout mouseover mouseup touchstart touchmove touchend touchcancel s q u mousedown touchstart mousemove touchmove mouseup touchend v r prototype tolowercase w math x w max y w min z w abs a w pow b w pi c number d string e array f tostring g fill h object prototype tostring i j push k a isurl url i l s a f d 6 a f d 3 rgba s d s s d s s d s s d s hsba s d deg xb0 s s d s s d s s d s hsla s d deg xb0 s s d s s d s s d s s i m nan 1 infinity 1 infinity 1 n cubic bezier o w round p setattribute q parsefloat r parseint s r prototype touppercase t a availableattrs arrow end none arrow start none blur 0 clip rect 0 0 1e9 1e9 cursor default cx 0 cy 0 fill fff fill opacity 1 font 10px arial font family arial font size 10 font style normal font weight 400 gradient 0 height 0 href http raphaeljs com letter spacing 0 opacity 1 path m0 0 r 0 rx 0 ry 0 src stroke 000 stroke dasharray stroke linecap butt stroke linejoin butt stroke miterlimit 0 stroke opacity 1 stroke width 1 target blank text anchor middle title raphael transform width 0 x 0 y 0 u a availableanimattrs blur c clip rect csv cx c cy c fill colour fill opacity c font size c height c opacity c path path r c rx c ry c stroke colour stroke opacity c stroke width c transform transform width c x c y c v x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 g w x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 x hs 1 rg 1 y achlmqrstvxz gi z achlmrqstvz x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 d d e d x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 ig rstm x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 d d e d x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 ig d d e d x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 ig ba a radial gradient r x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 x09 x0a x0b x0c x0d x20 xa0 u1680 u180e u2000 u2001 u2002 u2003 u2004 u2005 u2006 u2007 u2008 u2009 u200a u202f u205f u3000 u2028 u2029 bb bc function a b return a key b key bd function a b return q a q b be function bf function a return a bg a rectpath function a b c d e if e return m a e b l c e 2 0 a e e 0 0 1 e e l 0 d e 2 a e e 0 0 1 e e l e 2 c 0 a e e 0 0 1 e e l 0 e 2 d a e e 0 0 1 e e z return m a b l c 0 l 0 d l c 0 z bh function a b c d d null d c return m a b m 0 d a c d 0 1 1 0 2 d a c d 0 1 1 0 2 d z bi a getpath path function a return a attr path circle function a var b a attrs return bh b cx b cy b r ellipse function a var b a attrs return bh b cx b cy b rx b ry rect function a var b a attrs return bg b x b y b width b height b r image function a var b a attrs return bg b x b y b width b height text function a var b a getbbox return bg b x b y b width b height bj a mappath function a b if b return a var c d e f g h i a br a for e 0 g a length e g e i a e for f 1 h i length f h f 2 c b x i f i f 1 d b y i f i f 1 i f c i f 1 d return a a g h a type h win svgangle h doc implementation hasfeature http www w3 org tr svg11 feature basicstructure 1 1 svg vml if a type vml var bk h doc createelement div bl bk innerhtml v shape adj 1 bl bk firstchild bl style behavior url default vml if bl typeof bl adj object return a type p bk null a svg a vml a type vml a paper j a fn k j prototype a prototype a id 0 a oid 0 a is function a b b v call b if b finite return m g a if b array return a instanceof array return b null a null b typeof a a null b object a object a b array array isarray array isarray a h call a slice 8 1 tolowercase b a angle function b c d e f g if f null var h b d i c e if h i return 0 return 180 w atan2 i h 180 b 360 360 return a angle b c f g a angle d e f g a rad function a return a 360 b 180 a deg function a return a 180 b 360 a snapto function b c d d a is d finite d 10 if a is b e var e b length while e if z b e c d return b e else b b var f c b if f d return c f if f b d return c f b return c var bn a createuuid function a b return function return xxxxxxxx xxxx 4xxx yxxx xxxxxxxxxxxx replace a b touppercase xy g function a var b w random 16 0 c a x b b 3 8 return c tostring 16 a setwindow function b eve raphael setwindow a h win b h win b h doc h win document a engine initwin a engine initwin h win var bo function b if a vml var c s s g d try var e new activexobject htmlfile e write body e close d e body catch f d createpopup document body var g d createtextrange bo bv function a try d style color r a replace c p var b g querycommandvalue forecolor b b 255 16 b 65280 b 16711680 16 return 000000 b tostring 16 slice 6 catch e return none else var i h doc createelement i i title rapha l colour picker i style display none h doc body appendchild i bo bv function a i style color a return h doc defaultview getcomputedstyle i p getpropertyvalue color return bo b bp function return hsb this h this s this b bq function return hsl this h this s this l br function return this hex bs function b c d c null a is b object r in b g in b b in b d b b c b g b b r if c null a is b d var e a getrgb b b e r c e g d e b if b 1 c 1 d 1 b 255 c 255 d 255 return b c d bt function b c d e b 255 c 255 d 255 var f r b g c b d hex a rgb b c d tostring br a is e finite f opacity e return f a color function b var c a is b object h in b s in b b in b c a hsb2rgb b b r c r b g c g b b c b b hex c hex a is b object h in b s in b l in b c a hsl2rgb b b r c r b g c g b b c b b hex c hex a is b string b a getrgb b a is b object r in b g in b b in b c a rgb2hsl b b h c h b s c s b l c l c a rgb2hsb b b v c b b hex none b r b g b b b h b s b v b l 1 b tostring br return b a hsb2rgb function a b c d this is a object h in a s in a b in a c a b b a s a a h d a o a 360 var e f g h i a a 360 60 i c b h i 1 z a 2 1 e f g c i a a e i h 0 0 h i a f h i i h 0 0 a g 0 0 h i i h a return bt e f g d a hsl2rgb function a b c d this is a object h in a s in a l in a c a l b a s a a h if a 1 b 1 c 1 a 360 b 100 c 100 a 360 var e f g h i a a 360 60 i 2 b c 5 c 1 c h i 1 z a 2 1 e f g c i 2 a a e i h 0 0 h i a f h i i h 0 0 a g 0 0 h i i h a return bt e f g d a rgb2hsb function a b c c bs a b c a c 0 b c 1 c c 2 var d e f g f x a b c g f y a b c d g 0 null f a b c g f b c a g 2 a b g 4 d d 360 6 60 360 e g 0 0 g f return h d s e b f tostring bp a rgb2hsl function a b c c bs a b c a c 0 b c 1 c c 2 var d e f g h i g x a b c h y a b c i g h d i 0 null g a b c i g b c a i 2 a b i 4 d d 360 6 60 360 f g h 2 e i 0 0 f 5 i 2 f i 2 2 f return h d s e l f tostring bq a path2string function return this join replace y 1 var bw a preload function a b var c h doc createelement img c style csstext position absolute left 9999em top 9999em c onload function b call this this onload null h doc body removechild this c onerror function h doc body removechild this h doc body appendchild c c src a a getrgb bv function b if b b r b indexof 1 return r 1 g 1 b 1 hex none error 1 tostring bx if b none return r 1 g 1 b 1 hex none tostring bx x g b tolowercase substring 0 2 b charat b bo b var c d e f h i j k b match l if k k 2 f r k 2 substring 5 16 e r k 2 substring 3 5 16 d r k 2 substring 1 3 16 k 3 f r i k 3 charat 3 i 16 e r i k 3 charat 2 i 16 d r i k 3 charat 1 i 16 k 4 j k 4 s w d q j 0 j 0 slice 1 d 2 55 e q j 1 j 1 slice 1 e 2 55 f q j 2 j 2 slice 1 f 2 55 k 1 tolowercase slice 0 4 rgba h q j 3 j 3 j 3 slice 1 h 100 if k 5 j k 5 s w d q j 0 j 0 slice 1 d 2 55 e q j 1 j 1 slice 1 e 2 55 f q j 2 j 2 slice 1 f 2 55 j 0 slice 3 deg j 0 slice 1 d 360 k 1 tolowercase slice 0 4 hsba h q j 3 j 3 j 3 slice 1 h 100 return a hsb2rgb d e f h if k 6 j k 6 s w d q j 0 j 0 slice 1 d 2 55 e q j 1 j 1 slice 1 e 2 55 f q j 2 j 2 slice 1 f 2 55 j 0 slice 3 deg j 0 slice 1 d 360 k 1 tolowercase slice 0 4 hsla h q j 3 j 3 j 3 slice 1 h 100 return a hsl2rgb d e f h k r d g e b f tostring bx k hex 16777216 f e 8 d 16 tostring 16 slice 1 a is h finite k opacity h return k return r 1 g 1 b 1 hex none error 1 tostring bx a a hsb bv function b c d return a hsb2rgb b c d hex a hsl bv function b c d return a hsl2rgb b c d hex a rgb bv function a b c return 16777216 c b 8 a 16 tostring 16 slice 1 a getcolor function a var b this getcolor start this getcolor start h 0 s 1 b a 75 c this hsb2rgb b h b s b b b h 075 b h 1 b h 0 b s 2 b s 0 this getcolor start h 0 s 1 b b b return c hex a getcolor reset function delete this start a parsepathstring function b if b return null var c bz b if c arr return bj c arr var d a 7 c 6 h 1 l 2 m 2 r 4 q 4 s 4 t 2 v 1 z 0 e a is b e a is b 0 e e bj b e length r b replace z function a b c var f g b tolowercase c replace function a b b f push b g m f length 2 e push b n f splice 0 2 g l b b m l l if g r e push b n f else while f length d g e push b n f splice 0 d g if d g break e tostring a path2string c arr bj e return e a parsetransformstring bv function b if b return null var c r 3 s 4 t 2 m 6 d a is b e a is b 0 e d bj b d length r b replace function a b c var e f v call b c replace function a b b e push b d push b n e d tostring a path2string return d var bz function a var b bz ps bz ps b a b a sleep 100 b a sleep 100 settimeout function for var c in b b g c c a b c sleep b c sleep delete b c return b a a finddotsatsegment function a b c d e f g h i var j 1 i k a j 3 l a j 2 m i i n m i o k a l 3 i c j 3 i i e n g p k b l 3 i d j 3 i i f n h q a 2 i c a m e 2 c a r b 2 i d b m f 2 d b s c 2 i e c m g 2 e c t d 2 i f d m h 2 f d u j a i c v j b i d x j e i g y j f i h z 90 w atan2 q s r t 180 b q s r t z 180 return x o y p m x q y r n x s y t start x u y v end x x y y alpha z a bezierbbox function b c d e f g h i a is b array b b c d e f g h i var j bq apply null b return x j min x y j min y x2 j max x y2 j max y width j max x j min x height j max y j min y a ispointinsidebbox function a b c return b a x b a x2 c a y c a y2 a isbboxintersect function b c var d a ispointinsidebbox return d c b x b y d c b x2 b y d c b x b y2 d c b x2 b y2 d b c x c y d b c x2 c y d b c x c y2 d b c x2 c y2 b x c x2 b x c x c x b x2 c x b x b y c y2 b y c y c y b y2 c y b y a pathintersection function a b return bh a b a pathintersectionnumber function a b return bh a b 1 a ispointinsidepath function b c d var e a pathbbox b return a ispointinsidebbox e c d bh b m c d h e x2 10 1 2 1 a removedfactory function a return function eve raphael log null rapha l you are calling to method a of removed object a var bi a pathbbox function a var b bz a if b bbox return b bbox if a return x 0 y 0 width 0 height 0 x2 0 y2 0 a br a var c 0 d 0 e f g for var h 0 i a length h i h g a h if g 0 m c g 1 d g 2 e push c f push d else var j bq c d g 1 g 2 g 3 g 4 g 5 g 6 e e n j min x j max x f f n j min y j max y c g 5 d g 6 var k y m 0 e l y m 0 f o x m 0 e p x m 0 f q x k y l x2 o y2 p width o k height p l b bbox bm q return q bj function b var c bm b c tostring a path2string return c bk a pathtorelative function b var c bz b if c rel return bj c rel if a is b e a is b b 0 e b a parsepathstring b var d e 0 f 0 g 0 h 0 i 0 b 0 0 m e b 0 1 f b 0 2 g e h f i d push m e f for var j i k b length j k j var l d j m b j if m 0 v call m 0 l 0 v call m 0 switch l 0 case a l 1 m 1 l 2 m 2 l 3 m 3 l 4 m 4 l 5 m 5 l 6 m 6 e tofixed 3 l 7 m 7 f tofixed 3 break case v l 1 m 1 f tofixed 3 break case m g m 1 h m 2 default for var n 1 o m length n o n l n m n n 2 e f tofixed 3 else l d j m 0 m g m 1 e h m 2 f for var p 0 q m length p q p d j p m p var r d j length switch d j 0 case z e g f h break case h e d j r 1 break case v f d j r 1 break default e d j r 2 f d j r 1 d tostring a path2string c rel bj d return d bl a pathtoabsolute function b var c bz b if c abs return bj c abs if a is b e a is b b 0 e b a parsepathstring b if b b length return m 0 0 var d e 0 f 0 g 0 h 0 i 0 b 0 0 m e b 0 1 f b 0 2 g e h f i d 0 m e f var j b length 3 b 0 0 m b 1 0 touppercase r b 2 0 touppercase z for var k l m i o b length m o m d push k l b m if l 0 s call l 0 k 0 s call l 0 switch k 0 case a k 1 l 1 k 2 l 2 k 3 l 3 k 4 l 4 k 5 l 5 k 6 l 6 e k 7 l 7 f break case v k 1 l 1 f break case h k 1 l 1 e break case r var p e f n l slice 1 for var q 2 r p length q r q p q p q e p q p q f d pop d d n by p j break case m g l 1 e h l 2 f default for q 1 r l length q r q k q l q q 2 e f else if l 0 r p e f n l slice 1 d pop d d n by p j k r n l slice 2 else for var s 0 t l length s t s k s l s switch k 0 case z e g f h break case h e k 1 break case v f k 1 break case m g k k length 2 h k k length 1 default e k k length 2 f k k length 1 d tostring a path2string c abs bj d return d bm function a b c d return a b c d c d bn function a b c d e f var g 1 3 h 2 3 return g a h c g b h d g e h c g f h d e f bo function a b c d e f g h i j var k b 120 180 l b 180 e 0 m o p bv function a b c var d a w cos c b w sin c e a w sin c b w cos c return x d y e if j o p a b l a o x b o y o p h i l h o x i o y var q w cos b 180 e r w sin b 180 e t a h 2 u b i 2 v t t c c u u d d v 1 v w sqrt v c v c d v d var x c c y d d a f g 1 1 w sqrt z x y x u u y t t x u u y t t c a c u d a h 2 d a d t c b i 2 e w asin b d d tofixed 9 f w asin i d d tofixed 9 e a c b e e f h c b f f e 0 e b 2 e f 0 f b 2 f g e f e e b 2 g f e f f b 2 else e j 0 f j 1 c j 2 d j 3 var g f e if z g k var h f i h j i f e k g f e 1 1 h c c w cos f i d d w sin f m bo h i c d e 0 g i j f h c d g f e var k w cos e l w sin e m w cos f n w sin f o w tan g 4 p 4 3 c o q 4 3 d o r a b s a p l b q k t h p n i q m u h i s 0 2 r 0 s 0 s 1 2 r 1 s 1 if j return s t u n m m s t u n m join s var v for var w 0 x m length w x w v w w 2 p m w 1 m w l y p m w m w 1 l x return v bp function a b c d e f g h i var j 1 i return x a j 3 a a j 2 3 i c j 3 i i e a i 3 g y a j 3 b a j 2 3 i d j 3 i i f a i 3 h bq bv function a b c d e f g h var i e 2 c a g 2 e c j 2 c a 2 e c k a c l j w sqrt j j 4 i k 2 i n j w sqrt j j 4 i k 2 i o b h p a g q z l 1e12 l 5 z n 1e12 n 5 l 0 l 1 q bp a b c d e f g h l p push q x o push q y n 0 n 1 q bp a b c d e f g h n p push q x o push q y i f 2 d b h 2 f d j 2 d b 2 f d k b d l j w sqrt j j 4 i k 2 i n j w sqrt j j 4 i k 2 i z l 1e12 l 5 z n 1e12 n 5 l 0 l 1 q bp a b c d e f g h l p push q x o push q y n 0 n 1 q bp a b c d e f g h n p push q x o push q y return min x y m 0 p y y m 0 o max x x m 0 p y x m 0 o br a path2curve bv function a b var c b bz a if b c curve return bj c curve var d bl a e b bl b f x 0 y 0 bx 0 by 0 x 0 y 0 qx null qy null g x 0 y 0 bx 0 by 0 x 0 y 0 qx null qy null h function a b var c d if a return c b x b y b x b y b x b y a 0 in t 1 q 1 b qx b qy null switch a 0 case m b x a 1 b y a 2 break case a a c n bo m 0 b x b y n a slice 1 break case s c b x b x b bx b x d b y b y b by b y a c c d n a slice 1 break case t b qx b x b x b qx b x b qy b y b y b qy b y a c n bn b x b y b qx b qy a 1 a 2 break case q b qx a 1 b qy a 2 a c n bn b x b y a 1 a 2 a 3 a 4 break case l a c n bm b x b y a 1 a 2 break case h a c n bm b x b y a 1 b y break case v a c n bm b x b y b x a 1 break case z a c n bm b x b y b x b y return a i function a b if a b length 7 a b shift var c a b while c length a splice b 0 c n c splice 0 6 a splice b 1 l x d length e e length 0 j function a b c f g a b a g 0 m b g 0 m b splice g 0 m f x f y c bx 0 c by 0 c x a g 1 c y a g 2 l x d length e e length 0 for var k 0 l x d length e e length 0 k l k d k h d k f i d k e e k h e k g e i e k j d e f g k j e d g f k var o d k p e e k q o length r e p length f x o q 2 f y o q 1 f bx q o q 4 f x f by q o q 3 f y g bx e q p r 4 g x g by e q p r 3 g y g x e p r 2 g y e p r 1 e c curve bj d return e d e d null bj bs a parsedots bv function b var c for var d 0 e b length d e d var f g b d match d f color a getrgb g 1 if f color error return null f color f color hex g 2 f offset g 2 c push f for d 1 e c length 1 d e d if c d offset var h q c d 1 offset 0 i 0 for var j d 1 j e j if c j offset i c j offset break i i 100 j e i q i var k i h j d 1 for d j d h k c d offset h return c bt a tear function a b a b top b top a prev a b bottom b bottom a next a next a next prev a prev a prev a prev next a next bu a tofront function a b b top a bt a b a next null a prev b top b top next a b top a bv a toback function a b b bottom a bt a b a next b bottom a prev null b bottom prev a b bottom a bw a insertafter function a b c bt a c b c top c top a b next b next prev a a next b next a prev b b next a bx a insertbefore function a b c bt a c b c bottom c bottom a b prev b prev next a a prev b prev b prev a a next b by a tomatrix function a b var c bi a d transform p getbbox function return c b d b return d matrix bz a transformpath function a b return bj a by a b b a extracttransform function b c if c null return b transform c r c replace 3 u2026 g b transform p var d a parsetransformstring c e 0 f 0 g 0 h 1 i 1 j b k new cb j transform d if d for var l 0 m d length l m l var n d l o n length q r n 0 tolowercase s n 0 q t s k invert 0 u v w x y q t o 3 s u t x 0 0 v t y 0 0 w t x n 1 n 2 x t y n 1 n 2 k translate w u x v k translate n 1 n 2 q r o 2 y y b getbbox 1 k rotate n 1 y x y width 2 y y y height 2 e n 1 o 4 s w t x n 2 n 3 x t y n 2 n 3 k rotate n 1 w x k rotate n 1 n 2 n 3 e n 1 q s o 2 o 3 y y b getbbox 1 k scale n 1 n o 1 y x y width 2 y y y height 2 h n 1 i n o 1 o 5 s w t x n 3 n 4 x t y n 3 n 4 k scale n 1 n 2 w x k scale n 1 n 2 n 3 n 4 h n 1 i n 2 q m o 7 k add n 1 n 2 n 3 n 4 n 5 n 6 j dirtyt 1 b matrix k b matrix k j sx h j sy i j deg e j dx f k e j dy g k f h 1 i 1 e j bbox j bbox x f j bbox y g j dirtyt 1 b function a var b a 0 switch b tolowercase case t return b 0 0 case m return b 1 0 0 1 0 0 case r return a length 4 b 0 a 2 a 3 b 0 case s return a length 5 b 1 1 a 3 a 4 a length 3 b 1 1 b 1 ca a equalisetransform function b c c r c replace 3 u2026 g b b a parsetransformstring b c a parsetransformstring c var d x b length c length e f g 0 h i j k for g d g j b g b c g k c g b j if j 0 k 0 j 0 tolowercase r j 2 k 2 j 3 k 3 j 0 tolowercase s j 3 k 3 j 4 k 4 return e g f g for h 0 i x j length k length h i h h in j e g h j h h in k f g h k h return from e to f a getcontainer function b c d e var f f e null a is b object h doc getelementbyid b b if f null if f tagname return c null container f width f style pixelwidth f offsetwidth height f style pixelheight f offsetheight container f width c height d return container 1 x b y c width d height e a pathtorelative bk a engine a path2curve br a matrix function a b c d e f return new cb a b c d e f function b function d a var b w sqrt c a a 0 a 0 b a 1 a 1 b function c a return a 0 a 0 a 1 a 1 b add function a b c d e f var g h this a this c this e this b this d this f 0 0 1 i a c e b d f 0 0 1 j k l m a a instanceof cb i a a a c a e a b a d a f 0 0 1 for j 0 j 3 j for k 0 k 3 k m 0 for l 0 l 3 l m h j l i l k g j k m this a g 0 0 this b g 1 0 this c g 0 1 this d g 1 1 this e g 0 2 this f g 1 2 b invert function var a this b a a a d a b a c return new cb a d b a b b a c b a a b a c a f a d a e b a b a e a a a f b b clone function return new cb this a this b this c this d this e this f b translate function a b this add 1 0 0 1 a b b scale function a b c d b null b a c d this add 1 0 0 1 c d this add a 0 0 b 0 0 c d this add 1 0 0 1 c d b rotate function b c d b a rad b c c 0 d d 0 var e w cos b tofixed 9 f w sin b tofixed 9 this add e f f e c d this add 1 0 0 1 c d b x function a b return a this a b this c this e b y function a b return a this b b this d this f b get function a return this r fromcharcode 97 a tofixed 4 b tostring function return a svg matrix this get 0 this get 1 this get 2 this get 3 this get 4 this get 5 join this get 0 this get 2 this get 1 this get 3 0 0 join b tofilter function return progid dximagetransform microsoft matrix m11 this get 0 m12 this get 2 m21 this get 1 m22 this get 3 dx this get 4 dy this get 5 sizingmethod auto expand b offset function return this e tofixed 4 this f tofixed 4 b split function var b b dx this e b dy this f var e this a this c this b this d b scalex w sqrt c e 0 d e 0 b shear e 0 0 e 1 0 e 0 1 e 1 1 e 1 e 1 0 e 0 0 b shear e 1 1 e 0 1 b shear b scaley w sqrt c e 1 d e 1 b shear b scaley var f e 0 1 g e 1 1 g 0 b rotate a deg w acos g f 0 b rotate 360 b rotate b rotate a deg w asin f b issimple b shear tofixed 9 b scalex tofixed 9 b scaley tofixed 9 b rotate b issupersimple b shear tofixed 9 b scalex tofixed 9 b scaley tofixed 9 b rotate b norotation b shear tofixed 9 b rotate return b b totransformstring function a var b a this s if b issimple b scalex b scalex tofixed 4 b scaley b scaley tofixed 4 b rotate b rotate tofixed 4 return b dx b dy t b dx b dy p b scalex 1 b scaley 1 s b scalex b scaley 0 0 p b rotate r b rotate 0 0 p return m this get 0 this get 1 this get 2 this get 3 this get 4 this get 5 cb prototype var cc navigator useragent match version s navigator useragent match chrome d navigator vendor apple computer inc cc cc 1 4 navigator platform slice 0 2 ip navigator vendor google inc cc cc 1 8 k safari function var a this rect 99 99 this width 99 this height 99 attr stroke none settimeout function a remove k safari be var cd function this returnvalue 1 ce function return this originalevent preventdefault cf function this cancelbubble 0 cg function return this originalevent stoppropagation ch function if h doc addeventlistener return function a b c d var e o u b u b b f function e var f h doc documentelement scrolltop h doc body scrolltop i h doc documentelement scrollleft h doc body scrollleft j e clientx i k e clienty f if o u g b for var l 0 m e targettouches e targettouches length l m l if e targettouches l target a var n e e e targettouches l e originalevent n e preventdefault ce e stoppropagation cg break return c call d e j k a addeventlistener e f 1 return function a removeeventlistener e f 1 return 0 if h doc attachevent return function a b c d var e function a a a h win event var b h doc documentelement scrolltop h doc body scrolltop e h doc documentelement scrollleft h doc body scrollleft f a clientx e g a clienty b a preventdefault a preventdefault cd a stoppropagation a stoppropagation cf return c call d a f g a attachevent on b e var f function a detachevent on b e return 0 return f ci cj function a var b a clientx c a clienty d h doc documentelement scrolltop h doc body scrolltop e h doc documentelement scrollleft h doc body scrollleft f g ci length while g f ci g if o var i a touches length j while i j a touches i if j identifier f el drag id b j clientx c j clienty a originalevent a originalevent a preventdefault break else a preventdefault var k f el node l m k nextsibling n k parentnode p k style display h win opera n removechild k k style display none l f el paper getelementbypoint b c k style display p h win opera m n insertbefore k m n appendchild k l eve raphael drag over f el id f el l b e c d eve raphael drag move f el id f move scope f el b f el drag x c f el drag y b c a ck function b a unmousemove cj unmouseup ck var c ci length d while c d ci c d el drag eve raphael drag end d el id d end scope d start scope d move scope d el b ci cl a el for var cm t length cm function b a b cl b function c d a is c function this events this events this events push name b f c unbind ch this shape this node h doc b c d this return this a un b cl un b function a var c this events d c length while d if c d name b c d f a c d unbind c splice d 1 c length delete this events return this return this t cm cl data function b c var d bb this id bb this id if arguments length 1 if a is b object for var e in b b g e this data e b e return this eve raphael data get this id this d b b return d b d b c eve raphael data set this id this c b return this cl removedata function a a null bb this id bb this id delete bb this id a return this cl hover function a b c d return this mouseover a c mouseout b d c cl unhover function a b return this unmouseover a unmouseout b var cn cl drag function b c d e f g function i i i originalevent i preventdefault var j h doc documentelement scrolltop h doc body scrolltop k h doc documentelement scrollleft h doc body scrollleft this drag x i clientx k this drag y i clienty j this drag id i identifier ci length a mousemove cj mouseup ck ci push el this move scope e start scope f end scope g c eve on raphael drag start this id c b eve on raphael drag move this id b d eve on raphael drag end this id d eve raphael drag start this id f e this i clientx k i clienty j i this drag cn push el this start i this mousedown i return this cl ondragover function a a eve on raphael drag over this id a eve unbind raphael drag over this id cl undrag function var b cn length while b cn b el this this unmousedown cn b start cn splice b 1 eve unbind raphael drag this id cn length a unmousemove cj unmouseup ck k circle function b c d var e a engine circle this b 0 c 0 d 0 this set this set push e return e k rect function b c d e f var g a engine rect this b 0 c 0 d 0 e 0 f 0 this set this set push g return g k ellipse function b c d e var f a engine ellipse this b 0 c 0 d 0 e 0 this set this set push f return f k path function b b a is b d a is b 0 e b p var c a engine path a format m a arguments this this set this set push c return c k image function b c d e f var g a engine image this b about blank c 0 d 0 e 0 f 0 this set this set push g return g k text function b c d var e a engine text this b 0 c 0 r d this set this set push e return e k set function b a is b array b array prototype splice call arguments 0 arguments length var c new cg b this set this set push c return c k setstart function a this set a this set k setfinish function a var b this set delete this set return b k setsize function b c return a engine setsize call this b c k setviewbox function b c d e f return a engine setviewbox call this b c d e f k top k bottom null k raphael a var co function a var b a getboundingclientrect c a ownerdocument d c body e c documentelement f e clienttop d clienttop 0 g e clientleft d clientleft 0 i b top h win pageyoffset e scrolltop d scrolltop f j b left h win pagexoffset e scrollleft d scrollleft g return y i x j k getelementbypoint function a b var c this d c canvas e h doc elementfrompoint a b if h win opera e tagname svg var f co d g d createsvgrect g x a f x g y b f y g width g height 1 var i d getintersectionlist g null i length e i i length 1 if e return null while e parentnode e d parentnode e raphael e e parentnode e c canvas parentnode e d e e e raphael c getbyid e raphaelid null return e k getbyid function a var b this bottom while b if b id a return b b b next return null k foreach function a b var c this bottom while c if a call b c 1 return this c c next return this k getelementsbypoint function a b var c this set this foreach function d d ispointinside a b c push d return c cl ispointinside function b c var d this realpath this realpath bi this type this return a ispointinsidepath d b c cl getbbox function a if this removed return var b this if a if b dirty b bboxwt this realpath bi this type this b bboxwt bi this realpath b bboxwt tostring cq b dirty 0 return b bboxwt if b dirty b dirtyt b bbox if b dirty this realpath b bboxwt 0 this realpath bi this type this b bbox bi bj this realpath this matrix b bbox tostring cq b dirty b dirtyt 0 return b bbox cl clone function if this removed return null var a this paper this type attr this attr this set this set push a return a cl glow function a if this type text return null a a var b width a width 10 this attr stroke width 1 fill a fill 1 opacity a opacity 5 offsetx a offsetx 0 offsety a offsety 0 color a color 000 c b width 2 d this paper e d set f this realpath bi this type this f this matrix bj f this matrix f for var g 1 g c 1 g e push d path f attr stroke b color fill b fill b color none stroke linejoin round stroke linecap round stroke width b width c g tofixed 3 opacity b opacity c tofixed 3 return e insertbefore this translate b offsetx b offsety var cr cs function b c d e f g h i j return j null bb b c d e f g h i a finddotsatsegment b c d e f g h i bc b c d e f g h i j ct function b c return function d e f d br d var g h i j k l m n 0 for var o 0 p d length o p o i d o if i 0 m g i 1 h i 2 else j cs g h i 1 i 2 i 3 i 4 i 5 i 6 if n j e if c l start m cs g h i 1 i 2 i 3 i 4 i 5 i 6 e n k c m start x m start y m m x m m y m x m y if f return k l start k k m m x m y c m n x m n y m end x m end y i 5 i 6 join n j g i 5 h i 6 continue if b c m cs g h i 1 i 2 i 3 i 4 i 5 i 6 e n return x m x y m y alpha m alpha n j g i 5 h i 6 k i shift i l end k m b n c l a finddotsatsegment g h i 0 i 1 i 2 i 3 i 4 i 5 1 m alpha m x m x y m y alpha m alpha return m cu ct 1 cv ct cw ct 0 1 a gettotallength cu a getpointatlength cv a getsubpath function a b c if this gettotallength a c 1e 6 return cw a b end var d cw a c 1 return b cw d b end d cl gettotallength function if this type path if this node gettotallength return this node gettotallength return cu this attrs path cl getpointatlength function a if this type path return cv this attrs path a cl getsubpath function b c if this type path return a getsubpath this attrs path b c var cx a easing formulas linear function a return a function a return a a 1 7 function a return a a 48 function a var b 48 a 1 04 c w sqrt 1734 b b d c b e a z d 1 3 d 0 1 1 f c b g a z f 1 3 f 0 1 1 h e g 5 return 1 h 3 h h h h h backin function a var b 1 70158 return a a b 1 a b backout function a a a 1 var b 1 70158 return a a b 1 a b 1 elastic function a if a a return a return a 2 10 a w sin a 075 2 b 3 1 bounce function a var b 7 5625 c 2 75 d a 1 c d b a a a 2 c a 1 5 c d b a a 75 a 2 5 c a 2 25 c d b a a 9375 a 2 625 c d b a a 984375 return d cx easein cx ease in cx cx easeout cx ease out cx cx easeinout cx ease in out cx cx back in cx backin cx back out cx backout var cy cz window requestanimationframe window webkitrequestanimationframe window mozrequestanimationframe window orequestanimationframe window msrequestanimationframe function a settimeout a 16 ca function var b new date c 0 for c cy length c var d cy c if d el removed d paused continue var e b d start f d ms h d easing i d from j d diff k d to l d t m d el o p r s d initstatus e d initstatus d anim top d prev d percent d prev f d status d initstatus delete d initstatus d stop cy splice c 1 d status d prev d percent d prev e f d anim top if e 0 continue if e f var t h e f for var u in i if i g u switch u u case c p i u t f j u break case colour p rgb cb o i u r t f j u r cb o i u g t f j u g cb o i u b t f j u b join break case path p for var v 0 w i u length v w v p v i u v 0 for var x 1 y i u v length x y x p v x i u v x t f j u v x p v p v join q p p join q break case transform if j u real p for v 0 w i u length v w v p v i u v 0 for x 1 y i u v length x y x p v x i u v x t f j u v x else var z function a return i u a t f j u a p m z 0 z 1 z 2 z 3 z 4 z 5 break case csv if u clip rect p v 4 while v p v i u v t f j u v break default var a n i u p v m paper customattributes u length while v p v a v t f j u v o u p m attr o function a b c settimeout function eve raphael anim frame a b c m id m d anim else function b c d settimeout function eve raphael anim frame c id c d eve raphael anim finish c id c d a is b function b call c d callback m d anim m attr k cy splice c 1 if d repeat 1 d next for s in k k g s r s d totalorigin s d el attr r ce d anim d el d anim percents 0 null d totalorigin d repeat 1 d next d stop ce d anim d el d next null d totalorigin d repeat a svg m m paper m paper safari cy length cz ca cb function a return a 255 255 a 0 0 a cl animatewith function b c d e f g var h this if h removed g g call h return h var i d instanceof cd d a animation d e f g j k ce i h i percents 0 null h attr for var l 0 m cy length l m l if cy l anim c cy l el b cy m 1 start cy l start break return h cl onanimation function a a eve on raphael anim frame this id a eve unbind raphael anim frame this id return this cd prototype delay function a var b new cd this anim this ms b times this times b del a 0 return b cd prototype repeat function a var b new cd this anim this ms b del this del b times w floor x a 0 1 return b a animation function b c d e if b instanceof cd return b if a is d function d e e d null d null b object b c c 0 var f h i for i in b b g i q i i q i i h 0 f i b i if h return new cd b c d f easing d e f callback e return new cd 100 f c cl animate function b c d e var f this if f removed e e call f return f var g b instanceof cd b a animation b c d e ce g f g percents 0 null f attr return f cl settime function a b a b null this status a y b a ms a ms return this cl status function a b var c d 0 e f if b null ce a this 1 y b 1 return this e cy length for d e d f cy d if f el id this id a f anim a if a return f status c push anim f anim status f status if a return 0 return c cl pause function a for var b 0 b cy length b cy b el id this id a cy b anim a eve raphael anim pause this id this cy b anim 1 cy b paused 0 return this cl resume function a for var b 0 b cy length b if cy b el id this id a cy b anim a var c cy b eve raphael anim resume this id this c anim 1 delete c paused this status c anim c status return this cl stop function a for var b 0 b cy length b cy b el id this id a cy b anim a eve raphael anim stop this id this cy b anim 1 cy splice b 1 return this eve on raphael remove cf eve on raphael clear cf cl tostring function return rapha l s object var cg function a this items this length 0 this type set if a for var b 0 c a length b c b a b a b constructor cl constructor a b constructor cg this this items length this items this items length a b this length ch cg prototype ch push function var a b for var c 0 d arguments length c d c a arguments c a a constructor cl constructor a constructor cg b this items length this b this items b a this length return this ch pop function this length delete this this length return this items pop ch foreach function a b for var c 0 d this items length c d c if a call b this items c c 1 return this return this for var ci in cl cl g ci ch ci function a return function var b arguments return this foreach function c c a m c b ci ch attr function b c if b a is b e a is b 0 object for var d 0 e b length d e d this items d attr b d else for var f 0 g this items length f g f this items f attr b c return this ch clear function while this length this pop ch splice function a b c a a 0 x this length a 0 a b x 0 y this length a b var d e f g for g 2 g arguments length g f push arguments g for g 0 g b g e push this a g for g this length a g d push this a g var h f length for g 0 g h d length g this items a g this a g g h f g d g h g this items length this length b h while this g delete this g return new cg e ch exclude function a for var b 0 c this length b c b if this b a this splice b 1 return 0 ch animate function b c d e a is d function d e d null var f this items length g f h i this j if f return this e j function f e call i d a is d d d j var k a animation b c d j h this items g animate k while g this items g this items g removed this items g animatewith h k k return this ch insertafter function a var b this items length while b this items b insertafter a return this ch getbbox function var a b c d for var e this items length e if this items e removed var f this items e getbbox a push f x b push f y c push f x f width d push f y f height a y m 0 a b y m 0 b c x m 0 c d x m 0 d return x a y b x2 c y2 d width c a height d b ch clone function a a new cg for var b 0 c this items length b c b a push this items b clone return a ch tostring function return rapha l s set a registerfont function a if a face return a this fonts this fonts var b w a w face glyphs c a face font family for var d in a face a face g d b face d a face d this fonts c this fonts c push b this fonts c b if a svg b face units per em r a face units per em 10 for var e in a glyphs if a glyphs g e var f a glyphs e b glyphs e w f w k d f d m f d replace mlcxtrv g function a return l l c c x z t m r l v c a m z if f k for var h in f k f g h b glyphs e k h f k h return a k getfont function b c d e e e normal d d normal c c normal 400 bold 700 lighter 300 bolder 800 c 400 if a fonts var f a fonts b if f var h new regexp s b replace w d s g p s i for var i in a fonts if a fonts g i h test i f a fonts i break var j if f for var k 0 l f length k l k j f k if j face font weight c j face font style d j face font style j face font stretch e break return j k print function b d e f g h i h h middle i x y i 0 1 1 var j r e s p k 0 l 0 m p n a is f e f this getfont f if f n g 16 f face units per em var o f face bbox s c q o 0 t o 3 o 1 u 0 v o 1 h baseline t f face descent t 2 for var w 0 z j length w z w if j w n k 0 b 0 l 0 u t else var a l f glyphs j w 1 b f glyphs j w k l a w f w a k a k j w 0 f w i 0 l 1 b b d m a transformpath b d t k n u n s n n q v t b q n d v n return this path m attr fill 000 stroke none k add function b if a is b array var c this set e 0 f b length h for e f e h b e d g h type c push this h type attr h return c a format function b c var d a is c e 0 n c arguments b a is b d d length 1 b b replace e function a b return d b null p d b return b p a fullfill function var a g b 2 g c function a c d var e d c replace b function a b c d f b b d e b in e e e b typeof e function f e e e e null e d a e return e return function b d return string b replace a function a b return c a b d a ninja function i was h win raphael i is delete raphael return a a st ch function b c d function e in test b readystate settimeout e 9 a eve raphael domload b readystate null b addeventlistener b addeventlistener c d function b removeeventlistener c d 1 b readystate complete 1 b readystate loading e document domcontentloaded i was h win raphael a raphael a eve on raphael domload function b 0 window raphael svg function a var b hasownproperty c string d parsefloat e parseint f math g f max h f abs i f pow j k a eve l m n http www w3 org 1999 xlink o block m5 0 0 2 5 5 5z classic m5 0 0 2 5 5 5 3 5 3 3 5 2z diamond m2 5 0 5 2 5 2 5 5 0 2 5z open m6 1 1 3 5 6 6 oval m2 5 0a2 5 2 5 0 0 1 2 5 5 2 5 2 5 0 0 1 2 5 0z p a tostring function return your browser supports svg nyou are running rapha l this version var q function d e if e typeof d string d q d for var f in e e b f f substring 0 6 xlink d setattributens n f substring 6 c e f d setattribute f c e f else d a g doc createelementns http www w3 org 2000 svg d d style d style webkittaphighlightcolor rgba 0 0 0 0 return d r function b e var j linear k b id e m 5 n 5 o b node p b paper r o style s a g doc getelementbyid k if s e c e replace a radial gradient function a b c j radial if b c m d b n d c var e n 5 2 1 i m 5 2 i n 5 2 25 n f sqrt 25 i m 5 2 e 5 n 5 n n tofixed 5 1e 5 e return l e e split s s if j linear var t e shift t d t if isnan t return null var u 0 0 f cos a rad t f sin a rad t v 1 g h u 2 h u 3 1 u 2 v u 3 v u 2 0 u 0 u 2 u 2 0 u 3 0 u 1 u 3 u 3 0 var w a parsedots e if w return null k k replace s xb0 g b gradient k b gradient id p defs removechild b gradient delete b gradient if b gradient s q j gradient id k b gradient s q s j radial fx m fy n x1 u 0 y1 u 1 x2 u 2 y2 u 3 gradienttransform b matrix invert p defs appendchild s for var x 0 y w length x y x s appendchild q stop offset w x offset w x offset x 100 0 stop color w x color fff q o fill url k opacity 1 fill opacity 1 r fill l r opacity 1 r fillopacity 1 return 1 s function a var b a getbbox 1 q a pattern patterntransform a matrix invert translate b x b y t function d e f if d type path var g c e tolowercase split h d paper i f end start j d node k d attrs m k stroke width n g length r classic s t u v w x 3 y 3 z 5 while n switch g n case block case classic case oval case diamond case open case none r g n break case wide y 5 break case narrow y 2 break case long x 5 break case short x 2 r open x 2 y 2 z 2 u 1 v f 4 1 w fill none stroke k stroke v u x 2 w fill k stroke stroke none d arrows f d arrows endpath p d arrows endpath d arrows endmarker p d arrows endmarker d arrows startpath p d arrows startpath d arrows startmarker p d arrows startmarker d arrows if r none var a raphael marker r b raphael marker i r x y a g doc getelementbyid a p a h defs appendchild q q path stroke linecap round d o r id a p a 1 var c a g doc getelementbyid b d c p b d c getelementsbytagname use 0 c q q marker id b markerheight y markerwidth x orient auto refx v refy y 2 d q q use xlink href a transform f rotate 180 x 2 y 2 l scale x z y z stroke width 1 x z y z 2 tofixed 4 c appendchild d h defs appendchild c p b 1 q d w var f u r diamond r oval f s d arrows startdx m 0 t a gettotallength k path f m s f m t a gettotallength k path d arrows enddx m 0 w w marker i url b if t s w d raphael getsubpath k path s t q j w d arrows i path a d arrows i marker b d arrows i dx f d arrows i type r d arrows i string e else f s d arrows startdx m 0 t a gettotallength k path s s 0 t a gettotallength k path d arrows enddx m 0 d arrows i path q j d raphael getsubpath k path s t delete d arrows i path delete d arrows i marker delete d arrows i dx delete d arrows i type delete d arrows i string for w in p if p b w p w var g a g doc getelementbyid w g g parentnode removechild g u 0 none 0 3 1 1 1 3 1 1 1 3 1 1 1 1 1 1 3 4 3 8 3 4 3 1 3 8 3 1 3 8 3 1 3 1 3 v function a b d b u c b tolowercase if b var e a attrs stroke width 1 f round e square e butt 0 a attrs stroke linecap d stroke linecap 0 g h b length while h g h b h e h 2 1 1 f q a node stroke dasharray g join w function d f var i d node k d attrs m i style visibility i style visibility hidden for var o in f if f b o if a availableattrs b o continue var p f o k o p switch o case blur d blur p break case href case title case target var u i parentnode if u tagname tolowercase a var w q a u insertbefore w i w appendchild i u w o target u setattributens n show p blank new p u setattributens n o p break case cursor i style cursor p break case transform d transform p break case arrow start t d p break case arrow end t d p 1 break case clip rect var x c p split j if x length 4 d clip d clip parentnode parentnode removechild d clip parentnode var z q clippath a q rect z id a createuuid q a x x 0 y x 1 width x 2 height x 3 z appendchild a d paper defs appendchild z q i clip path url z id d clip a if p var b i getattribute clip path if b var c a g doc getelementbyid b replace url g l c c parentnode removechild c q i clip path l delete d clip break case path d type path q i d p k path a pathtoabsolute p m0 0 d dirty 1 d arrows startstring in d arrows t d d arrows startstring endstring in d arrows t d d arrows endstring 1 break case width i setattribute o p d dirty 1 if k fx o x p k x else break case x k fx p k x k width 0 case rx if o rx d type rect break case cx i setattribute o p d pattern s d d dirty 1 break case height i setattribute o p d dirty 1 if k fy o y p k y else break case y k fy p k y k height 0 case ry if o ry d type rect break case cy i setattribute o p d pattern s d d dirty 1 break case r d type rect q i rx p ry p i setattribute o p d dirty 1 break case src d type image i setattributens n href p break case stroke width if d sx 1 d sy 1 p g h d sx h d sy 1 d paper vbsize p d paper vbsize i setattribute o p k stroke dasharray v d k stroke dasharray f d arrows startstring in d arrows t d d arrows startstring endstring in d arrows t d d arrows endstring 1 break case stroke dasharray v d p f break case fill var d c p match a isurl if d z q pattern var f q image z id a createuuid q z x 0 y 0 patternunits userspaceonuse height 1 width 1 q f x 0 y 0 xlink href d 1 z appendchild f function b a preload d 1 function var a this offsetwidth c this offsetheight q b width a height c q f width a height c d paper safari z d paper defs appendchild z q i fill url z id d pattern z d pattern s d break var g a getrgb p if g error delete f gradient delete k gradient a is k opacity undefined a is f opacity undefined q i opacity k opacity a is k fill opacity undefined a is f fill opacity undefined q i fill opacity k fill opacity else if d type circle d type ellipse c p charat r r d p if opacity in k fill opacity in k var h a g doc getelementbyid i getattribute fill replace url g l if h var i h getelementsbytagname stop q i i length 1 stop opacity opacity in k k opacity 1 fill opacity in k k fill opacity 1 k gradient p k fill none break g b opacity q i fill opacity g opacity 1 g opacity 100 g opacity case stroke g a getrgb p i setattribute o g hex o stroke g b opacity q i stroke opacity g opacity 1 g opacity 100 g opacity o stroke d arrows startstring in d arrows t d d arrows startstring endstring in d arrows t d d arrows endstring 1 break case gradient d type circle d type ellipse c p charat r r d p break case opacity k gradient k b stroke opacity q i stroke opacity p 1 p 100 p case fill opacity if k gradient h a g doc getelementbyid i getattribute fill replace url g l h i h getelementsbytagname stop q i i length 1 stop opacity p break default o font size p e p 10 px var j o replace g function a return a substring 1 touppercase i style j p d dirty 1 i setattribute o p y d f i style visibility m x 1 2 y function d f if d type text f b text f b font f b font size f b x f b y var g d attrs h d node i h firstchild e a g doc defaultview getcomputedstyle h firstchild l getpropertyvalue font size 10 10 if f b text g text f text while h firstchild h removechild h firstchild var j c f text split n k m for var n 0 o j length n o n m q tspan n q m dy i x x g x m appendchild a g doc createtextnode j n h appendchild m k n m else k h getelementsbytagname tspan for n 0 o k length n o n n q k n dy i x x g x q k 0 dy 0 q h x g x y g y d dirty 1 var p d getbbox r g y p y p height 2 r a is r finite q k 0 dy r z function b c var d 0 e 0 this 0 this node b b raphael 0 this id a oid b raphaelid this id this matrix a matrix this realpath null this paper c this attrs this attrs this transform sx 1 sy 1 deg 0 dx 0 dy 0 dirty 1 c bottom c bottom this this prev c top c top c top next this c top this this next null a a el z prototype a a constructor z a engine path function a b var c q path b canvas b canvas appendchild c var d new z c b d type path w d fill none stroke 000 path a return d a rotate function a b e if this removed return this a c a split j a length 1 b d a 1 e d a 2 a d a 0 e null b e if b null e null var f this getbbox 1 b f x f width 2 e f y f height 2 this transform this transform concat r a b e return this a scale function a b e f if this removed return this a c a split j a length 1 b d a 1 e d a 2 f d a 3 a d a 0 b null b a f null e f if e null f null var g this getbbox 1 e e null g x g width 2 e f f null g y g height 2 f this transform this transform concat s a b e f return this a translate function a b if this removed return this a c a split j a length 1 b d a 1 a d a 0 0 b b 0 this transform this transform concat t a b return this a transform function c var d this if c null return d transform a extracttransform this c this clip q this clip transform this matrix invert this pattern s this this node q this node transform this matrix if d sx 1 d sy 1 var e this attrs b stroke width this attrs stroke width 1 this attr stroke width e return this a hide function this removed this paper safari this node style display none return this a show function;1.2972068;0.7555265;-3.3266652;-3.9380593;1.1027805;-0.17897;CODE
this removed this paper safari this node style display return this a remove function if this removed this node parentnode var b this paper b set b set exclude this k unbind raphael this id this gradient b defs removechild this gradient a tear this b this node parentnode tagname tolowercase a this node parentnode parentnode removechild this node parentnode this node parentnode removechild this node for var c in this this c typeof this c function a removedfactory c null this removed 0 a getbbox function if this node style display none this show var a 0 var b try b this node getbbox catch c finally b b a this hide return b a attr function c d if this removed return this if c null var e for var f in this attrs this attrs b f e f this attrs f e gradient e fill none e fill e gradient delete e gradient e transform this transform return e if d null a is c string if c fill this attrs fill none this attrs gradient return this attrs gradient if c transform return this transform var g c split j h for var i 0 l g length i l i c g i c in this attrs h c this attrs c a is this paper customattributes c function h c this paper customattributes c def h c a availableattrs c return l 1 h h g 0 if d null a is c array h for i 0 l c length i l i h c i this attr c i return h if d null var m m c d else c null a is c object m c for var n in m k raphael attr n this id this m n for n in this paper customattributes if this paper customattributes b n m b n a is this paper customattributes n function var o this paper customattributes n apply this concat m n this attrs n m n for var p in o o b p m p o p w this m return this a tofront function if this removed return this this node parentnode tagname tolowercase a this node parentnode parentnode appendchild this node parentnode this node parentnode appendchild this node var b this paper b top this a tofront this b return this a toback function if this removed return this var b this node parentnode b tagname tolowercase a b parentnode insertbefore this node parentnode this node parentnode parentnode firstchild b firstchild this node b insertbefore this node this node parentnode firstchild a toback this this paper var c this paper return this a insertafter function b if this removed return this var c b node b b length 1 node c nextsibling c parentnode insertbefore this node c nextsibling c parentnode appendchild this node a insertafter this b this paper return this a insertbefore function b if this removed return this var c b node b 0 node c parentnode insertbefore this node c a insertbefore this b this paper return this a blur function b var c this if b 0 var d q filter e q fegaussianblur c attrs blur b d id a createuuid q e stddeviation b 1 5 d appendchild e c paper defs appendchild d c blur d q c node filter url d id else c blur c blur parentnode removechild c blur delete c blur delete c attrs blur c node removeattribute filter a engine circle function a b c d var e q circle a canvas a canvas appendchild e var f new z e a f attrs cx b cy c r d fill none stroke 000 f type circle q e f attrs return f a engine rect function a b c d e f var g q rect a canvas a canvas appendchild g var h new z g a h attrs x b y c width d height e r f 0 rx f 0 ry f 0 fill none stroke 000 h type rect q g h attrs return h a engine ellipse function a b c d e var f q ellipse a canvas a canvas appendchild f var g new z f a g attrs cx b cy c rx d ry e fill none stroke 000 g type ellipse q f g attrs return g a engine image function a b c d e f var g q image q g x c y d width e height f preserveaspectratio none g setattributens n href b a canvas a canvas appendchild g var h new z g a h attrs x c y d width e height f src b h type image return h a engine text function b c d e var f q text b canvas b canvas appendchild f var g new z f b g attrs x c y d text anchor middle text e font a availableattrs font stroke none fill 000 g type text w g g attrs return g a engine setsize function a b this width a this width this height b this height this canvas setattribute width this width this canvas setattribute height this height this viewbox this setviewbox apply this this viewbox return this a engine create function var b a getcontainer apply 0 arguments c b b container d b x e b y f b width g b height if c throw new error svg container not found var h q svg i overflow hidden j d d 0 e e 0 f f 512 g g 342 q h height g version 1 1 width f xmlns http www w3 org 2000 svg c 1 h style csstext i position absolute left d px top e px a g doc body appendchild h j 1 h style csstext i position relative c firstchild c insertbefore h c firstchild c appendchild h c new a paper c width f c height g c canvas h c clear c left c top 0 j c renderfix function c renderfix return c a engine setviewbox function a b c d e k raphael setviewbox this this viewbox a b c d e var f g c this width d this height h this top i e meet xminymin j l a null this vbsize f 1 delete this vbsize j 0 0 this width m this height this vbsize f j a m b m c m d q this canvas viewbox j preserveaspectratio i while f h l stroke width in h attrs h attrs stroke width 1 h attr stroke width l h dirty 1 h dirtyt 1 h h prev this viewbox a b c d e return this a prototype renderfix function var a this canvas b a style c try c a getscreenctm a createsvgmatrix catch d c a createsvgmatrix var e c e 1 f c f 1 if e f e this left this left e 1 b left this left px f this top this top f 1 b top this top px a prototype clear function a eve raphael clear this var b this canvas while b firstchild b removechild b firstchild this bottom this top null this desc q desc appendchild a g doc createtextnode created with rapha l a version b appendchild this desc b appendchild this defs q defs a prototype remove function k raphael remove this this canvas parentnode this canvas parentnode removechild this canvas for var b in this this b typeof this b function a removedfactory b null var b a st for var c in a a b c b b c b c function a return function var b arguments return this foreach function c c a apply c b c window raphael window raphael vml function a var b hasownproperty c string d parsefloat e math f e round g e max h e min i e abs j fill k l a eve m progid dximagetransform microsoft n o p m m l l c c z x m t l r c v z x q clmz clmz gi r progid s blur g s s g t position absolute left 0 top 0 width 1px height 1px u 21600 v path 1 rect 1 image 1 w circle 1 ellipse 1 x function b var d ahqstv ig e a pathtoabsolute c b match d e a path2curve d clmz g if e a pathtoabsolute c b match d var g c b replace q function a b c var d e b tolowercase m g p b c replace s function a e d length 2 g d p b m l l d d push f a u return g d return g var h e b i j g for var k 0 l h length k l k i h k j h k 0 tolowercase j z j x for var m 1 r i length m r m j f i m u m r 1 o g push j return g join n y function b c d var e a matrix e rotate b 5 5 return dx e x c d dy e y c d z function a b c d e f var g a h a matrix k g fillpos l a node m l style o 1 p q r u b s u c m visibility hidden if b c l coordsize i r n i s m rotation f b c 0 1 1 if f var t y f d e d t dx e t dy b 0 p x c 0 p y o 1 m flip p l coordorigin d r n e s if k g fillsize var v l getelementsbytagname j v v v 0 l removechild v k t y f h x k 0 k 1 h y k 0 k 1 v position t dx o n t dy o g fillsize v size g fillsize 0 i b n g fillsize 1 i c l appendchild v m visibility visible a tostring function return your browser doesn t support svg falling down to vml nyou are running rapha l this version var a function a b d var e c b tolowercase split f d end start g e length h classic i medium j medium while g switch e g case block case classic case oval case diamond case open case none h e g break case wide case narrow j e g break case long case short i e g var k a node getelementsbytagname stroke 0 k f arrow h k f arrowlength i k f arrowwidth j b function e i e attrs e attrs var l e node m e attrs p l style q r v e type i x m x i y m y i width m width i height m height i cx m cx i cy m cy i rx m rx i ry m ry i r m r s w e type m cx i cx m cy i cy m r i r m rx i rx m ry i ry t e for var y in i i b y m y i y r m path a getpath e type e e dirty 1 i href l href i href i title l title i title i target l target i target i cursor p cursor i cursor blur in i e blur i blur if i path e type path r l path x c m path tolowercase indexof r a pathtoabsolute m path m path e type image e fillpos m x m y e fillsize m width m height z e 1 1 0 0 0 transform in i e transform i transform if s var b m cx d m cy e m rx m r 0 g m ry m r 0 l path a format ar 0 1 2 3 4 1 4 1 x f b e u f d g u f b e u f d g u f b u if clip rect in i var h c i clip rect split k if h length 4 h 2 h 2 h 0 h 3 h 3 h 1 var i l cliprect a g doc createelement div j i style j clip a format rect 1 px 2 px 3 px 0 px h l cliprect j position absolute j top 0 j left 0 j width e paper width px j height e paper height px l parentnode insertbefore i l i appendchild l l cliprect i i clip rect l cliprect l cliprect style clip auto if e textpath var k e textpath style i font k font i font i font family k fontfamily i font family split 0 replace g o i font size k fontsize i font size i font weight k fontweight i font weight i font style k fontstyle i font style arrow start in i a t i arrow start arrow end in i a t i arrow end 1 if i opacity null i stroke width null i fill null i src null i stroke null i stroke width null i stroke opacity null i fill opacity null i stroke dasharray null i stroke miterlimit null i stroke linejoin null i stroke linecap null var l l getelementsbytagname j m 1 l l l 0 l m l f j e type image i src l src i src i fill l on 0 if l on null i fill none i fill null l on 1 if l on i fill var n c i fill match a isurl if n l parentnode l l removechild l l rotate 0 l src n 1 l type tile var o e getbbox 1 l position o x n o y e fillpos o x o y a preload n 1 function e fillsize this offsetwidth this offsetheight else l color a getrgb i fill hex l src o l type solid a getrgb i fill error t type in circle 1 ellipse 1 c i fill charat r c t i fill l m fill none m gradient i fill l rotate 1 if fill opacity in i opacity in i var p m fill opacity 1 2 1 m opacity 1 2 1 a getrgb i fill o 1 2 1 p h g p 0 1 l opacity p l src l color none l appendchild l var q l getelementsbytagname stroke l getelementsbytagname stroke 0 t 1 q t q f stroke if i stroke i stroke none i stroke width i stroke opacity null i stroke dasharray i stroke miterlimit i stroke linejoin i stroke linecap q on 0 i stroke none i stroke null q on null i stroke 0 i stroke width 0 q on 1 var u a getrgb i stroke q on i stroke q color u hex p m stroke opacity 1 2 1 m opacity 1 2 1 u o 1 2 1 var v d i stroke width 1 75 p h g p 0 1 i stroke width null v m stroke width i stroke width q weight v v v 1 p v q weight 1 q opacity p i stroke linejoin q joinstyle i stroke linejoin miter q miterlimit i stroke miterlimit 8 i stroke linecap q endcap i stroke linecap butt flat i stroke linecap square square round if i stroke dasharray var w shortdash shortdot shortdashdot shortdashdotdot dot dash longdash dashdot longdashdot longdashdotdot q dashstyle w b i stroke dasharray w i stroke dasharray o t l appendchild q if t type text t paper canvas style display o var x t paper span y 100 z m font m font match d d px p x style m font p font m font m font family p fontfamily m font family m font weight p fontweight m font weight m font style p fontstyle m font style z d m font size z z 0 10 p fontsize z y px t textpath string x innerhtml c t textpath string replace g 60 replace g 38 replace n g br var x getboundingclientrect t w m w right left y t h m h bottom top y t x m x t y m y t h 2 x in i y in i t path v a format m 0 1 l 2 1 f m x u f m y u f m x u 1 var x y text font font family font weight font style font size for var ba 0 bb length ba bb ba if ba in i t dirty 1 break switch m text anchor case start t textpath style v text align left t bbx t w 2 break case end t textpath style v text align right t bbx t w 2 break default t textpath style v text align center t bbx 0 t textpath style v text kern 0 c function b f g b attrs b attrs var h b attrs i math pow j k l linear m 5 5 b attrs gradient f f c f replace a radial gradient function a b c l radial b c b d b c d c i b 5 2 i c 5 2 25 c e sqrt 25 i b 5 2 c 5 2 1 5 m b n c return o f f split s s if l linear var p f shift p d p if isnan p return null var q a parsedots f if q return null b b shape b node if q length b removechild g g on 0 g method none g color q 0 color g color2 q q length 1 color var r for var s 0 t q length s t s q s offset r push q s offset n q s color g colors r length r join 0 g color l radial g type gradienttitle g focus 100 g focussize 0 0 g focusposition m g angle 0 g type gradient g angle 270 p 360 b appendchild g return 1 d function b c this 0 this node b b raphael 0 this id a oid b raphaelid this id this x 0 this y 0 this attrs this paper c this matrix a matrix this transform sx 1 sy 1 dx 0 dy 0 deg 0 dirty 1 dirtyt 1 c bottom c bottom this this prev c top c top c top next this c top this this next null e a el d prototype e e constructor d e transform function b if b null return this transform var d this paper viewboxshift e d s d scale d scale 1 1t d dx d dy o f d f b c b replace 3 u2026 g this transform o a extracttransform this e b var g this matrix clone h this skew i this node j k c this attrs fill indexof l c this attrs fill indexof url g translate 0 5 0 5 if l k this type image h matrix 1 0 0 1 h offset 0 0 j g split if k j norotation j issimple i style filter g tofilter var m this getbbox p this getbbox 1 q m x p x r m y p y i coordorigin q u n r u z this 1 1 q r 0 else i style filter o z this j scalex j scaley j dx j dy j rotate else i style filter o h matrix c g h offset g offset f this transform f return this e rotate function a b e if this removed return this if a null a c a split k a length 1 b d a 1 e d a 2 a d a 0 e null b e if b null e null var f this getbbox 1 b f x f width 2 e f y f height 2 this dirtyt 1 this transform this transform concat r a b e return this e translate function a b if this removed return this a c a split k a length 1 b d a 1 a d a 0 0 b b 0 this bbox this bbox x a this bbox y b this transform this transform concat t a b return this e scale function a b e f if this removed return this a c a split k a length 1 b d a 1 e d a 2 f d a 3 isnan e e null isnan f f null a d a 0 b null b a f null e f if e null f null var g this getbbox 1 e e null g x g width 2 e f f null g y g height 2 f this transform this transform concat s a b e f this dirtyt 1 return this e hide function this removed this node style display none return this e show function this removed this node style display o return this e getbbox function if this removed return return x this x this bbx 0 this w 2 y this y this h width this w height this h e remove function if this removed this node parentnode this paper set this paper set exclude this a eve unbind raphael this id a tear this this paper this node parentnode removechild this node this shape this shape parentnode removechild this shape for var b in this this b typeof this b function a removedfactory b null this removed 0 e attr function c d if this removed return this if c null var e for var f in this attrs this attrs b f e f this attrs f e gradient e fill none e fill e gradient delete e gradient e transform this transform return e if d null a is c string if c j this attrs fill none this attrs gradient return this attrs gradient var g c split k h for var i 0 m g length i m i c g i c in this attrs h c this attrs c a is this paper customattributes c function h c this paper customattributes c def h c a availableattrs c return m 1 h h g 0 if this attrs d null a is c array h for i 0 m c length i m i h c i this attr c i return h var n d null n n c d d null a is c object n c for var o in n l raphael attr o this id this n o if n for o in this paper customattributes if this paper customattributes b o n b o a is this paper customattributes o function var p this paper customattributes o apply this concat n o this attrs o n o for var q in p p b q n q p q n text this type text this textpath string n text b this n return this e tofront function this removed this node parentnode appendchild this node this paper this paper top this a tofront this this paper return this e toback function if this removed return this this node parentnode firstchild this node this node parentnode insertbefore this node this node parentnode firstchild a toback this this paper return this e insertafter function b if this removed return this b constructor a st constructor b b b length 1 b node nextsibling b node parentnode insertbefore this node b node nextsibling b node parentnode appendchild this node a insertafter this b this paper return this e insertbefore function b if this removed return this b constructor a st constructor b b 0 b node parentnode insertbefore this node b node a insertbefore this b this paper return this e blur function b var c this node runtimestyle d c filter d d replace r o b 0 this attrs blur b c filter d n m blur pixelradius b 1 5 c margin a format 0 px 0 0 0 px f b 1 5 c filter d c margin 0 delete this attrs blur a engine path function a b var c f shape c style csstext t c coordsize u n u c coordorigin b coordorigin var d new d c b e fill none stroke 000 a e path a d type path d path d path o b d e b canvas appendchild c var f f skew f on 0 c appendchild f d skew f d transform o return d a engine rect function b c d e f g var h a rectpath c d e f g i b path h j i attrs i x j x c i y j y d i w j width e i h j height f j r g j path h i type rect return i a engine ellipse function a b c d e var f a path g f attrs f x b d f y c e f w d 2 f h e 2 f type ellipse b f cx b cy c rx d ry e return f a engine circle function a b c d var e a path f e attrs e x b d e y c d e w e h d 2 e type circle b e cx b cy c r d return e a engine image function b c d e f g var h a rectpath d e f g i b path h attr stroke none k i attrs l i node m l getelementsbytagname j 0 k src c i x k x d i y k y e i w k width f i h k height g k path h i type image m parentnode l l removechild m m rotate 0 m src c m type tile i fillpos d e i fillsize f g l appendchild m z i 1 1 0 0 0 return i a engine text function b d e g var h f shape i f path j f textpath d d 0 e e 0 g g i v a format m 0 1 l 2 1 f d u f e u f d u 1 i textpathok 0 j string c g j on 0 h style csstext t h coordsize u n u h coordorigin 0 0 var k new d h b l fill 000 stroke none font a availableattrs font text g k shape h k path i k textpath j k type text k attrs text c g k attrs x d k attrs y e k attrs w 1 k attrs h 1 b k l h appendchild j h appendchild i b canvas appendchild h var m f skew m on 0 h appendchild m k skew m k transform o return k a engine setsize function b c var d this canvas style this width b this height c b b b px c c c px d width b d height c d clip rect 0 b c 0 this viewbox a engine setviewbox apply this this viewbox return this a engine setviewbox function b c d e f a eve raphael setviewbox this this viewbox b c d e f var h this width i this height j 1 g d h e i k l f k i e l h d d k h b h d k 2 k e l i c i e l 2 l this viewbox b c d e f this viewboxshift dx b dy c scale j this foreach function a a transform return this var f a engine initwin function a var b a document b createstylesheet addrule rvml behavior url default vml try b namespaces rvml b namespaces add rvml urn schemas microsoft com vml f function a return b createelement rvml a class rvml catch c f function a return b createelement a xmlns urn schemas microsoft com vml class rvml a engine initwin a g win a engine create function var b a getcontainer apply 0 arguments c b container d b height e f b width g b x h b y if c throw new error vml container not found var i new a paper j i canvas a g doc createelement div k j style g g 0 h h 0 f f 512 d d 342 i width f i height d f f f px d d d px i coordsize u 1e3 n u 1e3 i coordorigin 0 0 i span a g doc createelement span i span style csstext position absolute left 9999em top 9999em padding 0 margin 0 line height 1 j appendchild i span k csstext a format top 0 left 0 width 0 height 1 display inline block position relative clip rect 0 0 1 0 overflow hidden f d c 1 a g doc body appendchild j k left g px k top h px k position absolute c firstchild c insertbefore j c firstchild c appendchild j i renderfix function return i a prototype clear function a eve raphael clear this this canvas innerhtml o this span a g doc createelement span this span style csstext position absolute left 9999em top 9999em padding 0 margin 0 line height 1 display inline this canvas appendchild this span this bottom this top null a prototype remove function a eve raphael remove this this canvas parentnode removechild this canvas for var b in this this b typeof this b function a removedfactory b null return 0 var g a st for var h in e e b h g b h g h function a return function var b arguments return this foreach function c c a apply c b h window raphael;-2.6799114;-0.36090603;-1.5536194;-1.8770479;1.881986;1.5706525;CODE
background jpg xff xd8 xff xe0 x00 x10jfif x00 x01 x02 x00 x00d x00d x00 x00 xff xec x00 x11ducky x00 x01 x00 x04 x00 x00 x00d x00 x00 xff xee x00 x0eadobe x00d xc0 x00 x00 x00 x01 xff xdb x00 x84 x00 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x01 x02 x02 x02 x02 x02 x02 x02 x02 x02 x02 x02 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x01 x01 x01 x01 x01 x01 x01 x02 x01 x01 x02 x02 x02 x01 x02 x02 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 x03 xff xc0 x00 x11 x08 x03 x00 x00 n x03 x01 x11 x00 x02 x11 x01 x03 x11 x01 xff xc4 x00k x00 x01 x01 x01 x01 x01 x01 x00 x00 x00 x00 x00 x00 x00 x00 x00 x00 x00 x03 x02 x01 x04 t x01 x01 x01 x01 x01 x01 x01 x00 x00 x00 x00 x00 x00 x00 x00 x00 x00 x00 x01 x02 x03 x06 x07 x10 x01 x00 x02 x01 x04 x01 x05 x01 x01 x00 x00 x00 x00 x00 x00 x00 x00 x01 x12q xf0 x11a xa1q x91 xd1 xe1 x02 x13 x81b x11 x01 x01 x01 x01 x00 x03 x01 x01 x00 x00 x00 x00 x00 x00 x00 x00 x00 x11 x01 x12 qa x02 xff xda x00 x0c x03 x01 x00 x02 x11 x03 x11 x00 x00 xf9 xc6 xf7 x0f x9e x80 x00 x0e xb5 xc8 x1c x8a x8e x00 x00 x005 xb15 xa9 x86 xc4 xd2c xad x00 x00 xe8 xb3 x9a xady xe9nz x8a xf3 xd1s xd1 xd3h xc8 x00 x00 xad x86 xae x14 xf0x 6 x8c x80 x00 n xd25 x0b xe1 xab x9e x8af xa0 xf0 xf4 xda2 x03 xa2 xcd x02j xd5 x8c xd2 xe9x xc1t xba xea x0e xed8 x9ff xa7 xd2 xe1 xb4 xe2 t xf4 xb8 xa8 xe6 x00 x006 xd3 xa0 x00 x00 xa5 7 xcf xd5 xf0ru xb1 xcf xd3 xc2 xaa xc8 x0e xed 5f x9bi4 x9a xb6 xd1 x88 x0b xa6 xd1 x88 x0b xae xa2 x00 xb5c x95 xabt xacrr xebh x80 o x1d xaf x85 xf0s xc7g x83 xc2 x88 x805yjb xc2 xe2 x83 x00 y xd6 xe4xvu xb9 x08 xb8 x80 xb4 xaf xa5 x9am xa2k xd0 xda x00m 4 xdabj xfbf x9bf xbam x9a x xc1un x95 x8c x17k xad x00 x0bv x16 xe9j xc1t xad x02 xb4 x82 x85 xa3 x02 xbf x9f x9dg xa7 xcf xcf x9e xben xb3 xd1 xda xac xb9 x80 xa55 xa8 x0b xe0 xa6 xb5 x07 x83 xc2 x88 x80 xf9 xf8u x9f x9fa xf9 xf8 xe7 xd0 xaa x005ik xc0ro x02 xcc x80 y xc4 xb53 xd8vq xcfb xec x80 x0b5 x02h xbe xd1 x88 x16 xe9 xb4b x02 xeb xa4 xd4 t xa3 xd1o xae x9ft xeb xba xfd x14 xfa xe3 xb9 xf7 xd3 xaf xd3h xc8 n xd22 xb7 xe1 xe0 xa4d xbf x0f r xa0 x03t x9cw x0e x9c xfe x85 x1d xc1 xcf xe7 xe8 xb0 x00 xd4 t xa2 xfbf xd0 xba x1bf xd0 xba x8a x02 x94 x9c xc3w x02 x93 x98 n2 x005 xce xa0s xa2 xfbf x95 xbam x18 x80 xba xe8 x00 xd5 x1d xc7 xbb xca x14 x9cw x1e xe7 xf2 xca x80 x00 x0b xfe xeb xaf x95 xef xe34 xfc xbf xd7 x7f n xb3 x9b x0b7 xd6 x817 xd6 x8a xd3 x9e xbe zb x9c xf5 xf2t xca x80 x00 rw xed x8e xe1 xbb x88w xed x8e xe0 xb8 xc2 x80 x00 x03 xa0r h xe7 xc3 xad ng xfe x1dh xdb x00 x00 rs xa8 x1c xe8 xdd x85 xeb x02 x93 xc1 xd6 n xb0 xa0 xff xd9;0.12799177;0.44376662;-0.9458875;-7.415273;0.51937354;2.3661737;CODE
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
console instance;-4.7641478;-1.2991298;4.0766687;1.8040596;-0.7461398;-0.23217957;CODE
determine if we can just highlight the current one;-1.2334363;2.229035;4.2012773;2.0702715;3.0798728;-0.76625764;-
or if we need to rebuild the breadcrumb;-2.2149847;-1.526238;4.410821;3.4457479;0.50574595;2.2042902;TASK
ok so just toggle this one instead;-5.1217155;-0.5773418;3.5593584;-0.4869624;-1.483283;1.0915788;CODE
we need to rebuild the breadcrumb;-3.0816627;-1.6662233;4.2721357;2.3791275;-0.6390491;1.3858923;TASK
normal call tree node focus;-2.1312578;-0.35067624;1.6148945;0.038368173;-0.8092335;3.7994733;IRRE
nested call widget prop value prop key index in dict list;-1.9215572;1.5626521;-0.6557013;-1.3850969;-0.3931307;0.7813954;IRRE
normal call;-2.0458574;2.7283762;4.6167746;0.920695;0.20432928;-1.6028675;IRRE
nested call we might edit subvalue;-0.03607114;4.595629;1.3418175;1.7498553;3.1103706;0.31233308;IRRE
trying to resolve type dynamically;-3.1772938;4.5439515;-0.36118007;0.34124848;2.8404925;-0.35398224;IRRE
widget no longer exists just remove it;-5.8581533;0.44433048;1.981887;-0.4401185;-4.427018;2.674994;OUTD
array of addons that will be created at console creation;-4.5392604;0.16722693;2.210271;-0.41158947;0.34871224;0.2531896;CODE
addons consoleaddonmode;-7.0725846;0.2216904;1.6535152;0.77369297;-1.1873816;1.3851619;CODE
display mode of the console either docked at the bottom or as a;-5.335367;0.56057787;4.760161;-1.8761175;-2.13503;1.5302329;CODE
floating window;-4.008512;-0.19339024;5.375181;-1.5018091;-2.4111178;0.574667;CODE
current widget being selected;-3.5459635;0.12890302;4.22654;1.7669566;-1.9914284;3.4428246;CODE
indicate if the inspector inspection is enabled if yes the next;-3.3854842;3.0992668;-0.1683932;4.3462186;0.6556172;-0.23794185;-
touch down will select a the widget under the touch;-4.214679;-2.1387444;5.506364;0.25702864;-2.989509;2.912843;CODE
true if the console is activated showed;-5.4784374;1.0948812;2.4975703;2.9130068;-1.9625115;-0.040149957;CODE
instantiate all addons;-5.1492863;0.44082034;1.3193121;1.1135813;1.8003191;1.0881014;TASK
select the first panel;-2.7076788;1.9688902;5.8931446;-2.0210054;0.002050434;2.2828186;CODE
reverse the loop look at children on top first and;-0.29549623;2.9846127;6.438777;-2.6015677;-0.10554262;-2.2567072;IRRE
modalviews before others;-3.8517873;0.09033052;5.3495407;1.3259665;1.3355569;5.9617424;CODE
no widget to highlight reduce rectangle to 0 0;-2.0586798;2.22828;1.9946831;-2.3984454;-3.8606946;3.268763;CODE
try to filter widgets that are not visible invalid inspect target;-3.00886;2.2704005;-2.5729206;3.1457295;-3.3367364;1.8028352;OUTD
reverse the loop look at children on top first;-0.10629296;3.1284459;6.3794303;-1.9936886;-0.24641593;-1.1163024;IRRE
self win remove widget self;-4.924589;1.4401315;1.62945;0.1431281;-2.5587478;3.5495212;CODE
if scancode 273 top;-1.3246753;2.5353115;0.8469819;-3.0049837;1.5488585;-5.0947833;-
elif scancode 274 down;-4.2763186;-0.123405196;-2.9628832;-2.219346;0.34328344;-4.32982;CODE
elif scancode 276 left;-3.1747482;0.430591;-1.8034041;-3.6696103;0.70869315;-4.9379597;-
elif scancode 275 right;-1.8939992;0.5546263;-2.0966964;-3.5111985;0.8478916;-5.935531;-
top bar;-3.11282;-1.2955688;7.1378393;-2.0374775;-1.1695815;-0.43978822;IRRE
bottom bar;-3.882916;-1.4807004;6.9194803;-2.6687071;-1.5155716;-0.7900166;IRRE
reverse the loop look at children on top first and;-0.29549623;2.9846127;6.438777;-2.6015677;-0.10554262;-2.2567072;IRRE
modalviews before others;-3.8517873;0.09033052;5.3495407;1.3259665;1.3355569;5.9617424;CODE
no widget to highlight reduce rectangle to 0 0;-2.05868;2.22828;1.9946824;-2.3984463;-3.8606942;3.268763;CODE
try to filter widgets that are not visible invalid inspect target;-3.00886;2.2704005;-2.5729206;3.1457295;-3.3367364;1.8028352;OUTD
reverse the loop look at children on top first;-0.10629386;3.1284454;6.3794303;-1.9936877;-0.2464167;-1.1163011;IRRE
normal call tree node focus;-2.1312578;-0.35067624;1.6148945;0.038368173;-0.8092335;3.7994733;IRRE
nested call widget prop value prop key index in dict list;-1.9215572;1.5626521;-0.6557013;-1.3850969;-0.3931307;0.7813954;IRRE
normal call;-2.0458574;2.7283762;4.6167746;0.920695;0.20432928;-1.6028675;IRRE
nested call we might edit subvalue;-0.03607049;4.5956297;1.3418174;1.7498542;3.11037;0.31233206;IRRE
trying to resolve type dynamically;-3.1772938;4.5439515;-0.36118007;0.34124848;2.8404925;-0.35398224;IRRE
widget no longer exists just remove it;-5.8581533;0.44433048;1.981887;-0.4401185;-4.427018;2.674994;OUTD
dunno why but if we are creating inspector within the start no lang;-6.507102;-1.1419934;-0.6428196;3.1635838;0.67404467;1.189438;META
rules are applied;-2.0672166;-0.37122393;2.6640124;3.3132873;3.9421754;-1.3305436;-
draw cursor;-2.670632;-1.2601621;6.4584894;-3.9087143;-3.4335752;-0.863641;-
pull joycursor to the front when added;-5.0701737;1.1082408;4.492119;-0.116514936;-1.3447114;2.9948492;TASK
as a child directly to the window;-5.42938;-2.212932;6.7366605;0.7605893;-0.61902994;1.0585467;CODE
bind unbind when joycursor s state is changed;-4.257484;3.1490495;1.4616066;0.9741188;-0.8751635;3.6220298;-
create cursor points;0.23912352;-0.8956691;4.0192995;-4.6375575;-1.7730668;0.5848286;IRRE
check axes and set offset if a movement is registered;0.056579437;3.8384469;2.2074928;-1.4867601;-2.559415;1.9078766;IRRE
invert y axis to behave like mouse;-0.043612096;0.4037771;4.5343094;-5.2572856;-6.130951;3.1588745;-
set intensity of joycursor with joystick buttons;-0.9563607;1.460926;2.574949;-2.5121047;-1.4086186;3.0622492;IRRE
window event correction necessary;-2.672258;0.7060979;1.8393127;3.2813642;-1.0254544;1.7152702;CODE
move joycursor as a mouse;-3.0232282;-0.75412625;3.302404;-2.6362727;-3.1411755;1.7810093;-
pin the cursor to the mouse pos;-3.9263508;-1.4334824;3.8833902;-1.133159;-2.5966864;1.9149852;CODE
always listen for joystick input to open the module;-4.2487817;1.2715725;1.3894197;1.5321879;-1.9144949;2.3583598;CODE
like a keyboard listener;-2.5650704;-4.0126233;6.541293;1.1983614;0.30302587;-0.5867841;-
if key 293 and modifiers f12;-2.8475635;2.1738238;-1.7447661;-1.0320362;2.59867;-4.844196;-
elif key 292 and modifiers f11;-3.448956;-1.269693;-3.5654166;-2.7656903;2.218648;-3.303782;-
elif key 292 and modifiers shift shift f11;-3.0529892;-0.99267715;-3.2956765;-3.7185032;0.2220526;-1.1411142;-
late import to avoid breaking module loading;-4.066905;-0.3605217;-2.9752526;3.2547765;-2.3632796;2.0886145;CODE
if key 289 f8;-4.7704773;2.0242927;1.3150531;-2.0163329;1.0271076;-5.15718;-
elif key 288 f7;-3.9688013;-1.8701766;-1.1140546;-3.006876;0.70937014;-4.351431;-
elif key 287 f6;-5.2385216;-1.6284953;-1.1203889;-3.1695595;1.0487759;-3.7809682;-
attributes;0.2576558;-3.22067;3.3483093;0.8768757;4.9077525;-1.3673276;META
profile mask;-0.79884124;-2.369574;3.3382583;-2.483755;0.31548223;2.8908474;-
filename;-4.737769;-3.0031154;4.0040417;-1.2405667;0.7650533;-2.6931474;-
taken from http en wikipedia org wiki list of displays by pixel density;-1.0988998;-2.062988;2.0505536;-3.6391585;-1.1728354;2.3239255;CODE
device name width height dpi density;-1.2212234;0.47839263;-0.578081;-4.429957;-0.1750482;4.0314226;-
taken from design google com devices;-4.7083635;-4.8811126;3.008293;-1.0607855;1.0744936;1.0234548;CODE
please consider using another data instead of;3.8760111;1.8668277;2.730345;0.00069499336;0.89879996;-1.4747158;CODE
a dict for autocompletion to work;-2.182372;-1.4339323;-1.0374955;2.498177;0.1432291;-2.473791;CODE
these are all in landscape;-1.4272853;-3.2437148;4.6920733;-1.0867497;1.4710329;0.9739613;-
simulate with the android bar;-1.9390746;-0.30616137;4.986126;0.022930328;-1.9164511;2.5759945;IRRE
fixme should be configurable;-5.752615;-1.2639065;-0.21594343;1.6667591;-2.6097252;4.0097904;-
xxx use ctx;-4.560111;0.90604013;2.7087667;-2.1956596;1.8052492;-0.214725;-
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
this will call max on the result dictionary so it s best to store;2.1687453;1.7785779;1.5599934;0.22761063;3.285042;-1.8215026;IRRE
it instead of calling it 3 times consecutively;-6.065577;2.9856036;3.4441898;1.0248485;1.6877753;-1.3440953;IRRE
bind your callbacks to track all matching operations;-2.0476897;3.0649846;2.3081698;4.1638293;2.1644747;1.7056727;IRRE
the format below is referred to as strokes a list of stroke paths;-2.1156442;-3.3348196;4.6581287;-3.6987412;2.9717364;-0.33472037;CODE
note that each path shown here consists of two points ie a straight;-1.1753013;0.48667026;4.8349514;-3.4105906;-1.7742009;-0.77915704;TASK
line if you plot them it looks like a t hence the name;-0.33976975;-0.56039137;5.0597215;-4.61944;-3.9513657;-1.1243485;-
now you can search for the t gesture using similar data user input;-0.26080966;-1.2423377;3.707526;-0.5792369;-0.50066733;1.1284124;CODE
this will trigger both of the callbacks bound above;-5.400219;2.4537153;2.3571494;3.9437466;-0.97386545;3.7495599;IRRE
same as above but keep track of progress using returned value;0.74818057;3.8474705;5.3447638;3.7227106;-0.015776593;-1.7142762;IRRE
print progress progress 0;-1.7257781;1.645174;2.731902;-1.6426677;-2.9683213;-2.5021436;CODE
assuming a kivy clock clock tick here;-1.796346;-0.077590786;4.9600716;-0.2985876;-1.9619813;-2.4033022;-
print result progress 1;-0.34806433;2.2441719;3.946606;-0.7373938;-1.6678905;-4.689276;IRRE
default number of gesture matches per frame;0.19254643;1.992269;1.8002527;-0.9384926;0.16701856;2.3438485;CODE
fixme relevant number;-2.4674714;1.776376;1.5729029;0.2712698;0.16850066;-2.507984;-
algorithm data;5.8306503;-2.4027236;3.0810883;-1.3759974;3.767302;-4.015882;-
recognizer;1.1273544;-4.4750648;0.85969704;0.12985623;2.9541457;-1.2455077;-
will match all names that start with a capital n;-1.1732322;0.16782965;0.9655071;-1.9760026;3.5343583;-3.532346;CODE
ie next new n nebraska etc but not n or next;-1.6831453;-0.28074175;2.9696696;1.388909;1.8446529;-0.71326065;META
exactly n;-1.30755;-1.5046148;3.0130618;-2.3636272;0.15447155;-2.3234396;-
nebraska teletubbies france fraggle n n etc;-1.3798453;-1.4014007;2.835554;-1.2027001;-0.5151612;-0.7507559;CODE
max priority 50;-1.1199998;0.9463103;3.0605433;0.48902583;2.334758;0.38111436;-
max priority 50 same result as above;1.2763003;3.8621023;1.1524622;-0.2949272;1.7432368;0.33870825;IRRE
min priority 50 max 100;-0.4431042;2.1680999;2.545559;-0.4909851;2.5356007;0.5390475;-
prepare a correctly sorted tasklist;0.46586204;1.0340134;2.5676606;2.165381;1.0969405;-0.19085662;TASK
now test each gesture in the database against filter criteria;2.0479887;3.0795038;0.7394479;5.186417;2.3777056;-0.23077135;CODE
fixme use a try block maybe shelve or something;-5.9345655;3.5707545;-0.6243334;3.4714632;-3.4333727;-0.6911867;CODE
fixme match them all with protractor and don t load exacts or;-0.9296649;1.2033004;-2.9652278;-0.22999293;-1.039453;0.16505142;CODE
just compare the data or something seems better to do this on import;5.3047028;1.3795408;-0.9896671;0.70080096;0.17287523;-1.5964478;CODE
than on every subsequent call to recognize and fix it in general;-0.36112148;0.34793633;1.978676;6.290499;1.1515036;-1.6116489;IRRE
too;-1.7322359;-1.8354214;3.278208;1.435351;-1.1778053;0.0069642067;-
obtain a list of multistrokegesture objects matching filter arguments;1.2476404;0.92223954;-0.5345294;1.0886503;4.9516134;-0.052394107;IRRE
initialize the candidate and result objects;1.5158795;2.232905;0.9170292;3.7977457;4.991703;-1.6211832;IRRE
this is done to inform caller if they bind to on complete and there;-6.543201;1.3600141;2.5418947;3.7120035;3.4045799;1.7838211;CODE
is nothing to do perhaps should just return none;-5.001506;5.610494;-1.0260727;1.7079798;-3.4542894;-1.6734328;IRRE
this callback is scheduled once per frame until completed;-4.6538305;2.6273;2.447299;3.9785485;-2.8403628;2.7343097;CODE
get the best distance and number of matching operations done;4.7920046;1.0119567;3.8374836;-1.600757;3.5410721;-1.5177183;CODE
the loop has ended prepare to dispatch complete;-4.1157694;1.9886551;0.93395203;3.026619;-0.5188181;-1.9230944;CODE
dispatch or reschedule another run;-3.5675774;0.9767346;2.8083613;4.7799034;0.6920098;2.1447487;CODE
end recognize tick;-1.9173955;0.8674368;2.5707433;-0.87049586;-0.7865255;-1.6307789;CODE
recognize helper function do not use directly set up a;-3.4910223;0.6128069;-1.6897067;0.67446744;0.15104374;-0.50349855;CODE
candidate object from arguments either use a specified object;0.2645768;2.225357;-0.5790768;2.7894874;4.8753815;-1.1510783;CODE
or make a new one from strokes and apply safe skip settings to;-4.3724284;1.2890837;0.19763422;3.1161652;-0.917979;3.7767406;CODE
use less resources;-1.6110657;-2.3157582;4.7909584;2.8784456;0.14342389;2.41755;-
default event handlers;-5.7286158;-1.6068246;3.4137511;3.5089307;-1.1031547;3.4707239;CODE
progresstracker;1.7814099;-3.0989254;4.052288;1.1570218;-0.17136674;-2.8868513;-
fired by recognize;-1.0713586;-1.9409454;0.1464801;2.6766543;0.8336199;-1.6806785;-
fired locally;-2.8442914;-0.7954437;2.2560766;2.9769764;-1.4895552;-0.09094964;IRRE
results self results to avoid too many self lookups;4.845068;0.9604375;-0.026902651;2.8658845;2.5673647;-1.2721188;CODE
add a result used internally by the recognize function;1.2924999;1.4393375;-0.9107943;1.50461;2.6071837;-1.186923;CODE
multistrokegesture;-0.3239063;-0.7163662;3.7475955;-0.20113948;3.7676048;0.9094993;-
vector x1 y1 vector x2 y2 stroke 1;0.62395567;-0.42959142;0.79030377;-5.0818353;-1.5911545;0.44930056;-
vector vector vector vector stroke 2;-0.9415494;-1.6287974;1.6227542;-4.2431684;-1.2049696;-1.7072495;-
stroke 3 stroke 4;-2.6451004;-0.19142316;2.9420753;-0.9234763;0.9421835;-2.2711246;-
optimal cosine distance inlined here for performance;3.6353636;0.8158334;1.8050796;-1.0307978;-2.2139318;2.7316961;CODE
if you put the below directly into math acos you will get a domain;-2.2078712;-1.0405447;1.539341;-3.3591046;0.43345806;-2.2862923;CODE
error when a 1 0 and angle 0 0 ie math cos angle 1 0 it seems to;-2.3038242;2.6560128;-2.1835692;-3.7388449;-4.286481;-3.168204;-
be because float representation of 1 0 1 0 is 1 0 ie 1 00000 001;-0.14275408;1.9645767;-3.0214612;-6.6949835;-1.3661296;-3.0191967;CODE
and this is problematic for math acos;-0.41264644;0.20483498;0.5227583;-1.1653906;0.18844315;-3.0401745;CODE
if you try math acos 1 0 1 0 in interpreter it does not happen;-3.4197445;1.3365707;-2.691776;-2.8965776;-2.8133688;-5.6213336;CODE
only with exact match at runtime;0.52941823;4.164029;0.22973976;3.4610567;3.6804712;0.07884754;CODE
fixme i m sure there is a better way to do it but;-4.5990157;-0.98925424;2.7212775;1.2527728;-0.16455962;2.286654;TASK
elif result 1 has not happened to me but i leave it here;-1.3324437;2.839092;-0.45876092;1.4303206;-1.632041;-5.8676276;IRRE
handle a theoretical case where a multistrokegesture is composed;0.42322415;1.0595541;1.7519958;2.581349;5.7384205;2.409522;CODE
manually and the orientation sensitive flag is true and contains;-2.8921278;4.008965;-2.1009886;-0.574807;1.5313089;0.5943901;-
a unistroketemplate that has orientation sensitive false or vice;-1.8211355;0.19245675;0.5173837;-0.9073289;0.7043942;1.8060056;-
versa this would cause keyerror requesting nonexistent vector;-2.3071492;1.476608;-7.1529837;-3.0925636;-3.278722;-0.21010226;CODE
count as a match operation now since the call to get;-0.8117314;5.227791;2.4936826;3.1873112;3.1363533;-3.5832896;IRRE
angle similarity below will force vector calculation;3.2967827;0.86511505;-0.47431046;-3.4785051;-1.5991881;0.8212947;CODE
even if it doesn t make it to get distance;0.24453285;2.4965084;4.2374187;1.6802453;-2.337962;1.8416834;CODE
note with this implementation we always resample the candidate;5.838952;0.37713942;-2.2161007;2.702151;3.8536694;2.3818727;TASK
to any encountered unistroketemplate numpoints here the filter;-0.39078456;0.77891356;-1.6088122;-1.9690183;-3.3407252;2.5941205;CODE
is only applied to multistrokegesture see theoretical case;-0.076547116;0.89261776;0.39994678;2.5012233;3.9695323;2.880653;CODE
above should not matter normally;-2.2075517;1.8461294;2.4029372;-0.65303034;1.0480084;1.2170503;-
skip if candidate gesture angles are too far off;0.0019400696;3.2730289;0.8875938;2.149847;0.37797466;1.2769399;-
get the distance between cand tpl paths;0.29374665;2.1334298;2.0227232;-3.5541613;-1.9449539;0.5659425;-
seed with index of each stroke;2.4190035;0.21724458;3.818919;-1.8286755;2.365247;-1.1567007;-
prepare orders;-3.5877922;0.15898655;3.77077;0.9805849;3.2561023;-1.7432021;-
generate unistroke permutations;0.9981591;0.35896176;3.3558295;-4.01983;1.6447625;-1.1872973;-
heap permute algorithm;0.9706644;0.7396105;1.6182114;-3.1819885;2.5549963;-0.81246793;-
create unistroke permutations from self strokes;0.017009614;-0.14639626;3.9402719;-3.816962;0.9772474;0.56798697;CODE
while b pow 2 len r use b s bits for directions;-1.4573303;-0.20104802;0.11472515;-5.270284;0.40249255;-1.999014;CODE
if b i 1 1 is b s bit at index i 1;0.58036107;3.32388;-0.4334638;-5.7883058;2.8029165;-2.175958;-
unistroketemplate;-3.3482256;-1.1093547;1.810584;-0.25529397;-0.7840383;-0.23288815;-
all previously computed data is now void;-0.081602834;4.101283;-2.104822;1.6613404;-1.8090146;0.21483018;CODE
used to lazily prepare the template;-2.730975;-1.9650797;0.86287016;2.9416733;2.0298479;1.9956897;OUTD
how many points are we resampling to;5.4974666;-0.16162707;2.9470966;-0.4118778;-0.84153044;1.178547;CODE
p rotate by p radians restore;-1.5712055;1.4045188;1.0537713;-3.1984081;-3.2028105;2.4608488;-
now store it using the number of points in the resampled path as the;4.49815;2.0787346;2.2743824;-2.1709397;-0.689086;4.079184;CODE
dict key on the next call to get it will be returned instead of;-5.5014095;1.7393904;0.5170397;1.7627288;-1.5453199;-1.150436;IRRE
recomputed implicitly you must reset self db or call prepare for;-5.195057;2.4333994;-4.628128;4.4158306;-0.65043414;0.82285994;IRRE
all the keys once you manipulate self points;-1.5701003;-2.009112;4.1760073;-1.8274541;0.758496;-0.2827353;CODE
compute startangleindex as n 8;-0.37187535;0.92573017;-0.38400903;-6.65538;0.5449764;-1.2129972;IRRE
candidate;-0.13416648;-1.8540678;3.9304278;2.7851288;2.4437578;-3.249628;-
used to lazily prepare the candidate;0.2404373;-1.9882283;0.5998559;5.595897;4.3137417;-2.4153566;OUTD
angle between unit vectors inlined here for performance;2.444014;-0.03412159;1.1197051;-2.9923134;-2.047974;2.2500546;CODE
fixme domain error on float representation of 1 0 exact match;0.15228452;4.145181;-5.1681614;-3.6815543;-3.4513538;-0.3216387;CODE
see comments in multistrokegesture get distance;-0.5760909;0.84894675;3.542043;-0.21388423;0.6022034;0.15619588;-
inlined combine strokes for performance;0.49010772;-0.7290224;2.6150362;-0.08056274;2.267802;2.2160988;CODE
compute startangleindex as n 8;-0.37187535;0.92573017;-0.38400903;-6.65538;0.5449764;-1.2129972;IRRE
full rotation invariance;0.6084664;-0.3178521;0.44601083;-1.8119856;-1.5937291;5.097489;CODE
rotation bounded invariance;0.7064531;0.13612746;-0.040466256;-0.7095111;-1.8065939;4.999853;CODE
bound points rotate by points radians restore;0.57222867;1.007458;1.5819021;-3.574141;-4.1963787;3.3842623;CODE
helper functions from this point on this is all directly related to the;-2.190026;-3.442979;3.7458768;0.54895204;0.9848663;0.8253873;CODE
recognition algorithm and is almost 100 transcription from the javascript;1.1771833;-3.5586803;1.6863676;-1.7056419;1.3108549;-1.8384618;CODE
resample a path to n points;5.4936085;0.62409234;3.0058024;-2.896047;-1.2374859;2.1053894;CODE
work insert i q q is the next i;-3.9449618;0.5006656;3.5418568;-1.0367413;1.6544745;-2.1822772;CODE
rounding error insert the last point;0.7914349;5.020209;0.40530127;-3.5493402;-3.9795175;-3.1517687;CODE
rotate points around centroid;0.16347566;1.072825;3.416719;-4.606606;-2.295924;3.2164977;CODE
1d or 2d gesture test;1.399262;0.896552;2.4135668;-0.17985559;-1.0321369;-1.2912643;IRRE
translate points around centroid;1.7548873;1.1122813;3.5722716;-5.891091;-2.095592;2.3542054;CODE
helper function for the protractor algorithm;1.0356357;-0.41469747;-1.0672747;-1.0312611;1.0715271;1.146825;CODE
depending the platform if openssl support wasn t compiled before python;-4.072709;-2.921436;-4.4502735;0.36519042;-2.5095367;-0.4281847;CODE
this class is not available;-5.940044;-2.5861642;0.63868475;-0.45568213;0.8225983;-2.098297;CODE
list to save urlrequest and prevent gc on un referenced objects;-3.3449252;1.22001;0.1542261;4.9547305;1.3331106;3.8855405;CODE
url of the request;-6.4045205;-0.61220735;5.393699;0.9104338;-0.4046526;1.2380475;CODE
request body passed in init;-6.131793;2.3830426;1.1279981;3.0680861;-0.82941777;2.687497;IRRE
request headers passed in init;-6.1220694;1.6516;-0.21074235;2.347746;-0.24127522;3.2504354;CODE
save our request to prevent gc;-4.354266;1.2890788;1.6300532;4.2256556;-0.97479206;2.3958907;CODE
using trigger can result in a missed on success event;-2.6817725;4.300162;-0.42653722;5.1203094;-2.9053082;-0.9489252;IRRE
clean ourself when the queue is empty;-3.1539695;3.0664074;2.2563503;3.7359223;0.46883842;2.279269;TASK
ok authorize the gc to clean us;-3.7170548;-1.6318339;-0.46682748;2.5647864;0.14115274;0.046963632;TASK
parse and fetch the current url;-3.782407;1.8970423;4.097706;2.6346073;0.1008893;0.22280206;IRRE
read content;-3.0872667;-3.0574515;4.6718264;0.93873656;0.6034679;-1.6072539;CODE
before starting the download send a fake progress to permit the;-4.63541;-0.15741108;0.6540858;4.5028315;-2.6518362;1.7692833;CODE
user to initialize his ui;-5.606361;-1.4269042;5.3002176;1.0435404;-0.12637582;2.3016384;IRRE
ensure that results are dispatched for the last chunk;1.8076234;4.9124966;1.9160615;4.803575;1.8696961;-0.7182131;IRRE
avoid trigger;-2.4928954;2.370639;2.0805447;4.772144;-0.14237669;0.9022698;CODE
if it s an image decoding would not work;-1.6262431;-0.41761854;1.7570393;-2.756357;-1.3578638;2.12907;-
return everything;-3.1518548;3.820401;4.09464;2.3540628;-0.737178;-1.7226356;IRRE
entry to decode url from the content type;-3.3852146;0.1949566;-0.5673005;-0.13510442;1.6194541;1.6770604;CODE
for example if the content type is a json it will be automatically;-3.04475;-0.18550189;0.432773;3.8820958;1.0056334;3.5207171;IRRE
decoded;-2.3146837;-2.1049116;1.9637982;-0.7946045;2.1752203;-3.5234604;-
read the result pushed on the queue and dispatch to the client;-3.0987492;1.4077699;2.6636412;3.7299604;-0.18849134;1.1183175;CODE
small workaround in order to prevent the situation mentioned;-3.957819;2.7780955;-0.13472205;4.349187;-1.3360268;4.200749;-
in the comment below;-3.7280548;-3.3191922;3.9047782;-0.5274394;0.6129712;-1.2761141;CODE
xxx usage of dict can be dangerous if multiple headers;-4.1429615;0.555052;-2.176865;-1.1382259;1.6072588;-0.92542726;CODE
are set even if it s invalid but it look like it s ok;-3.4872398;4.0755963;-1.1510675;2.6731408;0.73365015;-1.1518056;IRRE
http stackoverflow com questions 2454494;-4.9006267;-1.896425;1.5904826;-2.1713138;1.37749;-2.4660668;CODE
urllib2 multiple set cookie headers in response;-3.3425376;1.5117662;0.7889217;0.4414222;0.6181572;1.8174326;CODE
append user pass to hostname if specified;-4.064843;3.074515;2.3844886;0.96352047;0.51634634;-0.69454294;CODE
parse url;-3.7736406;0.20999373;3.635272;0.5406932;0.75724506;-0.6475595;IRRE
translate scheme to connection class;-2.791322;-2.1319077;-0.46276587;-0.33747926;1.5958177;1.7715052;CODE
reconstruct path to pass on the request;-5.5092325;1.9921731;2.9855933;2.7298248;-0.5467163;3.9447823;CODE
path parse fragment;-3.5892692;-0.0707097;1.2626196;-0.11760998;0.62930864;2.498805;IRRE
create connection instance;-3.0758193;-2.225001;2.8224568;0.25320926;0.60102177;1.6299347;IRRE
send request;-5.2585063;-1.0491412;5.9029784;0.14366707;-1.1475265;-1.1730255;CODE
read header;-5.4292297;-0.72891957;2.397196;-0.25975123;-0.16914758;-1.083129;CODE
get method;-3.160488;2.2951815;3.8778653;3.3957849;0.42212844;-2.5825422;-
send request;-5.2585063;-1.0491412;5.9029784;0.14366707;-1.1475265;-1.1730255;CODE
show warning and return a sane value;-0.63622326;6.855661;-0.96725833;3.405486;-0.75214463;-3.436768;IRRE
rgb;-1.1334099;-1.6814802;4.24524;-2.2024093;0.056909773;-1.3276819;-
rgba;-0.63772655;-1.4240746;3.110712;-1.9985543;0.5531852;-0.69020456;-
rrggbb;-1.1411371;-2.6972978;2.8353536;-1.6390716;-0.011158611;-3.2483046;-
rrggbbaa;-1.5172365;-2.101935;2.9795444;-0.70046574;-0.37499574;-1.4195281;-
default r g b values to 1 if greater than 255 else x 255;1.0705485;4.712341;-1.1565061;-5.3335986;0.28643188;-1.6348276;IRRE
in case of invalid input like rgb rgb r rgb r g;-0.3931708;2.8356667;0.2713208;0.34267318;1.4876359;-1.4047657;CODE
if text 0;-1.9810413;5.7159085;2.477853;-2.0890393;-0.81058204;-7.003578;-
raise colorexception invalid color format for r text;-2.0820057;2.4621325;-2.5326312;-1.2295717;-1.769767;-1.2341076;CODE
ambiguous case;-2.6148517;2.7701657;3.882397;0.20529258;4.954731;-2.616691;META
put some values;1.4086021;3.449834;6.53243;-3.4668164;2.195443;-5.1790233;IRRE
using the same index key erases all previously added key value pairs;-1.866106;3.2340682;-2.2714493;-2.4117472;0.17870167;1.5218896;TASK
get a value using a index key and key;-0.6816081;3.824671;2.4784858;-2.9829745;1.6919019;-2.566167;IRRE
or guess the key entry for a part of the key;-2.2719007;-1.0097913;3.2241483;-0.45017132;2.8828268;-2.5665503;CODE
original store get tito;-2.047533;-0.76198596;2.3040192;-0.101354286;0.08852602;0.569588;-
original store put tito name mathieu;-3.0050333;-0.3016258;0.991416;-2.3907943;-0.94401175;-0.46712783;-
original store delete tito;-3.7726557;0.30470946;1.0086545;-1.4708732;-0.12095485;0.7945068;CODE
original store count;-0.9992693;1.2923691;2.3245602;-0.8542859;1.7211671;-1.9157683;-
original store exists tito;-2.798604;-0.31229255;1.1159586;-0.33671933;-0.071363874;0.5818876;-
original for key in store keys;-3.894301;-0.6801919;0.9976321;-2.8581715;2.285577;0.06339022;CODE
get all the key entry availables;-1.7605431;-0.5190291;2.504104;-0.34705293;3.2202227;-1.6072178;CODE
get only the entry from key entry;-1.4394256;2.4467924;3.340748;-0.11686036;2.2790575;-1.1966833;CODE
operators;-1.3019552;1.2171341;3.8186886;-1.7628037;2.3286169;-2.6750956;-
used for implementation;-1.7918669;-3.952134;3.167431;1.4134964;3.0841722;-1.4497981;TASK
privates;-2.2839003;-1.366881;4.3143644;0.095375486;1.2098954;-2.093083;CODE
xxx not entirely sure about the best value 0 or 1;-0.11914007;3.9041345;2.2837281;-4.915526;1.3397381;-3.5398448;TASK
backward compatibility first argument was a dict;-4.459942;-0.074628286;-4.363904;1.4837748;-0.5043218;-1.3380424;-
don t import redis during the documentation generation;-4.998067;-2.3919783;-2.891136;3.2213392;0.1504381;1.6214283;CODE
already installed don t do it twice;-4.453499;0.85212415;0.9336698;2.1818879;-0.2637886;1.2536603;CODE
get gobject mainloop context;-5.5571775;-0.68212557;0.8688625;1.2669209;0.52949536;4.3588586;IRRE
schedule the iteration each frame;0.84305423;0.5442348;5.1180205;0.44042927;-1.1619226;0.914265;CODE
xxx we need to loop over context here otherwise we might have a lag;-3.5508373;2.3072765;2.978876;-0.19085433;-0.116635524;-0.63480157;TASK
android support;-4.007929;-3.2953165;2.742088;1.5214578;-0.24257311;0.6694055;-
after wakeup we need to redraw more than once otherwise we get a;-2.9262545;1.2209285;2.275556;3.2564225;-0.03752553;2.6724029;TASK
black screen;-3.7334676;1.3445821;2.7270439;-1.1844484;-2.5122054;-1.6160256;-
init the library;-6.415471;-6.837369;0.72916436;1.9547993;0.02869413;-1.3153523;IRRE
check if android should be paused or not;-2.3200595;3.369569;1.9297637;3.4547694;-1.258661;0.23910345;IRRE
if pause is requested just leave the app;-5.1465487;2.0803652;3.906153;4.3908687;-1.9267375;2.367937;CODE
do nothing until android asks for it;-4.6095247;1.0321802;2.1713154;3.6946936;-1.8904697;1.576636;CODE
try to get the current running application;-5.821288;0.61439186;3.1449497;2.763317;-2.00326;0.8005208;CODE
no running application stop our loop;-4.501857;2.8816812;2.9608133;1.850174;-3.5599427;-2.1013892;IRRE
try to go to pause mode;-5.421674;0.6927939;3.0401397;0.19574277;-3.6900647;1.6445166;CODE
app goes in pause mode wait;-4.7679834;1.6945704;1.7769743;1.1483833;-3.1290274;2.0881388;-
is it a stop or resume;-3.9777696;0.263568;4.6235104;3.0357752;0.9060625;-0.709634;-
app must stop;-5.0293484;1.4060566;3.8664505;3.282103;-3.1743762;0.0140955;-
app resuming now;-5.2516356;0.44657704;4.242178;1.835557;-2.6127822;0.85518634;-
g android redraw count 25 5 frames seconds for 5 seconds;-1.0754651;1.7788743;2.0649886;-0.998737;-2.7228758;1.1401039;CODE
app doesn t support pause mode just stop it;-5.1183443;1.2567079;1.4112414;1.3696333;-3.2421327;3.0456228;CODE
prevent installing more than once;-2.3171637;1.1557429;0.51318294;3.2640932;1.8263636;2.6848154;-
don t let twisted handle signals unless specifically requested;-3.5602827;2.2316673;0.61306906;2.5664449;-1.4814472;3.7158346;CODE
install threaded select reactor to use with own event loop;-2.904713;-0.6814792;-0.39996758;2.611653;0.6342501;2.776;CODE
now we can import twisted reactor as usual;-4.272003;-3.828574;-0.514406;1.1308262;-1.2955896;1.208249;CODE
will hold callbacks to twisted callbacks;-4.423873;1.0983598;0.6187359;3.0700035;-2.0860407;2.34805;IRRE
twisted will call the wake function when it needs to do work;-4.471288;-1.0847914;0.8339779;2.3691049;-2.7794821;2.1269863;TASK
called every frame to process the reactors work in main thread;-3.0455089;-2.6233647;3.1167996;2.6713798;-1.2678322;2.601132;CODE
start the reactor by telling twisted how to wake and process;-4.387059;-2.5415351;2.1364636;1.6322252;-2.0998712;0.6677618;-
make sure twisted reactor is shutdown if eventloop exists;-4.756202;0.18391858;-0.9116933;4.2537174;-1.621131;2.263596;IRRE
twisted 24 3 0;-2.8453264;0.19189341;2.469878;-3.8048005;-1.4711436;-3.7880116;-
start and stop the reactor along with kivy eventloop;-4.371283;-1.6831927;2.2882683;2.275208;-3.0661147;1.9191469;IRRE
prevent uninstalling more than once;-2.284076;2.3482773;0.41670507;1.9891983;0.8834682;2.3638692;-
async app tests would be skipped due to async run forcing it to skip so;-2.1699536;4.069567;-1.8169416;6.787017;-4.121194;0.15547395;CODE
it s ok to be none as it won t be used anyway;-5.3331194;1.4802202;-1.8392755;1.4969889;1.3386983;0.7467339;-
window is its own parent oo;-7.322406;-1.7509538;3.5678804;0.33353108;0.1241822;3.0724502;CODE
don t check the child we checked before moving up;-1.6932236;3.3897786;1.2612541;2.528443;-1.0342836;0.6773226;CODE
window is its own parent oo;-7.322406;-1.7509538;3.5678804;0.33353108;0.1241822;3.0724502;CODE
check what the gl backend might be we can t know for sure;-6.1790643;-1.836249;-0.5539535;1.1800829;-1.2012544;2.1513333;CODE
what it ll be until actually initialized by the window;-4.496027;-1.437273;4.1481695;2.1009092;0.3839646;0.2325116;IRRE
this prevent in some case to be stuck if the screen doesn t refresh;-5.3858976;1.2160887;3.474904;2.8881922;-2.2459075;2.7127066;CODE
and we wait for a number of self framecount that never goes down;-0.86514145;1.4434736;1.5307661;3.4380116;-0.9623134;0.61312443;CODE
reset for the next test but nobody will know if it will be used;-2.8890355;2.8411539;-0.6103244;5.777261;-1.6383964;-2.7403867;IRRE
use default kivy configuration don t load user file;-4.6884565;-1.0386257;-0.17296469;1.8005965;-4.406639;3.7019367;CODE
force window size remove all inputs;-1.2665861;3.3096147;2.2490675;-0.19441128;-2.1959736;3.2044811;CODE
bind ourself for the later screenshot;-6.263846;-0.6581437;5.4355297;-0.6720403;-0.5442838;3.9226184;CODE
ensure our window is correctly created;-4.9539394;2.034616;2.9095726;2.2411222;-2.3407009;1.7703727;IRRE
don t save screenshot until we have enough frames;-2.6517658;0.76834315;3.3578045;0.18230957;-3.7686293;2.0618525;CODE
log debug framecount d self framecount;-2.8941472;1.7308315;-1.1318164;-0.57227343;-4.1950984;-0.81543374;CODE
check if there is framecount otherwise just;-2.9197648;5.114192;1.0484926;0.7568819;-1.4091939;-1.0656992;IRRE
assume zero e g if handling runtouchapp manually;-2.883939;5.3370023;0.18457662;3.4215899;-0.9083764;-0.8594251;CODE
don t create screenshots if not requested manually;-3.8453424;1.9899943;1.1859645;2.5415654;-2.1135767;2.5320704;CODE
just get a temporary name;-4.645634;-1.399948;1.8195404;0.9823498;1.6501492;0.4912399;-
get a filename for the current unit test;-0.53912467;4.1412354;-0.39622065;3.702577;-0.06965;-2.8266501;IRRE
capture the screen;-4.019497;-1.3530693;5.9030247;-0.56151843;-2.737484;0.9271512;-
search the file to compare to;1.0683848;2.1412313;1.8607336;0.5513256;0.2848423;-4.6858306;IRRE
get sourcecode;-4.2218685;-4.356621;-1.553362;-0.40317303;-0.47111148;-1.0362473;-
s at render d images are different;-1.5677996;1.4531397;1.0821148;-2.2611494;-1.9761822;2.1571007;CODE
generate html;-2.5961728;-1.4227822;4.7811728;-1.918205;0.77585936;-0.88591623;-
color ffdddd if not match else ffffff;-0.850894;3.665706;0.3017196;-2.579918;1.814491;-3.9069862;-
fd write h2 s d h2 self id self test counter;-0.8720802;3.1747842;-2.936699;-0.79601735;2.6430988;-4.868734;CODE
device tuio id args;-3.6470797;-0.022978274;-0.57093936;-2.1607094;2.0546207;-0.47886732;IRRE
set profile to accept x y and pos properties;-1.7294235;1.2386723;-1.0159945;-1.5615729;0.3141399;3.4952157;IRRE
set sx sy properties to ratio e g x win width;0.4039087;1.2997828;-0.23781604;-3.8936763;1.4095583;4.455281;IRRE
run depack after we set the values;-1.6340058;2.936672;-1.21116;-1.3614935;-1.2207922;-0.24689762;IRRE
https gist github com tito f111b6916aa6a4ed0851;-5.6858397;-5.171467;-2.0610955;-1.521824;-1.8571415;-0.98339504;CODE
subclass for touch event in unit test;-1.8971567;1.8858541;1.5936598;5.2623;0.96462375;-0.42728245;IRRE
async app tests would be skipped due to async run forcing it to skip so;-2.169954;4.069567;-1.8169415;6.7870193;-4.1211934;0.15547395;CODE
it s ok to fail here as it won t be used anyway;-4.5153103;1.4661165;0.23063923;4.480164;-0.439344;-2.6214614;-
from https docs pytest org en latest example simple html;-6.62141;-0.88448685;0.3445884;-1.0291672;-3.9233916;0.62778234;CODE
from https docs pytest org en latest example simple html;-6.62141;-0.88448685;0.3445884;-1.0291672;-3.9233916;0.62778234;CODE
force window size remove all inputs;-1.2665861;3.3096147;2.2490675;-0.19441128;-2.1959736;3.2044811;CODE
ensure our window is correctly created;-4.9539394;2.034616;2.9095726;2.2411222;-2.3407009;1.7703727;IRRE
need to do it to reset the global value;-3.8087308;4.002854;3.356666;-0.5849996;-0.9250483;1.2945403;TASK
keep track of all the kivy app fixtures so that we can check that it;-2.5187159;-2.9056036;2.2418172;3.7556498;-2.2628744;1.0673345;-
properly dies;-3.3086512;1.632146;2.5458906;2.7785702;-0.7660496;-2.5399365;-
force window size remove all inputs;-1.2665861;3.3096147;2.2490675;-0.19441128;-2.1959736;3.2044811;CODE
have to make sure all global kv files are loaded before this because;-4.1164703;-1.5842512;-3.340116;0.16874677;-3.4176276;1.8260759;CODE
globally read kv files e g on module import will not be loaded again;-3.7607014;-1.0892501;-2.0138125;1.9173187;-2.6752446;2.3148947;CODE
in the new builder except if manually loaded which we don t do;-6.0667233;0.8744656;-0.9323861;4.3405323;0.82442;3.725986;CODE
release all the resources;-3.6755111;-3.3238356;4.1784506;3.1558187;-0.2459987;1.2567331;-
check that the project works normally before packaging;-5.7171926;-0.043391217;-3.2284803;2.864362;-3.9957485;0.09220164;CODE
create pyinstaller package;-3.5041714;-4.613128;-1.8602432;-2.456856;-2.7472706;-0.12100135;IRRE
test package;-1.5601188;0.68221694;-0.04900319;3.7436228;0.42401856;-8.071072;IRRE
right after the animation starts;-5.796942;-1.8565726;5.9926815;-0.2709779;-2.6121604;1.9942378;-
during the first half of the animation;-4.2946005;0.15151198;6.191259;0.018734012;-2.7589834;0.6418375;-
during the second half of the animation;-4.4391193;0.4718076;6.1605177;0.03227133;-2.6773589;0.58888215;-
after the animation completed;-5.094444;-0.89800495;7.0524693;0.8407709;-1.4233629;1.4670968;TASK
right after the animation starts;-5.796942;-1.8565726;5.9926815;-0.2709779;-2.6121604;1.9942378;-
during the first half of the first round of the animation;-3.3229587;-0.109676935;5.4819903;0.42443365;-2.5664427;0.86762595;CODE
during the second half of the first round of the animation;-3.5158465;0.0921084;5.5370827;0.39408255;-2.5843205;0.82704324;CODE
during the first half of the second round of the animation;-3.151418;0.26460195;5.8372555;0.43785232;-2.5173948;0.9151311;CODE
during the second half of the second round of the animation;-3.2968376;0.4269345;5.708521;0.3459519;-2.5877001;0.98790205;CODE
after the animation stopped;-5.5532255;0.85074025;4.939703;0.2125376;-4.033522;0.6249847;-
right after the animation started;-5.239317;-2.2815511;5.1808352;-0.48924145;-2.686179;1.8668004;-
during the first half of the animation;-4.2946005;0.15151198;6.191259;0.018734012;-2.7589834;0.6418375;-
ec assert 1 false 0 n progress is still 0;-0.88337976;5.453815;-3.5790346;2.7690878;-2.7999477;-3.8275058;TASK
during the second half of the animation;-4.4391193;0.4718076;6.1605177;0.03227133;-2.6773589;0.58888215;-
ec assert 1 false 0 n progress is still 0;-0.88337976;5.453815;-3.5790346;2.7690878;-2.7999477;-3.8275058;TASK
after the animation compeleted;-6.430275;-0.22449687;4.1089034;0.6759035;-2.5009942;1.9954365;CODE
ec assert 1 false 1 n progress is still 0;-0.4804247;5.4223638;-3.471901;3.174894;-2.22648;-3.7871578;TASK
activate widget;-5.1104307;-1.2029405;3.6543887;0.70374537;-2.4729943;3.1766853;-
just tests whether the app is gc d after the test is complete;-1.7396946;2.2356024;-1.2599989;4.902743;0.38004467;-1.1744366;IRRE
create property in kv and set app to it;-3.7160296;-0.49982622;2.1024487;0.820146;2.019346;3.0759144;IRRE
just tests whether the app is gc d after the test is complete;-1.7396946;2.2356024;-1.2599989;4.902743;0.38004467;-1.1744366;IRRE
simulate what backend does after first frame render;-2.8993957;2.1267092;4.2321515;1.984861;-1.630352;3.7227612;CODE
ensure that the gstreamer play stop doesn t mess up the volume;-2.926286;2.7349513;0.66463095;1.5865766;-2.416313;3.4774542;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
create one just so we don t incur loading cost;-2.040363;-1.1794819;3.246453;1.48655;1.8269601;3.0345423;CODE
move touch outside;-3.0833066;-0.055178184;6.499839;0.08536194;-2.9665315;1.4922148;-
move touch outside button bounds;-3.879039;1.3394377;5.6612234;-0.804609;-2.829904;3.5245833;META
first touch;-3.8835554;-0.087411545;7.1725936;1.5256208;-1.3154067;-0.8322934;-
second touch;-3.8914685;-0.5166233;7.749199;2.203158;-1.0710723;-0.5246432;-
on press should be called only once;-4.933508;1.9265327;3.2644093;5.226175;-0.7843233;2.901214;IRRE
initial state;-3.741193;1.9022555;3.952687;1.188861;1.1682231;-1.1804837;IRRE
first touch;-3.8835554;-0.087411545;7.1725936;1.5256208;-1.3154067;-0.8322934;-
second touch;-3.8914685;-0.5166233;7.749199;2.203158;-1.0710723;-0.5246432;-
third touch;-4.31962;0.18535921;7.2501755;0.5805095;-0.40381628;-0.78691286;-
release first touch still pressed;-5.1483526;1.6489218;4.57946;2.8025105;-3.1103978;2.1684413;TASK
release second touch still pressed;-5.3730316;1.7529612;4.60242;2.897198;-2.8662775;2.2000358;TASK
release last touch now not pressed;-5.941205;1.7961457;4.2162986;2.8945165;-4.1900005;1.553489;-
three touches down;-3.1387477;1.4100074;6.667085;-0.07087839;0.60843635;-1.7778362;CODE
cancel first touch move outside;-4.9559927;2.4530382;5.4240527;1.5488042;-3.485704;2.768356;-
on cancel assert not called still have active touches;-5.1201363;5.1008;-0.41000038;6.580087;-2.7577574;0.8403615;TASK
release second touch inside bounds;-3.6467435;2.4285183;5.172657;1.2716515;-1.7096267;2.2687767;-
on release assert not called still have active touches;-5.274771;2.2274852;-1.1719834;7.5467763;-2.2096016;1.282357;TASK
cancel last touch;-4.9793487;2.3183227;5.8331137;2.2316523;-2.7359846;1.1532265;-
on cancel assert called once now cancel fires;-4.2469807;5.61621;-2.390901;7.2228036;-1.9818249;-0.74412;CODE
on release assert not called should not fire release;-4.239131;2.9250467;-4.0799804;8.252467;-2.055574;0.4563794;IRRE
monkey patch to ignore exception;-3.0331151;1.9218682;-3.4562569;5.0654035;-1.5548612;-0.316639;CODE
we should be able to create the event;-4.0366607;-3.5820322;6.4088936;3.3665547;1.4000323;1.500769;IRRE
with pytest raises typeerror;-2.25592;1.1701381;-4.9321966;-0.07207602;-5.230646;-1.0941834;IRRE
kivy clock start clock;-3.8637803;-0.9628615;3.0007741;-0.69251764;-2.9654007;-0.38487703;-
for now it doesn t yet raise a error;-7.21373;1.0702169;-4.328115;4.0545635;-4.0177727;-0.54003704;CODE
is the time reset was called no point of testing it;-2.939655;2.4449484;-1.2636776;5.506622;-2.4308522;-1.6510782;IRRE
assert list e history 20;-0.6094316;4.623652;-0.92145324;4.7337213;0.5171966;-4.634471;CODE
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
out of bounds of fbo;0.6443624;1.8325377;0.2478444;-0.30868873;-1.7122211;-0.1630459;-
in fbo black;-1.5078332;-2.321776;2.5012817;-0.60387796;0.43901876;-0.6856552;-
color 0 0 56789 0 5;-2.9087164;0.27465037;0.8341226;-5.804471;0.9281976;-3.5154448;-
color 0 56789 0 0 5;-2.7797918;0.2018282;1.015198;-5.623793;1.0624968;-3.5531855;-
overlap above 2 w alpha;-0.7275119;2.7070856;3.5794914;-3.6895719;-0.9340576;0.6448741;-
color 0 0 56789 0 1;-2.781905;0.7546062;0.32558483;-6.1441917;0.66549516;-3.7387486;-
color 0 56789 0 0 1;-2.681845;0.78169197;0.42547637;-5.9192147;0.69705343;-3.7790246;-
overlap above 2 w o alpha;-0.63725924;2.56061;3.3991516;-4.004262;-0.94997734;-0.2677461;-
returned class;-3.1900835;1.029862;0.7957635;2.4397466;1.4344711;-2.8056326;IRRE
returned types in container;-2.0744548;2.2301006;-1.095481;1.6398073;0.97448796;-0.04007961;IRRE
returned values;1.1411875;5.8973804;2.8201737;-0.4660654;-0.40167683;-5.7607074;IRRE
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
xxx please be careful to only save this file with an utf 8 editor;-4.117983;-0.5747014;1.0075634;-2.9346638;-1.8163188;-0.59780335;CODE
existing files;-3.7846618;-3.7507675;2.8046424;-0.23426163;1.8664153;-0.5123892;-
on macos and ios files ending in uffff etc are changed;-4.512821;-1.6316185;-0.84088844;-0.27123213;-4.237045;2.0493274;CODE
we cannot predict the filenames that will be created;-0.9227474;-3.2768028;-0.7799857;2.9289033;0.7669165;-1.1130959;IRRE
if it works on window and linux we can safely assume it also works;-4.2896;-4.014223;-0.5663814;0.20687951;-2.9388182;1.7431524;CODE
on macos and ios;-4.6383753;-6.1048665;2.4753306;-0.5963818;-2.4299445;0.62435514;-
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
add a fake garden module to the temporary directory;-4.9824553;-0.2885984;0.6447019;2.08109;-0.5259338;1.8664681;CODE
with initial arguments;-3.4011295;1.839673;4.311799;0.05548707;2.0102613;-3.0663075;IRRE
changing properties later;-3.7119005;0.5354021;3.6411338;3.775498;2.8359134;4.5189376;-
the size of the rectangle containing the fbo texture shadow needs;-0.24274114;0.17984228;1.8611754;-3.1518955;-1.1457983;2.1000595;TASK
to be adjusted according to the size of the shadow otherwise there;-2.601108;-0.048840348;4.5659976;-0.38949135;-0.974314;3.017181;IRRE
will be an unwanted cropping behavior;-2.0263357;0.8784701;2.0240824;1.1398945;-3.8231313;2.739069;-
now we will turn on the inset mode it is expected that;-4.3268147;0.5880952;3.1794631;0.62766534;-3.0835032;2.098803;IRRE
there will be no size adjustments;-0.9491275;1.2516018;1.6943861;0.2877528;-2.005837;2.8691473;-
now turning off and reverting back to the default mode;-4.2863655;2.134209;2.696488;0.5189581;-1.4021246;3.0883229;CODE
testing with initial arguments;-1.0291458;6.832463;0.15975982;5.1323514;0.21603787;-5.4750276;IRRE
now turning off and reverting back to the default mode;-4.2863655;2.134209;2.696488;0.5189581;-1.4021246;3.0883229;CODE
now we will turn on the inset mode it is expected that;-4.3268147;0.5880952;3.1794631;0.62766534;-3.0835032;2.098803;IRRE
there will be no size adjustments;-0.9491275;1.2516018;1.6943861;0.2877528;-2.005837;2.8691473;-
if the size of the rectangle containing the fbo texture shadow;0.13085827;2.0184238;1.3787085;-2.8509722;-1.1683061;1.4694694;CODE
changes its position will need to be adjusted;-3.6683192;1.1949897;4.0019836;0.67478746;-2.3633723;4.3057866;TASK
now we will turn on the inset mode it is expected that;-4.3268147;0.5880952;3.1794631;0.62766534;-3.0835032;2.098803;IRRE
there will be no position adjustments;-1.603962;1.6982465;2.7112777;0.5235692;-1.3887277;1.8226815;-
now turning off and reverting back to the default mode;-4.2863655;2.134209;2.696488;0.5189581;-1.4021246;3.0883229;CODE
testing with initial arguments;-1.0291458;6.832463;0.15975982;5.1323514;0.21603787;-5.4750276;IRRE
now turning off and reverting back to the default mode;-4.2863655;2.134209;2.696488;0.5189581;-1.4021246;3.0883229;CODE
now we will turn on the inset mode it is expected that;-4.3268147;0.5880952;3.1794631;0.62766534;-3.0835032;2.098803;IRRE
there will be no position adjustments;-1.603962;1.6982465;2.7112777;0.5235692;-1.3887277;1.8226815;-
there is a bug in roundedrectangle that distorts the texture if the;-0.45187277;0.77493393;-0.14708158;-1.8209423;-4.6901646;3.5471997;CODE
radius value is less than 1 otherwise it could be 0;-1.7730433;4.5113635;0.2657601;-2.937624;-3.98254;-3.5303102;IRRE
testing with initial arguments;-1.0291458;6.832463;0.15975982;5.1323514;0.21603787;-5.4750276;IRRE
basic circle;-2.258252;0.036789533;7.1172485;-3.3649726;-1.6282281;-2.8523152;-
reduced circle;-0.9982655;2.2319515;4.390332;-2.2230797;-2.2414153;1.2212803;-
moving circle;-2.1458151;0.7881618;7.057264;-2.2514987;-3.5043368;-1.1260958;-
ellipse;-0.74085665;-0.6300819;5.210808;-3.2087266;-3.2439578;-2.1668184;-
1 point;-0.73807716;1.392271;4.866035;-2.1357079;-0.48951685;-2.9531438;CODE
25 points;0.51030064;0.047010604;5.0899925;-0.8002029;0.44485933;-4.290827;CODE
basic rounded rectangle;-0.9963406;0.1576329;5.6119356;-5.2154746;-1.771414;-0.6847515;-
the largest angle allowed is equal to the smallest dimension width;-0.6631596;0.713234;1.5197788;-4.156573;0.1398369;2.3750052;CODE
or height minus the largest angle value between the anterior angle;-0.9190393;1.372595;3.5392478;-2.0599813;-0.35662353;2.266375;IRRE
and the posterior angle;-0.98594534;-1.219691;5.15864;0.15956305;0.21923578;3.4825852;-
same approach as above;0.46828717;1.2443416;5.0815053;1.1116692;3.5082846;0.8157813;-
a circle should be generated if width and height are equal and all;0.3815254;3.642551;4.575548;-2.3905683;0.51847833;-0.26645207;-
angles passed are greater than or equal to the smallest dimension;-0.10438174;1.8143911;0.6582524;-3.1903548;-0.87431306;2.1349802;CODE
currently the minimum radius should be 1 to avoid rendering issues;-0.34007674;2.4699447;2.0566945;-2.5263276;-2.008448;2.1125948;CODE
angles adjustment avoid issue if radius is less than 1;-0.6521502;4.0271697;0.7821882;-0.1245663;-3.286203;2.1500523;CODE
if width and or height 2px the figure should not be rendered;-3.0033202;4.0541654;1.4294951;-1.8460342;-4.5681624;2.1804647;CODE
this avoids some known smoothline rendering issues;-1.3331422;-0.25093305;0.7708158;-1.262153;-3.5844984;5.7832975;CODE
normal line with width 1;-0.23857212;2.4937382;2.9701765;-6.0444627;-1.5588392;-0.04470305;CODE
normal line with width 3;-1.2926602;1.9665;2.9552257;-6.24856;-0.6658888;0.1155975;CODE
enlarged line that should look width 3;-2.1324484;1.6486739;3.075038;-4.4369698;-1.595403;1.9711555;-
translate 30 10 1 so the enlargement goes around 0 0 0;0.2286453;2.744508;0.3839448;-6.339967;-3.6315382;-0.7397569;-
scale 3 1 1 x scaled by 3 so the line width should become 3;-0.8556115;1.9832699;2.86957;-6.830642;-1.4928781;2.1637802;CODE
code defined in the points setter of antialiasingline class;-1.6664627;0.70939225;-2.0489357;-2.2484736;-0.017940935;2.3888383;CODE
the same function present in the antialiasingline code;-2.3193839;1.4266167;-1.6333276;-3.1044493;-1.400384;1.3777997;CODE
externalized for testing;-1.199307;-2.175719;-0.065660246;6.3666425;0.21819666;-1.416935;IRRE
at least 3 points are required otherwise we will return an empty;-0.8125846;4.724067;1.4178206;-0.38897422;2.2504184;-2.8475218;CODE
list which means there are no valid points;0.54250455;3.7467892;-0.4779544;-0.9008178;0.77128583;-6.166822;OUTD
we expect a type error to be thrown if stencil mask is not an object;-2.4480226;2.8945324;-4.758052;2.1400485;-1.1382391;0.70069695;CODE
of type instruction;-2.8906782;-4.5603366;1.7086408;1.145861;3.0505493;-5.0109925;CODE
no typeerror here;-2.9292924;1.5774364;-2.3407242;-1.6241753;-4.3790703;-5.5434837;-
test the gradient responsible for the smooth line effect;1.0475624;1.0492918;0.6695801;1.625546;-2.1048744;0.87500817;IRRE
check the width defined through tests with the custom texture;0.82428604;4.5322676;-1.7252893;0.89494133;-1.4253614;0.05560322;IRRE
this set of points must remain unchanged;1.080758;3.6942158;3.1610434;-2.1909027;0.563724;2.703103;CODE
this set of points should be reduced from 16 to 8;2.6647837;3.3990872;3.3103218;-4.8398113;-1.116659;0.14778908;CODE
this set of points should be reduced from 72 to 50;3.1204724;3.2852626;3.183821;-3.5600433;-1.207291;-0.22649907;CODE
this set of points should be reduced to;2.7147353;3.5352478;3.0085623;-3.4800596;-0.012556176;1.7727278;CODE
line closed default;-6.186603;2.0247967;1.3594522;-0.6939917;-2.7797897;1.9654728;CODE
without closing the line;-3.014466;1.3928607;6.92325;0.3725879;-0.50640994;-0.8828113;-
test if antialiasing is disabled if the graphic has one of its;-1.6287936;4.6849327;-0.30944192;2.1951232;-1.073962;0.83307964;IRRE
dimensions decreased to less than 4px;-0.47297508;2.7236655;-0.909728;-5.1057763;-3.6148627;3.6786852;-
re enable antialiasing line rendering;-3.846133;1.2738929;0.31475508;-1.9206395;-3.811073;5.057286;CODE
disabling antialiasing;-3.515011;0.72902626;-0.52450925;0.018225458;-1.1416185;4.2609553;-
re enable antialiasing;-4.120462;0.27167696;-0.05556614;-0.54966843;-2.1166046;4.7182517;-
test if antialiasing is disabled if the graphic is initialized with;-2.160755;4.984594;-0.6247224;3.0631332;-1.6984609;2.2951555;IRRE
at least one of its dimensions less than 4px;-0.091112435;1.560631;1.7954651;-4.8475695;0.019108612;1.451673;-
test if antialiasing is disabled if the graphic has one of its;-1.6287936;4.6849327;-0.30944192;2.1951232;-1.073962;0.83307964;IRRE
dimensions decreased to less than 4px;-0.47297508;2.7236655;-0.909728;-5.1057763;-3.6148627;3.6786852;-
re enable antialiasing line rendering;-3.846133;1.2738929;0.31475508;-1.9206395;-3.811073;5.057286;CODE
disabling antialiasing;-3.515011;0.72902626;-0.52450925;0.018225458;-1.1416185;4.2609553;-
re enable antialiasing;-4.120462;0.27167696;-0.05556614;-0.54966843;-2.1166046;4.7182517;-
test if antialiasing is disabled if the graphic is initialized with;-2.160755;4.984594;-0.6247224;3.0631332;-1.6984609;2.2951555;IRRE
at least one of its dimensions less than 4px;-0.091112435;1.560631;1.7954651;-4.8475695;0.019108612;1.451673;-
test if antialiasing is disabled if the graphic has one of its;-1.6287936;4.6849327;-0.30944192;2.1951232;-1.073962;0.83307964;IRRE
dimensions decreased to less than 4px;-0.47297508;2.7236655;-0.909728;-5.1057763;-3.6148627;3.6786852;-
re enable antialiasing line rendering;-3.846133;1.2738929;0.31475508;-1.9206395;-3.811073;5.057286;CODE
disabling antialiasing;-3.515011;0.72902626;-0.52450925;0.018225458;-1.1416185;4.2609553;-
re enable antialiasing;-4.120462;0.27167696;-0.05556614;-0.54966843;-2.1166046;4.7182517;-
test if antialiasing is disabled if the graphic is initialized with;-2.160755;4.984594;-0.6247224;3.0631332;-1.6984609;2.2951555;IRRE
at least one of its dimensions less than 4px;-0.091112435;1.560631;1.7954651;-4.8475695;0.019108612;1.451673;-
500 500 400 400 irrelevant just for testing purposes;0.1184144;0.9647218;-0.93634146;2.8004298;0.16814043;-2.9713645;IRRE
500 500 400 400 irrelevant just for testing purposes;0.1184144;0.9647218;-0.93634146;2.8004298;0.16814043;-2.9713645;IRRE
test disabling antialiasing if the points are very close;2.274111;5.010114;-1.5542599;1.7876977;-2.041754;0.25288272;CODE
re enable antialiasing line rendering;-3.846133;1.2738929;0.31475508;-1.9206395;-3.811073;5.057286;CODE
disabling antialiasing;-3.515011;0.72902626;-0.52450925;0.018225458;-1.1416185;4.2609553;-
re enable antialiasing;-4.120462;0.27167696;-0.05556614;-0.54966843;-2.1166046;4.7182517;-
test disabling antialiasing if the points are very close;2.274111;5.010114;-1.5542599;1.7876977;-2.041754;0.25288272;CODE
re enable antialiasing line rendering;-3.846133;1.2738929;0.31475508;-1.9206395;-3.811073;5.057286;CODE
disabling antialiasing;-3.515011;0.72902626;-0.52450925;0.018225458;-1.1416185;4.2609553;-
re enable antialiasing;-4.120462;0.27167696;-0.05556614;-0.54966843;-2.1166046;4.7182517;-
normal args;-0.700908;1.6608994;2.2877862;-1.1441194;-0.23153496;-0.5325006;IRRE
key word args;-2.742884;-2.1297472;3.2902648;0.5451024;1.9160943;-2.0555904;IRRE
create a root widget;-4.072596;-2.410568;4.400485;-2.074158;-1.7609403;2.7497995;IRRE
put some graphics instruction on it;-4.5483704;-2.7583115;4.8863983;-2.519737;-2.4679282;-0.56872535;CODE
render and capture it directly;-3.1345842;0.12004445;4.61771;0.951629;-2.5876856;2.6600084;IRRE
create a root widget;-4.072596;-2.410568;4.400485;-2.074158;-1.7609403;2.7497995;IRRE
put some graphics instruction on it;-4.5483704;-2.7583115;4.8863983;-2.519737;-2.4679282;-0.56872535;CODE
render and capture it directly;-3.1345842;0.12004445;4.61771;0.951629;-2.5876856;2.6600084;IRRE
create a root widget;-4.072596;-2.410568;4.400485;-2.074158;-1.7609403;2.7497995;IRRE
put some graphics instruction on it;-4.5483704;-2.7583115;4.8863983;-2.519737;-2.4679282;-0.56872535;CODE
render and capture it directly;-3.1345842;0.12004445;4.61771;0.951629;-2.5876856;2.6600084;IRRE
xxx on osx ci builder img sdl3 is not used;-6.8840785;0.6236285;-2.0904899;-3.1428094;-1.3202246;3.1680255;OUTD
therefore the test below wont work yet with imageio only;-1.4089333;2.6752079;-2.4506137;2.338966;-3.7609136;-1.5947431;TASK
load kivy logo;-3.8007672;-2.8738782;3.5093386;-0.7285618;-2.5761979;2.6494794;CODE
try to save without any format;-4.856217;1.5860658;-1.3532625;-0.84148043;-2.8531222;-0.57636535;CODE
save it in png;-3.4911826;-0.56549764;5.404705;-1.9221424;-2.2627032;1.4079577;CODE
if false then there is no provider;-4.5967093;4.0070386;-0.3391611;2.6540642;0.50547564;0.5591256;IRRE
try to save in a filename;-5.0240726;0.63716483;0.40321803;0.917337;-2.280091;-0.8386329;CODE
xxx test wrote but temporary commented;-4.9525633;4.175281;-2.6957226;3.1746283;-3.2852232;-5.2816615;IRRE
xxx because of the issue 6123 on osx;-6.919466;-0.87945986;-2.4283426;-2.282749;-0.49056175;-1.2692724;-
xxx https github com kivy kivy issues 6123;-6.2494855;-2.7587075;-1.5035857;-1.0440882;-5.1724825;-1.0512208;CODE
with open filename rb as fd2;-3.5175717;-0.9593395;-0.644639;-1.9291645;0.28749183;0.16711022;CODE
pngdatafile fd2 read;-1.8937855;0.37545237;-0.49233103;-2.1913633;-2.4581769;1.3623687;CODE
check the png file data is the same as bytesio;-2.000761;2.6082408;-1.3330238;-1.0869023;-2.3867803;-0.27155587;-
self asserttrue pngdata pngdatafile;-1.6291325;4.6744914;-2.9229815;2.0100663;-1.9605411;0.6470259;CODE
save it in jpeg;-2.3933837;-1.1716341;4.964476;-2.0323558;-1.983513;0.98540354;CODE
if false then there is no provider;-4.5967093;4.0070386;-0.3391611;2.6540642;0.50547564;0.5591256;IRRE
you need an image testsuite to run this for information see;-2.4299154;-0.8618214;2.1408482;0.4869801;-1.0752411;0.17151366;CODE
kivy tools image testsuite readme md;-3.689134;-1.9271353;-0.7448904;0.8478543;-3.369826;0.116581306;IRRE
kivy image test protocol v0 pixel values;-0.9748153;0.067511626;-2.1366837;-0.394951;-4.2040114;0.2205499;IRRE
v0 pixels note t is not included here see match prediction;0.12497266;-0.31160322;-1.0047742;-1.3490615;-2.1775491;0.52798337;CODE
kivy image test protocol v0 file name;-4.0088196;-1.3782974;-1.2811787;0.98604125;-2.9735513;0.032187358;IRRE
width x height pattern alpha fmtinfo testname encoder ext;-0.9375099;2.016481;-2.7514398;-4.9418826;-1.0580846;0.6890358;IRRE
converts predicted rgba pixels to the format claimed by image loader;1.6026883;-0.26260692;-2.3280113;-0.83205926;-1.3970424;3.0224845;CODE
rgb bgr default to 4 byte alignment;-1.7567315;1.4947505;-2.2407076;-5.0036635;-0.17344755;3.9090595;CODE
assume pitch 0 unaligned;-0.63787645;5.081618;-0.75793326;-2.9474556;-1.7852497;0.38887402;-
print pixnum ptr bpp format pixnum ptr bpp pix;-3.6160095;2.132297;-1.1002418;-6.006225;0.58733314;-1.7492422;CODE
required for ffpy memview;-2.8681834;-1.034124;-1.7920161;-2.3362498;-2.720719;2.709764;CODE
fixme bytearray for py2 compat i can t be bothered to research;-3.1026328;-2.6471198;-4.110999;-3.0509822;-4.8201146;-0.26566273;CODE
assume pitch 0 unaligned;-0.63787645;5.081618;-0.75793326;-2.9474556;-1.7852497;0.38887402;-
gif format not listed as supported in sdl3 loader;-5.4557867;-0.4810206;-2.3222723;-1.709671;-2.327393;3.536053;CODE
test activating first checkbox;-2.7274463;5.8719287;0.5506591;4.4193206;0.614081;-2.806754;IRRE
test activating second checkbox deactivates first;-3.2144601;6.60844;-0.2575276;4.433111;-0.76242536;-0.93722343;IRRE
test activating first checkbox again;-3.2013247;6.04396;0.3202247;4.939476;-0.3259087;-2.3933692;IRRE
test activating second checkbox again;-2.9351506;6.213691;0.20854704;4.7745457;0.28699115;-2.3762722;IRRE
test deactivating when allow no selection false;-1.8678651;7.2929473;-3.091345;6.715505;-1.354119;-2.1519203;CODE
this should not work at least one must stay active;-2.6350896;1.4058626;2.1322615;2.8802514;-0.29401562;1.9456247;CODE
since allow no selection false b should remain active;-3.5179808;5.4951096;-1.0314511;2.8721766;2.2529047;0.77613425;CODE
test with allow no selection true;-0.5570807;7.73871;-2.5588322;5.602365;0.8218312;-5.7970324;IRRE
now deactivating should work;-6.0553846;1.9703014;0.23942827;0.99968755;-2.8945286;4.1696744;-
activate again;-5.850278;0.44665214;3.2056842;1.0139863;-0.20882455;-0.3993404;-
bug fixed;-5.070265;1.2799077;-1.524005;2.7699506;-1.9178195;0.95690924;-
put utf 8 in string and validate no more crash due to str encoding;-2.2562504;2.670636;-2.346948;1.2431351;-1.3470788;-1.99176;CODE
put utf 8 in string validate close open the app and edit the value no;-4.6740465;2.383721;-0.33758837;0.7702352;-1.3168703;-1.166153;CODE
more weird space due to ascii utf8 encoding;-2.1329405;0.43347898;0.18712272;-3.6465912;-2.6310089;0.46187994;-
create an unicode directory and select it with path no more crash at;-4.5395412;-0.44358397;-0.98323035;-0.22208726;-0.59997416;0.16499297;IRRE
validation;0.9612818;3.4564471;2.1926444;3.89224;3.9736898;-5.883083;-
create an unicode directory and select it with path and restart the;-6.332117;-1.4703189;0.24062592;-1.8637707;-0.84256107;0.5900036;IRRE
path is still correct;-5.838125;-0.6944571;1.5293924;-0.018896248;-2.3013525;-0.1897089;TASK
the old error before utf 8 was standard;-4.8123746;1.4006917;-4.333606;-0.98615354;-2.8675444;0.05430861;OUTD
import knspace kivy uix behaviors knspace knspace;-2.4273775;-3.0042558;-1.7530655;-2.656851;-1.9899853;1.5957509;CODE
this could actually be none rather than raising depending;-1.5015953;2.012965;1.8054676;1.00526;1.0037764;-1.1751707;CODE
on when the class was instantiated so if this fails change the;-5.4207497;3.2652388;-1.54079;5.6586204;2.0566409;2.038287;CODE
test to assert is none;-0.8974271;8.49905;-3.5605915;5.059683;-0.8447145;-8.128291;IRRE
base class needed for builder;-2.5198655;-2.089118;0.09190845;0.55115336;5.273814;1.3204919;CODE
invalid indent;-5.34747;2.8489645;-1.5132117;-0.8691409;0.27858943;-3.294691;OUTD
builder load string dedent kivy 1 0;-4.535773;0.6747486;-1.3223425;0.15446562;-0.31606182;0.6786521;CODE
call the on press and check the result;-3.848539;3.0744507;3.4130313;2.2670465;-1.9625541;-2.7753189;IRRE
this test cover a large part of the lang;-0.86143064;-0.09393939;1.2629312;5.210848;0.6509368;-3.4396787;IRRE
and was used for testing the validity of the new rewrite lang;-6.015213;-1.8121792;-1.1917535;4.0791755;1.5939287;-0.42423773;CODE
however it s not self explained enough;-1.9623982;-2.7415063;2.964631;0.6601288;-0.41406152;-1.0921961;CODE
check that all the events match;-0.59454757;3.0011587;4.2693615;3.4733238;1.1406257;-3.21567;-
check that the ids are properly saved during on kv post dispatch;-3.1034486;2.627019;-1.9969366;2.1201353;1.5164571;1.0145838;CODE
check that the root widget is as expected;-4.8836226;3.0571454;0.5495294;1.5616288;-4.881967;0.9398512;-
check that the base widget is as expected;-4.085903;3.9045708;0.6848016;1.5308282;-3.6700566;1.0062009;-
check that the properties have expected values;1.5024016;6.7110763;0.54040277;3.4293692;1.5093963;-3.0559406;IRRE
make a copy of the ids at the current moment;-1.5836734;-0.68773705;1.9794127;0.13665892;3.7141597;1.3285009;-
except attributeerror python 2;-2.6353014;1.9780514;-3.6183317;1.033821;-4.224847;-3.1947272;CODE
used to determine which tests must be skipped;0.24003547;2.0404263;-2.217749;5.7065806;1.4839847;-4.498367;TASK
restores handler to original state;-6.579158;2.5534663;1.5635675;3.6961074;-1.4315815;5.247046;-
create the default file first so it gets deleted so names match;-2.977327;2.2562768;0.44166395;0.39783186;1.4318762;2.0219114;CODE
wait a little so the timestamps are different for different files;-2.1108541;-0.42519325;0.10974156;0.295179;-1.066908;1.8756799;CODE
files that should have remained after purge;-2.7552347;0.83400077;0.48019606;0.9573818;0.17798375;1.5421454;CODE
one of the remaining files is the current open log remove it;-4.5121746;1.6756139;1.3025297;1.0413699;-1.9792027;0.50222397;CODE
the open log may or may not have been counted in the remaining;-2.4510694;3.3044317;-0.07816979;2.787459;-0.062269833;-3.4250019;CODE
files remove one from expected to match removed open file;-2.8943658;3.3450415;-0.3866911;0.11969681;-1.5509435;0.05885552;CODE
pytest mark xfail issue 7986 not yet fixed;-5.6603384;1.7355703;-3.8242655;-0.036674257;-4.3390193;1.3131379;TASK
assert pytest approx 7 factor dpi2px 7 unit 2 inch in;0.7825529;1.6527777;-2.2285001;-2.6478932;-2.181867;0.89614797;CODE
assert pytest approx 10 new factor dpi2px 10 unit;1.1362206;2.6586313;-4.253435;-0.7288682;-1.9357191;0.4314053;CODE
import factory kivy factory factory;-2.861122;-1.9342978;-0.104994364;-0.15817167;-1.1954715;1.4245754;CODE
kill kv lang logging too long test;-1.4218771;2.3014314;-2.2160566;4.3232512;-2.4117994;-0.5183578;IRRE
add the logging back;-6.2321815;0.43723312;3.530394;2.0733767;-3.1068947;1.3250432;TASK
build the widget tree add window as the main el;-4.789123;-1.7663189;4.271839;0.30138928;-1.5782499;4.1326394;CODE
activate inspector with root as ctx;-6.701071;0.12334999;-1.1394887;0.8141752;0.1421744;2.652969;-
pull the inspector drawer from bottom;-5.3432837;-1.1322439;2.832862;-0.7510267;-1.4962039;1.3179805;CODE
by default is inspector appended as the first child;-6.5347652;1.120918;0.65817887;1.4469641;1.3330938;2.0051472;CODE
to the window and positioned at the bottom;-5.3398833;-1.5816901;7.807576;-1.4527894;-1.1186389;1.4706517;CODE
close inspector;-3.4888988;-0.7334124;3.0872204;1.7729758;0.4173228;-2.3743732;CODE
stop inspector completely;-3.491145;2.3003502;0.8545288;2.732151;-1.3542153;-0.07826941;CODE
build the widget tree add window as the main el;-4.789123;-1.7663189;4.271839;0.30138928;-1.5782499;4.1326394;CODE
activate inspector with root as ctx;-6.7010727;0.12335005;-1.1394882;0.8141747;0.14217359;2.6529694;-
pull the inspector drawer from top;-5.2034693;-1.0403615;3.0155444;-0.53574693;-1.402062;1.6800514;CODE
by default is inspector appended as the first child;-6.5347652;1.120918;0.65817887;1.4469641;1.3330938;2.0051472;CODE
to the window we move it to the top;-4.7171497;-1.3158718;7.484577;-0.73473316;-2.6528714;1.7910062;CODE
elf advance frames 20 drawer is moving like with activate;-6.3088894;0.37064233;0.3468593;-0.23312938;-3.1244624;2.9966831;-
close inspector;-3.4888988;-0.7334124;3.0872204;1.7729758;0.4173228;-2.3743732;CODE
stop inspector completely;-3.491145;2.3003502;0.8545288;2.732151;-1.3542153;-0.07826941;CODE
build the widget tree add window as the main el;-4.789123;-1.7663189;4.271839;0.30138928;-1.5782499;4.1326394;CODE
checked widget;-4.2855353;0.8711667;3.891226;0.45981807;-2.042948;-0.37396914;-
activate inspector with root as ctx;-6.701071;0.12334999;-1.1394887;0.8141752;0.1421744;2.652969;-
pull the inspector drawer from bottom;-5.3432837;-1.1322439;2.832862;-0.7510267;-1.4962039;1.3179805;CODE
touch button center;-3.7094958;-0.94425243;7.006207;-1.0047683;-2.7977183;3.280845;META
open inspector properties;-4.805661;-1.2546442;0.81256425;1.1567061;1.7974875;2.0488694;CODE
check if the button is selected;-2.7267613;2.6576467;3.399596;2.660923;-0.1401014;-0.7609322;IRRE
stored instance;-1.2314916;0.01878086;3.9062536;1.8252314;2.5197175;0.22155704;-
data in properties;1.9493319;-0.044436995;2.9228;-0.8296884;4.530055;-0.9305125;-
slice because the string is displayed with quotes;-2.7230363;2.102669;1.615439;-2.1753476;-1.0419164;-2.6678576;IRRE
close inspector;-3.4888988;-0.7334124;3.0872204;1.7729758;0.4173228;-2.3743732;CODE
stop inspector completely;-3.491145;2.3003502;0.8545288;2.732151;-1.3542153;-0.07826941;CODE
build the widget tree add window as the main el;-4.789123;-1.7663189;4.271839;0.30138928;-1.5782499;4.1326394;CODE
checked widget;-4.2855353;0.8711667;3.891226;0.45981807;-2.042948;-0.37396914;-
activate inspector with root as ctx;-6.701071;0.12334999;-1.1394887;0.8141752;0.1421744;2.652969;-
pull the inspector drawer from bottom;-5.3432837;-1.1322439;2.832862;-0.7510267;-1.4962039;1.3179805;CODE
but don t inspect yet;-3.8311915;-0.43473756;1.5045892;3.3046198;-1.62795;-3.2528956;TASK
touch button center to open the popup;-3.8241355;-1.3633608;5.585438;-0.11221163;-3.2414012;3.1453218;META
start inspecting;-2.4677258;-1.285452;2.154497;3.5625217;-0.17189935;-4.145233;-
inspect firstmodal s button;-5.912509;0.41636038;2.8504305;1.6802357;-1.7296715;1.8380064;META
open inspector properties;-4.805661;-1.2546442;0.81256425;1.1567061;1.7974875;2.0488694;CODE
check if the popup is selected;-2.655468;1.7674525;3.1481721;3.3249521;-1.0504947;-0.5687723;IRRE
stored instance;-1.2314924;0.018781127;3.906254;1.825231;2.5197163;0.22155662;-
check with new popup instance if the properties match;-2.1366596;3.4712307;2.3375578;5.4130597;1.7635453;0.28295904;CODE
data in properties;1.9493319;-0.044436995;2.9228;-0.8296884;4.530055;-0.9305125;-
slice because the string is displayed with quotes;-2.7230375;2.1026697;1.6154383;-2.1753483;-1.0419167;-2.6678572;IRRE
close popup;-4.747844;-0.5778675;4.877281;1.4414186;-1.5790088;0.3265964;CODE
close inspector;-3.4888983;-0.7334126;3.0872204;1.7729753;0.41732392;-2.374373;CODE
stop inspector completely;-3.491145;2.3003502;0.8545288;2.732151;-1.3542153;-0.07826941;CODE
build the widget tree add window as the main el;-4.789123;-1.7663189;4.271839;0.30138928;-1.5782499;4.1326394;CODE
checked widget;-4.2855353;0.8711667;3.891226;0.45981807;-2.042948;-0.37396914;-
activate inspector with root as ctx;-6.7010727;0.12335005;-1.1394882;0.8141747;0.14217359;2.6529694;-
pull the inspector drawer from bottom;-5.3432837;-1.1322439;2.832862;-0.7510267;-1.4962039;1.3179805;CODE
but don t inspect yet;-3.8311915;-0.43473756;1.5045892;3.3046198;-1.62795;-3.2528956;TASK
touch button center to open the popup;-3.8241365;-1.3633606;5.585438;-0.11221138;-3.2414012;3.1453233;META
touch window center to open;-4.146501;-0.7921712;5.4858475;0.087114446;-3.4828818;3.855638;CODE
the second and the third popup;-6.0053005;-1.2928505;5.800474;1.2210499;0.5317381;-0.29738098;-
fixed order first opened last closed;-3.8054938;3.1036642;1.9009305;0.9555301;-0.39774755;0.95666975;CODE
start inspecting;-2.4677258;-1.285452;2.154497;3.5625217;-0.17189935;-4.145233;-
inspect button;-5.5271244;0.041318275;3.6036613;3.0105364;-0.9885386;-0.89643055;META
check if the popup is selected;-2.655468;1.7674525;3.1481721;3.3249521;-1.0504947;-0.5687723;IRRE
stored instance;-1.2314924;0.018781127;3.906254;1.825231;2.5197163;0.22155662;-
close popup;-4.747844;-0.5778675;4.877281;1.4414186;-1.5790088;0.3265964;CODE
close inspector;-3.4888983;-0.7334126;3.0872204;1.7729753;0.41732392;-2.374373;CODE
stop inspector completely;-3.491145;2.3003502;0.8545288;2.732151;-1.3542153;-0.07826941;CODE
patch win on close method to prevent eventloop from removing;-5.238017;2.1580527;0.08642476;5.970263;-0.9738086;3.6028953;CODE
window from event listeners list;-3.4268825;-1.4208523;5.1404037;1.4268752;-0.73000973;2.3342702;CODE
restore method on close to window;-5.4472046;1.3312614;4.002508;3.476091;-1.4913903;3.502541;CODE
not rendering widgets in tests so don t do screenshots;-3.501212;2.6468644;-0.27141833;2.516079;-6.22087;-0.7993034;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
test begin event;-1.8005062;4.1039596;3.11469;6.479172;0.22452626;-5.036036;IRRE
test update event;-2.078665;3.30837;2.189453;7.185388;-0.51173854;-4.2592587;IRRE
test end event;-2.7413538;4.459257;2.8457232;6.759498;-0.7176423;-5.159227;IRRE
test begin event;-1.8005062;4.1039596;3.11469;6.479172;0.22452626;-5.036036;IRRE
test update event;-2.078665;3.30837;2.189453;7.185388;-0.51173854;-4.2592587;IRRE
test end event;-2.7413538;4.459257;2.8457232;6.759498;-0.7176423;-5.159227;IRRE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
helper methods;-0.8455087;-2.26191;3.483713;3.4555154;1.7358958;-1.4010128;-
flip because the mouse provider uses system s;-4.7568574;-1.2379348;2.9636436;-0.6790628;-1.9600772;2.9939337;IRRE
raw one and it s changed to bottom left origin;-5.9706798;0.25133678;2.7022266;-1.7144941;-2.558393;1.2675402;-
with window s system size 1 for mouse pos;-2.1552825;-0.41506866;2.55766;-2.934044;-1.2121819;3.4730415;CODE
prepare mousemotioneventprovider;-5.3194523;-1.4996035;1.0485715;1.7581556;-2.0157495;3.5452762;-
and widget it interacts with;-5.4019957;-4.4921956;5.7191696;0.7120628;-2.0244672;3.2146642;CODE
defaults from me it s missing because we use;-6.574357;-1.535588;1.3772631;0.66400105;-0.97007024;2.7038898;CODE
the provider directly instead of me;-5.0496774;-1.0528804;1.9898828;0.7410049;-1.4809164;2.990327;CODE
touch dot appears touch again dot disappears;-4.6017203;1.1827025;2.0836246;-0.43868056;-4.526827;1.9522233;CODE
register mouse provider;-4.99825;-2.996959;1.8081163;-1.1497542;-0.6293706;4.926863;-
no mouse touch anywhere;-4.6105947;0.5495381;3.4895065;-0.12517132;-5.006124;1.1108285;IRRE
right button down red dot should appear;-6.3480844;-0.13365309;2.816001;-1.7763884;-3.4284146;1.9759367;CODE
doesn t do anything on a pure button;-5.5352855;0.8901738;0.5818507;1.9435624;-2.5135067;0.71665484;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
multitouch sim is changed in on touch down;-3.8690088;2.1662362;3.9045482;0.5556871;-2.0777497;3.899959;CODE
method of the widget that s able to handle;-2.741842;-1.5253055;5.593568;1.8523718;-0.32103303;2.7868593;CODE
multiple touches therefore for scatter we;1.7318645;-1.5833873;5.9340897;-2.1486614;-1.3198878;2.407553;CODE
need to dispatch the method and because we;-2.6115375;0.051093545;2.4784474;5.9533577;1.7757369;0.23256661;TASK
triggered only on mouse down directly i e;-5.0356665;-1.3058851;4.917725;0.7822266;-2.975646;3.4025817;CODE
without me dispatch on touch down was not;-5.990972;0.96669513;2.6550303;3.0613673;-1.6756034;1.8877653;CODE
called multitouch sim is false;-3.9959033;3.0923502;1.8316339;1.4773158;-1.8693415;1.2837511;IRRE
elf advance frames 1 initialize stuff;-4.881564;-0.68223727;-1.2413751;0.2190569;-1.163644;1.8469592;IRRE
the red dot isn t present;-5.24438;1.2057446;1.551857;-1.3546737;-4.0555444;-1.0860633;CODE
the red dot is present;-3.6163423;-0.63024944;4.2301397;-1.4708897;-2.3024533;-0.8358539;CODE
xxx right button up;-5.778179;0.4789854;4.5980387;-2.415332;-1.4864287;1.0807881;META
first release the touch then check so that we;-4.3237095;-0.9878592;3.8300326;4.590502;-2.4287674;0.10950534;IRRE
have the red dot drawn in on demand and in the;-2.9593878;-2.3603446;6.070715;-0.4432395;-0.08344268;0.20603572;CODE
default multitouch everywhere because in the;-4.1441736;-0.8033801;2.9928288;1.0722946;-1.3966688;5.1709514;CODE
multitouch on demand is the circle drawn after;-3.7173998;0.35514882;6.6726494;-0.46869767;-2.8288567;3.0758393;-
the touch is released in on mouse release;-5.58971;-1.9217355;6.071435;0.5223429;-3.4126346;2.3585246;-
because the red dot is removed by the left button;-6.620228;0.10186384;1.9673598;-1.04417;-2.8543503;1.4452398;IRRE
the red dot is present;-3.6163423;-0.63024944;4.2301397;-1.4708897;-2.3024533;-0.8358539;CODE
button is down on the previous dot s position;-5.59089;1.4481483;3.8626888;-1.557173;-3.4516196;1.8848461;CODE
if the multitouch is disabled the touch event;-3.732165;1.5421383;3.880586;2.314652;-2.0304942;2.3003886;-
increments the counter;-1.5321045;2.5979073;5.3686776;-2.4210637;0.9499579;-4.9506;-
the right click is ignored test ends here;-5.19141;4.050607;-0.31455863;4.9518366;-4.4507484;-2.2969441;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
the red dot is present;-3.6163418;-0.63025016;4.23014;-1.4708903;-2.302452;-0.8358547;CODE
ellipse proxy 3 1318 instruction proxy ref;-6.0962696;-0.82990545;-1.4519393;-1.3600378;-2.4556236;1.1343585;CODE
the dot is removed after the touch is released;-6.7255716;-0.6916972;3.6366482;0.28136128;-2.9508677;2.563242;OUTD
when right touch is preserved dot remains;-3.8732834;0.8613918;4.263873;-0.11134781;-3.345295;3.5854197;CODE
when left touch is destroyed dot removed;-5.408086;1.2075772;3.7035658;0.2603105;-2.3626018;2.822367;OUTD
no matter where;-2.4590204;-1.0695721;5.461392;-0.24842869;-1.3929089;1.8196677;-
the touch which holds the only ref to the dot;-4.5708327;0.029801497;6.109581;0.3986218;-1.5332471;1.9726957;CODE
instance ellipse is collected therefore the;-0.5134984;-0.12268772;2.0519845;-0.68651855;0.140594;0.12090221;CODE
proxy can confirm the dot is removed;-5.5168476;0.6184067;0.13143927;1.7119864;-2.7604423;2.0455709;OUTD
indirect ref at least it would be nasty for;-3.9528682;1.5056691;2.3203096;4.677585;0.5089635;2.82804;CODE
checking if the ellipse remained on visible on;-1.3099009;3.4874756;1.9149398;0.18886602;-4.078248;0.36237198;CODE
the canvas after being gc ed if not impossible;-3.2016044;-0.060962338;4.05499;1.2627423;-2.0302126;2.1577501;-
without the instruction object trick;-4.166815;-0.72663784;2.5259635;0.6205843;1.4861274;-2.518797;CODE
the red dot is present;-3.6163418;-0.63025016;4.23014;-1.4708903;-2.302452;-0.8358547;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
touch dot appears move touch dot moves;-3.5126803;-0.7354844;2.4869845;-1.8355029;-4.5607634;1.3951288;CODE
release touch touch dot disappear;-5.250094;-0.08404978;1.9804078;0.11805171;-4.674485;2.668693;IRRE
register mouse provider;-4.99825;-2.996959;1.8081163;-1.1497542;-0.6293706;4.926863;-
no mouse touch anywhere;-4.6105947;0.5495381;3.4895065;-0.12517132;-5.006124;1.1108285;IRRE
right button down red dot should appear;-6.3480844;-0.13365309;2.816001;-1.7763884;-3.4284146;1.9759367;CODE
if the multitouch on demand is disabled;-3.8057115;1.7955459;3.1624281;2.8989236;-1.2974449;4.0038548;-
doesn t do anything on a pure button;-5.5352855;0.8901738;0.5818507;1.9435624;-2.5135067;0.71665484;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
xxx right button up;-5.7781787;0.47898546;4.598038;-2.415333;-1.48643;1.0807896;META
first release the touch then check so that we;-4.3237095;-0.9878592;3.8300326;4.590502;-2.4287674;0.10950534;IRRE
have the red dot drawn in on demand and in the;-2.9593878;-2.3603446;6.070715;-0.4432395;-0.08344268;0.20603572;CODE
default multitouch everywhere because in the;-4.1441755;-0.8033807;2.992828;1.0722945;-1.3966682;5.1709504;CODE
multitouch on demand is the circle drawn after;-3.7173998;0.35514882;6.6726494;-0.46869767;-2.8288567;3.0758393;-
the touch is released in on mouse release;-5.58971;-1.9217355;6.071435;0.5223429;-3.4126346;2.3585246;-
on demand works after the touch is up;-4.8142967;-0.74750733;5.4688835;4.2222605;-2.2947445;2.8530736;-
multitouch sim is changed in on touch down;-3.8690078;2.166236;3.9045491;0.55568695;-2.0777497;3.8999581;CODE
method of the widget that s able to handle;-2.741841;-1.5253055;5.593567;1.8523732;-0.32103187;2.786859;CODE
multiple touches therefore for scatter we;1.7318653;-1.5833873;5.9340906;-2.1486616;-1.3198881;2.407553;CODE
need to dispatch the method and because we;-2.6115355;0.051093567;2.4784458;5.953359;1.7757373;0.2325646;TASK
triggered only on mouse down directly i e;-5.0356665;-1.3058841;4.9177237;0.7822271;-2.975646;3.402581;CODE
without me dispatch on touch down was not;-5.99097;0.9666955;2.6550286;3.0613668;-1.6756034;1.8877648;CODE
called multitouch sim is false;-3.9959033;3.0923502;1.8316339;1.4773158;-1.8693415;1.2837511;IRRE
elf advance frames 1 initialize stuff;-4.881565;-0.6822384;-1.2413759;0.21905768;-1.1636437;1.8469603;IRRE
the red dot isn t present;-5.24438;1.2057446;1.551857;-1.3546737;-4.0555444;-1.0860633;CODE
the red dot is present;-3.6163418;-0.63025016;4.23014;-1.4708903;-2.302452;-0.8358547;CODE
do not make any hard refs to drawelement;-4.186595;2.8793693;4.5331173;1.2128605;-0.20843002;0.24646457;CODE
the right click doesn t draw the red dot;-6.2256722;-0.082013346;2.9330351;-0.9844554;-5.0338984;1.2446958;CODE
the instructions aren t present test ends;-3.7559521;1.8006595;-1.0377749;3.9810472;-2.4003315;-5.709539;CODE
the red dot isn t present;-5.24438;1.2057446;1.551857;-1.3546737;-4.0555444;-1.0860633;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
the red dot moves when the touch is moving;-3.825693;-1.064447;4.7496796;-0.5935727;-3.7636356;0.63613766;CODE
bounding box from rectangle r 10 20 width;-0.4045275;2.9917998;3.515327;-3.8749733;-1.8543986;2.0839207;CODE
right button up;-5.358324;-0.5128424;5.879751;-0.63877356;-2.3838875;0.6056705;META
because the red dot is removed by the left button;-6.620228;0.10186384;1.9673598;-1.04417;-2.8543503;1.4452398;IRRE
the red dot is present;-3.6163423;-0.63024944;4.2301397;-1.4708897;-2.3024533;-0.8358539;CODE
the dot is at 11 11 but the touch is in;-4.4199905;0.56230503;3.9159825;-2.36657;-3.1138237;-1.4914008;META
its bounding box therefore it can move it;-4.1735687;0.6202852;4.228573;-1.7683831;-3.1190703;2.8158293;CODE
manipulating already existing touch;-3.9794;-0.5237015;6.757052;0.32076532;-1.2865372;4.4400425;CODE
no new one was created;-5.370527;-1.5084515;0.9753961;0.18774606;-0.47737387;-1.3562447;CODE
the red dot is present;-3.6163423;-0.63024944;4.2301397;-1.4708897;-2.3024533;-0.8358539;CODE
the red dot moves when the touch is moving;-3.825693;-1.064447;4.7496796;-0.5935727;-3.7636356;0.63613766;CODE
bounding box from rectangle r 10 20 width;-0.4045275;2.9917998;3.515327;-3.8749733;-1.8543986;2.0839207;CODE
the dot is removed after the touch is released;-6.7255716;-0.6916972;3.6366482;0.28136128;-2.9508677;2.563242;OUTD
when right touch is preserved dot remains;-3.8732827;0.8613913;4.2638736;-0.111348376;-3.3452942;3.5854177;CODE
when left touch is destroyed dot removed;-5.408086;1.2075772;3.7035658;0.2603105;-2.3626018;2.822367;OUTD
no matter where;-2.4590204;-1.0695721;5.461392;-0.24842869;-1.3929089;1.8196677;-
the red dot is present;-3.6163423;-0.63024944;4.2301397;-1.4708897;-2.3024533;-0.8358539;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
tests;0.88049054;1.2949181;4.1925097;6.4629726;0.08019503;-9.306;IRRE
register mouse provider;-4.99825;-2.996959;1.8081163;-1.1497542;-0.6293706;4.926863;-
no mouse touch anywhere;-4.6105947;0.5495381;3.4895065;-0.12517132;-5.006124;1.1108285;IRRE
left button down;-5.3919597;-0.14310241;6.7352552;-0.91169703;-1.6202352;0.6117723;META
the red dot isn t present;-5.24438;1.2057446;1.551857;-1.3546737;-4.0555444;-1.0860633;CODE
left button up;-5.8864946;0.10322276;5.847129;-0.6298079;-1.9439893;1.002403;META
after the releasing the touch disappears;-6.147422;0.9468805;5.5790796;1.7281084;-3.611758;1.6243418;-
but the counter remains;-2.9586604;2.6144187;4.986994;1.2132338;-0.16286711;-2.670002;META
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
register mouse provider;-4.99825;-2.996959;1.8081163;-1.1497542;-0.6293706;4.926863;-
no mouse touch anywhere;-4.6105947;0.5495381;3.4895065;-0.12517132;-5.006124;1.1108285;IRRE
right button down red dot should appear;-6.3480844;-0.13365309;2.816001;-1.7763884;-3.4284146;1.9759367;CODE
the red dot is present;-3.6163418;-0.63025016;4.23014;-1.4708903;-2.302452;-0.8358547;CODE
do not make any hard refs to drawelement;-4.186596;2.8793716;4.5331173;1.2128602;-0.20843032;0.24646485;CODE
check ellipse s position;-1.1095378;2.8980591;2.84568;-2.5304656;-4.203256;-2.7912657;-
bounding box from rectangle r 10 20 width;-0.4045279;2.9917998;3.5153272;-3.874974;-1.8543979;2.08392;CODE
almost equal because the correct y uses the same;0.9790516;3.4733393;1.5498637;-2.0107102;-4.415985;-2.8538117;IRRE
float float which returns decimal garbage;0.17692032;3.7668624;-1.112753;-3.2316244;-4.470583;-2.623455;CODE
the red dot moves when the touch is moving;-3.825693;-1.064447;4.7496796;-0.5935727;-3.7636356;0.63613766;CODE
bounding box from rectangle r 10 20 width;-0.4045275;2.9917998;3.515327;-3.8749733;-1.8543986;2.0839207;CODE
bounding box from rectangle r 10 20 width;-0.4045275;2.9917998;3.515327;-3.8749733;-1.8543986;2.0839207;CODE
because the red dot is removed by the left button;-6.620228;0.10186384;1.9673598;-1.04417;-2.8543503;1.4452398;IRRE
the red dot is present;-3.6163418;-0.63025016;4.23014;-1.4708903;-2.302452;-0.8358547;CODE
cleanup;-2.8195245;-1.0944757;4.192664;3.2826767;1.6149893;-1.8455502;TASK
remove mouse provider;-5.2792516;-0.52740747;2.1447542;-0.56607324;-2.471305;5.839471;-
these are taken from the examples in javascript code but made unistrokes;-3.6522977;-2.0454621;3.176307;-3.17099;0.17482403;-1.114185;CODE
dataset that matches n pretty well;7.3463497;-1.4264586;1.3304136;-1.8476816;3.6313274;-3.9971588;IRRE
recognizer scheduling;1.5473514;-3.5397928;-1.0133977;2.8711767;4.8092647;1.0418464;-
recognize tick is scheduled here compares to tinvar;-0.25628048;-0.5952542;0.4815642;1.299524;-1.5086721;-0.3063923;IRRE
now complete the search operation;-3.4472363;-0.4797506;3.171699;0.2686607;2.0509782;-2.3553658;CODE
clock tick first run scheduled here 9 left;-3.4184797;2.0183532;3.1755927;-0.34964997;-1.6600502;-1.6352028;CODE
clock tick 8 left;-4.4553204;0.7062286;5.12094;-2.351601;-1.8862913;-2.8561516;-
clock tick 7 left;-3.6458006;0.51326483;5.0331736;-2.0290132;-1.5230037;-3.4715052;-
run some immediate searches should not interfere;-2.615215;0.7830083;0.55858356;5.687691;-0.44934586;0.9213464;CODE
clock tick matches tbound in this tick;-1.6241505;2.4841225;2.772342;-2.2879329;-0.039709475;-3.78967;CODE
clock tick should match ninv but times out got t;-1.4501932;2.101074;0.1352733;-0.9938508;-2.4958017;-1.9631836;META
clock tick matches tbound in this tick;-1.6241505;2.4841225;2.772342;-2.2879329;-0.039709475;-3.78967;CODE
clock tick matches ninvar in this tick;-1.4171605;2.0791078;0.6096084;-2.8869033;-1.7042773;-2.4344645;CODE
clock tick should match tinvar but times out;-1.7737377;1.9525841;-0.42839122;-1.0440812;-3.6774166;-1.540214;META
recognizer filter tests;3.8381336;1.0016286;-4.1739397;4.078206;1.8168448;-3.7808647;IRRE
misc tests;0.54023135;2.3053892;-1.5989355;4.05074;-0.9137406;-5.9331574;IRRE
test protractor;-0.69694906;2.5992956;-1.2317897;2.500443;-1.4630206;-4.2517257;IRRE
a set wid 88 number shouldn t be accepted;-2.2591755;3.3498776;-3.1457455;0.012384298;3.3182456;-0.8305892;IRRE
try;-3.4765866;0.8005777;2.456937;3.0131333;-3.3279965;-2.7025638;CODE
a set wid string shouldn t be accepted;-3.1505306;3.9291084;-3.0617406;0.8798779;2.483785;-0.33184147;IRRE
self fail number accept string fail;-3.2365167;6.7405887;-3.400016;2.2153978;-0.1115221;-4.7313485;CODE
except valueerror;-1.676744;4.6333942;-2.2338173;1.3479702;-2.8161018;-4.642704;IRRE
pass;-1.8139739;0.29341647;3.770756;0.25528902;1.9562176;-4.0854783;-
test observer;-1.5342512;3.5419204;2.3089569;7.32637;0.29423222;-3.0585012;IRRE
test observer;-1.534251;3.5419204;2.308955;7.3263717;0.2942327;-3.0585003;IRRE
button togglebutton active false explicit initial state;-4.3775835;3.042599;0.18781874;2.1378894;-1.519881;2.4588728;META
should not update rebind false;-5.5919256;4.315802;-1.667533;3.0359151;-3.1266172;3.4184365;CODE
elf assertequal obj false text inactive still old value;-2.757339;6.5168567;-6.0554185;2.5493474;-1.3515152;-2.1961133;IRRE
color set wid 00ff00;-2.6016946;-0.8337712;0.6026774;-4.1818037;1.707054;0.2168973;IRRE
color set wid 7f7fff7f;-2.4298868;-0.079983436;0.8342008;-3.0726192;-0.106436156;1.7747728;IRRE
initial checks;-3.0386279;3.909344;1.9052306;3.6959143;1.2361786;-4.6257796;IRRE
get value should call getter once;-2.8553114;4.4217668;2.8651574;2.926964;0.7486132;1.0347;IRRE
setter should raise an attributeerror;-1.9759223;2.543237;-3.0296772;3.500781;-2.7790096;0.8138033;IRRE
initial checks;-3.0386279;3.909344;1.9052306;3.6959143;1.2361786;-4.6257796;IRRE
set property should call setter to set the value;-2.3159945;2.3475652;2.6174643;1.776408;0.7573316;1.5244329;IRRE
getter and callback should not be called because set prop doesn t;-4.856127;2.7780857;2.007712;3.6320608;-2.3620422;2.5013237;IRRE
returns true;-1.7568694;6.1937304;1.3589805;2.108573;-2.153825;-6.423035;IRRE
set property to same value as before should only call setter;-2.0327172;4.5516768;2.013758;2.8887048;1.2358422;2.945738;IRRE
get value of the property should call getter once;-2.8806887;4.450449;3.0430512;3.3524168;1.2066392;2.4023001;IRRE
initial checks;-3.0386279;3.909344;1.9052306;3.6959143;1.2361786;-4.6257796;IRRE
get value of the property should call getter once;-2.880687;4.4504466;3.0430503;3.352415;1.206639;2.4023006;IRRE
get value of the property should return cached value;-2.0155606;4.767155;1.7962209;3.0652018;-0.31839606;2.263981;IRRE
getter should not be called;-5.7560663;3.065871;-0.009746096;3.3742816;-2.0219805;2.2776263;IRRE
set value of property should call getter and setter;-2.6835704;2.61654;2.874512;1.9519404;1.4161463;2.2586339;IRRE
assert values when setting x width or right properties;1.2690799;6.7397695;-2.1268609;1.592466;0.16090907;-1.230251;IRRE
callback should be called only when property changes;-4.035785;3.6808155;2.9716313;5.8249555;-2.4216502;4.7515063;IRRE
initial checks;-3.0386279;3.909344;1.9052306;3.6959143;1.2361786;-4.6257796;IRRE
set property should call setter to set the value and getter to;-2.73288;2.093652;3.0546463;2.0429437;1.1705561;2.331734;IRRE
to get the value for dispatch call;-3.2263126;2.0334146;2.5544727;1.3120176;0.67053246;-0.4377125;IRRE
set property to same value as before setter and getter and callback;-2.1985204;3.4771776;4.4081764;3.4526424;0.7200898;3.3413143;IRRE
are called;-2.554035;-0.5018675;4.912618;2.6317594;1.6646432;-1.7863597;IRRE
initial checks;-3.0386279;3.909344;1.9052306;3.6959143;1.2361786;-4.6257796;IRRE
change the base value should trigger an update for the cache;-3.038926;3.116786;0.67579126;2.0912044;0.068241514;3.0887153;IRRE
now read the value again should use the cache;-4.169046;4.070522;1.1971158;1.8300004;-1.8516562;1.3658096;IRRE
change the prop itself should trigger an update for the cache;-4.617482;0.81835145;0.3894465;4.465485;-1.0183668;5.132012;CODE
initial checks;-3.0386279;3.909344;1.9052306;3.6959143;1.2361786;-4.6257796;IRRE
set alias property some value should call setter and then getter to;-2.7836883;2.7202566;1.775618;2.3469007;1.7649862;4.238484;IRRE
pass the value to callback;-3.6201577;3.4825346;4.806856;1.7369715;-1.5086765;0.70969754;IRRE
same as the step above should call setter getter and callback;-5.7255197;1.3719023;3.8812206;2.938645;-1.1329826;4.0564275;IRRE
get the value of property should use cached value;-1.9713116;4.4340577;1.5670886;2.662932;0.3281692;2.9470005;IRRE
widget2 name pasta does not raise a valueerror;-3.8931267;1.0634625;-2.9239883;1.3371872;-4.279981;0.15300001;CODE
widget3 name pasta does not raise a valueerror;-4.4606814;1.3563482;-2.969356;0.97802454;-3.8751867;-0.02361165;CODE
def test object init error the above 3 test rely on this;-2.154808;4.433562;-3.941135;3.7837996;-1.2961972;-5.2751184;IRRE
pass touch file;-4.9121313;-0.6035282;3.7965405;0.9214426;-2.583114;1.4195013;-
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
xxx mathieu i tried to fix the window context to prevent segfault here;-5.9209166;2.242083;-0.7357072;-1.6351;-2.4569285;-0.15582927;CODE
but nothing actually works works alone but not after a window restart;-6.1501136;0.43581173;1.3050017;2.0484085;-4.1469574;0.92368436;META
on linux;-4.572343;-6.7432647;2.650971;-2.4744234;-1.3672833;-2.6489134;-
1 0x00007ffff12807e9 in at usr lib libnvidia glcore so 418 43;-3.7768147;0.8729363;-2.8302853;-5.164535;0.639158;-0.0214587;-
2 0x00007ffff1288554 in at usr lib libnvidia glcore so 418 43;-3.7622693;0.31344828;-2.4159474;-5.218183;1.079325;-0.42354655;-
3 0x00007ffff0e2e3db in at usr lib libnvidia glcore so 418 43;-4.647133;0.18042307;-3.500419;-6.0695214;0.97526556;0.23098798;-
4 0x00007ffff5d5ae15 in pyx f 4kivy 8graphics 3vbo 11vertexbatch draw noqa;-4.930334;1.5957417;-1.1529852;-6.4041724;-1.3464746;0.70534205;-
pyx v self 0x7fffed641390 at kivy graphics vbo c 6529;-4.831418;-1.9625902;-2.363195;-3.2621818;-3.2888842;0.64139915;CODE
on osx;-5.7961626;-5.9651914;3.152553;-1.9118994;-1.054225;-1.4095083;-
thread 1 queue com apple main thread;-3.3215308;-0.5597396;3.0074255;0.79742765;-0.47373056;1.1745554;CODE
stop reason exc bad access code 1 address 0x0;-5.7496996;3.2097054;-2.4863908;0.4332034;-1.7114885;-0.20801564;TASK
frame 0 0x00007fff555d9d42 glengine glerunvertexsubmitimmediate 1234 noqa;-3.446551;2.581858;-0.66623664;-5.0276856;-1.601156;-1.5481299;CODE
frame 1 0x00007fff554c1544 glengine gldrawelements exec 563;-4.6882467;0.9097066;-1.64765;-4.5626597;-2.0637796;-0.39634418;-
frame 2 0x000000010429d273 vbo cpython 36m darwin so;-3.1161335;-2.92293;-1.6460487;-4.7336507;-2.1672332;-3.3865964;CODE
pyx f 4kivy 8graphics 3vbo 11vertexbatch draw;-5.5606747;-0.3161529;0.54488426;-4.0764933;-2.6862195;2.0712476;-
pyx v self 0x000000010cf344f8 at vbo c 6575 opt;-4.064898;0.25381944;-4.280038;-3.4913354;-1.6834211;0.17057307;CODE
rstdocument scatter gridlayout rstparagraph;0.5892326;-1.0278411;0.43496382;-3.4772115;-0.8369072;3.7924378;CODE
anchor and ref might change in the future;-3.4726646;-0.68155915;3.5831487;4.207266;-0.63347715;3.0639772;TASK
test queries;1.7315264;4.254604;1.9192737;4.120577;3.1048195;-7.7952313;IRRE
basic functionality tests;-2.1906667;0.60773313;0.6461768;5.8752084;0.9735917;-6.97632;IRRE
toggle timing tests toggle on property;-1.8324363;3.9059632;0.0821828;6.0406837;-0.730053;0.2430398;IRRE
call as class method;-3.3083599;-0.45066443;2.1981509;2.5451865;1.6094276;-0.20883134;IRRE
remove btn1;-4.22753;1.0086246;0.14794326;-2.27026;0.1796774;0.46745402;-
use class method to get remaining widgets;-0.9225218;0.95322937;3.3576791;0.8304742;0.49910906;0.77518934;CODE
try to modify returned list;-2.6802454;3.9024556;1.1975834;3.407351;-1.0450002;-1.9486818;CODE
verify internal group is unchanged;-1.7016642;5.05183;0.086995;1.9931002;1.2663534;-0.41940564;CODE
memory management tests;0.6117263;1.0666317;0.5033025;5.4502025;-0.18496145;-4.537619;IRRE
get group reference;-1.0108075;1.7391372;3.2010515;-0.4002816;1.6062142;-0.9578035;CODE
create weak references to track garbage collection;1.6040778;-0.19716512;-1.6308013;4.2164254;1.8123629;1.0858383;IRRE
delete buttons and the group list;-2.658473;0.8100484;4.132548;-0.8568827;0.71036434;1.979344;CODE
verify widgets were garbage collected;-2.1315296;1.2765843;-1.2368362;3.5505226;-2.2067604;-0.98325765;-
verify only btn1 remains in group after gc;-0.012136431;6.14798;-0.8166786;0.33214855;1.1911881;-1.7446995;CODE
validation and edge cases;2.652565;2.212903;1.5138197;2.9659104;4.9773703;-1.7529789;CODE
event callback tests;-3.0120347;3.5066044;1.8362993;7.807321;-1.8760806;-2.5064871;IRRE
copied from actionbar example edited for the test;-4.3465986;1.854649;0.42629278;4.0924115;-1.4487473;-0.1434388;IRRE
press release;-4.460167;-3.5316076;5.4691854;3.877965;-1.1312804;-1.0625598;-
kill kv lang logging too long test;-1.4218771;2.3014314;-2.2160566;4.3232512;-2.4117994;-0.5183578;IRRE
add the logging back;-6.2321815;0.43723312;3.530394;2.0733767;-3.1068947;1.3250432;TASK
mustn t allow more than one dropdown opened;-4.005909;2.4693213;0.7999998;1.7511622;1.1057153;0.7538015;CODE
passed;-3.8687704;-0.14950068;2.425011;1.892829;1.3164536;-3.4070625;-
click on group 2 to open its dropdown;-3.901397;-1.555675;4.8788147;0.026769284;-1.6276443;1.4353281;CODE
dropdown shows up;-3.1748168;-0.28039512;1.7715969;-0.1446442;-2.0225682;-0.30070788;CODE
then click away;-3.3685243;-1.0535291;5.945074;1.9120724;-1.1085488;1.4544953;CODE
group 2 dropdown disappears;-3.4555638;1.0870914;2.0117464;-0.08689904;-1.9371992;1.143798;CODE
click on group 1 to open its dropdown;-3.523264;-0.94320804;4.7901287;-0.14049387;-1.0173811;1.4099613;CODE
dropdown shows up;-3.1748168;-0.28039512;1.7715969;-0.1446442;-2.0225682;-0.30070788;CODE
then click away;-3.3685243;-1.0535291;5.945074;1.9120724;-1.1085488;1.4544953;CODE
group 1 dropdown disappears;-3.1749132;1.4218473;1.792121;-0.11962253;-1.6601148;0.8371417;CODE
no dropdown present yet;-4.8550754;-2.4551988;2.2594507;1.4904448;-1.3647461;-1.1207628;TASK
click on active group;-3.633873;-1.3172066;4.976272;0.40125975;-0.20346704;1.7501141;CODE
active group dropdown shows up;-2.9771335;-0.3274829;1.2728306;-0.34922576;-0.98823017;1.417841;CODE
active group dropdown value in weakproxy;-1.506493;1.6085448;-0.645652;2.1592867;1.8078582;3.814688;IRRE
click away;-3.7488663;-1.2791319;5.5566654;0.72448295;-1.3676631;0.84604454;CODE
wait for closed group dropdown to disappear;-2.2529862;2.4367964;3.0005028;2.7024565;-0.7139988;2.6987581;CODE
go to the next frame after the dropdown disappeared;-4.9538674;0.38646927;5.27971;-0.015899237;-2.8178656;2.8065557;CODE
no dropdown is open;-4.7519073;0.26172432;2.1291442;0.49594903;-3.240448;-0.19888288;CODE
click on group 2 to open its dropdown;-3.901397;-1.555675;4.8788147;0.026769284;-1.6276443;1.4353281;CODE
dropdown shows up;-3.1748168;-0.28039512;1.7715969;-0.1446442;-2.0225682;-0.30070788;CODE
then click on group 1 to open its dropdown;-3.1657598;-1.3650663;4.904104;-0.35870695;-0.57319075;1.6983718;CODE
group 2 dropdown disappears group 1 dropdown shows up;-2.9985447;1.0955691;0.7947982;-0.60370225;-2.1442916;1.4309055;CODE
click away;-3.7488663;-1.2791319;5.5566654;0.72448295;-1.3676631;0.84604454;CODE
no dropdown is opened;-5.127729;0.2794161;1.8843056;0.93049514;-3.2854397;-0.25181162;CODE
no dropdown present yet;-4.8550754;-2.4551988;2.2594507;1.4904448;-1.3647461;-1.1207628;TASK
click on group 2;-3.8128219;-1.8259003;5.990636;-0.40583718;-0.69689155;-0.12299846;CODE
group 2 dropdown shows up;-3.022641;0.62739366;1.8097035;-0.6571911;-1.6880178;0.67300093;CODE
group 2 dropdown value in weakproxy;-1.1905562;2.2507224;-0.2502603;1.2813836;1.7015442;3.1514874;IRRE
click away from actionbar and wait for it to disappear;-4.9482713;1.2632418;3.8440237;1.2619121;-2.4094574;4.431345;CODE
click on group 1;-3.4317005;-1.2237442;5.9731183;-0.75792223;-0.2828085;-0.3106053;CODE
wait for closed group 2 dropdown to disappear;-2.6936147;2.6950047;2.893401;2.4297256;-0.6892095;2.5522232;CODE
and for group 1 dropdown to appear there are 2 dds now;-2.388681;0.17355646;2.2611601;-1.2629708;2.9052603;0.6323378;CODE
go to the next frame after the dropdown disappeared;-4.9538674;0.38646927;5.27971;-0.015899237;-2.8178656;2.8065557;CODE
group 1 dropdown value in weakproxy group 2 dd;-1.0067558;2.7261088;-0.78338975;0.06751299;2.321093;2.6891184;IRRE
click away from actionbar;-4.849568;-0.6240736;4.4051075;0.1526668;-2.5421894;4.3386497;CODE
wait for closed group dropdown to disappear;-2.2529862;2.4367964;3.0005028;2.7024565;-0.7139988;2.6987581;CODE
go to the next frame after the dropdown disappeared;-4.9538674;0.38646927;5.27971;-0.015899237;-2.8178656;2.8065557;CODE
no dropdown present in window;-5.193395;0.12391571;2.0448961;0.4992628;-2.6796062;0.57090914;CODE
click on group 2 to open its dropdown;-3.901398;-1.5556756;4.8788147;0.026769582;-1.6276443;1.4353287;CODE
dropdown shows up;-3.1748168;-0.28039512;1.7715969;-0.1446442;-2.0225682;-0.30070788;CODE
then click on group 2 dropdown button;-2.9019089;-0.89513445;4.9214125;-0.36926934;-0.34940687;1.757389;CODE
dropdown disappears;-4.07508;0.5032871;2.2278337;0.5816407;-2.31839;0.3247886;CODE
click on group 1 to open its dropdown;-3.523264;-0.9432073;4.790127;-0.14049435;-1.0173812;1.4099613;CODE
dropdown shows up;-3.1748168;-0.28039512;1.7715969;-0.1446442;-2.0225682;-0.30070788;CODE
then click on group 1 dropdown button;-2.4327075;-0.5944173;4.902499;-0.41600922;0.19421777;1.7199925;CODE
dropdown disappears;-4.07508;0.5032871;2.2278337;0.5816407;-2.31839;0.3247886;CODE
no dropdown present yet;-4.8550754;-2.4551988;2.2594507;1.4904448;-1.3647461;-1.1207628;TASK
click on active group;-3.633873;-1.3172066;4.976272;0.40125975;-0.20346704;1.7501141;CODE
active group dropdown shows up;-2.9771335;-0.3274829;1.2728306;-0.34922576;-0.98823017;1.417841;CODE
active group dropdown value in weakproxy;-1.506493;1.6085448;-0.645652;2.1592867;1.8078582;3.814688;IRRE
click on active group dropdown button needed to window;-4.2226734;-1.5411351;3.7189217;0.22991599;-0.55184287;2.691061;CODE
wait for closed group dropdown to disappear;-2.2529852;2.4367964;3.0005026;2.702457;-0.7139989;2.698759;CODE
go to the next frame after the dropdown disappeared;-4.9538674;0.38646927;5.27971;-0.015899237;-2.8178656;2.8065557;CODE
no dropdown is open;-4.7519073;0.26172462;2.1291437;0.4959495;-3.2404478;-0.19888316;CODE
click on group to open its dropdown;-3.1489713;-1.6070186;4.900115;0.115708366;-1.1723241;1.3396214;CODE
dropdown shows up;-3.1748168;-0.28039512;1.7715969;-0.1446442;-2.0225682;-0.30070788;CODE
then click on group dropdown button;-2.383624;-1.5752274;5.058336;-0.38810968;0.2080228;1.8100494;CODE
dropdown disappears;-4.07508;0.5032864;2.2278342;0.58164144;-2.3183906;0.32478845;CODE
repeat;-1.6292728;1.1639252;6.8832784;1.5085413;1.4547193;-3.1930037;-
no dropdown present yet;-4.8550754;-2.4551988;2.2594507;1.4904448;-1.3647461;-1.1207628;TASK
click on group;-2.7894008;-1.6649983;6.594534;-0.06781783;-0.28188625;0.29756284;CODE
group dropdown shows up;-2.4409058;0.023824418;2.0109215;-0.7464256;-1.529263;0.61440414;CODE
group dropdown value in weakproxy;-0.7214797;1.7754831;0.03211265;1.9350361;2.1673124;3.3702705;IRRE
click on group dropdown button;-2.3495328;-1.3110994;4.9233017;-0.44907317;-0.14992067;1.5378789;CODE
wait for closed group dropdown to disappear;-2.2529852;2.4367964;3.0005026;2.702457;-0.7139989;2.698759;CODE
go to the next frame after the dropdown disappeared;-4.9538674;0.38646927;5.27971;-0.015899237;-2.8178656;2.8065557;CODE
no dropdown is open;-4.7519073;0.26172447;2.129145;0.49594972;-3.2404478;-0.19888261;CODE
load zip with images named 000 png 001 png;-2.3049285;0.29670054;-0.0034529332;-2.5142517;-0.22489691;1.5904113;CODE
bind to on load because there are various;-4.572097;0.62692356;3.3659947;3.0207605;2.992526;3.8557184;CODE
steps where the image is re loaded but;-4.8583126;0.2577245;5.3621955;1.1928822;-3.580518;4.1928854;META
the event is triggered only at the end;-6.0242643;1.2664682;3.772716;3.0914211;-2.0021718;1.2135426;CODE
cube zip has 63 pngs used for animation;-3.449344;-1.1699703;1.4249507;-3.0824432;-0.39832243;0.1856864;CODE
ref loader load urllib;-4.659112;0.46054;0.15388483;2.8849945;-1.8306426;2.3931184;CODE
pure delay fps isn t enough and;-3.1081705;1.433382;0.86780834;0.3409863;-3.2788572;1.4411238;-
just 1 isn t either index collisions;-0.23081309;2.9098632;-1.1493983;-1.715213;1.8122683;-2.8953784;-
cube zip has 63 pngs used for animation;-3.449344;-1.1699703;1.4249507;-3.0824432;-0.39832243;0.1856864;CODE
pure delay fps isn t enough and;-3.1081705;1.433382;0.86780834;0.3409863;-3.2788572;1.4411238;-
just 1 isn t either index collisions;-0.23081309;2.9098632;-1.1493983;-1.715213;1.8122683;-2.8953784;-
check whether it really changes the images;-1.8101697;2.5851262;2.2760134;2.371791;-3.497981;1.6250564;-
in the anim delay interval;-1.7419924;1.9619424;1.9927698;-0.39940184;-1.379298;0.9462988;CODE
different frames sequence is changing;-1.6400695;2.7111876;2.4266098;-2.0737376;-2.2679145;1.5615714;-
bubble width button height arrow pos;-3.0801594;0.12989306;3.5690997;-3.5519211;-1.505654;2.5897799;META
158 9 34 3 bottom left noqa e201 e241;-2.8112972;2.692337;2.9078176;-5.7358956;0.0030430302;-4.289541;-
651 4 26 1 bottom mid noqa e201 e241;-4.12089;2.704954;1.7818807;-5.9437327;1.1976744;-3.6955943;-
6 5 44 7 bottom right noqa e201 e241;-3.7241075;1.8308554;2.499696;-6.124709;0.5450576;-3.0103798;-
754 6 50 6 top left noqa e201 e241;-3.1093116;2.4199216;1.3730708;-5.897986;0.67063534;-3.6294413;-
957 8 74 1 top mid noqa e201 e241;-2.535215;2.2643406;0.79346824;-5.068418;1.9636846;-2.9848385;-
852 1 33 1 top right noqa e201 e241;-3.4354463;1.8237662;1.957723;-5.7825294;1.5833718;-2.8673515;-
472 9 45 1 left top noqa e201 e241;-3.9488637;1.8655448;1.8135407;-6.264011;1.5454516;-2.4656394;-
578 3 52 7 left mid noqa e201 e241;-4.750519;2.5369027;1.634113;-4.517229;0.91173494;-3.38855;-
687 8 17 7 left bottom noqa e201 e241;-3.721146;2.0014894;2.4663947;-5.7525373;1.6337267;-2.900354;-
313 7 8 6 right top noqa e201 e241;-2.384641;1.6238087;1.5544502;-5.1410255;1.6910961;-2.7630296;-
194 3 46 4 right mid noqa e201 e241;-3.6895034;2.556802;1.5049464;-4.8268228;1.2707689;-3.8338423;-
59 3 29 7 right bottom noqa e201 e241;-3.2886183;1.5428475;2.3701215;-5.6643085;0.4333444;-3.2556815;-
101 3 346 0 0 0 73 6 l noqa e201 e241;-0.15625826;2.541433;0.070772104;-7.42833;0.42027253;-5.52628;-
489 0 535 1 0 0 442 1 l noqa e201 e241;-2.0847893;2.2580035;-0.3806106;-7.6537013;1.59742;-5.550628;-
390 9 728 1 0 0 114 3 l noqa e201 e241;-1.564826;1.7441964;-0.7636104;-7.3032794;0.19045919;-4.7120147;-
224 5 675 5 0 0 560 6 l noqa e201 e241;-2.1925662;2.1578262;0.11342228;-7.2849874;0.86687344;-4.578853;-
264 9 677 3 0 0 8 3 l noqa e201 e241;-2.161467;1.3133193;0.19061786;-6.1392236;1.2560136;-5.5857253;-
544 6 126 0 0 0 120 9 l noqa e201 e241;-1.4083573;2.044659;-0.068936415;-6.790478;0.61409134;-5.974831;-
290 9 962 6 0 0 275 5 l noqa e201 e241;-0.6176605;2.864309;0.15609235;-6.596063;-0.046739187;-4.1704516;-
358 4 514 4 0 0 427 1 l noqa e201 e241;-1.3092811;1.957681;0.45513144;-6.914247;1.4183296;-4.982555;-
604 3 648 2 0 0 226 1 l noqa e201 e241;-2.5281835;2.3037815;-0.11314023;-7.497789;1.0033653;-4.921552;-
287 4 875 6 0 0 446 5 l noqa e201 e241;-1.5103588;2.3722668;-0.2090294;-6.2900896;1.2333422;-5.092176;-
755 7 103 5 444 6 0 0 b noqa e201 e241;-1.7353356;2.4785047;0.25792015;-6.3380246;1.5265169;-5.791961;-
307 9 471 7 80 9 0 0 b noqa e201 e241;-1.7728418;1.8685586;-0.25077498;-6.729051;1.9557014;-4.883725;-
849 9 194 8 652 7 0 0 b noqa e201 e241;-1.7953413;1.7232796;-0.25915277;-6.788962;1.3065836;-5.0329776;-
975 7 691 0 120 9 0 0 b noqa e201 e241;-0.1869123;2.2493784;-0.4501158;-7.2323475;1.3083742;-5.6083426;-
539 1 903 3 530 6 0 0 b noqa e201 e241;-2.1537914;2.4464712;-0.12206877;-7.7358875;2.0821993;-5.4306755;-
37 5 727 5 37 0 0 0 b noqa e201 e241;-1.2622097;2.8459845;0.95131546;-6.9186206;0.6853282;-5.160348;-
856 5 779 0 565 5 0 0 b noqa e201 e241;-1.9519749;2.0949006;-0.36337715;-6.44206;1.8985195;-5.000053;-
536 7 228 3 48 4 0 0 b noqa e201 e241;-2.7215655;1.6829861;0.6382213;-5.9122896;1.5837954;-5.0608897;-
170 9 870 4 127 6 0 0 b noqa e201 e241;-1.6077967;2.2886322;-0.23095447;-5.5548196;-0.7495219;-5.32525;-
955 7 530 6 526 0 0 0 b noqa e201 e241;-1.7276466;1.9673558;-0.2153688;-6.5739474;1.3443041;-5.806853;-
878 1 690 4 878 1 18 8 r noqa e201 e241;-2.4019768;3.1125286;0.77021915;-6.2642846;1.6579475;-3.943531;-
771 6 365 2 771 6 31 1 r noqa e201 e241;-1.5143981;1.8424246;1.3594009;-6.89446;2.4812772;-5.3911366;-
679 7 305 4 679 7 259 6 r noqa e201 e241;-2.654834;1.0848405;0.58699816;-6.1457057;1.7701513;-3.919107;-
700 2 614 6 700 2 105 4 r noqa e201 e241;-0.97602683;1.4983099;1.6888521;-5.9318233;2.5777671;-4.4214635;-
444 1 864 5 444 1 152 3 r noqa e201 e241;-3.4077342;1.9480443;1.0062386;-6.993589;2.8023162;-4.6008472;-
189 0 790 4 189 0 602 9 r noqa e201 e241;-0.57251346;2.2900836;0.5516732;-6.381411;0.75071377;-4.953357;-
376 0 993 9 376 0 486 4 r noqa e201 e241;-1.2801061;2.1625285;0.9569866;-8.4330225;1.6085963;-5.99809;-
518 5 338 5 518 5 194 6 r noqa e201 e241;-3.5036583;1.8465897;1.3003424;-6.154614;2.437338;-4.996143;-
982 1 666 1 982 1 282 5 r noqa e201 e241;-2.8202472;2.242766;0.032710336;-7.291412;2.0896494;-5.0963383;-
926 4 565 1 926 4 187 3 r noqa e201 e241;-2.9347482;2.1172493;2.0187433;-6.359296;2.4542167;-4.117744;-
375 2 746 6 36 2 746 6 t noqa e201 e241;-1.7482047;2.8582509;0.9518293;-7.704633;2.3411326;-4.224302;-
448 9 228 5 297 4 228 5 t noqa e201 e241;-3.235059;1.0806302;0.7197935;-5.544143;2.6725998;-4.128316;-
792 3 593 5 746 2 593 5 t noqa e201 e241;-3.219712;2.110769;1.1230112;-6.4378185;2.9232635;-4.141332;-
856 1 89 7 23 1 89 7 t noqa e201 e241;-2.2024572;2.5530827;0.94941384;-6.723191;2.370705;-4.4170012;-
721 3 319 0 356 5 319 0 t noqa e201 e241;-1.9591954;2.6574793;-0.1053232;-7.8018603;1.7703222;-5.113423;-
127 7 355 7 69 3 355 7 t noqa e201 e241;-3.7498372;2.5255382;1.428893;-6.8340364;0.9149144;-4.6848626;-
412 3 493 8 163 2 493 8 t noqa e201 e241;-2.3814945;1.6564355;1.6253673;-6.534289;2.4124882;-4.2298656;-
40 8 115 8 15 8 115 8 t noqa e201 e241;-1.198333;2.2653713;1.7295518;-5.211599;1.7807095;-4.069734;-
233 9 148 5 189 4 148 5 t noqa e201 e241;-2.063865;0.84659874;0.026980275;-4.563754;0.63586915;-5.541823;-
982 4 661 5 105 9 661 5 t noqa e201 e241;-2.5691388;1.9181044;-0.029911911;-6.3097153;2.4419384;-4.793463;-
assert content size;0.6456759;5.222673;-1.5794448;3.6072528;0.9723636;-1.7573375;CODE
assert arrow layout size;-0.98415565;3.5758297;-0.39520353;0.44683975;-0.48981464;1.368496;CODE
assert content position;-1.7720444;5.5463104;0.8094577;3.6588109;1.537494;-1.469459;CODE
assert arrow layout position;-2.0516508;3.938659;0.21519761;0.5679266;-0.45542666;0.8689859;CODE
assert arrow position within arrow layout;-1.8200085;4.063567;-0.113128535;1.0372525;-0.9588839;1.3806578;CODE
hal arrow length 2 hal half arrow length;-1.6552942;0.86308366;2.661855;-4.3986;0.44595358;-1.3593692;-
assert arrow rotation;-0.4521929;3.9504282;-1.520573;1.711384;-1.6146166;-0.94531804;CODE
assert content size;0.6456759;5.222673;-1.5794448;3.6072528;0.9723636;-1.7573375;CODE
assert content position;-1.7720444;5.5463104;0.8094577;3.6588109;1.537494;-1.469459;CODE
haw bubble arrow width 2 half arrow width;-2.0245318;0.95927614;2.787959;-4.8750634;-0.7109291;1.907649;-
test issue 6370;-1.7904234;5.061073;-3.2900624;2.1372116;-2.5456362;-7.180387;IRRE
remove a slide smaller index than the current slide s;-1.4509509;2.7148926;2.7067258;-1.8072844;-0.88441455;2.9824085;-
remove a slide bigger index than the current slide s;-1.6166162;2.3739014;2.7644346;-1.5629417;-1.0779903;3.0778456;-
remove the current slide the last one left;-4.5955787;1.878253;5.4936285;-1.8354657;-0.64610994;0.2700288;-
colorpicker has a stated default colour opaque white;-3.3692958;0.5536737;-2.675503;0.39407253;-2.3946736;2.2197492;CODE
colorwheel has a different default color transparent black;-4.517255;0.95829004;-1.1371284;-0.86243385;-1.2543428;2.6919115;CODE
click on corner of widget;-5.572074;-1.5601192;5.9797215;-1.9465035;-3.9605992;2.4744833;CODE
too far from the center no effect;-2.5883205;2.0780718;4.2725663;0.051800463;-5.230677;1.1366733;CODE
click in middle half the radius up;-3.9684074;0.26283312;6.098521;-1.8597101;-4.460306;0.7006318;CODE
colorpicker has a stated default colour opaque white;-3.3692958;0.5536737;-2.675503;0.39407253;-2.3946736;2.2197492;CODE
colorwheel has a different default color transparent black;-4.517255;0.95829004;-1.1371284;-0.86243385;-1.2543428;2.6919115;CODE
set without alpha;-1.6632607;2.1492474;3.2564485;-0.74231046;-0.38204244;-0.52458155;IRRE
set with alpha;-1.1324182;1.2162244;4.479062;-1.9668036;0.56905174;-1.7848216;IRRE
just press button;-5.313505;-0.94259626;6.174014;1.2931601;-2.3519719;1.1625065;META
open dropdown;-3.414145;-1.8583782;4.765717;0.51787406;-0.30824292;-0.010577276;CODE
press within dropdown area should stay open;-4.035737;0.99767107;3.5799763;1.4484339;-2.197295;2.1245375;CODE
start in dropdown but release outside should stay open;-4.5586457;1.5510197;4.3682017;2.135788;-1.1206715;3.554007;CODE
start outside but release in dropdown should close;-5.1753216;1.4114046;4.2837358;2.5774062;-1.5340393;2.8974922;CODE
open dropdown again;-4.442643;0.4584254;4.28624;2.1182775;-1.5943017;0.8744221;CODE
press outside dropdown area to close it should close;-4.559965;0.2884927;4.4783964;1.0272372;-1.6098516;2.4617388;CODE
ref github issue 5278 init rows cols sizes fix;-1.1046139;1.2181641;-3.6200798;-2.450286;-3.468403;1.5403345;IRRE
this combination could trigger an error;-4.0760303;3.0177262;-1.6934601;0.8652361;1.5455072;-4.0896773;CODE
set pos to some random value to make this test more reliable;3.2626216;6.330022;-1.5656613;5.943533;-0.57235765;-4.2963953;IRRE
0 1 2;-2.5299845;0.063785024;2.9714615;-4.363006;-0.17404124;-4.8759656;-
2 1 0;-1.922585;1.767267;3.3170512;-2.7052326;0.097818665;-4.4511485;-
0 1;-2.018396;1.7460043;3.0959432;-3.6597617;-0.67719513;-5.292951;-
2 3;-3.8268602;0.43441758;4.0858603;-3.1595225;1.9986985;-5.366759;-
2 3;-3.8268602;0.43441758;4.0858603;-3.1595225;1.9986985;-5.366759;-
0 1;-2.018396;1.7460043;3.0959432;-3.6597617;-0.67719513;-5.292951;-
1 0;-1.5624485;2.4980729;3.5201719;-3.0049706;-0.9159242;-4.838919;-
3 2;-3.744641;0.4637684;4.2153625;-2.6653292;1.8919945;-5.407994;-
3 2;-3.744641;0.4637684;4.2153625;-2.6653292;1.8919945;-5.407994;-
1 0;-1.5624485;2.4980729;3.5201719;-3.0049706;-0.9159242;-4.838919;-
0 2;-3.0471303;0.43734384;3.1327126;-3.8733993;-0.4964097;-5.215565;-
1 3;-3.201053;1.1188112;4.1468387;-4.151734;1.4554034;-6.0007334;-
2 0;-2.4647024;1.3693689;3.5659375;-2.3757374;0.02254102;-4.771006;-
3 1;-3.1068225;1.2827098;4.2109118;-3.4795852;1.6211159;-5.8422837;-
1 3;-3.201053;1.1188112;4.1468387;-4.151734;1.4554034;-6.0007334;-
0 2;-3.0471303;0.43734384;3.1327126;-3.8733993;-0.4964097;-5.215565;-
3 1;-3.1068225;1.2827098;4.2109118;-3.4795852;1.6211159;-5.8422837;-
2 0;-2.4647024;1.3693689;3.5659375;-2.3757374;0.02254102;-4.771006;-
noinspection pyprotectedmember;-2.24623;1.1049868;-2.1782024;0.42019346;-1.3709176;3.6026714;CODE
just press button;-5.313505;-0.94259626;6.174014;1.2931601;-2.3519719;1.1625065;META
open modal;-4.759639;-0.06884273;6.39219;0.13341829;0.2105354;1.1694716;CODE
press within modal area should stay open;-5.96817;2.4773586;4.7339845;1.2182022;-2.3202422;4.116112;CODE
start in modal but release outside should stay open;-6.597353;2.311643;4.840627;2.155601;-0.968232;5.2458987;META
start outside but release in modal should close;-6.6151295;2.3077748;4.6504965;2.9132566;-1.3465105;4.6892543;META
open modal again;-6.2103977;1.8367981;5.6229415;1.3271544;-1.0879874;1.7094676;CODE
press outside modal area should close;-6.1056037;1.9141564;5.3319144;1.2156043;-2.120729;4.2205234;CODE
use kv because recycleview cannot be constructed from python;-3.0302708;-2.3016033;-2.8759196;-2.2474735;-3.0805905;0.087829694;CODE
0 1 2;-2.5299845;0.063785024;2.9714615;-4.363006;-0.17404124;-4.8759656;-
2 1 0;-1.922585;1.767267;3.3170512;-2.7052326;0.097818665;-4.4511485;-
0 1;-2.018396;1.7460043;3.0959432;-3.6597617;-0.67719513;-5.292951;-
0 1;-2.018396;1.7460043;3.0959432;-3.6597617;-0.67719513;-5.292951;-
1 0;-1.5624485;2.4980729;3.5201719;-3.0049706;-0.9159242;-4.838919;-
1 0;-1.5624485;2.4980729;3.5201719;-3.0049706;-0.9159242;-4.838919;-
0 2;-3.0471303;0.43734384;3.1327126;-3.8733993;-0.4964097;-5.215565;-
2 0;-2.4647024;1.3693689;3.5659375;-2.3757374;0.02254102;-4.771006;-
0 2;-3.0471303;0.43734384;3.1327126;-3.8733993;-0.4964097;-5.215565;-
2 0;-2.4647024;1.3693689;3.5659375;-2.3757374;0.02254102;-4.771006;-
use kv because recycleview cannot be constructed from python;-3.0302708;-2.3016033;-2.8759196;-2.2474735;-3.0805905;0.087829694;CODE
if scrollable width avoids zerodivisionerror;-1.2947091;3.7124693;-4.153743;-1.9469208;-4.952096;1.8267211;CODE
if scrollable height avoids zerodivisionerror;-2.0421011;3.1538465;-3.5320652;-1.9496697;-5.5377264;1.8599433;CODE
1 2;-3.0582857;0.35204685;4.1479173;-3.3124318;1.3374486;-6.0562406;-
2 1;-2.646043;0.23820533;4.203131;-2.8344553;1.2994128;-5.8948927;-
4 5;-1.8187984;1.1036255;5.064045;-1.4941326;0.47056645;-4.263284;-
4 5;-1.8187984;1.1036255;5.064045;-1.4941326;0.47056645;-4.263284;-
5 4;-1.8528275;1.108216;5.001825;-1.606109;0.5093531;-4.3488407;-
5 4;-1.8528275;1.108216;5.001825;-1.606109;0.5093531;-4.3488407;-
4 7;-1.1609676;0.92463696;4.8413353;-1.8541943;0.32099703;-4.156366;-
7 4;-1.4227906;0.8096777;4.7714915;-2.1388063;0.48131585;-4.3018436;-
4 7;-1.1609676;0.92463696;4.8413353;-1.8541943;0.32099703;-4.156366;-
7 4;-1.4227906;0.8096777;4.7714915;-2.1388063;0.48131585;-4.3018436;-
eventloop window add widget rl do layout called;-5.854472;-0.97047514;4.02699;-0.2524522;-1.2143927;5.209616;IRRE
we start with the default top left corner;-5.592803;-1.7773387;5.9317913;-1.8572813;-1.7891085;2.6869605;CODE
check the collision with the margin empty area;-2.1697109;3.4733284;2.7677372;0.27361447;-1.6001114;-1.5593771;-
check the scroll position;-3.4276063;1.9616482;4.6536875;-0.9448313;-3.7167351;-0.09223415;-
reset scroll to original state;-3.9628456;2.1659992;4.1896377;0.44421428;-2.5094283;4.641625;IRRE
get widgets ready;-3.7099965;-1.9769486;3.6487248;0.4371096;-3.024307;2.590374;CODE
get widgets ready;-3.709997;-1.9769502;3.6487253;0.43710905;-3.024307;2.5903742;CODE
get widgets ready;-3.709997;-1.9769502;3.6487253;0.43710905;-3.024307;2.5903742;CODE
get widgets ready;-3.709997;-1.9769502;3.6487253;0.43710905;-3.024307;2.5903742;CODE
touch in the half of the bar;-3.290372;0.48492894;7.9945717;-1.071093;-2.5673;-1.4268016;IRRE
get widgets ready;-3.709997;-1.9769502;3.6487253;0.43710905;-3.024307;2.5903742;CODE
touch in the half of the bar;-3.2903726;0.48492965;7.99457;-1.0710927;-2.567301;-1.4268019;IRRE
get widgets ready;-3.709997;-1.9769502;3.6487253;0.43710905;-3.024307;2.5903742;CODE
touch in the half of the bar;-3.2903726;0.48492965;7.99457;-1.0710927;-2.567301;-1.4268019;IRRE
xxx this shouldn t be needed but previous tests apparently;-2.465743;3.5091076;-0.5827561;1.0998086;-0.96298593;-2.068544;IRRE
don t cleanup;-2.7356226;0.65383154;1.718078;3.418058;-0.4009356;-0.5903457;TASK
get widgets ready;-3.709997;-1.9769502;3.6487253;0.43710905;-3.024307;2.5903742;CODE
eventloop post dispatch input update touch;-5.321082;-0.12708782;3.739835;3.5094867;-1.5199564;2.2311769;CODE
wait for velocity to die off;-1.7046909;0.69916177;1.4797614;2.7830973;-2.342621;0.28771633;CODE
eventloop post dispatch input update touch;-5.321081;-0.12708814;3.739835;3.5094867;-1.5199564;2.2311766;CODE
kill kv lang logging too long test;-1.4218771;2.3014314;-2.2160566;4.3232512;-2.4117994;-0.5183578;IRRE
add the logging back;-6.2321815;0.43723312;3.530394;2.0733767;-3.1068947;1.3250432;TASK
get widgets ready;-3.7099965;-1.9769486;3.6487248;0.4371096;-3.024307;2.590374;CODE
default pos new pos slider id;-5.0544004;-0.26846337;0.18154487;-1.6828235;2.0007396;2.9025102;CODE
custom touch;-4.0817103;-1.7116475;6.7487106;-0.08762473;-0.47136924;3.2053008;-
touch down;-3.0018313;-0.9341855;7.461439;0.95120317;-1.1735948;-2.0967426;CODE
touch on handle;-5.5825276;-0.9152778;6.2029862;0.23311056;-2.366883;-0.64563906;-
touch in widget area ignored previous value;-4.204234;4.2871704;4.709901;0.69214195;-4.343375;3.0128198;IRRE
touch on handle;-5.5825276;-0.9152778;6.2029862;0.23311056;-2.366883;-0.64563906;-
touch in widget area;-4.486144;-0.48209003;7.287372;-1.4404469;-3.4839976;2.7672446;-
move from default to new pos;-4.0256457;0.050037485;1.5050865;0.73834044;-0.721013;4.1019654;CODE
move from handle to center;-4.100521;0.714315;5.0637655;-2.2913349;-2.8418772;3.29838;CODE
move to center ignored previous value;-1.5198096;4.7132335;3.7867098;-2.367842;-4.5987616;2.2599664;IRRE
touch on handle;-5.5825276;-0.9152778;6.2029862;0.23311056;-2.366883;-0.64563906;-
touch in widget area;-4.486144;-0.48209003;7.287372;-1.4404469;-3.4839976;2.7672446;-
touch up;-3.5220068;-1.0706351;6.589954;1.186469;-1.7915671;-1.3167427;-
default orientation is lr tb;-3.6807346;1.3046045;0.08390708;-3.297225;0.14937587;4.4450154;CODE
default orientation is lr tb;-3.6807346;1.3046045;0.08390708;-3.297225;0.14937587;4.4450154;CODE
default orientation is lr tb;-3.6807346;1.3046045;0.08390708;-3.297225;0.14937587;4.4450154;CODE
floating point error requires almost equal;2.4498918;5.0313315;-3.980756;-1.5314505;-5.4583178;-3.3077493;CODE
happens when padding is too big;-2.213185;2.0765078;1.1446391;-0.8137751;-3.4439595;0.8871982;TASK
check if text is modified while recreating from lines and lines flags;0.2787646;3.6081622;0.30740494;1.3721186;-1.179829;-1.8580898;CODE
check if wordbreaking is correctly done;-2.4035003;3.6173966;-0.099304445;3.8477356;0.76998;-4.104996;CODE
if so secondvery should start from the 7th line;-1.6941813;0.7860607;3.146178;1.0119703;0.7740318;-1.7779974;CODE
none displayed str;-6.5364976;3.037045;-1.8253459;-3.2487617;-2.5451376;-3.2280145;-
none internal str;-5.871159;1.0649862;-1.1235424;-1.6886808;0.41729188;-3.158184;CODE
enter internal action;-7.555727;0.10749889;3.5444515;2.4851112;0.34513897;0.19233768;CODE
1 scale;2.3201706;0.61742574;5.1511865;-3.1881218;-1.2739956;-1.9518175;-
assert cursor is here;-2.292069;5.051824;-2.4474757;4.044276;-2.4524353;-4.8488464;CODE
multiline;-0.7732352;-0.81777316;4.5560913;-3.8930366;1.5834541;-2.4247155;-
text;-2.914245;-3.0481303;7.405587;-0.5022071;1.795113;-3.5489922;-
move and check position;-1.930443;3.562136;5.203806;-0.95359933;-1.0150734;-2.9556856;-
mult iline;-1.7110354;2.5736554;3.9141963;-0.07076223;-0.7250954;-0.79483074;-
text;-2.914245;-3.0481303;7.405587;-0.5022071;1.795113;-3.5489922;-
ti key down push selection;-3.0572069;-0.038376812;3.514564;-1.2955762;-0.36037013;1.3112439;CODE
none displayed str;-6.5364976;3.037045;-1.8253459;-3.2487617;-2.5451376;-3.2280145;-
none internal str;-5.871159;1.0649862;-1.1235424;-1.6886808;0.41729188;-3.158184;CODE
shift internal action;-5.5362043;0.73836726;4.0052176;1.1081529;0.07935063;3.3396168;CODE
1 scale;2.3201706;0.61742574;5.1511865;-3.1881218;-1.2739956;-1.9518175;-
pop selection;-0.47305858;-1.0590343;5.3525867;2.1992695;1.6271365;0.7557995;CODE
overwrite selection with n;1.0366801;3.0893638;0.8765547;-2.0498624;3.6288002;-2.0913835;CODE
assert cursor is here;-2.292069;5.051824;-2.4474757;4.044276;-2.4524353;-4.8488464;CODE
singleline;-1.593267;-0.52269405;4.22114;-1.7272717;0.49359605;-2.1675265;-
move and check position;-1.930443;3.562136;5.203806;-0.95359933;-1.0150734;-2.9556856;-
single line;-2.0679512;0.9764083;5.21663;-2.0924997;0.7025006;-3.3491962;-
push selection;0.12865579;-0.91781145;4.816066;2.7379584;1.7781532;2.8424072;CODE
pop selection;-0.47305673;-1.0590348;5.3525887;2.1992674;1.6271363;0.7557997;CODE
try to overwrite selection with n;-0.15401202;3.578092;-0.9292462;-1.9715887;1.6428633;-2.8905923;CODE
shouldn t work because single line;-3.311422;4.5343065;1.9321858;-1.8618963;-1.9755104;-1.8974978;-
assert cursor is here;-2.292069;5.051824;-2.4474757;4.044276;-2.4524353;-4.8488464;CODE
cursor at the place of;-4.913076;-0.5945483;5.230801;-1.9215246;-2.2161446;-0.900079;-
some random te xt;-0.3794318;-0.71786743;2.8145745;0.023072783;0.17966104;-3.835223;IRRE
push selection;0.12865579;-0.91781145;4.816066;2.7379584;1.7781532;2.8424072;CODE
pop selection;-0.47305858;-1.0590343;5.3525867;2.1992695;1.6271365;0.7557995;CODE
cursor at the place of selection between chars;-1.5818243;0.037500184;2.7710216;-1.8570391;-0.12080958;-0.8941772;CODE
some rando m te xt;-0.46003276;-0.67289066;2.1011162;-0.27150324;0.67249864;-2.07375;IRRE
cursor now at some rando xt;-2.856628;-1.20665;2.4194865;-0.072666734;-2.1417997;-1.0639724;IRRE
assert cursor is here;-2.292069;5.051824;-2.4474757;4.044276;-2.4524353;-4.8488464;CODE
cursor at the place of;-4.9130754;-0.5945485;5.2308025;-1.9215248;-2.2161448;-0.90008056;-
some random te xt;-0.3794318;-0.71786743;2.8145745;0.023072783;0.17966104;-3.835223;IRRE
push selection;0.12865579;-0.91781145;4.816066;2.7379584;1.7781532;2.8424072;CODE
pop selection;-0.47305673;-1.0590348;5.3525887;2.1992674;1.6271363;0.7557997;CODE
cursor at the place of selection between chars;-1.5818243;0.037500184;2.7710216;-1.8570391;-0.12080958;-0.8941772;CODE
some rando m te xt;-0.46003276;-0.67289066;2.1011162;-0.27150324;0.67249864;-2.07375;IRRE
assert cursor is here;-2.292069;5.051824;-2.4474757;4.044276;-2.4524353;-4.8488464;CODE
overwrite blinking event because too long delay;-4.0464945;1.9614266;1.2162882;2.1265602;-2.5004504;2.1099129;TASK
from kwargs cursor blink true;-4.6715436;-1.1603742;0.2139988;0.4852324;-4.0169344;0.7791798;IRRE
set whether to blink check if resets;-3.727998;3.6637454;1.8330587;3.7140136;-1.1705629;-0.6497596;IRRE
no blinking cursor visible;-4.634574;0.84135276;1.0216224;-1.0234289;-3.7806168;0.70112115;-
cursor position col and row should not be;-1.6141672;2.3513243;0.42112863;-3.6316528;-4.23233;-0.15564336;-
changed by ctrl cursor down and ctrl cursor up;-4.865387;-1.1315556;1.9916111;-0.7097486;-2.9230633;2.1500325;CODE
textinput on touch down was checking the possibility to scroll up;-3.9149518;-0.39423302;2.8239105;1.539371;-4.383806;0.86863047;CODE
using the positions of the rendered lines rects these positions;-1.214334;1.1552551;5.7483454;-4.1124945;-1.5596689;2.0627995;CODE
don t change when the lines are skipped e g during fast scroll;-2.814555;2.2202096;2.4703908;0.5108923;-2.7461197;3.2617743;CODE
or ctrl cursor home which lead to scroll freeze;-4.528811;-1.0113373;2.9938085;-0.22870156;-4.315242;3.318149;-
move viewport to the first line;-5.0958548;1.1580989;4.7825966;-2.385129;-2.4523036;3.7209096;-
slowly scroll to the last line to render all lines at least once;-2.1817696;1.5200753;4.513077;0.0048643085;-2.3330245;2.3916137;CODE
little overscroll is important for detection;1.2005587;-0.5407352;1.5775694;1.0828737;-2.5625074;1.9005537;CODE
lines scrolled at once will follow the lines to scroll property;-2.9210618;0.73695904;2.942079;0.60679513;-2.6080396;3.7412603;-
jump to the first line again;-3.9901881;2.6252658;5.439746;0.55156535;-1.2704583;-2.6853943;-
temp fix only change of cursor position triggers update as for now;-3.0525448;1.0710039;-0.6977065;0.26007736;-4.9804916;2.241404;CODE
scrolling up should work now;-5.7632637;-0.43002045;3.7116573;-1.4703286;-4.8760715;3.0941339;-
select all;-0.6335845;1.0912315;4.8431444;-0.34978458;3.4147277;-2.4031782;CODE
win dispatch event name key scancode kstr modifiers;-3.7524345;-1.7848498;-2.646355;-0.30113542;2.787153;2.0138755;-
copy;-3.5731924;-2.9976223;3.4671576;0.10231948;-0.22375208;-1.8696725;-
home;-2.3549318;-1.9512153;5.574404;0.3565258;-0.6824297;-2.8162801;-
paste;-3.004248;-2.1417015;5.7386503;-0.2993468;-0.120636545;-2.7975314;-
create textinput instance with dummy contents;-2.591589;1.1122936;0.32795745;2.5330544;1.0019335;-0.20861304;IRRE
use container to have flexible textinput size;-0.64717996;0.8504174;1.7191604;-0.63581043;-0.77324;3.669323;CODE
change textinput s size to contain the needed amount of lines;-0.5696498;1.7742841;2.2353375;-2.026924;-1.8555045;0.39689964;CODE
in case the root widget is scrollview this cushion is needed;-3.7489512;-2.1577246;2.523748;-1.1040686;-3.0319407;5.105638;CODE
because scrollview s direct child is always at pos 0 0;-4.9504657;1.4122161;0.36212552;-0.8264115;-3.4714527;3.6385932;-
test label attribute inside button;-1.6583434;3.3811038;1.3880877;2.2266843;0.80074304;-1.234401;META
we should have 2 progress minimum and one success;-0.08216882;1.6858256;4.0334167;4.350438;0.7941782;-0.94141495;CODE
ref 2983 5568;-4.043188;0.07671521;0.40355453;-1.4212805;0.9592725;-2.483711;-
300 0 sometimes is 299 9 or 300 1 however;-0.51174545;2.2117922;-1.662995;-2.2438061;-0.040072814;-3.7856085;-
we just want to know that it s really close;-1.3248805;-1.4108655;3.4628294;1.5285753;-1.8951943;-1.2235824;CODE
fix issue https github com kivy kivy issues 2275;-5.786096;-2.3929343;-1.5858634;-0.26565847;-5.6639557;-0.42913127;CODE
attributeerror nonetype object has no attribute texture;-3.178105;1.0375718;-5.0864344;-1.5614408;-4.6515775;-0.18631448;META
none of them should work;-4.342711;0.14255714;-0.77198404;-0.00436407;0.32730687;0.23023601;-
currently rejected with a shader didn t link but work alone;-4.867889;-1.1851038;-1.9745033;1.1388747;-2.180994;1.6743928;META
rotated rotate tree i shift list to start at i;-1.6229292;0.54459774;2.4882448;-2.2753534;-0.15891343;1.3985956;-
walk starting with i;-2.4297268;-0.0795232;4.167699;-0.3617834;0.48444816;-1.1611298;-
comparison should be performed with unrotated size;3.197768;5.295975;0.94687766;1.1604155;-0.1878977;-0.7569823;CODE
as it also takes into account the window density;1.0001725;-0.59386075;2.4097285;0.077947676;-1.7051319;4.3889947;CODE
this is automatically set by the window provider but we can;-5.833426;-2.1305385;3.7633126;0.22029087;-1.6118883;7.082922;IRRE
force it manually for this specific test;-1.9759591;6.583482;-1.7658418;6.7436986;-1.8150772;-4.0854025;CODE
test that setting the size property to 100 100;2.3164675;6.0496917;0.7369401;2.7138362;-0.59121054;-2.7761078;IRRE
sets the system size to 100 100 when the window is not rotated;-1.6849514;2.2646797;1.5193713;-0.977848;-3.1504683;4.134415;CODE
and the density is 1 0;-0.50979424;1.0069196;0.52674264;-3.5048285;-2.8138382;0.08513598;-
test that setting the size property to 100 50 sets the system size;2.7856863;4.9484367;-0.2603407;2.2834806;-0.57408696;-1.2436421;IRRE
to 50 100 when the window is rotated 90 degrees and the density is;-0.5659763;0.72030234;3.0881052;-1.7644299;-2.8204815;1.057705;CODE
1 0;-1.5624485;2.4980729;3.5201719;-3.0049706;-0.9159242;-4.838919;-
test that setting the size property to 200 100 sets the system size;2.9568217;4.7684007;-0.4413935;2.7161794;-0.52511424;-1.302112;IRRE
to 100 50 when the window is unrotated and the density is 2 0;-1.3559129;1.1652832;2.025293;-1.5343912;-3.321942;0.80207556;CODE
test that setting the size property to 100 200 sets the system size;2.9008796;4.7837386;-0.5792415;2.757864;-0.49770007;-1.2178885;IRRE
to 100 50 when the window is rotated 90 degrees and the density is;-0.71715796;0.6819791;2.904884;-1.7759401;-2.7866504;1.1800902;CODE
2 0;-2.4647024;1.3693689;3.5659375;-2.3757374;0.02254102;-4.771006;-
the native handle is implemented on all the known;-5.820753;-4.7928967;1.3758844;0.77614343;0.6076875;3.1963704;TASK
supported platforms if it is not implemented we likely do;-3.6320221;-5.953844;-1.0354462;1.5517311;-1.7198501;1.8235172;CODE
not have a windowinfo implementation and returns none;-5.597414;2.7378662;-1.0771922;0.93782246;-2.1830103;0.27779722;TASK
even if we have a windowinfo implementation and therefore;-3.4164722;-1.8825939;1.1092461;3.176332;0.08940766;2.8686233;TASK
is not none if returns 0 it means something is wrong;-3.0965354;6.490722;-2.2891266;-1.9121441;-2.3347952;-6.5208097;IRRE
skip the test if the system returns unknown;0.2805303;7.354784;-1.8553258;6.928695;-1.8020269;-5.0547805;IRRE
we expect a valid theme either light or dark;-3.5262377;-1.4073454;1.4079251;3.13932;-0.80751777;-0.27018338;-
import tlp visual test label layout perf;-1.1868224;-0.6515114;-3.2162466;-2.1908474;-0.4621196;0.3418576;CODE
import tlrp visual test label layout real perf;-0.9707906;-0.24666615;-3.878226;-2.4023097;-0.8383248;0.99097204;CODE
if in words i or n in words i skip spaces;-1.9132441;2.037738;1.4312906;-1.0348028;1.3674458;-3.7061787;-
tick for texture creation;-1.0202395;-1.3395348;4.2609572;-3.0371995;-0.37353548;1.7459835;CODE
tick for texture creation;-1.0202395;-1.3395348;4.2609572;-3.0371995;-0.37353548;1.7459835;CODE
clean cache to prevent weird case;-3.5894578;4.0725694;0.37864745;1.68527;0.5424873;1.2409011;TASK
force gc before next test;-0.16815789;4.173053;-1.1635224;6.468375;-1.2262607;-0.8942876;CODE
print f found no component label for n;-2.228538;2.3970318;-1.9343716;-4.904363;0.54185694;-3.7274065;CODE
print f found more than one component label for n;0.74507874;2.3037856;-0.09450374;-5.4550576;3.0325918;-2.8321543;CODE
don t actually execute anything;-5.6221895;2.0592234;0.19670129;4.212094;-0.73138;-2.4341424;CODE
from os path import join as slash just like that name better;-4.2301006;-2.5335448;-1.9933747;-1.7279972;-1.190847;-0.75405705;CODE
from here to the kivy top;-1.7629308;-3.467893;5.827505;-0.50381064;-3.0084145;0.58837557;CODE
image dir images examples relative to generation dir;-1.5064765;-2.285188;1.5336145;-1.3008771;0.90599567;2.4876437;-
info is a dict built up from;-2.8475082;-4.648255;0.5609642;-1.0129378;2.1281276;-3.7001238;CODE
straight filename information more from reading the docstring;-3.0886598;-2.077647;0.103123136;-0.73364127;1.6216402;-0.91094893;CODE
and more from parsing the description text errors are often;-2.6798992;-1.1651742;-2.6939147;3.1756191;0.76439947;-0.45788202;CODE
shown by setting the key error with the value being the error message;-5.178797;3.8277667;-0.78345865;-0.261289;-1.3188452;-1.2982553;IRRE
it doesn t quite meet the requirements for a class but is a vocabulary;-0.63840747;-5.294495;0.44161212;2.743789;4.0377283;-1.2765468;CODE
word in this module;-6.012295;-1.347153;2.9268634;-0.624763;2.378541;-1.729774;CODE
continue don t want to show ugly entries;-3.5380976;3.0554924;3.8030164;-0.034263052;-0.2949722;0.84801936;CODE
make text a set of long lines one per paragraph;-1.1325946;-0.26031637;3.849087;-1.3606406;0.59011984;-0.46012604;IRRE
add links where the files are referenced;-2.8343933;-2.8209136;2.4659896;0.13251095;0.37925482;3.2875373;TASK
now break up text into array of paragraphs each an array of lines;-0.5691216;-0.12756269;3.391501;-1.5979872;-0.6603166;-1.2122788;CODE
ignore wrapping if note or similar block;-2.6833653;5.068544;0.11219549;2.6584215;-0.0036607042;0.30935085;TASK
include images;-2.4022083;-2.8754172;4.978451;-0.6216705;0.4368511;2.2831023;CODE
double separator if building on windows sphinx skips backslash;-6.910603;0.17316645;-3.6073148;0.058001343;0.13741246;1.4488794;CODE
else code;-4.441368;2.004988;3.8591807;-0.16988531;2.7281425;-4.983001;-
prevent highlight errors with none;-3.1848402;5.0629706;-2.3989024;2.4732714;-0.8739008;-0.7443529;-
make sure all the directories has been created before;-4.683955;-1.1471028;-0.6010227;1.5941187;-1.7868954;-0.8148036;IRRE
trying to write to the file;-5.9084005;-0.08144464;1.8955435;-1.8348078;-4.169624;-3.5004234;CODE
ios 7;-2.6834216;-3.0651853;4.4399767;0.34732565;-1.518859;0.098283485;-
ios 6 1 and earlier;-3.5045183;-1.2845881;1.0736436;0.36673737;-1.7749447;1.0324756;-
itunes artwork ad hoc;-2.6487362;-3.7741387;2.785727;-1.827326;0.5110894;3.655736;-
ensure the destination directory will be set;-3.8264935;1.9474757;0.59904355;1.8276204;-3.1306274;1.7128402;IRRE
read the source image and do some quality checks;-0.51204485;-0.26995376;-0.028347647;-1.0250529;-2.8724172;-0.07337226;CODE
a define directive to redirect to that symbol from the symbol name without;-5.6342726;1.826218;0.7161495;0.43804753;1.9386575;3.1413717;CODE
if line startswith define;-2.5644038;5.041843;1.3850387;1.4466475;1.0836596;-2.7090883;CODE
there is no double type in gles functions that were using;-3.2230299;-0.58141965;-4.000949;-2.7529688;-1.3368698;0.296348;CODE
a double were renamed with the suffix f;-3.6958387;0.22217211;-0.0050152005;-1.4540293;0.40399286;-1.2795316;CODE
print define s s symbol1 symbol2;-2.3302774;1.7940751;-0.25267553;-5.489651;1.8888798;-2.6840725;CODE
see explanation about doubles on gles above;-0.98976624;0.5560817;0.32629126;-2.6198387;0.15450504;-1.0230597;CODE
print define s s symbol1 symbol2;-2.3302774;1.7940751;-0.25267553;-5.489651;1.8888798;-2.6840725;CODE
generate;-1.1600518;-1.0482955;4.000058;-2.2357519;2.6078572;-5.441951;-
pipe to kivy kivy graphics common subset h;-0.6827301;-1.0934397;2.1193185;-2.458626;-1.1537406;2.8701944;IRRE
print pragma once;-3.0023258;1.385173;2.513551;-0.48160988;0.17313603;-1.5580469;CODE
print include gl2platform h;-3.5472095;0.32366338;-1.4680989;-3.8968952;-0.18096027;0.9618161;CODE
print ifdef cplusplus;-3.695697;1.4905404;-1.990821;-1.5799052;-0.7883115;-3.3714812;CODE
print endif;-2.6684391;1.4176648;2.242086;-4.0725465;-0.8850042;-3.3103242;CODE
don t add the same symbol more than once;-3.2546778;3.363684;1.7970823;-1.9739282;2.8286593;-0.4942422;TASK
define gl shader binary formats 0x8df8;-3.6555216;-0.70291036;-4.9456897;-6.1909165;1.4030973;1.7535057;CODE
define gl rgb565 0x8d62;-4.108405;0.31021348;-2.3067105;-5.8853207;2.7680845;1.7964617;CODE
print ifdef cplusplus;-3.695697;1.4905404;-1.990821;-1.5799052;-0.7883115;-3.3714812;CODE
print endif;-2.6684391;1.4176648;2.242086;-4.0725465;-0.8850042;-3.3103242;CODE
usr bin env python;-4.4434023;-3.2804286;-2.2293885;-2.92909;-3.937616;-3.571847;CODE
ruff noqa;-2.4534037;1.1729168;2.287785;-1.8612963;0.97860295;-0.51314807;-
test suite configuration key is test name values are;-3.1422875;2.5838945;-2.1555574;0.7139191;0.17961004;-1.9841292;IRRE
alpha global alpha used for all pixels except t;-1.6490088;1.3999448;-0.91126317;-2.885033;-3.1471336;2.272504;CODE
patterns allowed v0 pattern characters force include and exclude;-3.5935276;2.4322467;-4.37634;0.10737598;2.3182983;0.7396045;CODE
image gimp layer types to export for this test w target extensions;-1.0635636;0.57941335;-1.5511068;0.6614664;-1.7244109;1.2981416;CODE
kivy image test protocol v0 data key is pattern char value is pixel w o a;-2.3208163;0.157048;-2.290582;-1.9864088;-2.3559737;-0.49750495;IRRE
kivy image test protocol v0 return pixel data for given pattern char;-0.25558212;0.6282215;-1.8037413;-0.82881564;-2.4684265;-0.5407994;CODE
kivy image test protocol v0 filename;-3.7093215;-1.0436578;-1.3092998;1.0088398;-3.2204669;-0.062145516;IRRE
saves an image to one or more files we can t specify these details when;-1.7604127;-0.2215442;2.0435073;-0.4004258;1.5322647;2.431038;CODE
saving by extension this declaration is pep8 compliant s all good;-5.170925;-1.2112727;-3.6449041;2.2306151;2.9193103;0.26371977;CODE
fixme last argument to file tga save is undocumented not sure what;-6.8908195;1.0383685;-2.2102244;1.4066705;-2.5896904;0.59802943;CODE
interlaced bkgd block gama block;-2.0378525;2.2706723;-1.0234604;-2.7473092;0.55766505;2.789631;CODE
draw pattern on layer helper for make images below;-1.2846013;-0.6151813;6.1663103;-2.6707377;-1.6523812;3.3087993;CODE
create an image from the given pattern with the specified layertype in;0.49672288;0.33039933;3.3369944;-2.8778238;1.177183;2.7548351;IRRE
draw the pattern with given alpha and save to the given extensions gimp;0.36304227;-0.6933165;3.5453827;-3.1092477;-1.812758;0.53603923;CODE
adjust the encoder accordingly;0.0687978;1.633107;-0.100935645;-3.37924;0.040458817;3.8334813;-
cheat for indexed formats draw in rgb a and let gimp make palette;-0.7905307;-0.9929334;-0.42001492;-2.9127493;-1.3059763;1.5108856;CODE
indexed layer types are drawn in rgb rgba and converted later;-0.9836477;1.1400698;-1.8620788;-2.8397346;-1.6457602;3.3585768;-
we need to supply pixels of the format of the layer;-0.09306826;-0.5017745;1.7448713;-6.9626527;-0.34274504;3.498577;TASK
pick the correct layer type for indexed formats;-0.396216;-0.14517339;-2.75598;-1.7722796;2.342739;2.1319098;CODE
draw pattern nx1 and 1xn variations;2.224988;1.6503818;3.0609684;-6.8607826;0.9566263;0.9441597;CODE
create the gimp image and the layer we will draw on;-2.5163276;-2.4648197;6.075485;-3.0673666;-3.1363552;1.9098791;IRRE
add alpha layer if we are planning on encoding alpha information;-0.7716052;-1.9724314;1.0679656;-1.793486;1.5965779;2.5199025;TASK
draw it;-2.3900344;-0.44236767;7.797874;-2.5310936;-1.3946916;-3.6822872;-
convert to indexed before saving if needed;1.2164663;3.4647982;-0.53346723;0.03429601;1.140085;0.78684306;CODE
save each individual extension;-1.0589507;-0.09803348;2.5540092;0.8091734;3.5316172;3.1776686;CODE
fixme this fails;-6.462873;0.9270292;0.622434;2.5473669;-3.218393;-0.9100096;CODE
pdb gimp image delete img;-2.6905909;1.3761724;-0.29780218;-2.338215;-3.554386;1.5640236;CODE
fixme pattern generation needs thought this sucks;-2.7352583;0.31569305;0.17780927;1.5768704;1.5437882;-0.32191527;TASK
usr bin env python;-4.4434023;-3.2804286;-2.2293885;-2.92909;-3.937616;-3.571847;CODE
ref https github com cython cython issues 1968;-5.972644;-0.7453617;-2.2212594;-1.1586696;-3.5736187;-0.6634548;CODE
ensure we don t have any thing like doc running;-4.549486;-1.6465778;0.5874948;5.3870263;-0.65409034;-0.19134526;CODE
check ignore list first;-0.46246105;6.780627;0.9116526;4.0983267;0.05756614;-2.6199098;-
print ignored ignore list;-1.3137163;4.2503867;-0.52778953;1.7005962;-1.9368764;-1.567219;CODE
special case core providers;-2.7996209;-3.24739;-0.25678432;1.6584531;2.8415835;3.560073;CODE
print ignored not a init py;-4.6531715;1.9120446;-2.2482553;0.31332624;-4.873189;-0.27014348;IRRE
fd write auto generated file by setup py build factory n;-2.965641;-1.5070009;-2.276601;-0.18634537;-2.165394;1.1806146;TASK
https pythonhosted org pyinstaller hook global variables e g;-4.6503596;-1.6137271;-2.50405;0.5152822;-4.3993835;0.77737355;CODE
pyinstaller 6;-3.8804104;-4.242957;-0.29737875;-2.2581582;-2.6163602;-1.7327297;-
pyinstaller 6;-3.8804104;-4.242957;-0.29737875;-2.2581582;-2.6163602;-1.7327297;-
for mod name in core mods process remaining default modules;-4.452303;-0.8493919;-0.51513976;0.9354469;0.5617546;3.5950677;CODE
if hasattr m mod name capitalize e g video video;-3.211812;1.0546935;1.831253;-1.2168885;1.720764;0.042621747;CODE
hiddenimports get deps all hiddenimports;-4.5234513;0.8443179;-2.6605673;0.7922194;0.4812062;2.9632628;CODE
usr bin env python;-4.4434032;-3.2804277;-2.2293892;-2.929091;-3.9376152;-3.5718482;CODE
pycodestyle py check python source code formatting according to pep 8;-4.0009727;-1.0296804;-5.027607;-1.0041404;-2.3776126;-1.8233919;CODE
copyright c 2006 2009 johann c rocholl johann rocholl net;-3.5219646;-2.397475;0.75715107;-2.1809535;2.576267;-1.3911697;-
copyright c 2009 2014 florent xicluna florent xicluna gmail com;-5.4658265;-2.0888617;1.5452411;0.21307935;0.50623655;-1.6249175;-
copyright c 2014 2016 ian lee ianlee1521 gmail com;-5.2197485;-3.5857139;0.6870127;-0.5564623;0.38831297;-2.295316;-
permission is hereby granted free of charge to any person;-5.3292656;-2.5892837;1.737111;-1.5058918;0.46368358;-0.3940294;CODE
obtaining a copy of this software and associated documentation files;-4.9878516;-7.510509;-0.1627762;-0.11070758;1.4031988;-0.51883227;CODE
the software to deal in the software without restriction;-2.7924497;-4.6995335;1.4181554;2.6397738;2.907182;-0.3823139;CODE
including without limitation the rights to use copy modify merge;-3.780742;0.7103482;-0.9100818;1.1599157;1.6893864;3.1161537;-
publish distribute sublicense and or sell copies of the software;-3.349171;-3.3605754;0.3559343;-0.42936292;1.8497145;1.3326174;META
and to permit persons to whom the software is furnished to do so;-4.89964;-5.7224164;1.307808;0.99686044;3.8312829;0.84891456;TASK
subject to the following conditions;-2.0042007;3.3280876;3.7246943;-0.50035596;4.5974727;-1.8110567;-
the above copyright notice and this permission notice shall be;-7.542624;-3.628741;1.4359803;-0.74147344;0.99463004;0.5551125;CODE
included in all copies or substantial portions of the software;-2.6716125;-6.619176;0.77121603;2.062474;3.2346141;-1.2891859;CODE
the software is provided as is without warranty of any kind;-3.1757393;-4.016807;-1.3546865;1.6068882;0.11811706;0.48549414;-
express or implied including but not limited to the warranties of;-2.2748125;2.2144434;0.332426;2.7176142;4.6693463;0.08755861;META
merchantability fitness for a particular purpose and;-0.73582983;-0.91335934;0.68275684;1.903387;4.2985797;1.1239542;CODE
noninfringement in no event shall the authors or copyright holders;-4.5886564;-0.3971049;-1.3884681;1.8029743;1.0399625;0.66626966;OUTD
be liable for any claim damages or other liability whether in an;-2.7623734;1.6895524;-1.1391125;1.9350711;2.170359;-1.3723342;CODE
action of contract tort or otherwise arising from out of or in;-4.6426115;3.017586;2.2457843;2.3043268;2.4549754;1.8379737;CODE
connection with the software or the use or other dealings in the;-3.8799996;-7.421963;3.6812747;2.1153796;0.82131094;-1.6395377;CODE
software;-1.6231102;-7.44677;5.0367627;1.8323617;1.6376363;-4.1100783;-
errortoken is triggered by backticks in python 3;-3.7045367;2.295838;-4.7245426;-0.3094736;-3.6156695;-0.58876216;CODE
work around python 2 6 behavior which does not generate nl after;-1.834019;0.35370162;-5.9627476;0.39364374;-2.0208511;-0.9679731;CODE
a comment which is on a line by itself;-5.1389904;0.78179497;2.8833196;1.1468885;-0.122453116;-1.9409992;CODE
comment with nl tokenize generate tokens n pop send none 1 n;-2.3874433;0.88871986;-0.8153937;0.0510809;0.064891525;-1.2978903;CODE
plugins check functions for physical lines;-1.8498586;2.8824089;0.27167308;1.1896595;-1.1516805;0.29904538;CODE
physical line physical line rstrip n chr 10 newline;-1.8177478;1.6465108;1.7215797;-5.1145387;-0.9126088;-0.817626;IRRE
physical line physical line rstrip r chr 13 carriage return;-3.0205414;2.3643255;-0.007325119;-3.1572027;-1.7232769;-0.8394011;IRRE
physical line physical line rstrip x0c chr 12 form feed l;-3.0398932;1.0728902;0.9954465;-4.3658566;-0.41200352;1.1407653;IRRE
special case for long urls in multi line docstrings or comments;-4.0155435;-0.90444773;0.5777934;0.66171527;2.8992531;0.79748136;CODE
but still report the error when the 72 first chars are whitespaces;-3.9674842;3.3269358;-2.8914156;-1.6658889;-1.486609;-4.3287687;TASK
len chunks 2 and chunks 0 and;0.2729113;1.2116596;1.1895531;-5.269402;0.35343114;-4.5306125;-
if hasattr line decode python 2;-1.7391397;3.4973233;-3.078456;-2.428875;-2.6070113;-4.1078844;CODE
the line could contain multi byte characters;-4.386006;0.56610936;-0.055346258;-4.5339637;-0.1451858;-3.2859151;CODE
plugins check functions for logical lines;-2.3578157;3.8920758;-1.048972;1.1887721;1.0508454;-2.6355329;CODE
return don t expect blank lines before the first line;-2.189308;5.7973866;-0.15846536;-0.49655864;-2.0404217;-3.279622;CODE
search backwards for a def ancestor or tree root top level;-0.94542825;-0.31055793;-0.49891144;-0.012005863;1.5101084;-0.35191128;CODE
assert char in;-1.1164303;5.677919;-2.2317603;3.3989968;1.1002734;-6.27937;CODE
code e202 if char in else e203 if char in;-3.2103019;3.6147342;-0.06817264;-1.687798;2.4904733;-5.952578;CODE
continue slice syntax no space required;-3.4200943;3.2692344;0.740128;-1.5027938;-1.5187232;-0.63667357;CODE
continue allow tuple with only one element 3;-3.2166073;5.2910724;1.3957646;-2.1211;2.2897;-2.6682634;CODE
indent next tells us whether the next block is indented assuming;-3.1755807;3.2763722;0.7107925;0.6313544;1.1525768;-2.9362652;-
that it is indented by 4 spaces then we should not allow 4 space;-4.948819;1.4693513;0.08909761;-2.9065695;1.8707503;-0.022381797;-
indents on the final continuation line in turn some other;-6.0399895;3.1423163;2.9494987;-1.642311;1.2681273;-0.39644504;CODE
indents are allowed to have an extra 4 spaces;-4.407498;1.5997908;1.2806109;-2.8807964;2.6802523;-0.44715118;-
remember how many brackets were opened on each line;-2.1127985;1.9081297;3.7531765;-1.8322556;2.297517;-3.9928534;CODE
relative indents of physical lines;-0.7166262;0.5984896;2.743876;-4.317392;-0.12624818;2.2621105;IRRE
for each depth collect a list of opening rows;3.0427275;0.76456636;4.6935287;-4.535961;2.102074;-1.0300634;CODE
for each depth memorize the hanging indentation;-0.2436887;-2.5297222;3.5082352;-0.8752918;2.260544;-1.4447492;CODE
visual indents;-3.2138438;-1.4671142;4.482066;-3.718195;1.1974356;1.0774814;-
for each depth memorize the visual indent column;1.3397417;-3.2617655;2.736527;-3.9890294;2.093473;0.58618724;CODE
this is the beginning of a continuation line;-5.1796546;1.6957321;5.4875755;0.9473701;-0.2515043;0.07323766;CODE
record the initial indent;-2.6923335;2.6386342;2.3459532;-0.53921473;2.6307843;-1.2179385;IRRE
identify closing bracket;-4.292806;1.049996;1.2352597;-2.0731304;2.6511483;-1.079008;-
is the indent relative to an opening bracket line;-4.105052;0.6492223;0.7279003;-1.5473415;1.5118335;0.2167216;CODE
is there any chance of visual indent;-2.83936;0.17848621;3.3231819;-0.036071297;1.1663072;1.3217454;-
closing bracket for visual indent;-4.9835167;0.878502;1.5110738;-1.1987938;1.2795908;1.2542946;CODE
closing bracket matches indentation of opening bracket s line;-3.541189;2.1363165;-0.46846342;-0.9802515;1.2912776;-0.568527;CODE
visual indent is broken;-5.4553328;1.128451;0.08787284;-1.0174565;-2.1182032;0.8451337;-
hanging indent is verified;-3.7186964;3.2388587;-0.82458395;1.5823041;-0.29130277;-2.2492335;-
visual indent is verified;-4.0760126;1.7709975;-0.8222874;-0.51638913;0.5536016;-0.49329904;-
ignore token lined up with matching one from a previous line;-1.4494257;5.049662;0.4568979;0.40299788;0.8322501;-1.6574175;CODE
indent is broken;-4.755653;1.1789683;0.30702192;-0.2390603;-1.0734742;-1.6644005;-
look for visual indenting;-3.3285854;-1.0023724;2.6012392;-3.3803382;1.6396427;-0.3349125;CODE
deal with implicit string concatenation;-2.1145518;3.1741097;0.51053596;-1.195663;1.2650737;-1.5239191;CODE
special case for the if statement because len if 4;-1.6512058;4.783304;1.9008527;-1.209788;1.815021;-5.9235377;CODE
keep track of bracket depth;1.0424478;0.8364442;1.3121244;-0.30555087;2.9351192;0.8732567;-
parent indents should not be more than this one;-4.548764;2.9162312;1.5768496;-2.0680373;2.1930804;-0.5549501;CODE
allow lining up tokens;-5.0071554;-0.09740829;0.24627247;0.4940519;2.1660922;0.6099639;-
syntax class a b is allowed but avoid it;-4.3296585;1.846583;-2.6488392;1.2068697;4.4298472;-1.4601477;CODE
allow return a foo for a in range 5;-1.2366918;5.6239533;1.1020135;1.3014001;1.8536257;-2.6095836;IRRE
found a probably needed space;-3.0910733;0.145918;2.3120735;-0.4831186;-1.8366838;-1.5091912;-
tolerate the operator even if running python 3;-2.412851;1.9683983;-4.8838897;1.2608107;-2.9581082;-1.424857;CODE
deal with python 3 s annotated return value;-0.33406535;1.5864584;-3.3983462;0.37807536;-0.91844755;-3.302448;CODE
a needed trailing space was not found;-4.1183634;2.7826402;-1.1602224;-2.5102859;-2.222612;-1.2021021;-
allow keyword args or defaults foo bar none;-5.3899055;2.1418993;-2.7153072;2.1409395;1.0174321;2.0047913;IRRE
check if the operator is being used as a binary operator;-1.7100801;4.331164;-3.6989481;-1.1288278;2.1521122;-2.983624;IRRE
allow unary operators 123 x 1;-3.6635;5.181627;-2.2610662;-2.9699297;2.430937;-2.191251;-
allow argument unpacking foo args kwargs;-3.7524526;1.5517943;-2.4577734;2.0933182;-0.27482286;1.1379107;IRRE
surrounding space is optional but ensure that;-3.2699287;3.727948;1.1555434;0.9390131;1.2056143;3.6855998;META
trailing space matches opening space;-2.2806895;2.2242756;0.5616749;-2.037344;0.63194764;-1.0899681;CODE
a needed opening space was not found;-5.3302794;0.96035475;-0.5618111;-1.6382433;-2.4399893;-0.5253186;CODE
bad prefix symbol not in and symbol lstrip 1 or;-5.325839;2.6576352;-2.8900013;-2.4892364;0.09332476;-1.4185275;-
yield start e262 inline comment should start with;-5.908201;0.82520264;-0.8632775;1.3446227;-0.29878977;-1.2834498;-
if bad prefix;-2.5461104;3.9287663;0.9189088;2.9192173;1.5513792;-3.2934983;-
yield start e265 block comment should start with;-5.9053774;0.8588276;-0.024102038;1.4633068;-0.4717325;-1.6324489;-
yield start e266 too many leading for block comment;-4.0185256;2.1904848;-1.0423626;0.63225615;-1.1419973;-1.7348326;CODE
if indent level allow imports in conditional statements or functions;-2.80164;3.3620121;-2.5149834;1.2261534;3.1478088;-1.2793376;CODE
if not logical line allow empty lines or comments;-3.814776;4.8422627;-0.3407315;-0.052357193;0.23429337;-2.8173637;IRRE
allow try except else finally keywords intermixed with imports in;-3.4243114;3.4642656;-3.5978565;3.3423948;0.757392;-0.34929714;CODE
order to support conditional importing;-0.45400727;1.2065821;-1.3688473;3.2295635;3.5374706;0.73103917;CODE
the first literal is a docstring allow it otherwise report error;-8.019936;2.0290217;-4.7129984;1.6740553;1.2478886;-3.024981;CODE
if counts counts and a 1 dict;0.18756706;2.878847;1.2697204;-1.4024365;0.85385543;-7.3645005;-
counts counts and 1 2 slice;1.1986523;1.6569399;3.4608877;-2.7120857;1.0711902;-5.1513124;-
counts counts annotation;1.8385427;-0.6934072;1.0733434;-0.11362749;2.133461;-2.9364204;-
the character is strictly speaking a binary operator but the;-3.5510406;-0.17365806;-1.4745764;-4.4126496;2.8717802;-2.8019893;META
common usage seems to be to put it next to the format parameters;-3.1163778;-0.73881334;-1.189303;-1.864379;2.6767375;1.8874494;IRRE
after a line break;-3.3334568;1.9068996;4.8607545;2.0172806;-0.9231972;-3.0234318;CODE
previous non newline token types and text;-3.2651014;0.0585231;-0.39611802;-0.8683218;1.8906438;-0.74929595;CODE
return allow comparison for types which are not obvious;1.7843959;6.422693;-1.9988319;3.473177;2.7315352;-3.7666655;CODE
identifiers on the lhs of an assignment operator;-1.010649;0.56059223;-1.7666224;-1.732072;6.6634455;-0.79295313;IRRE
identifiers bound to a value with as global or nonlocal;2.198277;2.42393;-2.2113402;-1.6379901;4.79589;1.2926526;IRRE
helper functions;-2.2546968;-0.75392056;3.996788;0.25188038;0.45613816;-2.1225598;CODE
python 2 implicit encoding;-0.7167926;-0.95919144;-3.453095;-4.79221;-1.9425074;-1.7146741;CODE
fall back if file encoding is improperly declared;-3.4214847;3.763065;-5.7171335;0.38879713;-0.3571699;-0.57697225;-
the physical line contains only this token;-4.4966674;1.6331465;-0.3812952;-2.8862333;0.14572209;-0.28469318;IRRE
the comment also ends a physical line;-4.536619;-0.04641338;2.8445275;-0.21801582;-2.0013216;-0.25716445;IRRE
don t care about expected errors or warnings;-2.898515;1.2875136;-1.3518386;5.466802;-1.1173576;-2.367301;CODE
pycodestyle section pep8 deprecated;-6.4213176;-2.7835033;-4.6169477;-1.9098052;-2.3851497;1.233533;OUTD
first read the default values;-2.4211094;1.9263217;1.2638505;-1.4599653;-0.2356138;-0.67630184;IRRE
second parse the configuration;-2.574374;1.9706714;1.6302109;-1.5247619;3.5162783;0.736745;IRRE
third overwrite with the command line options;-6.1115627;1.9384204;-0.2003922;0.6687029;-0.2568378;1.999663;CODE
don t read the command line if the module is used as a library;-5.814314;-0.7305204;-3.1975205;1.33636;-2.502704;1.4483234;CODE
if parse argv is true and arglist is none arguments are;-1.5118554;3.5862167;-2.9855878;1.368894;-0.044167038;-1.9613594;IRRE
parsed from the command line sys argv;-3.3758771;-0.042725492;-1.7256829;-1.4470278;-1.3689625;-0.50164807;CODE
e125 continuation line does not;-5.6217184;2.3859584;-0.3780923;-0.78057426;-1.5518976;0.1506411;CODE
distinguish itself from next logical line;-1.0493066;4.721658;2.3442688;-0.6570814;3.5828454;-4.5559373;CODE
e126 continuation line over indented for hanging indent;-4.31785;1.3894882;0.18196404;-0.90536827;0.6111076;0.27912652;CODE
e127 continuation line over indented for visual indent;-4.009266;0.69717085;0.23446333;-2.0516744;0.57001615;1.4043034;CODE
e128 continuation line under indented for visual indent;-4.872725;0.7603679;0.03483271;-2.659834;0.43254092;1.3435658;CODE
e402 module level import not at top of file;-4.636733;0.106817044;-2.583472;-0.875254;-2.1625717;2.4474344;CODE
e741 ambiguous variable name;-3.3729794;2.1861799;-2.9448416;-1.3689848;1.4400055;-1.1664556;IRRE
e731 do not assign a lambda expression use a def;-2.1557472;1.102753;-4.1063004;0.1547379;-0.7932157;-0.8160019;CODE
w503 allow putting binary operators after line split;-2.8093698;2.8237336;-4.2232847;-3.6495886;2.0589716;0.029654041;-
file couldn t be opened so was deleted apparently;-6.3474336;0.07888893;-1.881682;-0.7487912;-3.2658966;-1.088243;CODE
don t check deleted files;-2.2465174;1.5115349;0.94240326;2.1365108;-2.2097535;-0.86974883;CODE
got a single file to check;-4.3808107;1.327128;1.0123975;1.7312253;-1.1565635;-4.482383;CODE
report dict one key value pair for each title;-0.554976;0.16139583;0.2377401;-2.6155884;2.7910826;-3.2262657;CODE
this method sends report to gist different file in a single gist and;-1.6851162;0.44518948;-0.039457876;3.0621371;1.196853;1.261033;CODE
returns the url;-5.256729;1.2201458;4.7928953;1.447595;-1.9611719;-1.6027602;IRRE
start output debugging;-3.1455843;0.34592995;0.9349648;1.0589399;-3.2117321;-2.5531373;IRRE
prints the entire output;-1.1176795;1.3070948;3.2938678;-2.4382534;-1.3013824;-3.7092996;IRRE
on windows system the console leave directly after the end;-5.9755955;1.3822751;4.471664;0.042390194;-2.9018877;1.472743;CODE
of the dump that s not cool if we want get report url;-4.0738807;-2.116827;1.940641;1.590026;-1.0322337;-0.6221386;-
ruff noqa;-2.4534037;1.1729168;2.287785;-1.8612963;0.97860295;-0.51314807;-
cdef void glgetshaderprecisionformat cgl glenum shadertype cgl glenum precisiontype cgl glint range cgl glint precision;-1.7604731;0.020244638;-5.0106773;-3.4411159;-0.5296698;0.18683945;CODE
cdef void glreleaseshadercompiler;-4.831613;-1.2800002;-4.7347245;0.36784598;-0.40697685;0.8019011;CODE
cdef void glshaderbinary cgl glsizei n cgl gluint shaders cgl glenum binaryformat cgl glvoid binary cgl glsizei length;-3.292447;-0.35014486;-4.638669;-5.952425;0.1460279;0.77595186;CODE
this file was automatically generated with kivy tools stub gl debug py;-5.561784;-3.493082;-3.2865;0.15818858;-5.781335;-1.1526645;IRRE
if x startswith;-2.4920588;4.274322;4.1245465;0.9953367;1.2631482;-3.5961637;-
there are some functions that either do not exist or break on osx;-6.430956;-1.3003527;-0.07726396;0.750999;-1.9075986;-2.5761425;CODE
just skip those;-0.48832488;0.34496972;2.3888423;2.2399397;1.235212;-0.04722192;-
print skipping generation of s x;-2.2762196;2.0335443;-2.0122526;-2.5829022;-0.43973592;-1.4828372;CODE
credits sean anderson;-1.9419966;-1.8511264;0.99693507;-0.6142593;0.12427976;-1.2903419;-
1 open the source image and get the dimensions;-0.06851746;-2.0586693;4.3498535;-6.235969;-0.51356566;0.0668658;CODE
2 search the nearest 2;-0.12855059;0.12877908;4.835564;-1.6828505;1.733876;-4.196245;-
3 invoke etc1tool;-5.466593;0.9371266;0.579105;-0.28776604;2.2031343;-1.2124416;-
5 write texture info;-0.41693768;-3.0201952;2.5913508;-4.043377;1.3732343;-0.32661644;TASK
1 open the source image and get the dimensions;-0.06851746;-2.0586693;4.3498535;-6.235969;-0.51356566;0.0668658;CODE
2 search the nearest 2;-0.12855059;0.12877908;4.835564;-1.6828505;1.733876;-4.196245;-
3 for pvr the image must be a square use the bigger size then;-1.5719982;1.3369125;1.5571095;-4.8782396;0.3466157;2.09711;TASK
4 invoke texture tool;-2.5067594;-1.2704946;0.40072805;-1.1046641;-0.5973591;3.1210332;-
5 write texture info;-0.41693768;-3.0201952;2.5913508;-4.043377;1.3732343;-0.32661644;TASK
one container for the title bar;-3.3026817;-0.33222124;5.4788113;-1.745097;1.9379184;2.2125688;IRRE
one container for the content;-2.161679;0.46957418;5.964851;-0.74679285;3.6449425;1.3866109;CODE
real is open independent on public event;-3.3397176;-0.06516572;2.4513009;2.2962933;0.9619727;0.54123825;CODE
create dropdown for the group and save its state to is open;-2.2577314;1.1064283;4.904845;1.301496;0.84031004;2.4111478;CODE
put open close responsibility to the event;-4.9604807;0.4651443;4.3594694;3.7467842;0.7138531;2.554401;CODE
trigger dropdown opening when clicked;-3.244065;-0.016624203;2.46047;1.6173134;-1.1765989;1.8957669;CODE
trigger dropdown closing when an item;-2.698758;1.4719446;2.0535338;2.9455051;-0.33224368;1.6703593;CODE
in the dropdown is clicked;-4.9767;-1.7180243;4.5613217;0.6072503;-1.5490711;0.7308383;CODE
opening only if the dropdown is closed;-3.062906;2.947841;3.126322;3.5237567;-0.27702394;0.9949462;CODE
closing is open manually dismiss manually;-4.8408923;1.8499401;0.4540046;3.130023;-2.9704006;2.4855359;CODE
if container was set incorrectly and or is missing;-3.205632;5.273395;0.21586706;3.3432956;-1.0914478;-1.0279819;IRRE
set dropdown width manually or if not set then widen;-0.0572179;1.4986621;2.2254844;0.042976264;-0.62332904;2.9683218;IRRE
the actiongroup dropdown until the widest child fits;-1.141566;0.045110863;4.5443554;0.66784424;1.3087175;3.5862708;CODE
set the dropdown children s height;-1.6516821;0.86777717;3.722289;-1.4282671;-0.52058494;1.5441021;IRRE
dismiss dropdown manually;-3.6782029;1.7287009;2.2391117;2.9048645;-1.3599644;2.1199288;CODE
auto dismiss applies to touching outside of the dropdown;-4.195;2.4250977;2.2125897;3.7994466;-2.5828588;2.835688;META
if adding actionseparator normal mode;-6.2535887;3.2298067;-0.36163127;0.65409046;0.83741975;3.4152079;TASK
everything visible add it to the parent;-5.7316117;-0.6938377;5.962289;-0.1627086;0.4957116;3.7604523;TASK
normal mode items can fit to the view;-0.9990851;1.2743737;2.498228;-2.0903382;0.48262897;6.4622927;CODE
display overflow and its items if widget s directly added to it;-1.8121814;3.1364346;4.0567126;0.26360303;-1.8923361;2.6275802;TASK
all the items can fit to the view so expand everything;-0.15951586;-0.22441112;5.5935335;-1.2709293;1.2617193;4.962633;CODE
layout all the items in order to pack them per group;0.9261653;-0.47748902;5.8397694;-2.9741952;2.7690403;1.8876019;-
layout the items in order to pack all of them grouped and display;1.1312933;-0.5523978;6.5428333;-3.5647974;2.3518522;1.9953188;-
only the action items having important;-4.5526776;-1.4499085;4.87957;3.1694248;2.2404125;2.9241657;CODE
if space is left then display actionitem inside their;-3.6932657;3.7185843;5.3264093;-0.8656673;0.47415954;1.6593807;CODE
actiongroup;-3.9018023;-2.0488696;5.3818345;1.4577991;1.7197474;1.3116926;-
if space is left then display other actionitems;-2.5923765;3.975577;5.9566183;-0.8508083;1.0990198;1.0712332;CODE
for all the remaining actionitems and actionitems with in;-1.4489644;1.8531516;4.04895;0.13648161;4.3953466;-0.84629023;CODE
actiongroups display them inside overflow group;-3.4376576;1.8370533;2.5401807;0.17222136;-0.25179785;4.3083324;-
determine the layout to use;-1.9645226;-0.6103542;6.1713552;-4.954949;2.8276136;1.4192661;-
can we display all of them;-1.2260851;-1.6099758;6.4617605;-2.9766712;3.4484513;-0.47146595;-
can we display them per group;0.9086187;-0.6908966;5.8182793;-2.4623375;3.6723948;0.4194266;-
ok we can display all the items grouped;-1.1520905;-0.5147502;7.201413;-1.8768483;2.195708;0.004173413;-
none of the solutions worked display them in pack mode;-4.7558613;-0.51401156;-1.8340907;-1.3318264;-1.819454;1.0758758;-
xxx clean the first registration done from main here;-5.2438707;1.8395114;0.425489;-0.22154874;1.4376376;1.7601528;CODE
otherwise kivy uix actionbar actionprevious main actionprevious;-5.1405253;-1.1968147;2.0271454;0.7113026;-1.4263169;4.5509253;IRRE
track touches active vs cancelled;-1.6810157;0.82918024;3.9448779;3.4289193;-1.123523;2.8792448;-
note internal hooks for subclassing;-3.0930848;-2.4986537;-0.9208273;3.7342358;4.0988264;2.9608793;CODE
these methods are called internally before dispatching the corresponding;-2.8608863;-2.0369508;0.14161387;3.2641034;2.912026;4.3240795;CODE
public events they allow subclasses to implement internal state changes;-2.8833976;-3.786774;2.5289228;5.004416;3.928252;2.2953413;CODE
e g togglebuttonbehavior updating its state separately from;-4.2244177;-0.7190786;4.148371;2.862918;1.4734832;4.0943217;META
user facing event handlers maintaining a clean separation between;-4.4533973;0.70029944;3.0747595;4.5353284;0.7386451;3.5825064;CODE
internal logic and external event dispatch;-4.7862124;-0.62269753;2.9261458;4.638472;2.488555;1.9724387;CODE
do not call these directly or bind to them use;-5.6258583;-0.85874426;1.197901;0.47964182;2.3438597;3.0330048;IRRE
on press on release on cancel events instead;-5.766564;-0.03772487;2.723178;3.6007907;-2.4090369;3.3010268;-
let parent handle first;-6.023423;3.3520162;4.929394;1.851281;0.90493405;1.2821847;CODE
ignore scroll events;-3.044978;2.327866;3.1377501;2.807282;-3.3671963;3.7019348;-
only handle touches within bounds;-1.9934914;3.7401872;5.3820143;0.45697913;-1.0353358;1.054648;CODE
prevent double handling;-2.522554;5.663179;0.5272437;3.6254122;0.95877063;0.8959852;CODE
grab touch to track its lifecycle;-2.1811278;-1.9545739;7.037454;3.423362;-1.2980578;1.833223;-
check if this is the first touch before adding;-4.588516;4.2099595;4.6592693;2.0470698;-1.140846;-1.0859367;CODE
only dispatch press event on first touch;-5.3602657;0.28381166;4.2633142;3.745894;-1.2113497;3.9149632;-
we own this touch;-4.260744;-2.2825658;6.344653;1.4559236;-1.4826804;-0.35617512;CODE
cancel if moved outside and cancellation is enabled;-4.76081;3.6496916;2.9010308;1.7482346;-1.8962278;3.154603;CODE
move from active to cancelled;-3.674945;0.8968374;1.6207047;0.7670637;-0.7249715;2.5892544;CODE
dispatch cancel event if this was the last active touch;-5.5540624;1.4128265;5.347907;3.458847;-0.7181201;1.9034611;CODE
let parent handle;-6.5515246;1.8405709;4.621084;1.7280394;0.20984623;1.1243026;CODE
we touched this widget before;-5.172525;-2.7812564;6.375122;0.9277488;-3.3734515;1.3362262;CODE
not our touch;-2.9557228;-0.3691865;6.162023;2.481223;-2.8439672;0.8463273;-
sanity check;-2.0208912;3.6404388;2.9253924;3.8377485;-0.29781756;-4.864077;-
release ownership;-5.117578;-2.9805856;2.4317322;0.5149135;0.9636769;0.42457935;-
remove from active tracking;-1.3578763;1.1417618;2.3534439;0.989685;-0.61554486;5.4474263;CODE
check if this touch was cancelled;-3.9268076;1.876853;3.349291;3.741198;-3.524532;-0.6368942;IRRE
dispatch release if not cancelled and conditions met;-3.5824878;2.0903049;1.1801;4.554859;1.0725181;1.1082393;-
only dispatch release after all touches are released;-5.54665;-0.13939197;4.1496344;4.512312;-0.20245856;4.404078;-
cleanup cancelled touch tracking;-4.433154;0.6718883;1.2781051;2.7390893;-4.310968;3.717551;TASK
anchor none the last anchor node selected e g shift relative node;-3.2024925;1.9732016;3.3369253;-2.3085494;-0.8055112;2.8804903;CODE
the idx may be out of sync;-4.9077616;0.8346097;-0.60539496;-0.543006;-2.3329313;1.3582835;-
anchor idx 0 cache indexes in case list hasn t changed;-2.1950598;3.7163863;-1.0879849;-0.044365633;-0.5672706;3.7802262;CODE
last selected node none the absolute last node selected;-1.901536;2.868537;2.1199517;-0.9906674;-0.1794271;1.1483544;CODE
ctrl down false if it s pressed for e g shift selection;-3.5391247;2.11567;0.7469476;1.5153364;-2.2319057;1.6300094;CODE
holds str used to find node e g if word is typed passed to goto node;-4.0313745;2.1375532;-0.56869185;1.0093898;1.4203951;-1.9135942;OUTD
last key time 0 time since last press for finding whole strs in node;-1.8346238;2.8133633;0.20946023;-1.4375285;-0.48927563;-1.6203444;CODE
key list keys that are already pressed to not press continuously;-2.5099053;0.8671574;2.8604772;1.8193554;-0.26267;-0.27292833;CODE
offset counts cache of counts for faster access;1.6350248;1.0980866;2.1782496;0.84339577;1.3111999;1.5630964;IRRE
if node in self selected nodes and not range select selected;0.6435685;4.2125163;0.5682407;-0.6510948;1.2295866;-0.61990786;CODE
keep anchor only if not multiselect ctrl type selection;-1.5773922;2.0646067;0.6485939;0.679518;0.7749264;3.8482556;CODE
else it s not selected at this point;-4.647141;1.5698409;3.7763984;2.2037208;-0.024374273;1.978227;CODE
if s not in keys don t keep adding while holding down;-3.546734;3.2795413;1.6885377;-0.015372035;-1.1818987;-3.0218308;CODE
doesn t invert indices here;0.39445943;3.763124;-0.46519166;-5.722311;-2.2306905;-1.9813914;CODE
for offset selection we have a anchor and we select everything;-0.6804337;0.21333385;4.4094963;-0.53011197;1.0866654;3.95309;CODE
between anchor and added offset relative to last node;-1.2328408;2.590876;4.6308217;-2.5249498;-1.262735;3.2614813;IRRE
list changed cannot do select across them;-1.6576425;2.7309892;1.1251421;1.1368479;-0.27308127;0.4116581;CODE
try just in case;-2.0592444;3.208032;1.5703489;2.9781678;-1.1585679;-3.0504787;CODE
elf anchor node in case idx was reversed reset;-5.978158;1.9419582;-2.2193744;-1.0371572;-1.0861466;2.9261062;IRRE
keep the anchor and last selected node;-1.967701;1.6683514;5.262337;-0.37803742;0.30898085;3.1891513;IRRE
empty beforehand so lookup in deselect will be fast;-0.9006746;5.113492;-0.28784359;-0.7915024;0.81307936;-0.535995;CODE
try just in case;-2.0592444;3.208032;1.5703489;2.9781678;-1.1585679;-3.0504787;CODE
bind covering;-2.6489763;1.0691805;3.7390914;0.1300354;3.296246;2.2715435;-
return a decimal approximation of an aspect ratio;2.4975436;2.361719;0.9004106;-2.9971764;-4.0358014;1.9728979;IRRE
return scaled size based on sizer where sizer n none scales x;3.9469473;4.4981256;0.7273869;-3.834755;-1.2292911;1.6269165;CODE
to n and none n scales y to n;2.686273;0.38245836;2.672078;-4.2245097;-0.23046927;-1.0988419;-
return if no reference size yet;0.8143034;7.7341285;0.07337714;2.4231873;0.9449296;-2.633802;CODE
same aspect ratio;1.1526695;0.6300351;3.8598247;-3.400786;-0.53071386;4.104625;-
scale x;1.6161224;1.5041113;5.4169273;-4.5700912;-2.966235;0.07720102;-
scale y;2.2204854;0.5925636;6.107435;-3.801372;-4.034419;-1.0133669;-
set background size and position;-2.7234993;0.9007748;6.436413;-3.3690572;-1.182824;3.9710689;IRRE
when we are generating documentation config doesn t exist;-5.1795187;-2.8407428;-2.8494163;1.4291834;-0.75440913;1.0277497;CODE
no mouse scrolling so the user is going to drag with this touch;-4.4188156;-1.040481;4.771513;-0.35306907;-4.09845;2.784546;CODE
don t forget about grab event;-3.443253;-1.6347214;4.4686165;4.734094;1.3275656;2.3266187;CODE
encoding utf 8;-2.7622137;-0.64821744;0.27048004;-2.8575876;-1.3963621;-0.7661873;-
x08 self delete word left alt backspace;-5.2376947;1.4905074;-0.32557803;-2.6009436;-1.4893419;2.69679;CODE
join the modifiers e g alt ctrl;-3.2612693;-1.7394915;4.0462775;-2.6378934;3.2129881;-0.38389444;CODE
else e g ctrl alt or alt ctrl alt gr key;-5.1477003;-2.0837715;3.4695508;-0.8736068;-1.0356766;1.3691256;-
look up mod and key;-6.5127144;-2.0226088;2.3217795;-2.9395804;1.3897133;-0.20822069;-
clicking on a widget will activate focus and tab can now be used;-5.155005;-0.4384101;2.3396766;1.5138041;-3.9262464;4.1217685;CODE
to cycle through;-2.5204175;-0.8371538;7.9668045;0.99520236;1.6213486;-1.4179333;CODE
when we are generating documentation config doesn t exist;-5.1795187;-2.8407428;-2.8494163;1.4291834;-0.75440913;1.0277497;CODE
elf focus false this ll unbind;-5.7154927;0.5968371;0.04547631;0.6760579;-3.5932996;3.4169097;IRRE
if self keyboard remove assigned keyboard from dict;-2.8757746;1.3273276;-1.7602264;-0.5313952;-0.23498264;-0.8964204;CODE
if next is value prevent infinite loop;-0.7829722;6.849232;3.3516793;1.2362468;-0.96529144;-5.216191;IRRE
old focus keyboards keyboard keyboard should be in dict;-3.5091827;-1.4704932;-1.9995352;-1.8660523;-2.0187151;0.7883456;-
keyboard shouldn t have been released here see keyboard warning;-5.364764;-1.0301392;-1.0021462;1.7090379;-2.399175;-0.54010725;-
if we hit a focusable walk through focus xxx;-1.5202471;-0.03248285;4.938958;2.7017741;-0.33074477;2.3699732;-
return none make sure we don t loop forever;-2.428075;7.0855594;1.7883803;2.532913;-1.5603405;-4.374204;CODE
hit unfocusable walk widget tree;-2.9110994;-0.97613204;2.3131196;1.6514416;-2.9512293;3.286759;-
next itr current is returned first when walking forward;-3.4734454;3.4218993;2.9512742;1.1479706;-2.538729;0.26396233;CODE
why did we stop;-2.938492;0.4420441;3.5286624;2.3859525;-3.15677;-0.8269311;-
if keycode 1 tab deal with cycle;-2.9507058;4.2878594;1.0408278;0.01676621;1.2852974;-2.0973778;-
track event history uid event grab list;-1.1710687;-1.2326618;2.590534;2.147259;-0.4417745;1.9928156;CODE
keep last 2 frames to compare grab states;1.7574306;3.8652904;3.7081552;0.30788326;-0.8545279;0.11605262;IRRE
elf event times me uid clock get time;-3.7817183;-0.9840091;-0.63907444;-0.019902062;-1.3344082;-0.5577727;-
save original grab list for other event managers;-1.5365759;-0.15270405;2.9196422;3.290947;1.3817946;4.1601653;CODE
dispatch to widget tree;-3.8854125;-1.6963441;2.4191198;2.0675402;0.5490062;3.4651923;-
store this frame s state for next frame comparison;1.4657816;4.329304;4.2661095;0.28837544;0.55332613;0.8908551;CODE
check for widgets that lost hover;-3.2032201;0.4934776;1.891349;1.0141037;-4.3581457;1.169353;CODE
clean up completed events;-2.6117384;1.1230353;3.747866;4.6727185;0.9370811;2.120781;TASK
restore original grab list;-3.1400552;0.77191746;1.9576708;1.0574733;0.5381701;1.6754537;-
check registered collides handled;-2.2172835;2.708319;-0.2608295;4.0713863;1.4367037;-1.4062465;-
not registered or didn t handle continue transparent for hover;-6.67181;1.1854069;0.18076241;1.2886922;-2.9733958;2.7066936;CODE
save current state;-3.010777;1.8689377;4.6869326;3.6391857;0.75524944;2.255357;CODE
restore previous frame s state;-2.9353757;2.1672747;3.293318;0.08505478;-2.1707993;4.2085743;-
find widgets that lost hover;-2.3244975;-0.7538834;2.7735162;-0.4932891;-3.6671305;1.6250145;-
restore current state;-4.3140693;2.599624;3.806796;2.281221;-0.0006701008;2.435637;-
transform to widget space if needed;-0.92355555;0.99332315;4.5689993;-2.85002;-1.553211;5.089529;CODE
set widget as grab target;-3.2419667;0.8061792;3.4010346;1.5714523;-2.4773245;4.4175906;IRRE
dispatch with context handling;-4.1475253;-0.35186687;2.4276552;4.355551;2.9625123;3.850762;-
restore grab state;-5.2822943;1.7332205;1.9460912;2.359631;-0.61447114;2.0497224;-
subscribe to hover motion events;-2.4968746;-2.9926383;5.457494;0.6795666;-1.0253315;3.6203794;-
filter only process hover events with position;-0.98415756;1.5797696;4.242668;0.781503;-1.6238644;2.7234683;-
handle based on hover mode;-3.5555346;1.2232636;4.7276955;0.112715006;-0.8310843;2.295969;CODE
standard children first then self;-3.1346586;0.8779135;2.165025;0.47145832;1.9969935;-0.28309894;CODE
handle hovermode all and hovermode self;-2.6847708;1.4052346;1.8971556;0.16439271;-1.1024555;2.91797;CODE
block children;-2.7612216;1.4913229;4.314973;2.1703484;0.37406823;-0.09243055;-
dispatch to children unless blocked;-4.2325306;1.5072322;3.0296853;3.1988516;1.1366059;1.6357982;-
always dispatch to self;-4.980169;-0.8935051;2.5878103;4.8488135;-0.07476161;2.1330912;CODE
handle begin update hover active;-4.8038635;0.30424398;3.559593;2.2227182;-1.9307745;3.4836597;CODE
already grabbed by us;-1.9930227;0.06532628;3.1676443;2.1213694;-0.028561022;0.0100354105;CODE
disabled widgets block but don t dispatch;-5.7115145;1.9092363;0.920443;1.9791596;-2.8502038;4.5004315;META
hover within bounds grab and dispatch;-3.152788;0.4303271;4.0014944;-0.21131238;-1.6934202;2.929374;-
first time dispatch enter;-6.41934;-0.51828337;2.4863908;2.7054145;1.3972896;-0.08451718;-
moved within bounds dispatch update;-2.115441;2.2027318;0.84895545;1.2544997;-1.1224935;3.230517;CODE
handle end hover stopped or left;-6.1346283;2.2756922;3.722566;-0.08708224;-4.230031;0.54226875;CODE
we own this hover clean up and dispatch leave;-4.774422;-2.2028933;3.9471614;1.5428928;-0.27119812;1.8036617;TASK
disabled widget blocking;-5.7479753;1.4603453;1.8000275;2.0040047;-4.580416;3.8696527;-
knspace my widget now points to widget;-4.214652;0.29263607;2.889907;-0.72244745;-3.6509464;2.8521042;CODE
knspace my widget now points to widget2;-4.1586223;0.37776408;2.35197;-1.0604045;-3.586836;2.8913667;CODE
return getattr parent name if parent doesn t have it;-2.7781703;4.3019195;0.64590836;2.4982526;1.9195812;0.02454643;CODE
needs to overwrite eventdispatcher property so kv lang will work;-5.460533;-0.13543065;-1.1452428;2.6415095;-0.23351243;4.750253;TASK
we only get here if we never accessed our knspace;-2.6491208;-1.4747169;2.810736;-0.48558256;-2.7302632;-0.48707575;CODE
etattr knspace name none reset old namespace;-5.866671;-0.15336184;-2.073001;-1.0593581;-0.84067756;2.3134933;IRRE
knspace self knspace get parents in case we haven t before;-2.0253305;0.43931878;0.18408582;-0.5581227;1.6076529;-0.8909072;CODE
if value is none if none first update the recursive knspace;0.56932956;4.170614;-0.36402947;-1.8489879;1.0240709;-3.5036085;IRRE
elf knspace none cause a kv trigger;-2.8849826;-0.35267022;-2.9091346;-0.38581952;-2.2536783;-0.7719374;-
elf set parent knspace update before trigger below;-2.413833;0.82399225;-1.2001721;-0.13250583;0.50319654;1.9718124;CODE
process only grabbed events or events within bounds;-3.3227274;2.6206598;1.17175;3.0099626;-2.2532094;0.8017022;-
filter out non qualifying events;1.7366064;2.641392;0.7398257;2.8699722;2.9740565;0.8146537;-
grabbed events always pass through;-4.160807;1.6629133;3.759555;5.1878695;-0.6498249;1.4219567;-
check collision and registration;-0.38030243;2.5303233;2.3632963;1.0535381;1.9360387;-2.9567366;-
block if collides but not registered;-3.40504;4.1229763;0.70506746;3.6104884;1.2111455;-0.9373006;META
pass through to normal processing;1.492161;-0.21426764;1.332295;1.2106639;2.4929523;1.4147701;-
called as class method togglebuttonbehavior get group group id;-3.199701;0.23203452;1.005971;0.7330214;0.99549884;2.07831;IRRE
called as instance method my button get group;-3.0716698;1.6572062;3.8656733;2.9702742;0.5793408;1.7826234;IRRE
group mygroup shared across entire application;-1.2248337;-0.37391576;3.4393399;0.069200754;1.0718544;4.1669283;-
group root mygroup scoped to root widget;-3.1585405;1.1361872;2.9151511;-0.37649462;-1.1989964;4.638455;-
these groups won t conflict with other mycomponent instances;-3.58719;2.028029;-0.5925898;2.1848314;2.339409;3.7664652;-
multiple instances won t interfere with each other;-2.0352955;2.3128104;0.93326575;3.6812763;1.1315913;2.376607;CODE
each filterpanel instance has independent size groups;2.2784472;1.189738;0.06527919;-1.5054833;1.0815928;4.0288453;CODE
active booleanproperty false internal storage for active state;-3.3558512;3.6951258;-2.5614138;2.9353118;1.0249372;3.140815;CODE
bind early so initial group value triggers handler;-3.008498;3.3356512;2.2021942;2.516109;0.6516519;3.817521;IRRE
initialize parent behavior;-4.637032;3.4584253;2.1380045;2.1669574;1.8378253;3.1645026;IRRE
override buttonbehavior do press hook;-4.650079;0.64470345;1.448821;3.8620293;-1.1814939;3.505834;CODE
override buttonbehavior do release hook;-5.664151;0.2205594;0.25074363;4.3658204;-1.0072728;4.4786916;CODE
block deactivation if this would leave the group with no active members;-3.014311;2.1617806;2.3321736;1.664409;1.212355;2.7220304;CODE
return cancel deactivation cannot leave group empty;-3.8613636;5.018824;-0.648569;1.6342117;-1.5284256;2.226067;IRRE
apply state change;-2.4702032;2.4305491;2.1855888;2.1014795;2.4723513;2.3684955;-
when activating ensure all other buttons in the same group are;-3.0781143;3.7943494;2.3299167;1.4756234;2.7552142;2.5681581;META
deactivated;-4.95526;-0.10725934;3.659817;-0.025385037;-1.0953146;-0.55309224;-
remove from previous group;-1.4754012;3.306406;4.4733;-0.85897976;1.7126565;0.57166445;CODE
cleanup empty groups;-1.9406004;2.0452583;0.9950728;1.0374551;1.0017045;-0.38481534;TASK
cleanup empty owner entries;-3.8620708;1.4432117;-0.47346324;-0.25226676;0.67254776;-0.22720613;TASK
register in new group;-2.9259713;0.834958;3.049527;-0.54202235;2.2835872;-0.624182;CODE
revalidate active state in new group;-1.8479286;2.5774128;2.7740734;0.8273967;1.8264011;2.669744;CODE
defer on release until ripple fade has completed;-4.4239216;1.6832306;1.8862087;4.581629;-1.2447418;4.9850883;CODE
optimize layout by preventing looking at the same attribute in a loop;2.9877346;3.9643052;2.862445;0.38064522;1.9661139;3.4157414;IRRE
calculate maximum space used by size hint;0.75948304;2.0674784;1.6537362;-3.350877;0.44192043;-0.93551636;CODE
min size from all the none hint and from those with sh min;1.5364261;2.246056;1.1083016;-3.0635295;0.11389526;-1.189255;CODE
do not move the w h get above it s likely to change on above line;-4.5831656;2.182022;2.7785985;-1.7061747;-3.4568107;1.7144247;CODE
make sure the size hint min max are not violated;-0.9166472;4.636807;-2.5219338;-0.53420645;-2.6004152;1.3997291;CODE
there s no space so just set to min size or zero;-2.8172483;3.3965914;1.1888953;-4.9243436;-2.1532362;2.8814762;IRRE
hint i 0 everything else is zero;-2.338951;3.2155995;1.6071838;-4.6369176;-2.353369;-4.667339;CODE
hint gets updated in place;-3.9919362;-0.4572818;2.6497812;3.5052338;-1.8172617;-1.6718651;CODE
background color 1 0 0 5 50 translucent red;-3.1630175;0.5521211;2.9856393;-4.1376243;-0.7828495;-0.9555071;-
internal map that specifies the different parameters for fixed arrow;-1.3374071;1.3575139;1.3269954;-1.5869585;1.0697049;5.6064696;CODE
position layouts the flex arrow pos uses these parameter sets;-3.1496594;-0.70848924;2.287852;-3.247848;0.74154574;4.9468265;IRRE
as a template;-2.8231752;-4.0069366;6.269945;0.9334552;4.4540534;0.46706098;-
0 orientation of the children of bubble content arrow;-2.5157158;1.4324439;2.9981415;-4.0803504;-2.045512;2.0497081;-
1 order of widgets to add to the boxlayout default content arrow;-2.8452647;0.30792674;3.1810358;-3.0264478;-1.4041939;4.909845;TASK
2 size hint of arrow image layout;-2.0188205;-1.135493;5.212708;-4.4061007;-1.4322202;4.0377607;CODE
3 rotation of the arrow image;-2.3934076;-0.83234733;4.463883;-4.176578;-1.3017491;1.2109888;-
4 pos hint of the arrow image layout;-2.8955958;-1.6537282;4.94443;-4.7091627;-0.35482422;2.4854422;CODE
bottom left vertical 1 1 none 0 top 1 0 x 0 05 noqa e201 e241 e501;-1.0469499;2.3282797;1.5650084;-9.553851;-0.05515672;-2.0690508;-
bottom mid vertical 1 1 none 0 top 1 0 center x 0 50 noqa e201 e241 e501;-1.5678905;2.812376;2.8141541;-8.870612;-0.3231701;-1.2437704;-
bottom right vertical 1 1 none 0 top 1 0 right 0 95 noqa e201 e241 e501;-2.0786602;2.262319;2.4014773;-8.206847;-0.20100753;-2.954073;-
right bottom horizontal 1 none 1 90 left 0 0 y 0 05 noqa e201 e241 e501;-2.2864068;2.2336693;1.3284272;-9.122893;-1.2584065;-3.1674385;-
right mid horizontal 1 none 1 90 left 0 0 center y 0 50 noqa e201 e241 e501;-2.788078;3.1503477;2.468342;-8.224648;-1.7005261;-2.6439517;-
right top horizontal 1 none 1 90 left 0 0 top 0 95 noqa e201 e241 e501;-2.0381553;2.5004468;2.8043604;-7.966238;0.2044162;-2.402727;-
top left vertical 1 1 none 180 bottom 0 0 x 0 05 noqa e201 e241 e501;-1.5022311;2.7029912;1.5636816;-10.026147;-0.18610115;-1.9805787;-
top mid vertical 1 1 none 180 bottom 0 0 center x 0 50 noqa e201 e241 e501;-1.8472284;2.898073;2.9447546;-8.863957;-0.45853212;-0.951291;-
top right vertical 1 1 none 180 bottom 0 0 right 0 95 noqa e201 e241 e501;-2.4268887;2.7689917;2.4101908;-8.920173;-0.41664627;-3.0439217;-
left bottom horizontal 1 none 1 90 right 1 0 y 0 05 noqa e201 e241 e501;-1.8558038;2.4900737;1.4511241;-9.187945;-0.50095814;-3.3868613;-
left mid horizontal 1 none 1 90 right 1 0 center y 0 50 noqa e201 e241 e501;-2.461699;3.2254837;2.563605;-8.513194;-0.9736375;-2.7517738;-
left top horizontal 1 none 1 90 right 1 0 top 0 95 noqa e201 e241 e501;-1.6907096;2.7604244;2.7508838;-8.108321;0.9542266;-2.6076453;-
the order of the following list defines the side that the arrow;-2.6508343;-0.20871992;3.6059341;-3.6036682;1.6742066;-0.9591432;CODE
will be attached to in case of ambiguity same distances;1.0332285;1.5708816;2.7927496;-0.08511764;5.562759;1.4774319;CODE
this function calculates the proper value for pos hint i e the;0.35270935;3.973951;0.15407696;-3.7123404;-2.8321724;-3.8195477;CODE
arrow texture does not overflow and stays entirely connected to;-3.0767784;0.6210133;1.2772092;-0.39997882;-4.4090257;3.7109432;CODE
the side of the content;-2.9664571;-2.9559886;8.187553;-1.2557247;1.149378;-0.96678096;-
remove the children of the bubble boxlayout as a first step;-2.8654795;2.0183368;4.3895345;-1.7561407;-0.8609907;3.346737;-
find the layout parameters that define a specific bubble setup;0.98346376;0.7074818;3.3743918;-3.653456;1.6854022;2.048876;IRRE
rotate the arrow place it at the right pos and setup the size;-2.017176;0.39089397;4.904879;-4.119351;-2.2639587;3.4845686;IRRE
of the widget so the boxlayout can do the rest;-3.9745123;-2.1537282;7.342956;-1.714901;-1.4341948;4.221142;CODE
set the orientation of the bubble boxlayout;-2.9390614;0.4007483;3.713856;-3.559114;-1.962637;4.153809;IRRE
add the updated children of the bubble boxlayout and update;-2.9305682;0.5405789;5.0231285;-0.7628675;-0.37781635;3.5805292;CODE
properties;-1.6438527;-0.56832975;4.6443586;1.6928638;3.3379152;-1.85997;-
set the arrow margin so we can use this property for proper sizing;-0.0342192;0.39400497;1.7262586;-1.5640051;-1.1590582;6.3169246;IRRE
of the bubble widget;-2.4829395;-3.4210408;6.517419;-1.2728605;-1.811404;-0.014720306;-
determine whether to add the arrow image layout to the;-2.4372654;0.5364295;4.284812;-1.2816969;-0.7993391;3.9610133;TASK
bubble boxlayout or not;-2.4721558;0.322048;4.8578606;-2.6583126;-0.7585339;3.4219599;-
start the camera playing at creation;-5.746795;-1.0496178;4.8013086;0.39069864;-1.369064;2.4139953;-
create the camera and start later default;-3.4190025;0.71060073;4.920184;0.6798441;-0.15750876;5.6834474;IRRE
and later;-2.201772;-2.0195792;5.9220166;3.9571943;1.1892352;-0.3216324;-
create a camera object with the best image available;1.6704648;0.7703491;5.571472;-0.75657403;1.5683669;4.3045015;IRRE
create a camera object with an image of 320x240 if possible;-1.2131593;0.7298725;3.408193;-4.3613744;0.09828935;2.8835847;IRRE
if len slides 2 none or 1 slide;-1.7987131;3.5521176;2.597715;-1.3892552;1.6868794;-3.6126494;-
if len self slides 2 none or 1 slide;-2.2490425;3.4498308;2.449148;-1.3305256;1.2286527;-2.7426584;CODE
private properties for internal use only;-3.511476;0.37676716;0.727062;1.5668594;2.6993594;3.7873764;CODE
if first slide is moving to right with direction set to right;-2.231344;2.0236888;3.7883368;-0.751722;-0.97952235;0.48418838;IRRE
or toward left with direction set to left;-2.9885583;-0.44566557;5.1732025;-1.8427624;0.10922868;1.4214294;IRRE
put last slide before first slide;-2.887992;1.5076962;4.980177;-1.3287696;0.15507254;1.7398535;CODE
if reached full offset switch index to next or prev;-0.51553863;5.833567;2.502054;-1.1197512;-0.105500884;0.8801207;IRRE
move to next slide;-2.9104605;-0.014456128;5.75872;-2.2165747;-1.1870279;1.0948437;-
move to previous slide;-3.5263975;0.20242709;5.3938026;-1.888552;-1.661941;2.6773305;-
compute target offset for ease back next or prev;2.729008;2.3774698;2.6472657;-1.01795;-1.9480288;2.1538954;IRRE
if new offset is 0 it wasn t enough to go next prev;-2.0208607;5.8073735;1.0342088;-0.10278374;-2.9028141;1.2921618;IRRE
detect edge cases if not looping;2.584936;3.955469;2.1860793;-0.41100326;1.8153895;-2.0668788;IRRE
don t forget about grab event;-3.443253;-1.6347214;4.4686165;4.734094;1.3275656;2.3266187;CODE
xxx be careful the widget parent refer to the relativelayout;-4.4040413;-0.32498303;3.5068233;-1.4912198;-1.7391531;4.8781157;-
added in add widget but it will break if relativelayout;-4.5302796;2.0947375;2.0097315;0.4769439;-3.015471;3.5123131;TASK
implementation change;-3.4500027;-0.015359898;1.8065294;3.1497598;1.274707;-0.12792055;TASK
if we passed the real widget;-3.6015546;-0.069970794;3.5966604;2.6396027;-0.7411998;1.1224669;-
children must be a list of slides or none;-3.516287;-0.36020926;2.9423268;-0.15158305;2.0014665;-0.4086274;TASK
todo color chooser for keywords strings;-1.8440217;-1.5409217;0.41092798;-0.117930755;3.0574749;-0.190253;CODE
elf text color 000000;-5.3995724;-2.2196088;0.33285287;-3.4469595;-0.36099666;-2.9621475;-
use text color as foreground color;-2.567643;-0.18187554;2.9319143;-1.5275521;-0.15124378;1.5660167;IRRE
set foreground to white to allow text colors to show;-3.297975;0.79852474;2.9147234;-1.0473793;-1.9296795;2.1956222;IRRE
use text color as the default color in bbcodes;-3.6891577;0.340771;-0.17316464;-2.5595667;0.6956658;1.868466;IRRE
create a label from a text using line options;-1.4415131;-0.021401575;3.3871439;-2.12916;1.795585;-0.33703005;IRRE
if self password and not hint don t replace hint text with;-4.347822;2.2658143;-0.46940786;1.8289157;-1.5326285;-1.0322282;CODE
fixme right now we can t render very long line;-4.688817;1.0119395;2.0890062;-1.003131;-4.912341;1.7147505;CODE
if we move on vbo version as fallback we won t need to;-2.7372224;-2.0569382;-1.08988;3.3822608;-0.5694862;4.3370833;TASK
do this;-2.656733;-1.1640106;3.5973141;1.93247;0.7430802;-0.67490816;CODE
try to find the maximum text we can handle;-0.15480697;2.4703388;3.258991;-0.7364985;2.1168342;-3.542955;CODE
ok we found it;-3.3744814;-2.8520887;1.6164148;0.4043396;-0.5578777;-1.1785202;-
return the width of a text according to the current line options;-0.50827533;2.6904953;3.5379684;-1.5080577;-0.5195231;-0.30400655;IRRE
get bbcoded text for python;-3.4349759;-1.5216401;-1.3525407;-2.9274414;-1.9237025;-2.0233967;CODE
replace brackets with special chars that aren t highlighted;-2.8182046;0.5247271;-0.03707231;-0.9040409;1.2426763;-0.5037985;CODE
by pygment can t use bl cause is highlighted;-4.7152357;0.028337913;-4.302286;-0.8761454;-2.569365;1.6824622;-
replace special chars with bl and br;-3.254409;1.3611515;-0.78810817;-4.303963;1.2888905;-1.3937953;CODE
remove possible extra highlight options;-3.7550187;0.80994624;0.6945078;0.5704571;1.1809702;2.460389;-
overridden to prevent cursor position off screen;-4.1325903;1.2122409;1.8035668;0.507429;-3.8701017;3.7049289;-
kivy 1 0;-1.4029053;0.04636393;2.796707;-1.5439909;-2.6861467;-2.9736822;-
to monitor changes we can bind to color property changes;-2.1316743;-1.4852502;2.899577;3.5059996;1.0926485;2.7671986;-
print rgba str value or instance color;-0.95156544;1.4116197;-1.2748929;-2.8055377;1.7968218;-1.5216016;IRRE
initialize list to hold all meshes;-0.97670436;2.4038353;2.013479;0.98384047;1.4615057;2.9212375;IRRE
if its already zoomed all the way out cancel the inertial zoom;-2.977266;2.2823725;3.122074;1.2829982;-4.7180185;5.3383245;CODE
if its already zoomed all the way in cancel the inertial zoom;-3.213494;2.4994242;3.2435653;1.3539714;-4.550718;5.0945153;CODE
code is still set up to allow pinch to zoom but this is;-4.950058;-0.47029084;2.6061864;-0.32834125;-4.1634345;3.9273195;TASK
disabled for now since it was fiddly with small wheels;-5.701375;-0.73972225;1.3715993;-0.47741216;-1.9431171;2.3191173;CODE
comment out these lines and adjust on touch move to reenable;-5.3952785;0.36056304;4.141021;0.1738419;-3.833194;3.4255538;-
this;-2.447512;-2.229283;4.445673;2.6490912;1.0222366;-0.7718055;CODE
this is a pinch to zoom;-1.7285627;-1.8869493;6.5199556;-1.5454274;-2.4390485;2.0258605;CODE
user was pinching and now both fingers are up return;-4.836682;1.976453;3.5663998;1.5899905;-3.7966402;-1.0783191;IRRE
to normal;-1.576485;-0.07399839;5.6227617;1.1649109;-0.84021944;0.3885293;-
user was pinching and at least one finger remains we;-3.2164207;1.3726801;4.131673;0.98813677;-1.9657016;-1.497025;CODE
don t want to treat the remaining fingers as touches;-3.7215097;1.7455499;5.6558466;-0.24166256;-0.8140357;1.1997455;CODE
if touch up is outside the wheel ignore;-3.1913679;3.3527036;2.1817238;1.4846689;-2.726764;1.3086914;-
compute which colorarc is being touched they aren t;1.2855594;2.043045;2.225357;-1.8305107;-0.5100969;-2.855845;-
widgets so we don t get collide point and set;-2.3792;-1.404147;5.1000724;-0.74666405;-1.9725428;3.2722821;CODE
hsv based on the selected colorarc;3.126717;-0.49314302;0.03433963;-1.8144747;1.2404592;0.112993285;CODE
first calculate the distance between endpoints of the outer;0.11102937;1.5837798;4.470472;-4.072924;-2.0905666;-0.7918117;CODE
arc so we know how many steps to use when calculating;1.0739928;-0.083220415;4.842798;0.20393628;-1.725006;-1.6716899;-
vertices;-0.18544084;-1.4488586;5.146662;-4.749028;0.35470015;-2.6297333;-
if not d outer 1 add a last point if d outer is even;0.1186077;5.0368423;2.800853;-4.7996755;1.1433296;-2.936084;CODE
defaults to ffffffff;-4.2264266;-0.36157456;0.08712202;-1.1072046;-2.8907678;3.1969566;CODE
now used only internally;-7.020938;-0.7798;2.3763435;2.1134377;0.48975575;0.86925006;CODE
to prevent interaction between hsv rgba we work internally using rgba;-1.8604615;-0.5642242;-0.87974775;0.58047736;-1.0890375;3.3263383;CODE
create a dropdown with 10 buttons;-0.6025716;-0.0452058;5.5004034;-1.8477925;2.648358;-0.704322;IRRE
when adding widgets we need to specify the height manually;-3.443319;0.50741047;0.82920665;-2.2631702;-3.6143115;4.537435;TASK
disabling the size hint y so the dropdown can calculate;-0.36203864;3.1139367;0.9789996;0.9144191;-2.0669067;0.8858406;CODE
the area it needs;-2.5260065;-1.3042128;6.724481;-0.5412619;-0.07961566;1.0225376;TASK
for each button attach a callback that will call the select method;-1.8025253;0.6036167;4.6530724;2.1902642;1.8433675;2.8711705;CODE
on the dropdown we ll pass the text of the button as the data of the;-2.3776872;-1.971503;4.962859;0.18000746;0.70289487;1.5578442;META
selection;2.2316139;-1.7080317;6.1581593;2.5045087;5.470379;-1.7585709;CODE
then add the button inside the dropdown;-4.132693;-1.3523406;4.787365;0.9672064;-0.41106817;2.3431625;TASK
create a big main button;-3.7023358;-0.9474406;7.310977;-0.14724836;0.29670638;2.8632665;IRRE
show the dropdown menu when the main button is released;-4.3678455;0.09480401;5.6126266;2.8628936;-0.5943262;3.0415447;CODE
note all the bind calls pass the instance of the caller here the;-5.3140287;3.120223;2.0649462;3.3292346;1.4162083;3.0369887;IRRE
mainbutton instance as the first argument of the callback here;-5.409745;1.9446803;3.4293194;2.953105;-1.4211863;3.423233;IRRE
dropdown open;-3.5195284;-0.94886076;4.3192086;0.80851;-0.28713852;-0.20241974;CODE
one last thing listen for the selection in the dropdown list and;-2.6434798;-2.0985124;3.8872201;1.9653007;1.0878994;0.19632731;CODE
assign the data to the button text;-1.3701959;0.046969052;5.0737658;-1.4260399;1.3554882;0.5080904;IRRE
kivy 1 4 0;-1.3501842;0.36075163;2.5883927;-1.8970364;-2.3065832;-2.8097215;-
ensure we are not already attached;-4.831614;2.0772946;3.635539;2.7325788;-0.6768585;1.2450665;CODE
we will attach ourself to the main window so ensure the;-5.06903;-0.24047893;2.7038982;0.910227;-2.1789203;3.177322;CODE
widget we are looking for have a window;-3.8002965;-2.7692242;6.2914996;-1.5078607;-2.055416;2.1970003;CODE
attach ourself to the main window;-4.637896;-1.3457315;5.085553;-0.13310441;-1.7181453;3.512106;CODE
explicitly test for false as none occurs when shown by on touch down;-1.823669;7.040813;1.0108166;3.9366777;-1.7181314;-2.9969401;CODE
calculate the coordinate of the attached widget in the window;-2.3135645;0.2800936;5.070298;-3.5362327;-4.0444283;2.3362432;CODE
coordinate system;-0.24508101;-0.20252825;4.790805;-5.8324084;-2.2208502;0.25714436;CODE
ensure the dropdown list doesn t get out on the x axis with a;0.5451343;3.7549868;2.1834872;-2.0392904;-2.873678;1.8114715;CODE
preference to 0 in case the list is too wide;0.7221594;3.848851;1.139849;-1.268;1.0728213;-0.35906354;CODE
determine if we display the dropdown upper or lower to the widget;-1.7926569;1.971776;3.1898181;0.35325125;-1.429575;-0.21824531;CODE
none of both top bottom have enough place to display the;-4.846773;2.114547;3.5282283;-3.125958;-2.0889277;1.7197896;-
widget at the current size take the best side and fit to;-0.61547816;-0.4035804;5.0358963;-1.886507;-2.3413808;3.9799035;-
import ew kivy uix effectwidget;-4.075139;-3.5088518;-0.3202849;-1.9685038;-4.440138;2.922455;CODE
ifdef gl es;-2.3761165;1.4200331;1.5646051;2.1244857;0.15261132;-1.5679303;CODE
endif;-2.5042036;0.32218668;2.8978314;0.36728838;-0.5615267;-1.6890813;CODE
make sure opengl context exists;-4.7807064;-0.44192412;-1.8955432;-0.26372552;-0.878957;4.414656;CODE
elf refresh background color in case this was changed in kwargs;-4.7057996;-0.8515009;0.7295054;1.4592196;-1.8806028;2.8839798;IRRE
add remove fbos until there is one per effect;-1.9794816;2.3052232;1.3362094;1.0817426;-0.7624738;3.1654844;TASK
remove fbos from unused effects;-3.2425776;0.42953393;-0.46919948;0.2123236;-2.1273901;4.892145;CODE
do resizing etc;-2.1792595;-2.0188174;4.4577475;-2.0890422;-1.2256273;4.939875;CODE
if there are no effects just draw our main fbo;-1.8067548;-1.9125028;4.0009775;1.9481999;-2.0663774;1.8961905;CODE
build effect shaders;-1.6258578;-5.3684716;2.2215364;-2.0272481;-0.33806053;2.7320876;CODE
add the widget to our fbo instead of the normal canvas;-3.1926355;-1.3634937;3.7471826;-1.0017716;-3.8737304;5.579494;TASK
remove the widget from our fbo instead of the normal canvas;-3.6676135;0.14669514;3.2654116;-0.89717;-4.358471;5.5541673;CODE
clear widgets from our fbo instead of the normal canvas;-3.1696372;-0.33917153;2.7640402;-0.9379905;-4.1161027;5.512832;CODE
import that module here as it s not available on non windows machines;-5.172496;-4.1883373;-2.8275847;-1.9705584;-2.7466433;1.1950811;CODE
see http bit ly i9klje except that the attributes are defined in;-4.053654;-1.6015594;-2.5349004;-0.834999;3.8377438;1.4238693;CODE
win32file not win32com bug on page;-5.8696804;0.7950613;-2.9825146;0.56082666;-1.681932;1.3528168;-
note for some reason this doesn t work after a os chdir no matter to;-5.2413235;-1.7063475;-1.17708;-0.54348254;-1.9167213;1.6909238;CODE
what directory you change from where windows weirdness;-4.694136;-1.4834584;1.2754531;-1.1401849;-2.123553;1.6348108;CODE
this error can occurred when a file is already accessed by;-6.3301954;1.105505;-0.84862536;1.4517187;-1.7213371;-0.61513525;CODE
someone else so don t return to true because we have lot;-1.0545167;2.946455;2.4443042;3.1231692;-1.3813739;-0.47916985;CODE
of chances to not being able to do anything with it;-4.0703163;-1.227342;2.4958546;4.6157436;-1.6654346;-2.444851;CODE
patterns;2.041111;-2.4256997;6.775384;0.597754;4.7687078;-3.3985868;-
callbacks;-5.388628;0.45069367;4.768242;4.3197618;-0.3878297;0.24076042;IRRE
don t respond to touchs outside self;-5.028654;0.90273714;3.7771676;2.5375352;-3.1752124;0.62425643;CODE
don t respond to touchs outside self;-5.028654;0.90273714;3.7771676;2.5375352;-3.1752124;0.62425643;CODE
just check if we can list the directory this is also what;-5.2947664;-1.7046646;1.1433682;-0.72549343;-0.42375857;-0.6212233;IRRE
add file does so if it fails here it would also fail later;-7.0380535;2.3094532;-0.4184354;4.059733;-1.275609;1.0943166;TASK
on do the check here to prevent setting path to an invalid;-6.975441;3.079972;-2.9907854;3.476822;-2.3362582;1.2212586;IRRE
directory that we cannot list;-3.4597309;-0.13862701;1.316083;0.029306415;0.062474135;-2.0298944;-
if entry path is to jump to previous directory update path with;-4.0351777;2.659144;2.5792866;3.3236003;0.030421171;0.07101084;CODE
parent directory;-4.071861;-1.0871947;4.1552043;-0.75348705;1.325158;0.29085025;-
trigger to start gathering the files in the new directory;-1.0742444;-0.39044526;3.4325013;2.548802;0.5514554;0.9965086;CODE
we ll start a timer that will do the job 10 times per frames;-1.4595652;-0.41464725;6.241519;2.3615441;-0.721284;1.3402001;TASK
default;-5.2986646;-1.8012849;4.161423;0.8626395;-0.7494437;1.3156078;CODE
cancel any previous clock if exist;-3.5319848;4.7878156;2.1682775;1.7583367;-0.28399476;-0.870436;-
show the progression screen;-1.9916396;0.30752498;7.2916794;-3.2040715;-1.2463908;-0.077871904;-
not enough for creating all the entries all a clock to continue;-0.9030006;2.0604203;3.6501238;-0.13728887;0.9268874;-2.4147542;CODE
start a timer for the next 100 ms;-1.3963778;0.021789351;5.0947323;2.0187662;-1.324716;-0.058288515;CODE
create maximum entries during 50ms max or 10 minimum slow system;3.677667;1.2888844;2.605838;-0.3158729;2.7865815;0.8030309;IRRE
on a fast system core i7 2700k we can create up to 40 entries;1.390006;-1.9055325;-0.4810376;0.39445102;2.4715376;0.21039984;IRRE
in 50 ms so 10 is fine for low system;-0.26655582;-0.051660787;0.6471981;0.25308704;-0.8695404;1.7847716;CODE
except typeerror in case gitems gen is none;-4.4532404;3.6205127;-4.8342094;1.6664618;-1.7260386;-3.3795986;CODE
if this wasn t enough for creating all the entries show a progress;-0.38219678;0.6233843;5.044558;2.1667514;1.2310109;-0.03323482;CODE
bar and report the activity to the user;-2.4137597;-0.2759119;5.322456;0.27031842;0.0051116096;0.99157023;IRRE
we created all the files now push them on the view;-4.625621;-4.4901977;4.606143;0.7389192;-2.4984972;3.9162588;IRRE
stop the progression creation;-0.5746908;0.20249079;3.1310241;1.9132358;0.10146371;-0.59391737;-
if we cancel any action the path will be set same as the;-6.9141893;2.3360314;2.8203566;3.6805034;-1.0952706;4.256093;IRRE
previous one so we can safely cancel the update of the previous;-4.9779654;-0.8937458;3.5044682;3.872861;-0.69338197;1.3246089;CODE
path;-4.162573;-2.7342591;6.019224;-0.25148016;-0.24145554;-1.8543303;-
generator that will create all the files entries;0.11024091;-1.8862069;2.6834335;-0.112149924;1.9899327;-0.6195297;IRRE
the generator is used via update files and create files entries;-3.6863983;-3.911089;0.26751578;-0.22014807;2.159948;-0.12900124;IRRE
don t use it directly;-4.2241077;-1.1952951;1.6299174;2.6054816;-1.0211651;1.8715674;CODE
add the components that are always needed;-2.9924676;-1.1545315;3.426843;0.24831255;4.1141253;2.9945402;TASK
unknown fs just always add the entry but also log;-3.8364756;2.087898;-0.98283094;1.371056;-2.3837016;-1.7030238;TASK
generate an entries to go back to previous;-0.038256038;2.2177794;5.7338266;-0.6235716;2.5722048;-0.5063351;-
generate all the entries for files;1.5934948;-0.9018714;2.4838226;-0.5888584;1.9047412;-1.5627751;CODE
in the following use fully qualified filenames;-3.2979991;-2.1177025;-2.3722847;-0.56374615;4.9413533;0.6471524;CODE
apply filename filters;-0.069535375;0.08832151;-0.9527914;1.2232405;1.8633738;1.8966016;-
sort the list of files;0.78877544;-1.0582123;3.0453067;0.40872443;-0.5026184;-0.72040725;-
use a closure for lazy loading here;-3.4164891;2.4630377;1.904209;5.6259627;0.8774894;2.7348967;CODE
optimize layout by preventing looking at the same attribute in a loop;2.9877346;3.9643052;2.862445;0.38064522;1.9661139;3.4157414;IRRE
size;-1.293162;-0.48505983;5.254666;-1.905388;0.41176203;-2.3314316;-
pos;-1.9962835;-1.1447797;4.340867;0.7006273;-0.5030006;-1.7367243;-
size self trigger layout;-0.7740389;0.34969854;2.3137147;-2.884008;0.2599033;4.300376;CODE
size hint self trigger layout;-1.5192461;0.29323354;2.177472;-1.5530907;-0.67311937;3.0386634;CODE
size self trigger layout;-0.7740389;0.34969854;2.3137147;-2.884008;0.2599033;4.300376;CODE
size hint self trigger layout;-1.5192461;0.29323354;2.177472;-1.5530907;-0.67311937;3.0386634;CODE
clock undershoot margin fixme this is probably too high;-2.6787624;-0.6319167;2.1251752;-1.6774658;-3.3103373;0.9376203;CODE
the color is applied to all canvas items of this gesture;-2.398574;-0.66416395;5.6999464;-1.0734375;-1.2822745;2.377111;CODE
this is the touch uid of the oldest touch represented;-3.7741272;-0.8742588;3.839115;-1.5278599;0.32631257;1.6035011;CODE
store various timestamps for decision making;1.173146;-1.9934989;4.4248705;1.5691811;3.422795;0.96795297;CODE
we can cache the candidate here to save zip vector instantiation;-0.84718966;-2.0986958;-1.815806;0.77562094;3.9119394;2.0066586;CODE
key is touch uid value is a kivy graphics line it s used even;-6.6883454;-2.5874012;2.5942454;-2.1496377;-2.2676558;1.9748161;IRRE
if line width is 0 i e not actually drawn anywhere;-1.1026163;5.076657;2.037981;-3.8815408;-3.0833008;-1.9282509;CODE
make sure the bbox is up to date with the first touch position;-5.691348;1.6521649;0.9340431;1.5588692;-2.9846566;1.3139313;-
a list of gesturecontainer objects all gestures on the surface;-0.5639227;-3.8069708;3.933583;-0.9265052;0.30862072;3.3525748;IRRE
touch events;-3.2202308;-2.6365838;8.458125;2.2087476;-1.4923857;0.62583596;-
if the touch originates outside the surface ignore it;-2.1848538;2.1312575;3.1965973;2.6071477;-3.0294297;2.6628335;-
add the stroke to existing gesture or make a new one;-4.0983934;-0.35620704;4.6254034;1.0932764;-0.030236963;3.8475275;TASK
we now belong to a gesture new or old start a new stroke;-4.0734053;-0.3569738;3.2207768;2.1776602;0.4796868;1.9677861;CODE
retrieve the gesturecontainer object that handles this touch and;-2.728451;-0.1801741;4.5202227;0.3975358;-0.49566525;3.8626328;CODE
test for colliding gestures if found merge them to one;-0.6374681;2.1524758;2.3812194;2.792861;-0.6406793;-1.3072944;IRRE
add the new point to gesture stroke list and update the canvas line;-2.8832154;0.67127186;5.300379;-0.8939418;-3.0662313;4.1395802;CODE
draw the gesture bounding box if it is a single press that;-2.567199;1.2697297;6.513893;-1.1657673;-1.2886717;2.0701077;-
does not trigger a move event we would miss it otherwise;-5.34348;0.38304254;2.8994234;3.7244847;-2.6047854;2.0187566;CODE
if this stroke hit the maximum limit dispatch immediately;-2.6887844;1.8633711;2.0157275;4.3426557;-0.028596248;1.345789;CODE
dispatch later only if we have a window;-5.7010508;-0.23226161;4.476242;4.788773;0.3890259;3.8014793;CODE
gesture related methods;-0.6782926;-3.4245002;5.673044;0.54293233;-0.19229728;2.287375;-
create the bounding box rectangle for the gesture;-1.8421687;0.57639545;5.080436;-3.471911;-2.4758642;4.3104978;IRRE
update the bbox in case this will normally be done in on touch move;-6.3840885;-0.1303919;3.2076025;1.1798137;-1.8319122;3.9093385;CODE
but we want to update it also for a single press force that here;-4.931127;-2.4493487;3.059482;4.8422265;-1.1010368;1.9729455;CODE
register the stroke in gesturecontainer so we can look it up later;-3.3118978;-0.82561576;3.1922283;1.0172176;0.5239355;4.485646;-
swap order depending on gesture age the merged gesture gets;-2.4595065;2.9495046;2.8094413;-0.6596542;0.28875503;3.2346644;TASK
the color from the oldest one of the two;-2.2688594;0.08440993;3.8653023;-1.6411837;0.95323926;-1.8354875;OUTD
apply the outer limits of bbox to the merged gesture;-3.0397651;2.3807976;2.2186282;-0.6273482;0.83382016;3.5680723;-
now transfer the coordinates from old to new gesture;-2.2926624;0.16602145;4.5148244;-2.132318;-2.264486;4.3584824;CODE
fixme this can probably be copied more efficiently;-2.7924085;-1.5579324;0.6338985;1.3878845;-0.21246673;0.95086;CODE
fixme can t figure out how to change group for existing line;-4.5679903;1.0820183;1.4597669;-1.1537093;-1.6841724;0.9565978;CODE
if draw bbox is changed while two gestures are active;-3.9759474;1.9077799;4.281849;1.2162112;-0.6789726;2.3059874;CODE
we might not have a bbrect member;-3.2886136;-1.8433607;-1.5011187;1.8186984;1.4408602;-1.0525696;-
timeout callbacks;-3.7860935;1.5557504;2.8105576;4.132218;-2.548681;-0.23298444;IRRE
gesture is part of another gesture just delete it;-5.0991917;1.8876715;2.372018;0.08699614;-1.1694462;4.1559043;CODE
not active already handled or has active strokes it cannot;-6.4867225;1.7761028;0.12747897;2.915648;-0.30908933;2.3299167;CODE
possibly be complete proceed to next gesture on surface;-3.2993433;-1.0545771;5.222535;0.8570022;-0.99703467;2.9383936;CODE
max strokes reached or temporal window has expired the gesture;-4.7030177;0.9331764;2.0047238;1.5913996;-3.5958788;3.1027455;CODE
is complete need to dispatch complete or discard event;-4.397478;0.51612157;1.5841742;5.4121776;1.6005874;3.0564725;CODE
merge into one list;1.0418885;0.6492868;4.5948305;-1.4570867;3.0005713;-2.2372153;CODE
merge into one list;1.0418885;0.6492868;4.5948305;-1.4570867;3.0005713;-2.2372153;CODE
if that makes impossible to construct things with deferred method;-1.9563258;2.3241155;0.35310215;5.5112114;2.9291785;2.6052284;CODE
migrate this test in do layout and or issue a warning;-4.2238207;3.9517343;-1.5667689;3.736662;-1.0963662;-1.532965;CODE
the goal here is to calculate the minimum size of every cols rows;5.0465646;1.3943064;1.3406122;-5.219191;-0.54816335;-0.71345866;-
and determine if they have stretch or not;2.656448;1.7888668;3.581841;1.5409962;0.3397007;-2.0466309;-
if no cols or rows are set we can t calculate minimum size;4.0254908;4.408399;-0.9396478;-4.2687116;-0.75200874;-0.02161692;IRRE
the grid must be constrained at least on one side;1.5285201;3.1200228;1.1988782;-3.8073251;-0.8022682;3.4003816;TASK
elf cols min size none 0 min size from all the none hint;0.2539409;0.7329145;-0.12599403;-4.859491;-0.20934449;-1.8237349;CODE
elf rows min size none 0 min size from all the none hint;1.518782;2.998076;-1.027001;-5.6159616;0.34110492;-2.3421447;CODE
update minimum size from the dicts;2.572815;1.4112244;-0.4393368;-2.359696;0.7125083;1.5344133;CODE
calculate minimum size for each columns and rows;5.7426367;1.7241616;1.9496874;-5.432142;-0.21789661;-0.16423233;CODE
compute minimum size maximum stretch needed;3.1866868;2.3101673;2.3119829;-3.554121;-0.65747565;2.1219795;-
calculate minimum width height needed starting from padding;1.357238;1.8458273;1.7312542;-4.334144;-0.8657795;1.6027038;TASK
spacing;-0.19859827;0.08323888;6.378916;-2.727788;0.9032518;-2.4580593;CODE
we need to subtract for the sh max min the already guaranteed size;1.1797259;2.988766;1.3779769;-0.8216545;-1.6183265;1.0535702;CODE
due to having a none in the col so sh min gets smaller by that size;1.5173947;2.445083;-0.75349885;-3.3307884;-3.7857559;1.4995716;CODE
since it s already covered similarly for sh max because if we;-1.5453033;-1.2475681;0.8831699;3.0635166;0.72563434;2.5249376;CODE
already exceeded the max the subtracted max will be zero so;-0.7012135;5.318663;0.24272114;-1.5918659;-1.8481787;-2.717162;CODE
it won t get larger;-3.133701;1.0421293;2.831632;-0.1200794;-3.2992518;2.0267076;-
finally set the minimum size;-0.877663;2.5451083;2.205817;-0.7879335;-2.5779216;2.7561903;CODE
resolve size for each column;4.686815;3.5819113;0.57774085;-5.2354026;0.003397201;0.90848935;CODE
fix the hints to be within bounds;-0.8540521;1.9625723;1.567325;-0.11449712;-2.3590126;-2.123359;CODE
if the col don t have stretch information nothing to do;0.5398178;1.1155709;1.7346109;-0.3464713;-0.25490332;-0.16279857;CODE
add to the min width whatever remains from size hint;-0.13836962;2.7731612;3.3457077;-4.0157313;-0.20549473;2.991004;CODE
same algo for rows;3.031882;1.2869039;2.7380683;-2.7677772;3.779247;-1.9447237;CODE
fix the hints to be within bounds;-0.8540521;1.9625723;1.567325;-0.11449712;-2.3590126;-2.123359;CODE
if the row don t have stretch information nothing to do;1.8431292;4.620157;2.4998689;-1.8637251;0.387396;-0.97174114;CODE
add to the min height whatever remains from size hint;-0.8299649;3.0471797;4.2776823;-3.6850207;-1.3230331;1.7999302;CODE
delayed imports;-3.2466931;-0.94211274;0.08931022;3.2261107;-0.56912714;0.7817151;CODE
calculate the appropriate height;0.13226256;2.2891278;4.481675;-3.9036982;-1.5566018;-1.949424;-
if the height is too higher take the height of the container;-1.2992043;3.6514196;2.4766252;-1.1617461;-2.2953033;0.5726848;-
and calculate appropriate width no need to test further;2.7033005;4.256134;2.827873;-2.756495;0.45170346;-2.4402814;TASK
note compatibility code due to deprecated properties;-6.2745047;-0.61496246;-5.154872;1.8286935;0.8702386;0.92061067;TASK
update texture from core image;-1.6330551;-0.29285046;1.8625921;-0.2231212;-1.9454994;4.7745004;CODE
do something;-2.8416326;-0.30672786;4.4771266;1.526233;-0.8052002;-2.8079188;CODE
image will be re loaded from disk;-3.862664;0.6145089;2.8755987;-0.05628323;-3.7454836;2.7133365;CODE
hello world text;-5.4849977;-2.6257265;4.179096;-0.5253739;0.3097204;-1.953384;-
unicode text can only display glyphs that are available in the font;-3.3595603;1.6946423;-0.7198395;-2.044371;-2.3746784;1.5540612;CODE
multiline text;-1.9951508;-0.54480076;4.2759333;-3.4268727;2.1133914;-2.0138006;-
size;-1.293162;-0.48505983;5.254666;-1.905388;0.41176203;-2.3314316;-
define your background color template;-3.5974424;-2.301701;3.1594539;-1.8619355;3.3068924;2.9137776;CODE
now you can simply mix the backgroundcolor class with almost;-2.5224478;-2.1992;1.9807626;0.87696385;2.6392672;3.5548503;IRRE
any other widget to give it a background;-3.8727334;-3.497596;6.8816395;-0.8695062;-2.2081301;2.7531161;-
default the background color for this label;-3.0863817;-0.64328814;2.1324382;-1.2195691;1.2791338;2.4779358;CODE
to r 0 g 0 b 0 a 0;-0.2671856;3.2541726;1.2268865;-5.4112353;-0.42170742;-1.2508767;-
use the backgroundlabel any where in your kv code like below;-3.3229754;-1.735945;2.604977;-1.4510416;-0.34138122;2.134716;IRRE
hello world with world in bold;-3.3727157;-1.6055846;2.9991677;-0.1339941;0.23172188;-0.39538434;-
hello in red world in blue;-3.8297722;-0.9948737;3.1287081;-1.0205573;0.024189983;-1.617965;-
color color color;-0.62810177;-1.3002454;3.402819;-2.426643;1.5312899;-1.4494807;-
note the inversion of direction as y values start at the top of;-1.1555328;0.99429303;1.874854;-6.5748725;-5.9128685;0.13114183;IRRE
the texture and increase downwards;-0.32759964;-1.0539712;6.5510473;-3.6522484;-0.33852932;2.0939815;CODE
indicate the position of the anchors with a red top marker;-2.82851;0.61951995;5.3400807;-2.0284324;-0.14962414;1.3036506;-
draw a green surround around the refs note the sizes y inversion;-1.0586224;1.4625555;6.263929;-3.7141008;-2.0509021;0.870001;TASK
bind all the property for recreating the texture;-1.4746084;1.8336335;2.9817529;0.6970753;0.40505603;5.613583;CODE
note compatibility code due to deprecated properties;-6.2745047;-0.61496246;-5.154872;1.8286935;0.8702386;0.92061067;TASK
force the texture creation;-3.2013667;-0.39138582;1.6086178;0.5015138;-1.7889328;4.66759;CODE
create the core label class according to markup value;0.50830144;0.64800894;1.6655598;-0.68517977;5.113513;1.2453068;IRRE
markup have change we need to change our rendering method;-5.0337114;0.46609077;4.2774987;0.8664122;-0.42064458;3.8280673;TASK
check if the label core class need to be switch to a new one;-2.5442235;2.015796;-0.96044874;3.6137662;2.3341956;1.5335354;CODE
when disabled color or outline color changes should not get;-4.4004908;1.0578724;0.30555278;1.2860849;-2.0893047;3.1923704;CODE
assigned or trigger updates;-1.6349877;-1.7629089;2.4675686;1.6473211;2.995028;-0.08418901;CODE
note compatibility code due to deprecated properties;-6.2745047;-0.61496246;-5.154872;1.8286935;0.8702386;0.92061067;TASK
must be removed along with padding x and padding y;-4.396862;1.774842;1.6129194;-3.634313;-2.1128533;2.3588133;TASK
we must strip here otherwise if the last line is empty;-3.7344115;4.8258834;2.3150423;-0.46863818;-1.2513282;-2.6560135;-
markup will retain the last empty line since it only strips;-3.3931384;4.1285853;2.0717413;-0.973937;-1.670647;0.5953952;CODE
line by line within markup;-1.6233382;0.51019233;3.7931616;-2.7510002;1.492732;-1.3263174;CODE
force the rendering to get the references;-2.8586762;1.4144171;2.035927;2.2730968;-1.2848827;3.9304411;CODE
properties;-1.6438534;-0.56833;4.644358;1.6928649;3.337914;-1.859969;-
l texture is good;0.70280397;-2.43069;3.3938117;-1.7426673;0.3564684;0.9759289;-
l texture is not updated yet;-3.3047664;-1.024116;0.49031568;-0.5284661;-2.7770157;2.319294;TASK
l texture is good now;-1.495208;-0.45804784;1.3659368;-0.82912284;-1.8044494;1.2019315;-
todo test when children have size hint max min of zero;0.6860056;5.9477944;1.2975107;0.881015;-0.3996847;-4.278193;CODE
all divs are float denominator;-1.0654781;1.6628869;2.350557;-5.4385715;-2.760369;-1.1684477;CODE
too small just set to min;-1.260812;2.923778;3.1979945;-2.0495424;-3.295126;1.2811791;IRRE
hint i sh min stretch ratio set to min size;2.47543;2.2772925;3.3833554;-3.2801545;-1.4450583;1.2451282;IRRE
hint i 0 everything else is zero;-2.3389497;3.2155986;1.6071849;-4.6369157;-2.3533697;-4.667338;CODE
these dicts take i widget child as key;-4.824585;-0.3369261;0.79834497;-2.3807015;-0.24787089;1.5753461;-
not mined contrib all who s sh min sh or had no min sh;-0.86035633;2.1719515;0.9473103;-0.8116767;-0.23814148;-3.2995996;-
not maxed contrib all who s sh max sh or had no max sh;-0.511558;1.4326878;1.6192681;-0.7541907;-0.4148036;-1.7462969;-
h mins avail the sh amt removable until we hit sh min;-3.9841254;1.3627942;3.4564247;-0.48295763;-0.44835946;0.98779994;-
h maxs avail the sh amt addable until we hit sh max;-2.6720943;0.69837964;2.3775904;-0.134597;0.19891223;0.06501922;TASK
first for all the items set them to be within their max min;0.17569637;2.4861486;4.4530535;0.55094224;1.3561785;2.6457977;CODE
size hint bound also find how much their size hint can be reduced;2.1670706;2.3944085;0.95125616;-1.6354969;-1.0095357;0.029811963;CODE
or increased;-1.8174889;0.21082982;3.7830722;1.8061117;0.2436251;-0.45718348;-
diff sh min sh how much we are under the min;0.65968096;1.7402575;3.592008;-1.8767861;-1.1911539;-1.7465376;-
hint i sh max how much we are over the max;-0.826918;1.4964089;4.6026707;-0.34214717;-2.2896852;-2.7652626;CODE
not mined contrib i max 0 diff how much got removed;-1.2826014;3.7923489;0.24966943;-1.270384;-1.3605496;-1.4712222;OUTD
not maxed contrib i max 0 diff how much got added;-0.014531048;2.8283346;1.8888147;-1.9751188;0.0606429;-2.0204973;TASK
if margin is zero the amount of the widgets that were made smaller;0.5604917;1.9012728;2.1973765;-2.431233;-2.6437254;3.1245928;-
magically equals the amount of the widgets that were made larger;0.44439435;-0.5072786;3.9318147;-1.6253779;-0.90622675;1.951175;IRRE
so we re all good;-0.9353292;-0.41689214;2.50866;0.5171622;-1.2343944;-1.5319061;-
we need to redistribute the margin among all widgets;-1.4550223;-1.4343176;2.5322018;0.44898748;-0.9619184;5.4976845;TASK
if margin is positive then we have extra space because the widgets;-0.74618703;0.46700373;1.7848339;-1.4154632;-2.6617482;2.912139;IRRE
that were larger and were reduced contributed more so increase;0.32987887;-0.053978268;2.0841117;0.6033974;-1.3440574;1.9056338;IRRE
the size hint for those that are allowed to be larger by the;-0.1963824;0.8543944;2.617463;-0.6136862;0.93529165;-0.2746718;CODE
most allowed proportionately to their size or inverse size hint;1.8031973;1.4434024;2.3735821;-1.3566072;0.58116037;0.15066952;CODE
similarly for the opposite case;-1.3099588;-0.18735142;3.6706464;2.0949068;3.0478952;-0.059996217;CODE
when reducing the size of widgets proportionately those with;2.1876261;0.30568895;3.2362301;-1.0141364;-0.56713384;4.6078124;CODE
larger sh get reduced less and those with smaller more;2.051914;1.5677924;1.5904042;-1.0269234;-2.66911;1.599815;-
contrib amt is all the widgets that are not their max min and;-0.83803713;-1.932518;1.2016507;0.39308482;-0.5200275;1.753503;-
can afford to be made bigger smaller;-0.502272;-0.57313955;3.9600618;-0.6932837;-1.4503756;3.6991644;CODE
we only use the contrib amt indices from now on;0.3532256;-1.451752;-2.1032188;-1.5010892;-0.3851004;0.48563117;IRRE
assert mult 1 should only happen when all sh are zero;1.01874;7.9339795;-5.0103006;3.3460414;-2.0315259;-2.1389089;CODE
n len items check when n 1;1.4560442;4.6023436;2.0528858;-2.5397077;2.6200004;-6.320621;-
if not sh available i all were under the margin;-2.015425;-0.5678413;3.5480258;-0.23722498;-0.9479668;-0.6226828;-
noinspection pyargumentequaldefault;-2.6167524;3.4010181;-1.9453379;0.81056005;-0.02050582;-0.4530185;CODE
internals properties used for graphical representation;0.86656415;-4.347174;3.4415343;-2.9354215;1.6467543;2.682315;CODE
add view;-4.4485064;-2.3275547;6.47898;-1.0774696;-0.3047721;2.9922361;TASK
if not p it s first page;-5.7464886;1.145812;4.690417;1.5865188;1.315136;1.8896528;-
elif p l children not first but there are post pages;-5.586246;0.67159295;3.2386544;0.97298086;1.292738;-0.72496116;META
else not first and there are no post pages;-5.462783;1.5381782;3.3820348;0.8927369;-0.46161863;-0.9713852;-
if not p second page no left margin;-3.941139;4.771088;2.2506428;0.21686679;-0.46354422;0.34700376;-
else there s already a left margin;-1.2598057;0.8538725;4.249194;0.7505608;0.42282084;2.1314425;IRRE
move next page up to right edge;-3.5501444;0.081603475;5.5168123;-2.0805845;-2.155573;2.9953356;-
move current page until edge hits the right border;-4.350093;1.0242374;5.313221;-0.5536814;-2.524926;4.0320354;-
move previous page left edge up to left border;-4.621621;0.98266786;4.9216204;-1.7470678;-2.5098603;3.585607;-
move current page up to left edge;-3.9549186;0.58149785;5.4882107;-2.1582482;-2.2840965;3.4284859;-
move next page until its edge hit the left border;-4.4445043;0.98520595;6.4849243;-0.6688151;-2.0586832;2.640782;-
move second next page up to right border;-4.436288;1.0499684;6.0634174;-1.7972699;-1.6487913;2.625792;-
create content and add to the popup;-4.1707315;-1.415779;5.666418;0.049915884;0.0033636435;0.38157505;TASK
bind the on press event of the button to the dismiss function;-4.056282;1.035716;4.204869;1.9141123;-1.4780763;2.2799711;META
open the popup;-5.150451;-2.7949388;4.9784446;0.46783254;-2.4521728;0.0129527;CODE
import factory kivy factory factory;-2.861122;-1.9342978;-0.104994364;-0.15817167;-1.1954715;1.4245754;CODE
mypopup bad;-4.1685133;0.49285606;3.5709765;1.2410109;-2.2604287;0.08196446;-
internal properties used for graphical representation;1.1817114;-4.208394;3.5184987;-2.7911;1.6819892;2.4131691;CODE
add popup;-4.758698;-2.476683;6.115538;0.64350784;-1.696038;0.61063945;TASK
this will update the graphics automatically 75 done;-3.3405507;-1.7417719;3.8509;0.8400355;-1.918663;2.6179457;CODE
layout won t shouldn t change previous size if size hint is none;-3.2453825;4.5329833;0.7611166;-0.8018624;-2.143743;4.677396;CODE
which is what w h being none means;-3.8928025;1.9737322;-1.1281002;-1.0285114;1.0681471;-0.5817411;-
get the total number of items;0.4589947;2.6569586;5.0348372;-1.7012451;1.5759236;-4.1273217;-
limit index to valid range and handle negative indices;2.3463876;6.0545073;-0.9126372;-1.8988886;-0.043825503;-0.48543295;-
get padding and spacing;0.82380897;-0.27265915;4.14684;-4.3521776;-0.4649181;-0.38075477;TASK
calculate total dimensions;2.320587;0.73119754;2.8167565;-6.9882793;0.3962849;-0.71072274;-
calculate total width including spacing and padding;1.4105188;0.65213567;2.8228366;-4.7384014;-0.014853324;-0.15246008;TASK
calculate position of target item;1.2860464;3.0899775;5.2585993;-2.250156;-0.4858382;-0.5017838;-
calculate viewport width;-0.5860801;0.30885434;2.6017401;-4.1499;-1.3847001;1.836198;-
calculate scroll position 0 to 1;-0.923112;2.3567262;3.527784;-5.4648747;-3.5897772;-0.13120241;-
we want the target item to be visible in the viewport;-4.066577;0.043478608;4.448322;0.8361223;-1.4394842;5.839889;CODE
if the item is wider than the viewport center it;-2.429904;1.4961753;4.7450447;-0.86400753;-1.2996399;4.359341;-
center the item;-1.7479706;1.7581248;7.9566526;-1.7807523;-1.0294245;2.6956384;-
make sure the item is visible;-6.2837505;1.5300075;3.5321138;1.1689739;-1.5531616;2.112989;-
apply scroll position;-2.9806201;0.12268052;4.4487104;-2.5223832;-2.6008084;3.634179;-
else vertical orientation;-2.6532407;1.1061062;4.949062;-3.514987;0.17240989;0.7881792;-
calculate total height including spacing and padding;1.1719649;0.91826546;3.0456445;-4.9774213;-1.2559108;-0.247719;TASK
calculate position of target item;1.2860464;3.0899775;5.2585993;-2.250156;-0.4858382;-0.5017838;-
calculate viewport height;-1.1480201;0.4301254;2.7611158;-4.1255746;-2.4010746;1.8336134;-
calculate scroll position 0 to 1;-0.923112;2.3567262;3.527784;-5.4648747;-3.5897772;-0.13120241;-
we want the target item to be visible in the viewport;-4.066577;0.043478608;4.448322;0.8361223;-1.4394842;5.839889;CODE
if the item is taller than the viewport center it;-2.6866972;2.2693586;5.0475554;-1.1731998;-1.2548409;3.859845;-
center the item;-1.7479706;1.7581248;7.9566526;-1.7807523;-1.0294245;2.6956384;-
make sure the item is visible;-6.2837505;1.5300075;3.5321138;1.1689739;-1.5531616;2.112989;-
apply scroll position;-2.9806201;0.12268052;4.4487104;-2.5223832;-2.6008084;3.634179;-
calculate minimum size for each columns and rows;5.7426367;1.7241616;1.9496874;-5.432142;-0.21789661;-0.16423233;CODE
compute minimum size maximum stretch needed;3.1866868;2.3101673;2.3119829;-3.554121;-0.65747565;2.1219795;-
this can be further improved to reduce re comp but whatever;-1.980943;0.35792685;-0.28731364;2.4832397;-0.23855159;4.1685305;META
else size hint is none so check if it can be resized inplace;-1.8084111;4.1873255;0.8934785;-4.0607295;-2.2386835;3.502124;IRRE
layout won t shouldn t change previous size if size hint is none;-3.2453825;4.5329833;0.7611166;-0.8018624;-2.143743;4.677396;CODE
which is what w h being none means;-3.892803;1.9737321;-1.1280997;-1.0285112;1.0681484;-0.5817411;-
visible area is one row column;0.35136336;3.4190836;4.353757;-5.6073213;-0.82060885;1.627344;-
calculate grid dimensions;2.9312158;0.64133096;2.2383869;-6.95001;-0.7748406;0.37244752;-
limit index to valid range and handle negative indices;2.3463876;6.0545073;-0.9126372;-1.8988886;-0.043825503;-0.48543295;-
if cols rows not set calculate them;5.194115;5.853581;0.449817;-2.2879732;-0.96286434;-4.4102874;IRRE
calculate row and column of target index;4.723397;2.7313077;1.5338751;-4.545137;-0.02128854;-1.2527516;-
calculate total dimensions;2.320587;0.73119754;2.8167565;-6.9882793;0.3962849;-0.71072274;-
calculate total width and height of the grid;0.8231981;1.0184098;3.9961836;-5.4587746;-0.90134305;-0.3732901;-
right to left;-3.5383322;-1.2388263;6.3307214;-2.4562645;-0.3707172;-1.2820921;-
position at left of viewport;-4.074712;0.070686124;5.576112;-3.2597027;-2.148382;2.5874991;-
calculate base position from bottom;0.5631192;1.8533956;4.6160192;-4.8351007;-1.0961559;-0.6031406;CODE
position at top of viewport;-4.1215315;-0.51546216;6.024977;-2.845107;-2.6887808;4.1196876;-
adjust scroll position to center big widgets;-1.5613687;-1.1272405;3.5855737;-3.01081;-4.938985;4.803409;-
center wide widgets;-0.98770374;-1.9020507;5.044355;-3.1930552;-3.1957104;4.0912747;-
center tall widgets;-1.2290463;-1.0512828;4.41;-3.5255618;-3.3084686;4.0982785;-
apply scroll positions;-1.8889887;-0.022012254;4.985813;-3.551869;-1.7253815;3.3331273;-
at least one changed data unpredictably;3.8046308;2.0859563;-0.18665116;2.095523;-1.0254622;-2.0792778;-
if f for f in flags if not f need to redo everything;-2.2959213;4.992248;1.2477928;0.6015611;1.7066073;-1.4484828;CODE
first update the sizing info so that when we update the size;-1.4884292;0.415803;1.7294133;0.3183292;-1.7622991;2.5590124;CODE
the widgets are not bound and won t trigger a re layout;-4.595826;1.4404093;0.91824174;-1.1019673;-4.493703;4.944197;-
make sure widget is added first so that any sizing updates;-2.9176164;1.4463384;0.5450854;0.23769927;-5.020936;4.597352;TASK
will be recorded;-1.507163;-0.9879415;4.4189863;2.7846615;1.5484803;-1.7489647;-
then add all the visible widgets which binds size size hint;-1.3678086;0.9663982;2.8838995;-2.1506684;-1.9381276;5.477083;TASK
add to the container if it s not already done;-4.57631;3.2145932;4.885528;3.6345186;0.6815401;0.9750856;CODE
finally make sure if the size has changed to cause a re layout;-3.9967906;1.524819;2.5118885;-1.4920069;-2.9306684;5.2175975;CODE
we could use layoutchangeexception here but refresh views in rv;-4.1282964;1.5085365;1.242587;3.039814;-0.30355403;5.9856343;CODE
needs to be updated to watch for it in the layout phase;-5.3403206;-2.4612453;4.4180965;1.4792486;-1.6231325;3.989213;CODE
internals;-4.0143366;-2.3030775;5.733412;1.019813;1.5179479;-1.3261786;CODE
lm clear layout;-3.1188304;1.493251;3.2782252;-2.4961262;0.4732101;5.225874;-
if data we were re triggered so finish in the next call;-1.5696821;2.1627462;4.750432;5.2087502;0.49071446;-0.32351875;TASK
otherwise go until fully laid out;-2.896912;1.7360469;3.0302231;3.4360178;-1.3373849;1.0706567;CODE
if flags data in case that happened meanwhile;0.81047595;6.056268;2.4444249;2.571394;0.72792614;-2.3613887;CODE
make sure if we were re triggered in the loop that we won t be;-3.0351117;2.2211683;2.7065294;5.157306;-1.497644;-1.2520443;IRRE
called needlessly later;-3.777708;0.40163493;1.8718704;1.6752175;-0.7530216;0.49316078;IRRE
todo make this also listen to layoutchangeexception;-5.119503;2.7902153;1.9505067;2.6669455;-0.39942417;4.252863;CODE
dispatches the prop of this class when the;-4.1784124;-0.63756126;1.9051505;3.857473;4.233045;1.4884821;CODE
view adapter layout manager property changes;-4.314156;-0.09401121;0.9934327;0.51450783;-0.98872304;7.283128;-
now convert the sv coordinates into the coordinates of the lm in;1.8341858;-0.7043056;0.63284373;-5.7665;-1.5978124;3.560029;CODE
case there s a relative layout type widget in the parent tree;-3.7697117;-0.6849398;1.4490572;-0.85164976;0.86109495;4.704332;CODE
between the sv and the lm;3.4672785;-5.0708437;1.5097662;0.8156494;1.9448508;2.618237;-
or easier way to use;-2.0682733;-3.7918866;5.688306;2.2578263;2.3329206;0.9555395;-
whatever too complicated don t try to compute it;2.63288;-1.7885711;2.030659;-2.664118;0.94099325;-3.4258652;CODE
overwrite this method so that when data changes we update;-0.10038297;3.3571525;2.1489232;4.4759183;0.9302248;1.3919346;CODE
selectable nodes;0.74238676;-1.0979238;3.061332;-1.6721519;3.8045251;2.1964417;CODE
the indices of the data is used as the nodes;5.494671;-1.2460997;1.2324711;-5.989537;1.6914544;0.60345566;-
the indices of the data is used as the nodes so node;3.5605652;-0.6740468;0.7067392;-5.6221833;1.3709593;0.6376823;-
can be made more selective update than refresh from data which;0.5843931;1.2292202;2.5913389;3.8737025;0.93479985;3.6037083;CODE
causes a full update but this likely affects most of the data;-0.37731147;-0.22265588;-0.12871155;2.892009;-1.9268174;0.9903902;CODE
implement this method in the subclass recycleboxlayout;-1.8850058;1.1002636;0.69282943;-0.45797598;2.3256338;4.0776176;CODE
or recyclegridlayout;-3.1037548;-1.3194389;3.9949186;-2.1964302;0.84346086;5.6606603;-
resolve the real class if it was a string;-2.4208605;3.0691736;-1.7537895;2.3035264;2.7682784;-2.5600297;CODE
current number of unused classes in the class cache;0.18717061;-0.6897368;-0.29437718;2.433795;2.3123343;0.46540728;CODE
maximum number of items in the class cache;-0.059505176;0.32612827;0.6405826;1.7931057;3.3697195;0.5472992;CODE
all keys will be reduced to max size;-1.3874707;0.89980406;0.54182243;-2.4304726;-0.26923117;2.5745494;-
internals;-4.0143366;-2.3030775;5.733412;1.019813;1.5179479;-1.3261786;CODE
views current displayed items;-1.9979619;0.307016;5.2687416;-0.37654728;0.5449198;2.3642654;-
items whose attrs except for pos size is still accurate;0.8529049;1.9252442;0.5938587;1.1302097;0.040822927;1.5041302;CODE
is it in the dirtied views;-2.3325667;-2.4886146;3.3465993;0.9595769;-0.32189187;1.8137162;CODE
if viewclass in dirty views get it first from dirty list;-1.174595;1.8977642;1.2126089;2.7681446;2.0514357;0.8692528;CODE
we found ourself in the dirty list no need to update data;-2.144829;-1.3688095;-1.2038225;2.3277287;-0.96047515;0.39543957;CODE
global cache has this class update data;-2.286349;-1.008608;0.5457267;2.3386226;0.560735;2.690619;CODE
random any dirty view element update data;-0.28226897;1.3767334;1.9415745;2.3463364;0.61535007;2.1242888;IRRE
elif cached views viewclass otherwise go directly to cache;-2.783447;-0.6502066;-1.3693283;3.3575525;-0.12815215;4.3852654;IRRE
global cache has this class update data;-2.286349;-1.008608;0.5457267;2.3386226;0.560735;2.690619;CODE
iterate though the visible view;-1.6472926;1.649815;5.8518686;0.36565357;0.20936374;2.8728194;-
add them into the container if not already done;-3.0972779;2.0836892;3.7807372;1.3694351;1.3553818;1.0517312;CODE
if view is not none was current view;-3.2815254;4.2487626;1.7377948;2.1976433;-0.40808794;1.2169218;CODE
pos self pos incorrect;-3.2606509;1.5324872;0.2331653;0.022843536;-0.66573155;-2.0470212;CODE
handle some additional roles;-3.3343754;-1.6735939;3.3402898;0.5046621;2.3164318;1.6846913;TASK
import parse color kivy parser parse color;-2.3935285;-2.456614;-2.4306548;-0.29628175;-1.2824595;-0.5421004;IRRE
rgb parse color cccccc;-0.8647602;-1.1157722;-1.1003462;-3.4723697;0.77940613;-0.56988525;IRRE
rgb parse color eeeeee;0.09737981;-0.96323043;0.032805465;-3.5130978;0.41866055;-0.63911533;IRRE
internals;-4.0143366;-2.3030775;5.733412;1.019813;1.5179479;-1.3261786;CODE
set the documentation root to the directory name of the;-8.099897;-3.8699186;-0.3556944;1.5028177;-1.4564664;1.7237879;IRRE
first tile;-2.11877;1.8831272;6.132094;-2.8826199;0.17160685;-0.4682754;-
parse the source;-0.77535003;-2.4457018;2.1351573;-0.59374607;1.7100145;-2.9877872;IRRE
fill the current document node;-3.6025455;-0.3228816;4.9636703;0.90572613;1.6654804;1.6362457;CODE
clear the current widgets;-4.5237417;0.71635664;3.57012;1.1263899;-3.05606;3.6010637;-
parse the source;-0.77535003;-2.4457018;2.1351573;-0.59374607;1.7100145;-2.9877872;IRRE
fill the current document node;-3.6025455;-0.3228816;4.9636703;0.90572613;1.6654804;1.6362457;CODE
check if it s a file;-4.73909;1.5302231;0.27260324;1.2068497;-1.3389956;-3.570376;IRRE
whether it s a valid or invalid file let source deal with it;-6.323756;1.4376749;-3.0115836;1.3897762;-0.5864554;-2.4283452;CODE
get the association;-1.8919766;-1.8275522;2.083094;1.0325072;2.8236775;-0.8743954;-
search into all the nodes containing anchors;0.73716974;0.55368835;1.9636989;-1.2323941;1.6068507;0.24470128;CODE
not found stop here;-5.559852;-0.91466403;2.867108;-0.53578836;-2.5988483;-2.8976817;-
found calculate the real coordinate;-1.3840711;1.886383;2.9338367;-5.35651;-4.3674893;-3.007215;-
get the anchor coordinate inside widget space;-2.8347805;1.126498;3.8820417;-2.3389432;-3.432188;3.835606;-
ay node y;-0.97645944;-1.3982825;3.2895448;-4.733695;-3.1491547;-2.5103645;-
what s the current coordinate for us;-1.0368909;-0.74253124;3.9911911;-2.9070978;-2.3855245;-0.08701374;CODE
ax ay self scatter to parent ax ay;0.56579584;-0.32792208;0.9700679;-4.4078298;-4.590852;3.2634459;CODE
store refblock here while building;-4.104122;1.5133333;3.6815403;2.142098;-0.74248636;2.6099463;CODE
store order for autonum sym footnotes refs;-2.2321494;1.5218617;0.033479027;0.10824019;1.7955317;1.307888;TASK
last four default chars aren t in our roboto font;-4.097969;-0.81034166;-0.60567504;-2.0191193;-0.8670069;-0.5388266;CODE
those were replaced with something else;-4.107956;-1.8940362;2.3758824;-0.11254059;0.49392784;0.9684925;-
u002a asterisk;-3.4664257;-2.1734314;0.3587624;-1.8057218;2.625898;-2.1654308;-
u2020 dagger;-3.5330398;-0.95097524;1.542143;-3.6481476;0.39501017;-1.3077766;-
u2021 doubledagger;-2.339491;-0.65848607;0.45906675;-2.470034;-0.47186297;-1.5366472;CODE
u00a7 section;-3.4014924;-2.137376;3.1037924;-0.97161096;2.4638069;-0.59107554;-
u00b6 pilcrow;-3.6716173;-1.3039417;2.7785976;-3.401283;-0.22799148;-1.6465615;-
u0023 number;-3.2326007;-0.82603765;0.78723055;-2.3288274;0.5367184;-3.1784759;-
u2206 cap delta;-2.4826853;0.7406098;1.237092;-3.0498245;0.22779928;-1.1744493;-
u220f cap pi;-2.5259554;0.027392665;2.1860425;-2.7064056;-1.628161;-1.7361543;-
u0470 cap psi;-3.059904;0.6483961;0.26712537;-2.715632;-0.4509281;-1.7409157;-
u0466 cap yus;-3.5567958;-1.0493574;1.0566097;-3.9190865;1.2016695;-3.4240422;-
get foot cit refs manually because the output from;-2.2028394;3.0953944;-0.020838087;2.7250104;-1.002984;0.5852043;IRRE
docutils parser doesn t contain any of these;-4.4974713;-1.082157;-4.0915046;0.5864676;0.92658406;-1.8085183;CODE
node s refid refname backref and or are just;-3.3573024;0.7048407;-1.1274431;-0.30350202;2.9938447;1.5514436;CODE
backref true is used in nodes footnote;-2.841295;2.1429465;-1.2889335;1.6563195;-1.6102889;1.5351418;TASK
auto is either 1 int or;-3.0527408;1.7900746;0.4447677;-1.8997865;1.2605188;-3.42804;CODE
these are unique and need to go first;-0.69390607;-0.5256623;5.187331;-0.7881069;4.9956346;-1.0331736;TASK
autonum autosym are unique;-1.1248037;2.1340604;-2.045104;-0.10857257;3.0914567;-1.024878;-
it can be e g image or something else too;-3.3687527;-3.1102927;4.899806;-1.4473873;0.43589216;1.701668;IRRE
x footnote;-3.4510262;-0.5444928;3.0632207;-1.3973886;-0.5395052;-1.4007014;TASK
check if its autonumbered;-3.3431764;4.8642983;0.16092144;3.7755404;1.3763328;-1.6786245;IRRE
auto is either 1 int or;-3.0527408;1.7900746;0.4447677;-1.8997865;1.2605188;-3.42804;CODE
can have multiple refs;-2.0894012;1.256775;3.5499926;2.3194733;3.5201042;0.67687786;-
8 1 2 footnote ref;-4.2982755;1.1913592;1.568485;-0.53236204;-0.45001245;-2.119953;TASK
we can have a footnote without any link or ref;-5.0422993;-0.8734585;1.7733234;2.0744228;-0.7885772;0.9307678;TASK
1 empty footnote;-4.5592933;3.2178817;-0.35245723;-0.29871386;-1.6051943;-2.3017528;TASK
handle no refs;-3.2270408;3.2618039;3.3052275;3.1988852;-1.6697112;-0.48482215;-
colorize only with refs;-0.43497103;1.3202085;2.6674745;1.055505;0.54328084;3.1195807;-
has no refs;-3.6136067;2.0516598;2.7029274;2.6301594;-2.4859626;-1.689878;-
list of refs;-2.1121109;-1.8847871;3.2813087;2.3232422;1.4051056;-1.54385;-
1 1 2 footnote;-3.0792634;0.66307765;2.3256278;-1.6945082;0.3743166;-3.537032;TASK
single ref;-1.8536419;1.3030367;3.9022257;2.177819;1.3314514;-0.5655438;-
give it anchor event manually;-5.712529;-0.11738356;4.1002707;2.790853;-2.606134;4.8721576;-
check if its autonumbered;-3.3431764;4.8642983;0.16092144;3.7755404;1.3763328;-1.6786245;IRRE
auto is either 1 int or;-3.0527408;1.7900746;0.4447677;-1.8997865;1.2605188;-3.42804;CODE
can have multiple refs;-2.0894012;1.256775;3.5499926;2.3194733;3.5201042;0.67687786;-
8 1 2 footnote ref;-4.2982755;1.1913592;1.568485;-0.53236204;-0.45001245;-2.119953;TASK
parser should trigger it when checking;-4.0644817;4.6633706;-2.691725;4.6316533;0.67232126;-2.965549;IRRE
for backlinks but we don t have any refs;-4.589117;-1.0682952;2.7639794;1.9008594;-0.16850278;1.5662315;CODE
to work with so we have to trigger it manually;-5.3318806;-3.6396186;2.7660468;3.6926534;-0.3743559;1.1556345;-
has a single or no refs;-2.6540287;2.1340048;1.9000362;2.8320384;0.059393916;-1.3281907;-
assert self text;-2.3153963;4.5388255;-1.3107421;4.9849544;0.99654615;-4.43387;CODE
check if parent isn t a special directive;-4.722111;4.9409966;-0.48647514;2.9314463;2.115023;0.91856056;IRRE
ref replace something;-3.8515508;2.4279222;3.917971;2.5433228;0.524909;-0.6801593;-
ref;-3.6667383;1.1504012;4.8376017;2.6893897;-0.35862154;-1.7474428;-
comment;-3.2438884;-0.3641724;4.814371;2.013918;0.46966788;-2.9296966;-
rewrite it to handle autonum sym here;-3.481661;2.8806875;-0.965564;0.32109213;2.9158413;-0.43367773;TASK
close tags with departure;-2.7972307;0.649305;4.0109854;1.5820078;1.5890425;1.5503858;IRRE
self do strip text false;-4.3257637;3.7711618;0.50172204;0.52040714;-2.3242557;-0.569235;CODE
docutils parser breaks path with spaces;-4.067333;-1.1059376;-1.8799156;1.471162;-0.672161;-0.17280214;CODE
e g c my path c mypath;-4.442215;-2.406227;3.1402748;-0.9665583;1.842626;0.27722263;-
use user s size if defined;-0.22879663;4.2972484;1.4696977;-0.8746024;1.4981184;-0.6274003;CODE
todo;-3.4879296;-1.2275677;4.9053526;0.9818142;-0.81314033;-1.7930582;TASK
img url;-3.0819566;-0.7314517;4.2844877;-0.44189212;-1.5930088;0.21511506;-
img image img;-2.1142642;-0.34961542;4.5706205;-1.7999171;-0.90938115;0.48824364;-
img needs refs and on ref press;-4.290807;1.4545584;4.5849323;2.6773543;-2.825787;1.9062365;TASK
close opened footnote x;-5.0374575;0.82617486;1.7626507;0.6183778;-1.3043269;0.6166167;CODE
self text ref;-4.987141;-0.80877143;2.612693;1.5205985;1.0487509;-0.7380708;CODE
self set text self current link;-4.9158387;0.60335964;3.1804845;0.7411169;0.3085042;2.8095486;CODE
self text color ref;-4.163682;-0.19487406;2.0017545;-0.66030973;0.12527332;0.6848911;CODE
try to preload it;-5.967024;-0.5596785;1.8742789;2.0061657;-3.5987144;2.2619963;CODE
if exist use the title of the first section found in the;-6.0604067;2.660209;2.2593992;2.4741879;3.9991806;-2.2953615;IRRE
document;-5.3167543;-4.2837205;5.43495;0.6113514;3.318797;-2.3599281;CODE
replace the text with a good reference;-2.831084;0.24669664;2.536185;1.0124792;0.8141473;-1.0129594;CODE
search anchors;-1.0482699;-2.1940267;2.8978004;1.512106;0.91785043;1.0160049;-
force sandboxclock s scheduling;-2.5419424;-0.31520578;-0.52550596;3.3040762;-1.702888;2.0603468;CODE
import pdb pdb set trace;-1.1817963;-1.6393924;-2.8815744;-2.3049636;-1.8058326;0.048652;CODE
raise exception fdfdfdfdfdfdfd;-4.257274;4.4771576;-3.8536453;4.2098827;-0.19689369;-1.3023533;CODE
raise exception;-3.7995334;5.6346545;-0.6691941;5.5775633;0.44163236;-1.7165868;CODE
invalid for testing;-3.4935641;5.1371465;-4.840784;3.456599;-1.9835234;-8.001991;IRRE
on touch up root d;-5.0443954;-0.7660877;4.383071;0.035208467;-0.9944375;-1.0765072;-
on touch down root f;-5.1652117;-0.15348358;4.749896;-0.14675248;-2.0189192;-1.1643822;CODE
on press root args;-7.4436445;0.24800225;2.7804115;1.3080944;-2.636264;-0.9621151;IRRE
this exception is within the with block but will be ignored by;-5.566146;5.4517703;-3.4809778;3.279212;-0.5050583;-0.56623477;CODE
default because the sandbox on exception will return true;-4.8141575;3.0270214;-2.1565127;5.5379195;-2.153882;0.38963065;CODE
the children are positioned relative to the scatter similarly to a;0.7930107;-1.2223254;7.2140512;-2.5730994;-1.8189626;0.7403314;-
the scatter size has no impact on the size of its children;1.1099801;0.797446;1.9467254;-0.04107487;-2.329467;1.9021096;-
if you want to resize the scatter use scale not size read 2 scale;2.633692;0.7845358;1.494356;-5.3472376;-5.1959877;4.5052404;CODE
the scatter is not a layout you must manage the size of the children;-0.63631475;-1.49405;5.7652397;-3.5067358;-1.3949132;3.2408636;-
x y lower left corner;-3.0360835;-0.32488778;5.5968447;-7.115434;-2.7303739;-1.3169082;-
xxx float calculation are not accurate and then scale can be;1.7486098;4.362995;-0.6160653;-3.8778222;-5.975623;-0.30099103;META
thrown again even with only the position change so to;-3.195164;4.037211;3.3222568;2.0200431;-1.7244477;-0.9718091;CODE
prevent anything wrong with scale just avoid to dispatch it;0.7587977;2.136956;0.2341345;3.2203603;-2.95725;4.988053;META
if the scale visually didn t change 947;1.0799723;1.6557022;2.9464808;-0.13766497;-2.9023602;0.9652548;-
remove this ugly hack when we ll be python 3 only;-5.2314196;-2.8557827;-2.701959;-0.08008823;-2.7839656;-1.8261474;CODE
just do a simple one finger drag;-3.3161173;-0.9674582;5.610179;-1.1077746;-1.5665869;1.9971606;CODE
last touch pos has last pos in correct parent space;-4.5521116;2.339343;3.0364237;-0.8168478;-0.7591683;1.6453439;-
just like incoming touch;-3.9584048;-2.158405;7.48736;3.2067513;-0.53550446;1.0422413;-
we have more than one touch list of last known pos;-1.3175267;-1.3155491;3.2067246;2.147974;1.7624618;-0.41201776;-
add current touch last;-4.198681;1.3899133;6.78533;0.8814683;-1.2275984;1.1538812;TASK
we only want to transform if the touch is part of the two touches;-2.209494;1.0872402;6.1867657;-0.3651392;-1.1295815;3.1354656;CODE
farthest apart so first we find anchor the point to transform;0.83858633;0.5879236;5.2625513;-3.7329283;-2.5887449;2.4294405;CODE
around as another touch farthest away from current touch s pos;-1.4491963;-0.08526838;5.8261642;0.50324434;-1.6664002;1.3359889;CODE
now we find the touch farthest away from anchor if its not the;-2.6377985;-0.20900543;5.2917986;1.9377614;-3.4779222;2.5243187;CODE
same as touch touch is not one of the two touches used to transform;-2.9654644;-1.1426086;5.007509;-0.936197;-0.991669;2.687341;OUTD
ok so we have touch and anchor so we can actually compute the;-1.7742288;-0.7086101;6.5294337;-0.6963025;-1.7451351;-0.15034796;META
transformation;-0.9362786;0.13174681;6.1401076;-3.5484586;-1.7096213;-0.50837165;CODE
if not old line length div by zero;-2.1655223;4.8827415;2.4690952;-4.0681906;-2.5669057;-1.8327264;-
auto bring to front;-4.722234;0.14562559;5.0716953;2.6222544;0.54330707;2.819711;-
if the touch isn t on the widget we do nothing;-4.5947;0.7081352;5.4628315;2.2082584;-4.483595;1.4008642;CODE
let the child widgets handle the event if they want;-3.415906;0.47073188;4.4210205;1.7939191;-1.9869603;4.0072007;CODE
if our child didn t do anything and if we don t have any active;-3.2055495;2.9051266;2.0598454;3.0850463;-0.08826742;-0.48988515;CODE
interaction control then don t accept the touch;-5.486884;1.6195958;3.7291782;2.2865703;-3.2887714;2.494371;CODE
grab the touch so we get all it later move events for sure;-4.2852707;-1.5037422;7.610882;3.2424495;-2.3141067;3.131723;CODE
let the child widgets handle the event if they want;-3.415906;0.47073188;4.4210205;1.7939191;-1.9869603;4.0072007;CODE
rotate scale translate;-0.0666745;0.30133572;4.091899;-4.2921596;-4.155785;2.4634054;CODE
stop propagating if its within our bounds;-0.5767172;1.6465763;2.6237924;4.0599566;-1.5624428;2.19592;-
if the touch isn t on the widget we do nothing just try children;-4.1964707;0.3500267;5.031642;2.2076733;-3.6963055;0.90010655;CODE
remove it from our saved touches;-5.8224983;0.40428486;5.1447597;1.0407923;-3.552923;3.8191247;CODE
stop propagating if its within our bounds;-0.5767172;1.6465763;2.6237924;4.0599566;-1.5624428;2.19592;-
create the manager;-4.1318545;-3.2987356;4.599203;0.92184865;-0.064130686;0.6810876;IRRE
add few screens;-3.6604898;-0.48997405;6.662938;-1.8928701;-0.6461547;1.2055757;TASK
by default the first screen added into the screenmanager will be;-4.5010047;0.64086753;2.1042254;0.91931295;-1.0633209;4.500255;CODE
displayed you can then change to another screen;-5.4771447;0.98393124;7.0645576;-1.1191047;-0.98776793;3.0367758;-
let s display the screen named title 2;-6.6329145;-0.1488144;6.031197;-2.493012;0.33528826;-0.56309414;CODE
a transition will automatically be used;-3.8000758;-1.5528665;5.5162487;3.250225;1.307108;2.5569072;IRRE
create both screens please note the root manager current this is how;-5.0632415;-0.5272643;5.054494;-1.6547986;-1.3517988;3.671709;TASK
you can control the screenmanager from kv each screen has by default a;-2.427482;-0.31376085;3.3258655;-0.33362383;-0.35707453;4.9708295;CODE
property manager that gives you the instance of the screenmanager used;-4.0250044;-2.1953466;3.0970252;1.4506103;0.7097859;4.3473625;-
declare both screens;-4.41749;1.5362828;3.6378555;-1.5366553;1.6220583;1.5705906;-
create the screen manager;-4.477808;-3.6311796;4.9695206;-1.1074108;-1.1754131;2.656301;IRRE
later;-2.726311;-2.1820984;7.2767243;3.571628;0.35708508;-1.4124526;-
privates;-2.2839003;-1.366881;4.3143644;0.095375486;1.2098954;-2.093083;CODE
create your own transition this shader implements a fading;-2.4590592;-1.1413596;3.1389575;-1.5019356;-0.21523264;3.5145657;TASK
transition;-1.9088612;-1.4185138;7.6765404;1.1792696;0.27917886;-1.3379316;-
and create your transition;-2.2802286;-2.2578094;6.187828;1.9500363;1.2131941;-0.72085714;IRRE
ensure that the correct widget is on top;-3.4506552;2.122351;3.4053357;0.5854263;-3.824403;4.8774743;-
by default the first added screen will be shown if you want to;-5.575215;0.18275426;4.406764;0.40278447;-1.5819826;4.4853196;TASK
show another one just set the current property;-3.0939844;3.7690737;5.6729536;1.3002608;2.7219627;2.3595986;IRRE
by default the first added screen will be shown if you want to;-5.575215;0.18275426;4.406764;0.40278447;-1.5819826;4.4853196;TASK
show another one just set the current property;-3.0939844;3.7690737;5.6729536;1.3002608;2.7219627;2.3595986;IRRE
iterate over a copy of screens as self remove widget;-2.3334296;1.5732772;3.8167965;-0.6461517;-2.3831034;3.0543776;CODE
modifies self screens in place;-5.225794;-0.43920133;4.763881;-0.11731154;-2.6434777;4.7963977;CODE
ensure screen is removed from its previous parent;-4.644888;3.1122663;4.1239276;1.1027985;-1.3664194;4.1164765;OUTD
later;-2.726311;-2.1820984;7.2767243;3.571628;0.35708508;-1.4124526;-
later;-2.726311;-2.1820984;7.2767243;3.571628;0.35708508;-1.4124526;-
stop any transition that might be happening already;-2.482465;1.9889449;3.0753615;4.180121;-1.9789853;1.2496517;CODE
ensure the screen name will be unique;-3.6954424;0.69728315;2.1577635;0.42324093;1.5344737;2.0978658;-
change the transition if given explicitly;-1.9763591;3.9714534;2.8488486;0.2366131;-0.17239906;1.402146;-
change the transition options;-3.9543037;0.5656312;5.289102;-0.071085274;0.22016622;3.2652013;-
add and leave if we are set as the current screen;-5.5370703;2.7771707;6.704878;0.60258424;-1.1765714;2.5533154;TASK
d left up down right;-2.9331686;1.412809;5.848337;-3.3285935;0.52710634;-2.283741;CODE
di d index self sm transition direction;0.63560617;0.5898984;-0.1779735;-2.8312287;0.28806815;2.8043022;CODE
self sm transition direction d di 1 len d;-0.45442352;0.18920423;1.6860384;-4.1438646;-0.45805973;1.3017565;CODE
state machine enums;-0.10314463;1.1870418;1.1728739;-0.30864805;3.948342;0.022232212;-
touch intent detection state machine;-0.791129;-1.5423291;3.5898163;1.9905428;1.0812612;0.86779696;CODE
tracks whether a touch gesture is a tap click or a scroll gesture;-0.44184107;-1.341739;3.0735092;3.3682535;-1.5968533;1.1656816;CODE
based on movement distance and timeout thresholds;3.6946132;-0.90216804;3.9465992;1.6793052;-0.7284216;1.0367255;CODE
state transition diagram;-1.4271176;-0.059533674;4.9737644;-1.4098822;1.3231045;0.28641173;-
movement scroll distance;-0.45411944;-0.5668678;4.9368896;-3.033692;-3.4964118;1.8500507;-
unknown scroll;-5.712593;-0.33713552;3.2332728;-2.175829;-4.001989;1.1206584;-
timeout expires;-4.1453676;1.3378124;0.59930646;1.7997421;-3.472895;-0.7235192;-
try simulate touch down;-2.6395018;-0.91569763;7.060505;0.9523948;-3.6787074;1.600845;CODE
child grabbed no child grabbed;-3.4325182;2.6163917;2.529197;0.7564678;-1.273065;-0.7120608;-
hand off to child transition to scroll mode;-3.956598;0.24251632;4.540393;-0.77247274;-2.274394;4.9965653;CODE
button etc label empty space etc;-5.879502;0.10747362;2.915136;-1.3695803;-0.03383374;1.4117452;META
state descriptions;-1.3661889;-1.5859733;3.1240888;0.47629347;5.2754564;-0.45323306;META
unknown initial state accumulating movement to detect intent;-2.9762802;1.3307409;0.98381406;1.8299994;-0.52376586;0.61545444;IRRE
scroll scroll gesture confirmed either movement exceeded threshold;-2.3130116;2.1096132;-1.7173818;0.33193254;-5.3596764;1.9894289;-
or timeout expired without child widget consuming the touch;-4.8515787;0.9810804;4.404825;3.5553775;-2.9638684;3.9915283;-
unknown unknown detecting intent accumulating movement;-2.5341895;-0.6635632;0.84106046;0.9669805;-0.4968597;0.87411356;CODE
scroll scroll confirmed scroll gesture movement exceeded threshold;-1.681503;1.228612;-1.888071;0.4971389;-4.8113737;2.83143;-
this addresses issues 1464 and 1499 for low performance devices;-2.009611;-1.6197213;-2.8979602;1.0064784;-0.53101915;-0.49757954;CODE
then use the s as a widget;-2.1465578;-2.9326892;5.894726;-0.5598703;-0.24856684;2.9419036;IRRE
internal class not documented;-6.3048368;-4.1887794;-3.178463;1.582678;2.0040777;0.11997463;CODE
get current value in config;-2.3304083;3.4542558;1.8683591;0.40535828;0.02652878;1.1756964;IRRE
create popup layout;-3.1999454;-1.7502824;6.696847;-3.485107;0.78276294;2.5489097;IRRE
create the textinput used for numeric input;0.46284932;0.03958;1.6671315;-3.4569871;-1.5720047;-2.4713712;CODE
construct the content widget are used as a spacer;-3.2142124;-0.75717694;3.952787;-1.7450333;0.045736525;4.5331416;CODE
2 buttons are created for accept or cancel the current value;-6.2135468;3.1314774;3.2991927;-0.5221379;-0.93099284;-0.05745925;IRRE
all done open the popup;-5.306342;-2.1096241;5.028184;1.4755951;-2.950534;-0.23978038;CODE
create popup layout;-3.1999454;-1.7502824;6.696847;-3.485107;0.78276294;2.5489097;IRRE
create the filechooser;-5.24858;-1.8802545;2.2106786;0.676076;0.1851415;0.34675312;IRRE
construct the content;-3.3577063;-1.8772581;6.003992;-0.4215021;5.0443945;-0.9702587;CODE
2 buttons are created for accept or cancel the current value;-6.2135468;3.1314774;3.2991927;-0.5221379;-0.93099284;-0.05745925;IRRE
all done open the popup;-5.306342;-2.1096241;5.028184;1.4755951;-2.950534;-0.23978038;CODE
create popup layout;-3.1999447;-1.7502824;6.6968484;-3.4851077;0.7827621;2.5489097;IRRE
2 buttons are created for accept or cancel the current value;-6.2135468;3.1314774;3.2991927;-0.5221379;-0.93099284;-0.05745925;IRRE
all done open the popup;-5.306342;-2.1096241;5.028184;1.4755951;-2.950534;-0.23978038;CODE
we know the type just by checking if there is a in the original;-1.8970325;0.5687182;-1.3724478;2.0050893;3.04266;-1.941658;CODE
value;-0.69988436;2.4135733;5.148833;-1.763415;2.0859022;-6.1452317;IRRE
create the popup;-5.2102866;-2.932962;6.1616764;-0.047271278;-0.60148954;0.33710396;IRRE
add all the options;-3.608179;-1.0474467;6.4341974;-0.19745848;2.0168774;-0.142164;TASK
finally add a cancel button to return on the previous panel;-4.8835754;2.820862;3.9566648;1.233297;-2.3458643;3.686432;CODE
and open the popup;-5.1882415;-3.2355335;5.0694327;1.2550775;-2.7059696;1.3326643;CODE
return false new uid doesn t exist;-5.697377;5.5370345;-3.923463;3.0400586;0.21899077;-0.9093673;CODE
determine the type and the class to use;-0.82875514;-0.5837664;0.995007;-1.1400791;4.8992634;-3.92792;IRRE
create a instance of the class without the type attribute;-1.7561022;0.5411056;0.004734525;1.2636751;3.6665666;1.5840763;IRRE
instance created add to the panel;-5.145366;-0.3948234;2.7748063;1.3488889;0.57728094;2.2968707;TASK
internal class not documented;-6.3048368;-4.1887794;-3.178463;1.582678;2.0040777;0.11997463;CODE
config setdefaults colorselection testcolor ff0000;-3.7966292;2.665691;-2.4889314;0.62556607;-1.5051706;0.7203662;IRRE
the following two methods constrain the slider s value;0.45901722;3.3678997;1.454274;0.06652066;0.22068173;3.1761026;CODE
to range min max otherwise it may happen that self value self min;0.30267474;4.566593;-0.067484595;-1.191676;-0.06654107;0.17545722;IRRE
at init;-3.754013;-1.7399292;2.8254545;1.593162;-0.15742703;-0.1292644;IRRE
default value shown;-3.7227345;2.8490055;2.0278716;-2.117573;-0.8992533;0.336787;IRRE
available values;2.4446642;3.1812346;3.182188;-1.1087433;4.0930395;-3.4111202;IRRE
just for positioning in our example;-1.2783254;-1.6940584;7.191597;-0.29097596;1.8586568;0.48961183;CODE
remove any previous binds;-4.9093285;3.6541681;2.106858;0.36588866;-0.27655706;3.993187;-
optimize layout by preventing looking at the same attribute in a loop;2.9877346;3.9643052;2.862445;0.38064522;1.9661139;3.4157414;IRRE
determine which direction and in what order to place the widgets;-1.6739163;-0.8371629;5.8230677;-3.296376;-0.7140217;2.5466573;CODE
left to right;-2.9431427;-1.2822574;7.095874;-3.6310978;0.25670806;-2.1121588;-
bottom to top;-3.508756;-1.2113509;7.5712547;-2.0203452;-0.71640605;-0.5321998;-
right to left;-3.5383322;-1.2388263;6.3307214;-2.4562645;-0.3707172;-1.2820921;-
top to bottom;-2.8019497;-1.2993901;8.286159;-2.3279145;-0.28467605;-0.7632661;-
u ustart inner loop position variable;-0.30304527;2.456599;2.4330094;-3.6942666;-2.2265232;-0.43805048;IRRE
v vstart outer loop position variable;0.15628974;2.2395234;0.5453973;-3.145412;-1.4279332;1.2202617;IRRE
space calculation used for determining when a row or column is full;3.176581;2.8936012;0.92019576;-4.062534;0.06559264;-2.1994991;CODE
v padding y size in v direction for minimum size property;2.2901316;0.81136537;0.8966745;-5.0205536;-2.1217535;3.4530303;TASK
u padding x size in h direction;-1.157576;1.0032248;2.4400718;-6.0736346;-1.8781514;2.325491;TASK
v padding x size in v direction for minimum size property;2.2373683;1.2715211;0.71470916;-5.13392;-1.2175641;4.053426;TASK
u padding y size in h direction;-1.2360388;0.45411298;2.8284352;-5.672631;-2.9528897;1.3246697;TASK
space calculation row height or column width for arranging widgets;1.7192856;0.49961618;2.1214848;-5.4109287;-1.3029689;1.7319269;CODE
does the widget fit in the row column;-0.011957409;0.5478414;3.306916;-3.3277755;-2.1444504;2.8369749;CODE
no space left but we re trying to add another widget;-4.6682663;1.2702813;4.3409815;-2.2875602;-3.087036;1.5343503;TASK
tiny value added in order to avoid issues with float precision;1.2275594;3.3810112;-1.2787703;-2.6894493;-3.5817425;-0.87637055;CODE
causing unexpected children reordering when parent resizes;-2.3830836;2.9676425;1.0438695;-0.46014714;-2.3791544;2.9265344;-
e g if size is 101 and children size hint x is 1 5;0.0533871;2.9118242;3.485935;-1.66882;2.2106204;-3.0967937;CODE
5 children would not fit in one line because 101 1 5 101 5;-0.845986;3.7039497;2.7892063;-2.3971324;1.1881729;-2.5728889;-
even if there s no space we always add one widget to a row;-1.5981858;2.3604083;4.3456545;-1.4630631;-1.0626159;2.952013;CODE
apply the sizes;-0.36661163;0.10304917;4.8682737;-1.5541061;0.5175651;-0.056747243;-
push the line;-3.6593897;0.7824485;7.6048594;-0.2609868;-2.5961206;-1.9881114;-
v position is actually the top right side of the widget;-4.551861;-1.0932784;3.5915468;-2.7743645;-3.8167307;3.0566316;META
when going from high to low coordinate values;2.849841;1.9419048;1.1025141;-4.5592117;-3.330487;1.7238535;IRRE
we need to subtract the height width from the position;-0.6317074;3.1552866;5.0492325;-4.4918256;-1.5537069;1.2407869;TASK
apply the sizes;-0.36661163;0.10304917;4.8682737;-1.5541061;0.5175651;-0.056747243;-
push the last incomplete line;-3.7201443;3.7327836;4.0147715;-1.0965279;-1.6773393;-1.9781169;CODE
depending of the distance activate by norm pos or invert;2.8601978;1.625392;2.2652934;-2.4497166;-1.3533547;3.9680605;TASK
tp clear widgets to clear all the widgets in the content area;-3.6813269;1.005415;2.9160116;-0.09786147;-1.6288707;3.1485078;CODE
tp clear tabs to remove the tabbedpanelheaders;-4.24507;1.3849225;0.8221366;-0.8485574;-1.6720049;3.5605807;CODE
background color 1 0 0 5 50 translucent red;-3.163016;0.5521221;2.9856398;-4.1376247;-0.78284925;-0.95550805;-
rgba 0 1 0 1 green;-1.1415912;1.1965048;1.7158296;-4.8980975;-0.1785377;-1.3506235;-
only allow selecting the tab if not already selected;-3.4563856;2.8526576;2.4073594;2.5644283;0.31737122;2.3658519;CODE
dispatch to children not to self;-4.5822473;1.163347;2.3790705;3.1772933;0.41820624;1.3352228;CODE
tabbed panel header is a child of tab strib which has a;-6.0505495;0.29412276;1.4442145;-1.7733674;0.38042793;2.4615135;CODE
tabbed panel property;-2.9545605;1.0121362;3.5267217;-1.4483992;-0.44637072;3.9624705;-
tab removed before we could switch to it switch back to;-6.5212603;0.8118251;2.9577646;0.35276455;-2.5550644;3.1076112;CODE
previous tab;-5.505162;0.47811344;6.209881;0.9179551;-0.41610554;1.2526655;-
other settings;-4.663743;-1.9775409;4.981105;1.0558316;-1.4463795;3.2998552;IRRE
these variables need to be initialized before the kv lang is;-3.547292;1.3831806;-2.3458102;-1.2951493;-0.56628436;0.2588311;IRRE
processed setup the base layout for the tabbed panel;-2.8117;-0.20060316;3.3784192;-3.2311106;-0.08719172;5.195925;IRRE
https github com kivy kivy issues 3493 issuecomment 121567969;-5.670783;-2.337695;-2.4290016;0.30078575;-5.2214866;-0.18664764;CODE
if content has a previous parent remove it from that parent;-2.9234812;4.031286;3.1972902;1.4648386;2.0695755;0.77964306;CODE
ensure canvas;-3.8195364;1.6829443;3.7426074;1.4635208;-3.7970479;1.9438759;-
no need to instantiate if class is tabbedpanelheader;-3.7671893;2.5612113;0.35410058;1.6905633;0.10317551;2.9416318;CODE
cache variables for faster access;-0.40056568;-0.63818717;1.5483186;1.8609794;2.2633865;2.791371;CODE
update scrlv width when tab width changes depends on tab pos;-2.5044434;1.4628178;-0.26384777;-1.2287841;-2.02912;4.0977597;CODE
remove all widgets from the tab strip;-3.4251547;1.5867085;2.493584;-0.8822771;-2.6057456;3.047769;CODE
bottom or top positions;-1.413532;-0.19500999;6.938871;-2.4823375;0.8462409;0.26081452;-
one col containing the tab strip and the content;-2.0461776;0.7329334;4.828217;-4.058527;0.70005417;-0.5937063;-
tab layout contains the scrollview containing tabs and two blank;-4.8260574;1.3307936;0.9470921;-2.6182175;-1.7310255;2.309006;-
dummy widgets for spacing;-0.65732366;-0.15767796;3.0872104;-2.0011296;-0.9000413;2.7408752;CODE
bottom;-2.5681274;-1.0690482;7.385418;-2.2228417;-0.74206156;-2.3471942;-
add two dummy widgets;-2.4550388;0.8596669;3.0554416;-1.4607041;0.021380816;2.7247937;TASK
top;-2.3651862;-2.3254008;6.275359;-1.0995518;0.50633377;-2.0451756;-
left or right positions;-2.204606;-0.41267738;6.9638233;-2.50005;0.85047203;-1.1033945;-
one row containing the tab strip and the content;-2.105046;2.3601103;5.2861323;-3.6222124;1.2564076;-1.3106805;-
tab layout contains two blank dummy widgets for spacing;-3.8689563;2.485072;-0.19160749;-2.8223712;-2.6523042;2.2028332;CODE
vertically and the scatter containing scrollview;-0.33634627;-0.9926376;4.156911;-4.168244;-3.4841568;3.9767237;IRRE
containing tabs;-3.4533784;-0.85581845;3.773308;-0.7530371;3.1931922;-0.12004377;-
rotate the scatter for vertical positions;1.0334666;-0.33689585;4.0685377;-6.2219653;-4.5769506;2.2956433;CODE
update scatter s top when its pos changes;-0.1242487;-0.39086357;2.5182273;-0.3060852;-3.1147158;4.567237;CODE
needed for repositioning scatter to the correct place after its;-0.7845782;-0.2907572;4.881925;-2.524971;-3.440675;3.895018;CODE
added to the parent use clock schedule once to ensure top is;-4.21432;1.2855616;3.388714;2.5644069;0.22018632;2.2773552;TASK
calculated after the parent s pos on canvas has been calculated;-0.6255072;2.9167972;4.1512365;-1.2403164;-2.368822;1.783605;-
this is needed for when tab pos changes to correctly position;-5.4580836;1.0229422;3.4089057;0.3422224;-0.30004337;3.6482158;CODE
scatter without clock schedule once the positions would look;1.4479148;-0.31346402;4.4467506;-0.91424876;-0.81196886;2.8249032;-
fine but touch won t translate to the correct position;-5.091454;1.5489745;3.3655746;-1.0725747;-5.248378;1.3209554;META
on positions left top and right top;-2.073375;-0.35069904;8.032504;-3.929164;1.2680702;0.18508598;-
calculate top of scatter;4.50511;0.76085025;3.4887528;-6.0145974;-5.1246862;0.9983208;-
add widgets to tab layout;-2.9128194;-1.475612;3.6109483;-2.838664;-1.8158062;3.2906818;TASK
add widgets to self;-3.7275941;-1.8620088;3.237257;-1.0081633;-2.979829;3.5971057;TASK
tab width none;-4.173752;2.2256358;1.8404253;-2.695115;-3.6711128;0.27097982;-
size hint x x xyz;-1.4094331;1.4371016;2.9409683;-3.6395645;-1.0737429;-1.6801333;CODE
drop to default tab width;-2.6851585;2.1054757;2.2946553;-1.2267067;-2.237239;3.8836613;CODE
size hint x none;-1.549218;2.307778;2.9481091;-2.2891283;-0.35059306;-2.521576;CODE
bottom or top;-2.5937593;-0.6354869;6.034517;-1.5581728;0.527629;-1.1210176;-
required for situations when scrl v s pos is calculated;0.354929;1.5723467;0.0054928004;2.4745004;1.8418945;-0.626053;CODE
when it has no parent;-4.258785;1.3093575;4.1855116;2.625598;1.280965;-0.79794407;-
left or right;-4.0052013;-1.0273142;6.2295065;-2.223361;1.1126487;-2.645069;-
or textinput instance selection color or app selection color;-2.3338199;-3.0486076;1.5884743;1.7996272;1.0200412;0.84045327;CODE
late binding;-4.9451256;-0.10720619;1.5873688;3.3027115;-0.33610556;2.281942;-
for reloading we need to keep a list of textinput to retrigger the rendering;-5.129879;0.26037014;1.9160733;3.276578;-3.2370741;4.1057057;CODE
cache the result;-0.92504525;2.333947;4.048017;3.6176038;-0.83697253;-1.1248631;IRRE
when we are generating documentation config doesn t exist;-5.1795187;-2.8407428;-2.8494163;1.4291834;-0.75440913;1.0277497;CODE
register an observer to clear the textinput cache when opengl will reload;-3.5728977;0.72887146;0.50753516;3.6483338;-2.8121152;4.830675;CODE
internal class used for showing the little bubble popup when;-4.8048697;-2.217987;2.5762942;0.5403019;1.0180404;1.1294781;CODE
copy cut paste happen;-4.0830374;-1.283943;2.674217;0.115546584;-1.7297541;-0.83727306;-
this is a prevention to get the bubble staying on the screen if the;-4.178226;0.66151553;4.0386786;0.9290781;-3.3787313;1.1728674;CODE
attached textinput is not on the screen anymore;-6.015245;0.45535868;2.7817802;1.0656677;-5.2998896;1.5260354;OUTD
show only paste on long touch;-2.803242;1.8780328;3.8187606;0.04818136;-2.2975953;1.6560215;-
show only copy for read only text input;-1.276797;2.3495038;1.1307403;1.0355289;-1.3443929;0.18285154;CODE
normal mode;-2.6321185;-0.122423254;3.8074648;-2.5852203;0.53934216;1.8181996;-
from to range of lines being partially or fully rendered;-0.3906405;3.070672;3.647802;-2.1067212;-2.033841;1.9346012;CODE
in textinput s viewport;-4.5575767;-1.950351;2.5629554;-1.283907;-2.343579;1.5805516;CODE
when the gl context is reloaded trigger the text rendering again;-5.835414;2.2539537;1.4202303;3.0840375;-1.50116;5.578155;CODE
avoid refreshing text on every keystroke;-3.4757824;0.3890709;2.8698063;3.3307807;-0.9354245;2.2515993;CODE
allows for faster typing of text when the amount of text in;-1.4385325;-0.9795609;2.4744592;0.9776271;0.13676415;0.82752776;CODE
textinput gets large;-1.4640908;-0.60508543;0.8515473;0.23230612;-4.1463118;0.31507337;CODE
calling trigger here could lead to wrong cursor positioning;-3.2492864;2.3966782;0.49988487;0.34319577;-3.509129;0.6843785;IRRE
and repeating of text when keys are added rapidly in a automated;-0.09975344;-2.281011;3.1237085;1.004595;2.5902169;-0.67199856;CODE
fashion from android keyboard for example;-2.3247318;-4.321941;4.54296;-2.0857959;1.1006377;1.9502045;CODE
handle undo and redo;-5.8416805;2.8772068;2.797061;1.8149563;-0.08513599;1.7566184;CODE
get current paragraph from cursor position;-2.9208434;0.6377687;3.6963274;-0.09848279;-1.831593;0.49908155;CODE
handle undo and redo;-5.8416805;2.8772068;2.797061;1.8149563;-0.08513599;1.7566184;CODE
reset redo when undo is appended to;-5.7558517;3.4140775;1.99508;2.2054052;-0.5842811;3.1974711;CODE
delsel;-2.9312766;0.0638482;3.411474;-0.21630535;2.182123;-1.2671573;-
reached at top of undo list;-5.141838;0.60864353;3.0803957;1.2823601;-2.3558826;1.0369934;CODE
delsel;-2.9312766;0.0638482;3.411474;-0.21630535;2.182123;-1.2671573;-
reached at top of undo list;-5.141838;0.60864353;3.0803957;1.2823601;-2.3558826;1.0369934;CODE
ime system handles its own backspaces;-4.460061;0.36920848;1.1338507;0.5535827;-3.5003707;3.4155154;CODE
ch text col 1;-1.3315921;-0.7021609;2.5868678;-5.7288594;1.407979;-4.0141187;-
refresh just the current line instead of the whole text;-4.814409;2.0247126;4.794901;1.5321401;-2.2125123;1.8552951;CODE
avoid trigger refresh leads to issue with;-3.661701;3.573561;0.48486388;4.2249436;-3.023557;1.889536;CODE
keys text send rapidly through code;-3.0484402;-0.90964895;1.6587971;-0.6724423;-1.3776679;-0.75546056;CODE
handle undo and redo;-5.8416805;2.8772068;2.797061;1.8149563;-0.08513599;1.7566184;CODE
handle undo and redo for backspace;-5.343243;2.106857;2.0011861;0.63484186;-0.6441332;2.908513;CODE
reset redo when undo is appended to;-5.7558517;3.4140775;1.99508;2.2054052;-0.5842811;3.1974711;CODE
offset for horizontal text alignment;-0.6068922;1.7186049;3.2379153;-3.9098659;-0.8371374;0.81840837;IRRE
selection control;0.960462;-1.5824232;4.936279;1.9493222;3.465926;1.6887609;CODE
handle undo and redo for delete selection;-3.4198549;2.9331708;1.2256027;1.409189;1.3679512;2.979618;CODE
handle undo and redo for backspace;-5.343243;2.106857;2.0011861;0.63484186;-0.6441332;2.908513;CODE
reset redo when undo is appended to;-5.7558517;3.4140775;1.99508;2.2054052;-0.5842811;3.1974711;CODE
update graphics only on new line;-3.5535772;1.8908857;4.8620844;-0.25153714;-2.1481755;3.9223275;CODE
allows smoother scrolling noticeably;-1.6365649;-2.3068864;3.9598796;-0.32676193;-3.0741975;4.70009;-
faster when dealing with large text;1.4912997;-0.83831936;3.2945955;0.66894406;0.541239;0.16172837;CODE
self trigger update graphics;-2.83417;-0.77717245;4.2259464;0.31819165;-2.084335;2.9568596;CODE
touch control;-3.7006047;-2.1529703;7.793742;1.2651241;-1.9648492;1.1111511;-
schedule long touch for paste;-3.1897316;-1.0172011;4.407805;2.1132119;-1.9277548;1.3100026;CODE
check for scroll wheel;-3.760907;0.62258136;2.9005768;-0.86690634;-3.1696074;-0.801921;CODE
todo implement scrollleft and scrollright;-4.1716986;-0.009860327;2.661977;-0.45831016;-1.7156944;2.8430903;TASK
stores the touch for later use;-4.202449;-1.3938737;6.37341;2.0693007;-0.9131523;3.7319522;CODE
is a new touch down so previous scroll states needs to be reset;-4.9956274;0.7616851;3.6549816;2.1630065;-2.792364;4.1298766;CODE
schedule long touch for paste;-3.1897316;-1.0172011;4.407805;2.1132119;-1.9277548;1.3100026;CODE
cancel update existing selection after a single tap;-2.567172;3.019979;3.0489607;4.1795893;-0.057092372;3.1476736;CODE
types of touch that will have higher priority in being recognized;-1.8307403;-1.7543769;3.3632586;3.722664;2.7945902;3.2422347;-
compared to single tap;-0.5048001;-0.65607035;5.1279893;3.688265;0.30494997;0.6149987;IRRE
is a single tap and did not scrolled;-4.5210056;1.3140211;4.6194825;1.6692322;-2.588693;2.0548549;CODE
selection needs to be canceled;-3.4255612;1.4673585;1.0783403;4.7742276;1.1953274;1.7270138;TASK
show bubble;-0.6148752;1.0273649;6.1758285;-1.3258545;-1.5639942;-1.8468351;-
to be considered a scroll touch should travel more than;-3.163179;0.63945323;4.623194;1.40422;-2.498288;2.1472352;-
scroll distance in less than the scroll timeout since touch down;-1.5219116;1.4013786;2.6076367;-0.018269349;-4.72456;2.4697163;CODE
distance isn t enough yet to consider it as a scroll;-0.9109657;0.08009413;4.4262033;-0.4735539;-2.7492304;2.328274;TASK
timeout is not reached scroll is still enabled;-4.9469786;1.4211111;1.576749;1.205991;-4.9224825;2.4057553;TASK
we have a scroll;-3.917773;-2.4882145;7.5341835;-0.54557604;-2.2851756;-0.48044366;-
ignore event if not triggered;-3.328982;4.679489;2.0081673;5.8041115;-1.662017;1.8515176;-
stop if cursor blink value changed right now;-3.1057537;3.4137604;1.9440469;2.0705693;-3.0796154;0.14163448;IRRE
don t blink make cursor visible;-4.613408;0.53593886;2.3498416;-0.4540479;-3.0920603;1.4392732;CODE
callback for blinking the cursor;-5.737977;-0.06325235;3.5414555;1.7157599;-3.2553992;1.5511974;IRRE
start max 0 start;-2.0009775;3.0335643;3.2802527;-1.750784;-0.9131273;-1.4415681;-
with markup texture can be of height 1;-1.0378468;1.3044176;2.5075243;-4.1856174;-0.58267766;2.4383771;-
self line spacing 2;-1.2989061;2.4847276;2.456104;-4.0052214;-1.570248;-0.42019638;CODE
now if the text change maybe the cursor is not at the same place as;-4.8916206;1.8084619;2.052547;0.03298401;-3.2986956;1.4144406;-
before so try to set the cursor on the good place;-5.5094995;0.36575434;3.4642599;0.04661161;-4.5544205;1.3461658;CODE
if we back to a new line reset the scroll otherwise the effect is;-4.246184;1.4240679;3.6626894;1.2691292;-3.6132276;3.686881;IRRE
ugly;-2.5738647;-2.0357077;3.513931;-0.33956528;-0.21824913;-1.5285712;-
with the new text don t forget to update graphics again;-5.499298;0.2765832;4.1090736;0.2970721;-1.931539;2.8516486;CODE
if not inserting at first line then;-4.0585403;6.2944493;1.8144988;1.209164;0.63658684;-4.412378;CODE
make sure line flags restored for first line;-4.4060965;5.028165;0.10974901;0.35280055;-1.5225854;1.0742811;CODE
split smart assumes first line to be not a new line;-0.20369634;2.51167;-0.91005677;0.27380204;1.5178423;-0.21844201;CODE
this is a little bit complex because we have to;-1.6572684;-2.135678;5.856331;1.1012799;1.8226565;0.3377329;META
handle scroll x;-5.0159903;1.0688678;4.711441;-0.8877466;-2.4759145;2.0014937;-
handle padding;-2.153754;-0.5290739;4.090227;-2.1368296;-1.3910389;1.5838321;TASK
create rectangle for the lines matching the viewport;-0.69744563;0.6166449;5.544661;-4.355744;-0.00010647927;2.7662091;IRRE
crop the texture coordinates to match the viewport;-0.48432094;-0.48892584;3.08016;-2.867033;-2.901757;4.631227;IRRE
this is the first step of graphics the second is the selection;-1.7904494;-3.5002184;6.613412;-1.0201513;2.4439263;2.0701017;CODE
adjust view if the cursor is going outside the bounds;-1.485897;2.0799499;3.5471637;-0.82245517;-3.6289933;3.0747561;-
draw labels;0.3018771;-2.0828555;6.7417984;-5.2068276;0.32280636;-0.63804275;-
compute coordinate;-0.53406274;1.424676;3.5103202;-6.3403773;-3.3779857;-2.1837678;-
adjust size texcoord according to viewport;-1.5815451;0.15177979;2.4406598;-3.5752566;-1.5081842;4.544242;-
cropping;-0.28899825;-2.1107717;6.220955;-1.2975124;-1.7415997;2.0192769;-
nothing to show;-4.5794353;1.0991257;3.4133584;-0.3350251;-3.194286;-2.4320014;-
horizontal alignment;0.8192769;1.9734812;5.5175066;-5.5087776;0.7389323;-0.49976718;-
base dir self resolved base dir label find base direction value noqa;-1.5992768;1.9593174;-1.3572246;-4.751299;0.88056254;0.67243737;IRRE
add rectangle;-2.4089193;1.099859;7.248955;-5.290152;-0.5666849;0.4967671;TASK
useful to debug rectangle sizes;0.83001065;0.045265388;1.5317117;-2.3316894;-2.8230503;-0.114392266;-
self canvas add color 0 5 0 5 mode rgba;-3.1156282;0.40032628;1.5874338;-4.921394;-2.360543;2.3776898;TASK
self canvas add rectangle pos rect pos size rect size;-1.5746996;1.4722894;4.050395;-4.626081;-2.819445;2.2967038;TASK
self canvas add color;-3.6156223;-0.34233317;3.9644248;-2.1855636;-2.8841023;2.1180716;TASK
local references to avoid dot lookups later;-0.76228833;-2.1697009;-1.9625807;1.2736236;2.9118588;2.7619388;CODE
selection borders;0.28054872;-1.1203009;6.0683746;-2.2823768;3.092034;1.1945505;CODE
draw the current selection on the widget;-2.121101;-0.32079872;5.4102736;-0.30958658;-1.2689028;2.0978246;CODE
if the size change we might do invalid scrolling text split;-1.668102;1.856039;1.2086673;-0.15657106;-0.8501329;3.1777487;OUTD
size the text maybe be put after size hint have been resolved;-3.9832957;1.9945775;-0.19247589;-0.43569422;-2.8544664;1.7619187;CODE
get the pixel width of the given row;1.8238978;1.8641535;2.7859905;-7.282804;-2.2853706;0.07402451;-
return the current cursor x y from the row col;0.709175;2.1435153;2.729949;-3.9610744;-3.6425202;-1.1923134;CODE
horizontal alignment;0.8192769;1.9734812;5.5175066;-5.5087776;0.7389323;-0.49976718;-
return the height of the cursor s visible part;-1.8845258;2.1834886;3.7571604;-2.8173382;-3.0733545;1.7461916;IRRE
return the position of the cursor s top visible point;-1.8228798;1.7345097;4.96283;-2.778976;-3.7179487;2.1124563;CODE
get or create line options to be used for label creation;-1.7935846;-0.24795415;2.107239;-0.796307;3.4195843;2.5602455;IRRE
create a label from a text using line options;-1.4415131;-0.021401575;3.3871439;-2.12916;1.795585;-0.33703005;IRRE
if self password and not hint don t replace hint text with;-4.347822;2.2658143;-0.46940786;1.8289157;-1.5326285;-1.0322282;CODE
fixme right now we can t render very long line;-4.688817;1.0119395;2.0890062;-1.003131;-4.912341;1.7147505;CODE
if we move on vbo version as fallback we won t need to;-2.7372224;-2.0569382;-1.08988;3.3822608;-0.5694862;4.3370833;TASK
do this try to find the maximum text we can handle;0.72476035;2.5382974;3.27269;0.1924622;1.9929963;-3.2218437;CODE
check for blank line;-2.216607;5.8441167;0.0061017214;-1.5668708;-1.4486365;-6.0296454;CODE
exception happen when we tried to render the text;-6.210358;3.867587;-0.08925823;1.4028882;-2.526564;0.038317226;CODE
reduce it;-1.8899366;2.593776;4.3689203;0.8370133;-2.3097622;-0.19142607;-
ok we found it;-3.3744814;-2.8520887;1.6164148;0.4043396;-0.5578777;-1.1785202;-
tokenize a text string from some delimiters;-0.21625622;0.51997626;0.9341534;-0.7035627;1.6541617;-1.0799674;CODE
depend of the options split the text on line or word;-1.6734396;0.36048993;4.5578156;-0.08120376;3.5282943;0.043248817;CODE
no autosize do wordwrap;-4.312954;-0.2551295;0.6062537;0.46994737;-0.5909977;2.371685;CODE
try to add each word on current line;-3.7944489;1.3188035;3.310804;-0.64371413;0.08659742;-1.7799553;CODE
if we have more than the width or if it s a newline;-0.37630343;1.3166115;4.607954;-1.8119887;1.4903489;-0.17608479;CODE
push the current line and create a new one;-4.030984;1.9737393;6.1137905;-1.5770804;-0.8351106;-0.34501463;IRRE
split the word;-1.1933446;-0.85967535;5.4569063;0.39495406;2.4524941;-2.1091704;-
can t fit the word in give up;-2.2344625;1.1122681;1.912806;1.44091;-2.2989905;-1.0628185;-
handle deletion;-3.5118039;3.1267908;1.8172802;1.6403931;0.41520485;1.5550154;CODE
move cursor one char to the right if that was successful;-3.2830923;2.8379557;2.99144;-0.37929744;-3.2802398;-1.9489847;CODE
do a backspace effectively deleting char right of cursor;-3.0944118;0.8281076;1.0858417;-1.5213858;-2.4494977;0.8715385;CODE
handle action keys and text insertion;-5.691165;0.1148971;2.55845;1.9922373;1.8105192;2.0433035;CODE
this allows either ctrl or cmd but not both;-7.3146367;-1.5085863;2.2856293;0.15163235;-1.3348444;3.1290808;META
check for command modes;-3.9447172;2.4521704;-0.38229644;2.1326957;-0.513104;-0.5847161;CODE
we use x01info x02 to get info from ime on mobiles;-3.0121262;-1.4936621;2.7687767;-1.1736813;-0.17606366;1.772808;CODE
pygame seems to pass x01 as the unicode for ctrl a;-5.5360446;-0.35150972;-2.1567385;-2.9949155;-4.4845357;-0.22802351;CODE
checking for modifiers ensures conflict resolution;-1.8740171;2.1188333;-3.3545473;5.0761914;4.1872306;0.006142512;CODE
we expect to get managed key input via on textinput;-2.7546268;-1.4567566;-0.78913885;1.4246196;-1.8946356;0.7679254;CODE
self recalc size;0.32644704;2.1639955;1.7113242;-2.932106;0.13930199;2.1021292;CODE
if key 27 escape;-4.647521;2.9278872;1.5640861;-0.43363854;-0.044769492;-5.179322;-
elif key 9 tab;-4.184188;-1.5119786;1.4668831;-3.3091462;0.96870977;-2.9434004;-
actions that can be done in readonly;-5.8210382;-0.6882791;2.925617;4.9379;1.3569598;1.2715719;CODE
if key ord a select all;-1.7361091;4.488711;0.88886756;-0.3625393;4.553092;-3.705923;CODE
elif key ord c copy selection;-2.087809;0.42766586;-2.5859296;-2.3738136;2.6833365;-1.4324112;CODE
actions that can be done only if editable;-3.226319;1.4795107;1.9965764;4.5566354;0.81487757;2.2312157;CODE
if key ord x cut selection;-1.2142149;3.1962788;-0.37179124;-2.3661942;3.9509404;-0.8180331;CODE
elif key ord v paste clipboard content;-4.357622;-0.66515356;-1.0325761;-3.1000147;1.0085616;-1.1721007;CODE
elif key ord z undo;-6.4817677;1.3145462;-0.34674206;-2.0289576;1.0209348;-0.4277398;CODE
elif key ord r redo;-4.6573205;-0.5946675;-0.39867452;-2.9673333;2.9122617;-2.4981194;CODE
current ime composition in progress by the ime system or if nothing;-1.1392668;-0.5176424;0.633753;2.7059698;-0.074884854;1.7084624;CODE
cursor position of last ime event;-3.0997117;2.0660894;4.665797;-0.060284313;-2.7973254;1.6890095;-
if text pcc len ime pcc self ime composition always;-0.48927087;1.702778;-0.7089337;-1.6892216;2.383812;-0.06726636;CODE
remember to update graphics;-3.9959323;-0.836095;4.9173145;0.67796683;-3.4689233;2.6533804;CODE
properties;-1.6438527;-0.56832975;4.6443586;1.6928638;3.3379152;-1.85997;-
adjust scrollview to ensure that the cursor will be always inside our;-2.1109686;0.45811382;3.0446694;0.056372765;-3.2866316;4.810007;-
viewport;-5.1194525;-2.6443431;6.2071657;-2.1914017;-1.3229098;2.3388457;-
if offset is outside the current bounds readjust;0.6621009;5.4838033;1.6252133;0.28840357;-3.6433403;0.2722358;IRRE
avoid right center horizontal alignment issues if the viewport is at;-1.9594374;2.2564633;1.210901;-1.1123705;-3.3796618;4.5046277;CODE
the end of the line if not multiline;-2.4220831;4.2040257;2.7484467;-3.007883;-1.8129541;-4.434743;CODE
do the same for y;-2.3911626;-0.9262378;3.1949995;-0.23053783;-2.668566;-1.576128;CODE
this algo try to center the cursor as much as possible;-3.1174443;-0.47293633;2.4777074;-0.45583376;-4.4377604;1.0777049;CODE
set font size 20dp;-2.2067995;1.1223359;1.9598503;-2.7230024;-1.4605715;3.4549255;IRRE
check if the widget is ok for a node;-2.954432;3.9033706;0.1889759;3.060914;-2.7753556;-0.3149091;IRRE
create node;-3.5425467;-0.9300957;3.106167;-2.5557432;1.4995008;-1.1533862;IRRE
check if the widget is ok for a node;-2.954432;3.9033706;0.1889759;3.060914;-2.7753556;-0.3149091;IRRE
add nodes;-1.5761397;-1.7670488;4.264792;-2.8862667;1.769395;0.45337665;TASK
private;-3.4954188;-1.6864076;5.220953;0.23000242;0.40702155;-2.3223498;CODE
display only the one who are is open;-2.4505017;3.0571623;6.089699;0.008446644;1.4694009;0.18621157;CODE
now do layout;-5.477766;-1.9171011;6.515153;-2.4643757;0.038850892;1.7085484;CODE
now iterate for calculating minimum size;4.033938;3.610007;1.7544309;-2.775504;0.45534804;-2.0768754;CODE
toggle node or selection;-2.384363;-0.3326755;3.265526;1.0325987;0.8116446;2.376666;CODE
private properties;-2.761634;0.25638422;2.1949966;0.73507994;2.8257742;0.2113479;CODE
properties;-1.6438527;-0.56832975;4.6443586;1.6928638;3.3379152;-1.85997;-
start playing the video at creation;-4.8040657;-3.1065733;3.2557533;0.20343459;-1.8352929;0.23924707;-
create the video and start later;-3.4721105;-1.0288073;5.916461;1.0036424;-0.70978045;2.1475897;IRRE
and later;-2.201772;-2.0195792;5.9220166;3.9571943;1.1892352;-0.3216324;-
check if filename is not url;-3.5603096;3.7032158;0.54400426;1.9548042;-1.7166631;-2.0806856;IRRE
save the current volume and delta to it;-0.4136478;1.1225386;3.7996774;-0.82205594;-2.120015;2.3416338;CODE
calculate delta;-0.062240373;2.005563;3.8305655;-1.3828143;-2.6331427;-2.2452962;-
convert to minutes seconds;-0.16929466;-0.034047205;4.181098;-3.117565;-1.7830082;-1.5184345;-
fix bubble label position;-0.8655301;0.9045931;3.2218888;-3.471038;-1.3228635;2.3246355;-
start playing the video at creation;-4.8040657;-3.1065733;3.2557533;0.20343459;-1.8352929;0.23924707;-
create the video and start later;-3.4721105;-1.0288073;5.916461;1.0036424;-0.70978045;2.1475897;IRRE
and later;-2.201772;-2.0195792;5.9220166;3.9571943;1.1892352;-0.3216324;-
internals;-4.0143366;-2.3030775;5.733412;1.019813;1.5179479;-1.3261786;CODE
by default videoplayer should look for thumbnail and annotations;-3.2246072;-2.2029843;-0.57857627;0.42390314;-2.199671;3.5178316;CODE
with the same filename except extension of the source video file;-3.3019028;0.7005101;-0.24959762;0.6725329;0.44015452;3.2082987;CODE
remove all window children;-3.490347;1.5877501;3.8887975;-0.1234265;0.36496785;2.565249;CODE
put the video in fullscreen;-3.5437171;-0.32097563;3.9937656;-1.739699;-3.2885678;3.4300818;-
ensure the video widget is in 0 0 and the size will be;-3.2610734;2.5390053;0.5014718;-1.9024631;-4.985845;4.413589;-
readjusted;-2.426266;-0.14531757;3.75303;1.6176828;-2.5911567;0.7706586;CODE
f key;-2.7431238;-1.1417308;3.4399855;-2.8756633;0.13535032;-3.3727145;-
capslock;-3.4215717;-1.7353957;4.073064;1.0118451;0.53674346;-1.0492195;-
xxx internal variables;-3.76876;2.2800946;0.96317434;-3.3746274;1.8536165;-1.7729228;CODE
xxx move to style kv;-3.7656507;-1.176834;3.4149;-4.1580706;-0.33337304;1.5430444;-
load all the layouts found in the layout path directory;-3.2527547;-0.6013569;2.8270252;-0.95142275;-0.33748415;3.9473152;CODE
ensure we have default layouts;-3.9078505;0.03201137;1.9543933;-0.3061116;0.32138586;5.5032926;CODE
load the default layout from configuration;-3.913491;0.86852175;2.6063857;-0.67723715;-0.4985848;6.938272;CODE
ensure the current layout is found on the available layout;-4.185725;2.423934;2.6149302;0.87805676;0.3892397;5.912108;CODE
update layout mode shift or normal;-3.9598072;1.2884221;1.933582;-2.8721106;-0.5240244;5.6099916;CODE
create a top layer to draw active keys on;-1.6221119;-1.678747;4.8936825;-2.9885263;0.45857763;3.3896368;IRRE
update mode according to capslock and shift key;-4.174863;0.9943975;0.3412786;-0.88724;0.032478604;2.9037023;CODE
ensure new layouts are loaded first;-3.8051903;2.4250977;2.1448853;2.6949415;0.8820587;6.478528;CODE
it s a filename try to load it directly;-7.4447455;-1.9361737;-0.104536675;-0.93268114;-1.6922861;-0.17033626;CODE
first load available layouts from json files;-2.6858711;-0.32963297;2.2196102;1.0683893;-0.038383033;6.369601;CODE
xxx fix to be able to reload layout when path is changing;-6.7151537;1.3247511;0.58897465;0.5650849;-2.9207423;5.883447;CODE
note all math will be done in window point of view;-0.1686089;-0.23258142;3.6505766;-2.7312562;-1.8767394;-0.86692715;CODE
determine rotation of the target;0.7627719;1.9287183;2.7881935;-1.7089881;-2.0330842;-0.40155646;-
determine the position of center top of the keyboard;-1.783144;0.30816567;4.384514;-3.5067384;-1.851342;-0.014792986;-
determine the position of center bottom of the target;-0.049416635;1.9424443;5.2346916;-2.2749686;-3.3217416;0.17214255;-
the goal now is to map both point calculate the diff between them;3.3396282;3.1313334;3.102645;-4.7609935;-0.9826177;0.52025;CODE
we still have an issue self pos represent the bounding box;-2.842693;-0.2368523;0.8588304;0.3486802;-0.52351904;2.5515888;TASK
not the 0 0 coordinate of the scatter we need to apply also;1.5981085;1.5963595;-1.2429956;-5.436624;-7.1674185;2.272097;TASK
the diff between them inside and outside coordinate matrix;3.3341863;1.8510835;0.1265642;-6.2677903;-2.9778335;2.354849;CODE
it s hard to explain but do a scheme on a paper write all;0.81014204;-2.1061606;3.767993;-0.17136168;3.1251218;-2.133054;META
the vector i m calculating and you ll understand;1.5551364;-0.46326503;2.0114453;-6.376781;-1.3813;-1.7400439;-
now we have a good diff set it as a pos;-1.2158827;-0.11785845;3.5301335;1.6270726;0.9542776;0.8838424;IRRE
xxx implement popup with all available layouts;-4.020165;-0.021078369;4.124636;-1.8844984;1.4532443;4.7074637;TASK
get relative efficient surface of the layout without external margins;0.79639506;-0.42863944;2.5840566;-3.0325274;0.1984477;5.721281;-
get relative unit surface;0.3844071;0.7014668;2.4372118;-4.054248;-1.1815786;3.125581;-
calculate individual key relative surface and pos without key;1.1757705;0.59274143;0.30157694;-6.2051873;1.1949699;0.93367887;-
margin;-0.42362666;-0.7829051;6.887209;-2.2110636;-0.8091591;-1.0158433;-
get line name;-2.6939218;1.5853134;2.5842185;-1.3688909;-0.43120858;-1.2821887;-
go through the list of keys tuples of 4;-0.82489145;-0.20044853;1.7770844;-4.459584;2.9269714;-4.796816;-
calculate relative pos size;3.8551614;2.8742354;2.0132751;-3.166031;-0.03900158;-0.14758341;-
now adjust considering the key margin;-2.3990448;-0.012982239;3.2336218;-2.4301994;-1.4585338;2.1389813;-
draw background;-3.37569;-1.8982127;8.081119;-2.3427758;-1.2787051;0.6712352;-
xxx separate drawing the keys and the fonts to avoid;-3.0657737;-0.30901235;4.1010337;-4.6577353;1.1020274;2.2783434;CODE
xxx reloading the texture each time;-4.7419543;1.4702191;2.2410486;1.0443041;-1.886754;3.7560549;CODE
first draw keys without the font;-3.5979464;-0.6041177;4.4511433;-3.7496443;-1.0980166;1.2831994;CODE
then draw the text;-2.997535;-1.0822039;7.8869104;-2.0186877;-0.71729505;-1.5441046;CODE
retrieve the relative text;-1.5185486;0.8861536;3.9457533;-1.7318376;1.1881362;-0.70770407;-
focus on the surface without margins;-0.8706905;-0.8201324;4.677271;-0.8468054;-2.5381293;4.896542;-
get the line of the layout;-4.021967;0.8925596;6.181314;-3.327685;-0.18115109;2.0722706;-
e height h mbottom mtop h efficient height in pixels;0.94627863;-0.4641421;0.13969457;-4.485892;-0.96192724;3.9903197;-
line height e height layout rows line height in px;-2.2586207;1.9936281;0.46712533;-6.2258544;-0.5478132;3.8186247;-
get the key within the line;-3.6616175;1.8993659;3.9644186;-2.1659672;0.764463;-2.4100542;CODE
get the full character;-2.7074664;0.45104554;4.3773394;-1.4305823;1.0445355;-2.7181792;CODE
save pressed key on the touch;-4.516698;-1.3529626;5.5014653;0.5298611;-2.1154277;1.3495563;CODE
for caps lock or shift only;-4.0918674;-1.4834177;3.319179;-1.8138497;1.4497186;0.43134975;CODE
do not repeat special keys;-2.6152458;2.07213;1.2681217;-1.0547487;2.837267;-0.25043377;CODE
send info to the bus;-2.9296644;-0.4395586;4.193296;-0.14171493;1.9123654;-1.099876;CODE
save key as an active key for drawing;-3.6667206;-0.8726255;3.8426807;-1.01958;-0.77701455;2.924628;CODE
save pressed key on the touch;-4.516698;-1.3529626;5.5014653;0.5298611;-2.1154277;1.3495563;CODE
send info to the bus;-2.9296644;-0.4395586;4.193296;-0.14171493;1.9123654;-1.099876;CODE
do stuff here and kill the event;-3.3047853;-1.151096;4.36036;2.1100545;-0.69556385;-0.64023834;CODE
references to all the widget destructors partial method with widget uid as;-3.984298;-0.48877817;-1.6608952;2.1023488;0.66794515;3.732192;CODE
key;-3.2980633;-2.310344;4.472562;-1.659043;0.35199484;-3.493572;-
internal method called when a widget is deleted from memory the only;-4.340445;1.7487814;2.2385237;3.5339427;-1.4473166;4.361959;CODE
thing we remember about it is its uid clear all the associated callbacks;-7.728071;-0.15767917;0.31455642;3.446104;-0.52876854;3.1496696;IRRE
created in kv language;-3.7594404;-4.252426;0.9515285;-1.6137158;1.5644886;-2.7208233;IRRE
base class used for widget that inherits from class eventdispatcher;-4.1962957;-2.3041043;1.1577016;1.084787;0.6533133;4.2959237;CODE
https docs python org 2 library gc html gc garbage;-4.8142548;-2.9452822;-4.2370815;-0.18057042;-4.78768;-0.22284637;CODE
before doing anything ensure the windows exist;-4.3383594;0.2002623;1.7232298;2.8393717;-1.4045825;1.6896228;CODE
assign the default context of the widget creation;-4.611042;-0.24601483;1.8817626;0.7895681;-0.31268373;6.8518577;IRRE
create the default canvas if it does not exist;-4.430593;3.503989;2.4819894;0.11532527;-2.0740423;3.3329365;CODE
apply all the styles;-2.6631901;-2.4206567;3.7317247;-0.20800357;3.2631497;1.9611522;-
bind all the events;-3.463774;0.24949221;6.402163;2.512482;1.6933453;1.7539686;-
proxy weakref proxy for more information;-0.39266387;-1.0635847;0.31535548;4.2786517;0.95817846;4.291081;CODE
only f should be enough here but it appears that is a very;-0.79288685;1.2344774;2.0412505;0.06386387;-0.8585721;-1.8231573;META
specific case the proxy destructor is not called if both f and;-4.808531;3.4778066;-1.1734316;2.7582216;-0.049783077;2.507585;IRRE
proxy ref are not together in a tuple;-3.8628213;2.2628367;-0.6912732;1.2574213;-0.3469057;1.2934216;-
collision;-2.478075;-0.35299352;6.7975206;0.28424168;0.19405875;-4.603174;-
default event handlers;-5.728618;-1.6068249;3.4137504;3.508932;-1.1031544;3.4707239;CODE
tree management;-0.7676776;-2.5261018;4.3378563;2.3313086;3.9940116;0.5007033;-
check if the widget is already a child of another widget;-2.685747;3.5689688;2.1870441;2.0598037;-0.06595605;1.0395364;CODE
child will be disabled if added to a disabled parent;-4.74341;2.3178687;1.0914185;1.8406769;1.2168056;1.9594697;TASK
we never want to insert widget before canvas before;-5.517578;1.6055051;3.6735137;0.9838849;-3.5647266;5.2742496;CODE
we pass index only when we are going on the parent;-1.3425041;3.8588786;1.4011239;0.39650697;1.8611805;2.5793967;-
so don t yield the parent as well;-3.9928405;2.1938715;2.2724311;2.1968505;0.9927935;0.93053347;CODE
if we want to continue with our parent just do it;-4.1626935;1.3370177;3.8252869;1.3508149;-0.74890506;2.0776784;CODE
self is root if we want to loopback from the first element;-4.9592676;3.7200391;1.9809448;0.64807636;-0.42738447;0.20351015;CODE
if we started with root i e index none then we have to;-4.1056523;1.1842043;0.61452436;-1.2634598;0.538091;-0.5863029;-
start from root again so we return self again otherwise we;-5.952196;1.6622273;2.139136;1.3520386;-3.212588;-0.8885757;CODE
never returned it so return it now starting with it;-5.252881;1.2296412;3.1184409;0.582365;-2.644633;0.030887142;IRRE
call walk on box with loopback true and restrict false;-3.8638403;5.222956;1.6378797;3.5948558;-2.098457;1.5212399;IRRE
now with loopback false and restrict false;-4.4188056;5.41519;0.9398239;5.0581717;-0.8880026;0.66746694;IRRE
now with restrict true;-2.9172723;2.8943856;2.4932914;3.7193398;2.4693825;-1.1961449;-
process is walk up level walk down its children tree then walk up;-2.9043972;-1.1306615;3.465635;0.19413862;0.81310415;-0.27673084;CODE
next level etc;-2.359546;-3.1889927;4.7335544;1.5747086;1.8157682;-1.2776963;CODE
default just walk down the children tree;-4.262747;-1.2864194;3.8939817;0.38979557;0.10640935;2.374858;CODE
we need to go up a level before walking tree;-2.2558913;-0.89066905;2.5070655;0.8990657;-0.6917593;-0.12753032;TASK
now walk children tree starting with last most child;-1.7832854;-0.31828502;3.6442325;0.53685194;1.6899809;-0.5710491;-
we need to return ourself last in all cases;-3.233123;2.6294372;3.7045925;3.4901342;-2.3162146;-0.3125658;CODE
if going up continue walking up the parent tree;-2.8622618;0.73166937;4.2455497;1.2741237;0.47698107;-0.313591;CODE
call walk on box with loopback true;-4.14707;3.8182728;2.310434;2.8638084;-2.5998347;1.6716213;IRRE
now with loopback false;-5.428073;4.2300167;2.2743957;4.6672845;-2.3400152;-0.0726075;IRRE
in kv;-1.7103202;-2.3606515;3.5207021;-0.3277147;0.7926898;-2.642391;-
necessary to ensure a change between value of equal truthiness;1.1023811;4.6895094;0.13067356;2.9688072;2.2741854;-0.37410894;IRRE
doesn t mess up the count;-0.7349024;2.8103669;2.9281607;2.344058;1.2942446;-1.8518481;CODE
pylint disable w0611;-7.042065;0.32538226;-3.317939;-0.46263412;-2.2440033;2.4366632;CODE
b str a return 12 54 68;-2.6478431;1.6702001;1.9390106;-2.7089033;0.44470873;-5.3936;IRRE
c strtotuple b return 12 54 68;-2.5977254;1.9069021;0.17691028;-3.4687574;-0.007274973;-5.7712693;IRRE
security;-3.0031831;-2.9077418;6.4307017;1.3690578;1.0151117;-3.5959496;-
fast syntax check;-0.5990705;-0.55465084;-0.18094312;2.910334;3.6185243;-5.355153;-
if s startswith;-1.6757497;3.2227044;4.078858;1.735399;1.1888425;-5.510749;-
00ff00;-2.993552;-1.6867163;2.383946;-2.7834957;-0.35489467;-3.4581494;-
3fc4e57f;-4.1145434;-0.5647234;1.0879626;-1.5918903;0.27668583;-1.2682494;-
return join 0 02x format int x 255 for x in color;-0.5081297;2.612869;-0.7441551;-6.932725;1.4011666;-3.0038595;CODE
aliceblue f0f8ff;-3.188362;-0.35895708;1.9222614;-1.3443928;1.0350285;-2.2808852;-
antiquewhite faebd7;-4.457109;-1.6979153;0.27960014;-1.388126;2.209242;-2.0488875;-
aqua 00ffff;-3.1154485;-0.2992768;2.621805;-1.6325763;0.6869097;-2.4837673;-
aquamarine 7fffd4;-3.9015906;-1.6472617;1.527541;-2.3446903;0.9974268;-0.7161656;-
azure f0ffff;-2.7681763;-0.6966975;2.62828;-0.4691556;-0.34884065;0.28166467;-
beige f5f5dc;-1.5623147;-1.1818477;2.2141268;-2.0607023;0.22642732;-1.2906673;-
bisque ffe4c4;-2.4402397;0.557988;0.39457768;-2.0824208;1.2243133;-1.7031257;-
black 000000;-3.4904163;-1.3581915;2.2941246;-3.8358927;1.434966;-2.3827994;-
blanchedalmond ffebcd;-3.0479128;-1.5704683;1.3394718;-2.1187758;1.5420651;-2.5975587;-
blue 0000ff;-4.077237;-1.0844153;2.6964958;-3.3088136;1.805737;-2.749364;-
blueviolet 8a2be2;-5.1957455;-1.9133275;0.8452037;-1.432521;0.93094414;-0.23499797;CODE
brown a52a2a;-2.1653938;0.020804921;1.2826622;-1.1967117;1.1592417;-3.0918489;-
burlywood deb887;-4.535983;-0.97690314;1.5488597;-3.8127675;0.87847817;-1.6819772;-
cadetblue 5f9ea0;-2.7148283;-0.8489565;0.9501694;-0.61257976;2.2779267;-3.5252414;-
chartreuse 7fff00;-0.9059162;-0.8028467;2.6356056;-5.5984216;-0.0526363;-2.5256608;CODE
chocolate d2691e;-3.275389;-0.86912334;1.5481502;-2.121621;0.6928715;-2.8726854;-
coral ff7f50;-2.7705615;-1.6592867;1.3262599;-2.4085965;0.2760234;-1.8472838;-
cornflowerblue 6495ed;-3.2230742;0.091733135;1.0417202;-1.5087378;-0.051133182;-3.433596;-
cornsilk fff8dc;-1.9090121;-3.2008774;-0.66168904;-2.7330801;-0.8108509;-2.8793097;-
crimson dc143c;-2.9093075;-0.45697024;3.1222818;-2.6356018;1.0023592;-1.1431569;-
cyan 00ffff;-2.3677366;-0.5258749;1.4247723;-3.7594342;-0.39150164;-2.344553;-
darkblue 00008b;-5.3091044;-2.3446367;1.5281539;-2.1809762;0.77510977;-1.564572;-
darkcyan 008b8b;-4.0471816;-1.2648149;1.0586206;-3.6030898;0.9314577;-2.5870285;-
darkgoldenrod b8860b;-4.469878;-1.0009781;0.78368294;-2.5885684;1.6950257;-2.456123;-
darkgray a9a9a9;-3.0190675;-1.3944508;2.244828;-1.3877594;0.0845571;-1.6762159;-
darkgrey a9a9a9;-2.9388359;-1.3872972;1.5875313;-1.91935;0.6238512;-1.8632734;-
darkgreen 006400;-5.044919;-1.4969748;0.973697;-3.1987464;0.3622884;-2.8746066;-
darkkhaki bdb76b;-3.6830008;-1.9009199;0.38269675;-3.296627;1.7670461;-3.2592022;-
darkmagenta 8b008b;-3.8466847;-1.3265038;1.7361332;-2.6168852;0.19090825;-1.5866998;-
darkolivegreen 556b2f;-3.6803625;-1.3032309;-0.25605333;-3.9724846;-0.50132585;-2.7760515;-
darkorange ff8c00;-3.6145165;-1.7015696;1.865652;-1.9048853;0.5176289;-1.3296366;-
darkorchid 9932cc;-4.79763;-2.234463;-0.6769413;-2.4286082;1.8949986;-2.1963654;-
darkred 8b0000;-2.6336014;-2.2982402;1.8646399;-2.3674202;0.57038707;-2.424387;-
darksalmon e9967a;-3.4941885;-1.3139148;1.568377;-1.8071374;0.931003;-2.083802;-
darkseagreen 8fbc8f;-3.6486185;-1.5161769;0.4339544;-2.9288077;0.3019257;-2.3388352;-
darkslateblue 483d8b;-6.4525185;-1.2709666;-0.35588694;-3.8137674;0.9933563;-1.2688235;-
darkslategray 2f4f4f;-3.7821367;0.27580783;0.91137666;-2.0967417;-0.34511536;-1.5688642;-
darkslategrey 2f4f4f;-4.155262;-0.24270956;-1.0390012;-2.905851;-0.544343;-0.94922733;-
darkturquoise 00ced1;-4.126395;-0.002850791;0.4403774;-2.3228376;-0.5984338;-2.0528762;-
darkviolet 9400d3;-4.20173;-1.7683252;1.4251028;-2.0017548;0.79151034;-1.4999772;CODE
deeppink ff1493;-3.1488125;-2.5621197;1.5812696;-2.854237;-0.44796988;-1.716093;-
deepskyblue 00bfff;-2.7799742;-3.0553916;0.3543566;-1.269718;1.6239746;-1.8455609;-
dimgray 696969;-3.3172827;-0.49578714;1.4994055;-3.937895;0.6721307;-3.3699102;-
dimgrey 696969;-3.3034942;-0.5288408;0.7966776;-4.485299;1.3224487;-4.1284156;-
dodgerblue 1e90ff;-2.8092422;-0.9593264;0.34689677;-0.92160076;0.6121493;-1.945136;CODE
firebrick b22222;-4.5923805;-2.883954;0.2511853;-2.389286;0.30350712;-2.7777205;-
floralwhite fffaf0;-2.8946633;-1.3080525;2.1100132;-0.41154236;0.84880334;-1.5794269;-
forestgreen 228b22;-4.1864834;-2.5085633;0.3898451;-2.3801591;1.8165967;-2.6734095;CODE
fuchsia ff00ff;-2.3217378;-1.5044212;2.3214874;-0.760233;-0.645339;-2.4127922;-
gainsboro dcdcdc;-2.9207084;-2.3397071;1.7615784;-0.73389274;1.681135;-0.6009859;-
ghostwhite f8f8ff;-2.9442737;-0.14521438;0.7993413;-0.6037435;0.44314128;-1.0369302;-
gold ffd700;-1.5204253;-1.5193081;1.8209748;-0.98514086;0.21746954;-1.7311698;-
goldenrod daa520;-2.899409;-2.4407892;2.108261;-1.0135771;1.8856144;-2.6233706;-
gray 808080;-3.5816152;0.16033529;3.7307382;-2.0851386;0.10476852;-0.95102465;-
grey 808080;-4.0917387;0.26117063;4.001403;-2.0117507;0.18183741;-0.58549;-
green 008000;-3.6581714;-0.45264933;3.3168094;-2.990494;1.551929;-2.2242193;-
greenyellow adff2f;-2.4923394;-1.9155343;1.2458075;-1.1236472;-0.82300943;-1.0256239;-
honeydew f0fff0;-2.7473147;-1.4748235;1.0211847;-1.7539791;0.22628179;-2.8114524;-
hotpink ff69b4;-3.8262331;-1.7741418;1.6786053;-2.6200566;-0.067405276;-2.318112;-
indianred cd5c5c;-2.3830807;-1.456567;1.1585736;-2.3512578;2.330084;-1.5138159;-
indigo 4b0082;-4.0110617;-0.58496386;2.5062711;-3.4216213;2.0670679;-1.9548138;-
ivory fffff0;-1.37139;0.7645114;2.1125138;-0.7577403;-0.70576084;-1.9263208;-
khaki f0e68c;-3.3176575;-0.5199912;2.050074;-2.7781506;-1.1544533;-0.60001945;-
lavender e6e6fa;-3.8742344;-0.057673085;1.22171;-2.375441;1.6395855;-1.6414784;CODE
lavenderblush fff0f5;-3.3003147;-1.7456926;0.64690095;-2.4252994;1.0973686;-1.7069113;CODE
lawngreen 7cfc00;-3.1388257;-2.2565992;0.45891747;-1.4842111;0.2176876;-2.3353622;-
lemonchiffon fffacd;-2.3995206;-1.7707063;1.674559;-1.4754969;-0.15159616;-2.4005094;-
lightblue add8e6;-6.597176;-1.0258483;0.82453424;-2.0349355;0.059725914;-0.6128939;TASK
lightcoral f08080;-3.9970055;-0.67427176;2.4721355;-2.5028172;-0.4716077;-1.2102411;-
lightcyan e0ffff;-3.0722132;-1.6439681;2.0256581;-2.2572987;-0.27499697;-2.4846902;-
lightgoldenrodyellow fafad2;-3.347126;-1.8680264;1.0606767;-0.38648236;0.8195906;-1.6181465;-
lightgreen 90ee90;-3.536202;-1.2638991;2.0350618;-2.4634006;0.4048329;-1.144261;-
lightgray d3d3d3;-4.396504;-2.3066113;0.8890056;-4.8227077;0.08372553;-0.83790934;-
lightgrey d3d3d3;-4.921323;-3.0882635;-1.5644082;-5.0368085;-0.51168305;-0.1602708;-
lightpink ffb6c1;-4.4775143;-2.2012527;0.5746376;-2.7138238;-0.7807042;-1.5246145;-
lightsalmon ffa07a;-3.2374985;-1.1342351;1.4903034;-2.8662443;0.3456564;-0.8807544;-
lightseagreen 20b2aa;-4.8940153;-0.7056834;1.2396475;-3.3215046;1.9672418;-3.115389;-
lightskyblue 87cefa;-3.4248703;-1.529761;1.3133942;-1.6778184;0.71115196;-1.474718;-
lightslategray 778899;-4.513521;-0.84060496;1.2605432;-3.3148584;0.078102686;-3.0974026;-
lightslategrey 778899;-4.5813293;-1.075037;0.034834437;-3.6542492;0.14402339;-3.2434368;-
lightsteelblue b0c4de;-4.081193;-1.8249292;0.81934553;-2.0725186;0.9261907;-1.2454771;-
lightyellow ffffe0;-2.8417184;-3.3065145;1.3334131;-1.6877266;-0.7495604;-1.1338006;-
lime 00ff00;-4.1409845;-0.4045818;2.7827055;-3.3597004;0.643627;-2.3772295;-
limegreen 32cd32;-5.298895;-1.3645556;0.000854085;-4.4289064;1.6479857;-2.607632;-
linen faf0e6;-3.3058417;-0.11201247;2.2473748;-1.8199879;-1.0147545;-1.0483087;-
magenta ff00ff;-2.9195354;-0.45098802;0.7380125;-3.5244975;-0.015204067;-3.7466516;-
maroon 800000;-1.743637;0.5835666;2.0280373;-2.5525413;-0.050744083;-1.5581155;-
mediumaquamarine 66cdaa;-3.338485;-1.4286296;0.8076914;-3.1925273;1.3580154;-2.4552088;-
mediumblue 0000cd;-2.6095645;-1.6076958;1.0273337;-2.8747687;0.11308444;-3.2678201;-
mediumorchid ba55d3;-2.548012;-0.53677356;-0.75570595;-2.4790387;0.28897873;-0.9664813;-
mediumpurple 9370db;-1.2233828;-1.2285002;-0.6022567;-1.3945186;1.6437325;-1.613685;-
mediumseagreen 3cb371;-3.6006835;0.45898798;-0.16773504;-3.2622976;1.1071465;-3.0651693;-
mediumslateblue 7b68ee;-4.4423046;-0.49957243;0.34506482;-2.289696;0.85276586;-0.60035765;-
mediumspringgreen 00fa9a;-2.3202498;1.0123394;-0.061053462;-2.7015176;0.59311515;-1.6217854;-
mediumturquoise 48d1cc;-3.327291;-0.21331371;-1.089677;-3.1918893;-0.8902266;-0.08945848;-
mediumvioletred c71585;-2.5962949;-1.4222438;0.37162507;-0.7479977;-0.4256957;-1.1764725;CODE
midnightblue 191970;-3.9933627;-1.43958;1.7175194;-1.2858443;-0.33622098;-1.9109536;-
mintcream f5fffa;-3.2845914;-0.5370505;2.1543891;-2.0266821;1.7572678;-2.2733228;CODE
mistyrose ffe4e1;-2.6113226;-0.7304091;0.8416605;-1.9244233;-0.86538726;-0.7768775;-
moccasin ffe4b5;-2.6072636;-1.3686941;0.43431783;-3.064952;0.7341641;-2.617824;-
navajowhite ffdead;-2.3990958;-0.003496503;1.6766526;-1.3683894;0.591023;-1.6324214;-
navy 000080;-3.3034718;-0.931674;1.9909513;-1.9272574;1.2402849;-2.9519053;-
oldlace fdf5e6;-4.2981186;-0.6028246;1.327871;-2.722034;-0.04156765;-2.458693;-
olive 808000;-3.231911;-0.73804426;3.1750638;-1.8411168;-0.40651253;-1.6757398;-
olivedrab 6b8e23;-4.3637443;-0.8626849;0.7451839;-2.3041053;0.1869452;-2.4861288;-
orange ffa500;-2.398914;-1.3809822;2.9198718;-1.1915408;1.3367052;-1.451011;-
orangered ff4500;-2.2448566;-1.9273298;2.3131335;-1.8482461;1.7152889;-2.0505018;-
orchid da70d6;-2.5321417;-1.3432204;1.298612;-0.5692716;1.7542711;-1.5148137;-
palegoldenrod eee8aa;-2.5228345;-1.0126226;1.4063128;-1.1845942;0.8452909;-1.6648822;-
palegreen 98fb98;-3.9562485;-0.9320901;0.9192875;-3.2760518;-0.2273548;-3.3514214;-
paleturquoise afeeee;-1.240997;-1.0578542;2.2649;-0.30538034;-2.1791768;0.07794972;CODE
palevioletred db7093;-3.7216537;-2.048294;-1.2024482;-1.4042237;0.7313788;-2.3215823;CODE
papayawhip ffefd5;-3.2054284;-1.4113761;1.6756223;-1.0322531;0.16186863;-0.06860106;-
peachpuff ffdab9;-3.533396;-2.0569618;0.7397696;-1.6528987;0.22614679;-2.8145351;-
peru cd853f;-3.2555144;-0.68022084;0.91952425;-2.1936712;-1.082407;-2.2708805;-
pink ffc0cb;-3.061732;-1.0930948;1.712712;-2.8578234;1.0506953;-2.0909715;-
plum dda0dd;-3.1307204;-1.4556473;1.5207163;-0.7483776;1.537424;-2.582559;TASK
powderblue b0e0e6;-3.9071658;-1.4347472;0.8340174;-1.6758512;0.62667817;-1.5104084;-
purple 800080;-3.1489832;-0.34156415;4.1612473;-2.583655;1.8350272;-1.0676248;-
red ff0000;-3.4678876;-0.67388844;3.535477;-2.3563938;0.2528543;-2.3614287;-
rosybrown bc8f8f;-2.5769427;-0.94613713;2.2145953;-2.8260367;0.7046502;-1.6543874;-
royalblue 4169e1;-5.0939784;-0.74428755;0.88944674;-2.5717201;2.467243;-1.7253543;-
saddlebrown 8b4513;-3.6186903;-1.4536992;1.03717;-4.099811;0.47935304;-2.1620297;TASK
salmon fa8072;-2.608569;-0.65922886;2.3097124;-2.290111;0.9782222;-2.912662;-
sandybrown f4a460;-3.41474;-1.9986554;1.0473682;-1.985958;0.11306185;-2.1415954;-
seagreen 2e8b57;-5.046566;-1.1207036;0.17236647;-3.4424782;0.37327918;-2.9600022;-
seashell fff5ee;-3.6886911;-2.3179517;1.6413033;-1.5524317;-0.8391553;-2.0750022;CODE
sienna a0522d;-2.592287;-1.6843972;0.34552914;-4.5739055;0.3691089;-1.0294133;-
silver c0c0c0;-2.495413;-1.4840922;1.5445439;-2.5314543;2.184117;-2.8418267;-
skyblue 87ceeb;-3.9434571;-2.2937775;1.6108282;-0.38400313;1.2491599;-0.9278603;-
slateblue 6a5acd;-5.401066;-2.4015388;2.074428;-2.1528516;0.41457716;-0.8653134;-
slategray 708090;-4.547655;-1.3035989;3.3415678;-2.0789375;-0.98584;-0.4933161;-
slategrey 708090;-5.0356174;-1.6939075;2.2252042;-2.624164;-0.6302838;-1.0046452;-
snow fffafa;-1.4477987;-0.8683709;2.725137;-0.6220865;-0.5870002;-0.9526856;-
springgreen 00ff7f;-2.842001;-1.1751505;1.4449183;-2.0403383;0.07179562;-2.537115;-
steelblue 4682b4;-4.623911;-1.3788059;1.093315;-2.4117477;2.2040591;-2.8976684;-
tan d2b48c;-2.9445055;-0.4683462;1.2721424;-3.0464559;-0.020933758;-1.8868074;-
teal 008080;-4.5462337;-0.16731383;1.6436453;-3.3847444;1.6121207;-2.4547603;-
thistle d8bfd8;-4.2369127;-1.8148541;0.8907301;-2.1032157;0.64658594;-1.6367565;CODE
tomato ff6347;-2.4891741;-1.0245396;1.5103661;-2.4823823;-1.4435904;-3.642662;-
turquoise 40e0d0;-3.683962;0.7191032;2.8833315;-3.2348256;2.2138176;-1.3461001;-
violet ee82ee;-2.493849;-1.6464444;2.2094412;-2.0212016;1.349338;-1.559337;CODE
wheat f5deb3;-2.8536456;-0.67895454;1.1894923;-1.4956591;0.67035747;-2.8152332;-
white ffffff;-1.9760346;-0.00070919597;3.4519818;-2.6807134;0.13704005;-1.9036523;-
whitesmoke f5f5f5;-2.4684327;-0.31806973;-0.12890375;-1.0357378;-0.35173908;-1.6626967;-
yellow ffff00;-2.7956824;-0.301362;2.5818932;-2.581438;0.03265423;-2.6982741;-
yellowgreen 9acd32;-4.902032;-0.8467686;-0.5078892;-3.6045246;1.2685163;-1.5124465;-
we want to print deprecated warnings only once;-2.7484407;1.9985838;-3.1069772;3.8433352;-0.012795779;0.12788577;CODE
create a key named toto with the value 1;-2.3571677;2.0337796;2.3604426;-2.1138792;2.7958596;-2.1359375;IRRE
it s the same as;-2.2787373;-2.293514;4.417705;-0.16365343;0.77169615;0.48425597;-
on android sys platform returns linux2 so prefer to check the;-4.045418;-2.5453804;-0.5904183;-0.221297;-1.8251922;-0.31814635;CODE
existence of environ variables set during python initialization;-2.8907816;0.38677654;-3.8099144;0.054568116;-0.855609;1.2125244;IRRE
we used to use this method to detect android platform;-2.190941;-2.9498327;0.32817173;2.628384;0.50410396;-0.01045011;CODE
leaving it here to be backwards compatible with pydroid3;-5.035822;-1.5328536;-1.7250305;-1.9439977;-1.0298443;0.83768785;-
and similar tools outside kivy s ecosystem;-2.8319755;-6.211186;2.7016242;1.2300721;-2.035692;0.95148516;CODE
first time self lazy lazy is reify obj reify get runs;-1.0996993;-1.5743036;-0.78728247;3.9749627;-0.27297533;-0.3023464;CODE
econd time self lazy lazy is hard to compute int;0.7204652;0.17748801;-1.1824738;-0.29892242;-1.7334987;-1.6776522;CODE
check if file exist;-2.977543;4.3901954;-0.111940436;2.2048032;-0.6757718;-3.869997;IRRE
match a line like revision a01041;-0.43955803;2.9667268;-1.5825753;-3.5711036;1.6590474;-4.474722;META
couldn t find the hardware revision assume it is not a pi;-4.3765306;-2.1761444;-0.3303192;-1.1923746;-0.99924845;-1.2966098;META
determine the pi version using the processor bits using the new style;-1.3537107;0.43747497;-0.7264697;-2.0721977;1.468172;-1.3341477;META
revision format;-2.2719936;-1.5179137;1.3678509;-1.7661289;1.7164413;-2.8078356;META
if it is not using the new style revision format;-5.684329;-0.0637221;-2.112654;0.86293334;0.33604255;0.8709232;CODE
then it must be a raspberry pi 1;-2.625031;-0.008005281;1.3494893;-1.2719301;-1.0599308;-0.06847334;TASK
construct a point at 82 34;-1.0835742;1.7628946;3.9926631;-3.6142206;0.064867325;-2.146418;CODE
construct by giving a list of 2 values;1.8924755;2.3836887;3.1934268;-2.5564647;5.2450647;-4.2544637;IRRE
optimized method;5.7744856;1.5468233;1.9606227;1.3180777;2.3376744;1.3806463;-
non optimized method;4.540759;1.7589711;-0.35073638;1.2139189;1.2244178;1.8424537;-
use the list getslice method and convert;-1.0514927;2.7205455;1.8419161;-1.9340881;1.3770647;-3.4012854;IRRE
result to vector;2.3345268;0.47245583;2.073994;-5.5828915;-1.5141906;-3.1890826;IRRE
linear algebar sucks seriously;-0.5523552;-0.53331244;0.27282253;-2.467552;-2.94743;1.9195503;IRRE
yaaay i love linear algebra applied within the realms of geometry;0.8356956;-4.97616;1.6613731;-4.156185;-1.2246779;1.4984704;CODE
this is mostly the same as the line intersection;-0.60217977;-0.7743279;5.176937;-2.7189603;-0.5791156;0.57657444;CODE
here are the new bits;-3.8527277;-2.9067748;2.6912143;-1.6188911;0.4569856;-1.8094496;CODE
kivy cross platform ui framework;-4.1789036;-5.522198;1.1213871;0.90942603;-4.544669;2.408705;CODE
https kivy org;-4.5613203;-3.346022;3.4736364;0.2365067;-3.4969852;-1.4937578;CODE
if p returncode if not returncode 0;-1.5396272;6.703722;-1.9422337;1.2441021;1.156542;-4.5932317;IRRE
sdl3 dev is installed before setup py is run when installing from;-4.5420604;-2.0613637;-3.6680427;-0.55939484;-2.538971;2.0610995;CODE
source due to pyproject toml however it is installed to a;-5.9346905;-3.5718696;-2.4158764;0.00029693864;-1.2017311;2.6502419;-
pip isolated env which we need to add to compiler;-4.9402623;-2.2831168;-2.9136815;0.35854435;-0.95315796;1.675178;TASK
register an extension to ensure a compiler is created;-3.9214709;-1.499737;-2.870344;2.7108502;2.4876664;1.8108182;IRRE
disable building fake extensions;-4.764537;1.7733314;-2.5556772;3.1697192;-0.5134888;2.639749;-
run to populate self compiler;-3.371833;-1.3465676;-2.34004;2.6618268;0.53756374;-0.14794396;CODE
create a temporary file which contains the code;-4.2095547;0.034863096;0.85842866;1.4428333;0.5781893;-0.6989139;IRRE
determine on which platform we are;-1.166806;-3.2797194;2.5856488;-1.7202638;0.7439891;-2.6347551;CODE
detect python for android project http github com kivy python for android;-3.2308729;-4.7879276;-2.3707607;1.3751364;-3.9350345;-1.422023;CODE
proprietary broadcom video core drivers;-1.5726919;-2.9837098;-1.183849;-0.32290298;-1.0422941;3.2242491;-
force detected raspberry pi version for cross builds if needed;-2.1167912;0.025367985;-3.5825312;3.6435647;-0.96966666;0.8550694;CODE
the proprietary broadcom video core drivers are not available on the;-3.2522972;-2.9607852;-1.5846337;-0.22880122;-2.102293;2.311737;-
raspberry pi 4;-2.684756;-1.0850037;4.1585946;-2.7612112;-0.82874966;-1.0418905;-
use mesa video core drivers;-2.6397455;-2.62057;0.10297223;-0.25848997;-2.5749876;3.636392;-
needed when cross compiling;-3.8869834;-1.9758465;-2.9159348;0.26234886;0.518569;-1.0386667;-
if the user has specified a kivy deps root use that as the root for;-4.9069214;0.22497992;0.13375509;1.6093824;-0.48808935;0.7601218;IRRE
atm only sdl dependencies otherwise use the default locations;-4.1661654;0.1936771;-1.4551834;0.104750544;1.5773623;5.6500173;CODE
if kivy deps root is none and platform is linux or darwin show a warning;-5.3271155;-3.711542;-2.7506378;1.6818408;-2.8549347;-2.0307307;CODE
message because using a system provided sdl3 is not recommended;-6.3936844;-0.49139324;-2.6196642;-0.08851266;0.613563;1.6670893;CODE
will be shown only in verbose mode;-6.771754;2.2820218;1.7446874;2.4214365;-1.2171762;1.6431823;IRRE
print;-3.535585;-1.5634334;5.3574166;-2.6611266;-0.051176514;-3.929873;CODE
print;-3.535585;-1.5634334;5.3574166;-2.6611266;-0.051176514;-3.929873;CODE
detect options;-1.1267543;1.976655;2.5458505;3.591721;3.1006458;-0.43250257;-
now check if environ is changing the default values;-3.2130082;4.248074;-0.5069261;2.2230456;-1.9050913;1.0160338;IRRE
we want to be able to install kivy as a wheel without a dependency;-3.5922277;-3.35241;0.2217918;-0.28322968;-1.0811887;2.5700788;CODE
on cython but we also want to use cython where possible as a setup;-3.076595;-3.1728942;2.3453083;-1.1646601;-0.1737679;1.3199619;IRRE
time dependency through pyproject toml if building from source;-3.186297;-0.30262515;-2.1177218;2.753616;0.28142348;3.760551;CODE
there are issues with using cython at all on some platforms;-4.0713406;-2.8578308;-2.144965;-0.578249;-4.714992;0.77865213;CODE
exclude them from using or declaring cython;-2.0301292;3.0973425;-2.2871578;0.47300425;2.426361;-0.4437676;CODE
this determines whether cython specific functionality may be used;-2.6194413;-1.1407143;-0.7866437;1.6058618;1.3519819;0.6231852;CODE
never use or declare cython on these platforms;-4.581899;-1.7827175;-2.577263;-0.29672885;-1.2970227;-0.010656461;CODE
setup classes;-2.0113811;-3.2182522;1.9887284;-0.13696295;4.58329;-0.009873092;IRRE
the build path where kivy is being compiled;-4.837777;-5.097691;0.65907747;1.2607497;-2.9946868;0.46277118;CODE
version is imported by exec but help linter not complain;-5.574455;0.67371404;-4.550943;3.041167;-2.1057475;0.97771883;CODE
build the extensions in parallel if the options has not been set;-1.6111046;2.0801864;1.6166009;2.583088;3.3696048;4.2556367;IRRE
use a maximum of 4 cores if cpu count returns none then parallel;1.6629918;3.067734;-0.57566625;0.1766153;-0.11655418;-0.09656063;IRRE
build will be disabled;-7.226251;-1.3812046;0.36947787;2.1069636;-2.2621891;0.78795266;-
build files;-3.1398504;-5.0845876;2.0504236;0.25991613;-0.11952516;-1.391315;-
generate headers;-2.349003;-1.1034825;2.0404537;-2.1530857;2.7563152;-0.48453388;CODE
config pxi autogenerated file for kivy cython configuration n;-4.017983;-1.3803978;-2.4309647;-1.0843458;-2.1897178;3.0218122;CODE
config py autogenerated file for kivy configuration n;-3.2248282;-2.010651;-1.1514722;-0.09391731;-2.4238746;2.8234046;CODE
generate content;-1.693418;-2.0197194;4.9946976;-0.9053406;3.0944903;-1.5169061;-
config h define 0 1 n format opt value;-1.8443681;3.6174927;-4.6236286;-6.071466;1.3995222;0.6175988;CODE
extract version simulate doc generation kivy will be not imported;-3.536612;-1.9919316;-3.6730978;1.81167;-2.698887;0.21074922;CODE
cython check;-2.4763844;2.9846222;0.6393867;0.442263;-1.0161949;-5.0853505;-
on python for android and kivy ios cython usage is external;-3.9964774;-3.4650302;-1.8851945;-0.16161239;-4.735925;1.1935625;CODE
extra build commands go in the cmdclass dict command name commandclass;-5.375336;-3.890812;-4.7904005;1.1881669;0.46107277;0.74422497;CODE
see tools packaging platform build py for custom build commands for;-5.3178964;-5.815726;-2.284045;0.14703578;-2.4857183;0.16499509;CODE
portable packages also e g we use build ext command from cython if its;-4.2841496;-5.3645773;-0.3065235;-0.35510093;-0.71181077;0.4322729;CODE
installed for c extensions;-5.0982733;-3.2733147;0.5344606;-1.2884891;0.07557837;0.36472923;CODE
add build rules for portable packages to cmdclass;-3.802716;-3.9664657;-4.839202;1.639871;3.6738636;2.629925;CODE
detect which opengl version headers to use;-2.8233166;-0.13058726;-1.9871813;0.22117396;0.5983247;1.8932899;CODE
check if we are in a kivy ios build;-3.703055;-2.443347;-0.34075555;3.0595484;-2.5973618;-1.2810117;IRRE
detect gstreamer only on desktop;-1.62568;0.7335997;0.40975988;1.5013003;0.028172944;3.8025253;-
works if we forced the options or in autodetection;-5.941663;0.07314316;-1.3112508;4.455095;-0.39308748;5.5136504;CODE
check the existence of frameworks;-2.982858;-1.7962441;-1.5705055;4.241366;0.27196908;-1.5361377;-
use pkg config approach instead;-3.343634;0.37927365;-1.1528686;0.7587208;-0.21928653;4.426952;-
detect sdl3 only on desktop and ios or android if explicitly enabled;-3.0021527;0.56637377;-2.2259066;0.8425911;0.88699305;2.6018357;IRRE
works if we forced the options or in autodetection;-5.941663;0.07314316;-1.3112508;4.455095;-0.39308748;5.5136504;CODE
check the existence of frameworks;-2.982858;-1.7962441;-1.5705055;4.241366;0.27196908;-1.5361377;-
use pkg config approach instead;-3.343634;0.37927365;-1.1528686;0.7587208;-0.21928653;4.426952;-
declare flags;-3.212707;2.4839265;0.7031817;-1.0131415;3.8084505;-0.89943886;-
use xcode select to search on the right xcode path;-2.4690688;-1.7968205;1.0916126;-0.10523642;0.12849206;0.6239256;CODE
xxx use the best sdk available instead of a specific one;-3.3591456;-2.2211933;0.08266991;0.62973404;1.0192684;4.400872;IRRE
if darwin has already been configured with frameworks don t;-4.0380945;-5.739273;-2.0383933;3.725121;-1.614959;0.963244;CODE
configure sdl3 via libs;-5.6499977;-3.07816;-2.918667;-2.3134496;0.807247;2.6044526;-
todo move framework configuration here;-4.6142454;-0.98908734;1.5002997;1.9944195;-2.396105;4.3249483;TASK
no pkgconfig info or we want to use a specific sdl3 path so perform;-5.3749046;-2.2706134;-2.5674098;-1.1768073;1.0311754;3.3580608;IRRE
manual configuration;-3.6806152;-2.1238606;4.448018;-0.7980587;1.9744003;1.0803139;-
try to find sdl3 in default locations if we don t have a custom path;-6.4640827;-1.3097949;-2.0120828;-1.8422943;-0.7657469;3.2403185;CODE
if we have a custom path we need to add the rpath to the linker;-5.4630184;-0.7059641;1.0834464;0.82784545;-1.8630579;4.6076646;TASK
so that the libraries can be found and loaded without having to;-5.982483;-4.71823;-0.9508547;2.2487826;0.4249182;3.4727736;CODE
set ld library path every time;-4.104016;-1.4116817;-0.21155196;1.5097004;0.48473457;3.9377933;IRRE
ensure headers for all the sdl3 and sub libraries are available;-5.407773;-1.3255143;-4.011182;0.9037501;1.743275;3.690669;CODE
sources to compile;-2.8012726;-6.2755475;-1.130932;0.62292534;0.67012537;-2.2859912;CODE
all the dependencies have been found manually with;-2.6823661;-3.1302807;-1.1080353;0.6098682;-1.3268381;1.0545756;CODE
grep inr e cimport include kivy graphics context instructions pxd pyx;-5.137273;-1.8802569;-0.77683806;-2.3662715;-1.9813738;0.67207116;CODE
activate imageio provider for our core image;-2.8796568;-2.122091;0.6299696;0.8601722;-1.1219149;5.0491433;CODE
kivy graphics egl backend egl angle is always compiled;-5.170021;-2.5191276;-2.022735;-0.07446939;-4.9586077;2.9533584;CODE
but it only acts as a proxy to the real implementation;-5.6440735;-1.4022521;0.09644472;3.6951208;1.0870975;3.9515977;TASK
dispmanx is only available on old versions of raspbian buster;-4.300357;-1.1922077;-1.8509573;-1.006007;-2.557981;1.9965224;OUTD
for this reason we need to be sure that egl dispmanx is available;-3.6593115;-3.0400608;-0.28894857;1.448249;0.006229137;2.474207;CODE
before compiling the vidcore lite module even if we re on a rpi;-4.08202;-3.814909;-2.3218114;1.9749682;-2.5102017;1.7990149;CODE
fixme add an option to depend on them but not compile them;-4.7267075;-0.24654087;-3.6660511;3.5851383;1.3037926;2.1113672;CODE
cause keytab is included in core and core is included in;-4.862558;-1.9607325;-1.8162187;1.1598431;-0.06863924;2.460422;CODE
window x11;-6.307433;-2.2853935;5.1007857;-2.6707687;-0.9470872;0.94710207;CODE
depends;-1.2178625;-1.2130965;5.430064;3.3479671;0.94362056;-0.7497188;CODE
core window window x11 keytab c;-4.967537;-2.0182064;1.6685884;-2.4050615;-2.0938663;2.396697;CODE
core window window x11 core c;-4.723466;-1.9651072;1.771331;-1.27877;-1.9917896;2.6397867;CODE
extension modules;-3.6824346;-3.143951;1.404144;-0.092013404;2.121211;1.5260469;CODE
the cythonized file can be either a c or cpp file;-4.100323;-1.2043484;-1.5229388;-2.7115016;-0.28386146;0.16165672;-
depending on the language tag in the pyx file or the;-5.382495;-2.576926;-0.36979377;0.83853084;1.4502144;1.1626779;CODE
flag passed to the extension;-5.8423243;3.3112152;0.088670485;2.1457162;1.4138179;1.3964323;-
if the language tag or the flag is not set we assume;-4.6828218;2.5929596;0.45631135;3.1335998;1.343192;-0.27426887;IRRE
the file is a c file;-4.6107016;-2.4439733;0.47236323;-3.4162235;-1.5340741;-1.934822;-
if line 0;-1.7580154;5.284385;2.5331447;-2.920805;-2.6920779;-6.879885;-
can t use cython so use the c or cpp files instead;-4.6825786;-1.6163776;-2.0041466;-1.9037734;-2.9907591;0.8639471;IRRE
automatically detect data files;1.9999232;-1.2598315;0.6233309;1.8760204;1.6992631;-0.19813146;IRRE
setup;-3.0413523;-2.18117;7.284192;-1.2866654;1.5119874;-2.0934033;IRRE
flasky extensions flasky pygments style based on tango style;-3.3541012;-2.1761262;-0.8496929;-2.3358889;-2.3392267;2.415952;CODE
background color f8f8f8;-3.8543274;-1.0781245;3.2822547;-2.5986814;-0.64292336;1.9918228;-
no corresponding class for the following;-2.5372412;0.99017274;-1.4770709;-2.3371007;3.9594057;-2.2499042;CODE
text class;-1.8484664;-3.30638;3.6516757;0.12770832;4.058162;-4.130752;IRRE
whitespace underline f8f8f8 class w;-3.592975;0.12216941;-1.2054589;-1.6290175;0.3463652;0.13422953;IRRE
error a40000 border ef2929 class err;-3.5296688;0.8789629;-3.6370142;-1.944076;-1.0935875;-0.6600612;IRRE
other 000000 class x;-2.2413375;-1.2249068;-1.0808247;-2.4052596;4.704339;-2.8397985;IRRE
comment italic 8f5902 class c;-4.3332224;-1.1863289;-1.2552292;-0.9835848;0.27137372;-1.2583661;IRRE
comment preproc noitalic class cp;-5.108901;1.0963953;-1.3763645;0.103114665;2.15683;-1.187144;IRRE
keyword bold 004461 class k;-3.3349812;-2.227112;-4.494825;-2.5217028;4.126638;-2.574963;IRRE
keyword constant bold 004461 class kc;-3.1410153;-1.9042761;-5.3801966;-1.6438355;2.1135929;-1.7969397;CODE
keyword declaration bold 004461 class kd;-5.012618;-2.3272197;-5.991311;-2.4101214;5.106498;-1.051164;IRRE
keyword namespace bold 004461 class kn;-4.5084457;-2.8676672;-5.0893903;-2.071133;3.3545706;-0.59191376;IRRE
keyword pseudo bold 004461 class kp;-3.1521554;-1.8276467;-5.389119;-3.008699;4.2185;-0.5056437;CODE
keyword reserved bold 004461 class kr;-5.865508;-1.649628;-6.2589903;-1.5408682;2.9753692;-0.7280476;IRRE
keyword type bold 004461 class kt;-3.3596385;-2.0599406;-4.8342595;-1.5348054;3.4886918;-1.4715453;IRRE
operator 582800 class o;-1.469907;-0.28317228;-3.1538887;-2.7168956;2.1789572;-3.0776234;IRRE
operator word bold 004461 class ow like keywords;-2.8962379;-0.961391;-2.8247693;-2.1236138;5.1426253;-1.3311776;IRRE
punctuation bold 000000 class p;-4.0830765;0.533991;-2.4650204;-0.94171715;2.884444;-1.744001;IRRE
because special names such as name class name function etc;-4.993439;-3.4266117;-2.8106313;0.2049985;3.1875203;0.5724752;CODE
are not recognized as such later in the parsing we choose them;-2.559535;-1.8288808;-3.1832726;1.5263866;4.287773;-1.4470218;CODE
to look the same as ordinary variables;1.4705883;0.4666463;3.318799;-2.8491142;-0.25992444;-0.12401174;IRRE
name 000000 class n;-2.134369;-2.4666355;-0.6145291;-1.9342573;5.0768976;-4.470296;IRRE
name attribute c4a000 class na to be revised;-1.5688775;-0.16095473;-2.7993436;-0.36225945;3.0245416;0.78106964;IRRE
name builtin 004461 class nb;-5.642681;-2.7334244;-3.3396924;-3.1557007;4.570208;-2.695718;IRRE
name builtin pseudo 3465a4 class bp;-4.2401524;-1.1842545;-2.160889;-2.9959269;4.594781;-2.0441315;CODE
name class 000000 class nc to be revised;-1.547257;-1.9555421;-3.4435236;-0.29056782;4.7722073;-1.6796154;IRRE
name constant 000000 class no to be revised;-4.0687885;0.101253726;-5.5558767;0.5614038;3.7130806;-2.011833;CODE
name decorator 888 class nd to be revised;-4.776733;-2.5384753;-2.3161612;0.5733216;4.934934;0.734689;CODE
name entity ce5c00 class ni;-3.3530867;-1.9970942;-2.5433123;-1.6052718;4.3163815;-1.3273174;IRRE
name exception bold cc0000 class ne;-5.6293173;1.493834;-5.802706;-0.39774063;3.2234092;-2.1177697;CODE
name function 000000 class nf;-2.4843936;-0.6669176;-3.363623;-2.9191847;2.4159954;-1.7641035;CODE
name property 000000 class py;-4.5594506;-0.657621;-3.2989194;-1.1885895;1.0608058;-1.1639445;IRRE
name label f57900 class nl;-2.9381363;-1.8693938;-1.883743;-1.7359506;4.0892243;-0.6451638;IRRE
name namespace 000000 class nn to be revised;-3.6368606;-2.7464118;-3.275627;-0.4530196;4.3857636;0.3695119;IRRE
name other 000000 class nx;-2.861942;-2.5017483;-1.1505483;-2.6652136;6.0818334;-1.545139;IRRE
name tag bold 004461 class nt like a keyword;-3.8623989;-2.898803;-1.5591772;-1.6412092;6.608465;-1.4894999;IRRE
name variable 000000 class nv to be revised;-1.9222016;-0.32891682;-3.99558;-1.3917058;4.500105;-1.0490841;IRRE
name variable class 000000 class vc to be revised;-2.3665752;-1.1542686;-3.6385243;0.26235932;4.0821066;-0.4819687;IRRE
name variable global 000000 class vg to be revised;-2.5049074;0.45638356;-3.2598464;-0.30592215;3.240073;0.63407296;IRRE
name variable instance 000000 class vi to be revised;-3.0649617;0.68730146;-2.9466326;0.28562862;2.9717276;-0.45555854;IRRE
number 990000 class m;-0.04673246;-0.7370662;-0.86101747;-1.8232349;3.4745405;-4.2450056;IRRE
literal 000000 class l;-2.0252123;0.5537785;-2.5925844;-2.5183496;3.155885;-3.5938687;IRRE
literal date 000000 class ld;-3.4372985;-0.63846403;-4.152238;-0.64852875;2.0456378;-2.366261;IRRE
string 4e9a06 class s;-3.1499035;0.23474164;-2.3687692;-1.5651733;3.059507;-2.974481;CODE
string backtick 4e9a06 class sb;-4.1988544;1.3064878;-2.0539913;-2.6207838;2.305111;-1.901245;CODE
string char 4e9a06 class sc;-3.5121362;-0.22624029;-2.2358074;-2.6140532;1.8072457;-3.1714532;CODE
string doc italic 8f5902 class sd like a comment;-4.7322435;-1.7644844;-2.626167;-0.6488689;2.5692067;-0.9146411;CODE
string double 4e9a06 class s2;-2.8782485;0.6934369;-2.7744298;-1.885266;2.2010524;-2.3854485;CODE
string escape 4e9a06 class se;-5.960104;0.6406364;-3.5350063;-0.9997499;1.3053371;-1.3513074;CODE
string heredoc 4e9a06 class sh;-4.567209;0.13936912;-2.5659971;-0.6990754;0.19877285;-3.4392009;CODE
string interpol 4e9a06 class si;-0.44555032;1.3765924;-2.7984974;-3.5399637;1.1777582;-1.1074644;CODE
string other 4e9a06 class sx;-3.672402;1.0114074;-2.3136075;-2.3444407;4.557468;-0.3518101;CODE
string regex 4e9a06 class sr;-3.381408;0.7816657;-2.5474794;-1.0524169;2.3724618;-1.4362342;CODE
string single 4e9a06 class s1;-2.6523716;0.9212411;-2.9966843;-1.2175707;3.3808115;-1.9269979;CODE
string symbol 4e9a06 class ss;-4.164417;0.17467098;-3.4708972;-3.303378;2.63427;-2.4786658;CODE
generic 000000 class g;-1.7846513;0.8109179;-2.182258;-1.4361299;1.8660216;-0.48387983;IRRE
generic deleted a40000 class gd;-2.5613766;0.06728438;-3.7974584;-0.64551014;0.338104;1.2592224;CODE
generic emph italic 000000 class ge;-2.6315281;-0.97404516;-2.5116885;-0.28015357;2.2480195;0.55821604;IRRE
generic error ef2929 class gr;-1.5760789;0.2301289;-4.1372557;0.47708482;-0.89013326;0.2765241;IRRE
generic heading bold 000080 class gh;-3.5367873;-0.25353363;-2.711005;-0.6352483;2.6915534;0.9284774;IRRE
generic inserted 00a000 class gi;-3.9737833;0.99595344;-4.7231135;-1.1412491;1.10774;-1.1196669;CODE
generic output 888 class go;-3.472094;0.4035319;-1.2664051;1.0393152;1.8343871;-0.90839154;IRRE
generic prompt 745334 class gp;-5.6201077;-0.16669436;-3.565325;0.23229131;3.0541046;-2.2574358;IRRE
generic strong bold 000000 class gs;-0.65285444;-0.050736982;-3.394288;0.58011514;3.2513177;0.38276374;IRRE
generic subheading bold 800080 class gu;-2.683104;-0.25330463;-2.302158;-0.26444668;3.5532122;1.6797129;IRRE
generic traceback bold a40000 class gt;-2.2102263;-0.4845871;-4.5746136;0.027670864;0.33074865;1.2739066;IRRE
coding utf 8;-2.2597036;-0.29598916;0.812568;-3.4921522;-0.7222955;-2.8706045;-
requests documentation build configuration file created by;-5.8790054;-3.8794606;-0.4462434;1.5026398;-0.330115;1.3970114;CODE
sphinx quickstart on fri feb 19 00 05 47 2016;-4.8788805;-3.9255672;-0.730002;1.5444242;-1.1307642;0.4787581;-
this file is execfile d with the current directory set to its;-5.3623505;-0.64111584;0.8627418;-1.6821736;-0.47146434;-0.25704795;IRRE
containing dir;-4.2482185;0.14888301;2.1260679;-0.2025947;3.126726;-1.6528529;-
note that not all possible configuration values are present in this;-4.0269885;1.7806062;-2.0728424;-1.4211332;0.2766693;2.976292;IRRE
autogenerated file;-2.6622903;-1.6092923;0.4768964;1.0668072;2.4582222;2.0231407;-
all configuration values have a default values that are commented out;-3.3996913;2.869801;-1.5561066;0.23039457;-0.77078545;2.4323823;IRRE
serve to show the default;-6.2591634;2.3770394;3.6526113;2.3070273;-0.8275508;3.8172827;CODE
if extensions or modules to document with autodoc are in another directory;-3.8139288;-1.2493426;-1.0028208;2.95747;0.9660156;1.8234375;CODE
add these directories to sys path here if the directory is relative to the;-3.130132;-0.23988472;-0.8693889;-1.2777269;-0.6398868;1.0796407;TASK
documentation root use os path abspath to make it absolute like shown here;-5.560034;-1.5128824;0.062013976;-1.1033163;-1.9114153;2.959073;CODE
sys path insert 0 os path abspath;-5.2221756;0.44469514;-3.0043662;-1.3492218;-2.1599796;1.2215868;CODE
insert requests path into the system;-5.9205737;-0.5402358;2.5716786;2.0458748;-0.10110616;2.6188424;CODE
general configuration;-1.6665144;-1.8953097;4.9528403;-0.7313499;3.1215398;2.6917934;-
if your documentation needs a minimal sphinx version state it here;-6.799406;-3.060456;-1.6201835;1.1439428;0.69033074;1.1986457;TASK
needs sphinx 1 0;-4.574928;-0.31950846;-0.54887295;-0.48507512;0.08892079;-1.1704645;TASK
add any sphinx extension module names here as strings they can be;-5.6855083;-1.3969464;-3.0940416;-0.3708499;1.3559302;2.1287222;CODE
extensions coming with sphinx named sphinx ext or your custom;-6.3773146;-2.5510695;-1.7845818;0.23807573;0.83094424;2.493894;-
ones;-0.1170184;-3.3038795;4.461087;0.82844776;1.1854988;-3.9121974;-
add any paths that contain templates here relative to this directory;-2.8526237;-0.7756221;1.2785109;-0.37860417;1.0185225;2.385932;CODE
the suffix es of source filenames;-3.5360596;-3.5900643;-1.5617365;0.28925195;1.4745767;1.0933369;CODE
you can specify multiple suffix as a list of string;-1.6493461;0.58102614;-0.42444414;-0.2638016;5.314148;-1.4689327;CODE
source suffix rst md;-3.0286262;-2.1714687;-3.1323211;-1.4568328;2.1222918;0.95404094;-
the encoding of source files;-0.90304905;-4.4986157;-1.2714306;-2.8009505;0.91257775;-0.23665343;CODE
source encoding utf 8 sig;-2.564977;-1.8920555;-2.6501787;-2.5847952;-2.0755298;0.6962311;-
the master toctree document;-3.6820295;-5.8695035;0.5764255;1.1128042;2.8388803;0.09762363;CODE
general information about the project;-1.4553878;-7.376494;4.413974;2.562986;0.8087875;-0.93472874;CODE
the version info for the project you re documenting acts as replacement for;-5.883998;-5.21452;-0.67450833;2.3348181;2.6026688;1.2096146;CODE
version and release also used in various other places throughout the;-4.962456;-4.996021;2.37299;1.880815;2.145131;1.6651074;META
built documents;-3.4950507;-5.586781;2.6183264;0.99918884;4.256336;-1.3302522;CODE
the short x y version;-1.4770344;-2.6703897;3.2004478;-2.1971874;0.598142;-1.4319658;META
the full version including alpha beta rc tags;-4.3465614;-4.751778;0.32109475;1.3850931;2.32486;0.6121474;META
the language for content autogenerated by sphinx refer to documentation;-5.541554;-4.8018637;-0.59798056;1.3506373;3.3187819;1.5078458;CODE
for a list of supported languages;-2.1978807;-5.0841813;-0.033693917;1.2299162;2.5975893;-1.4713155;CODE
this is also used if you do content translation via gettext catalogs;-4.864568;-3.339762;0.57556164;0.2304377;2.576628;2.587601;CODE
usually you set language from the command line for these cases;-6.794775;-1.4304526;-1.3594517;-0.33877558;0.33963725;0.49447817;CODE
there are two options for replacing today either you set today to some;-4.4408827;0.47666615;1.9736682;1.6618247;-1.4712563;1.3690233;CODE
non false value then it is used;-1.9278315;6.877767;-0.6251047;0.2014954;1.0674958;-5.4338937;IRRE
today;-3.8903816;-2.2541597;5.503705;1.0546299;-0.34318042;-1.2506064;-
else today fmt is used as the format for a strftime call;-4.163191;-0.337088;-0.8317748;0.37311697;0.32002407;-0.32606488;IRRE
today fmt b d y;-2.1006398;-0.43953243;1.7802442;-1.0298971;-0.420352;-2.4673512;-
list of patterns relative to source directory that match files and;0.44502407;-2.949224;0.9860093;0.76151156;2.5115898;-1.1524383;-
directories to ignore when looking for source files;-0.68579966;0.18484327;-0.1453982;2.7046762;-1.0614476;1.0845112;CODE
the rest default role used for this markup text to use for all;-7.2502117;-1.5990709;1.9487442;-0.0680604;1.2499746;2.6118174;CODE
documents;-3.4800932;-5.146788;4.4602695;1.0624515;4.9219294;-2.004947;CODE
default role none;-6.7737517;0.58125097;-0.38524544;-0.91764396;-1.8721962;0.9601222;CODE
if true will be appended to func etc cross reference text;-3.0234392;3.9349806;-0.3798046;3.5039823;2.231236;-2.854845;CODE
if true the current module name will be prepended to all description;-5.7625747;0.91821414;-0.9203459;3.2490382;2.4089832;2.312538;CODE
unit titles such as function;-1.8826323;-1.1285205;2.9309309;-0.67404896;4.142305;-0.4230408;CODE
if true sectionauthor and moduleauthor directives will be shown in the;-5.7278347;-1.2794111;-1.1175047;0.67477125;-0.45736286;2.0765276;META
output they are ignored by default;-1.6826385;4.1260333;-1.967709;-0.040238615;-2.7251017;-0.50741875;IRRE
show authors false;-1.0726886;1.2062253;-1.7555493;1.1189109;-0.90513533;-3.6091504;META
the name of the pygments syntax highlighting style to use;-4.293606;-4.3571095;-0.9378605;-1.8235326;-0.3931547;0.5665542;CODE
a list of ignored prefixes for module index sorting;-1.505409;1.3613328;-2.637262;0.27577353;1.910825;1.1115563;CODE
modindex common prefix;-2.8329165;1.3828948;-0.27088445;-1.4015036;2.8180947;1.990871;-
if true keep warnings as system message paragraphs in the built documents;-4.2634907;1.2779143;-2.0984106;5.8506236;0.64919204;0.71687305;CODE
keep warnings false;-2.297178;3.4720724;-1.9959058;6.221587;-1.8769784;-0.9546324;-
if true todo and todolist produce output else they produce nothing;-2.2332125;3.6933565;0.32377318;3.0063019;-0.9269663;-2.489003;TASK
options for html output;-2.103958;-1.6871557;3.9995558;-0.3469148;0.12951207;0.301062;IRRE
the theme to use for html and html help pages see the documentation for;-5.734128;-5.3870683;3.232671;-0.09792297;-0.8818828;1.4461299;CODE
a list of builtin themes;-3.4004333;-6.8065505;3.7868178;0.0020094546;1.6952584;-0.62931716;CODE
theme options are theme specific and customize the look and feel of a theme;-2.2932634;-4.010802;3.3858967;-0.2933166;0.9937108;3.8526058;-
further for a list of options available for each theme see the;-3.3185728;-4.943438;5.136449;-0.07640668;2.4760995;2.5155826;CODE
documentation;-5.275622;-7.480966;3.7151163;2.304026;2.9932058;-2.7141862;CODE
note bg fff59c;-3.6278856;-1.5831064;-0.3284648;-3.4461532;-0.48160475;-1.3564295;TASK
add any paths that contain custom themes here relative to this directory;-2.7839477;-1.5204052;1.6016177;-0.6811076;0.06039186;3.1307425;TASK
html theme path;-4.6423397;-2.9701045;4.631136;-1.2658224;-1.2070507;2.4382272;-
the name for this set of sphinx documents if none it defaults to;-4.8452806;-1.2810842;-0.16310202;0.81097585;3.1778915;1.8357023;CODE
project v release documentation;-5.1252556;-6.5939956;-0.71911734;1.599466;0.26715338;0.018383637;CODE
html title none;-6.9493237;0.3297406;0.9405743;-0.2949359;-1.5806875;-1.5854825;-
a shorter title for the navigation bar default is the same as html title;-4.9117556;-1.1420512;1.1637268;0.35273474;-0.0108044995;2.4887555;CODE
html short title none;-6.0126605;0.49723396;0.8293653;0.14079161;-1.2020118;-1.5799385;-
the name of an image file relative to this directory to place at the top;-2.9921176;-0.94787973;4.684392;-2.3558118;-0.37927732;3.1543465;CODE
of the sidebar;-4.9647617;-3.8425605;6.934918;-0.9261423;-0.7293371;0.08718313;IRRE
html logo none;-5.460564;0.911316;2.0615942;-1.6727413;-2.3128157;-0.10209546;-
the name of an image file within the static path to use as favicon of the;-3.7721124;-1.0641137;2.4746397;-1.624857;-0.7352832;3.7811909;CODE
docs this file should be a windows icon file ico being 16x16 or 32x32;-4.954137;-1.6981033;-1.39213;-4.2825127;0.06622235;3.3182104;CODE
pixels large;-0.2168085;-0.19993682;3.4460833;-3.6162596;-2.8632224;1.9278531;-
html favicon none;-4.860114;0.054794293;1.5173441;-1.3250262;-3.5086834;1.7623163;-
add any paths that contain custom static files such as style sheets here;-2.7412045;-1.6984082;0.69596213;-0.6475392;1.2742815;3.5764132;TASK
relative to this directory they are copied after the builtin static files;-4.098321;-1.8378862;0.20292112;-0.3266008;-0.99920005;2.1655002;CODE
so a file named default css will overwrite the builtin default css;-4.867565;-0.06870731;-0.3100385;0.5236348;-0.2800337;3.5906715;CODE
add any extra paths that contain custom files such as robots txt or;-3.8289828;-2.5103002;0.5361193;0.62075764;0.99290264;2.1787992;TASK
htaccess here relative to this directory these files are copied;-2.6820016;-1.0540999;2.300358;-1.2484714;-2.0574923;0.66847736;CODE
directly to the root of the documentation;-7.7237444;-6.8337607;1.7328402;2.0410333;1.4792645;0.30104676;CODE
html extra path;-6.492363;-1.4858366;3.7212932;-0.1760661;-1.2025305;3.061004;-
if not a last updated on timestamp is inserted at every page bottom;-3.380057;2.6072447;2.429014;2.8160791;-2.1691463;2.4662716;CODE
using the given strftime format;-2.488044;0.19074644;-1.1781349;-1.4962364;-1.2541511;-0.8357097;CODE
html last updated fmt b d y;-4.614938;-0.5500267;0.99353236;-0.78108543;-2.1089;-0.027474448;CODE
if true smartypants will be used to convert quotes and dashes to;-1.6201993;0.4646741;-2.0583513;0.28860337;1.9917585;-3.298613;OUTD
typographically correct entities;-3.1627734;0.6653861;-0.6478671;2.030628;3.3413355;-1.8596458;IRRE
custom sidebar templates maps document names to template names;-3.412569;-1.7360795;0.35863417;-1.4760963;2.0999503;3.4815526;IRRE
additional templates that should be rendered to pages maps page names to;-3.0131454;-1.1686357;1.2176815;-0.24789006;2.9469469;3.8362076;TASK
template names;-4.152502;-2.8298323;2.2120771;-1.4921224;4.0623903;1.1020519;-
html additional pages;-3.935382;-1.7367023;4.864411;-0.72439694;2.3089595;2.8390627;TASK
if false no module index is generated;-3.1675193;4.984319;-3.764333;2.3079362;0.3254268;-0.8772129;CODE
html domain indices true;-1.8292311;1.2757429;0.5446816;-1.4391509;0.34986982;0.0065149814;CODE
if false no index is generated;0.39303786;7.091204;-1.9115977;1.5683416;1.3675897;-3.015084;-
html use index true;-3.595222;2.1236522;2.4619625;1.012533;-0.542303;1.031466;-
if true the index is split into individual pages for each letter;-0.087239206;2.9804232;1.2558324;-0.5887486;3.8742518;-0.63464457;CODE
html split index false;-2.4282386;3.4162977;0.732166;-1.030114;-1.0371385;0.43178147;-
if true links to the rest sources are added to the pages;-3.2874;0.18582988;0.83146113;3.5992918;0.12762827;1.9190313;TASK
if true created using sphinx is shown in the html footer default is true;-5.7614155;1.420397;-1.6190337;1.5887936;-0.7135032;1.2145429;IRRE
if true c copyright is shown in the html footer default is true;-5.4284353;0.7892899;-1.1160581;0.36055654;-1.0823772;0.9819789;CODE
if true an opensearch description file will be output and all pages will;-3.0695517;-1.2580261;-1.2844806;2.9611814;0.28644532;0.9312011;CODE
contain a link tag referring to it the value of this option must be the;-5.455162;1.0130816;1.7377074;0.8511398;1.8736529;1.8221148;TASK
base url from which the finished html is served;-5.415811;-0.27632585;5.6719785;0.42478263;0.12980822;2.660977;TASK
html use opensearch;-3.942055;-3.684547;0.3021388;1.6906439;-1.1141136;0.47765952;CODE
this is the file name suffix for html files e g xhtml;-6.2398553;-2.960945;0.9333552;-1.7751068;1.4997599;1.2871914;CODE
html file suffix none;-5.3716173;0.95808536;-1.431881;-1.0893004;-1.7058873;0.3232674;-
language to be used for generating the html full text search index;-2.2542915;-2.6141818;1.917369;0.44079798;1.2971416;-0.014188405;CODE
sphinx supports the following languages;-4.2167773;-3.5387232;-0.889378;-0.8469419;2.3370092;0.8272377;-
da de en es fi fr hu it ja;-0.9243625;-1.0577188;2.836581;0.6952012;-1.4077487;0.032006875;-
nl no pt ro ru sv tr;-1.6694536;-0.44466946;1.4689265;-1.1961275;-0.07480723;-0.9610874;-
html search language en;-3.9068787;-3.0351272;2.0748932;1.0197594;1.4431577;-0.8394484;-
a dictionary with options for the search language support empty by default;-2.8781736;-0.35976398;-2.3262017;1.3913424;1.4941993;0.18510282;CODE
now only ja uses this config value;-5.074632;2.0881412;-0.8662494;0.86514026;0.41433972;3.3981366;IRRE
html search options type default;-2.6479905;-0.35903046;0.004597047;0.81209123;-0.9208333;2.9113622;CODE
the name of a javascript file relative to the configuration directory that;-3.9569585;-1.2711532;3.0634649;0.42581937;-0.036905434;2.6593513;CODE
implements a search results scorer if empty the default will be used;0.5151587;3.723633;-0.50247306;4.5286365;2.433966;0.12870134;TASK
html search scorer scorer js;-0.97134197;-0.3231012;3.5369217;-0.28381294;0.2642837;-2.5472877;-
output file base name for html help builder;-4.987893;-1.4406427;1.4644281;-0.113422066;0.6334595;1.0862104;IRRE
options for latex output;-0.77418786;-2.2475128;3.2142375;-1.305479;1.1200869;-0.6471188;IRRE
the paper size letterpaper or a4paper;-1.7669125;-1.8389766;3.3320932;-2.1995568;1.0358329;0.8895433;CODE
papersize letterpaper;-2.1215465;-1.2520233;2.6150541;-1.7664456;0.23863205;2.3860862;CODE
the font size 10pt 11pt or 12pt;-1.6750573;-1.8809988;2.1688702;-2.4704711;-1.3557582;0.9013865;-
pointsize 10pt;0.7198778;-0.007150551;4.7257547;-3.0975966;-2.0303915;0.16284214;CODE
additional stuff for the latex preamble;-4.0489483;-5.061996;2.841277;0.6048962;3.489292;1.0690844;TASK
preamble;-4.110352;-1.4160292;3.664912;4.350269;1.8021462;-1.4311957;-
latex figure float alignment;0.32407802;1.310586;3.0394785;-3.5981898;-4.0184546;1.0959127;CODE
figure align htbp;-1.9149189;0.9280415;2.3876414;-4.90848;-2.906358;1.7099612;-
grouping the document tree into latex files list of tuples;2.3023336;-3.2386596;1.6762784;-1.7814533;2.390899;-0.30725157;CODE
source start file target name title;-4.7973037;-1.7677636;-0.032752488;0.9795698;0.54088956;1.6597416;CODE
author documentclass howto manual or own class;-4.0810566;-6.2627635;-1.1632161;1.919623;2.5834239;-0.7039961;CODE
the name of an image file relative to this directory to place at the top of;-3.2403562;-1.0557878;4.6419296;-2.4001656;-0.2781938;3.0401764;CODE
the title page;-5.557601;-5.0801597;6.191794;-0.4119689;0.5428871;-1.3154346;-
latex logo none;-4.6795306;1.0058596;1.4209571;-1.7388471;-1.7230723;-0.6875967;-
for manual documents if this is true then toplevel headings are parts;-4.174113;-2.4654324;0.16238014;1.2022654;4.7083106;1.2685717;CODE
not chapters;-3.0543485;-3.0068347;4.246442;1.6989915;1.0943677;-1.1838619;-
latex use parts false;-4.400668;3.907366;-0.7465189;1.2922089;1.1800579;-1.520928;-
if true show page references after internal links;-3.2312303;3.7853906;0.9523927;2.8663545;0.4734383;2.1625845;CODE
latex show pagerefs false;-3.6517825;3.0281918;-1.168384;0.85547566;-3.118687;0.31418604;-
if true show url addresses after external links;-2.8318703;3.254204;2.1855984;1.6215885;-0.78294367;0.13840763;TASK
latex show urls false;-3.7340508;2.6540372;0.61492246;0.69178444;-2.8468058;-0.8222282;-
documents to append as an appendix to all manuals;-4.516932;-2.821942;1.8482372;2.1152828;2.3311944;2.5015357;CODE
latex appendices;-4.149909;-0.12736838;2.8013356;-2.003273;1.6174768;1.6572851;CODE
if false no module index is generated;-3.1675193;4.984319;-3.764333;2.3079362;0.3254268;-0.8772129;CODE
latex domain indices true;-0.99045414;1.5662255;-0.77389324;-2.7926188;0.28047088;-1.070457;CODE
options for manual page output;-2.1640365;-1.3970991;2.0597456;1.3054615;0.63905376;1.6221924;IRRE
one entry per manual page list of tuples;-0.3255691;-1.3786653;1.401592;-1.0050623;4.6025724;-1.5290278;CODE
source start file name description authors manual section;-4.722677;-5.616155;-1.7339977;-0.40735802;1.5365365;1.2391104;META
if true show url addresses after external links;-2.8318703;3.254204;2.1855984;1.6215885;-0.78294367;0.13840763;TASK
man show urls false;-4.0776896;2.280605;1.0290836;1.5973512;-2.0528417;-0.82635564;-
options for texinfo output;-1.870882;-2.422926;0.2995383;0.8196815;-0.6365829;0.68801194;IRRE
grouping the document tree into texinfo files list of tuples;1.2388734;-3.2973933;0.27519876;-1.0996279;2.1005666;0.33326095;CODE
source start file target name title author;-4.7643156;-3.6008508;-1.5637186;0.71654177;-0.06073494;1.0970857;META
dir menu entry description category;-4.1906395;-3.5523632;1.1516713;0.22313368;3.6841507;1.2307802;CODE
documents to append as an appendix to all manuals;-4.516932;-2.821942;1.8482372;2.1152828;2.3311944;2.5015357;CODE
texinfo appendices;-5.4048266;-0.9674063;0.4808303;-0.53650755;0.58145046;2.4453812;CODE
if false no module index is generated;-3.1675193;4.984319;-3.764333;2.3079362;0.3254268;-0.8772129;CODE
texinfo domain indices true;-1.5438375;0.46594894;-2.3033707;-1.207148;-0.540229;-0.21325408;CODE
how to display url addresses footnote no or inline;-4.520831;0.14675863;1.5656279;-0.90221936;-1.2909973;0.7006027;TASK
texinfo show urls footnote;-3.869721;-2.2859752;0.87038153;1.1990033;-2.030577;0.79638183;TASK
if true do not generate a detailmenu in the top node s menu;-3.2686496;3.9121184;1.9046873;3.050851;-0.49774376;2.1372917;CODE
texinfo no detailmenu false;-5.349312;0.93899983;-0.23907575;2.001659;-3.255413;2.080789;-
options for epub output;-0.2544152;-1.4977194;0.07774519;0.15726647;-0.20425454;1.3791498;IRRE
bibliographic dublin core info;-1.4509227;-4.487126;0.84053624;-0.27796853;-0.72209835;-0.1727954;-
the basename for the epub file it defaults to the project name;-5.130788;-3.129251;-1.126996;0.022330794;0.009010737;2.212236;CODE
epub basename project;-2.1919181;-4.275771;0.09511357;-0.82869154;2.1784744;0.33050966;-
the html theme for the epub output since the default themes are not;-4.0080175;-2.2181203;1.2722687;-0.6163083;-1.9978304;2.8200386;CODE
optimized for small screen space using the same theme for html and epub;-1.0727814;-1.5475692;2.2320445;-0.62884;-1.4778346;4.860995;CODE
output is usually not wise this defaults to epub a theme designed to save;-3.3580496;-0.16749267;0.066647194;1.3392771;-3.3225813;2.3675704;CODE
visual space;0.16781223;-4.096241;6.539671;-2.2294936;0.99959284;1.5495485;-
epub theme epub;-4.0331526;-3.144839;2.2831137;-0.777278;-0.5780388;1.9334285;-
the language of the text it defaults to the language option;-5.234729;-1.4250088;1.3575565;0.7356239;-0.7370585;1.8366137;CODE
or en if the language is not set;-4.5562706;1.0014838;0.8786397;1.6045495;1.6363454;-1.3090055;IRRE
epub language;-2.4974377;-4.598109;1.0669488;0.25267646;1.3804922;-1.1572273;-
the scheme of the identifier typical schemes are isbn or url;-3.6331666;-3.7672336;-1.3886474;-1.0924183;5.799137;-0.53500175;-
epub scheme;-0.51240474;-1.3852749;0.50058734;-0.34693494;1.5157157;1.5152733;-
the unique identifier of the text this can be a isbn number;-1.8188543;-2.0167522;0.6934828;-3.0649126;6.710333;-3.5579722;CODE
or the project homepage;-3.8603806;-6.737098;3.6735747;2.6851957;-1.8618644;0.81723976;-
epub identifier;-2.9810336;-1.1028636;-1.3921474;-2.0781755;4.3191476;-0.4397077;-
a unique identification for the text;1.6157963;-1.3948193;1.9758679;-1.0942608;5.3736787;-2.4077287;CODE
epub uid;-3.2157037;-2.2558455;0.3052305;-0.49774832;1.1003299;-0.1534065;-
a tuple containing the cover image and cover page html template filenames;-2.4359126;-1.2571644;1.6677581;-1.2426192;1.5344099;1.7060446;-
epub cover;-2.1239393;-1.9495133;3.1115892;0.046492953;-0.018665578;0.6046485;-
a sequence of type uri title tuples for the guide element of content opf;-4.093714;-2.0852306;0.6321787;0.14288017;4.4064374;1.1620593;CODE
epub guide;-2.0316243;-4.657566;1.3749471;0.9018888;0.39844394;-0.2793996;-
html files that should be inserted before the pages created by sphinx;-5.054878;-0.948302;-0.056585796;0.5626719;0.2346735;2.9710522;CODE
the format is a list of tuples containing the path and title;-2.5459464;-3.763673;1.0412387;-4.0404377;2.9107301;-3.87298;CODE
epub pre files;-3.2376194;-2.8373597;-0.055253573;0.49798277;-0.09997185;1.5040506;-
html files that should be inserted after the pages created by sphinx;-5.1918774;-1.1727622;0.36565927;0.20914316;0.02896509;2.657977;IRRE
the format is a list of tuples containing the path and title;-2.5459464;-3.763673;1.0412387;-4.0404377;2.9107301;-3.87298;CODE
epub post files;-3.9280279;-2.701591;1.1465987;-0.19937745;-1.3521165;0.85192037;-
a list of files that should not be packed into the epub file;-0.10498286;-0.15472981;-1.4841768;0.8870501;0.714472;-0.056054816;CODE
the depth of the table of contents in toc ncx;-1.815084;-0.27323213;0.76496553;-1.6950264;0.5434765;1.2489289;CODE
epub tocdepth 3;-4.812689;-1.6416188;-0.5183486;-1.8235923;-0.031453338;-1.1029848;-
allow duplicate toc entries;-0.31290123;1.5657996;0.034772128;2.2010665;3.4278443;1.0547429;-
epub tocdup true;-2.4044821;0.20956352;-1.3353399;0.078216046;-0.3094733;-0.505431;-
choose between default and includehidden;-4.981778;-0.01575174;-0.2069135;3.1426113;2.7963762;4.933492;CODE
epub tocscope default;-3.3211558;-2.0174475;-1.7278463;0.7655685;-1.8463361;4.3463616;CODE
fix unsupported image types using the pillow;-2.2226858;0.4709552;-2.2389624;-1.3382386;-2.9896712;2.8259306;-
epub fix images false;-1.9416289;1.3036473;-0.9004824;0.30171537;-3.9025466;2.6483207;-
scale large images;3.8050349;-1.1642201;4.890664;-2.5478065;-2.2029388;4.356807;-
epub max image width 0;-0.8980019;1.1966176;0.111308575;-2.963293;-2.6105223;3.61065;-
how to display url addresses footnote no or inline;-4.520831;0.14675863;1.5656279;-0.90221936;-1.2909973;0.7006027;TASK
epub show urls inline;-3.3083184;-0.97057515;1.1694111;-0.027090307;-1.3196219;3.4276283;-
if false no index is generated;0.39303786;7.091204;-1.9115977;1.5683416;1.3675897;-3.015084;-
epub use index true;0.41358244;1.9915956;-1.7189565;0.15551409;0.09190229;1.1556727;-
usr bin env python;-4.4434032;-3.2804277;-2.2293892;-2.929091;-3.9376152;-3.5718482;CODE
setup py publish shortcut;-6.1352525;-2.679003;-0.14273891;-0.301848;-4.16054;1.9233888;IRRE
assert urllib3 version dev verify urllib3 isn t installed from git;-4.3724694;0.22352229;-4.644945;3.0032725;-1.9353962;-2.726097;CODE
sometimes urllib3 only reports its version as 16 1;-5.313641;-0.35702273;-3.8346255;0.19586891;-1.5350115;-0.6485775;META
check urllib3 for compatibility;-5.41392;-2.384969;-3.6109354;-0.47268736;-0.44340023;0.29270923;CODE
major minor patch urllib3 version noqa f811;-6.1890187;-2.1029866;-1.9639721;-0.8988099;-0.42085442;-0.082017526;META
urllib3 1 21 1;-4.56256;-0.46373883;2.1893268;-3.63722;1.0859101;-4.336745;-
check charset normalizer for compatibility;-1.8319749;1.2737801;-5.1116085;0.32841665;0.934611;1.7728393;CODE
chardet version 3 0 2 6 0 0;-5.2141914;-0.81039566;-3.3057697;-2.7341375;0.70741177;-2.666306;META
charset normalizer 2 0 0 4 0 0;-1.2680595;1.2332081;-2.5135067;-4.5284114;1.0459037;1.2313572;IRRE
cryptography 1 3 4;-3.009761;-0.20227484;1.6180867;-4.7247925;3.1099102;-4.426434;-
check imported dependencies for compatibility;-1.7092928;0.19290046;-4.228255;1.4015781;0.7028824;-0.322117;CODE
attempt to enable urllib3 s fallback for sni support;-6.100794;-2.7671106;-4.093018;0.99660856;-1.8275013;2.0406945;CODE
if the standard library doesn t support sni or the;-3.9867728;-4.9897876;-3.8756528;0.24901143;0.6507141;0.31484818;CODE
ssl library isn t available;-4.543202;-2.3487046;-1.0506393;-0.9198809;-2.9251277;0.1006483;CODE
check cryptography version;-4.2688446;0.4456714;-2.2637324;-0.38521683;0.34437573;-5.2002606;META
urllib3 s dependencywarnings should be silenced;-5.2481728;-2.235671;-3.8576753;5.4168973;-0.49430862;2.4259548;CODE
set default logging handler to avoid no handler found warnings;-4.222269;2.4228625;-2.2095635;4.581834;-2.7859523;3.4872913;CODE
filemodewarnings go off per the default;-2.8126118;1.3226167;-0.9198862;3.555717;-4.168752;5.120872;CODE
import socket noqa f401;-4.806144;-1.2759806;-1.6642002;-3.4146953;-1.6093739;-0.2832829;CODE
according to our docs we allow users to specify just the client;-5.181864;-1.707382;0.10978114;2.128997;2.4958465;4.900604;CODE
cert path;-4.831334;-1.5825593;0.6558992;-0.90314704;1.1024935;-1.4971069;-
can t handle by adding proxy manager to self attrs because;-5.642251;0.73169374;-0.5383842;3.0102887;-1.507966;5.126545;TASK
self poolmanager uses a lambda function which isn t pickleable;-2.6208699;1.3494383;-1.8581392;3.2105482;-1.9508214;1.9138755;CODE
save these values for pickling;0.45893288;0.88266295;2.1794095;-1.8834802;0.34327805;-2.2126093;IRRE
allow self specified cert location;-3.4273858;1.514969;-0.17943251;-0.50030327;0.6738785;1.4663452;CODE
fallback to none if there s no status code for whatever reason;-5.0720015;5.215174;-2.552526;3.8200998;0.43111548;-0.7894205;CODE
make headers case insensitive;-4.2639055;2.1876113;0.27694377;-0.6684536;2.9470577;1.4026347;CODE
set encoding;-1.0856638;-0.12499101;0.48082396;-3.8880973;2.182406;-0.43685603;IRRE
add new cookies from the server;-3.1304138;0.22907852;3.3161614;-0.01956087;-1.1651485;1.7564781;CODE
give the response some context;-3.5830152;-1.233247;6.116479;3.4597402;-0.5219278;-2.373619;CODE
only scheme should be lower case;-1.7443953;2.5653398;-1.697189;1.7479908;3.138677;2.221383;CODE
only scheme should be lower case;-1.7443953;2.5653398;-1.697189;1.7479908;3.138677;2.221383;CODE
if url startswith don t confuse urllib3;-5.863527;1.9601622;1.278644;2.9572513;0.6756437;-0.49318254;META
todo remove this in 3 0 0 see 2811;-5.9930234;3.0760462;-0.9101872;-3.3556864;-0.8532007;-1.0477843;CODE
this branch is for urllib3 v1 22 and later;-6.727563;-3.1450942;-1.1932644;-0.50048083;2.2402747;-0.33712712;CODE
this branch is for urllib3 versions earlier than v1 22;-7.1504145;-3.315226;-2.6066525;-0.12293333;1.4791244;0.35332954;CODE
by using the with statement we are sure the session is closed thus we;-4.571586;3.706343;0.8271627;3.5961583;0.2001935;-1.5563444;CODE
avoid leaving sockets open which can trigger a resourcewarning in some;-3.2268507;0.8313616;1.63705;3.8268552;-1.0858124;3.9354658;CODE
cases and look like a memory leak in others;-1.8111854;-0.05707642;1.7469479;0.2767927;1.3087119;-0.81824815;CODE
if response is not 4xx do not auth;-3.3692162;5.248673;-2.2022736;1.202018;-1.593086;-1.6261446;CODE
see https github com psf requests issues 3772;-5.7732697;-1.9405394;-1.0430247;0.2624318;-5.055744;-0.61341393;CODE
rewind the file position indicator of the body to where;-2.9836066;1.093982;5.488508;0.26020235;-1.3240279;3.8297749;-
it was to resend the request;-8.473318;-0.15527435;1.9793197;2.4982026;-1.6147819;1.6376923;CODE
consume content and release the original connection;-4.1090918;0.01561747;4.372419;2.5899336;0.13283256;4.1706905;IRRE
to allow our new request to reuse the same one;-6.422648;-0.7264212;3.565787;3.8029804;3.4852076;3.8648496;CODE
initialize per thread state if needed;-0.8468418;2.8564565;2.0009522;2.8563564;1.8744001;2.8349373;IRRE
if we have a saved nonce skip the 401;-2.147282;2.6633303;-1.4991589;3.5496216;-1.2175827;2.5872464;CODE
in the case of httpdigestauth being reused and the body of;-5.6890287;-0.44803065;2.0364742;2.9693189;1.1996536;3.0565176;CODE
the previous request was a file like object pos has the;-7.9755635;-0.94528574;-0.18433844;2.2410243;0.5694455;1.74952;CODE
file position of the previous body ensure it s set to;-4.3127728;2.939533;4.1538606;1.1525851;-1.9460447;3.4210162;IRRE
none;-1.9113709;-1.6103246;3.259452;0.9806513;-0.21791509;-4.18502;-
usr bin env python;-4.4434032;-3.2804277;-2.2293892;-2.929091;-3.9376152;-3.5718482;CODE
urllib3;-5.028319;-2.998216;2.7375042;-1.3870741;0.87114555;-3.090827;-
detect which major version of urllib3 is being used;-2.8255427;-0.052405912;-2.1219308;1.7863301;2.3157175;-1.0289055;META
if we can t discern a version prefer old functionality;-3.6626341;-2.4063437;0.21689129;4.3785286;1.1812202;0.99157834;META
character detection;2.2191417;-1.868078;3.2117832;-0.7922252;1.6367729;-2.202578;CODE
only return the response s url if the user hadn t set the host;-2.663793;4.293412;3.0577543;4.637511;-3.5897005;0.7521706;IRRE
header;-6.419937;-2.13438;5.8168955;-0.8260167;1.9629447;-1.5636332;CODE
if they did set it retrieve it and reconstruct the expected domain;-3.3137822;2.1224487;0.380904;2.6189055;-0.9474296;0.4801076;CODE
reconstruct the url as we expect it;-4.284566;0.025120804;4.0798388;1.3973494;-1.6963584;1.507738;CODE
if there are multiple cookies that meet passed in criteria;0.012090458;4.9204473;1.6840577;3.0449467;3.8106358;-0.15138492;-
we will eventually return this as long as no cookie conflict;-5.3270226;1.862082;1.8986447;2.3647542;-1.0390354;1.0772878;CODE
we re dealing with an instance of requestscookiejar;-5.041658;2.1055143;2.3690798;4.196136;-0.7764862;2.407364;CODE
we re dealing with a generic cookiejar instance;-3.4235623;-1.1105618;0.48790252;2.8579175;0.85265356;2.7653854;-
warnings;-3.1256826;-0.084715195;0.4136941;4.240725;-0.9979388;-2.9162078;-
todo response is the only one;-4.455443;-0.032083232;3.9938705;3.9765635;-0.5509635;-0.8177469;CODE
import encoding now to avoid implicit import later;-3.4515429;-0.40482503;-3.4495218;0.31035593;0.06902865;2.0217237;CODE
implicit import within threads may cause lookuperror when standard library is in a zip;-2.1760404;-0.425284;-6.9866056;1.6039339;-1.9477348;1.4679621;CODE
such as in embedded python see https github com psf requests issues 3578;-6.0905733;-4.304088;-2.6186202;0.466846;-4.9832096;-0.48848906;CODE
import encodings idna noqa f401;-3.3944802;-1.504931;-4.4640565;-3.6981237;-0.624162;-0.67433757;CODE
the set of http status codes that indicate an automatically;-3.8239028;-0.4385843;1.5711007;2.1803398;3.1994624;-0.079280674;IRRE
processable redirect;-5.3716097;1.6132467;2.8886745;3.5457015;-0.2913274;1.9298158;-
codes moved 301;-5.218517;-0.22418769;0.5441688;-1.5925645;-0.56251305;-1.3342576;-
codes found 302;-5.284875;-0.650701;-0.6815576;-0.5679223;-0.49787572;-4.372329;-
codes other 303;-4.2692494;-0.94427836;0.55491054;-3.1186593;3.4845672;-2.4518917;-
codes temporary redirect 307;-6.821167;2.015124;-0.21579218;0.6041396;-0.7151484;-0.68673325;-
codes permanent redirect 308;-6.6802855;1.3793589;-0.6676043;0.15611589;0.20748594;0.28361726;-
default empty dicts for dict params;-2.5438545;1.7063726;-2.1350513;-0.5123986;0.055609845;0.7719277;CODE
note that prepare auth must be last to enable authentication schemes;-4.934068;-0.5990231;-2.8034203;2.6112716;-0.3560265;0.015024729;TASK
such as oauth to work on a fully prepared request;-4.319416;-1.8620436;1.909847;3.0964394;1.1705117;0.87671065;CODE
this must go after prepare auth authenticators could add a hook;-5.646798;1.03956;-1.2521647;4.3757367;0.7397201;2.3744555;TASK
accept objects that have string representations;0.11632985;-0.33999032;0.23435919;0.49885094;4.1022887;-0.61254364;CODE
we re unable to blindly call unicode str functions;-4.451483;0.11864174;-2.4576652;-1.7653891;-2.3953252;-1.706982;CODE
as this will include the bytestring indicator b;-4.090014;-0.25087807;1.4091202;-2.9098997;4.2016673;-0.926824;CODE
on python 3 x;-3.4577177;-3.6854737;-0.27977052;-4.951252;-1.9853678;-4.846174;CODE
https github com psf requests pull 2238;-4.966717;-2.8111188;-0.9797179;0.3932135;-4.3722253;-1.0131693;CODE
remove leading whitespaces from url;-4.275889;0.83866584;1.461294;-0.3185747;-1.2790142;1.3484191;CODE
don t do any url preparation for non http schemes like mailto;-3.0898163;0.0177596;0.9478359;2.5750918;-0.8213906;1.7579299;CODE
data etc to work around exceptions from url parse which;-2.9158404;2.5306118;0.49242258;4.4469895;2.3407223;-0.6748592;CODE
handles rfc 3986 only;-5.9843745;0.15138379;-0.77801526;-0.9601788;2.7518427;-0.27788424;-
support for unicode domain names and paths;-3.9382188;-3.131869;0.026875908;-0.79960084;1.0851569;1.475285;CODE
in general we want to try idna encoding the hostname if the string contains;-2.7177944;1.4979388;-3.236772;0.67841387;0.77382433;-0.69795567;CODE
non ascii characters this allows users to automatically get the correct idna;-2.9717674;-0.43640265;-0.67376417;-1.0542393;1.6190515;-1.4438643;CODE
behaviour for strings containing only ascii characters we need to also verify;-1.1955706;4.3913608;-1.5052915;1.1774791;-1.743864;-3.346505;CODE
it doesn t start with a wildcard before allowing the unencoded hostname;-5.6787367;1.1488582;-2.7609212;1.2135292;0.9566283;-0.5131236;CODE
carefully reconstruct the network location;-0.18859322;-0.3737364;4.450054;-1.82805;-0.6391758;3.3113923;CODE
bare domains aren t valid urls;-3.2957437;1.6913595;-1.1244324;-0.35563752;-2.0274465;-0.33454838;CODE
check if file fo generator iterator;-0.9241652;3.9203372;-1.3269211;2.6862335;0.12087802;-1.7498983;IRRE
if not run through normal process;-2.7090046;5.5249033;0.74765736;3.2305996;-0.53530186;-2.4649525;CODE
nottin on you;-1.8489316;0.33866635;3.5109704;0.6631467;-2.4003358;-1.6165174;-
urllib3 requires a bytes like body python 2 s json dumps;-4.268889;-0.95694715;-4.3471794;-1.0363486;-2.908843;-0.84999883;CODE
provides this natively but python 3 gives a unicode string;-4.435937;-1.9029227;-2.700225;-2.9940777;-1.4469122;-1.6975758;CODE
record the current file position before reading;-1.7158933;1.7886906;3.7593176;1.1107479;-0.7407699;1.6054972;CODE
this will allow us to rewind a file in the event;-6.9187355;-1.2128282;4.9540663;3.4524105;-0.7944096;4.099337;CODE
of a redirect;-4.675187;0.95930177;4.7708817;2.3150263;1.1025702;-0.73964345;-
this differentiates from none allowing us to catch;-3.1789014;2.6512175;-0.08552742;3.4661593;0.50503886;-1.7516633;CODE
a failed tell later when trying to rewind the body;-5.7799063;3.6648288;1.1659502;3.5463698;-3.1938994;0.057826504;CODE
multi part file uploads;-0.9938596;-1.0499179;2.7646008;-0.91084594;1.8964202;2.2533069;CODE
add content type if it wasn t explicitly provided;-4.0293856;1.9480289;-1.968731;1.5894986;2.3224673;1.7966279;TASK
if no auth is explicitly provided extract it from the url first;-3.388942;2.2588208;-0.83667415;2.6101937;-0.8282826;1.0491077;CODE
special case basic http auth;-5.728957;1.1100041;0.24467438;-0.8885146;1.7061526;-0.46291056;CODE
allow auth to make its changes;-4.569143;-0.4884648;1.016797;1.6607729;-1.5276836;1.7271067;-
update self to reflect the auth changes;-3.8053706;0.42289564;-0.34051272;2.7496839;-2.0790112;2.4421897;CODE
recompute content length;-1.547588;1.979708;-0.073472686;-0.41338545;0.92383987;0.63283235;-
read the contents;-3.7830045;-3.9870489;4.4367476;0.29223853;0.75986546;-4.11864;CODE
don t need to release the connection that s been handled by urllib3;-5.968585;-0.8956311;-0.15754396;2.5768569;-1.3364862;2.5863922;CODE
since we exhausted the data;1.8921869;-0.20615566;2.8199108;2.6620743;-1.8204191;-2.6151109;-
try charset from content type;-4.343292;-0.18700166;-1.6154232;-0.504537;0.605746;-0.18110907;CODE
fallback to auto detected encoding;-1.110472;0.9609046;-4.997298;1.5709018;-0.001993175;2.0612128;-
decode unicode from given encoding;-1.1767478;0.33850208;0.1786375;-3.522666;0.10375476;-0.25267833;CODE
a lookuperror is raised if the encoding was not found which could;-1.8735094;1.3586226;-7.7651157;-0.8274767;-3.1040668;-2.3762355;CODE
indicate a misspelling or similar mistake;-3.5394347;1.5883614;-0.22938499;2.1585922;0.043669898;-2.5762358;-
a typeerror can be raised if encoding is none;-1.8814161;2.9589698;-7.5473676;-0.34879643;-2.5610018;-2.9000864;CODE
so we try blindly encoding;-0.5687403;-1.565307;-1.2601484;0.095838875;-1.4163969;-1.7048328;CODE
no encoding set json rfc 4627 section 3 states we should expect;-4.5730085;-0.0041555963;-4.8001146;-1.7760466;0.15025556;-0.51225215;IRRE
utf 8 16 or 32 detect which one to use if the detection or;-2.0430102;2.431701;-0.9421087;0.1315257;1.4282551;-2.5975628;CODE
decoding fails fall back to self text using charset normalizer to make;-1.4863261;1.237249;-3.9255774;-0.39529765;-2.1507723;2.5529535;CODE
a best guess;-1.0140374;-1.6434479;4.15097;2.165975;-0.94027305;-2.993769;-
wrong utf codec detected usually because it s not utf 8;-2.6594224;1.8664395;-4.8047466;-0.9454959;-2.5431354;-1.5704614;META
but some other 8 bit codec this is an rfc violation;-4.3089027;0.81207603;-3.090739;-2.1504674;2.8756073;-1.8215832;META
and the server didn t bother to tell us what codec was;-4.8085337;-1.4056478;-2.7777278;0.70891637;-0.8131455;-1.2508703;-
used;-5.3193235;-2.6206095;4.6549435;-0.1104514;-0.09298738;-3.4827583;-
catch json related errors and raise as requests jsondecodeerror;-2.293902;3.5973284;-2.9622347;4.151321;-3.4745567;-0.60346425;CODE
this aliases json jsondecodeerror and simplejson jsondecodeerror;-3.3088179;0.42015305;-2.9354336;-0.15274906;-2.7501457;1.0289668;CODE
we attempt to decode utf 8 first because some servers;-3.5704558;0.33479074;-0.9701863;-0.10523102;-2.0260608;-0.7618168;-
choose to localize their reason strings if the string;-1.771005;2.2760675;0.56366134;1.9107803;1.7955079;-1.133863;CODE
isn t utf 8 we fall back to iso 8859 1 for all other;-2.5759254;0.26202014;-1.7085698;-1.7985585;-0.10411545;-0.07700457;CODE
encodings see pr 3538;-3.337341;-1.1557338;-3.3165529;-3.5727024;0.09305566;-1.4902104;-
this code exists for backwards compatibility reasons;-5.9599814;0.356644;-3.6084802;0.5025069;1.2952136;-0.15322447;CODE
i don t like it either just look the other way;-2.384553;0.23730378;2.40992;-1.944399;-1.9780092;3.3672657;CODE
this traversal is apparently necessary such that the identities are;-4.8411946;1.5213768;-1.6330551;0.16994071;3.6965983;-1.0443999;CODE
preserved requests packages urllib3 is urllib3;-6.3889494;-0.46434355;-2.1114843;1.1848752;-0.4177148;1.4223193;CODE
formerly defined here reexposed here for backward compatibility;-7.2928815;-1.7733364;-3.0629148;0.8696546;1.2065008;2.4496272;CODE
from models import noqa f401;-1.9899532;-1.4933004;-3.4312332;-1.898553;-0.79232603;0.10322566;CODE
from utils import noqa f401;-4.273476;-2.1143048;-1.8773115;-3.3104696;-0.21448568;-1.882506;CODE
preferred clock based on which one is more accurate on a given system;1.6121418;0.8560454;1.8701861;2.1540802;-0.25250787;0.74040973;CODE
bypass if not a dictionary e g verify;-2.8625386;3.6091492;-2.7322204;3.9160526;0.79008;-3.851706;-
remove keys that are set to none extract keys first to avoid altering;-1.1818236;2.4022558;-1.5779574;-0.83070755;1.826741;0.5284928;IRRE
the dictionary during iteration;1.4837148;-0.104746886;1.7407211;1.7937787;1.4673897;-1.473339;-
special case allow http https redirect when using the standard;-4.1624327;2.5692902;-0.5759565;1.528414;-0.34237996;2.9396079;CODE
ports this isn t specified by rfc 7235 but is kept to avoid;-4.9342237;0.17608993;-0.4452095;-0.10432799;1.6667452;2.2725234;CODE
breaking backwards compatibility with older versions of requests;-5.2227674;1.0731163;-1.7099639;3.9760232;0.44804338;2.952638;CODE
that allowed any redirects on the same host;-4.7577844;1.0462689;1.5286697;1.2253951;-2.2878404;1.1433345;-
handle default port usage corresponding to scheme;-1.5499485;2.1168325;0.6207641;2.0469387;0.34489688;3.3226805;CODE
standard case root uri must match;-5.9357147;2.8186424;-1.5472782;-0.7302227;1.2804081;1.6318847;CODE
informational;-0.7322708;-3.4450603;5.2981715;2.7438843;3.5901077;-0.635577;CODE
redirection;-6.082681;0.6029449;5.863909;2.0760708;-0.2471244;-1.9597028;-
resume and resume incomplete to be removed in 3 0;-3.7726586;2.767972;-0.76638204;-0.2987678;0.37908456;1.0862616;OUTD
client error;-5.819324;1.5797446;0.15413225;-0.5322205;-2.9603875;-2.6140532;CODE
server error;-4.6257105;1.915388;1.8714014;-1.3483611;-2.552972;-3.480855;-
use the lowercased key for lookups but store the actual;-2.357508;0.5513506;-0.1325129;-1.4976026;4.0333676;2.101306;CODE
key alongside the value;-1.8896852;2.101414;4.2334986;-3.6568696;3.3241746;-1.1577348;IRRE
we allow fall through here so values default to none;-2.9531662;5.8020954;0.7824162;0.4187415;-0.44345772;1.3469718;IRRE
to native string is unused here but imported here for backwards compatibility;-6.9191933;-0.1928256;-5.2211;1.0658355;-1.6332798;0.2867279;CODE
from internal utils import noqa f401;-5.253477;-1.3004087;-2.794041;-2.4473994;-0.4090555;-0.32091516;CODE
ensure that is used to preserve previous delimiter behavior;-2.3836951;6.1040387;-2.1021378;2.4807673;2.1664667;0.60534006;OUTD
provide a proxy bypass version on windows without dns lookups;-2.6918976;0.54065424;-0.30877918;1.187172;-0.2592425;3.6307845;META
proxyenable could be reg sz or reg dword normalizing it;-4.6761074;0.37228826;-1.0500962;0.9770695;1.0181551;3.8941565;-
proxyoverride is almost always a string;-4.454341;1.7377204;-0.37842983;2.6825588;-0.43459657;2.6656194;CODE
make a check value list from the registry entry replace the;-4.5815773;3.0646708;-1.5364642;2.1572168;1.2660894;1.5618371;CODE
local string by the localhost entry and the corresponding;-3.511287;1.5320213;1.1262614;0.8261672;1.0664809;0.5952935;CODE
canonical entry;-1.9018662;-2.3225298;1.6812528;-0.19362098;5.9393477;0.17286606;CODE
filter out empty strings to avoid re match return true in the following code;1.0139215;6.2197394;-0.87845033;0.09152132;0.84362704;-3.8264208;CODE
now check if we match one of the registry values;-3.8525717;3.9967997;-2.4161263;1.804441;1.7155145;0.4508413;IRRE
test test replace r mask dots;2.2033165;4.2102013;-1.0224669;-1.6532177;-2.0532525;-3.7162573;IRRE
test test replace r change glob sequence;0.7444364;4.5581946;-1.0339487;0.48703867;-1.9723804;-4.497464;IRRE
test test replace r change glob char;-0.503605;4.1636863;-0.931834;0.26300198;-3.1686192;-3.9905024;IRRE
def proxy bypass host noqa;-4.014738;2.4118443;-1.0517751;0.08137941;-2.5312247;1.5871863;CODE
abort early if there isn t one;-2.8048015;2.563464;1.9824885;4.116657;0.77089196;0.61663926;-
return with login password;-4.0034447;1.4050672;1.9660087;0.64470136;-2.4209824;-1.4049115;IRRE
if there was a parsing error or a permissions issue reading the file;-4.949749;0.7987477;-1.125188;0.32075053;-2.2396963;-3.8170743;CODE
we ll just skip netrc auth unless explicitly asked to raise errors;-5.1489797;0.09419481;-3.5744736;2.9192812;-1.4963219;1.5316027;CODE
app engine hackiness;-3.3507724;-4.2728133;1.0415261;4.6314263;-1.080173;-0.05206196;-
from mitsuhiko werkzeug used with permission;-7.476323;-4.93119;0.30554518;0.9333734;0.016419787;0.44918245;CODE
from mitsuhiko werkzeug used with permission;-7.476323;-4.93119;0.30554518;0.9333734;0.016419787;0.44918245;CODE
from mitsuhiko werkzeug used with permission;-7.476323;-4.93119;0.30554518;0.9333734;0.016419787;0.44918245;CODE
this is not the real unquoting but fixing this so that the;-5.5063853;1.1973051;0.19264984;0.6384957;-1.6885006;0.6197082;CODE
rfc is met will result in bugs with internet explorer and;-6.2549706;-0.79506916;-1.8549057;2.058191;-0.46104947;0.58927923;IRRE
probably some other browsers as well ie for example is;-5.3832073;-2.1375453;1.1124943;0.8248221;-2.7772563;2.4880939;CODE
uploading files with c foo bar txt as filename;-3.1735733;-1.0300679;-0.07653686;-0.9452365;-1.2088473;-0.17679618;IRRE
if this is a filename and the starting characters look like;-5.782403;0.6970706;1.3070422;-2.6695452;-0.1760811;-2.6862705;CODE
a unc path then just return the value without quotes using the;-2.8564112;2.8816304;-0.24362022;-1.0154032;-0.1618587;-1.7621396;IRRE
replace sequence below on a unc path has the effect of turning;-2.4893773;2.7542977;1.3196876;-0.31531227;-1.9987204;-0.38635588;-
the leading double slash into a single slash and then;-6.144579;0.34502098;2.424917;-1.9224985;-0.84842765;-2.1030416;CODE
fix ie filename doesn t work correctly see 458;-5.6096683;0.931789;0.33444282;-1.6536994;-1.3047261;1.2610497;CODE
more information please see the discussion on issue 2266 this;-5.9004946;-2.5787227;-2.8149436;0.8757014;2.6024752;2.190011;CODE
assume utf 8 based on rfc 4627 https www ietf org rfc rfc4627 txt since the charset was unset;-2.7487404;0.46416765;-2.5429976;-1.043917;-0.6720137;-1.1445124;CODE
more information please see the discussion on issue 2266 this;-5.9004946;-2.5787227;-2.8149436;0.8757014;2.6024752;2.190011;CODE
try charset from content type;-4.343292;-0.18700166;-1.6154232;-0.504537;0.605746;-0.18110907;CODE
fall back;-1.0326751;0.9671373;4.7306957;1.1914278;-1.9349072;-1.4168466;-
the unreserved uri characters rfc 3986;-4.586728;-0.28677267;-2.4440854;0.16700847;0.8112566;1.0300024;CODE
afe with percent;0.6016488;-0.08373552;3.1060474;1.0108749;-0.090137;-1.5616629;-
afe without percent;0.36247578;0.66085786;2.435404;1.5617789;-0.119326405;-1.3505124;-
unquote only the unreserved characters;-1.6043148;2.4772503;-2.1395535;0.7132327;-0.31677118;0.25717974;CODE
then quote only illegal characters do not quote reserved;-5.353647;1.5010846;-3.297918;0.06431186;0.6454204;-0.85710263;CODE
unreserved or;-0.15116045;2.4703832;0.55493975;4.0978413;2.0160177;0.84153533;CODE
we couldn t unquote the given uri so let s try quoting it but;-6.414007;0.9542512;0.8284362;0.8991213;-1.4008569;-0.007238403;CODE
there may be unquoted s in the uri we need to make sure they re;-6.1593323;-0.41503474;-1.563904;1.7528768;-0.59606665;1.4083136;TASK
properly quoted so they do not cause issues elsewhere;-6.625218;-1.0644991;-3.4064093;1.8323556;-0.15792164;0.18476905;CODE
prioritize lowercase environment variables over uppercase;-0.10145287;1.769011;-1.8581337;1.1080711;2.9007926;2.764626;CODE
to keep a consistent behaviour with other http projects curl wget;-2.8669531;-0.0281594;0.5110411;3.776606;-2.203081;1.980373;CODE
first check whether no proxy is defined if it is check that the url;-3.8311656;2.1612117;0.25806168;1.1429582;-2.4387538;1.0553643;CODE
we re getting isn t in the no proxy list;-5.050921;-0.155468;0.5180211;0.5551867;-3.4906497;0.53673905;CODE
urls don t always have hostnames e g file urls;-4.0371246;-0.84923565;-0.030124461;-0.20811868;-2.1628222;0.86291075;CODE
we need to check whether we match here we need to see if we match;-1.0788405;3.5462327;2.52055;2.99055;0.50719434;-3.5879993;TASK
the end of the hostname both with and without the port;-6.0894413;0.5590859;2.1447248;-1.093917;-0.15746322;-0.86656725;CODE
if no proxy ip was defined in plain ip notation instead of cidr notation;-3.7028956;2.528863;-2.2122123;-1.7999085;0.6346909;1.3426278;CODE
matches the ip of the index;-0.37951994;3.4830217;1.9124926;-2.9029062;1.6416686;-1.2067939;-
the url does match something in no proxy so we don t want;-4.3439474;1.5561526;-0.24792987;1.5062344;-2.0702698;3.6562443;CODE
to apply the proxies on this url;-3.7983506;-1.3065469;3.4028733;1.1286359;-0.101482205;3.699332;CODE
parsed hostname can be none in cases such as a file uri;-5.7879496;1.3940156;-1.9411786;-0.41061005;-0.7817411;0.009061143;IRRE
null bytes no need to recreate these on each call to guess json utf;-0.9139441;2.633454;-1.3838997;1.0091913;0.052439574;-0.73647946;IRRE
null x00 encode ascii encoding to ascii for python 3;-3.0988524;0.51474214;-4.920203;-5.1653304;-3.4275763;-1.0300945;CODE
json always starts with two ascii characters so detection is as;-1.9605463;3.4216805;-1.0577995;1.3610307;-1.2089531;-1.350783;CODE
easy as counting the nulls and from their location and count;3.2261746;3.1235433;3.6176178;-2.2130365;2.8889837;-5.0661473;CODE
determine the encoding also detect a bom if present;0.96128917;3.01091;-2.4882793;-1.5753521;3.4941266;-2.2436612;-
return utf 32 bom included;-4.0262675;2.6009183;-3.5964634;-1.3067077;-0.58300716;-0.6081166;CODE
return utf 8 sig bom included ms style discouraged;-3.1738734;1.0310731;-5.080991;-0.77192265;0.018899877;1.2649956;CODE
return utf 16 bom included;-3.4396307;2.861208;-3.0090983;-0.867014;-0.9769365;-0.5350549;CODE
if sample 2 null2 1st and 3rd are null;1.827193;5.7637696;0.37077355;-0.7295735;3.0046508;-3.973109;-
if sample 1 2 null2 2nd and 4th are null;2.1507697;5.6764307;0.48194405;-1.2332131;3.022861;-3.9095933;-
did not detect 2 valid utf 16 ascii range characters;-2.9860787;3.3498118;-4.142906;-1.6030728;-2.805237;-2.4516966;CODE
did not detect a valid utf 32 ascii range character;-3.5900004;2.5401113;-4.32693;-1.9974397;-3.1331785;-2.513843;CODE
a defect in urlparse determines that there isn t a netloc present in some;-3.9642675;0.02609233;-2.8849514;1.8975312;-0.6949881;1.405496;IRRE
urls we previously assumed parsing was overly cautious and swapped the;-5.113422;-0.45445374;-1.4587797;3.725925;-0.4971446;1.532412;-
netloc and path due to a lack of tests on the original defect this is;-2.6051118;-0.78308195;-2.9634945;2.5942903;-2.3076637;-0.28717187;CODE
maintained with parse url for backwards compatibility;-5.575695;-0.23444413;-1.3495173;2.5665133;1.5575094;2.356909;CODE
parse url doesn t provide the netloc with auth;-4.389962;0.37711343;-2.7026649;0.6840068;-1.8896096;1.3949695;IRRE
so we ll add it ourselves;-2.9671066;-2.7101355;5.1897836;1.441876;1.6542712;-0.85965866;TASK
see func prepend scheme if needed;-3.5724113;0.15699159;0.81913966;0.22799085;1.6534158;2.3781562;CODE
issue 1483 make sure the url always has a trailing slash;-6.457735;2.093418;-0.9864301;0.0936179;-3.1965873;-1.32972;-
delay importing until the fixture in order to make it possible;-2.6520622;2.2712767;0.2316283;4.2970157;-1.0633508;2.9764519;CODE
to deselect the test via command line when trustme is not available;-2.8601143;5.5285745;-4.110342;5.3719144;-1.717819;-1.191514;CODE
only commonname no subjectaltname;-3.4920795;-0.33120504;-0.91275084;-1.1843075;2.2014916;-0.31708205;-
close server set release server block;-4.6502757;0.08019576;1.8668221;1.4604266;-0.9720536;2.1433072;IRRE
close server set release server block;-4.6502757;0.08019576;1.8668221;1.4604266;-0.9720536;2.1433072;IRRE
url f http host port path to thing view edit token hunter2;-6.155293;-2.534819;1.1064392;-0.7193913;-2.113455;1.4674945;CODE
b location get relevant section r n r n;-1.7004728;-0.056289565;4.3640614;-1.5891799;4.879081;0.628042;-
url f http host port path to thing view edit token hunter2;-6.155293;-2.534819;1.1064392;-0.7193913;-2.113455;1.4674945;CODE
verify we haven t overwritten the location with our previous fragment;-2.650486;3.826821;2.1573894;2.4311628;-2.0317934;1.3287138;-
assert r history 1 request url f http host port get relevant section;-2.8563473;4.1893563;-0.13473767;3.615574;-1.9338434;-0.99037814;CODE
verify previous fragment is used and not the original;-2.7850683;5.350618;0.66799605;2.8256073;0.086116046;0.89878684;-
assert r url f http host port final url relevant section;-2.8593128;4.686343;-0.34130272;2.6059113;-0.9911138;-1.8126323;CODE
see gh 3579;-3.3659656;-1.998059;2.019578;-0.28946543;-0.04881301;-0.038914725;-
connecting to an unknown domain should raise a connectionerror;-1.7169763;0.61738193;-2.0398622;0.8070589;-5.0513096;-0.47912434;CODE
connecting to an invalid port should raise a connectionerror;-2.0648572;1.8495821;-1.8112469;1.2898166;-4.576221;-1.5757612;CODE
inputing a url that cannot be parsed should raise an invalidurl error;-4.1043363;3.9801304;-1.1960396;2.8763866;-1.7305002;-0.15968901;CODE
any proxy related error address resolution no route to host etc should result in a proxyerror;-2.9493687;2.2748985;-3.349119;0.4862666;-3.9946969;0.53607696;TASK
should use netrc and work;-5.7983775;-2.9488444;0.8584989;-0.8223528;-1.0608426;1.753083;-
given auth should override and fail;-3.67909;3.2906916;-2.43831;3.2885628;-1.5235921;0.38850474;CODE
should use netrc and work;-5.798377;-2.9488442;0.8584994;-0.8223526;-1.0608431;1.7530819;-
given auth should override and fail;-3.67909;3.2906916;-2.43831;3.2885628;-1.5235921;0.38850474;CODE
should use netrc;-5.2399416;-4.4042115;1.569416;-0.21590698;-0.31521478;0.96014667;-
make sure that we don t use the example com credentails;-4.3911977;-1.0472268;-0.5775738;1.4742464;1.1494262;-0.68855625;IRRE
for the request;-4.5412703;-3.5361423;4.9989066;1.5942923;-0.33883634;-1.1361283;CODE
compat str is unicode;-5.3686147;-0.13077271;-2.977832;-2.6378348;-1.0510943;-1.097051;-
from issue 6935;-4.4371853;-3.3621213;0.08541347;-0.35207716;2.0823834;-2.6920788;CODE
prefix https example com trailing slash;-4.908105;1.9253412;0.47427833;-0.8779991;-2.0382316;0.06667158;CODE
from issue 6935;-4.4371853;-3.3621213;0.08541347;-0.35207716;2.0823834;-2.6920788;CODE
prefix https example com no trailing slash;-5.1257706;2.1437056;-0.32847324;-0.61290175;-2.457717;0.12219013;CODE
from issue 1321;-5.7360797;-2.3214943;-0.56218046;-0.3381822;1.4095367;-1.8179525;CODE
url http 9000 path query frag format;-3.7025988;0.0043806233;1.4077643;-1.7173902;0.51585245;1.3128498;CODE
this is testing that they are builtin strings a bit weird but there;-3.6365142;0.42450443;-1.3770177;0.6329718;-0.03811842;-5.187115;IRRE
we go;-2.904562;-1.7092183;4.626936;1.0545876;-1.471672;-1.5301409;-
per discussion in gh issue 3386;-4.446066;-0.3382385;-3.1056273;1.1715709;0.4350149;1.7019299;-
make sure r content is none;-2.7186117;3.6342294;-1.5309349;-1.1737928;-2.0891871;-1.4555625;-
default behavior;-4.553257;1.0250558;1.996191;4.0635643;-0.3790165;2.9540384;CODE
edge case check to see if location is in headers anyways;-4.635617;3.3792562;1.35824;0.3645753;1.087621;2.2280385;CODE
the n 1 th request fails;-5.1212506;2.974798;-1.2601346;0.354886;-1.1093919;-1.7540113;CODE
if the server thread fails to finish the test suite will hang;-2.452998;2.5705483;-0.61085397;5.5365005;-2.8058817;-2.772735;TASK
and get killed by the jenkins timeout;-2.8981678;-1.1112784;2.3466659;3.9130478;-1.5324987;0.508866;-
illegal bytes;-4.814637;1.2334229;-1.6209313;-3.254108;-1.5775008;-4.588678;-
reserved characters;-5.1963987;-0.4416788;-0.04914401;-0.61979145;2.1216729;-1.6831547;CODE
xxx unsure whether this is reasonable behavior;-3.0999372;4.7899613;1.0361074;1.4631354;-0.09527292;0.20246005;META
scikit learn documentation build configuration file created by;-3.9600399;-9.927073;-4.194255;0.41232544;-2.2379794;-2.3602831;IRRE
sphinx quickstart on fri jan 8 09 13 42 2010;-5.1329308;-3.6460268;-1.0790427;1.4264487;-1.1117867;0.8242676;-
this file is execfile d with the current directory set to its containing;-4.9612026;-0.14045922;0.4323283;-1.39122;0.18530825;-0.46917707;IRRE
dir;-4.2818923;-1.8943379;5.443149;0.14097983;1.2263892;-2.9519448;-
note that not all possible configuration values are present in this;-4.0269885;1.7806062;-2.0728424;-1.4211332;0.2766693;2.976292;IRRE
autogenerated file;-2.6622903;-1.6092923;0.4768964;1.0668072;2.4582222;2.0231407;-
all configuration values have a default values that are commented out;-3.3996913;2.869801;-1.5561066;0.23039457;-0.77078545;2.4323823;IRRE
serve to show the default;-6.2591634;2.3770394;3.6526113;2.3070273;-0.8275508;3.8172827;CODE
if extensions or modules to document with autodoc are in another;-4.101307;-1.5075133;-1.4834803;3.874117;2.1161568;1.7785672;CODE
directory add these directories to sys path here if the directory;-3.0222;0.12928623;0.73320174;-0.5902045;-0.2677048;-0.6921715;TASK
is relative to the documentation root use os path abspath to make it;-6.846311;-3.8536847;-1.1764064;0.57921505;-0.8715704;1.742568;CODE
absolute like shown here;-0.4831996;0.46452823;5.54197;-1.4618489;-1.4760778;-0.021415636;-
configure plotly to integrate its output into the html pages generated by;-1.2047389;-0.06295731;3.210562;-1.5703024;-4.795488;3.5206366;CODE
sphinx gallery;-3.6241593;-3.1369593;3.551655;-1.9837306;1.0262355;1.3912139;-
make it possible to render the doc when not running the examples;-4.9253535;-0.71424544;0.4969889;4.629847;-0.16383621;2.9893026;CODE
that need plotly;-1.0353024;-1.8201687;6.3991766;-0.8162503;-4.477357;-0.53461516;-
general configuration;-1.6665144;-1.8953097;4.9528403;-0.7313499;3.1215398;2.6917934;-
add any sphinx extension module names here as strings they can be;-5.6855083;-1.3969464;-3.0940416;-0.3708499;1.3559302;2.1287222;CODE
extensions coming with sphinx named sphinx ext or your custom ones;-6.0428095;-2.9165895;-1.7922026;0.28836215;0.71328247;2.3521852;-
see sphinxext;-4.7216;-4.3423867;0.63770646;0.37269562;0.33469316;-0.4670651;-
specify how to identify the prompt when copying code snippets;-5.226892;0.20080693;-1.7143587;3.2408347;0.68830866;-1.2983782;-
import jupyterlite sphinx noqa f401;-5.1867485;-1.3759379;-3.099806;-2.111449;-1.9969138;-0.020628467;CODE
in some cases we don t want to require jupyterlite sphinx to be installed;-4.891117;-2.37411;-2.5987127;1.6457158;-0.40062055;3.0489562;CODE
e g the doc min dependencies build;-4.51063;-6.6492;-0.17204319;3.0881305;2.4970171;1.5567269;CODE
produce plot directives for examples that contain import matplotlib or;-0.39943358;-4.0381794;-0.4232692;-2.498249;-4.2014647;2.0873811;CODE
from matplotlib import;0.46849322;-5.0013275;-0.53252965;-5.471847;-7.8529954;0.0009789019;CODE
options for the plot directive;-2.880154;-1.8737593;5.838184;-1.7739474;-3.4851747;4.3877206;CODE
https matplotlib org stable api sphinxext plot directive api html;-3.8658867;-3.3983557;-2.1468823;-3.4036455;-6.2085943;2.6132154;CODE
we do not need the table of class members because sphinxext override pst pagetoc py;-4.311492;-2.1519105;-3.7413375;0.97530603;1.2070105;1.1113751;CODE
will show them in the secondary sidebar;-3.034702;-2.4031718;5.2038507;-1.033653;0.5736751;2.2515278;IRRE
we want in page toc of class members instead of a separate page for each entry;-1.6622939;-1.4781582;1.4913385;1.191105;4.77872;1.9322141;CODE
for maths use mathjax by default and svg if no mathjax env variable is set;-1.2971494;0.61407596;-1.7444128;-0.6383994;-1.640937;3.0387726;CODE
useful for viewing the doc offline;-4.386508;-6.010475;2.5870233;2.2929401;0.0968822;0.9010974;CODE
add any paths that contain templates here relative to this directory;-2.8526237;-0.7756221;1.2785109;-0.37860417;1.0185225;2.385932;CODE
generate autosummary even if no references;0.13307229;2.3676727;-0.6723674;3.1951218;2.6551747;0.371221;CODE
the suffix of source filenames;-3.4956007;-3.615554;-1.516908;-0.2901678;1.8410093;1.1498793;CODE
the encoding of source files;-0.90304905;-4.4986157;-1.2714306;-2.8009505;0.91257775;-0.23665343;CODE
the main toctree document;-4.243085;-5.9445047;1.8096737;0.56580335;2.1148844;-0.4682721;CODE
general information about the project;-1.4553878;-7.376494;4.413974;2.562986;0.8087875;-0.93472874;CODE
the version info for the project you re documenting acts as replacement for;-5.883998;-5.21452;-0.67450833;2.3348181;2.6026688;1.2096146;CODE
version and release also used in various other places throughout the;-4.962456;-4.996021;2.37299;1.880815;2.145131;1.6651074;META
built documents;-3.4950502;-5.5867815;2.6183276;0.99918896;4.2563357;-1.3302513;CODE
the short x y version;-1.4770324;-2.670388;3.2004483;-2.1971877;0.5981427;-1.4319657;META
the full version including alpha beta rc tags;-4.3465614;-4.751778;0.32109475;1.3850931;2.32486;0.6121474;META
removes post from release name;-5.796663;-0.093296565;0.7268054;1.6185673;-0.61086386;1.813095;CODE
the language for content autogenerated by sphinx refer to documentation;-5.541554;-4.8018637;-0.59798056;1.3506373;3.3187819;1.5078458;CODE
for a list of supported languages;-2.1978807;-5.0841813;-0.033693917;1.2299162;2.5975893;-1.4713155;CODE
language none;-5.7895727;-1.5304825;1.2376621;0.30840692;-1.3493395;-4.411798;-
there are two options for replacing today either you set today to some;-4.4408827;0.47666615;1.9736682;1.6618247;-1.4712563;1.3690233;CODE
non false value then it is used;-1.9278315;6.877767;-0.6251047;0.2014954;1.0674958;-5.4338937;IRRE
today;-3.8903816;-2.2541597;5.503705;1.0546299;-0.34318042;-1.2506064;-
else today fmt is used as the format for a strftime call;-4.163191;-0.337088;-0.8317748;0.37311697;0.32002407;-0.32606488;IRRE
today fmt b d y;-2.1006403;-0.43953332;1.7802446;-1.0298961;-0.42035195;-2.4673524;-
list of patterns relative to source directory that match files and;0.44502407;-2.949224;0.9860093;0.76151156;2.5115898;-1.1524383;-
directories to ignore when looking for source files;-0.68579966;0.18484327;-0.1453982;2.7046762;-1.0614476;1.0845112;CODE
the rest default role used for this markup text to use for all;-7.2502117;-1.5990709;1.9487442;-0.0680604;1.2499746;2.6118174;CODE
documents;-3.4800932;-5.146788;4.4602695;1.0624515;4.9219294;-2.004947;CODE
if true will be appended to func etc cross reference text;-3.0234392;3.9349806;-0.3798046;3.5039823;2.231236;-2.854845;CODE
if true the current module name will be prepended to all description;-5.7625747;0.91821414;-0.9203459;3.2490382;2.4089832;2.312538;CODE
unit titles such as function;-1.8826323;-1.1285205;2.9309309;-0.67404896;4.142305;-0.4230408;CODE
add module names true;-5.7788076;-0.38980773;-1.4111986;0.6478277;0.5100571;0.051174298;TASK
if true sectionauthor and moduleauthor directives will be shown in the;-5.7278366;-1.2794098;-1.1175059;0.6747716;-0.45736352;2.076527;META
output they are ignored by default;-1.6826385;4.1260333;-1.967709;-0.040238615;-2.7251017;-0.50741875;IRRE
show authors false;-1.0726897;1.2062235;-1.7555497;1.1189103;-0.9051353;-3.6091506;META
a list of ignored prefixes for module index sorting;-1.505409;1.3613328;-2.637262;0.27577353;1.910825;1.1115563;CODE
modindex common prefix;-2.832916;1.3828944;-0.2708839;-1.401503;2.818095;1.9908704;-
options for html output;-2.103958;-1.6871557;3.9995558;-0.3469148;0.12951207;0.301062;IRRE
the theme to use for html and html help pages major themes that come with;-4.5966682;-5.993997;3.600302;0.0514852;-0.5594543;0.90770024;CODE
sphinx are currently default and sphinxdoc;-5.456008;-2.5677922;-1.4882972;0.8492153;-0.12882222;2.6894898;CODE
this config option is used to generate the canonical links in the header;-5.6201153;-1.9809089;0.22818299;-0.7099051;2.0788507;5.3617935;CODE
of every page the canonical link is needed to prevent search engines from;-2.9668953;-1.8185443;1.1724504;1.2729577;1.1253815;3.5369093;IRRE
returning results pointing to old scikit learn versions;-0.08022994;-6.8644576;-6.0577335;2.9738224;-3.6502278;-3.9295762;IRRE
theme options are theme specific and customize the look and feel of a theme;-2.2932625;-4.010801;3.3858974;-0.29331696;0.9937113;3.8526058;-
further for a list of options available for each theme see the;-3.3185728;-4.943438;5.136449;-0.07640668;2.4760995;2.5155826;CODE
documentation;-5.275623;-7.4809656;3.7151172;2.3040247;2.993205;-2.7141852;CODE
general configuration;-1.6665144;-1.8953097;4.9528403;-0.7313499;3.1215398;2.6917934;-
if prev next is included in article footer items then setting show prev next;-3.5667312;2.2186463;2.6110628;1.1248235;0.64574564;1.893074;IRRE
to true would repeat prev and next links see;-4.146485;1.2545333;4.323679;3.7117286;0.674755;0.9808638;-
https github com pydata pydata sphinx theme blob b731dc230bc26a3d1d1bb039c56c977a9b3d25d8 src pydata sphinx theme theme pydata sphinx theme layout html l118 l129;-7.027888;-2.5235043;-3.0642374;-6.2486043;-1.3465502;1.5574157;TASK
the switcher requires a json file with the list of documentation versions which;-6.2152443;-3.405194;-1.8226429;1.7200273;-0.45315203;1.7769059;CODE
is generated by the script build tools circle list versions py and placed under;-5.306946;-3.9729996;-1.5579209;-0.44860476;-3.086557;-0.4690348;META
the js static directory it will then be copied to the static directory in;-4.473361;-1.8798106;3.7494242;0.8120944;-2.6406708;3.0941715;CODE
the built documentation;-5.334483;-9.0008;2.460175;2.580104;2.7147768;-2.468725;CODE
check switcher may be set to false if docbuild pipeline fails see;-5.2261295;2.0850217;-4.546873;4.2594323;-2.1440306;-0.0902044;CODE
https pydata sphinx theme readthedocs io en stable user guide version dropdown html configure switcher json url;-6.6693845;-1.7775903;-0.6399003;-1.2678039;-2.1823103;2.552475;CODE
template placement in theme layouts;-2.0697153;-1.2085512;3.4633453;-1.4618136;0.88254124;4.342629;CODE
note that the alignment of navbar center is controlled by navbar align;-1.8270035;0.53480816;2.2910883;-1.8039579;-1.9767945;4.2569585;IRRE
navbar persistent is persistent right even when on mobiles;-2.5474854;1.3787172;2.3002243;1.8215069;-2.3272367;4.7110353;IRRE
use html sidebars that map page patterns to list of sidebar templates;-1.5260277;-2.4054122;3.072328;-1.580204;2.1692412;2.5644011;IRRE
when specified as a dictionary the keys should follow glob style patterns as in;-1.9229584;-1.8960215;-2.5044389;-2.215979;1.5679997;1.2833868;-
https www sphinx doc org en master usage configuration html confval exclude patterns;-4.698184;1.1175771;-2.802244;0.7662122;0.64630216;2.7216778;CODE
in particular specifies the default for all pages;-5.645748;-0.1194778;0.11604985;2.1979098;0.46910545;4.9385934;CODE
use html theme sidebar secondary remove for file wide removal;-3.5236967;0.6756376;1.917775;-0.9228987;-0.53606087;5.1369853;IRRE
sphinx gallery specific sidebar components;-5.0679502;-1.5884848;1.6289934;-2.8153193;1.8597232;4.9242635;IRRE
https sphinx gallery github io stable advanced html using sphinx gallery sidebar components;-5.557317;-2.2747035;-0.28808737;-0.9941492;-1.3837557;3.5726385;IRRE
add any paths that contain custom themes here relative to this directory;-2.7839477;-1.5204052;1.6016177;-0.6811076;0.06039186;3.1307425;TASK
html theme path themes;-3.3394637;-3.9195487;3.5062592;-1.4292636;-0.6530954;3.0691504;-
the name for this set of sphinx documents if none it defaults to;-4.8452806;-1.2810842;-0.16310202;0.81097585;3.1778915;1.8357023;CODE
project v release documentation;-5.1252556;-6.5939956;-0.71911734;1.599466;0.26715338;0.018383637;CODE
html title none;-6.9493237;0.3297406;0.9405743;-0.2949359;-1.5806875;-1.5854825;-
a shorter title for the navigation bar default is the same as html title;-4.9117556;-1.1420512;1.1637268;0.35273474;-0.0108044995;2.4887555;CODE
the name of an image file within the static path to use as favicon of the;-3.7721126;-1.0641135;2.4746401;-1.6248565;-0.73528343;3.7811913;CODE
docs this file should be a windows icon file ico being 16x16 or 32x32;-4.9541345;-1.6981033;-1.3921286;-4.282512;0.06622169;3.318211;CODE
pixels large;-0.21680874;-0.19993608;3.4460838;-3.6162608;-2.8632214;1.9278532;-
add any paths that contain custom static files such as style sheets here;-2.7412045;-1.6984082;0.69596213;-0.6475392;1.2742815;3.5764132;TASK
relative to this directory they are copied after the builtin static files;-4.098321;-1.8378862;0.20292112;-0.3266008;-0.99920005;2.1655002;CODE
so a file named default css will overwrite the builtin default css;-4.867566;-0.06870737;-0.3100391;0.5236358;-0.2800345;3.5906715;CODE
if not a last updated on timestamp is inserted at every page bottom;-3.380057;2.6072443;2.4290144;2.8160796;-2.1691465;2.4662707;CODE
using the given strftime format;-2.488044;0.19074644;-1.1781349;-1.4962364;-1.2541511;-0.8357097;CODE
html last updated fmt b d y;-4.614938;-0.5500267;0.99353236;-0.78108543;-2.1089;-0.027474448;CODE
custom sidebar templates maps document names to template names;-3.412569;-1.7360795;0.35863417;-1.4760963;2.0999503;3.4815526;IRRE
workaround for removing the left sidebar on pages without toc;-4.1382036;0.89286125;0.98702997;0.05300856;-1.4153535;4.293397;IRRE
a better solution would be to follow the merge of;-4.029878;1.064332;-0.16060327;2.5091126;2.0403905;4.1949124;-
https github com pydata pydata sphinx theme pull 1682;-6.947257;-4.1192656;-1.1519853;-2.9528813;-3.096838;0.41454086;CODE
additional templates that should be rendered to pages maps page names to;-3.0131454;-1.1686357;1.2176815;-0.24789006;2.9469469;3.8362076;TASK
template names;-4.1525016;-2.8298311;2.2120767;-1.4921225;4.0623903;1.102052;-
additional files to copy;-2.2270522;-2.7485962;1.7229887;-0.52867895;0.80136114;0.9373132;TASK
html extra path;-6.492367;-1.4858384;3.7212932;-0.17606634;-1.2025291;3.0610034;-
additional js files;-3.8693998;-3.407097;4.5093784;0.5376115;0.3247848;1.4110454;TASK
compile scss files into css files using sphinxcontrib sass;-3.3294027;-2.341725;-2.7287023;-1.8335229;-1.0603648;1.559139;CODE
additional css files should be subset of the values of sass targets;-0.2851249;0.17559752;-0.30251878;-0.9482488;0.6771323;2.5660405;IRRE
external jquery and datatables;-0.66417575;-1.2909162;2.603078;0.48571575;-1.8006318;2.8305597;CODE
internal api search initialization and styling;-3.6049435;-1.6761665;0.67678255;2.4275756;1.5412955;2.380636;CODE
if false no module index is generated;-3.1675184;4.9843183;-3.7643316;2.307938;0.32542804;-0.87721264;CODE
if false no index is generated;0.39303786;7.091204;-1.9115977;1.5683416;1.3675897;-3.015084;-
if true the index is split into individual pages for each letter;-0.087239206;2.9804232;1.2558324;-0.5887486;3.8742518;-0.63464457;CODE
html split index false;-2.4282386;3.4162977;0.732166;-1.030114;-1.0371385;0.43178147;-
if true links to the rest sources are added to the pages;-3.2874;0.18582988;0.83146113;3.5992918;0.12762827;1.9190313;TASK
html show sourcelink true;-4.471821;-1.2137864;1.4888829;0.32522064;-2.1981785;1.9795371;-
if true an opensearch description file will be output and all pages will;-3.0695517;-1.2580261;-1.2844806;2.9611814;0.28644532;0.9312011;CODE
contain a link tag referring to it the value of this option must be the;-5.455162;1.0130816;1.7377074;0.8511398;1.8736529;1.8221148;TASK
base url from which the finished html is served;-5.415811;-0.27632585;5.6719785;0.42478263;0.12980822;2.660977;TASK
html use opensearch;-3.9420555;-3.6845467;0.3021387;1.690645;-1.1141138;0.47765982;CODE
if nonempty this is the file name suffix for html files e g xhtml;-6.127417;-1.1160078;-0.2949148;-1.0881099;0.5384141;0.94837785;CODE
html file suffix;-3.9564016;-1.7042162;1.491068;-1.3157398;0.8793554;1.1045586;-
output file base name for html help builder;-4.987893;-1.4406427;1.4644281;-0.113422066;0.6334595;1.0862104;IRRE
if true the rest sources are included in the html build as sources name;-5.883049;-2.8492873;-1.0635096;2.5216703;0.25037634;2.5752723;CODE
adds variables into templates;-3.4330037;0.2453672;1.7299274;-1.1308805;2.2816439;1.5500952;CODE
finds latest release highlights and places it into html context for;-2.3615139;-3.0721476;2.425843;2.0282285;0.25599626;1.3530782;CODE
index html;-3.4635205;-1.0423644;5.122438;-1.1470559;0.009866987;1.0227412;-
finds the highlight with the latest version number;-3.1490963;0.09757575;0.44782132;0.82647574;0.0933143;-1.0241998;IRRE
get version from highlight name assuming highlights have the form;-2.1480653;0.79350096;0.8705247;0.97333544;2.0470207;1.2321948;CODE
plot release highlights 0 22 0;-2.254625;-0.23005177;1.0014713;-2.5520492;-6.7887764;-1.5151794;-
redirects dictionary maps from old links to new links;-3.604071;-0.04557069;0.17792505;1.2991635;-1.4707525;3.1432693;CODE
see https github com scikit learn scikit learn pull 22550;-1.7211413;-10.774588;-4.6568966;-1.4806607;-4.08962;-3.9953055;CODE
options for latex output;-0.77418816;-2.2475126;3.2142375;-1.305479;1.1200848;-0.64711857;IRRE
the paper size letterpaper or a4paper;-1.7669132;-1.8389766;3.332094;-2.1995564;1.035834;0.8895426;CODE
papersize letterpaper;-2.1215465;-1.2520233;2.6150541;-1.7664456;0.23863205;2.3860862;CODE
the font size 10pt 11pt or 12pt;-1.6750573;-1.8809988;2.1688702;-2.4704711;-1.3557582;0.9013865;-
pointsize 10pt;0.7198778;-0.007150551;4.7257547;-3.0975966;-2.0303915;0.16284214;CODE
additional stuff for the latex preamble;-4.0489473;-5.061995;2.8412774;0.60489655;3.4892929;1.0690843;TASK
grouping the document tree into latex files list of tuples;2.3023336;-3.2386596;1.6762784;-1.7814533;2.390899;-0.30725157;CODE
source start file target name title author documentclass;-4.3441353;-3.7272317;-2.3897734;1.4667231;1.638794;1.091958;CODE
howto manual;-3.6343744;-3.9119167;3.9914343;1.5069205;0.42477307;-2.5915225;-
the name of an image file relative to this directory to place at the top of;-3.2403562;-1.0557878;4.6419296;-2.4001656;-0.2781938;3.0401764;CODE
the title page;-5.557603;-5.0801606;6.1917944;-0.41196752;0.5428874;-1.3154355;-
documents to append as an appendix to all manuals;-4.516932;-2.821942;1.8482372;2.1152828;2.3311944;2.5015357;CODE
latex appendices;-4.149909;-0.12736826;2.8013353;-2.003273;1.6174774;1.6572853;CODE
if false no module index is generated;-3.1675184;4.9843183;-3.7643316;2.307938;0.32542804;-0.87721264;CODE
intersphinx configuration;-3.9373286;0.12151054;1.4088472;-1.8887244;1.1040919;3.7943177;CODE
forces release highlights to the top;-2.3776248;-1.8244331;4.5222635;1.0878636;-2.2228904;2.792014;CODE
avoid generating too many cross links;-0.831891;0.6470555;1.978371;0.15955923;2.8367984;2.5537481;CODE
for the index page of the gallery and each nested section we hide the secondary;-3.7323568;0.9182994;3.5710907;-0.3852885;1.5545218;5.093078;CODE
sidebar by specifying an empty list no components because there is no meaningful;-3.3021252;2.0232203;1.498392;-0.38270408;1.3852769;1.8039118;IRRE
in page toc for these pages and they are generated so sourcelink is not useful;-4.1807075;-2.37105;-1.1638037;0.6574199;0.5663412;2.4783177;CODE
either;-3.1887863;-1.2384976;2.68025;0.60332936;-1.4288646;-1.6814367;-
the following dictionary contains the information used to create the;-1.0506155;-2.9753911;2.7649434;-2.538011;4.5623293;-2.1824987;IRRE
thumbnails for the front page of the scikit learn home page;-1.5410235;-9.232382;0.43850562;-0.71863776;-3.3224432;0.18136223;CODE
key first image in set;-1.8619149;1.60024;4.7954154;-2.9866467;0.54926455;1.5591828;IRRE
values number of plot in set height of thumbnail;0.9464392;1.4176466;4.054942;-4.699853;-5.720395;1.0094709;IRRE
enable experimental module so that experimental estimators can be;0.51030254;-1.7111869;-2.4072142;4.926602;-3.704597;1.9271449;CODE
discovered properly by sphinx;-3.1017742;-3.3669071;-1.8247796;1.1587144;0.6368105;-1.4382381;-
from sklearn experimental import noqa f401;-0.20581266;-3.6725628;-5.111298;-2.6948104;-4.854143;-2.5994568;CODE
do not run the examples when using linkcheck by using a small priority;-2.3596814;3.3827457;-0.6253117;5.263535;0.86700314;2.7225015;CODE
default priority is 500 and sphinx gallery using builder inited event too;-5.1692257;0.25431928;0.41218695;2.228802;0.7055287;4.4696164;IRRE
triggered just before the html for an individual page is created;-4.612788;0.38858488;3.705622;3.1136823;-0.90643454;4.3791423;CODE
to hide show the prompt in code examples;-6.092204;0.57823205;1.2965143;1.5738014;-0.21677616;-1.1706768;-
the following is used by sphinx ext linkcode to provide links to github;-5.8470984;-4.88265;-1.1681924;-0.72505003;-0.2253805;0.7558402;-
package path l lineno;-5.2121572;-1.4486068;1.2674061;-0.18375349;0.119940706;0.2943489;-
todo 1 10 remove passiveaggressive;-2.6180828;3.4187758;-1.6283556;2.9020486;-2.3805654;1.5512239;TASK
maps functions with a class name that is indistinguishable when case is;-0.571566;2.2069178;-1.0313486;0.42582673;4.7238464;1.9518125;CODE
ignore to another filename;-2.2628279;3.7817357;1.010859;2.3518174;-0.32214546;1.4910538;-
config for sphinxext opengraph;-4.628699;-2.066778;-1.7094876;-0.97528434;0.15435603;3.0208592;CODE
config for linkcheck that checks the documentation for broken links;-3.852381;0.4256819;-1.1906317;4.2763467;-0.8657871;1.5759034;CODE
ignore all links in whats new to avoid doing many github requests and;-3.3588908;-1.8059616;-0.1679908;3.052435;-2.4036396;1.5315604;CODE
hitting the github rate threshold that makes linkcheck take a lot of time;-2.083975;-2.0351598;-1.093994;4.3645005;-2.4688103;1.4089909;-
default timeout to make some sites links fail faster;-2.399438;1.6785717;0.6958226;4.17524;-2.7217033;2.3074093;CODE
allow redirects from doi org;-3.1639295;-0.33034483;0.6476028;1.3998479;-1.9945998;1.7310477;CODE
ignore links to local html files e g in image directive target field;-2.528078;0.2808804;1.9965452;1.7756187;-1.2899024;5.13078;-
ignore links to specific pdf pages because linkcheck does not handle them;-2.2781656;1.979969;-1.2126673;4.3549056;-1.3600304;2.726682;CODE
utf 8 codec can t decode byte error;-3.944104;0.9452991;-4.450819;-2.532568;-2.773587;-0.8352997;-
r http www utstat toronto edu rsalakhu sta4273 notes lecture2 pdf page;-2.0434363;-4.3909316;0.41401184;-1.7281328;1.0498127;-0.03146176;TASK
the unseen labor behind our digital infrastructure pdf page;-2.5047777;-4.6479836;2.6336453;0.633305;-1.3129334;1.0796316;CODE
links falsely flagged as broken;-3.62884;2.9189956;-1.9199542;1.5222495;-2.2737114;0.5058688;-
broken links from testimonials;-3.3543637;0.43896845;-1.520345;3.3766267;-1.1211832;-0.2871576;IRRE
ignore some dynamically created anchors see;-2.7379425;2.963431;0.80352145;1.7462624;-0.39422622;5.0355134;IRRE
https github com sphinx doc sphinx issues 9016 for more details about;-6.2579556;-1.982969;-3.8103638;-0.8206937;-2.2674057;-0.17837732;CODE
the github example;-5.6746683;-7.8804193;1.625196;1.1819931;-0.44871092;-1.9861562;-
r https github com conda forge miniforge miniforge;-3.6207142;-4.3639445;-2.1355555;-1.6519977;-3.6102264;1.0478245;CODE
setting the maximum size of thread pools;0.047161337;1.4326044;0.7467726;0.08396566;0.17921624;2.9230368;IRRE
consistently create same random numpy array 5837352 comment6712034 5837352;2.913728;0.20156278;-3.383067;-3.4240294;-4.06606;-2.177741;IRRE
use a browser like user agent to avoid some 403 client error forbidden for;-4.6713357;0.5104045;0.45886955;1.4802163;-1.7868055;1.2136554;CODE
url errors this is taken from the variable navigator useragent inside a;-6.783701;0.31782815;-0.07944376;1.3748305;-2.0346124;0.64968735;CODE
browser console;-6.206272;-1.1015468;5.5240383;-0.11781189;-3.3337371;-0.3723662;CODE
use github token from environment variable to avoid github rate limits when;-1.9468219;0.12096254;-2.249493;2.2399783;-1.1625485;1.9166735;CODE
checking github links;-4.2172384;-3.2233717;0.38784572;1.9970193;-2.4521017;-2.4816787;-
skip the test in rcv1 rst if the dataset is not already loaded;1.4184574;3.9728796;-3.1152723;4.5628815;-0.8499094;-0.086066395;IRRE
import pandas noqa f401;-1.3414104;-2.1035857;-3.1001604;-5.2939076;-4.3778214;-1.7690102;CODE
checks sklearn skip network tests to see if test should run;1.7485648;1.458215;-5.2695394;4.9190745;-3.7127326;-2.8758562;IRRE
import pandas noqa f401;-1.3414104;-2.1035857;-3.1001604;-5.2939076;-4.3778214;-1.7690102;CODE
import pandas noqa f401;-1.3414104;-2.1035857;-3.1001604;-5.2939076;-4.3778214;-1.7690102;CODE
import pandas noqa f401;-1.3414104;-2.1035857;-3.1001604;-5.2939076;-4.3778214;-1.7690102;CODE
import pandas noqa f401;-1.3414104;-2.1035857;-3.1001604;-5.2939076;-4.3778214;-1.7690102;CODE
import matplotlib noqa f401;-0.7200885;-3.190362;-1.8495036;-6.6406493;-7.1725445;0.121925995;CODE
import cupy noqa f401;-3.7580156;-2.1039732;-2.4279473;-3.300755;-1.3820751;-1.5375186;CODE
normalize filename to use forward slashes on windows for easier handling;-2.631906;-0.39077252;0.3740702;-1.5070873;-0.45715532;3.3234124;CODE
later;-2.726311;-2.1820984;7.2767243;3.571628;0.35708508;-1.4124526;-
use matplotlib agg backend during the tests including doctests;0.5081804;-1.3539592;-2.983884;1.6373886;-5.886129;-1.4619588;IRRE
todo configure numpy to output scalar arrays as regular python scalars;2.9107578;-1.3463919;-4.380062;-4.811639;-6.7229047;1.4317417;CODE
once possible to improve readability of the tests docstrings;-1.854451;-0.43438542;-2.811889;6.8810534;1.0050625;-5.4343677;CODE
https numpy org neps nep 0051 scalar representation html implementation;-1.5143316;-1.9111632;-5.4347086;-5.9731555;-3.6069052;0.18294837;TASK
normally doctest has the entire module s scope here we set globs to an empty dict;-3.1870291;0.06402045;-4.616153;3.2781377;-1.1431259;-1.7537665;IRRE
to remove the module s scope;-6.0935135;2.6626632;0.88071483;0.87347466;-1.5592906;3.0810509;CODE
https docs python org 3 library doctest html what s the execution context;-6.473916;-2.9579732;-2.0663497;1.8866935;-2.0559306;-1.999993;CODE
here we generate the text only for one instance this directive;-3.5958817;1.6497556;2.331294;1.3959231;4.006618;1.8385259;CODE
should not be used for meta estimators where tags depend on the;0.81071144;0.5346222;-1.750583;5.1021566;1.4705669;4.8760233;CODE
sub estimator;2.281391;1.3954213;1.9973148;1.6239992;-0.7192006;1.3435315;-
get the first non empty line of the processed docstring this could lead;-3.5814378;3.7790525;-0.23841062;1.1142699;1.582212;-1.9185959;CODE
to unexpected results if the object does not have a short summary line;-0.1797176;5.1888223;0.06923389;2.314352;-1.2412407;-3.0224876;IRRE
default priority 9999 apply later than everything else;-3.2384098;1.8023717;-1.2295096;2.8187704;1.5467772;2.9769502;CODE
unwrap the object to get the correct source;-1.3458476;-0.18689057;1.8464648;0.050005857;-0.4645449;0.34196404;IRRE
file in case that is wrapped by a decorator;-5.6644287;1.001778;1.042122;1.9243475;1.6556493;3.0230255;CODE
a class href obj a decompose;-4.260436;-1.2399765;1.1148545;1.0640839;2.1616523;2.2179708;IRRE
external repo regex re compile r w w;-4.3827286;-0.23297103;-2.9871638;0.5654188;-0.05579513;-0.028051957;CODE
return 0 format issue no;-3.334251;5.5849752;-3.4693153;-3.2578797;-2.961198;-4.1261263;CODE
if repo match external repo;-2.2452435;1.8608981;-0.06435997;1.7647973;1.2131823;0.8451048;-
formatted issue self format text issue lstrip;-4.4003735;3.3587143;-1.6960948;-3.3768086;-0.6965825;-1.7522196;CODE
format template for issues uri;-4.7162185;0.49387;0.047204666;-0.313008;1.4679186;1.6962827;CODE
e g https github com sloria marshmallow issues issue;-5.736438;-3.4563754;-1.648081;1.4116474;-3.4333782;0.053695068;CODE
format template for pr uri;-4.8777213;-0.43649802;0.49442112;-1.992442;2.297978;1.5955874;CODE
e g https github com sloria marshmallow pull issue;-5.786921;-4.4892554;-0.76529795;2.2308545;-3.162194;0.5061755;CODE
format template for commit uri;-5.4468203;-0.899872;0.7245363;-0.98978925;0.7994317;1.8608385;CODE
e g https github com sloria marshmallow commits commit;-4.677669;-4.6889086;0.25157908;1.4425554;-1.6670618;0.16905849;CODE
shortcut for github e g sloria marshmallow;-5.5091076;-5.6223826;1.9325714;0.44470677;-1.28456;1.1098034;CODE
format template for user profile uri;-3.4479344;-1.7610458;1.4610844;-2.8317285;0.39763764;2.5984979;CODE
e g https github com user;-4.5676665;-5.5973144;1.2062645;0.4277031;-3.4662364;-0.79324865;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data exploration on the bike sharing demand dataset;3.7099102;-2.5108583;3.6865952;-1.0315009;1.6928203;0.6986165;IRRE
we start by loading the data from the openml repository;-4.1944923;-4.6257443;0.9048566;0.67584586;1.3711666;1.168407;CODE
to get a quick understanding of the periodic patterns of the data let us;4.616952;-3.1243968;4.8256817;-2.8949869;-0.6998448;-0.829638;CODE
have a look at the average demand per hour during a week;1.2294741;-2.0972168;4.8481827;0.47466815;-1.2707736;1.7358738;-
note that the week starts on a sunday during the weekend we can clearly;-0.38353235;0.13184838;3.0271492;1.8037753;-0.6956528;0.46837372;TASK
distinguish the commute patterns in the morning and evenings of the work days;1.5718983;-0.867638;4.0649433;-0.19019318;2.6575258;0.1821649;CODE
and the leisure use of the bikes on the weekends with a more spread peak;0.48479313;-1.0792695;4.6615057;0.5329997;-0.19903502;1.6230111;CODE
demand around the middle of the days;-1.5111359;0.22431496;6.7284718;1.0789937;-1.7143525;0.82775825;-
the target of the prediction problem is the absolute count of bike rentals on;4.928197;-0.8362956;1.9684851;3.6379616;1.6598098;-0.7431983;-
an hourly basis;0.75343037;-1.903718;5.1433487;-0.55344045;0.45283416;-0.4326869;-
let us rescale the target variable number of hourly bike rentals to predict;5.225936;-0.4585453;2.531058;-0.23489106;0.35903773;0.936981;CODE
a relative demand so that the mean absolute error is more easily interpreted;2.6099842;3.2860253;-0.048797406;2.3768384;-1.7094746;2.6330109;CODE
as a fraction of the maximum demand;0.8268542;1.0876777;5.334735;-0.10594016;1.0408347;1.3136427;-
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
the fit method of the models used in this notebook all minimizes the;3.7869666;-2.7160265;1.1095333;2.1165164;-1.5240571;3.1628265;CODE
mean squared error to estimate the conditional mean;1.073745;2.7206616;0.07588687;2.132679;-3.3234231;2.4285254;-
the absolute error however would estimate the conditional median;2.5249794;4.2840486;-0.056821503;1.2709225;-2.6761327;1.5457827;-
nevertheless when reporting performance measures on the test set in;2.7629707;2.2457175;-1.3236648;6.359465;0.91561365;-1.5927538;IRRE
the discussion we choose to focus on the mean absolute error instead;1.9126818;0.53213686;0.13540033;4.6741757;-3.9232771;1.4187001;IRRE
of the root mean squared error because it is more intuitive to;0.17626217;0.03754654;0.45975798;1.44066;-4.448717;0.48121655;CODE
interpret note however that in this study the best models for one;1.3596865;-2.5803325;1.9227821;5.068645;-0.05453578;-2.3341932;CODE
metric are also the best ones in terms of the other metric;3.1421907;-2.170868;2.1280107;0.82589114;0.9852602;1.8102075;CODE
the input feature data frame is a time annotated hourly log of variables;1.9524578;-4.854482;0.44123206;-1.1401749;-0.87090576;-1.2409523;CODE
describing the weather conditions it includes both numerical and categorical;2.4833314;-1.1179104;1.8103584;-2.2843843;2.4047124;-1.5850283;CODE
variables note that the time information has already been expanded into;-0.49532825;0.76346713;2.1362123;-1.1586548;-0.58583826;-1.0728018;CODE
several complementary columns;2.6287215;0.93872446;2.229038;-5.7473884;4.7846885;-0.8502558;-
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
if the time information was only present as a date or datetime column we;0.73965895;1.747555;1.2186608;-0.76669997;0.53239906;-0.8942298;CODE
could have expanded it into hour in the day day in the week;-1.3372824;0.7831145;2.5099025;0.53819615;-2.4332914;0.46194908;CODE
day in the month month in the year using pandas;0.16333741;-3.0780818;0.24550605;-3.1730132;-4.911683;-1.3240464;CODE
https pandas pydata org pandas docs stable user guide timeseries html time date components;-2.5582025;-5.0206046;-2.5848854;-1.3627806;-4.7496996;1.4704036;CODE
we now introspect the distribution of the categorical variables starting;0.8639858;-2.7236304;2.0826988;0.9743275;1.8535628;-0.37437522;CODE
with weather;-0.7628559;-1.7756567;7.1958647;0.42710578;-0.70600027;-2.0645792;-
since there are only 3 heavy rain events we cannot use this category to;-1.6320356;-2.4222007;1.842239;2.1927505;3.1063733;0.72632086;IRRE
train machine learning models with cross validation instead we simplify the;4.761504;-3.013632;-0.6718374;4.604687;3.3523197;0.4196179;-
representation by collapsing those into the rain category;2.1444454;-3.2614405;2.778427;-0.92368;3.959091;0.907631;CODE
as expected the season variable is well balanced;2.034785;1.998608;0.7766294;2.5430756;-0.791407;-0.8449948;IRRE
time based cross validation;3.1284645;0.1115642;1.2206453;2.9204497;2.3998308;-1.2169131;-
since the dataset is a time ordered event log hourly demand we will use a;2.8495817;-1.933505;1.9851464;0.170217;1.6386042;0.24162446;IRRE
time sensitive cross validation splitter to evaluate our demand forecasting;4.0775185;-0.5543312;-0.17928511;4.3711853;0.7620789;0.8938385;CODE
model as realistically as possible we use a gap of 2 days between the train;3.2369287;-0.5356217;4.0658817;3.4893389;0.4749314;1.679142;IRRE
and test side of the splits we also limit the training set size to make the;2.786566;-1.2349043;0.7577848;3.3100758;2.811134;1.2431998;IRRE
performance of the cv folds more stable;0.8023591;-2.0110812;-0.0709688;1.0138452;-1.7577071;3.0777159;CODE
1000 test datapoints should be enough to quantify the performance of the;5.3806334;0.6989498;0.79875976;3.8385644;0.6541106;-3.1789393;CODE
model this represents a bit less than a month and a half of contiguous test;4.352862;2.9978259;2.5838087;3.126305;-0.0977445;-3.185421;IRRE
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
let us manually inspect the various splits to check that the;-0.36617532;1.0132977;-0.17650911;-0.55961007;1.9213948;-0.42158967;CODE
timeseriessplit works as we expect starting with the first split;0.30145234;-0.47570273;-0.44809794;-0.23137395;-1.5597167;2.218726;-
we now inspect the last split;-1.5632083;0.2567516;3.4016187;1.9704342;0.98769766;-1.5245262;-
all is well we are now ready to do some predictive modeling;3.0772612;-5.9049487;2.1571398;4.758702;-0.084616505;0.74982893;CODE
gradient boosting;4.793625;-4.764862;2.3607268;-0.15444764;2.2859619;0.87690103;-
gradient boosting regression with decision trees is often flexible enough to;4.6244006;-5.4905972;-0.3053251;2.1479712;2.3266547;3.3051417;-
efficiently handle heterogeneous tabular data with a mix of categorical and;3.9865263;-1.0088013;1.1478218;-1.9462383;4.4630184;1.0723897;-
numerical features as long as the number of samples is large enough;8.774937;-2.4293127;0.23373435;-1.282694;3.1002805;0.4829532;TASK
here we use the modern;-2.1870072;-3.4716995;5.33986;3.0106719;-0.3812965;0.52544653;IRRE
class sklearn ensemble histgradientboostingregressor with native support;4.0652723;-6.832764;-6.2185326;2.5398202;1.2634704;2.258696;IRRE
for categorical features therefore we only need to set;1.1024988;-2.4089675;0.1810556;0.7075835;3.0275912;0.6297051;TASK
categorical features from dtype such that features with categorical dtype;2.2693727;-3.5211828;-2.2781198;-2.6914039;2.1751857;-0.47860909;TASK
are considered categorical features for reference we extract the categorical;1.0978537;-4.469721;-0.42202878;0.8958585;4.4112253;-1.0634806;CODE
features from the dataframe based on the dtype the internal trees use a dedicated;3.1109917;-5.590972;-2.7372434;-0.8056337;1.4859071;0.3081922;CODE
tree splitting rule for these features;1.9067347;-2.1168005;0.44454795;-1.3410914;5.386879;-0.23570256;TASK
the numerical variables need no preprocessing and for the sake of simplicity;2.8807123;0.016794914;-1.6401186;-3.7040443;-1.2221332;0.2624517;CODE
we only try the default hyper parameters for this model;0.4296872;-0.7017115;-3.1288307;1.8537066;-0.4576837;3.9530952;CODE
let s evaluate our gradient boosting model with the mean absolute error of the;3.2918942;-1.659589;-0.64548516;1.3970665;0.1553306;0.78419006;CODE
relative demand averaged across our 5 time based cross validation splits;4.992071;0.517566;0.4465173;4.2565064;1.6146512;1.8135785;-
we see that we set max iter large enough such that early stopping took place;-0.96497965;2.2704508;1.3886169;3.9601583;-3.281054;2.4912026;IRRE
this model has an average error around 4 to 5 of the maximum demand this is;2.1229353;1.3677745;0.79418737;3.2995968;-0.9581683;-0.20403044;CODE
quite good for a first trial without any hyper parameter tuning we just had;2.4013731;-1.9906446;0.19217765;4.3925443;-0.602183;-0.738883;IRRE
to make the categorical variables explicit note that the time related;0.7554748;-0.93761367;1.3002752;-1.997276;0.0145038115;-1.2865602;TASK
features are passed as is i e without processing them but this is not much;-1.784404;-2.4026883;-2.0304024;3.706172;2.391558;1.6196722;TASK
of a problem for tree based models as they can learn a non monotonic;3.2821887;-2.816535;-0.4209606;3.7750025;3.501738;0.63242865;CODE
relationship between ordinal input features and the target;1.879329;-0.61037564;0.9600213;-0.6051101;2.0123432;0.083557025;TASK
this is not the case for linear regression models as we will see in the;3.7579534;-0.22947885;0.11824613;2.2388945;-1.1750365;3.0346198;CODE
following;-3.283919;-1.2644446;6.869319;1.151007;0.70090026;-2.6075451;-
naive linear regression;5.0783463;-2.7488868;0.88690525;-1.3400798;-1.5645565;-1.1936017;-
as usual for linear models categorical variables need to be one hot encoded;0.7742005;-0.3245058;-3.380789;-2.2880795;1.3438998;0.8225263;CODE
for consistency we scale the numerical features to the same 0 1 range using;7.546646;-0.6353377;-0.6185662;-2.6369755;0.7534971;2.3047976;CODE
class sklearn preprocessing minmaxscaler although in this case it does not;3.2020695;-2.2225685;-6.314883;-1.0461323;-3.1130288;2.4049811;CODE
impact the results much because they are already on comparable scales;4.89021;-0.09151813;2.4747696;4.8656707;-1.4868317;0.9601644;IRRE
it is affirmative to see that the selected alpha is in our specified;-1.0451465;1.7060797;1.2131474;0.9935046;2.925666;0.50236404;CODE
range;-0.15387847;0.40157422;5.4211354;-2.1414773;-0.33619386;-3.810934;-
the performance is not good the average error is around 14 of the maximum;2.3376403;0.3801231;-1.4723067;2.9270449;-1.4789968;-1.0094918;CODE
demand this is more than three times higher than the average error of the;2.329589;3.0266993;0.5477219;1.7102534;-0.44434068;-1.5956368;CODE
gradient boosting model we can suspect that the naive original encoding;3.9133244;-4.213199;-3.4204783;1.0888397;1.6920514;0.86149997;-
merely min max scaled of the periodic time related features might prevent;4.2218657;-1.495925;-0.009100354;0.6558368;-0.7856367;5.6170506;TASK
the linear regression model to properly leverage the time information linear;4.3122497;-3.790915;3.0941408;2.479368;-0.884533;2.8127582;CODE
regression does not automatically model non monotonic relationships between;1.8523077;2.0021462;-2.3547564;1.3488115;-1.6877973;1.8963097;IRRE
the input features and the target non linear terms have to be engineered in;4.8196936;-4.274245;-0.7583627;-0.16287905;1.2255635;1.8381623;TASK
the input;-0.99205446;-1.6274831;7.7761087;0.06829488;0.4979873;-4.148328;CODE
for example the raw numerical encoding of the hour feature prevents the;1.1651633;-1.9536409;-3.0138786;-2.223716;-1.1672409;1.0676522;CODE
linear model from recognizing that an increase of hour in the morning from 6;2.3782628;-0.6888543;3.682194;-0.19133455;-0.23652603;-0.6160127;CODE
to 8 should have a strong positive impact on the number of bike rentals while;0.740868;1.0602808;1.7385617;1.2001041;1.683242;0.26652277;CODE
an increase of similar magnitude in the evening from 18 to 20 should have a;0.72615004;1.6768603;3.8046682;1.182775;-2.83471;-1.7143794;CODE
strong negative impact on the predicted number of bike rentals;2.1535113;0.17465882;1.2222831;3.4769068;-0.03506249;-0.4191488;-
time steps as categories;0.0539211;-2.823967;3.4929883;1.094299;2.7501009;-0.35429066;-
since the time features are encoded in a discrete manner using integers 24;2.207291;-1.5196195;0.90670043;-4.611387;1.5632284;-1.9249984;TASK
unique values in the hours feature we could decide to treat those as;1.7310858;-0.99321574;2.2756324;0.41078666;4.238088;0.26024053;IRRE
categorical variables using a one hot encoding and thereby ignore any;1.617481;1.5027815;-1.877116;-0.920989;1.9405582;-0.65678674;IRRE
assumption implied by the ordering of the hour values;-0.090611994;3.227796;0.9734808;-0.2519952;-0.38155165;0.29989493;IRRE
using one hot encoding for the time features gives the linear model a lot;4.053141;-3.708012;-2.2373111;-0.2566227;-0.5253607;2.5667338;TASK
more flexibility as we introduce one additional feature per discrete time;1.5935403;-4.343313;2.7296135;1.1529943;5.1441097;4.0358515;TASK
level;-2.330566;-2.191926;4.64252;-1.8583341;1.4155381;-3.691862;-
the average error rate of this model is 10 which is much better than using;2.7471092;-0.2020769;0.2659101;4.427634;-1.2147425;-0.9988939;CODE
the original ordinal encoding of the time feature confirming our intuition;0.92051494;-2.9462774;1.3291074;-1.3616815;0.20362845;1.4038105;TASK
that the linear regression model benefits from the added flexibility to not;1.0876942;-0.8327339;2.0835814;2.6187458;-0.48318237;4.423495;TASK
treat time progression in a monotonic manner;1.3484567;1.4021531;2.6859107;0.08394031;0.743697;1.3849039;-
however this introduces a very large number of new features if the time of;0.12288803;-4.888495;3.0447714;3.4742775;2.3201702;2.8693066;CODE
the day was represented in minutes since the start of the day instead of;-2.341108;1.5637066;3.6668952;-1.1291791;-0.7586253;-0.19886298;CODE
hours one hot encoding would have introduced 1440 features instead of 24;-1.0375633;-1.4938207;-1.5355273;-1.3450311;-0.38057646;0.4970827;CODE
this could cause some significant overfitting to avoid this we could use;1.2289407;-1.5519645;-0.21657573;6.143579;1.1191595;4.1583314;CODE
func sklearn preprocessing kbinsdiscretizer instead to re bin the number;0.045103338;-1.4593847;-5.9352865;-2.5344212;-0.8413408;-1.9536438;CODE
of levels of fine grained ordinal or numerical variables while still;3.213289;0.33901456;-0.7398428;-3.0512097;2.0022762;-0.5812403;CODE
benefitting from the non monotonic expressivity advantages of one hot;-0.24265891;0.4906136;1.1759485;1.7083358;2.0812497;1.3348079;CODE
encoding;-0.85109377;-3.1604438;2.14913;-3.5790567;2.2262733;-2.8905053;-
finally we also observe that one hot encoding completely ignores the;-1.4796638;-0.9634945;-3.789561;1.0022739;-0.979448;1.552152;CODE
ordering of the hour levels while this could be an interesting inductive bias;2.4708955;-1.5504191;2.249602;2.1725738;1.4257228;-0.23973168;CODE
to preserve to some level in the following we try to explore smooth;0.20465708;-2.1637554;4.255961;1.1266981;-0.6375642;3.9088907;CODE
non monotonic encoding that locally preserves the relative ordering of time;1.2473888;-0.18701251;0.3738283;-1.6979486;2.2366416;3.6261363;IRRE
features;1.4263527;-6.2441335;5.031171;1.4146436;3.9154737;-1.3022918;TASK
trigonometric features;1.0514817;-2.0989125;4.616023;-3.0288231;-0.8142324;-1.5018386;TASK
as a first attempt we can try to encode each of those periodic features;3.3670633;-4.9737372;0.97013634;-3.1955733;2.7894683;1.5119369;TASK
using a sine and cosine transformation with the matching period;-0.43981582;2.3842037;2.9789655;-2.6182826;-3.1555107;0.67136925;CODE
each ordinal time feature is transformed into 2 features that together encode;1.241375;-1.814054;0.2135129;-3.5341358;2.3927977;0.9542941;TASK
equivalent information in a non monotonic way and more importantly without;2.4252682;2.4201052;2.1084328;0.20588258;4.9590497;0.7956262;CODE
any jump between the first and the last value of the periodic range;-0.35165402;3.3187478;4.071802;-2.6582823;-2.4714408;-1.0215428;IRRE
let us visualize the effect of this feature expansion on some synthetic hour;1.8447404;-3.2964222;3.3252032;-1.4537497;-2.0029;1.3241256;CODE
data with a bit of extrapolation beyond hour 23;5.025627;-0.46192512;2.2421203;-1.1711438;-1.4709213;-1.533139;-
let s use a 2d scatter plot with the hours encoded as colors to better see;2.9878805;-1.7287581;4.0653205;-4.9012146;-2.9864495;-0.14167577;CODE
how this representation maps the 24 hours of the day to a 2d space akin to;0.9409696;-2.5164182;4.527567;-5.473459;-0.6609368;1.1421974;CODE
some sort of a 24 hour version of an analog clock note that the 25th hour;-2.4970245;-2.7746522;3.7315283;-1.2479706;-0.8383239;-2.1237068;TASK
is mapped back to the 1st hour because of the periodic nature of the;-1.8904965;-0.9194167;4.9911275;-1.0634912;-1.2890333;2.130758;-
sine cosine representation;-2.081269;0.3938423;2.0267322;-3.729641;-2.8480139;0.39284322;-
we can now build a feature extraction pipeline using this strategy;1.7362651;-5.5845675;-0.006692833;2.6625752;4.966051;2.504797;CODE
the performance of our linear regression model with this simple feature;5.4252005;-0.42451873;1.2645112;0.90741676;-0.53400534;0.34656146;CODE
engineering is a bit better than using the original ordinal time features but;0.52436763;-5.8967834;0.17576897;1.1516483;2.319421;-0.34442505;TASK
worse than using the one hot encoded time features we will further analyze;2.3389015;-5.4605827;-0.5175636;1.3238088;0.3951893;0.5315174;TASK
possible reasons for this disappointing outcome at the end of this notebook;-3.0443141;-0.55765676;0.93517;3.8910747;-4.746991;-1.2819781;CODE
periodic spline features;2.6178772;-3.2051723;3.1211903;-2.960579;-0.39957097;2.3722408;TASK
we can try an alternative encoding of the periodic time related features;2.8409839;-5.204282;1.1602695;-1.7245716;1.0388876;1.8285917;TASK
using spline transformations with a large enough number of splines and as a;3.4478652;-1.960464;1.0577528;-3.320686;-0.86581475;2.6533554;CODE
result a larger number of expanded features compared to the sine cosine;3.778845;-0.99138886;1.0157874;-1.6134816;-1.4110653;2.624505;IRRE
transformation;-0.9362786;0.13174681;6.1401076;-3.5484586;-1.7096213;-0.50837165;CODE
n knots n splines 1 periodic and include bias is true;0.33920288;0.8697482;1.1343368;-3.163128;-0.47273123;0.93715835;CODE
again let us visualize the effect of this feature expansion on some;1.5742787;-3.467265;4.2828074;-0.71504694;0.43787146;2.5657144;CODE
synthetic hour data with a bit of extrapolation beyond hour 23;4.14014;-1.9186466;0.53801537;-1.8007398;-1.6524042;-1.149063;-
thanks to the use of the extrapolation periodic parameter we observe;4.6666217;0.43663266;1.4515926;-1.7046065;-4.333217;4.0567403;IRRE
that the feature encoding stays smooth when extrapolating beyond midnight;1.8426914;-2.0869677;-0.9839603;-0.08181703;-1.8500222;3.4941103;TASK
we can now build a predictive pipeline using this alternative periodic;2.3193383;-3.371363;0.7249123;3.0482721;1.0091565;2.5474904;CODE
feature engineering strategy;2.0385435;-5.6740184;1.6309413;4.111485;3.6439989;1.046552;TASK
it is possible to use fewer splines than discrete levels for those ordinal;0.9223949;0.9874812;0.469984;-3.2734003;2.7155004;1.1149457;CODE
values this makes spline based encoding more efficient than one hot encoding;2.526056;0.2268358;-1.1926093;-4.2624145;-0.40357408;-0.18927874;IRRE
while preserving most of the expressivity;-0.6725241;2.49159;3.382989;0.989381;3.9771893;2.6814373;CODE
spline features make it possible for the linear model to successfully;2.780854;-2.9875805;0.27041408;1.0028807;-1.1005229;3.1074495;TASK
leverage the periodic time related features and reduce the error from 14 to;4.3717904;-1.2051438;-0.63806254;0.20401518;-1.7377113;-0.022406444;TASK
10 of the maximum demand which is similar to what we observed with the;1.6148877;0.81328624;4.017282;1.3526301;-0.33576742;0.1121005;-
one hot encoded features;1.4839687;-2.5528414;-0.18870986;-1.8756005;4.5005207;0.8134511;TASK
qualitative analysis of the impact of features on linear model predictions;4.8307853;-4.684111;0.42795137;4.487587;-0.26891688;1.5568757;TASK
here we want to visualize the impact of the feature engineering choices on;0.046721537;-7.5231023;4.1037946;2.8198519;0.76147175;1.3428739;TASK
the time related shape of the predictions;4.828706;-4.121202;4.5041265;2.13384;-1.9019678;0.5482428;-
to do so we consider an arbitrary time based split to compare the predictions;6.9268656;-0.9752377;0.9416639;5.154189;1.9467449;0.5708167;TASK
on a range of held out data points;7.964507;0.41895774;2.7856615;-2.2388933;1.2494584;0.52153885;CODE
we visualize those predictions by zooming on the last 96 hours 4 days of;2.8521092;-4.1603723;4.921403;1.0490686;-2.9977198;0.7989184;-
the test set to get some qualitative insights;1.4923649;-1.2848575;2.4553425;5.5214667;1.1163639;-6.636706;IRRE
we can draw the following conclusions from the above plot;-0.26448703;0.61410874;4.413149;-0.33952838;-5.199912;-1.3461442;CODE
the raw ordinal time related features are problematic because they do;1.1034207;-2.540315;-2.1796706;0.112461776;0.48566458;1.2588485;TASK
not capture the natural periodicity we observe a big jump in the;-0.1498915;-0.53790677;2.4699373;2.685872;-1.8183887;1.9057235;CODE
predictions at the end of each day when the hour features goes from 23 back;2.498471;-3.6437142;3.5268695;1.400911;-1.1718612;-0.40780896;CODE
to 0 we can expect similar artifacts at the end of each week or each year;1.2584296;-0.6441037;0.73645717;1.9414183;-1.1238203;0.2351589;CODE
as expected the trigonometric features sine and cosine do not have;-0.9131191;0.15757693;0.10182922;-1.8403193;-2.9211311;-0.26542902;TASK
these discontinuities at midnight but the linear regression model fails to;0.29961342;3.1665108;-1.8166703;-0.45497447;-5.633703;-0.24316211;META
leverage those features to properly model intra day variations;4.567113;-3.3644562;2.6327412;2.40851;2.6047707;3.6768274;CODE
using trigonometric features for higher harmonics or additional;2.0177906;-0.9055158;2.1891954;-1.123082;0.5030045;1.9149225;TASK
trigonometric features for the natural period with different phases could;-1.1316026;-0.7109456;3.1922362;-1.6138154;-0.017005246;0.9309586;TASK
potentially fix this problem;-5.6705847;-1.0058074;2.417765;2.6123405;-0.9694776;-0.96910965;CODE
the periodic spline based features fix those two problems at once they;3.299721;-2.6251223;0.8338809;-1.216875;-0.658732;3.305055;TASK
give more expressivity to the linear model by making it possible to focus;2.6511378;-0.8754082;3.4695075;1.270603;-0.5759662;3.6378613;CODE
on specific hours thanks to the use of 12 splines furthermore the;-0.46223563;-1.5885472;4.6450686;-1.3022975;0.0638183;-1.6894325;-
extrapolation periodic option enforces a smooth representation between;0.9537458;1.8130774;-0.17769927;-1.0817919;-1.5881867;6.3739085;CODE
hour 23 and hour 0;-2.090475;1.4888245;1.9214354;-3.476038;-1.5310408;-4.7706327;IRRE
the one hot encoded features behave similarly to the periodic;2.1635323;-2.121146;0.5175661;-3.2765388;0.655584;1.1714152;TASK
spline based features but are more spiky for instance they can better;1.0405872;-4.18081;1.8721122;-0.7882945;0.65191215;3.1508367;TASK
model the morning peak during the week days since this peak lasts shorter;2.2092636;-0.020336254;3.4862373;0.9803272;-1.3059204;2.4856086;CODE
than an hour however we will see in the following that what can be an;-0.14341873;-0.9010198;3.1340668;1.6877698;-0.23973489;-0.87684345;CODE
advantage for linear models is not necessarily one for more expressive;1.8454564;-2.3729675;1.0510322;2.740431;0.8114659;4.0334506;CODE
models;3.9722378;-4.8214254;5.0833;3.611487;2.8015873;-0.60680825;-
we can also compare the number of features extracted by each feature;5.3114805;-2.9790294;0.43989787;0.84007514;4.242141;-2.1034513;TASK
engineering pipeline;-0.7012111;-3.855313;2.5823588;1.8046871;1.1135093;-0.2084754;CODE
this confirms that the one hot encoding and the spline encoding strategies;0.29091954;-3.9348927;-0.017712897;-2.0934627;-0.37698656;0.97186244;CODE
create a lot more features for the time representation than the alternatives;2.3003595;-5.0966835;2.4982512;0.009663965;1.1712734;2.197577;TASK
which in turn gives the downstream linear model more flexibility degrees of;1.2219015;-2.1895292;0.3846263;1.4278578;1.6473215;4.968002;CODE
freedom to avoid underfitting;2.112562;-2.1327975;-0.45950127;5.0848274;2.5428004;1.0288525;CODE
finally we observe that none of the linear models can approximate the true;4.5532265;-0.13000222;-2.388024;3.1910617;-2.444111;2.1616325;CODE
bike rentals demand especially for the peaks that can be very sharp at rush;1.572753;-0.79789597;1.8532189;0.7830183;-0.50802207;2.1697884;CODE
hours during the working days but much flatter during the week ends the most;1.317205;-0.29060832;3.7266223;0.82611513;-2.4162688;1.2591541;META
accurate linear models based on splines or one hot encoding tend to forecast;5.668193;-2.936509;-0.6393839;2.1171455;-2.5451248;2.1389055;CODE
peaks of commuting related bike rentals even on the week ends and;2.7110653;0.053162497;1.3393441;-0.09257096;-0.4702401;1.1302572;CODE
under estimate the commuting related events during the working days;2.0687242;-0.39671102;3.0868566;1.0823396;-0.23359229;1.1860934;-
these systematic prediction errors reveal a form of under fitting and can be;4.685644;-1.4551163;-2.9924376;4.999843;-0.15119207;-0.104044646;CODE
explained by the lack of interactions terms between features e g;-0.1623081;-5.52599;-0.38371325;2.189696;0.9838955;0.77303624;TASK
workingday and features derived from hours this issue will be addressed;-2.6603923;-2.5052032;0.9533474;1.3072004;0.6576881;1.0495712;TASK
in the following section;-4.496762;-3.3664627;4.8205237;0.2909831;3.3964763;-1.2931597;CODE
modeling pairwise interactions with splines and polynomial features;2.6682146;-2.9544513;0.4204367;-2.3241682;0.10498023;2.238263;TASK
linear models do not automatically capture interaction effects between input;1.1336465;-0.23124458;-0.5420692;2.554073;-3.2922022;2.7011237;CODE
features it does not help that some features are marginally non linear as is;1.8980095;-2.2323751;-1.0799828;0.19554365;0.35340953;3.3885667;TASK
the case with features constructed by splinetransformer or one hot;1.1730309;-3.185126;-1.1420481;-0.15452325;2.3906944;3.1018085;CODE
encoding or binning;0.6500576;-3.0557458;0.5484902;-4.5260506;2.2854998;-2.2811596;-
however it is possible to use the polynomialfeatures class on coarse;1.2696728;-2.8268068;-2.964488;-0.483934;1.0263847;4.348863;IRRE
grained spline encoded hours to model the workingday hours interaction;1.1319813;-3.1652768;2.248016;-1.8410832;-1.1132882;0.17017557;CODE
explicitly without introducing too many new variables;2.1245544;1.3803215;1.1855445;0.59106064;4.1576753;0.24286073;CODE
those features are then combined with the ones already computed in the;3.1695058;-5.067284;0.85552067;1.0456432;4.411511;1.9359976;CODE
previous spline base pipeline we can observe a nice performance improvement;1.3410859;-2.504861;-0.43370855;0.67093754;-1.0504464;3.125101;CODE
by modeling this pairwise interaction explicitly;1.3964244;0.078354545;2.203691;-0.29885888;1.5367382;3.3887014;CODE
modeling non linear feature interactions with kernels;4.074522;-4.7387586;0.20495658;0.8462871;-0.17754942;2.4206312;TASK
the previous analysis highlighted the need to model the interactions between;0.6205689;-4.3455806;3.7880142;5.0979795;0.075404026;0.88125014;TASK
workingday and hours another example of a such a non linear;0.44381517;-0.18914185;4.3597593;-1.7009076;-1.2842505;-0.96960604;-
interaction that we would like to model could be the impact of the rain that;0.5343135;-3.1134324;5.2243705;3.2295995;-0.46960932;0.9997672;CODE
might not be the same during the working days and the week ends and holidays;-1.214621;0.7603998;2.8148792;1.1948749;-2.2996142;1.3735032;CODE
for instance;-2.844923;-5.770086;4.676184;3.0730984;0.053076837;-0.18811606;CODE
to model all such interactions we could either use a polynomial expansion on;1.3945203;-1.482516;1.9034084;0.40637732;1.1900665;2.9182787;CODE
all marginal features at once after their spline based expansion however;2.345749;-1.3230771;-0.78656477;-1.5264536;0.55421966;5.225956;TASK
this would create a quadratic number of features which can cause overfitting;4.0459085;-1.9598613;0.14431727;0.9634901;3.0286458;2.29866;TASK
and computational tractability issues;1.1563654;-3.9455593;0.18348989;1.8985918;2.5621822;-1.4051406;-
alternatively we can use the nystr m method to compute an approximate;6.8721175;-0.24936026;-1.0989627;-1.2587621;-1.1395948;2.117116;IRRE
polynomial kernel expansion let us try the latter;1.5543778;-1.6014671;-0.6319863;-2.4653926;-0.123876296;1.6007367;CODE
we observe that this model can almost rival the performance of the gradient;5.0653133;-3.4587076;0.2542406;3.8804421;-0.61909544;4.741055;CODE
boosted trees with an average error around 5 of the maximum demand;4.574123;-1.2218053;-0.33671367;2.0583053;1.3288642;0.40804553;CODE
note that while the final step of this pipeline is a linear regression model;2.8158538;-1.1980517;-0.6243466;1.4917142;-0.9290611;1.3297577;CODE
the intermediate steps such as the spline feature extraction and the nystr m;3.5453925;-4.2569165;0.43202275;-2.8555179;0.32606748;0.19330235;TASK
kernel approximation are highly non linear as a result the compound pipeline;5.17209;-3.777375;-2.6378143;0.28267765;-2.472854;3.994008;IRRE
is much more expressive than a simple linear regression model with raw features;3.4414968;-3.8942873;-0.08734707;1.5572149;-0.09937318;2.3786552;TASK
for the sake of completeness we also evaluate the combination of one hot;1.5498011;0.5550166;1.9285835;2.4887893;3.385916;-3.0799847;CODE
encoding and kernel approximation;5.1844625;-3.0501258;-1.2232207;-2.0525517;1.6334429;3.282016;-
while one hot encoded features were competitive with spline based features;1.923289;-4.014213;-0.94908094;-2.2397745;1.4619207;1.4208328;TASK
when using linear models this is no longer the case when using a low rank;2.5543258;0.5024939;-2.9281516;-0.20345867;-1.9223171;4.1458087;CODE
approximation of a non linear kernel this can be explained by the fact that;3.8583972;-2.5074444;-0.7940555;-0.68785006;-2.940286;3.8214629;CODE
spline features are smoother and allow the kernel approximation to find a;4.0512314;-4.0230803;-1.0993792;0.21946745;-1.2077105;3.77137;TASK
more expressive decision function;1.0321543;-1.5043238;3.2724402;3.4074574;5.3442683;0.36624917;CODE
let us now have a qualitative look at the predictions of the kernel models;4.644452;-6.396831;1.49691;4.169474;-0.14739601;2.5458093;CODE
and of the gradient boosted trees that should be able to better model;4.9500837;-7.7623186;0.98015946;2.7058082;2.546615;2.1284616;CODE
non linear interactions between features;3.785385;-3.0821044;1.6035286;-1.5063523;0.04250926;1.2787575;TASK
again we zoom on the last 4 days of the test set;0.8260664;0.27929455;2.5149076;3.5655165;-3.370155;-1.3291348;IRRE
first note that trees can naturally model non linear feature interactions;1.9484272;-5.4434447;-0.42445636;2.1304824;1.0691268;1.8478307;TASK
since by default decision trees are allowed to grow beyond a depth of 2;1.3403828;-1.8347399;-0.57911474;0.18289682;3.9866817;1.0333117;CODE
levels;-0.56132007;-2.6478157;4.871767;-1.2440828;3.0020099;-3.790323;-
here we can observe that the combinations of spline features and non linear;3.5017693;-3.7352462;0.72817755;-1.8860344;-0.04980969;2.1171105;TASK
kernels works quite well and can almost rival the accuracy of the gradient;5.482494;-6.131576;-1.3016176;0.8600686;-1.8660219;4.285292;-
boosting regression trees;4.679097;-4.4942083;0.20124456;1.0349205;2.877291;0.4991801;-
on the contrary one hot encoded time features do not perform that well with;1.0500088;-2.7466443;-2.7732017;0.09872821;-0.4089779;0.7379581;CODE
the low rank kernel model in particular they significantly over estimate;4.812639;-3.2749567;-2.8006895;0.9260678;-1.6120765;3.967107;-
the low demand hours more than the competing models;0.27108705;-1.4354956;2.3289135;2.419608;0.52950186;1.6679896;-
we also observe that none of the models can successfully predict some of the;2.7488136;-1.4783105;-2.7844493;6.0331144;-0.8642993;-1.5314124;-
peak rentals at the rush hours during the working days it is possible that;0.06531417;0.03747992;1.6631322;1.3829262;0.014341985;1.9139619;CODE
access to additional features would be required to further improve the;-1.7487109;-6.5174956;3.2845447;3.5052054;3.648318;2.9404085;TASK
accuracy of the predictions for instance it could be useful to have access;4.3038564;-5.149364;2.2874985;7.29544;0.71599;-1.0344397;CODE
to the geographical repartition of the fleet at any point in time or the;-2.3698466;-0.6107704;5.46523;-0.83503336;1.0923984;2.4124668;CODE
fraction of bikes that are immobilized because they need servicing;-0.31215122;1.1519183;1.420581;-0.79370004;0.736247;2.3275387;TASK
let us finally get a more quantitative look at the prediction errors of those;5.336336;-1.8994737;-0.68302953;5.391644;-2.4560807;-1.6094254;CODE
three models using the true vs predicted demand scatter plots;4.596492;-1.1534195;3.6348748;3.1934469;-1.8484735;1.5592388;-
this visualization confirms the conclusions we draw on the previous plot;-0.36464655;-2.1612763;4.9403324;0.19939667;-4.778892;1.3015097;CODE
all models under estimate the high demand events working day rush hours;1.48779;-1.583604;3.1234958;2.8633704;-0.051560845;1.0219861;-
but gradient boosting a bit less so the low demand events are well predicted;3.3051536;-2.086347;1.3075686;4.179765;-0.5685809;3.4126532;META
on average by gradient boosting while the one hot polynomial regression;5.217945;-2.5975509;-0.7733857;0.91884923;-0.518619;3.4676526;CODE
pipeline seems to systematically over estimate demand in that regime overall;1.4622252;0.36888462;-0.47139138;3.8844123;-2.399107;3.1781034;CODE
the predictions of the gradient boosted trees are closer to the diagonal than;5.3246965;-5.5051913;-0.3271922;0.75243324;-0.28187683;2.2595794;CODE
for the kernel models;4.841501;-6.3306704;1.4169508;0.86122453;0.7559971;1.8641263;CODE
concluding remarks;-2.5548632;0.6982546;2.7027164;3.9985068;0.4240034;-0.27675796;-
we note that we could have obtained slightly better results for kernel models;4.8925753;-5.0886016;-2.460645;3.5618882;-1.2331057;2.5060134;TASK
by using more components higher rank kernel approximation at the cost of;6.7762127;-4.285374;-2.4702156;-1.3719604;1.0855329;6.108003;-
longer fit and prediction durations for large values of n components the;8.385342;-2.4953506;-0.035515353;0.5958566;0.22621576;3.5173879;IRRE
performance of the one hot encoded features would even match the spline;2.528003;-2.036338;-1.217342;-1.2414148;1.2932656;1.8245732;TASK
features;1.4263527;-6.2441335;5.031171;1.4146436;3.9154737;-1.3022918;TASK
the nystroem ridgecv regressor could also have been replaced by;0.3254747;-0.83518314;-3.743104;-1.2941428;-3.8803728;4.1122785;OUTD
class sklearn neural network mlpregressor with one or two hidden layers;2.8926508;-2.5726852;-3.1905353;0.16468936;0.13038167;2.393487;IRRE
and we would have obtained quite similar results;3.223061;0.059558015;2.136358;3.4989223;0.023373548;-0.698581;IRRE
the dataset we used in this case study is sampled on an hourly basis however;5.0436287;-2.0131135;1.1250991;2.9856024;0.035610083;-0.3148917;CODE
cyclic spline based features could model time within day or time within week;3.0185916;-3.58811;2.9461544;-0.43896395;0.1365026;1.7383618;TASK
very efficiently with finer grained time resolutions for instance with;3.881007;-3.1807606;1.447675;-0.96767974;-0.25886527;2.6155868;CODE
measurements taken every minute instead of every hour without introducing;3.7353015;0.25311264;4.2262707;1.9185176;-2.3688602;1.8729258;CODE
more features one hot encoding time representations would not offer this;1.6218988;-4.3502784;-0.6487964;-0.6464579;1.9919102;1.6348004;TASK
flexibility;-0.9982517;-1.8865124;6.608542;0.8026653;0.74708736;1.1219437;-
finally in this notebook we used ridgecv because it is very efficient from;2.9623427;-5.6634;0.46547645;-0.99013275;-2.3557084;2.910913;CODE
a computational point of view however it models the target variable as a;3.8225362;-2.7163117;2.300719;3.240409;1.4737905;0.41687256;CODE
gaussian random variable with constant variance for positive regression;-0.18135661;0.84815234;-0.9868289;-0.90652835;-3.3128788;3.1256595;CODE
problems it is likely that using a poisson or gamma distribution would make;1.4151515;2.2660477;3.5954866;3.4861333;-0.26530012;-1.3848101;META
more sense this could be achieved by using;-1.2777392;-2.5903642;6.9352484;1.0022292;3.3830938;1.8709308;IRRE
gridsearchcv tweedieregressor power 2 param grid alpha alphas;-0.10211302;-1.1193211;-2.4637687;-2.9775023;-0.9180102;1.2629255;-
instead of ridgecv;0.042488333;-3.4989944;0.20515116;-2.0884316;-2.9918928;4.517284;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the dataset via openml;0.003337441;-1.9152975;0.3447811;0.34722126;1.7638704;2.207001;CODE
the usps digits datasets is available in openml we use;-0.74438;-3.1916902;-1.0322002;-2.273982;3.1683967;-0.30399293;IRRE
func sklearn datasets fetch openml to get this dataset in addition we;2.14302;-5.4356;-2.510436;-0.8094521;-0.053902593;-1.4532381;IRRE
normalize the dataset such that all pixel values are in the range 0 1;5.403895;2.3279722;0.45187014;-5.8908467;-1.6423194;2.6531415;IRRE
the idea will be to learn a pca basis with and without a kernel on;3.9752429;-7.154058;-1.2924552;-0.49446756;1.9069993;4.18461;-
noisy images and then use these models to reconstruct and denoise these;4.8390074;-2.1366842;1.9518346;0.44152325;0.46930847;4.3858533;IRRE
images;0.25060183;-3.6193693;8.883973;-1.4410268;0.945009;-0.7603151;-
thus we split our dataset into a training and testing set composed of 1 000;6.866935;-2.0172548;0.7622638;3.3650866;3.584843;-3.6206017;IRRE
samples for the training and 100 samples for testing these images are;3.7172477;-2.0968862;2.0596;2.0586557;1.6199541;-3.1346567;CODE
noise free and we will use them to evaluate the efficiency of the denoising;3.1061447;-3.4956377;0.3628365;2.013197;0.28369725;3.1967957;IRRE
approaches in addition we create a copy of the original dataset and add a;5.054432;-3.8308747;0.625206;0.9057906;2.893072;0.6880292;TASK
gaussian noise;3.1939833;-1.0378813;0.27652383;-1.850089;-2.1373937;1.9109502;-
the idea of this application is to show that we can denoise corrupted images;1.8425095;-0.45508543;0.7867229;-1.4546334;-0.5999721;3.749137;CODE
by learning a pca basis on some uncorrupted images we will use both a pca;4.272694;-3.6354423;-0.03406412;-1.1176145;2.725272;4.402187;-
and a kernel based pca to solve this problem;6.1824074;-0.96031356;-0.097071;-3.388251;2.4762335;2.0522556;CODE
in addition we will create a helper function to qualitatively assess the;0.84180295;-2.6898053;4.489797;4.5667233;2.2981348;-3.0087867;TASK
image reconstruction by plotting the test images;4.66963;0.3891628;3.431389;-1.5733534;-4.6781383;0.15632726;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
download the data if not already on disk and load it as numpy arrays;2.8921041;-1.1910126;-0.32695943;-3.9875488;-5.5998077;0.080465555;CODE
introspect the images arrays to find the shapes for plotting;3.7026775;-1.3649282;5.2281017;-4.41464;-3.7480736;1.1500326;CODE
for machine learning we use the 2 data directly as relative pixel;5.3235626;-4.1112027;2.7023695;-2.3451931;1.7978781;3.8386836;IRRE
positions info is ignored by this model;-1.1368489;1.8162282;0.4054087;-0.08165312;-1.1430933;2.1915607;CODE
the label to predict is the id of the person;3.0333207;-2.7711842;1.7707758;1.768999;4.8430586;-1.7789862;CODE
split into a training set and a test and keep 25 of the data for testing;6.030282;1.8188235;1.8693488;3.3457189;2.8935583;-3.5443177;IRRE
compute a pca eigenfaces on the face dataset treated as unlabeled;3.8365161;-1.6370752;-2.9659011;-4.012989;1.447879;4.1416945;IRRE
dataset unsupervised feature extraction dimensionality reduction;5.320632;-3.3898718;-1.6972774;-3.3954477;1.5209684;2.1858003;TASK
train a svm classification model;5.040332;-5.531184;1.1841791;0.39594606;3.5147371;-0.21447639;IRRE
quantitative evaluation of the model quality on the test set;4.3377585;1.1987242;-1.3460841;7.1274977;1.0674608;-3.419083;IRRE
qualitative evaluation of the predictions using matplotlib;5.549608;-4.9481993;0.7561686;1.2024819;-4.8507624;-3.5882423;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
initialize random generator;-1.2773602;0.71899813;0.60345614;0.21752855;1.2416154;-0.9327003;IRRE
load the data;0.79853487;0.056605678;5.9102864;-1.0126848;0.3381265;-1.3700435;CODE
first we load both datasets;3.7075725;-2.5162618;0.43813866;0.6126675;0.6287426;1.0965776;IRRE
note we are using;-3.456955;-4.0519867;4.658241;1.754808;-0.1472822;-1.2581164;TASK
func sklearn datasets fetch 20newsgroups vectorized to download 20;3.6201813;-4.7728963;-3.7613132;-0.91480476;-0.95676345;0.36375338;CODE
newsgroups dataset it returns ready to use features;-0.80517673;-1.7539312;0.1098861;3.5345445;-0.011464204;1.8256792;CODE
note x of the 20 newsgroups dataset is a sparse matrix while x;4.614254;-0.49211553;-1.6321123;-2.5398774;-0.2583037;2.1777334;IRRE
of diabetes dataset is a numpy array;6.7911997;-1.7848463;-1.5310456;-6.18333;-3.7762883;-1.7080673;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
hack to detect whether we are running by the sphinx builder;-4.5202;-0.84971195;-1.7690636;4.44111;-0.2929326;-0.3187099;CODE
reuters dataset related routines;4.6950483;-4.776409;0.30920509;0.8401608;0.98787564;-0.037672207;IRRE
the dataset used in this example is reuters 21578 as provided by the uci ml;2.7433882;-4.5790067;-0.5456323;-0.3094769;1.6443081;-1.9667019;CODE
repository it will be automatically downloaded and uncompressed on first;-3.948861;-3.5815976;0.7962907;2.1712012;0.41384292;3.3176994;CODE
run;-2.266743;0.6520291;4.1480117;1.7287916;-0.115474455;-3.24335;CODE
check that the archive was not tampered;-5.1914873;0.8580825;-3.3727894;1.9239715;-2.8610156;-0.5168469;-
main;-3.5065582;-3.4993644;5.766923;-0.43912065;0.92728966;-2.271624;CODE
create the vectorizer and limit the number of features to a reasonable;4.5347004;-1.5061364;-0.1609542;-0.42014167;3.1088617;2.8243933;IRRE
maximum;-1.3596199;0.006275604;5.2153406;-0.6442335;0.47318798;-3.35568;-
iterator over parsed reuters sgml files;-0.76558465;-1.3703134;-2.4191213;0.7656221;1.5012667;1.2801373;IRRE
we learn a binary classification between the acq class and all the others;3.124994;-5.1914363;0.42551163;2.0482726;7.4443564;-2.4557452;IRRE
acq was chosen as it is more or less evenly distributed in the reuters;1.4402862;0.61829394;2.1006355;2.211765;0.11637049;0.5682114;META
files for other datasets one should take care of creating a test set with;2.828489;-1.3363835;-1.7630123;1.8558503;1.2846432;-2.8694348;IRRE
a realistic portion of positive instances;3.5548754;1.3069674;1.6462375;3.3213153;3.5543416;-1.7317328;-
here are some classifiers that support the partial fit method;7.0774755;-3.7189837;0.18084937;1.4769654;3.5533528;1.78323;IRRE
discard test set;0.72142005;6.082172;-1.0580549;4.9951553;0.8125258;-3.030545;IRRE
we will feed the classifier with mini batches of 1000 documents this means;2.603052;-5.999141;0.8815808;3.7859492;5.1920533;0.46464613;CODE
we have at most 1000 docs in memory at any time the smaller the document;0.12956479;-1.940452;2.0898035;1.61507;1.0012792;1.2738231;CODE
batch the bigger the relative overhead of the partial fit methods;7.6988754;-0.94842666;-1.2526861;3.0619943;0.65406436;5.1635737;CODE
create the data stream that parses reuters sgml files and iterates on;-0.02902154;-2.132262;-0.693021;0.47254592;1.7947167;1.8724326;IRRE
documents as a stream;-2.409205;-4.8810945;3.9083273;1.6475428;3.431257;2.2286923;CODE
main loop iterate on mini batches of examples;2.8081837;-0.11311067;2.148337;0.14877415;0.22663146;-0.66387534;IRRE
update estimator with examples in the current mini batch;2.702527;-0.048734333;-0.7469607;3.4929457;-0.43132362;4.0410886;CODE
accumulate test accuracy stats;6.0120883;2.2828596;-0.62065846;6.421635;-0.36158082;-4.8582344;IRRE
plot results;2.7280972;0.6326069;7.251218;-4.383266;-6.211307;-4.720718;IRRE
the plot represents the learning curve of the classifier the evolution;3.5877583;-6.2985644;2.7517154;-0.79857516;-1.6549449;0.3829198;IRRE
of classification accuracy over the course of the mini batches accuracy is;5.62167;-3.1433794;-1.3965331;4.1169333;2.449896;1.0985922;IRRE
measured on the first 1000 samples held out as a validation set;4.764161;3.3277247;-1.5436164;4.0104494;-0.5941379;-2.8321342;CODE
to limit the memory consumption we queue examples up to a fixed amount;0.5612923;-0.38476;2.3023632;2.7531085;3.3714588;2.1209815;-
before feeding them to the learner;-1.8509458;-3.8984938;3.4274256;4.9657235;0.5943631;-0.808956;CODE
plot prediction times;5.211032;-3.020151;4.7047076;0.4168961;-5.947582;0.32720476;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
first example;-1.7130101;-1.4101841;4.9611588;1.4785457;1.579746;-2.1794183;-
the first example illustrates how the minimum covariance determinant;1.9966091;-2.3083384;-1.612292;-1.838389;-1.3088534;4.15352;CODE
robust estimator can help concentrate on a relevant cluster when outlying;5.53561;-0.6458415;0.099648945;1.8294002;-0.78048944;5.6807485;IRRE
points exist here the empirical covariance estimation is skewed by points;4.7392454;-0.52287704;-2.0515487;-1.1407673;-4.2751856;3.648878;CODE
outside of the main cluster of course some screening tools would have pointed;0.9871031;-4.0619783;1.3924013;4.7183933;0.2964983;-1.6017007;CODE
out the presence of two clusters support vector machines gaussian mixture;6.604793;-3.477017;-0.5224979;-0.20535542;2.5961099;3.499195;-
models univariate outlier detection but had it been a high dimensional;4.0839295;-0.48263124;-1.7778512;0.4866941;-1.3890531;0.92477036;META
example none of these could be applied that easily;0.58593094;-0.3701765;1.4895915;0.36431748;3.7589338;-1.2861865;-
x load wine data 1 2 two clusters;1.4863467;-0.37592265;-0.12821525;-2.7725751;1.0124134;2.1609726;CODE
learn a frontier for outlier detection with several classifiers;5.585667;-3.8063972;-0.99461657;0.4494106;0.32970557;1.0016633;CODE
second example;-1.1902189;-1.2147639;4.7001047;2.5256937;2.1703715;-1.4775444;-
the second example shows the ability of the minimum covariance determinant;2.2861876;-1.001672;-2.0927517;-0.8378431;-0.069686435;4.117718;CODE
robust estimator of covariance to concentrate on the main mode of the data;4.973603;-0.069673695;1.4245766;0.7624264;-0.9506199;6.6681523;CODE
distribution the location seems to be well estimated although the;2.8370025;-1.0972023;2.6045797;1.6066864;-0.92138886;1.9179285;META
covariance is hard to estimate due to the banana shaped distribution anyway;3.5898285;0.29695192;0.3264528;1.7534537;-3.59815;3.531331;META
we can get rid of some outlying observations the one class svm is able to;6.0966573;-2.4297552;-1.9417309;1.9027921;3.09389;4.2594647;CODE
capture the real data structure but the difficulty is to adjust its kernel;5.754912;-1.4104643;-1.3154749;-1.9811319;0.4285297;2.6435778;META
bandwidth parameter so as to obtain a good compromise between the shape of;3.1512702;0.85266745;3.179351;-1.1212896;1.2807342;4.763812;IRRE
the data scatter matrix and the risk of over fitting the data;7.339137;-1.7939979;1.701188;-1.2827243;-2.5445006;2.901716;-
x load wine data 6 9 banana shaped;-0.3048606;-1.142047;2.0111434;-4.630957;-0.29074565;0.22672646;CODE
learn a frontier for outlier detection with several classifiers;5.585667;-3.8063972;-0.99461657;0.4494106;0.32970557;1.0016633;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
hack to detect whether we are running by the sphinx builder;-4.5202;-0.84971195;-1.7690636;4.44111;-0.2929326;-0.3187099;CODE
benchmark and plot helper functions;4.349561;-2.0217156;2.667828;-0.020833489;-4.1780105;-0.29420838;CODE
ax1 set title evolution of prediction time with features;4.2785163;-3.6468954;0.27061397;1.008796;1.4299712;2.3391461;TASK
ax1 set xlabel features;1.0595801;-0.53050417;-1.0591239;-2.7088127;0.43194887;4.210578;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
if basemap is available we ll use it;-2.2474754;-4.820522;3.34049;-0.019303557;1.0938623;3.0692682;CODE
otherwise we ll improvise later;-1.3241091;-2.0078855;3.4649837;4.2516494;0.76506215;0.68537974;-
x y coordinates for corner cells;0.42943436;-0.15855147;3.4682386;-8.578858;-3.992921;1.0000855;CODE
x coordinates of the grid cells;1.1938763;0.97250885;3.1347892;-7.352223;-2.9789383;1.3927096;-
y coordinates of the grid cells;0.9027665;0.42357472;3.3228528;-6.7840323;-4.5404034;1.127217;-
choose points associated with the desired species;3.5733037;-0.04178967;4.053528;-2.0356722;3.2881546;0.9248575;CODE
determine coverage values for each of the training testing points;6.007862;1.8393974;-0.20324194;1.5758203;2.1920855;-3.9245658;IRRE
load the compressed data;1.2719257;-0.050416905;1.0271862;-1.8478132;0.7407448;1.3911477;CODE
set up the data grid;1.8734968;-1.6876365;4.360756;-4.1187997;1.490922;1.606785;IRRE
the grid in x y coordinates;1.0898342;-0.15629359;4.393819;-8.006659;-3.5477016;0.85807556;-
create a bunch for each species;2.309974;-1.5138211;4.7982655;-0.5409919;4.143002;-1.3709745;CODE
background points grid coordinates for evaluation;3.562641;-0.70177066;3.4907773;-4.1480694;-1.843106;1.5127138;CODE
we ll make use of the fact that coverages 6 has measurements at all;1.7856436;0.89520895;1.7072004;2.0746565;0.79070264;-0.36541033;-
land points this will help us decide between land and water;1.0232172;-1.2066914;5.0272026;0.16511387;1.7026151;-0.045058474;CODE
fit predict and plot for each species;5.827894;-2.4801188;3.179855;-1.6019508;-2.9199555;0.54645395;CODE
standardize features;2.4611804;-2.3838465;-0.8570295;-0.9768594;2.4093952;4.07738;TASK
fit oneclasssvm;1.6224686;-0.571696;-2.5008042;-0.22050378;3.6417434;3.2217114;IRRE
plot map of south america;0.050621983;-1.7204229;6.07646;-2.2746108;-1.9268228;0.44000375;-
predict species distribution using the training data;5.3769646;-4.5315504;0.7206618;3.2415478;1.3642831;-0.0084465;META
we ll predict only for the land points;3.350055;-1.4082582;3.651662;3.0652165;-0.8736229;0.17216775;CODE
plot contours of the prediction;4.4180245;-2.4117434;4.6239667;-0.43612507;-5.0765676;1.4503944;-
scatter training testing points;7.5089674;-1.3078396;0.13900074;1.0269932;-1.4075402;-0.14874353;IRRE
compute auc with regards to background points;2.4949224;-1.1725867;0.13123822;-2.6011665;-1.4639126;1.5291399;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
retrieve the data from internet;-1.1488235;-0.8154766;4.793705;-1.4064769;-0.4330832;0.15294214;CODE
the data is from 2003 2008 this is reasonably calm not too long ago so;0.95425206;-2.022607;0.8117479;-0.17476088;-0.8540295;-0.7080494;CODE
that we get high tech firms and before the 2008 crash this kind of;0.12426829;-3.3822947;2.0743458;3.6453252;-1.1263072;0.5862649;CODE
historical data can be obtained from apis like the;-0.45948625;-4.5600047;2.9202826;1.8825467;0.9890917;0.5504394;CODE
data nasdaq com https data nasdaq com and;-0.1502969;0.6921552;1.5131444;-4.4530125;-0.1078883;-1.4793118;CODE
alphavantage co https www alphavantage co;-4.485846;-1.1489815;0.7662031;-1.4326732;-0.49854276;-0.1562994;CODE
the daily variations of the quotes are what carry the most information;-0.43022332;-3.7210257;3.715598;1.5200256;1.451678;-0.24908948;CODE
stock market;-0.039140377;-0.5824651;5.6014457;-1.0052365;-0.59048665;-2.8012087;-
learning a graph structure;4.34279;-3.90859;4.159193;-3.307539;2.4247987;1.1510884;CODE
we use sparse inverse covariance estimation to find which quotes are;4.109874;-2.2832215;-1.5450029;-0.31281126;0.5031642;1.789153;IRRE
correlated conditionally on the others specifically sparse inverse;4.951909;1.8725983;-1.6994216;-0.54132575;0.48304066;4.9140735;IRRE
covariance gives us a graph that is a list of connections for each;2.607868;-3.6145608;3.1985843;-2.2108707;1.2658775;2.6903095;CODE
symbol the symbols that it is connected to are those useful to explain;-3.541365;-3.5606587;5.0277834;-1.0184474;0.6139563;-1.0837376;-
its fluctuations;1.4729353;-0.61709934;5.3473606;1.0117724;-4.2796507;-0.018647835;-
standardize the time series using correlations rather than covariance;3.51225;-0.3171153;-0.5251352;-1.032996;-3.224953;5.239306;CODE
former is more efficient for structure recovery;-0.5999831;-0.043542523;1.1070783;1.6105036;2.3359683;3.3088207;CODE
clustering using affinity propagation;5.5721893;-3.0129182;0.23863024;-0.97716767;1.7323108;3.7604303;IRRE
we use clustering to group together quotes that behave similarly here;2.046134;-0.6391608;1.1649779;-0.8355037;3.708054;-0.89348525;IRRE
amongst the ref various clustering techniques clustering available;3.5411491;-3.4315174;1.6660746;1.0800406;3.3020618;2.0073845;CODE
in the scikit learn we use ref affinity propagation as it does;3.3726053;-6.8037543;-3.1040692;1.361739;-0.6992547;3.2752862;CODE
not enforce equal size clusters and it can choose automatically the;2.0177493;2.1034837;-0.87932426;-0.28308874;1.7815969;5.101413;TASK
number of clusters from the data;3.859464;-1.395089;2.7790549;-3.0011632;0.7905946;-0.7282648;CODE
note that this gives us a different indication than the graph as the;1.4260656;0.5622793;3.5381424;-3.1728382;-2.7139452;-0.8361736;TASK
graph reflects conditional relations between variables while the;0.788851;1.8622289;2.1860662;-3.3892317;0.30789787;0.77491474;CODE
clustering reflects marginal properties variables clustered together can;3.1295328;-1.4613421;-0.73736054;-0.38798195;3.3271365;4.356647;IRRE
be considered as having a similar impact at the level of the full stock;0.4624735;-0.22320782;2.6369236;1.5315232;1.7666171;1.9188529;-
market;-1.2745507;-1.4637141;5.485896;0.03777865;0.67728966;-2.9420764;-
embedding in 2d space;2.0664303;-1.925827;3.4514523;-5.034963;0.14785612;4.1594734;-
for visualization purposes we need to lay out the different symbols on a;-0.43272883;-2.320202;5.6406045;-5.4642186;1.5427936;0.31669062;TASK
2d canvas for this we use ref manifold techniques to retrieve 2d;0.8351785;-2.79259;4.428165;-3.9533808;-2.6069767;3.6419039;CODE
embedding;1.5190164;-3.1246526;4.75728;-1.85627;2.2134178;2.5078983;-
we use a dense eigen solver to achieve reproducibility arpack is initiated;1.8683659;-3.3147233;-4.7909145;1.1463844;-1.8672578;2.6011083;IRRE
with the random vectors that we do not control in addition we use a large;3.407964;-2.1938522;1.7408669;1.6800998;0.718038;2.8927422;IRRE
number of neighbors to capture the large scale structure;5.483205;-1.9672037;2.9697292;-2.7521682;1.0208218;1.7247393;CODE
finding a low dimension embedding for visualization find the best position of;4.047837;-1.80287;4.0322075;-5.671513;-1.115642;4.211372;CODE
the nodes the stocks on a 2d plane;2.3421333;-1.5706892;3.0320952;-6.378316;-1.6637163;1.4044065;-
visualization;2.026305;-4.5795045;9.384689;-3.0934672;-0.121084325;-0.48344806;-
the output of the 3 models are combined in a 2d graph where nodes;3.6345532;-1.4256432;2.4848955;-3.1370382;0.74021876;1.3285958;IRRE
represent the stocks and edges the connections partial correlations;3.2419388;-2.701586;3.0150049;-4.382665;1.7133403;2.5629387;CODE
cluster labels are used to define the color of the nodes;1.9732232;-2.6338153;1.200585;-3.1034057;3.089752;1.8214655;CODE
the sparse covariance model is used to display the strength of the edges;5.342742;-3.7074249;2.287127;-2.1483269;-0.9987502;3.544621;IRRE
the 2d embedding is used to position the nodes in the plan;0.09078196;-3.1406279;3.6598613;-5.2642493;-0.42037034;4.8788385;OUTD
this example has a fair amount of visualization related code as;-1.2616732;-3.726166;5.2905006;-3.360633;0.6541321;0.13527624;CODE
visualization is crucial here to display the graph one of the challenges;1.1134075;-3.5058947;7.1038218;-2.949521;-1.7315273;-0.18851912;-
is to position the labels minimizing overlap for this we use an;1.9843022;0.25816455;4.1386957;-2.3558602;2.0305514;4.5895257;CODE
heuristic based on the direction of the nearest neighbor along each;5.5470343;-1.7824163;2.9663646;-1.9566542;2.3153455;0.17305668;CODE
axis;0.82978505;-0.13757393;7.4262204;-7.678327;-4.2319403;-0.20800017;-
plot the graph of partial correlations;2.539297;-0.7333539;4.51766;-5.252215;-4.079856;1.3573784;-
plot the nodes using the coordinates of our embedding;2.6980598;-1.5232869;3.968089;-6.344544;-3.2102988;3.247155;-
plot the edges;0.050338272;-0.9133859;7.392213;-5.121104;-4.3092275;-0.079941735;-
a sequence of line0 line1 line2 where;-0.92232174;2.9152195;2.513147;-3.3791823;0.5727096;-2.9035323;CODE
linen x0 y0 x1 y1 xm ym;-1.8716362;2.4427598;1.2831491;-6.010423;0.76823235;0.049917806;-
add a label to each node the challenge here is that we want to;0.09817441;-0.82931;4.1964397;-1.1748673;3.3621745;-0.45431495;TASK
position the labels to avoid overlap with other labels;0.89672244;0.7319177;4.5924997;-3.001861;1.6653367;1.8573521;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
analyzing the bike sharing demand dataset;3.588701;-2.04871;3.2437937;0.07919201;1.1685004;0.36227974;IRRE
we start by loading the data from the openml repository as a raw parquet file;-3.3702133;-3.0272896;-0.35232323;1.117951;1.9949354;2.002121;CODE
to illustrate how to work with an arbitrary parquet file instead of hiding this;-2.6791193;1.2701468;1.3911451;0.8270823;2.8932402;2.4021726;CODE
step in a convenience tool such as sklearn datasets fetch openml;1.0113646;-6.220267;-2.9013054;0.96308464;0.9792593;0.3360498;IRRE
the url of the parquet file can be found in the json description of the;-4.99598;-1.2647078;1.3555411;-0.12546492;0.6122047;1.6641661;CODE
bike sharing demand dataset with id 44063 on openml org;0.11335158;-1.4787805;-1.6525173;-0.95505816;3.533954;2.0296865;CODE
https openml org search type data status active id 44063;-3.395384;0.33029968;-3.549953;-0.03681105;1.4186887;0.20731373;CODE
the sha256 hash of the file is also provided to ensure the integrity of the;-4.597993;-0.59343207;-1.0545206;0.03590599;0.6983002;-0.012065157;CODE
downloaded file;-4.917825;-3.584182;2.864734;-1.2419881;-1.8796258;-1.1457384;CODE
we load the parquet file with polars for feature engineering polars;-1.4706795;-3.8359492;-1.247377;-1.9412827;1.7523907;0.39479765;CODE
automatically caches common subexpressions which are reused in multiple;-0.32437488;1.9777745;0.12059217;2.1572056;4.405405;3.8268237;IRRE
expressions like pl col count shift 1 below see;1.3016866;2.2792668;1.2759664;-6.162477;1.9062206;-3.4335833;-
https docs pola rs user guide lazy optimizations for more information;-1.3065424;-3.9142377;-1.3816648;2.2119331;1.905469;1.556184;CODE
next we take a look at the statistical summary of the dataset;6.096139;-5.2695327;1.6559047;2.0434134;0.54969627;-1.3030665;IRRE
so that we can better understand the data that we are working with;1.0719626;-4.6914544;2.370503;1.1686329;0.50736445;0.20844762;CODE
let us look at the count of the seasons fall spring summer;1.2319078;-0.56814307;2.9096534;1.6530206;-0.22937721;-1.1689014;CODE
and winter present in the dataset to confirm they are balanced;4.626679;-1.3206241;-0.16368854;1.2167336;0.17754243;-0.55195284;CODE
generating polars engineered lagged features;1.469464;-4.1880393;0.033838682;-1.3234531;-0.43453237;2.1583695;TASK
let s consider the problem of predicting the demand at the;3.3430865;0.71460336;4.6248755;2.8842387;0.27015135;-0.4374781;CODE
next hour given past demands since the demand is a continuous;-2.0362985;1.2824585;4.987572;1.7317266;-0.37104464;0.35949817;CODE
variable one could intuitively use any regression model however we do;0.7296852;-1.8889918;3.2463958;3.4454854;-0.89594823;0.18402438;CODE
not have the usual x train y train dataset instead we just have;2.8138509;-2.8176115;0.69255775;-0.85004014;0.087653376;0.39017987;IRRE
the y train demand data sequentially organized by time;4.771207;-1.2288063;4.2001467;-0.31848457;0.63902384;2.5303578;-
watch out however the first lines have undefined values because their own;-2.513671;4.8612137;0.42136535;-3.2628467;-3.0824254;-5.023253;IRRE
past is unknown this depends on how much lag we used;-0.40465352;-0.3387478;2.61135;3.6233757;-2.3024113;1.6237631;CODE
we can now separate the lagged features in a matrix x and the target variable;3.4382896;-1.894284;-0.28421086;-1.0685941;-0.53257406;6.3040175;TASK
the counts to predict in an array of the same first dimension y;7.394094;0.28087705;1.1778272;-2.0120854;-0.959819;-1.7822827;CODE
naive evaluation of the next hour bike demand regression;2.970248;-1.0730271;2.6846697;2.0070152;-0.25583616;-0.1951046;-
let s randomly split our tabularized dataset to train a gradient;6.7621145;-2.8907983;2.0769875;-0.62362176;2.4093862;1.478915;IRRE
boosting regression tree gbrt model and evaluate it using mean;2.826236;-0.9393556;-1.1899161;1.0430452;1.1668879;0.17189892;-
absolute percentage error mape if our model is aimed at forecasting;3.1160774;2.1870077;0.5590131;3.0899024;-2.8241284;1.743065;CODE
i e predicting future data from past data we should not use training;2.7332306;-3.2237728;1.9215239;5.405107;-0.013320769;0.21025823;CODE
data that are ulterior to the testing data in time series machine learning;5.9968038;-0.92184037;0.089703016;3.9735358;1.0049151;-2.557475;IRRE
the i i d independent and identically distributed assumption does not;-1.383683;2.81199;-0.5770919;2.0008852;-1.10885;0.6198899;CODE
hold true as the data points are not independent and have a temporal;3.155005;2.579848;2.1514218;1.8136536;0.11094028;1.579218;CODE
relationship;-1.8536149;-0.694128;6.153555;-0.23746772;0.07620596;-2.4522707;-
taking a look at the performance of the model;4.9982433;-3.4213054;1.425393;4.5592933;0.8981193;0.47835255;CODE
proper next hour forecasting evaluation;2.1070073;-1.3220682;2.0889378;4.4112253;-0.785537;-0.6738486;CODE
let s use a proper evaluation splitting strategies that takes into account;4.116863;1.694929;1.5856723;4.944708;5.111514;-0.1681087;CODE
the temporal structure of the dataset to evaluate our model s ability to;5.1336226;-4.788684;3.6863575;6.007563;2.3300354;-0.8594856;IRRE
predict data points in the future to avoid cheating by reading values from;6.4003077;-1.1830766;2.3386726;2.6059775;-0.47032997;-2.9855852;CODE
the lagged features in the training set;4.0504932;-5.810488;1.7703949;4.8095007;0.75291127;1.5548263;TASK
n splits 3 to keep the notebook fast enough on common laptops;0.39761424;-1.9557872;1.630408;-1.5856849;1.344191;1.0881106;TASK
gap 48 2 days data gap between train and test;2.5458052;2.7996204;-0.51277703;1.8023552;-1.1821522;-1.4652956;IRRE
max train size 10000 keep train sets of comparable sizes;4.3286896;1.2709864;0.9062527;-1.6013405;2.1851213;2.0118747;IRRE
test size 3000 for 2 or 3 digits of precision in scores;3.156463;2.0833907;-2.044584;0.34057415;-0.7697603;-4.79008;IRRE
training the model and evaluating its performance based on mape;4.449132;-2.6215384;1.4589344;4.643608;2.937567;-1.0318028;CODE
the generalization error measured via a shuffled trained test split;6.376271;0.2535278;-4.6032877;4.2499366;1.4408215;-1.7433432;IRRE
is too optimistic the generalization via a time based split is likely to;5.7831593;-2.3941913;0.35034505;4.497366;3.914107;2.916463;-
be more representative of the true performance of the regression model;4.938756;1.0680822;1.5536133;5.992286;0.565989;1.0795261;CODE
let s assess this variability of our error evaluation with proper;2.7203496;2.281861;-0.7806378;5.000608;0.4659882;-4.0299764;CODE
cross validation;2.493245;1.2475493;2.397642;1.889912;3.7310712;-3.8565283;-
the variability across splits is quite large in a real life setting;3.7880433;-2.0952017;1.7666572;2.6065714;0.54921514;1.8528115;IRRE
it would be advised to use more splits to better assess the variability;3.48086;0.19331498;1.4462227;2.8642178;3.2658749;0.87157685;CODE
let s report the mean cv scores and their standard deviation from now on;2.3124247;-0.35350758;0.39925787;0.16850474;-0.32957575;-2.2703028;CODE
we can compute several combinations of evaluation metrics and loss functions;5.5840883;-2.775586;-0.1796172;1.1139038;3.7970889;1.7180293;CODE
which are reported a bit below;-2.6351445;-1.7002114;1.3864825;0.8168097;1.5549867;-2.334212;CODE
modeling predictive uncertainty via quantile regression;3.1178854;-0.9108897;1.6439775;3.4398813;-1.6556573;1.4386203;META
instead of modeling the expected value of the distribution of;0.12969822;0.51404583;3.1547053;3.3451123;-1.1119515;1.3388296;IRRE
math y x like the least squares and poisson losses do one could try to;5.47717;-1.6143901;3.714576;-1.6492993;-2.915035;1.3777689;CODE
estimate quantiles of the conditional distribution;0.037357286;1.7841834;1.9082998;1.3928984;-0.40261456;1.6474539;META
math y x x i is expected to be a random variable for a given data point;1.5365963;1.4288077;1.609476;-3.360886;-3.151717;-1.1339358;CODE
math x i because we expect that the number of rentals cannot be 100;1.1456504;2.3490398;1.542678;-1.0791434;1.5840349;-3.2034743;-
accurately predicted from the features it can be influenced by other;7.019747;-5.8532043;2.0586119;4.106378;0.77978504;0.88048923;TASK
variables not properly captured by the existing lagged features for;0.1485242;0.4379701;-2.389809;1.417149;-2.5462196;1.9700762;CODE
instance whether or not it will rain in the next hour cannot be fully;-1.2553197;1.7083304;2.8266447;3.8874888;0.22771093;-2.6947932;CODE
anticipated from the past hours bike rental data this is what we;1.365865;-2.2560213;2.6228511;0.24884115;1.4009651;-0.5714386;CODE
call aleatoric uncertainty;0.779075;1.8723626;0.81442004;2.9177117;0.013965195;1.2110637;IRRE
quantile regression makes it possible to give a finer description of that;2.9338481;-1.740849;4.098004;1.3981888;-0.0016922608;0.9876735;CODE
distribution without making strong assumptions on its shape;2.830972;1.8814585;2.4982457;0.77420694;-0.075724505;2.244462;META
let us take a look at the losses that minimise each metric;5.640067;-1.6457635;1.376002;3.071999;0.07218445;3.2751212;CODE
even if the score distributions overlap due to the variance in the dataset;4.8072386;0.8665228;-0.32253623;3.1996713;1.2231156;2.0339856;CODE
it is true that the average rmse is lower when loss squared error whereas;0.9191979;-0.362148;-1.7774463;2.336168;-3.2360475;2.5713787;-
the average mape is lower when loss absolute error as expected that is;3.0333006;3.0931973;-2.8597753;0.9004868;-3.5220726;2.2023532;-
also the case for the mean pinball loss with the quantiles 5 and 95 the score;1.1327513;1.8764806;2.0094244;2.9672284;-1.5179873;-1.7516544;CODE
corresponding to the 50 quantile loss is overlapping with the score obtained;2.1469376;3.397584;0.2012558;-0.04515225;-2.0903904;-0.29994446;-
by minimizing other loss functions which is also the case for the mae;3.7797973;-1.410311;-2.3947434;1.7067431;-0.7845365;4.391023;CODE
a qualitative look at the predictions;4.4031034;-4.3586926;4.489663;6.819654;-0.38909265;-1.8096217;-
we can now visualize the performance of the model with regards;3.5951777;-4.484843;4.554314;2.9860373;0.55893695;1.8939229;CODE
to the 5th percentile median and the 95th percentile;2.5906131;-1.248973;3.2589457;-0.3042773;-0.54438156;-1.6362365;-
we can now take a look at the predictions made by the regression models;3.5823734;-5.1376615;2.065822;5.976811;-2.1596074;0.35990065;-
here it s interesting to notice that the blue area between the 5 and 95;-1.1312485;-0.8035716;3.6596677;-1.7195014;-0.6448212;-0.46065557;CODE
percentile estimators has a width that varies with the time of the day;1.8245273;0.14797607;3.2859175;-0.9518904;-2.786101;2.6925626;CODE
at night the blue band is much narrower the pair of models is quite;0.062296953;-0.49140596;2.1054516;0.3608914;-0.5266072;1.8375763;-
certain that there will be a small number of bike rentals and furthermore;0.49482483;-0.8891642;2.0259082;0.9292577;3.5177372;0.14365596;CODE
these seem correct in the sense that the actual demand stays in that blue;-1.9330338;1.0024892;2.0129137;0.59418947;0.46991178;1.3783298;CODE
band;-1.9679049;-0.6289792;6.8845577;-0.2747922;0.8946622;-2.2798645;-
during the day the blue band is much wider the uncertainty grows probably;0.9025698;0.8782858;3.8199263;2.239852;-2.3857021;1.3317347;META
because of the variability of the weather that can have a very large impact;0.7530107;-0.462897;2.4216425;2.242455;-1.6758215;2.293246;CODE
especially on week ends;0.18767178;-0.9819445;4.8595285;2.9626696;-1.8364525;1.7001768;CODE
we can also see that during week days the commute pattern is still visible in;-0.376819;0.4493679;2.139533;0.39051348;-0.028893348;4.021141;TASK
the 5 and 95 estimations;3.8420231;-2.0850284;1.781438;3.415164;-0.22380723;-1.1997201;-
finally it is expected that 10 of the time the actual demand does not lie;0.0916096;2.4410942;0.9927535;3.3408868;-0.89689904;0.21580832;CODE
between the 5 and 95 percentile estimates on this test span the actual;2.242039;2.2681506;0.48267177;3.1940994;-1.9548644;-2.8636608;IRRE
demand seems to be higher especially during the rush hours it might reveal that;0.16855893;-0.23854126;2.7838204;3.2111118;-1.6590565;1.0284194;-
our 95 percentile estimator underestimates the demand peaks this could be be;2.6672442;1.6957734;1.1356673;1.3771098;-3.3920493;1.6209846;CODE
quantitatively confirmed by computing empirical coverage numbers as done in;4.3858514;-1.4930104;-1.5378412;3.0246942;1.0587766;-2.1402466;CODE
the ref calibration of confidence intervals calibration section;2.8721063;-0.41459575;-1.0268734;3.1663058;-1.6240633;0.67564845;CODE
looking at the performance of non linear regression models vs;3.5549428;-2.1554716;1.3591266;5.0148773;-2.733256;-0.071928024;CODE
the best models;3.406389;-5.1769757;4.3530655;3.538247;2.0022666;1.1633995;-
conclusion;-1.7600391;1.0903363;5.187226;3.933175;0.70637393;-3.3991342;-
through this example we explored time series forecasting using lagged;1.8798968;-4.3427124;3.3522296;3.4360127;-1.8116121;2.9456944;CODE
features we compared a naive regression using the standardized;3.7212074;-3.4673815;-1.2450541;2.398665;-0.56059116;-1.2730819;TASK
class sklearn model selection train test split with a proper time;3.9526346;-0.82393664;-3.1860728;4.547854;0.53199005;-1.6429882;CODE
series evaluation strategy using;3.7744555;1.1936017;2.8623102;3.1238432;0.16604328;-3.190671;-
class sklearn model selection timeseriessplit we observed that the;4.583933;-7.3733163;-4.1893253;3.4618566;-0.35473964;0.012705788;CODE
model trained using class sklearn model selection train test split;3.825775;-1.5366635;-4.125186;3.6925416;1.5654945;-2.5913117;CODE
having a default value of shuffle set to true produced an overly;1.3905529;3.945288;-0.3886114;0.86515945;2.2345645;1.398647;IRRE
optimistic mean average percentage error mape the results;4.169016;2.8329866;0.2995878;3.4343052;-2.831104;-0.35670507;IRRE
produced from the time based split better represent the performance;4.440241;-0.9594518;2.7929952;1.850572;2.8966062;0.5706626;CODE
of our time series regression model we also analyzed the predictive uncertainty;3.2981317;-1.9370472;1.7316345;4.383322;-2.4766533;0.94350433;META
of our model via quantile regression predictions based on the 5th and;4.177869;-1.2234614;2.9950895;3.6781812;-0.779205;-0.7303944;CODE
95th percentile using loss quantile provide us with a quantitative estimate;3.001541;-0.98624593;1.4152077;0.90443486;-1.5437733;0.81056774;-
of the uncertainty of the forecasts made by our time series regression model;1.4486101;-0.978867;2.097721;4.2101307;-4.0094957;1.680492;CODE
uncertainty estimation can also be performed;5.2745614;0.004591564;2.005406;3.62398;0.3494228;2.083058;CODE
using mapie https mapie readthedocs io en latest index html;-4.507848;-0.2399974;-1.1838111;0.23111024;-1.6182214;1.8195754;CODE
that provides an implementation based on recent work on conformal prediction;4.404092;-3.4175692;-0.33627224;0.97841334;-0.58557576;2.9129684;TASK
methods and estimates both aleatoric and epistemic uncertainty at the same time;1.7500689;-0.1445715;0.016293937;5.352031;-0.24738643;2.2763844;META
furthermore functionalities provided;-2.112536;-2.8140697;3.1135604;0.27081472;3.135266;1.3304435;CODE
by sktime https www sktime net en latest users html;-3.2767072;-2.1378222;2.3923256;-0.46088746;-1.4756263;0.21992393;IRRE
can be used to extend scikit learn estimators by making use of recursive time;4.6457143;-8.36627;-2.8796186;3.08427;-2.297024;0.6843736;OUTD
series forecasting that enables dynamic predictions of future values;4.1846247;-3.1905487;3.673374;3.3259802;-0.66154236;1.5415276;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the 20 newsgroups dataset and vectorize it we use a few heuristics;4.9265447;-3.5779893;1.757954;-0.39926413;2.3041773;1.7091137;CODE
to filter out useless terms early on the posts are stripped of headers;-2.5858448;0.53754675;-1.830285;2.5827694;1.457905;1.8127366;CODE
footers and quoted replies and common english words words occurring in;-3.0183742;-2.2975972;1.4347402;0.8686533;1.4667674;-0.40091294;IRRE
only one document or in at least 95 of the documents are removed;-2.5642133;-0.03289115;0.44834763;1.2951672;1.7026169;-0.4278521;CODE
use tf idf features for nmf;1.5505071;-3.4734762;-3.0076559;0.53304756;2.4846509;1.2632251;TASK
use tf raw term count features for lda;1.6421411;-1.2716982;-3.9481027;-0.84386057;2.4121234;-0.113513395;TASK
fit the nmf model;2.18187;-1.0202107;-0.9099139;-0.7791673;-0.26956835;1.8017248;-
fit the nmf model;2.18187;-1.0202107;-0.9099139;-0.7791673;-0.26956835;1.8017248;-
fit the minibatchnmf model;1.7134718;-1.2701347;-1.6678314;0.25368938;-0.29423258;3.9427512;-
fit the minibatchnmf model;1.7134718;-1.2701347;-1.6678314;0.25368938;-0.29423258;3.9427512;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
download data if not already on disk;-1.0335482;0.7589755;3.4675379;1.2247393;-0.12795904;0.18836851;CODE
loading the redirect files;-4.649583;-0.16988531;3.1626375;1.923869;-3.0756104;1.4614393;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
return number if token 0 isdigit else token for token in tokens;-1.0251024;4.4189262;-1.4306107;-1.7783637;0.6823957;-5.1718445;CODE
exclude comp os ms windows misc;-1.9201136;0.97030014;-1.9462441;0.6176804;0.18990645;1.9478548;CODE
note the following is identical to x rows np newaxis;3.6957977;0.41325176;-0.75484043;-7.579465;-0.75324076;0.49338484;TASK
cols sum but much faster in scipy 0 16;3.949549;-1.8465724;-2.8924873;-4.4155245;-6.1860924;-2.6762056;META
categories;0.43083423;-5.6964126;4.8599014;1.345258;4.707574;-2.575319;-
words;-2.0362062;-3.702281;6.0088053;1.8112036;1.1756642;-2.1493628;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
we generate the sample data using the;4.9970655;-2.1910536;3.0767648;-0.8328221;3.2288697;-3.1858506;-
func sklearn datasets make checkerboard function each pixel within;2.3120587;-0.48154557;-1.4130026;-3.746576;-2.6924102;-0.1390497;IRRE
shape 300 300 represents with its color a value from a uniform;1.8769128;0.8964695;2.5766404;-4.768786;0.7388081;-2.2474122;CODE
distribution the noise is added from a normal distribution where the value;-0.8115037;0.77628785;1.59458;-0.89223284;-1.2026104;0.60372555;META
chosen for noise is the standard deviation;3.2338831;-2.9439685;0.39489496;1.3748852;0.022115443;-0.3160482;CODE
as you can see the data is distributed over 12 cluster cells and is;3.9082897;-0.97509855;1.3253812;-2.3258548;0.7681642;0.9248344;META
relatively well distinguishable;2.9442644;-0.9971443;1.9195858;1.6819216;4.7701144;-1.7948912;-
we shuffle the data and the goal is to reconstruct it afterwards using;4.4471126;-0.34767923;3.1129687;-0.9362297;3.1466877;1.4436753;CODE
class sklearn cluster spectralbiclustering;4.6985946;-7.075339;-3.9232547;-2.8731513;-1.4729223;1.7966918;IRRE
creating lists of shuffled row and column indices;4.026895;0.55225074;2.1004164;-5.6658216;1.9952724;-1.5008893;-
we redefine the shuffled data and plot it we observe that we lost the;4.392153;-0.27912256;3.6891625;-1.1388459;-2.4050522;0.607508;CODE
structure of original data matrix;5.1997232;-0.5448422;0.550739;-6.671569;0.54361266;2.3976724;CODE
fitting spectralbiclustering;4.9359417;-3.131443;-1.7238036;-3.1999683;-2.4925897;4.429586;-
we fit the model and compare the obtained clusters with the ground truth note;4.8828354;-0.671976;-1.306549;-0.88187796;-0.39801013;1.8316722;TASK
that when creating the model we specify the same number of clusters that we;3.3119476;-0.48798946;0.65071607;-0.04760935;3.862573;2.5445685;-
used to create the dataset n clusters 4 3 which will contribute to;2.2304168;-6.1300673;0.51852053;-1.8993803;1.29049;-0.478168;IRRE
obtain a good result;2.260115;1.0913216;4.4260855;4.245457;1.5696727;-6.826266;IRRE
compute the similarity of two sets of biclusters;4.9239225;0.41203165;1.2940832;-3.172256;1.4537681;-0.36449218;IRRE
the score is between 0 and 1 where 1 corresponds to a perfect matching it;3.0266964;3.0003192;0.14101577;-1.1761338;1.6368194;-5.20973;-
shows the quality of the biclustering;2.4020085;-2.2912776;1.9530761;1.4195979;1.2337548;0.52587783;-
plotting results;3.5057433;0.4475306;7.402773;-5.0158477;-5.8803387;-4.495321;IRRE
now we rearrange the data based on the row and column labels assigned by the;5.001427;0.43997127;3.224147;-5.262508;2.056103;0.4540634;CODE
class sklearn cluster spectralbiclustering model in ascending order and;4.54013;-4.860706;-3.6639724;-2.3300328;-0.4448864;2.2608776;IRRE
plot again the row labels range from 0 to 3 while the column labels;2.2628515;1.7264253;3.0844517;-7.447778;-3.9415581;-0.49858052;CODE
range from 0 to 2 representing a total of 4 clusters per row and 3 clusters;4.2136154;1.680584;1.749116;-6.3841414;0.6062603;-0.11486004;CODE
per column;4.6710863;0.37906286;5.076274;-5.3846;3.9327772;-3.12219;-
reordering first the rows and then the columns;1.1690601;1.3033935;4.255167;-4.813177;0.061226632;0.7692559;-
as a last step we want to demonstrate the relationships between the row;2.1094766;-0.016194781;4.941657;-3.315127;1.2813654;-1.865847;-
and column labels assigned by the model therefore we create a grid with;4.0077763;-1.8211249;2.7756443;-2.8470302;3.4944756;2.6495361;IRRE
func numpy outer which takes the sorted row labels and column labels;3.2397294;-1.0673361;-0.49982452;-5.931049;-2.6878386;0.09605654;-
and adds 1 to each to ensure that the labels start from 1 instead of 0 for;0.1853478;1.738252;2.4271367;-4.870374;2.9317863;-1.4787965;CODE
better visualization;2.122069;-4.3682427;8.609677;-2.7754717;-1.4368068;0.6265626;-
the outer product of the row and column label vectors shows a representation;2.0471363;-1.7854629;-0.4994121;-6.7146897;0.8075348;0.6470409;-
of the checkerboard structure where different combinations of row and column;0.7384862;1.9920586;2.7560785;-4.368146;3.8635986;-1.6460656;CODE
labels are represented by different shades of blue;0.09488052;-0.831459;2.3115706;-4.6697235;3.0079777;-0.013400063;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
shuffle clusters;4.485791;-1.4859788;3.3771694;-1.6202947;2.4726725;1.1437165;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate synthetic dataset;5.188225;-4.1678243;-0.58644694;-1.7688833;1.610775;-1.9116857;IRRE
generate 3 blobs with 2 classes where the second blob contains;1.3193249;0.23468952;0.14512178;-3.3536658;5.4049053;-1.1673977;IRRE
half positive samples and half negative samples probability in this;0.61271894;2.6871328;1.5005879;-1.2468923;0.27593374;-3.2248309;CODE
blob is therefore 0 5;-2.2900593;1.3132771;-0.12993531;-2.9799702;-1.2941475;-2.3089888;CODE
split train test for calibration;5.192808;1.6061399;-0.8968462;2.872564;0.36480907;-1.447553;CODE
gaussian naive bayes;4.1073074;-2.5453148;0.50971586;0.7282813;2.04031;-0.5718207;-
with no calibration;1.9104623;-0.17811172;3.0468242;0.098361135;-3.0209923;0.0925263;-
clf fit x train y train gaussiannb itself does not support sample weights;2.7939851;-0.36936995;-5.5183563;-0.9066048;-1.6139138;2.856513;CODE
with isotonic calibration;3.488572;0.14198585;0.98262745;-0.9264646;-1.5350107;3.0684395;CODE
with sigmoid calibration;4.6039524;-1.8153653;0.20938879;-2.5356493;-2.75818;2.763708;-
plot data and the predicted probabilities;4.3386292;-2.6364298;4.9048777;-0.4930413;-4.803787;-0.42589146;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
we will use a synthetic binary classification dataset with 100 000 samples;4.6243935;-5.4988036;0.6814154;1.1912748;3.8363366;-2.808268;IRRE
and 20 features of the 20 features only 2 are informative 10 are;1.0373126;-4.209802;0.97674936;0.014684892;3.4467041;-0.52590775;TASK
redundant random combinations of the informative features and the;4.3004713;-4.3910995;1.3213215;1.7977712;5.8079724;1.6295428;IRRE
remaining 8 are uninformative random numbers of the 100 000 samples 1 000;2.3777463;1.3035575;-0.83302337;-0.3758601;0.84076065;-3.6348586;CODE
will be used for model fitting and the rest for testing;2.5622046;-2.001876;1.7104982;3.1570425;0.026579518;-0.53609395;CODE
calibration curves;3.4506762;-1.2381366;1.6253392;-1.3435751;-4.535894;0.76160145;-
gaussian naive bayes;4.1073074;-2.5453148;0.50971586;0.7282813;2.04031;-0.5718207;-
first we will compare;0.1967063;0.91069597;3.1069462;3.669475;-0.051456448;-2.2950592;IRRE
class sklearn linear model logisticregression used as baseline;3.1299603;-3.7788699;-5.1574535;0.74965173;-1.494137;1.5692627;IRRE
since very often properly regularized logistic regression is well;4.370141;-2.6576;-0.9885367;3.8125687;-0.1631557;1.8947245;-
calibrated by default thanks to the use of the log loss;1.2372959;-0.26880172;-2.0611665;2.3938165;-4.770141;1.4402589;CODE
uncalibrated class sklearn naive bayes gaussiannb;4.480571;-3.970489;-6.464896;-0.29832405;-1.9797987;0.28737062;IRRE
class sklearn naive bayes gaussiannb with isotonic and sigmoid;4.5246363;-4.597841;-4.956643;-1.070004;0.24879083;1.4384605;CODE
calibration see ref user guide calibration;-0.20514391;-0.7126562;0.5363346;-0.045617264;-3.3589451;0.4176821;-
calibration curves for all 4 conditions are plotted below with the average;3.6530888;2.3454292;1.0102497;-1.8694288;-4.8023114;1.4563375;CODE
predicted probability for each bin on the x axis and the fraction of positive;3.2056086;0.12180767;2.3329725;-2.8458345;-2.4000719;-0.67674696;CODE
classes in each bin on the y axis;2.9868119;-1.3534522;2.1051123;-5.630403;1.3480866;-1.2218341;IRRE
add histogram;1.6775672;-1.8843946;5.781847;-4.4352393;0.355162;-1.4835509;TASK
uncalibrated class sklearn naive bayes gaussiannb is poorly calibrated;3.9342597;-3.1090744;-7.6014633;-0.20726866;-3.52055;0.73784184;IRRE
because of;-3.2468023;-0.84187305;3.14344;2.664467;-1.282754;-0.38173398;-
the redundant features which violate the assumption of feature independence;1.2436026;-2.339646;-0.84995985;2.2572503;4.1807323;3.0308108;TASK
and result in an overly confident classifier which is indicated by the;4.136357;-0.567004;-1.4170407;4.7777553;3.641598;-3.1491442;IRRE
typical transposed sigmoid curve calibration of the probabilities of;4.9173746;-2.2488654;-0.4436952;-0.5615919;-2.8134537;2.334874;-
class sklearn naive bayes gaussiannb with ref isotonic can fix;4.2374783;-2.9000738;-6.549924;0.3566306;-0.7899745;1.5633019;IRRE
this issue as can be seen from the nearly diagonal calibration curve;2.2587848;0.9892143;-3.6751173;-1.3569613;-7.1519003;3.4530592;CODE
ref sigmoid regression sigmoid regressor also improves calibration;4.287161;-2.2117493;-1.7491271;1.4666014;-3.2111638;3.8766437;-
slightly;-1.0121219;-2.6204414;4.2505317;0.03743877;-1.6277874;-1.4109654;-
albeit not as strongly as the non parametric isotonic regression this can be;4.2298183;0.2531804;0.44432235;1.3445436;-1.7954209;3.2820246;CODE
attributed to the fact that we have plenty of calibration data such that the;4.3229427;-3.823851;-0.4386309;3.4412837;-3.4174569;1.0205668;META
greater flexibility of the non parametric model can be exploited;2.1614184;-0.69212335;1.6464115;3.4823291;-0.3408136;4.1324244;-
below we will make a quantitative analysis considering several classification;5.1777973;-5.0150695;2.67675;2.7474706;5.682886;-1.2479144;IRRE
metrics ref brier score loss ref log loss;1.6333741;-0.6130971;-0.22889863;2.1731865;0.11530957;0.65297663;-
ref precision recall f1 score precision recall f measure metrics and;3.0318766;-2.2801259;-1.645649;3.740703;1.4653077;-1.1367108;IRRE
ref roc auc roc metrics;3.1043215;-3.7920673;-2.097193;0.65104485;1.057925;-0.5020972;-
notice that although calibration improves the ref brier score loss a;0.50600535;1.7813888;-1.0970737;4.032392;-1.9942698;0.5215232;-
metric composed;1.6565592;-0.8546122;1.7794601;-2.4290066;2.2943385;0.58774215;-
of calibration term and refinement term and ref log loss it does not;0.8960144;0.34091374;-3.3516634;2.8147514;-1.9345651;1.8692776;CODE
significantly alter the prediction accuracy measures precision recall and;4.201123;-3.120732;-0.76873606;6.746135;0.16422218;-0.44582736;IRRE
f1 score;1.9064919;0.7501399;0.5973831;1.3528706;0.49899223;-3.8357584;-
this is because calibration should not significantly change prediction;2.868628;-0.8227555;-3.4621637;4.1874485;-5.1170144;3.0067968;CODE
probabilities at the location of the decision threshold at x 0 5 on the;1.8102393;0.03434978;2.0701306;0.4092635;1.0720261;-0.57266617;-
graph calibration should however make the predicted probabilities more;4.5744452;-1.0455066;0.43859386;1.5883677;-2.611839;2.9020653;-
accurate and thus more useful for making allocation decisions under;3.5867565;-1.6660604;2.7105324;4.8259864;3.6245568;0.11328019;CODE
uncertainty;1.7247463;1.1764872;5.3808756;2.9461384;-0.6208561;-2.744142;META
further roc auc should not change at all because calibration is a;1.1871653;-0.9753614;-3.2808282;2.0942106;-0.90922016;1.5891204;-
monotonic transformation indeed no rank metrics are affected by;1.7161111;0.6118583;-1.9329461;-1.9188348;-1.8128266;4.8321705;CODE
calibration;3.24815;-0.25177023;2.0327723;-0.32912996;-3.014977;-0.75133216;-
linear support vector classifier;5.956812;-4.884791;-1.7747312;-2.1077204;3.0939672;1.0450405;IRRE
next we will compare;-0.14643767;1.1568003;3.1288931;4.1001744;-0.3428534;-2.9537783;IRRE
class sklearn linear model logisticregression baseline;3.5179725;-4.7696776;-5.1876216;0.5164744;-1.3777945;1.0249369;IRRE
uncalibrated class sklearn svm linearsvc since svc does not output;2.6625922;-2.2165399;-6.997659;-2.7326992;-5.085249;2.2759387;IRRE
probabilities by default we naively scale the output of the;4.3900046;-1.862942;2.407055;1.3413523;-0.6259658;1.5487844;CODE
term decision function into 0 1 by applying min max scaling;4.3097053;0.9796486;-1.5393858;-2.5782351;-0.22597533;4.371934;CODE
class sklearn svm linearsvc with isotonic and sigmoid;4.614827;-4.2293415;-4.986252;-3.7948418;-0.99460477;3.8502665;CODE
calibration see ref user guide calibration;-0.20514391;-0.7126562;0.5363346;-0.045617264;-3.3589451;0.4176821;-
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
below we generate a classification dataset with 2000 samples 2 features;5.839158;-4.3107862;0.6227015;-1.2417777;4.1812105;-2.6021883;IRRE
and 3 target classes we then split the data as follows;5.803369;-2.0974123;1.8205651;-0.5192267;6.6856046;0.4870159;IRRE
train 600 samples for training the classifier;5.135783;-4.030637;0.9466174;1.9858809;3.1721146;-2.327704;CODE
valid 400 samples for calibrating predicted probabilities;6.154475;-0.9341264;-2.9210517;3.4566214;0.2607521;-2.380875;CODE
test 1000 samples;4.3378596;3.4577725;1.619625;2.9397697;0.7033851;-6.632048;IRRE
note that we also create x train valid and y train valid which consists;0.15803736;1.3423266;-0.8655971;0.57606775;4.8596063;-1.3797089;OUTD
of both the train and valid subsets this is used when we only want to train;1.7722166;-0.7577271;0.3754953;3.7578444;5.5750594;0.15260628;IRRE
the classifier but not calibrate the predicted probabilities;3.3666146;-2.449717;-3.3938925;3.124651;-0.74919194;-0.3240244;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
fitting and calibration;4.134767;-0.29132774;1.9275547;-1.3372093;-2.8003485;1.2622882;-
first we will train a class sklearn ensemble randomforestclassifier;4.0041485;-7.8454056;-2.0756176;3.7487817;2.5279102;-1.5366923;IRRE
with 25 base estimators trees on the concatenated train and validation;4.5076284;-1.0161816;-0.7451453;1.9511694;4.588981;-0.5056265;-
data 1000 samples this is the uncalibrated classifier;5.8038034;-2.1743236;-0.71056736;-1.3384618;0.3839747;-1.4422857;CODE
to train the calibrated classifier we start with the same;4.0078216;-4.9690943;-0.22158402;3.028808;2.4967804;0.13669251;CODE
class sklearn ensemble randomforestclassifier but train it using only;2.9130244;-4.510369;-4.3227267;3.3729482;2.1822288;0.31176493;IRRE
the train data subset 600 samples then calibrate with method sigmoid;6.15411;-0.4133053;-1.4470038;0.325189;-0.3914154;0.08116047;IRRE
using the valid data subset 400 samples in a 2 stage process;5.1559224;3.3005488;-1.1444855;3.7335978;3.2832441;-0.3627405;IRRE
compare probabilities;2.6870925;1.8891946;3.4837744;2.3513489;1.4913324;-4.882903;IRRE
below we plot a 2 simplex with arrows showing the change in predicted;1.900178;-0.5910912;4.4063377;-3.2685041;-4.8295984;1.4778639;-
probabilities of the test samples;3.0866206;2.1581085;0.5464381;3.864134;1.9171774;-5.4077497;IRRE
plot arrows;0.12308337;-1.9702082;7.2061005;-4.882893;-5.000889;0.5990035;-
plot perfect predictions at each vertex;4.936189;-1.0402235;2.506475;-1.2878805;-4.4536424;0.44795483;-
plot boundaries of unit simplex;0.793599;1.1212132;4.38134;-7.0810876;-4.2996645;2.8783636;-
annotate points 6 points around the simplex and mid point inside simplex;1.7676133;-0.018560609;1.2888335;-4.8556385;0.13843335;1.956889;CODE
add grid;-1.2322522;-0.29162738;6.0407677;-4.3461027;-0.2692699;1.6592838;TASK
in the figure above each vertex of the simplex represents;-0.8129148;-1.1863687;3.2920377;-7.0603094;-1.0390792;2.243617;CODE
a perfectly predicted class e g 1 0 0 the mid point;3.136131;1.187072;-0.83337396;-0.22497642;0.0977082;-0.8540487;CODE
inside the simplex represents predicting the three classes with equal;3.5947554;-0.84556717;-0.56066895;-3.579966;2.5236778;-0.8572233;IRRE
probability i e 1 3 1 3 1 3 each arrow starts at the;-2.1313887;-0.2975959;5.025709;-2.268001;1.1061867;-1.5921654;CODE
uncalibrated probabilities and end with the arrow head at the calibrated;1.1989543;-0.57407176;2.011504;0.23885974;-2.6122456;1.2662619;CODE
probability the color of the arrow represents the true class of that test;0.40668657;1.2824754;1.3689302;1.7705051;1.7773073;-4.6682997;IRRE
sample;1.7340889;-0.29218516;6.123778;1.5984565;2.6697383;-5.329025;-
the uncalibrated classifier is overly confident in its predictions and;3.6668713;-2.0232532;-3.2660449;4.626158;-2.9023607;0.5933477;IRRE
incurs a large ref log loss log loss the calibrated classifier incurs;2.5734255;-1.7317587;-3.6789834;3.2915866;-0.4062936;0.54577297;IRRE
a lower ref log loss log loss due to two factors first notice in the;-1.0964522;1.6024132;-0.58505493;2.7947197;-1.038816;1.1861312;CODE
figure above that the arrows generally point away from the edges of the;-1.7021365;-1.6731285;5.2283077;-2.0615249;-3.037873;2.6177883;CODE
simplex where the probability of one class is 0 second a large proportion;2.726681;0.07443998;1.0927823;-2.225997;2.002664;0.6635741;IRRE
of the arrows point towards the true class e g green arrows samples where;1.5333701;-2.7065048;0.930985;-0.32259446;2.6440969;0.7192186;CODE
the true class is green generally point towards the green vertex this;-1.0425091;-0.57669127;-0.23189858;-0.1865477;1.166796;0.60064894;CODE
results in fewer over confident 0 predicted probabilities and at the same;3.6424153;1.334873;-1.9831113;5.2497363;-1.4641706;-2.0405161;IRRE
time an increase in the predicted probabilities of the correct class;3.7143478;-2.1780508;1.9392605;4.874805;1.4625524;-0.63175774;CODE
thus the calibrated classifier produces more accurate predicted probabilities;4.035467;-3.6058612;-2.5520508;3.6772563;-0.1371601;0.41449255;IRRE
that incur a lower ref log loss log loss;-0.2144748;1.03682;-0.25905085;2.7606833;-0.7963938;1.1060926;-
we can show this objectively by comparing the ref log loss log loss of;3.0850759;1.5086411;-0.48535612;3.665596;0.47962257;1.0531241;CODE
the uncalibrated and calibrated classifiers on the predictions of the 1000;5.476132;-5.447612;-1.0594716;2.2235436;0.314576;-1.2624692;IRRE
test samples note that an alternative would have been to increase the number;2.050442;4.285979;-0.5855529;3.28443;0.6936229;-5.364795;IRRE
of base estimators trees of the;3.1345117;-3.083163;0.77989954;2.0501297;1.8335594;1.3047291;-
class sklearn ensemble randomforestclassifier which would have resulted;2.5890143;-4.8908563;-4.6841125;3.6844358;0.68479246;-1.9370881;IRRE
in a similar decrease in ref log loss log loss;0.93156874;1.7340729;0.041010134;2.0382638;-1.7393341;1.5188075;-
we can also assess calibration with the brier score for probabilistics predictions;4.46054;-3.4391105;-0.9793765;5.3728194;0.79486877;-0.20262721;CODE
lower is better possible range is 0 2;1.000424;3.7445571;1.3935397;-1.3545283;-1.2742431;-1.3939115;-
according to the brier score the calibrated classifier is not better than;2.772981;-2.2112267;-2.5917804;2.8092957;0.79965204;-1.0886818;IRRE
the original model;-1.3411385;-3.0627577;3.967309;2.0433235;0.75819784;-0.3837735;-
finally we generate a grid of possible uncalibrated probabilities over;5.321626;-1.9687731;2.0229762;-1.0295739;0.80610585;0.64344865;CODE
the 2 simplex compute the corresponding calibrated probabilities and;2.813319;-1.1629562;-0.36259058;-2.4679732;-0.4029539;0.4153026;-
plot arrows for each the arrows are colored according the highest;1.6545103;-0.8285304;5.045211;-4.3849163;-3.0897882;-0.1282034;CODE
uncalibrated probability this illustrates the learned calibration map;4.2230124;-3.4794247;1.3829767;0.9133897;-1.9788966;1.1296254;IRRE
generate grid of probability values;4.599409;0.18994348;3.510153;-4.6637416;0.57769865;-0.5467307;IRRE
use the three class wise calibrators to compute calibrated probabilities;2.8355446;-1.8619953;-2.2984383;0.051102106;1.3076601;-0.26396278;IRRE
re normalize the calibrated predictions to make sure they stay inside the;4.310333;0.622507;0.8028959;2.7807074;-2.9599793;1.7859731;-
simplex this same renormalization step is performed internally by the;-1.811419;-0.09296346;-0.3263941;-1.063532;-1.4877316;4.791494;CODE
predict method of calibratedclassifiercv on multiclass problems;5.448127;-3.373595;-4.5910916;1.3018848;0.25513193;0.70274615;CODE
plot changes in predicted probabilities induced by the calibrators;3.2320025;-2.253126;1.088614;1.9725782;-6.1354966;1.6852747;-
plot the boundaries of the unit simplex;0.52750623;0.65549356;5.26694;-6.861865;-4.0663986;1.7679615;-
one can observe that on average the calibrator is pushing highly confident;2.7147143;-1.1139655;1.1999415;5.8328986;-5.5037737;0.38033944;-
predictions away from the boundaries of the simplex while simultaneously;4.985673;-0.49476215;1.6596677;0.76908386;-0.5479265;2.479329;CODE
moving uncertain predictions towards one of three modes one for each class;3.9377928;-0.54042923;1.0413269;3.4665098;3.1610296;2.8083155;CODE
we can also observe that the mapping is not symmetric furthermore some;0.0011659245;1.7004793;-0.75621;-1.2856737;0.37711513;3.4255874;-
arrows seem to cross class assignment boundaries which is not necessarily;-0.6504456;-0.6967527;-0.62642217;-0.67385525;1.6341438;0.93863803;IRRE
what one would expect from a calibration map as it means that some predicted;3.3184075;-2.244189;0.74337894;2.618228;-3.07782;0.98125327;CODE
classes will change after calibration;-0.09841213;-0.5447067;-2.4644587;2.252221;-0.84371346;1.4995583;IRRE
all in all the one vs rest multiclass calibration strategy implemented in;2.7785883;-2.5472233;-1.0980899;3.7678986;1.0627531;2.1924846;TASK
calibratedclassifiercv should not be trusted blindly;2.2788312;-1.5693245;-6.7418814;2.8332753;-3.5724418;0.41657388;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
we will use a synthetic binary classification dataset with 100 000 samples;4.6243935;-5.4988036;0.6814154;1.1912748;3.8363366;-2.808268;IRRE
and 20 features of the 20 features only 2 are informative 2 are;0.79273164;-4.230147;1.2501636;0.13369045;3.6821578;-0.33628267;TASK
redundant random combinations of the informative features and the;4.3004713;-4.3910995;1.3213215;1.7977712;5.8079724;1.6295428;IRRE
remaining 16 are uninformative random numbers;-0.31407958;1.8262914;0.4668262;-1.4829348;0.5502264;-3.7569208;CODE
of the 100 000 samples 100 will be used for model fitting and the remaining;4.4871225;-0.22301586;1.3282117;1.0354238;1.1365259;-0.5047629;CODE
for testing note that this split is quite unusual the goal is to obtain;-0.65621114;0.15316112;0.85641843;1.083557;2.5448258;-1.44514;CODE
stable calibration curve estimates for models that are potentially prone to;3.6151154;-2.006923;-1.0171477;5.3784347;-3.9899747;2.6651645;CODE
overfitting in practice one should rather use cross validation with more;2.5977662;-0.015346517;0.84371;4.375003;1.3443948;0.6209514;-
balanced splits but this would make the code of this example more complicated;2.555331;1.9548011;2.8083231;-1.2312937;3.7442448;-0.55495334;CODE
to follow;-2.1717365;-1.9475901;6.704328;3.448729;-0.5090555;-0.49173927;-
train samples 100 samples used for training the models;4.9104414;-3.3501527;1.7836605;3.2465916;2.1835797;-2.027295;CODE
calibration curves;3.4506762;-1.2381366;1.6253392;-1.3435751;-4.535894;0.76160145;-
below we train each of the four models with the small training dataset then;4.4194074;-5.516068;0.9915301;2.8695714;2.8049755;0.9436875;IRRE
plot calibration curves also known as reliability diagrams using;2.1839416;-2.3458614;1.9982499;-0.26515758;-2.4035375;-0.41081256;-
predicted probabilities of the test dataset calibration curves are created;5.4783444;-2.4885442;-1.8724228;3.7004817;-3.0360487;-2.0607424;IRRE
by binning predicted probabilities then plotting the mean predicted;2.795355;-1.8789339;2.3749456;-1.0715445;-3.9839456;-0.3898066;-
probability in each bin against the observed frequency fraction of;2.83855;1.322446;1.9852374;-1.3664424;0.11734641;-1.41216;-
positives below the calibration curve we plot a histogram showing;2.4930947;0.6317573;1.6234914;-2.464384;-4.956063;-0.43432727;-
the distribution of the predicted probabilities or more specifically;2.566612;-3.9461432;2.9595258;4.707758;-0.12408766;0.80014575;IRRE
the number of samples in each predicted probability bin;4.813054;-2.012947;0.43111408;2.0323102;1.0249562;-2.4226332;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
data 2d projection of the iris dataset;4.238533;-2.5176783;1.1832678;-5.2076144;-1.1934314;0.9085766;IRRE
x iris data 0 2 we only take the first two features for visualization;1.9229841;-1.9820184;0.12470048;-5.3766885;-0.47865656;1.3450328;TASK
probabilistic classifiers;5.2337947;-6.3007035;0.9501421;2.341148;5.4281206;-0.69876456;IRRE
we will plot the decision boundaries of several classifiers that have a;5.112336;-4.7881017;2.410347;1.7006239;4.2203693;-0.9078238;IRRE
predict proba method this will allow us to visualize the uncertainty of;5.2341805;-1.4106888;4.941555;2.5642953;-1.2304738;-1.0438732;CODE
the classifier in regions where it is not certain of its prediction;5.0862527;-2.0460298;-0.35149845;3.8211975;2.8804986;0.14853467;IRRE
plotting the decision boundaries;3.254684;-1.5874377;6.8018107;-2.751726;-0.8125479;-0.2012979;-
for each classifier we plot the per class probabilities on the first three;3.732127;-4.754008;2.4868145;-2.0183513;3.2120647;-0.69911057;CODE
columns and the probabilities of the most likely class on the last column;4.3763695;-1.3702579;0.8532925;-1.3502823;3.6187837;-1.9696263;IRRE
ensure legend not cut off;-2.912931;3.699941;1.8678341;1.596995;-2.182677;3.1617951;CODE
plot the probability estimate provided by the classifier;4.596509;-4.1004467;1.457148;-0.18176277;-0.7559204;1.2083318;IRRE
plot data predicted to belong to given class;5.0779834;-0.6253806;2.634402;-0.52331936;-1.4346151;-1.0364946;IRRE
add column that shows all classes by plotting class with max predict proba;4.61045;-1.6746249;1.0612785;-1.8725523;0.013412197;-0.048338436;IRRE
colorbar for single class plots;0.21916944;-2.4217846;2.521012;-2.53897;-0.40711087;2.2519145;IRRE
colorbars for max probability class column;2.1165144;-1.6372776;1.7587123;-2.4728508;2.4966688;1.3489735;IRRE
quantitative evaluation;4.372219;-0.50995016;4.7706122;4.1595025;2.0155306;-4.7226295;-
analysis;2.6429105;-0.54275125;6.312203;2.213518;1.0319147;-3.6721046;-
the two logistic regression models fitted on the original features display;1.8662742;-3.3263872;0.63037044;1.5120468;0.06156345;0.7784682;TASK
linear decision boundaries as expected for this particular problem this;4.424086;2.8320286;1.1547173;-0.99700373;2.5390656;1.4564506;CODE
does not seem to be detrimental as both models are competitive with the;0.018620012;-1.6615266;0.0650919;6.1269584;0.70557153;3.167589;CODE
non linear models when quantitatively evaluated on the test set we can;5.2676;0.74321246;-0.23928532;6.759161;-0.5666034;-1.5493106;IRRE
observe that the amount of regularization influences the model confidence;5.589905;-0.564168;-0.6191865;6.039868;-0.3771691;3.8665893;-
lighter colors for the strongly regularized model with a lower value of c;3.4073665;-0.8491838;-1.1775767;0.05637837;0.5321499;2.156226;IRRE
regularization also impacts the orientation of decision boundary leading to;3.1528852;-2.4542563;0.34778148;2.040123;2.2361963;6.138045;-
slightly different roc auc;0.26917315;-2.809623;-1.0138508;-0.35601383;1.5487033;-0.8389765;-
the log loss on the other hand evaluates both sharpness and calibration and;1.728394;-0.40443006;-1.2755401;2.8360062;-2.7243142;1.753064;-
as a result strongly favors the weakly regularized logistic regression model;3.5960438;-2.3826625;-1.2128383;4.1048927;0.89972705;3.991313;IRRE
probably because the strongly regularized model is under confident this;3.4230168;-0.51519823;-4.778879;5.0024242;-1.3222858;4.9558873;IRRE
could be confirmed by looking at the calibration curve using;2.2020226;-0.16125256;-0.68399674;1.4720725;-4.194226;-0.040315375;-
class sklearn calibration calibrationdisplay;2.6219652;-4.4015775;-5.149425;-0.85577655;-2.8740222;-0.6395969;IRRE
the logistic regression model with rbf features has a blobby decision;3.9059718;-4.1948066;-1.9419899;2.6208262;1.2736963;0.9851726;TASK
boundary that is non linear in the original feature space and is quite;1.129186;-1.2813228;1.3649703;-1.7424585;-0.7380088;4.260246;TASK
similar to the decision boundary of the gaussian process classifier which is;4.5700436;-4.1882977;1.5904388;1.6648496;3.557709;3.0007339;IRRE
configured to use an rbf kernel;-1.4100806;-3.9423826;-2.6885784;-0.9155831;-0.28185603;1.6595175;-
the logistic regression model fitted on binned features with interactions has;2.8362863;-3.4568698;0.69369876;0.6592459;1.5291429;-0.2760846;CODE
a decision boundary that is non linear in the original feature space and is;2.6102374;-1.7456937;0.13339277;0.954898;3.2990162;3.6268818;TASK
quite similar to the decision boundary of the gradient boosting classifier;4.904191;-5.9836926;0.9701872;1.0552294;4.02727;2.6635647;IRRE
both models favor axis aligned decisions when extrapolating to unseen region;4.74809;0.4299012;1.2898366;0.09187591;-2.314696;5.855683;-
of the feature space;2.18063;-5.1704006;3.4921515;-0.63660264;2.5852735;1.7891191;TASK
the logistic regression model fitted on spline features with interactions;3.3997924;-3.8754876;1.2523729;0.20588589;-0.4474466;0.63560414;CODE
has a similar axis aligned extrapolation behavior but a smoother decision;5.3777957;0.7882444;0.37470675;-1.9112319;-3.0122745;5.9321904;META
boundary in the dense region of the feature space than the two previous;-0.10512466;0.2238911;0.63852006;-1.3638455;-0.015149082;3.8486075;TASK
models;3.9722378;-4.8214254;5.0833;3.611487;2.8015873;-0.60680825;-
to conclude it is interesting to observe that feature engineering for;0.8954696;-7.9504128;0.862024;5.075103;1.8134215;1.5167551;CODE
logistic regression models can be used to mimic some of the inductive bias of;3.5157616;-4.1068716;0.97327214;5.5090203;1.6750964;0.22087742;OUTD
various non linear models however for this particular dataset using the;4.664984;-3.635251;1.1693178;1.9152713;-0.74191135;0.4199658;CODE
raw features is enough to train a competitive model this would not;3.0267277;-4.885446;0.20566377;5.173262;3.639014;1.5908917;TASK
necessarily the case for other datasets;5.299054;-2.9419465;0.8335512;2.3317122;3.6178048;0.081810765;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
iterate over datasets;6.4263773;-1.802763;1.7486569;-0.48532277;1.8628672;-2.1361396;IRRE
preprocess dataset split into training and test part;5.158834;-1.030217;-1.0156866;3.3109534;2.641477;-1.6653877;IRRE
just plot the dataset first;4.6126723;-1.8153832;5.1297517;-3.8354614;-2.9007008;0.21076585;IRRE
cm bright listedcolormap ff0000 0000ff;-3.4484696;-1.4411412;-0.33886743;-2.8114066;-0.35755786;0.74768466;-
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
plot the testing points;3.3787305;2.6716526;4.8303285;-1.3848403;-5.620406;-4.3919396;IRRE
iterate over classifiers;5.9412785;-3.1765063;0.2761596;0.36291677;4.695798;-2.4316916;IRRE
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
plot the testing points;3.3787305;2.6716526;4.8303285;-1.3848403;-5.620406;-4.3919396;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
standard scientific python imports;-0.747768;-6.5026984;-2.853305;-1.463533;-2.846401;-2.6265972;CODE
import datasets classifiers and performance metrics;5.9398413;-6.844338;-3.0860803;2.6194992;1.7301787;-0.18695627;CODE
digits dataset;4.9714155;-2.9362168;1.8861427;-4.667538;1.2799039;-3.952466;IRRE
the digits dataset consists of 8x8;4.8526235;-1.3396488;1.1199898;-6.6161656;1.0146233;-2.4766498;IRRE
pixel images of digits the images attribute of the dataset stores;3.5217216;-1.75453;0.93328774;-4.5313573;0.40535966;1.4495734;IRRE
8x8 arrays of grayscale values for each image we will use these arrays to;4.2337923;-0.33243585;3.4728556;-5.7896094;-0.47858667;0.857519;IRRE
visualize the first 4 images the target attribute of the dataset stores;3.8547027;-1.5782144;4.3045483;-3.6340058;0.72895634;3.22421;IRRE
the digit each image represents and this is included in the title of the 4;-2.5236938;-1.5512743;3.965106;-4.692717;3.2190936;-1.4289722;CODE
plots below;-0.07501;-0.98230344;8.544148;-5.547361;-4.741804;-0.9128834;-
note if we were working from image files e g png files we would load;-3.0597637;-3.4542413;3.154566;-1.7412318;-1.949334;3.0725436;CODE
them using func matplotlib pyplot imread;2.1332;-4.5938234;1.417386;-5.7171917;-6.9359846;-1.1652511;CODE
classification;5.668271;-5.8220553;4.2595444;1.7214531;6.909542;-2.19592;IRRE
to apply a classifier on this data we need to flatten the images turning;5.323151;-2.345865;1.6108886;-2.095373;0.50146985;1.9314592;CODE
each 2 d array of grayscale values from shape 8 8 into shape;5.691518;-0.093091756;2.5788198;-6.3324895;-1.7815726;1.7081456;IRRE
64 subsequently the entire dataset will be of shape;4.234286;-1.4421196;0.19302619;-4.13637;-0.3614836;-1.0006505;IRRE
n samples n features where n samples is the number of images and;3.7362912;-2.3158605;2.43072;-2.8668296;3.0092804;-0.90834713;TASK
n features is the total number of pixels in each image;2.1449904;-1.8436366;1.6854345;-5.615519;1.672226;0.24079937;TASK
we can then split the data into train and test subsets and fit a support;7.7603397;-1.2877569;1.0662892;3.0136566;4.1287937;-0.46354976;IRRE
vector classifier on the train samples the fitted classifier can;4.6706753;-2.8141828;-1.4146968;-0.117061436;2.4062088;0.72157407;IRRE
subsequently be used to predict the value of the digit for the samples;6.4610963;-0.39781418;2.5236695;1.9111106;1.990157;-4.2992826;IRRE
in the test subset;1.9604557;4.1754236;0.9971119;3.1065114;3.1091645;-5.7441635;IRRE
flatten the images;2.279508;-0.053518463;4.9457855;-4.295218;-2.3023322;4.0616913;-
create a classifier a support vector classifier;3.740607;-5.158089;-1.1258487;-0.7856627;4.049637;0.6213188;IRRE
split data into 50 train and 50 test subsets;6.140279;1.8025403;1.4934797;1.1093343;2.5843947;-1.6530207;IRRE
learn the digits on the train subset;4.568266;-1.8899287;2.6492844;-1.7798322;2.5202062;-2.1828785;IRRE
predict the value of the digit on the test subset;5.8108873;3.9612648;0.768117;1.37181;1.742599;-6.839873;IRRE
below we visualize the first 4 test samples and show their predicted;4.8675346;-0.2226987;2.9834998;1.1937982;-0.6581822;-3.8526955;IRRE
digit value in the title;-2.613691;0.75923586;2.742863;-3.2365048;3.0807626;-5.090927;IRRE
func sklearn metrics classification report builds a text report showing;2.7947361;-7.627177;-3.300556;1.6228808;-1.0575526;-1.7018411;IRRE
the main classification metrics;5.411867;-7.071462;0.9174885;2.226296;4.4869804;0.36536345;CODE
we can also plot a ref confusion matrix confusion matrix of the;2.4900568;-1.4229953;2.9040062;-2.3425322;-1.1128688;-1.5349162;-
true digit values and the predicted digit values;4.0628986;1.8342253;0.35931396;-0.77962625;-0.16935417;-5.147811;IRRE
if the results from evaluating a classifier are stored in the form of a;4.519699;0.4712135;-1.5824462;4.366813;5.087586;-2.2325616;CODE
ref confusion matrix confusion matrix and not in terms of y true and;1.1373911;2.3770602;-1.0597742;-1.7169493;-0.2262961;-1.8861312;CODE
y pred one can still build a func sklearn metrics classification report;3.4585998;-7.665356;-3.4217079;2.4907079;-0.09052517;-0.8625213;CODE
as follows;-2.4409127;-0.8133941;5.8557587;-0.12441757;1.5460417;-2.185881;-
the ground truth and predicted lists;4.050412;-2.4271443;0.7563432;2.9470043;1.4792914;-1.8436896;-
for each cell in the confusion matrix add the corresponding ground truths;2.383629;-0.077826805;0.34799737;-1.7583528;1.6617808;-0.6324621;CODE
and predictions to the lists;5.1800394;-4.3791013;4.8592663;2.3589396;2.4344404;-2.8874822;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
n train 20 samples for training;4.2988434;-0.47286776;2.2599835;0.23314905;2.6759171;-3.0895057;CODE
n test 200 samples for testing;3.0893743;2.4658077;0.92644626;1.6591822;0.43337473;-6.1303544;IRRE
n averages 50 how often to repeat classification;4.669681;-1.6317427;1.7262164;2.0518737;3.7405539;-1.7276784;IRRE
n features max 75 maximum number of features;2.0564976;-1.7145423;0.5358366;-2.5842571;2.5049152;-1.5738032;TASK
tep 4 step size for the calculation;1.5381997;2.2963245;-0.09602491;-2.6269464;-0.5802994;-0.123900086;CODE
add non discriminative features;3.3465812;-3.0637639;-1.3356763;-1.9637343;3.681965;1.1760901;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
first we define a function to generate synthetic data it creates two blobs centered;4.5327845;-1.7661301;0.65340763;-5.1394644;-0.7377644;0.74895716;IRRE
at 0 0 and 1 1 each blob is assigned a specific class the dispersion of;2.3774989;0.6132554;-1.1906406;-5.5422254;1.9885678;-0.21250801;IRRE
the blob is controlled by the parameters cov class 1 and cov class 2 that are the;-1.8573062;-1.0846329;-1.2479318;-2.263614;0.1608153;2.4853787;IRRE
covariance matrices used when generating the samples from the gaussian distributions;3.1644692;-2.657067;-1.2524865;-1.9616174;-0.80895513;3.857763;CODE
we generate three datasets in the first dataset the two classes share the same;5.6145277;-1.8456144;-0.50010264;-1.246839;5.3736296;-0.15811567;IRRE
covariance matrix and this covariance matrix has the specificity of being spherical;0.45554057;-0.62162066;-1.2999942;-2.7237072;-1.0553571;5.4797254;CODE
isotropic the second dataset is similar to the first one but does not enforce the;4.042842;-0.44355533;-3.532375;-1.8274442;-0.1199696;3.938717;CODE
covariance to be spherical finally the third dataset has a non spherical covariance;2.1118145;-0.6496472;-2.0743537;-1.7961465;-1.8791082;3.335543;CODE
matrix for each class;3.9750998;-1.7866614;1.4148701;-4.530701;4.1554513;-0.70312864;CODE
plotting functions;0.586535;-0.868445;6.5360317;-5.0168424;-5.8386497;-1.3482183;CODE
the code below is used to plot several pieces of information from the estimators used;3.3992007;-1.8788366;3.4789832;-2.678113;-3.2135308;0.49495822;CODE
i e class sklearn discriminant analysis lineardiscriminantanalysis lda and;3.3267248;-4.296304;-5.3670897;-1.4850947;1.2118963;0.8819879;IRRE
class sklearn discriminant analysis quadraticdiscriminantanalysis qda the;3.0641387;-4.0981135;-5.07465;-2.4729433;-0.22933939;0.37893733;IRRE
displayed information includes;-2.2389247;-1.2453189;3.7233121;-1.3557785;4.238758;0.17832048;CODE
the decision boundary based on the probability estimate of the estimator;3.9486372;-0.7199878;1.9593496;4.2507687;2.7527442;3.8630805;CODE
a scatter plot with circles representing the well classified samples;5.9822626;-2.1051543;3.482659;-2.5242465;-0.7296836;-0.4465568;IRRE
a scatter plot with crosses representing the misclassified samples;6.295431;-1.1450051;0.73007315;-1.8172637;-1.0606159;-1.1781095;IRRE
the mean of each class estimated by the estimator marked with a star;3.6208215;-0.20827216;-0.4065692;1.6271592;1.9667387;0.53373706;IRRE
the estimated covariance represented by an ellipse at 2 standard deviations from the;2.0186584;-0.9096099;-0.3242303;-2.0622315;-4.291736;3.2545886;CODE
mean;-0.8584131;0.4457244;6.374265;0.8543819;-1.3125975;-2.3286166;-
angle 180 angle np pi convert to degrees;-1.1759182;0.2969468;0.5127809;-4.8984284;-3.7889893;-0.057857797;-
filled gaussian at 2 standard deviation;2.2752967;1.8611164;-0.79522264;-3.9780123;-1.674298;1.0959817;-
comparison of lda and qda;1.2598034;-3.1131449;-1.9569806;-0.45951706;1.8906806;1.4620911;-
we compare the two estimators lda and qda on all three datasets;3.083844;-3.4072845;-2.2599876;0.75480616;0.6860458;1.4915727;IRRE
the first important thing to notice is that lda and qda are equivalent for the;-0.7928255;-4.1309953;-2.459912;0.88362104;2.7671874;1.8436996;CODE
first and second datasets indeed the major difference is that lda assumes;2.645711;-3.597711;-1.9476069;1.1578792;3.9817295;2.0023794;IRRE
that the covariance matrix of each class is equal while qda estimates a;2.597605;-1.7399274;-3.2990873;-0.4989468;0.9771142;4.0818048;CODE
covariance matrix per class since in these cases the data generative process;4.1748924;-3.512458;-1.5984062;-0.4341493;2.7754872;4.8739734;CODE
has the same covariance matrix for both classes qda estimates two covariance;1.0157992;-1.0304227;-4.2468915;-1.2022965;-0.05356994;4.6126895;CODE
matrices that are almost equal and therefore equivalent to the covariance;1.8670564;0.64294136;-0.56905633;-1.2361931;-2.1053443;3.1219425;CODE
matrix estimated by lda;4.7863054;-0.51553637;-2.5836236;-2.6810966;0.51983243;4.2212987;-
in the first dataset the covariance matrix used to generate the dataset is;4.879413;-3.9878278;-0.80351967;-2.508294;-0.18934274;1.7000908;CODE
spherical which results in a discriminant boundary that aligns with the;-0.023084851;-0.20409511;2.0972264;-3.5300088;-0.063788004;2.383496;IRRE
perpendicular bisector between the two means this is no longer the case for;-2.4792912;1.8221741;1.0191091;-3.0153537;-1.8069987;1.3510789;CODE
the second dataset the discriminant boundary only passes through the middle;3.9570172;0.24326916;-0.8257703;-3.5724707;-0.96227896;2.329161;IRRE
of the two means;-0.559948;0.9171331;5.634883;1.9034109;0.33019754;-1.3648844;-
finally in the third dataset we observe the real difference between lda and;3.164149;-1.896508;-2.7029412;0.114210546;2.0679657;0.73218465;CODE
qda qda fits two covariance matrices and provides a non linear discriminant;2.284375;-1.6312666;-3.6011152;-3.1413846;-0.40766802;4.8524;CODE
boundary whereas lda underfits since it assumes that both classes share a;-0.11477348;0.90715986;-1.8170639;1.0623049;4.497151;3.8272667;IRRE
single covariance matrix;2.5267441;-0.81240976;0.057462387;-3.6349945;-1.4088054;3.177567;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
defining the list of metrics to evaluate;3.9342139;-0.08117666;0.68412405;0.706929;2.5966928;-1.6562753;CODE
clustering algorithms are fundamentally unsupervised learning methods;5.31205;-5.5886207;-0.6590497;1.1741186;1.4719311;3.3152332;CODE
however since we assign class labels for the synthetic clusters in this;2.617212;-3.3554041;-2.224745;-1.7898217;2.972368;2.7742085;CODE
example it is possible to use evaluation metrics that leverage this;4.604499;-2.1961563;2.7453303;4.5781646;4.2453294;1.3233832;CODE
supervised ground truth information to quantify the quality of the resulting;5.5747633;-1.0950574;-0.31825283;2.6512895;3.8245232;-1.0353894;CODE
clusters examples of such metrics are the following;3.3723118;-1.848772;1.9664676;-3.2232046;0.9580585;1.5679606;-
v measure the harmonic mean of completeness and homogeneity;2.2869685;0.9605299;0.21894835;1.7898058;-0.07997648;3.9481118;CODE
rand index which measures how frequently pairs of data points are grouped;6.958072;-1.5472972;2.710481;-3.1834931;1.7359804;-0.60672593;IRRE
consistently according to the result of the clustering algorithm and the;6.1599693;0.74363977;-0.011761284;2.493584;0.99681735;0.013449565;IRRE
ground truth class assignment;0.70464075;1.0794184;-1.7471219;0.9533251;4.5412216;-2.326933;IRRE
adjusted rand index ari a chance adjusted rand index such that a random;1.1031897;0.52894366;-0.21792585;0.7424897;0.042252626;0.8994478;IRRE
cluster assignment has an ari of 0 0 in expectation;1.0580821;2.0346756;-2.6862762;-1.631973;-1.8656695;1.4684682;IRRE
mutual information mi is an information theoretic measure that quantifies;1.6482962;-1.6621522;1.5725545;0.3754832;3.2241704;2.7580109;CODE
how dependent are the two labelings note that the maximum value of mi for;2.8571157;1.3231132;-0.32797074;-2.0642924;2.2067878;0.61371636;CODE
perfect labelings depends on the number of clusters and samples;5.6040797;0.6263253;-0.15810522;-0.2884898;2.551274;0.9630102;CODE
normalized mutual information nmi a mutual information defined between 0;1.6166689;1.0259695;-1.923699;-3.6019921;1.8102856;4.5169134;CODE
no mutual information in the limit of large number of data points and 1;4.148808;0.2043861;-0.27175832;-1.9646789;1.015353;2.6137424;CODE
perfectly matching label assignments up to a permutation of the labels;3.0231802;0.8356958;0.20814455;-1.4932007;5.5133123;-1.0799443;IRRE
it is not adjusted for chance then the number of clustered data points is;3.5301445;1.0169907;0.9877973;1.446324;-0.8301497;2.222085;CODE
not large enough the expected values of mi or nmi for random labelings can;4.446972;0.7390669;-2.9540107;-0.41538882;1.106089;-0.412649;IRRE
be significantly non zero;1.9393798;4.6632533;-0.2504812;-2.3716986;-2.6006517;-3.1471224;-
adjusted mutual information ami a chance adjusted mutual information;1.9474207;-0.2956526;1.6417632;0.97766143;2.8424256;3.3192897;CODE
similarly to ari random cluster assignment has an ami of 0 0 in;1.532408;-0.03337403;-3.4727457;-0.861508;0.40251043;0.8214481;IRRE
expectation;-1.397013;0.8027673;6.566291;1.5335264;-0.18506774;-1.6607372;-
for more information see the ref clustering evaluation module;5.0589576;-1.7740428;0.88071495;0.78163797;4.005807;0.23027037;CODE
first experiment fixed ground truth labels and growing number of clusters;4.5702934;-1.6089767;-0.010735466;-1.45397;0.3256111;0.660191;-
we first define a function that creates uniformly distributed random labeling;1.5291629;-2.280158;2.5639875;0.8062161;4.2827134;1.8147885;CODE
another function will use the random labels function to create a fixed set;2.5972245;0.70973176;2.642851;-0.7681364;3.1278403;-0.24735184;IRRE
of ground truth labels labels a distributed in n classes and then score;4.6462355;-0.49479762;-0.7947019;-0.8832124;5.7715807;-1.3376364;IRRE
several sets of randomly predicted labels labels b to assess the;7.163072;-1.2629662;1.9433283;2.3003445;4.770564;-1.4313899;IRRE
variability of a given metric at a given n clusters;5.2011375;-1.0884087;0.3511977;-1.7906009;-0.44322994;2.3292503;CODE
in this first example we set the number of classes true number of clusters to;1.996927;-0.87604636;-0.06258351;-1.1630238;3.480826;-0.65210474;CODE
n classes 10 the number of clusters varies over the values provided by;4.200324;-0.07433244;-0.15483491;-3.193706;2.778917;-2.0741236;IRRE
n clusters range;4.5384254;0.006790946;2.0143116;-4.3023725;-0.07168671;-0.78797674;-
the rand index saturates for n clusters n classes other non adjusted;5.1357656;-3.581599;-2.7088408;0.67842305;2.590942;1.2290199;IRRE
measures such as the v measure show a linear dependency between the number of;2.1274335;0.33565906;0.9323107;-0.84826225;2.296374;3.3671927;CODE
clusters and the number of samples;5.0471354;-1.1573155;2.6863427;-0.8823361;2.037782;-0.28687495;-
adjusted for chance measure such as ari and ami display some random;1.6334292;0.30995038;1.987162;1.8810316;-0.071148865;0.17630658;IRRE
variations centered around a mean score of 0 0 independently of the number of;4.089182;4.7927322;0.49523586;-1.6183333;-0.24145564;-0.123187415;CODE
samples and clusters;7.265936;-1.9858042;3.4709685;-1.1140343;2.6609685;-0.63486147;-
second experiment varying number of classes and clusters;5.994459;-0.9237661;-0.26200497;1.7947948;1.9697531;-0.5211888;CODE
in this section we define a similar function that uses several metrics to;2.0422916;-2.2408087;2.3155577;-0.510666;3.1605666;3.2393699;CODE
score 2 uniformly distributed random labelings in this case the number of;2.21112;0.78274596;1.9139102;-0.619221;3.5160992;-2.5726712;CODE
classes and assigned number of clusters are matched for each possible value in;4.7344575;0.96881616;-1.3447353;-1.8608238;5.2593546;-1.859054;IRRE
n clusters range;4.5384254;0.006790946;2.0143116;-4.3023725;-0.07168671;-0.78797674;-
in this case we use n samples 100 to show the effect of having a number of;3.7502854;1.3512495;3.5386624;0.9868245;2.3460035;-3.6464162;CODE
clusters similar or equal to the number of samples;5.866614;0.3158336;2.9665072;-1.5945132;2.5822206;-0.28270525;-
we observe similar results as for the first experiment adjusted for chance;2.8465912;-0.06422811;1.0976981;6.1907506;-1.9426272;-1.6982459;CODE
metrics stay constantly near zero while other metrics tend to get larger with;3.121994;1.6040212;-0.75735015;-0.5307977;-4.131745;2.8541718;CODE
finer grained labelings the mean v measure of random labeling increases;4.90411;-3.2854383;1.4038944;1.9083203;2.4314065;2.5821567;IRRE
significantly as the number of clusters is closer to the total number of;4.829296;-0.45230734;2.4366543;0.06465131;0.11728189;0.19420953;CODE
samples used to compute the measure furthermore raw mutual information is;3.675261;-1.7119572;0.59661645;-0.56117934;2.739642;1.7246265;OUTD
unbounded from above and its scale depends on the dimensions of the clustering;3.2523105;1.4297972;0.7709662;-2.0145855;-0.9535728;4.4569426;CODE
problem and the cardinality of the ground truth classes this is why the;-0.35911065;0.78873706;-0.75698245;0.38439584;5.213665;-1.427305;CODE
curve goes off the chart;0.9014082;1.6934124;3.5944765;-2.4882393;-7.1144366;1.1667408;CODE
only adjusted measures can hence be safely used as a consensus index to;3.368391;1.1212516;-0.4522347;4.535384;2.9709117;4.4813995;-
evaluate the average stability of clustering algorithms for a given value of k;5.227555;-0.74580145;0.09403887;-0.108237386;-1.4248252;1.2764581;IRRE
on various overlapping sub samples of the dataset;7.256051;-0.83900374;1.4703323;-0.296706;2.9719996;-0.09380494;IRRE
non adjusted clustering evaluation metric can therefore be misleading as they;3.3758862;0.17637436;-3.8709238;1.9946947;-0.3778524;2.2919893;META
output large values for fine grained labelings one could be lead to think;6.654972;-1.2048981;0.014180713;-2.7200682;1.0684364;-1.8882269;IRRE
that the labeling has captured meaningful groups while they can be totally;1.2771225;-2.229613;1.5419855;1.7798574;3.3939993;0.36258858;CODE
random in particular such non adjusted metrics should not be used to compare;4.7903757;2.227112;-2.223343;3.7382336;-0.8602329;0.008756384;IRRE
the results of different clustering algorithms that output a different number;5.0715265;-0.80294186;-0.16166374;-1.3956313;2.066899;-0.78025436;IRRE
of clusters;3.960005;-2.5741398;4.8343287;-1.6168556;1.6661825;-0.32502472;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
compute affinity propagation;4.7869396;-2.1461387;-1.6317068;-2.8895204;0.41510937;3.4031827;IRRE
plot result;0.5002942;1.6767008;6.9213877;-5.063152;-6.4714985;-5.124746;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate waveform data;3.8815875;-0.9797483;2.0798411;-3.610437;-0.4754227;0.86536837;CODE
make the noise sparse;5.5278397;-2.0488734;1.1937197;-0.37051117;-0.14375572;3.3748782;IRRE
colors f7bd01 377eb8 f781bf;-3.5729558;-0.87752944;0.38444167;-5.013058;1.5913527;-2.462989;-
plot the ground truth labelling;2.325068;-1.0178059;2.5002782;-2.1027794;-0.47800693;-1.4957596;-
plot the distances;1.7595968;-0.6859538;7.3776064;-4.7393756;-5.656543;-1.0569135;-
plot clustering results;5.620403;-1.1297321;4.520116;-4.4933224;-4.409454;-0.0994855;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
create linkage matrix and then plot the dendrogram;2.9276354;-0.8688116;2.154192;-7.6949306;-2.4876482;2.7485766;IRRE
create the counts of samples under each node;5.593676;1.0707067;2.7003996;-2.6317487;2.4271762;-1.6758751;IRRE
current count 1 leaf node;0.23832789;2.6592436;3.6681702;-1.4543065;1.5376921;-1.6056286;-
plot the corresponding dendrogram;2.5574641;-0.45442992;3.7307222;-6.431757;-3.243307;0.47961944;CODE
setting distance threshold 0 ensures we compute the full tree;1.6080081;0.93317074;-1.6941973;0.21769805;0.5189906;1.9622145;IRRE
plot the top three levels of the dendrogram;1.9527893;-0.8193726;3.4444063;-6.489976;-1.5975846;0.1581749;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate centers for the blobs so that it forms a 10 x 10 grid;2.2747948;-0.119563304;3.597879;-6.6236687;-1.5099573;2.6745558;CODE
generate blobs to do a comparison between minibatchkmeans and birch;3.2260036;-2.0669377;0.13636634;-2.187912;-0.22579181;-0.2570976;TASK
use all colors that matplotlib provides by default;0.2524066;-1.412282;-1.2417933;-2.7188644;-4.6566544;2.3116941;CODE
compute clustering with birch with and without the final clustering step;2.5665576;-1.2502732;-1.8528312;-1.5177127;0.8507521;2.7688866;CODE
and plot;-0.61320823;-3.703801;6.4947276;-0.5808211;-3.761921;-1.4851487;-
plot result;0.5002942;1.6767008;6.9213877;-5.063152;-6.4714985;-5.124746;IRRE
compute clustering with minibatchkmeans;4.507736;-2.2118838;-0.79352224;-2.6043568;-0.7512329;1.9422414;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate sample data;5.170891;0.29904175;3.2010825;-1.1294338;2.7187808;-3.5542898;-
number of cluster centers for kmeans and bisectingkmeans;0.93144476;-1.3051832;1.2358656;-1.8560454;-0.16558883;1.3995992;CODE
algorithms to compare;6.177679;1.0030766;2.4118142;1.8482289;2.5304792;-5.4990263;IRRE
make subplots for each variant;5.097194;0.8392103;3.5555944;-5.1527667;-0.19124025;1.8499365;CODE
hide x labels and tick labels for top plots and y ticks for right plots;0.70710945;0.46384028;3.8367488;-3.9546452;-3.0113919;2.744691;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate datasets we choose the size big enough to see the scalability;7.0811367;-3.625409;0.67324275;0.13967896;1.7820083;0.9430609;IRRE
of the algorithms but not too big to avoid too long running times;4.655318;-4.632442;1.6354789;1.2913086;2.136384;-0.72065127;CODE
anisotropicly distributed data;6.9551935;-2.2839932;2.4630506;-3.0412183;0.2983183;4.347278;META
blobs with varied variances;3.8186352;-0.4317471;0.27563405;-2.5170484;0.38171905;1.4287692;CODE
set up cluster parameters;3.3847644;0.19073291;0.36082888;-2.2413692;1.3011028;3.9089153;IRRE
update parameters with dataset specific values;3.1468997;0.9850683;0.34782284;-0.2961681;0.95705295;0.714005;IRRE
normalize dataset for easier parameter selection;7.3460593;-1.0507267;0.51646656;-1.470845;2.067373;3.005627;IRRE
estimate bandwidth for mean shift;2.6821678;0.078964055;2.4780087;-0.056113195;-2.7915006;4.7062926;CODE
connectivity matrix for structured ward;4.3594875;-0.8166279;1.6945821;-4.4510565;1.7826791;3.107524;CODE
make connectivity symmetric;1.4617385;0.13541389;2.764215;-2.698169;0.16922386;2.955851;-
create cluster objects;2.4218855;-2.281131;2.2876918;-2.6284337;3.3868458;2.1139908;IRRE
catch warnings related to kneighbors graph;0.6013545;0.47176245;-2.5933824;-0.14425945;-2.4591975;-1.7077988;CODE
377eb8;-3.2394416;-0.35568774;1.9878036;-2.0714815;0.5609804;-3.5213711;-
ff7f00;-1.5215341;-2.2895124;3.0201576;-1.4312793;-0.5860017;-2.3476663;-
4daf4a;-1.4644228;-0.644233;1.7856381;-2.769044;1.119668;-1.3804107;-
f781bf;-2.1950033;-2.0410755;2.017877;-2.3717115;-0.17644581;-3.1477761;-
a65628;-1.8964489;-1.3510839;2.6234062;-1.7362324;0.0005306646;-3.42169;-
984ea3;-3.365741;-1.0009432;2.727797;-2.7002509;1.1319957;-3.5809689;-
999999;-2.132415;-0.82536834;0.69733757;-2.2920732;0.24809021;-3.9114347;-
e41a1c;-3.0807307;-0.46966854;2.8015385;-2.9272473;1.1985788;-2.9281187;-
dede00;-2.860573;-0.8446782;2.350382;-1.4776582;1.717411;-2.8874047;-
add black color for outliers if any;2.5757897;1.0161879;0.5610835;-0.64130443;-0.57961166;-0.3188421;TASK
colors np append colors 000000;-3.4620836;-0.44311765;-0.37607446;-5.0674286;-1.9489374;-2.3412435;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the coins as a numpy array;1.7876582;0.19246535;-0.2179622;-6.414225;-4.9100018;-0.5555829;CODE
resize it to 20 of the original size to speed up the processing;0.10090781;0.41235065;3.895189;-1.0238469;-1.7178451;3.892138;-
applying a gaussian filter for smoothing prior to down scaling;4.5772934;-0.07751157;0.78775;-0.24064521;-2.987508;8.382807;CODE
reduces aliasing artifacts;0.7536525;0.29955205;-0.9075586;-0.12240934;-0.20174155;4.57361;-
convert the image into a graph with the value of the gradient on the;2.414571;-1.1643856;5.299618;-4.1225996;-1.9538952;2.0618095;IRRE
edges;0.068448044;-1.8736738;6.8949966;-2.8999848;1.1524712;-0.009214684;-
take a decreasing function of the gradient an exponential;-1.272837;-0.2882803;2.1791523;0.43899617;-1.5955846;2.3463125;CODE
the smaller beta is the more independent the segmentation is of the;1.9180937;-1.1323988;1.5625035;-1.1091026;1.5200248;2.073823;CODE
actual image for beta 1 the segmentation is close to a voronoi;2.1838539;-1.3747892;1.5835711;-2.4934797;-2.2519922;2.9925723;CODE
the number of segmented regions to display needs to be chosen manually;0.55346555;1.2462877;3.327619;-3.2569723;2.5180542;2.14529;TASK
the current version of spectral clustering does not support determining;4.0979714;-2.3222597;-4.364643;0.48838946;1.109343;2.7529426;META
the number of good quality clusters automatically;4.1680603;-2.2436726;1.2378305;1.5552214;2.486035;0.020461455;IRRE
compute and visualize the resulting regions;3.7639449;-0.4726003;7.0494943;-6.8291774;-1.0950994;0.030858368;IRRE
computing a few extra eigenvectors may speed up the eigen solver;3.2717655;-2.8556638;-2.732218;-0.072316796;-1.1430619;4.812885;-
the spectral clustering quality may also benefit from requesting;4.117469;-4.0070515;0.4188748;2.3703673;2.6164694;3.2719193;CODE
extra regions for segmentation;3.6726005;-2.2662957;3.4005978;-2.8335176;2.7267644;3.1425834;CODE
apply spectral clustering using the default eigen solver arpack;3.5667784;-2.8841357;-5.3452253;-1.7831793;-2.2085822;5.436245;CODE
any implemented solver can be used eigen solver arpack lobpcg or amg;0.6612946;-2.0535727;-4.7985168;-1.950179;-1.7077098;2.8150415;TASK
choosing eigen solver amg requires an extra package called pyamg;-1.4624436;-1.9627218;-4.4762135;-1.3726802;-2.3325057;3.460557;IRRE
the quality of segmentation and the speed of calculations is mostly determined;6.615526;-1.7037644;1.6720508;-0.19461602;0.10741045;0.08154108;CODE
by the choice of the solver and the value of the tolerance eigen tol;2.04717;1.5416617;-1.313327;-0.7449098;-1.7364771;2.4730089;IRRE
todo varying eigen tol seems to have no effect for lobpcg and amg 21243;-1.5932477;1.0289247;-5.19626;0.93267983;-1.5962303;4.086816;CODE
to view individual segments as appear comment in plt pause 0 5;-2.7013366;0.4812838;2.8437612;-2.7095141;-0.15298745;1.089715;-
todo after 21194 is merged and 21243 is fixed check which eigen solver;-2.0414884;1.6478157;-4.6188126;-1.5666692;-1.0729771;0.9751288;TASK
is the best and set eigen solver arpack lobpcg or amg and eigen tol;1.9360569;-1.9277545;-3.572694;-1.0062448;-0.1615654;3.223246;IRRE
explicitly in this example;-2.2254949;2.0167282;4.2627597;0.33596987;2.7586875;-1.5085202;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
resize it to 20 of the original size to speed up the processing;0.10090781;0.41235065;3.895189;-1.0238469;-1.7178451;3.892138;-
applying a gaussian filter for smoothing prior to down scaling;4.5772934;-0.07751157;0.78775;-0.24064521;-2.987508;8.382807;CODE
reduces aliasing artifacts;0.7536525;0.29955205;-0.9075586;-0.12240934;-0.20174155;4.57361;-
define structure of the data;4.6201196;-0.83407426;3.7486403;-3.7891552;4.636856;-0.066018894;CODE
pixels are connected to their neighbors;1.6040297;-0.67473143;4.279006;-3.836275;-2.8014064;2.884614;-
compute clustering;5.6134815;-0.9169714;2.7749245;-3.8876472;3.118182;-1.5612417;-
n clusters 27 number of regions;0.70352685;-0.87093323;1.9919165;-3.8658504;1.8755033;-2.0480208;-
plot the results on an image;3.198636;-0.99823755;8.948382;-3.4942822;-5.232559;-1.0632858;IRRE
agglomerative clustering is able to segment each coin however we have had to;3.7168682;-1.1732793;-0.08093367;-1.3135308;0.8572053;2.1931171;CODE
use a n cluster larger than the number of coins because the segmentation;4.009972;1.4548956;1.4825443;-3.150665;1.2121482;0.49825615;IRRE
is finding a large in the background;1.3329511;-0.25584823;5.316877;1.8813125;-1.2207173;1.1652653;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
we use class sklearn datasets make blobs to create 3 synthetic clusters;5.058315;-6.139911;-2.7885659;-3.2453504;0.7177314;0.37899083;IRRE
we can visualize the resulting data;6.1313133;-3.8609025;7.5892572;-2.6905808;0.73154074;-1.1774014;IRRE
compute dbscan;3.0540898;-0.3217431;0.040310137;-4.4363427;1.5708112;-1.6159292;-
one can access the labels assigned by class sklearn cluster dbscan using;1.7747364;-3.8546686;-2.8134184;-2.4274879;1.7963867;0.7421689;IRRE
the labels attribute noisy samples are given the label math 1;4.9835367;0.6605757;-2.190329;-1.9522079;0.6099846;-1.0434631;META
number of clusters in labels ignoring noise if present;4.805049;1.1499047;-0.4740889;-0.6443329;1.5481079;0.4467378;-
clustering algorithms are fundamentally unsupervised learning methods;5.31205;-5.5886207;-0.6590497;1.1741186;1.4719311;3.3152332;CODE
however since class sklearn datasets make blobs gives access to the true;1.1777017;-3.7846386;-5.7833314;-0.05760133;-1.5552566;-0.73164797;IRRE
labels of the synthetic clusters it is possible to use evaluation metrics;5.3812385;-3.6213214;-0.25755322;-0.13513523;2.4708893;0.9165919;CODE
that leverage this supervised ground truth information to quantify the;4.449127;-3.9934194;0.1819689;2.8519254;3.7794323;-0.28022787;CODE
quality of the resulting clusters examples of such metrics are the;4.923214;-1.9801769;-0.36393645;0.19387579;0.77116656;1.3992515;IRRE
homogeneity completeness v measure rand index adjusted rand index and;2.306677;0.3925567;-2.4962308;1.2550973;1.162169;0.56981915;IRRE
adjusted mutual information ami;1.3079853;0.6109318;0.90733576;-0.46907377;2.1476488;3.721127;CODE
if the ground truth labels are not known evaluation can only be performed;2.1294312;2.5594919;-2.9467485;1.8724266;3.9355729;-1.1534046;CODE
using the model results itself in that case the silhouette coefficient comes;1.3876002;0.17152233;-0.051452257;0.6281976;-2.2550528;3.594968;CODE
in handy;-3.445346;-3.2546356;5.0801644;1.4949971;-0.43320152;-2.5287504;-
for more information see the;-4.103914;-4.206467;2.9282835;0.7477206;0.5501826;-1.5166482;CODE
ref sphx glr auto examples cluster plot adjusted for chance measures py;3.3461921;-2.3695562;-2.6679695;0.45572293;-3.3571103;2.4749088;CODE
example or the ref clustering evaluation module;4.672739;-2.996188;0.714016;1.3320334;3.5773332;-0.38026154;CODE
plot results;2.7280965;0.63260704;7.251219;-4.383265;-6.2113085;-4.720718;IRRE
core samples large dots and non core samples small dots are color coded;3.1392086;-1.2517388;-1.7731696;-2.591332;-1.8001835;-0.028698877;CODE
according to the assigned cluster samples tagged as noise are represented in;5.7472334;-1.8056395;-1.6453229;-0.4482239;3.226962;1.3586049;IRRE
black;-2.3477356;-1.7124604;5.647035;-1.4031284;1.2484072;-3.2195816;-
black used for noise;-1.7285401;-2.4290621;1.8040462;-0.50045395;0.4779218;0.3012101;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
load the data;0.79853487;0.056605678;5.9102864;-1.0126848;0.3381265;-1.3700435;CODE
learn the dictionary of images;2.01196;-5.86328;3.4768388;-1.8634075;0.5057538;0.8997666;-
the online learning part cycle over the whole dataset 6 times;4.3543844;-5.730675;0.7277024;2.8038673;2.080888;0.09517188;IRRE
plot the results;2.5723717;0.51060593;8.345838;-4.221384;-5.27153;-5.326178;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
visualize the clustering;4.2192216;-3.2050776;6.0570617;-3.720285;0.118597664;0.71472216;-
2d embedding of the digits dataset;5.453911;-2.828108;1.2439468;-6.561988;-0.05874596;0.48617756;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
original image;-2.9329057;-0.9630145;5.418416;-1.515437;-1.5453739;0.046183575;-
we start by loading the raccoon face image from scipy we will additionally check;-1.9912539;-4.6687694;-1.0344813;-2.6414165;-4.8103447;-1.2439815;CODE
a couple of information regarding the image such as the shape and data type used;1.6590524;-4.3983517;4.6508102;-3.9619417;1.6722971;1.230998;CODE
to store the image;-3.3448875;-1.2173947;6.8161707;-1.9604417;-0.6105904;3.0048532;-
thus the image is a 2d array of 768 pixels in height and 1024 pixels in width each;0.7693243;0.266104;3.2214324;-7.681828;-2.5863783;1.8157043;-
value is a 8 bit unsigned integer which means that the image is encoded using 8;-2.550285;1.9867785;-0.5147709;-6.605469;-0.51209897;-0.7252318;IRRE
bits per pixel the total memory usage of the image is 786 kilobytes 1 byte equals;-0.48552662;0.55955124;1.4888413;-3.9978347;-0.674728;1.3014146;-
8 bits;-2.2535558;-0.5708629;3.7394712;-4.6685095;1.0524973;-4.393166;-
using 8 bit unsigned integer means that the image is encoded using 256 different;-2.087935;1.700242;-1.5783907;-5.501464;-1.1529444;0.35828722;CODE
shades of gray at most we can check the distribution of these values;3.617716;1.2616746;2.374746;-1.4386994;-1.2397484;-3.9301834;IRRE
compression via vector quantization;4.404015;-2.839741;-0.83484703;-4.2323546;1.6455593;4.2247586;-
the idea behind compression via vector quantization is to reduce the number of;3.7614567;-2.5539925;-0.58677006;-2.621264;1.8471634;4.5211716;-
gray levels to represent an image for instance we can use 8 values instead;2.1117754;0.5201223;3.9162145;-5.2793083;1.1749967;1.1864406;IRRE
of 256 values therefore it means that we could efficiently use 3 bits instead;-0.8425475;0.14910798;-1.041505;-4.2539926;2.4557602;-2.5433476;IRRE
of 8 bits to encode a single pixel and therefore reduce the memory usage by a;1.1081895;1.2977252;1.5745322;-4.46913;0.04458538;2.2616558;CODE
factor of approximately 2 5 we will later discuss about this memory usage;-1.1011286;-0.52722955;2.9197335;-0.48367462;0.6578133;-0.9082633;CODE
encoding strategy;2.1040184;-1.6998754;1.4909796;-1.7506989;3.6054962;-0.5664744;-
we previously stated that we should save 8 times less memory let s verify it;-1.3645571;-0.07608993;0.23447707;2.360558;-0.26184443;1.2830411;CODE
it is quite surprising to see that our compressed image is taking x8 more;1.3982081;-0.53776175;0.32290405;-1.568851;-2.4756765;3.8839426;-
memory than the original image this is indeed the opposite of what we;-0.24307412;-1.1670579;4.197554;0.83395404;-1.3357031;2.7420807;CODE
expected the reason is mainly due to the type of data used to encode the;1.3945314;0.62784237;-4.8458176;-2.0699959;-1.0858446;-0.64522135;OUTD
image;-1.6429675;-1.5002543;8.676563;-1.5434151;0.197481;-1.2348815;-
indeed the output of the class sklearn preprocessing kbinsdiscretizer is;0.44567657;-4.752421;-7.5827713;-0.5264949;-0.9532413;-1.0209854;IRRE
an array of 64 bit float it means that it takes x8 more memory however we;-1.0343705;1.103859;0.21649487;-4.522347;-1.0128214;-0.32131404;CODE
use this 64 bit float representation to encode 8 values indeed we will save;-0.5279579;0.3092252;-1.805665;-6.7014947;-1.6530111;-0.5879599;IRRE
memory only if we cast the compressed image into an array of 3 bits integers we;0.60657895;2.4549038;0.6346151;-4.2328944;0.5770665;1.7416128;CODE
could use the method numpy ndarray astype however a 3 bits integer;0.88867164;0.9542747;-5.392459;-7.7852015;-3.4571347;-1.2747719;IRRE
representation does not exist and to encode the 8 values we would need to use;0.4950955;1.341238;-1.1716663;-6.2746825;2.1525707;-1.944953;TASK
the 8 bit unsigned integer representation as well;-1.7139629;-1.5375645;-0.41648883;-6.6482725;2.5513864;-1.2094064;CODE
in practice observing a memory gain would require the original image to be in;0.21025941;-0.18426685;2.5214617;4.035392;-0.111281715;4.602222;CODE
a 64 bit float representation;0.21750614;-1.1937928;-0.3691802;-7.4350038;-0.033505406;-1.1716524;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
set parameters;0.10336116;3.1397388;3.7041423;-0.6311514;2.825396;1.1828104;IRRE
ize 40 image size;-0.16595155;1.6944644;3.5126746;-2.8137095;-1.6562057;3.3331742;-
generate data;3.5066159;-0.7332362;4.43081;-2.3223329;2.8341296;-3.9849672;-
for x in x smooth data;4.6468973;0.9489587;0.8127926;-4.9407806;-0.24079415;0.5349151;CODE
add noise;-0.40944335;-1.7659887;4.127824;1.1994702;0.44748032;-0.32272136;TASK
compute the coefs of a bayesian ridge with gridsearch;3.5874546;-1.601815;-2.645811;-2.8559647;-1.8375323;2.7839167;-
cv kfold 2 cross validation generator for model selection;3.78396;-2.6998887;-3.2575877;2.061329;1.9516377;0.2397653;CODE
ward agglomeration followed by bayesianridge;3.6105077;-3.316027;0.86048895;1.3536035;1.1896219;2.1223779;-
select the optimal number of parcels with grid search;4.2270803;2.477122;2.6287758;-2.155826;3.0561984;0.44473282;CODE
clf fit x y set the best parameters;5.114268;2.0953093;-0.7655732;-2.0586288;-0.666173;2.555869;IRRE
anova univariate feature selection followed by bayesianridge;3.0636394;-3.7046068;0.2874983;2.965303;1.3571258;0.4956971;CODE
f regression mem cache feature selection f regression caching function;3.0451937;-1.3278935;-1.8250107;1.703977;-0.5140182;3.3983045;CODE
select the optimal percentage of features with grid search;6.3863544;-0.6557363;2.0148156;-0.91621417;1.5170842;1.7529067;TASK
clf fit x y set the best parameters;5.114268;2.0953093;-0.7655732;-2.0586288;-0.666173;2.555869;IRRE
inverse the transformation to plot the results on an image;2.5857842;-0.4446029;6.884959;-4.0074058;-6.1055;1.8832132;IRRE
attempt to remove the temporary cachedir but don t worry if it fails;-5.2137647;2.3637073;-1.0146512;2.4951823;-2.790541;0.81105566;META
coding utf 8;-2.259702;-0.29598805;0.812569;-3.4921534;-0.7222944;-2.870605;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
black removed and is used for noise instead;-3.6754043;-1.3744024;1.3084799;-1.0162462;0.8579793;1.8783839;OUTD
the probability of a point belonging to its labeled cluster determines;4.3489113;-0.45876554;2.3068602;-0.5057138;3.136365;1.9941577;CODE
the size of its marker;-0.5896372;-0.0067221127;4.6697226;-2.1687622;-0.05863818;-0.7208524;-
black used for noise;-1.7285401;-2.4290621;1.8040462;-0.50045395;0.4779218;0.3012101;CODE
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
one of the greatest advantages of hdbscan over dbscan is its out of the box;0.6210122;-3.8007336;-0.43875805;-0.7882692;0.83390665;1.2714329;IRRE
robustness it s especially remarkable on heterogeneous mixtures of data;6.7114563;-0.46964163;-1.5292016;0.1524322;1.5051343;2.6847928;-
like dbscan it can model arbitrary shapes and distributions however unlike;5.2944937;-3.7847416;1.1661811;-1.5130556;1.7452523;3.3262372;META
dbscan it does not require specification of an arbitrary and sensitive;0.097809315;0.3160881;-3.6687634;-1.0017513;3.1124697;0.6249123;CODE
eps hyperparameter;3.3326871;0.5062984;-0.9064808;-2.0191252;-0.42593822;0.7087509;IRRE
for example below we generate a dataset from a mixture of three bi dimensional;6.3238454;-2.076867;1.3992878;-5.1119456;3.0223973;1.5875491;CODE
and isotropic gaussian distributions;2.2973034;-3.5656672;-0.21027124;-1.8150473;-0.23284222;4.6294465;META
scale invariance;4.1787586;0.08426718;2.1825156;-1.5127645;-3.1616445;4.8589044;CODE
it s worth remembering that while dbscan provides a default value for eps;-0.29522836;0.110016204;-3.1307065;-1.657227;-0.68904716;2.1175377;CODE
parameter it hardly has a proper default value and must be tuned for the;-2.748943;4.40746;-2.7681727;1.6996111;-2.446935;2.1453052;IRRE
specific dataset at use;5.3852305;-3.8344483;2.7188318;-0.1767649;4.422186;-0.5405338;IRRE
as a simple demonstration consider the clustering for a eps value tuned;5.948841;-0.36616346;-0.5574636;-3.0143623;-0.17894933;3.5999146;IRRE
for one dataset and clustering obtained with the same value but applied to;5.7102413;1.0076727;0.52542746;-0.4579688;2.851374;1.1812353;IRRE
rescaled versions of the dataset;6.824774;-3.0069973;1.4061282;-2.1688976;-0.7769533;3.1786895;IRRE
indeed in order to maintain the same results we would have to scale eps by;5.5848637;0.6358275;0.18212366;-0.28730986;-0.83523595;4.231272;CODE
the same factor;-1.1110462;1.2273855;5.077103;-0.41365921;-1.2387381;-1.2715427;-
while standardizing data e g using;3.225563;0.47632414;0.64079076;-2.0630305;1.7459342;1.7604787;CODE
class sklearn preprocessing standardscaler helps mitigate this problem;2.6794562;-2.9504073;-8.408868;1.2649794;-3.3589327;1.5771437;CODE
great care must be taken to select the appropriate value for eps;-0.14807875;1.5352548;-1.3510357;-0.72091705;-0.8208575;0.6341201;CODE
hdbscan is much more robust in this sense hdbscan can be seen as;0.69031227;-3.4154568;-0.7322729;-0.71218485;0.5430836;1.1123055;CODE
clustering over all possible values of eps and extracting the best;7.326651;-0.62403;0.543678;-2.7622724;1.1249697;2.0546236;IRRE
clusters from all possible clusters see ref user guide hdbscan;1.7873542;-4.2408957;-0.021795696;-2.4296513;1.5603633;0.7629981;CODE
one immediate advantage is that hdbscan is scale invariant;2.1159554;-5.3754025;-0.061628126;-1.3092673;-0.2641498;4.5726485;CODE
multi scale clustering;6.493557;-3.142064;2.9738123;-2.1897614;1.9763597;4.546375;-
hdbscan is much more than scale invariant though it is capable of;1.7751305;-4.3188405;-1.4494625;-1.9678199;-0.97747475;3.508861;CODE
multi scale clustering which accounts for clusters with varying density;5.5770636;-2.4962168;1.3529493;-1.0822895;1.4571359;5.615946;CODE
traditional dbscan assumes that any potential clusters are homogeneous in;3.4520023;-0.13045241;-2.749688;-1.1586028;2.673956;3.0353115;-
density hdbscan is free from such constraints to demonstrate this we;3.1341097;-2.3841643;-2.3262982;-3.1693964;0.24960503;1.9191014;CODE
consider the following dataset;9.284378;-0.20273909;3.1203332;-2.1124325;2.4276998;-2.4178963;IRRE
this dataset is more difficult for dbscan due to the varying densities and;5.510331;-1.3058522;-1.122748;-2.3168364;0.8170875;1.0180757;CODE
spatial separation;3.005384;-2.1426222;4.7814627;-1.9986175;1.5635824;3.4704204;-
if eps is too large then we risk falsely clustering the two dense;4.6379604;0.63821733;-1.2996929;-0.66791636;-0.49723795;3.528066;-
clusters as one since their mutual reachability will extend;1.1107316;-1.8706148;3.3649457;-0.46436512;2.0669615;3.7232141;CODE
clusters;3.8283088;-3.2727606;5.327052;-1.121466;2.0298514;-0.20445268;-
if eps is too small then we risk fragmenting the sparser clusters;3.599817;-1.5733275;-1.0847285;-0.974572;-0.98414063;4.61318;IRRE
into many false clusters;6.1093273;0.19772609;1.2463814;-0.3216598;2.4866424;-1.1449038;CODE
not to mention this requires manually tuning choices of eps until we;2.6444585;-0.47747266;-1.6338135;-0.45996752;-1.1119606;3.7590637;CODE
find a tradeoff that we are comfortable with;0.5067814;1.3073033;2.589402;1.8304765;-1.2429104;1.0304874;CODE
to properly cluster the two dense clusters we would need a smaller value of;4.4404526;1.3049355;-1.0812219;-2.5320864;-0.7286413;2.7187357;IRRE
epsilon however at eps 0 3 we are already fragmenting the sparse clusters;3.0946617;-0.48466316;-3.2963836;-2.2582316;-1.4504253;3.8472657;IRRE
which would only become more severe as we decrease epsilon indeed it seems;-0.13267785;1.1583087;-1.533636;3.4524589;-1.0591966;2.1256728;CODE
that dbscan is incapable of simultaneously separating the two dense clusters;2.4954388;0.34194812;-2.3226125;-1.4195321;-0.17963585;2.4712808;-
while preventing the sparse clusters from fragmenting let s compare with;4.98905;0.72968596;-1.5273787;0.15902004;-0.466918;3.2373207;CODE
hdbscan;0.054996748;-4.599739;0.9676761;-3.720026;0.32125753;-2.3053184;-
hdbscan is able to adapt to the multi scale structure of the dataset without;4.7632017;-4.3300395;-1.3253754;-3.6126313;0.9916735;3.8251178;CODE
requiring parameter tuning while any sufficiently interesting dataset will;6.0109663;-3.2235587;-0.9336902;4.7015805;2.0938463;1.4181494;IRRE
require tuning this case demonstrates that hdbscan can yield qualitatively;2.119149;-2.7491372;-2.1524487;0.18892196;0.46501878;0.30397034;CODE
better classes of clusterings without users intervention which are;3.9031804;-2.659487;0.63638365;2.2920983;2.7192752;2.3700268;CODE
inaccessible via dbscan;-3.1866746;0.031505566;-1.7491995;-1.0140347;-0.93348706;0.12187073;-
hyperparameter robustness;3.899166;-0.17912582;-2.1231453;4.7507205;1.6427155;1.803681;IRRE
ultimately tuning will be an important step in any real world application so;2.7367814;-2.852203;1.3606192;4.209754;0.21089758;1.8327843;CODE
let s take a look at some of the most important hyperparameters for hdbscan;2.685358;-3.8727472;-1.9927386;-1.256531;0.7911257;-0.03874658;CODE
while hdbscan is free from the eps parameter of dbscan it does still have;-0.33422297;-1.8240136;-3.2841532;-2.1635416;-0.18979974;2.1158211;CODE
some hyperparameters like min cluster size and min samples which tune its;7.329213;-2.683748;0.80268264;0.93532884;3.129938;1.6733911;IRRE
results regarding density we will however see that hdbscan is relatively robust;2.8463774;-3.5324972;-2.5404775;-0.24383871;-1.2013003;1.4912198;IRRE
to various real world examples thanks to those parameters whose clear meaning;1.2067083;-0.5023983;2.3506353;0.3693512;1.2335775;-0.61815655;IRRE
helps tuning them;1.4951508;-1.1577159;4.179495;1.9294249;-2.1112428;-0.9159753;-
min cluster size;4.045489;0.14457911;0.3287653;-2.333467;0.92441934;2.951293;-
min cluster size is the minimum number of samples in a group for that;2.6140187;0.4603059;0.4237124;-0.8724807;1.836001;1.5748428;CODE
group to be considered a cluster;1.2254157;-0.15086173;2.0151446;-0.28478438;2.3695004;0.7532643;-
clusters smaller than the ones of this size will be left as noise;3.7751653;1.2923636;0.8376693;-1.0289493;-2.1881988;1.5518959;CODE
the default value is 5 this parameter is generally tuned to;-1.5390422;2.8879957;-0.6262331;-0.11645123;-0.8133993;0.31639168;IRRE
larger values as needed smaller values will likely to lead to results with;5.770788;3.867818;0.7011882;-1.447876;0.21220458;-2.6839943;IRRE
fewer points labeled as noise however values which too small will lead to;7.298766;2.066583;-1.2187486;-0.9629715;-0.04240934;0.97175825;IRRE
false sub clusters being picked up and preferred larger values tend to be;5.305749;3.3082116;-2.1349092;0.28168833;-0.80839777;0.39215538;IRRE
more robust with respect to noisy datasets e g high variance clusters with;6.752659;-4.1531963;-0.44832635;2.946469;0.52770567;4.062691;IRRE
significant overlap;2.003918;1.3997929;3.8019118;0.19096425;0.6577174;-1.9286749;-
min samples;6.1572294;1.5529944;1.5397371;-0.6571492;2.0449266;-2.0371122;-
min samples is the number of samples in a neighborhood for a point to;4.1080914;0.87106466;2.4370518;-2.2759156;1.6061851;0.6606079;CODE
be considered as a core point including the point itself;0.16743453;-0.7362354;3.0546837;1.2458495;0.8137068;2.572279;CODE
min samples defaults to min cluster size;3.6792386;0.83400905;-1.9869502;-0.38707352;-0.21145794;4.567217;CODE
similarly to min cluster size larger values for min samples increase;6.327139;-0.97789365;0.38982308;-1.5345271;0.7903831;3.4571257;IRRE
the model s robustness to noise but risks ignoring or discarding;2.936916;-0.72004354;-1.5876397;6.6823354;0.34605187;2.4718447;META
potentially valid but small clusters;3.4764714;0.14786176;-0.5396048;1.58232;1.6635846;0.29578844;META
min samples better be tuned after finding a good value for min cluster size;6.3885994;1.621531;-1.3520284;1.2854185;-0.623825;2.9910743;IRRE
dbscan clustering;3.6706593;-1.998133;1.3277892;-2.4777842;2.738609;1.1269844;-
during fit hdbscan builds a single linkage tree which encodes the;0.00093903946;-2.8085563;-1.6234163;-2.1642992;2.9237914;2.2753267;-
clustering of all points across all values of class cluster dbscan s;4.5109186;-0.89674735;-0.8186953;-2.8436327;2.5469553;1.5452045;IRRE
eps parameter;0.36094242;2.296146;0.24275413;-4.3622828;-1.2753955;0.7507588;IRRE
we can thus plot and evaluate these clusterings efficiently without fully;6.5401235;-1.8613311;1.9898977;-1.4259206;-1.1886382;1.2692097;-
recomputing intermediate values such as core distances mutual reachability;1.989678;0.27689475;-0.5031386;0.117363304;1.021471;3.2497482;IRRE
and the minimum spanning tree all we need to do is specify the cut distance;2.0813239;-0.31113964;1.3359271;-2.2395868;1.7457486;2.7787483;TASK
equivalent to eps we want to cluster with;5.187685;-2.2535832;2.5578291;-3.6850774;1.7258471;2.6656773;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate some training data from clustering;6.048789;-3.5614903;1.4324969;-0.7510298;2.4434857;1.1390089;CODE
train a clustering algorithm on the training data and get the cluster labels;4.928294;-3.2854521;0.64800024;-0.6715072;2.8534422;1.5012555;-
generate new samples and plot them along with the original dataset;5.367818;-0.7748792;3.6335125;-1.3133966;-1.8198025;-0.117380336;IRRE
declare the inductive learning model that it will be used to;1.9862458;-3.7391098;0.34531817;4.1460137;5.22002;0.32225633;OUTD
predict cluster membership for unknown instances;5.598511;-1.6525028;-1.1447848;1.9199415;2.3289099;1.2669908;CODE
plotting decision regions;4.4137855;-1.9843609;5.6003833;-3.7798944;-0.8159405;0.49769408;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
the function func sklearn datasets make blobs generates isotropic;3.4601395;-5.206347;-4.663357;-3.6616082;-4.0306406;0.77503365;IRRE
spherical gaussian blobs to obtain anisotropic elliptical gaussian blobs;1.5631981;-1.5721068;-1.3423378;-4.1880116;-2.3769038;4.327467;-
one has to define a linear transformation;-0.4191;0.32249168;2.0593703;-2.9923763;0.59053034;2.4573112;CODE
x aniso np dot x transformation anisotropic blobs;0.8270084;-2.054653;-2.545252;-7.58241;-2.962064;3.6929107;CODE
unequal variance;0.39980653;3.4961092;0.09584867;-0.18937257;-1.9887164;-1.4130236;CODE
unevenly sized blobs;1.5531505;1.426054;1.3859841;-4.1134553;-1.5181909;1.2273581;-
we can visualize the resulting data;6.1313133;-3.8609025;7.5892572;-2.6905808;0.73154074;-1.1774014;IRRE
fit models and plot results;5.078102;-1.0212786;3.6968982;-0.9704022;-5.1344986;0.17085226;IRRE
the previously generated data is now used to show how;1.3148053;-1.8629701;1.808694;-0.026618283;2.0064468;-0.35955432;OUTD
class sklearn cluster kmeans behaves in the following scenarios;2.77889;-1.8429496;-4.923764;-0.30335444;-1.9656739;1.0278281;CODE
non optimal number of clusters in a real setting there is no uniquely;4.578328;1.6840909;0.32998514;-1.0533441;0.6998629;2.504529;IRRE
defined true number of clusters an appropriate number of clusters has;2.1662614;2.4357314;0.26467344;-0.91446036;2.4991941;-0.94281447;CODE
to be decided from data based criteria and knowledge of the intended goal;3.2729447;-1.2592688;3.5504568;3.8399246;5.0514016;-0.8064077;CODE
anisotropically distributed blobs k means consists of minimizing sample s;5.2151747;-0.6329994;-0.49374917;-1.3479148;-0.9447002;3.2931442;IRRE
euclidean distances to the centroid of the cluster they are assigned to as;2.6393168;0.6115447;1.6628217;-3.4201293;-1.9462285;3.4364386;CODE
a consequence k means is more appropriate for clusters that are isotropic;3.6467402;-1.4836845;0.27524722;-0.89763427;-0.0915763;3.590891;CODE
and normally distributed i e spherical gaussians;1.1685265;-1.9876556;1.8343982;-2.4335747;-1.1636131;2.7368798;META
unequal variance k means is equivalent to taking the maximum likelihood;1.3602767;0.5392152;-0.53788394;1.0998441;-1.7811735;3.9009352;CODE
estimator for a mixture of k gaussian distributions with the same;2.9277105;-0.6396099;-0.42280447;-0.13788795;0.17192045;4.93004;META
variances but with possibly different means;2.205272;3.2772024;2.648554;0.4487489;-1.1529558;-0.6638972;META
unevenly sized blobs there is no theoretical result about k means that;2.2401738;-0.43249875;-0.71954185;-3.4314308;-0.9828282;0.31222153;IRRE
states that it requires similar cluster sizes to perform well yet;3.8370652;-1.4621875;-0.7572476;1.7995716;1.5691355;2.0783324;CODE
minimizing euclidean distances does mean that the more sparse and;5.262187;-1.8480871;0.48366958;-1.1024233;-1.3917515;4.8374825;CODE
high dimensional the problem is the higher is the need to run the algorithm;6.4665494;-1.4342201;0.9329586;-3.4301927;1.3268824;0.9117313;TASK
with different centroid seeds to ensure a global minimal inertia;2.3144715;1.4231539;1.3463336;-1.2856451;-0.64908385;5.4832187;-
possible solutions;-1.3597908;1.6416821;5.3897476;-0.84972334;0.25795656;-4.7082763;-
for an example on how to find a correct number of blobs see;1.6236314;-0.2795316;1.8412349;-3.0664735;1.1057711;-3.2111967;CODE
ref sphx glr auto examples cluster plot kmeans silhouette analysis py;2.1122062;-3.2259629;-2.3132992;-3.1447518;-4.0781646;2.5817497;-
in this case it suffices to set n clusters 3;0.39988816;0.043418836;0.0663346;-2.8402312;2.1443794;3.705089;CODE
to deal with unevenly sized blobs one can increase the number of random;2.206612;-0.2801682;1.9001325;-0.4850212;0.5555333;1.2228745;IRRE
initializations in this case we set n init 10 to avoid finding a;-3.1992867;2.8184726;-1.0011191;0.34293893;1.1643479;-0.9811802;CODE
sub optimal local minimum for more details see ref kmeans sparse high dim;6.6199083;-1.5629323;-1.9211206;-2.3348117;0.3868614;5.262637;IRRE
as anisotropic and unequal variances are real limitations of the k means;4.4551187;-1.2991574;-1.9766681;-0.19943888;-2.8705566;4.6169267;CODE
algorithm here we propose instead the use of;4.217515;0.20801713;3.8158243;-1.0436957;4.7457104;-0.9524178;-
class sklearn mixture gaussianmixture which also assumes gaussian;3.303464;-2.9616234;-5.017576;-1.1142373;-0.057185438;3.6084287;IRRE
clusters but does not impose any constraints on their variances notice that;3.3838975;0.9920003;-2.6369474;0.79954493;0.24071494;3.8908272;CODE
one still has to find the correct number of blobs see;0.502104;0.6681172;1.4644935;-1.8357314;0.90115535;-2.2747378;TASK
ref sphx glr auto examples mixture plot gmm selection py;1.3961525;-1.4457828;-3.0707326;-2.0989468;-1.653121;3.2536163;CODE
for an example on how other clustering methods deal with anisotropic or;4.74764;-3.380265;-0.8483792;-2.0517404;0.5287786;4.4528766;CODE
unequal variance blobs see the example;1.5227039;1.9697497;-2.1884553;-2.7729506;-1.9351871;0.13450769;CODE
ref sphx glr auto examples cluster plot cluster comparison py;2.4240968;-2.3718426;-2.9619038;-1.3248478;-3.5229585;2.6127949;-
final remarks;-3.729942;-0.6456553;4.5859194;2.2760768;0.28933856;-1.3549469;CODE
in high dimensional spaces euclidean distances tend to become inflated;4.3589425;-1.2918813;0.80916744;-2.6688135;-3.2373612;5.1386657;CODE
not shown in this example running a dimensionality reduction algorithm;3.7407706;0.6128499;-3.9779568;-5.546923;-0.062680714;0.87019;CODE
prior to k means clustering can alleviate this problem and speed up the;6.8274426;-0.9756822;0.55606294;1.1410129;1.0465431;3.211727;CODE
computations see the example;2.514706;-0.3167433;1.8703328;-4.1818833;-0.02895021;-2.5727808;-
ref sphx glr auto examples text plot document clustering py;0.5305838;-3.3842318;-1.5900637;-1.7783102;-3.389777;2.6804826;CODE
in the case where clusters are known to be isotropic have similar variance;3.6978111;-1.501731;-0.78535634;-1.1872349;-0.6661865;4.7564235;CODE
and are not too sparse the k means algorithm is quite effective and is one of;8.743096;-3.531091;0.27320376;-0.47203287;-0.10522347;0.6235241;IRRE
the fastest clustering algorithms available this advantage is lost if one has;3.973111;-3.1821864;1.1929344;1.3825426;1.6897547;2.7557635;CODE
to restart it several times to avoid convergence to a local minimum;-0.3173838;2.2958784;1.9310498;3.4259691;-2.5460508;2.347285;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the dataset;3.3733814;-2.8897374;2.069233;-0.41889125;0.5001514;-0.03551577;IRRE
we will start by loading the digits dataset this dataset contains;2.6397529;-2.7352288;-0.24111503;-3.5736117;0.70404387;-3.2871404;IRRE
handwritten digits from 0 to 9 in the context of clustering one would like;4.4854484;-0.86697793;1.9065157;-5.293589;1.2262433;-0.7080221;CODE
to group images such that the handwritten digits on the image are the same;4.4617305;-0.7535577;4.4997225;-2.8437686;2.2424433;2.108635;CODE
print f digits n digits samples n samples features n features;3.780504;-2.124756;-0.359784;-5.1088786;0.17059262;-4.162639;CODE
define our evaluation benchmark;4.1809387;-2.22706;1.5114098;5.448217;1.8158343;-1.7116262;CODE
we will first our evaluation benchmark during this benchmark we intend to;2.9093006;-1.0200642;2.05073;6.194978;1.1002171;-1.0445153;CODE
compare different initialization methods for kmeans our benchmark will;3.8139832;-0.7812397;-2.4915638;1.6112763;-0.79087365;1.2562298;IRRE
create a pipeline which will scale the data using a;6.2858806;1.3135139;2.2809575;-1.9394232;0.29793087;2.7606134;CODE
class sklearn preprocessing standardscaler;1.6901858;-3.353517;-6.404336;0.7443969;-1.5943406;0.55071044;IRRE
train and time the pipeline fitting;3.802779;-2.3235853;1.4110099;2.0147283;-0.34211376;2.5236526;CODE
measure the performance of the clustering obtained via different metrics;5.7629385;-1.877752;0.95934576;1.8904967;1.6933209;1.8206134;CODE
define the metrics which require only the true labels and estimator;3.7223923;0.45307556;0.72002864;0.76434076;2.065056;3.725233;CODE
labels;1.3791705;-3.3884714;5.675712;-2.4028962;4.842853;-1.4529474;-
the silhouette score requires the full dataset;3.730384;-3.3019402;-0.74317294;1.1289281;-0.53642756;0.14938374;IRRE
show the results;1.2329224;2.4068863;6.122899;-1.4952804;0.3681415;-7.299639;IRRE
run the benchmark;3.8601406;-1.387192;1.8177594;4.151311;0.18853724;-2.8731527;CODE
we will compare three approaches;0.23989196;0.09682114;4.7288666;4.9118834;2.6435876;-1.692197;IRRE
an initialization using k means this method is stochastic and we will;4.27062;-1.5071023;0.08786575;1.7163588;-0.23181656;1.9910008;IRRE
run the initialization 4 times;-3.760766;3.2540467;1.0294143;1.2376097;1.4556502;0.51773155;IRRE
a random initialization this method is stochastic as well and we will run;2.0007064;-0.8371644;0.028136099;3.1407897;0.4002041;1.0305344;IRRE
the initialization 4 times;-4.1379614;2.1762273;1.03277;0.3223225;1.7683537;-1.334386;IRRE
an initialization based on a class sklearn decomposition pca;5.7125273;-3.8692193;-4.897238;-1.4818276;1.5783403;3.2375636;IRRE
projection indeed we will use the components of the;-0.37493622;-3.2690074;4.4602404;1.2931348;0.0024107292;4.2743545;IRRE
class sklearn decomposition pca to initialize kmeans this method is;3.5931213;-2.8680747;-4.8405275;-3.0552022;-0.76819885;2.3409934;IRRE
deterministic and a single initialization suffice;-0.88990957;-0.35004544;-0.95829546;3.285759;3.1298378;2.1790605;IRRE
visualize the results on pca reduced data;6.015869;-1.5182059;1.3626434;-3.3499956;-0.3373554;2.029267;IRRE
class sklearn decomposition pca allows to project the data from the;4.910266;-7.310803;-3.3680732;-1.6062546;0.29279843;1.8643974;CODE
original 64 dimensional space into a lower dimensional space subsequently;0.60478055;0.013423139;0.4054726;-5.304237;0.66591537;2.798586;CODE
we can use class sklearn decomposition pca to project into a;5.776866;-5.908608;-3.5549104;-1.4093043;1.3548908;1.644925;CODE
2 dimensional space and plot the data and the clusters in this new space;4.8061094;-1.7837449;5.0681267;-6.6838965;-2.5268552;1.0993739;CODE
step size of the mesh decrease to increase the quality of the vq;1.1305641;2.073121;-0.62744457;0.77739173;-1.8667378;4.3705564;IRRE
h 0 02 point in the mesh x min x max x y min y max;0.8460549;2.0291545;-0.4007631;-7.5985937;-3.5989041;0.5287116;CODE
plot the decision boundary for that we will assign a color to each;2.4560258;-1.6418927;5.445053;-2.621385;0.95969707;-0.08623329;IRRE
obtain labels for each point in mesh use last trained model;3.580775;-0.6143729;1.8595995;-0.9581654;1.5432216;2.419354;CODE
put the result into a color plot;1.4292959;0.4262304;5.77492;-3.760507;-3.6140656;-2.4272733;IRRE
plot the centroids as a white x;1.3561311;1.2766328;4.847453;-6.8575454;-4.3508377;2.040425;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
calculate seeds from k means;5.372821;0.33026648;2.7541497;-2.8463163;-1.0706072;-2.5056999;CODE
plot init seeds along side sample data;3.6331124;-0.5076609;3.8451662;-2.7366383;-3.0965738;0.8356762;IRRE
colors 4eacc5 ff9c34 4e9a06 m;-2.1358266;-0.19754095;0.5860596;-4.473497;2.524617;-1.4464107;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generating the sample data from make blobs;3.546435;-1.8103943;0.39154923;-2.5954924;0.1332874;-1.6500251;CODE
this particular setting has one distinct cluster and 3 clusters placed close;0.92762506;1.2139986;2.324115;-2.810468;2.809692;2.7904515;IRRE
together;-1.8154237;-1.9608037;7.379568;-0.27506334;1.2080835;-2.9334564;-
for reproducibility;2.13557;-4.150555;1.1932337;6.300342;0.7544579;-3.7649484;CODE
create a subplot with 1 row and 2 columns;2.5120885;0.27632958;5.0315113;-6.8796988;-2.6093183;0.23185512;IRRE
the 1st subplot is the silhouette plot;-0.13930738;-1.4055169;5.565058;-3.7061858;-4.437846;0.9686748;-
the silhouette coefficient can range from 1 1 but in this example all;0.84862685;1.777421;-0.04771883;-3.2872257;-2.5738084;0.87223613;CODE
lie within 0 1 1;-0.7100831;3.980447;1.2910151;-4.2810597;-0.5701602;-4.0906982;-
the n clusters 1 10 is for inserting blank space between silhouette;-1.100522;0.1959554;0.64771813;-4.3895454;-1.3899615;1.2584704;CODE
plots of individual clusters to demarcate them clearly;4.9876566;-0.74189186;4.059236;-5.463922;-2.3845844;2.6491263;-
initialize the clusterer with n clusters value and a random generator;2.2643178;0.2122377;-0.28300333;-0.5882719;0.7068756;2.0258539;IRRE
seed of 10 for reproducibility;1.0976199;-1.0972425;0.66582805;3.374037;1.0147262;-4.5387173;CODE
the silhouette score gives the average value for all the samples;4.8867464;0.07130878;0.6696549;-0.15737832;-1.4527687;-1.0067129;IRRE
this gives a perspective into the density and separation of the formed;-0.00040972428;-1.5523279;4.213994;-2.2080255;0.021034453;1.7079042;CODE
clusters;3.8283088;-3.2727606;5.327052;-1.121466;2.0298514;-0.20445268;-
compute the silhouette scores for each sample;6.495348;-0.3146132;2.0059698;-1.8701417;0.3850427;-1.4483566;CODE
aggregate the silhouette scores for samples belonging to;6.6762657;-0.8492062;2.3540251;-0.6301529;2.342568;-0.1260991;CODE
cluster i and sort them;4.346231;-0.12549962;3.1338737;-3.5367084;2.6254694;0.15287067;-
label the silhouette plots with their cluster numbers at the middle;2.5961812;-0.7877745;3.8414485;-5.090298;-1.1435621;2.449692;-
compute the new y lower for next plot;1.4339195;1.8718872;4.699388;-3.297466;-6.186925;-0.6402966;CODE
y lower y upper 10 10 for the 0 samples;3.3177755;3.1748474;-0.18962634;-3.8382387;-3.6809497;-3.6026888;CODE
the vertical line for average silhouette score of all the values;4.887925;0.47670284;3.0275104;-3.7089193;-1.3909682;-0.37386554;IRRE
ax1 set yticks clear the yaxis labels ticks;-1.5420351;1.1729627;0.52496463;-3.4786496;-3.4571743;2.958006;IRRE
2nd plot showing the actual clusters formed;2.6746678;0.083279274;4.140604;-4.9429708;-4.1086826;0.47630048;CODE
labeling the clusters;4.8780327;-2.3033032;3.867823;-2.8645997;3.7975657;0.47220513;-
draw white circles at cluster centers;1.2564285;-1.2359316;4.350157;-3.1437125;-2.7515943;2.2342477;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
number of run with randomly generated dataset for each strategy so as;4.461302;-1.5545608;2.4627569;2.9628944;2.1860108;-0.92520994;CODE
to be able to compute an estimate of the standard deviation;3.8984745;-0.04730009;0.34493008;0.19497573;-1.6641831;0.62679857;CODE
k means models can do several random inits so as to be able to trade;3.3440866;-3.3404572;1.2242863;0.6511929;3.1432197;1.3212299;IRRE
cpu time for convergence robustness;3.9305308;-1.2656552;-1.7978252;4.7057037;-1.9534651;2.0697527;CODE
datasets generation parameters;5.6813335;-2.6005576;-0.44797534;0.11688644;3.1542013;-0.1703931;IRRE
part 1 quantitative evaluation of various init methods;0.76160073;-0.45553467;0.714444;3.730711;0.9569525;-0.31886938;IRRE
part 2 qualitative visual inspection of the convergence;3.1749508;-0.18686296;2.8413985;1.902768;-2.0230188;0.9673251;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate datasets we choose the size big enough to see the scalability;7.0811367;-3.625408;0.6732426;0.1396803;1.7820072;0.94306;IRRE
of the algorithms but not too big to avoid too long running times;4.655318;-4.632442;1.6354789;1.2913086;2.136384;-0.72065127;CODE
anisotropicly distributed data;6.9551935;-2.2839932;2.4630506;-3.0412183;0.2983183;4.347278;META
blobs with varied variances;3.8186336;-0.43174738;0.2756341;-2.5170503;0.38171825;1.4287682;CODE
run the clustering and plot;4.5616302;-1.4476147;4.606409;-4.1473804;-4.2787066;0.22981001;CODE
set up cluster parameters;3.3847644;0.19073291;0.36082888;-2.2413692;1.3011028;3.9089153;IRRE
update parameters with dataset specific values;3.1468997;0.9850683;0.34782284;-0.2961681;0.95705295;0.714005;IRRE
normalize dataset for easier parameter selection;7.3460593;-1.0507267;0.51646656;-1.470845;2.067373;3.005627;IRRE
create cluster objects;2.4218855;-2.281131;2.2876918;-2.6284337;3.3868458;2.1139908;IRRE
catch warnings related to kneighbors graph;0.6013545;0.47176245;-2.5933824;-0.14425945;-2.4591975;-1.7077988;CODE
377eb8;-3.2394416;-0.35568774;1.9878036;-2.0714815;0.5609804;-3.5213711;-
ff7f00;-1.5215341;-2.2895124;3.0201576;-1.4312793;-0.5860017;-2.3476663;-
4daf4a;-1.4644228;-0.644233;1.7856381;-2.769044;1.119668;-1.3804107;-
f781bf;-2.1950033;-2.0410755;2.017877;-2.3717115;-0.17644581;-3.1477761;-
a65628;-1.8964489;-1.3510839;2.6234062;-1.7362324;0.0005306646;-3.42169;-
984ea3;-3.365741;-1.0009432;2.727797;-2.7002509;1.1319957;-3.5809689;-
999999;-2.132415;-0.82536834;0.69733757;-2.2920732;0.24809021;-3.9114347;-
e41a1c;-3.0807307;-0.46966854;2.8015385;-2.9272473;1.1985788;-2.9281187;-
dede00;-2.860573;-0.8446782;2.350382;-1.4776582;1.717411;-2.8874047;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
compute clustering with meanshift;4.2222414;0.20438085;0.79146653;-1.7338196;-0.3482084;1.5368468;-
the following bandwidth can be automatically detected using;0.9955338;0.16100055;2.1556358;-0.017064191;1.5537094;2.0380104;IRRE
plot result;0.50029325;1.6766995;6.921388;-5.063152;-6.4714994;-5.1247444;IRRE
colors dede00 377eb8 f781bf;-3.8152173;-0.8134057;0.114481024;-4.8512106;1.4113234;-2.522737;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate the data;4.332126;-0.83362067;4.90541;-3.0842018;2.5492842;-5.028516;-
we start by generating the blobs of data to be clustered;6.3714046;-3.2321453;2.748575;-2.358676;2.5919058;2.6885724;-
compute clustering with kmeans;2.8100536;-1.3801291;0.3192103;-3.3349495;-0.12768301;1.4766444;-
compute clustering with minibatchkmeans;4.5077343;-2.2118835;-0.79352313;-2.6043565;-0.7512333;1.942242;-
establishing parity between clusters;3.6900318;0.09384509;-0.37946004;-0.9002487;3.1829247;0.6188184;-
we want to have the same color for the same cluster from both the;0.8532708;-1.2064658;3.3140213;-1.8175042;2.90578;3.5174503;CODE
minibatchkmeans and the kmeans algorithm let s pair the cluster centers per;2.944837;-1.3890435;0.20009676;-2.8871288;-0.85216844;2.5977824;CODE
closest one;-0.013899388;-0.580992;5.5254307;0.57267123;0.87948257;-2.3286054;CODE
plotting the results;2.7824183;0.35010907;8.162847;-4.9284263;-5.283578;-4.731769;IRRE
colors 4eacc5 ff9c34 4e9a06;-3.2242298;-0.88209325;0.030057007;-4.247699;2.3546817;-1.4713743;-
kmeans;-0.24878097;-2.5706186;3.923046;-2.1589222;-0.4025893;-0.94316924;-
minibatchkmeans;-0.027570518;-3.2839143;2.7758482;-1.4953896;-0.24366143;-1.1523558;-
initialize the different array to all false;-0.44843546;7.621553;1.6513315;0.43302852;0.68551856;-0.79439336;IRRE
ax plot x identical 0 x identical 1 w markerfacecolor bbbbbb marker;0.78297734;3.2341883;-0.11028121;-7.1100545;-1.8321719;1.1880225;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
run the fit;0.7230935;1.4304996;2.185687;1.140989;-1.2081004;-0.2503435;CODE
reachability plot;1.2411368;-1.3693297;6.239643;-0.43630618;-3.7468283;-0.19611149;-
optics;-0.57431513;-2.9392784;5.8530264;-0.14222631;-1.9433448;-0.58050084;-
dbscan at 0 5;0.46890795;1.1329309;-0.9611746;-3.530314;-0.18044487;-0.9856125;-
dbscan at 2;0.8393012;-1.2953504;1.2816797;-3.1218967;2.2720387;-1.198887;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate the data;4.332126;-0.83362067;4.90541;-3.0842018;2.5492842;-5.028516;-
plotting four circles;-0.042810712;0.42544144;6.2055016;-4.363643;-3.7294686;-0.55727226;-
we use a mask that limits to the foreground the problem that we are;0.08909166;-0.94386876;4.437253;1.4957227;-0.18944278;2.6916616;CODE
interested in here is not separating the objects from the background;-2.502238;-2.939315;6.9823723;-0.69130635;1.0502084;2.5931122;CODE
but separating them one from the other;-0.7860167;0.47790056;4.353989;-0.66150224;3.2742798;0.49481836;META
convert the image into a graph with the value of the gradient on the;2.414571;-1.1643856;5.299618;-4.1225996;-1.9538952;2.0618095;IRRE
edges;0.068448044;-1.8736738;6.8949966;-2.8999848;1.1524712;-0.009214684;-
take a decreasing function of the gradient resulting in a segmentation;2.8237126;-0.30855504;1.6400312;-0.5456456;-1.6651733;4.544365;IRRE
that is close to a voronoi partition;2.0799787;-1.287216;3.6901839;-4.4537163;0.44091952;1.7692633;IRRE
here we perform spectral clustering using the arpack solver since amg is;4.9592075;-2.662449;-2.5124526;-3.048849;-0.56479305;3.7911115;CODE
numerically unstable on this example we then plot the results;3.455698;2.9618185;1.4530615;-2.2586884;-5.9850035;-1.6552008;IRRE
plotting two circles;-0.55546886;0.49236533;6.154319;-3.138664;-4.903403;-0.27239046;-
here we repeat the above process but only consider the first two circles;-0.54241526;2.0446353;4.812867;-1.8857442;-0.8613752;-0.03463851;META
we generated note that this results in a cleaner separation between the;-1.959657;-1.5470579;1.390366;0.80816954;1.8243866;1.5927273;TASK
circles as the region sizes are easier to balance in this case;0.62143505;1.4249725;5.296241;-2.3029404;-1.1514586;1.651143;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate the swiss roll dataset;3.2985275;-2.2895503;0.5083362;-2.541022;0.39780974;-1.640854;IRRE
x1 1 0 5 make the roll thinner;0.20094734;2.216904;1.2400149;-5.84418;-0.9745329;-0.76719844;-
compute clustering without connectivity constraints;5.034216;-0.5756653;0.42017996;-2.2172446;1.390272;3.234988;CODE
plot unstructured clustering result;5.327215;-2.1780283;2.307663;-5.557595;-2.5729258;1.615489;IRRE
compute clustering with connectivity constraints;4.5618563;-0.9275108;0.40180805;-2.2463303;1.7587827;2.9160805;CODE
plot structured clustering result;5.6151586;-1.2873877;2.8489268;-4.841814;-2.4332886;1.6667963;IRRE
generate 2d spiral dataset;3.782101;-3.5278275;3.8848138;-5.2627063;-2.6834614;0.34749275;IRRE
capture local connectivity using a graph;2.3643177;-0.8613507;4.239307;-0.9633105;-1.1426015;1.5804285;-
larger number of neighbors will give more homogeneous clusters to;3.9853852;-1.6568768;0.9682941;-1.9486326;0.8704196;3.1015162;-
the cost of computation time a very large number of neighbors gives;5.3553257;-3.1227858;0.9176703;0.07787961;-0.7461089;0.4513756;-
more evenly distributed cluster sizes but may not impose the local;4.857519;0.93611985;-0.060994186;-0.80699766;1.1482245;5.2034416;META
manifold structure of the data;4.2881637;-2.6648858;2.7857666;-4.3472724;1.3012264;3.420526;CODE
plot clustering with and without structure;4.782192;-0.21831422;4.042039;-4.8473573;-2.1232932;2.5196238;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
20 newsgroups dataset;3.2984202;-2.8501842;3.1541846;-0.17639764;2.2133944;-0.58418775;IRRE
we will use the ref 20 newsgroups dataset 20newsgroups dataset which;0.58325464;-3.8010337;1.5885174;0.77988446;2.1879506;1.2303891;IRRE
comprises posts from newsgroups on 20 topics this dataset is split;2.924139;-1.795908;3.368098;-0.10450669;2.5855765;0.10391851;CODE
into train and test subsets based on messages posted before and after;3.698929;1.7823815;1.091451;5.005444;4.4408827;-2.3166728;CODE
a specific date we will only use posts from 2 categories to speed up running;1.4150251;-1.0739179;2.373557;2.86776;2.4556148;1.484917;CODE
time;-1.6567879;-2.739283;6.915778;0.42322037;-0.4083046;-2.2269478;-
each feature comprises meta information about that post such as the subject;-0.94051397;-5.511741;2.7129085;0.93521386;3.9007041;1.0466877;TASK
and the body of the news post;-3.3169827;-2.495917;4.2094574;2.6896756;0.6265099;0.6883003;CODE
creating transformers;-1.3486384;-2.0675867;4.5518293;-2.01826;0.79342014;0.3403058;CODE
first we would like a transformer that extracts the subject and;-0.82118773;-4.0911717;5.033229;-0.30004597;1.8850057;1.0762483;CODE
body of each post since this is a stateless transformation does not;-3.483876;3.1769395;2.9897227;0.0061275396;0.7687637;2.2589529;CODE
require state information from training data we can define a function that;4.1741276;-1.0914949;0.85912395;2.7120657;3.8198664;1.617623;CODE
performs the data transformation then use;3.3354857;0.57196885;2.2557793;-1.7083929;0.97491294;1.9955617;CODE
class sklearn preprocessing functiontransformer to create a scikit learn;1.0661285;-8.076993;-5.5889335;-0.6495753;-2.5620115;-1.7817595;CODE
transformer;-1.4245996;-1.5366583;5.2588625;-2.0365984;-0.047867265;-0.22808374;CODE
construct object dtype array with two columns;2.8473647;-0.15071358;-2.261951;-5.3442845;1.3291854;-1.1277703;CODE
first column subject and second column body;-0.96625346;1.6474203;2.5150912;-3.8747044;1.7751946;-0.7944919;-
temporary variable stores n n;-1.0913152;2.661003;1.0892617;-1.8478075;0.5605344;-3.262124;IRRE
store body text in second column;-0.11408141;1.8022352;4.569256;-3.2107809;0.9956713;0.39439964;-
save text after subject in first column;-1.8203481;2.0100775;3.6649652;-1.3333625;0.93766415;-0.6107354;CODE
we will also create a transformer that extracts the;-1.5873036;-2.7605617;2.9865072;-0.33147755;1.2279755;2.6598678;IRRE
length of the text and the number of sentences;-0.83579624;-0.22728826;3.58335;0.7794979;2.1480305;-3.6140285;-
classification pipeline;4.9405518;-6.5906534;0.39661905;1.7400354;5.3595486;-0.14851099;CODE
the pipeline below extracts the subject and body from each post using;-1.8239192;-0.7467051;2.484615;0.50945175;2.7211862;-0.73860866;CODE
subjectbodyextractor producing a n samples 2 array this array is;1.3699529;2.9838946;0.23832187;-2.664088;1.1943352;-1.3208824;CODE
then used to compute standard bag of words features for the subject and body;1.2300072;-4.609229;-0.08469591;-0.120657206;3.3127055;-2.018522;TASK
as well as text length and number of sentences on the body using;-0.49817753;-2.9414985;4.119873;0.2536125;2.5865655;-1.8875843;-
columntransformer we combine them with weights then train a;5.6990232;-0.84013677;0.86530006;-1.4265217;2.3564007;1.4891845;CODE
classifier on the combined set of features;5.0241156;-4.381246;0.7644897;0.48397124;6.4331493;0.49704078;IRRE
extract subject body;-1.9072202;-0.56893307;2.2215555;0.6903263;2.4253595;-0.21627155;-
use columntransformer to combine the subject and body features;0.11696893;-0.22151192;1.4311503;-1.3818523;1.788023;1.9883419;TASK
bag of words for subject col 0;1.1883353;-2.3820162;0.82317024;-1.6673506;3.5533874;-3.2706304;CODE
bag of words with decomposition for body col 1;2.282542;-1.497705;1.4408119;-2.8559594;2.6335618;-1.6928941;CODE
pipeline for pulling text stats from post s body;1.3321497;0.6396695;1.8619419;1.4724733;0.7213651;-1.1170708;CODE
returns a list of dicts;-0.2418863;-0.08069389;1.0964751;-0.440527;0.81635237;-3.010334;IRRE
list of dicts feature matrix;2.3349502;-3.0577757;-0.16208625;-4.9511075;0.8782096;-0.073540464;TASK
weight above columntransformer features;3.5965798;-0.2411489;-1.8894888;-2.513094;-0.43467757;4.6595936;TASK
use a svc classifier on the combined features;4.2676005;-3.8103087;-1.110741;-0.52178353;4.7920847;1.4294611;TASK
finally we fit our pipeline on the training data and use it to predict;4.8620043;-6.132441;1.2168548;5.3657026;1.3425967;0.36517587;CODE
topics for x test performance metrics of our pipeline are then printed;2.2361555;-2.5560415;-1.1467403;4.784257;0.4805732;-1.0886219;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load data from https www openml org d 40945;-3.26196;0.083056696;0.8874819;-1.0322462;-0.4502604;0.51625526;CODE
alternatively x and y can be obtained directly from the frame attribute;-0.74868774;0.9231306;2.0814016;-4.845781;-0.9391055;2.393663;META
x titanic frame drop survived axis 1;-1.5432014;0.8634936;1.0131733;-1.3334515;-4.3409386;1.7576195;-
y titanic frame survived;-2.3263705;-0.6725909;2.2678654;-0.49952513;-3.1084244;-0.37263265;-
use columntransformer by selecting column by names;1.8575093;0.7316779;-0.74607366;-2.8063972;2.1633651;0.8433923;CODE
we will train our classifier with the following features;3.775215;-4.673227;2.0386076;1.8652667;5.512183;-2.3784184;TASK
numeric features;5.6971216;-2.156077;0.9648183;-4.8339868;2.4415224;-2.624352;TASK
age float;-0.86300504;1.3446978;2.0519607;-2.1349282;-2.0622857;-2.2985487;CODE
fare float;-0.300047;1.3994606;4.2850866;-2.4186394;-1.7133;-3.227054;CODE
categorical features;3.0647922;-4.9467726;3.0004318;-1.7614312;3.929344;-2.221263;TASK
embarked categories encoded as strings c s q;-1.9746627;-1.4569579;0.0039456426;-1.5713595;4.1196737;-1.4714416;IRRE
sex categories encoded as strings female male;-0.6886159;-1.8041449;0.61610824;-2.6371527;2.7719438;-2.2026865;CODE
pclass ordinal integers 1 2 3;-1.3998481;0.13043962;-0.6446099;-6.0097218;4.573539;-3.3427868;CODE
we create the preprocessing pipelines for both numeric and categorical data;3.7604687;-3.184189;-0.8336792;-1.0614266;3.5471737;-0.8561225;CODE
note that pclass could either be treated as a categorical or numeric;2.0365624;-2.557046;-2.3414526;-1.9267735;4.9849434;-2.3433235;TASK
feature;0.43510035;-4.377278;5.305932;2.7540402;2.9616945;-1.2993188;TASK
append classifier to preprocessing pipeline;0.6073478;-3.1709812;-2.044973;2.6492207;3.8626325;1.5648153;CODE
now we have a full prediction pipeline;3.6343396;-4.6990566;2.5563102;6.2817826;1.0885222;0.8184538;CODE
html representation of pipeline display diagram;-2.9921591;-2.4913173;4.5835876;-3.0414104;1.1177986;2.7474003;CODE
when the pipeline is printed out in a jupyter notebook an html;-3.272971;-1.8416474;1.2724481;1.0231873;-2.492227;1.0114592;CODE
representation of the estimator is displayed;1.0025373;0.46160653;1.8249874;-1.4450481;-2.7799723;2.6651492;-
use columntransformer by selecting column by data types;2.7528164;0.97678834;-2.6266348;-2.811874;1.4655569;1.2977926;CODE
when dealing with a cleaned dataset the preprocessing can be automatic by;1.6475728;-1.0026804;-3.2924988;2.9481082;2.124657;1.2831638;TASK
using the data types of the column to decide whether to treat a column as a;3.8160355;2.946006;-0.94671893;-1.6807795;3.250594;-2.7031796;-
numerical or categorical feature;3.989776;-1.4975122;1.1205994;-2.8052554;3.6043983;-2.5561714;TASK
func sklearn compose make column selector gives this possibility;-0.13667771;-2.8235486;-2.6051428;-1.6135542;0.04070444;0.39394057;CODE
first let s only select a subset of columns to simplify our;3.7514288;0.880458;2.4769084;-3.5098872;3.3916945;-1.895316;CODE
example;-1.5896981;-3.407836;5.9375143;2.0448067;1.7390331;-1.9561437;-
then we introspect the information regarding each column data type;4.4240236;-1.7531152;-0.3969245;-2.231517;4.3692474;-1.068382;CODE
we can observe that the embarked and sex columns were tagged as;-1.2798043;-1.42552;2.223592;0.9683675;3.7990804;1.1355424;IRRE
category columns when loading the data with fetch openml therefore we;-0.7193593;-1.2849525;1.0251802;0.8905712;2.103769;1.7325357;CODE
can use this information to dispatch the categorical columns to the;2.7555664;-1.9882689;0.6314294;-2.5651603;5.155034;-0.026487838;CODE
categorical transformer and the remaining columns to the;2.284403;-0.94686294;1.0015206;-5.343481;1.8517953;0.7682854;CODE
numerical transformer;2.4168005;0.036788974;1.3738028;-4.6975236;-0.8823104;0.3715964;CODE
note in practice you will have to handle yourself the column data type;3.5902593;-0.7457892;0.35498726;-3.1399684;4.1458397;-0.10753022;TASK
if you want some columns to be considered as category you will have to;-0.42376292;-2.795943;0.032129608;-2.2858777;3.695196;1.0999256;-
convert them into categorical columns if you are using pandas you can;3.3734562;-2.3765535;0.9426259;-6.0062423;0.22806524;-2.759751;CODE
refer to their documentation regarding categorical data;0.6069991;-6.4915886;-0.22356512;-0.804369;3.029814;-2.1255608;CODE
https pandas pydata org pandas docs stable user guide categorical html;-2.3265345;-5.0065002;-2.987057;-3.1393163;-2.444267;-0.56807595;CODE
the resulting score is not exactly the same as the one from the previous;1.9162475;4.4854937;0.9827041;0.94672364;-1.3145216;-3.6966605;TASK
pipeline because the dtype based selector treats the pclass column as;0.66665006;-1.6610312;-5.786106;-0.74100477;2.2704906;0.67622876;CODE
a numeric feature instead of a categorical feature as previously;1.4212871;-0.9132675;-1.116501;-1.8939285;1.875294;0.004467979;TASK
using the prediction pipeline in a grid search;6.442007;-2.1500423;0.9095376;2.6413875;1.831358;0.9199039;CODE
grid search can also be performed on the different preprocessing steps;2.009041;-0.41653326;1.3346626;-0.85596246;2.5629945;2.0347598;CODE
defined in the columntransformer object together with the classifier s;2.0933006;-1.9100959;-2.8075888;-1.8651345;3.9295924;1.4989339;CODE
hyperparameters as part of the pipeline;1.9428945;-2.1918762;-0.24827792;4.2102404;2.9380481;3.0061173;IRRE
we will search for both the imputer strategy of the numeric preprocessing;1.6419356;-1.6068788;-1.703942;0.40382743;2.1897;-2.104082;CODE
and the regularization parameter of the logistic regression using;4.5182323;-4.1270595;-0.47486547;1.9859952;1.0539061;3.125175;IRRE
class sklearn model selection randomizedsearchcv this;4.630974;-5.116299;-5.0544434;2.0968134;1.148138;0.27572688;CODE
hyperparameter search randomly selects a fixed number of parameter;2.1752408;2.2541478;-1.6458505;2.9491751;0.76787525;-0.060710296;IRRE
settings configured by n iter alternatively one can use;-3.5323489;-0.9478076;2.0824335;-0.9500784;1.1661596;3.981514;IRRE
class sklearn model selection gridsearchcv but the cartesian product of;4.286399;-3.867222;-5.205785;-2.4219031;0.52571994;0.56243753;CODE
the parameter space will be evaluated;-0.97956103;3.0411289;-0.57354;-0.20229979;2.6044686;0.57412404;IRRE
calling fit triggers the cross validated search for the best;4.9217453;2.790377;-3.8838212;5.3054833;1.4849739;0.93057966;IRRE
hyper parameters combination;2.6452549;1.1213403;0.3818029;-2.619568;2.8027024;1.4324826;IRRE
the internal cross validation scores obtained by those parameters is;1.9949217;0.13281168;-1.6928138;1.0558376;2.0391562;-1.058729;IRRE
we can also introspect the top grid search results as a pandas dataframe;3.8009906;-3.5216303;1.6266963;-1.5617727;-1.568294;1.1732044;IRRE
the best hyper parameters have be used to re fit a final model on the full;3.3809133;-1.7713971;-0.9099959;2.76939;1.1565393;4.358442;IRRE
training set we can evaluate that final model on held out test data that was;4.408817;-0.40447876;0.2658833;6.9528546;2.6911123;-2.974454;CODE
not used for hyperparameter tuning;1.0693324;-1.2750461;-1.453674;2.3881147;0.111724906;1.0925463;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
illustration of pipeline and gridsearchcv;3.4076037;-3.7997663;1.8284794;-2.2378013;-1.4759617;2.0611565;CODE
the reduce dim stage is populated by the param grid;1.5942914;0.38920596;0.9935204;-2.3880715;-0.7349935;4.3758736;-
scores are in the order of param grid iteration which is alphabetical;3.7411008;1.5122528;1.460657;-2.5917995;1.5832999;-2.2979133;CODE
select score for best c;3.7482479;1.879863;1.8132503;-1.0428947;1.7630367;-4.931565;CODE
create a dataframe to ease plotting;3.257386;-2.8727162;6.0992312;-4.7152243;-5.0490894;-0.5440018;IRRE
caching transformers within a pipeline;-0.8685599;0.96677476;0.610915;3.0515668;0.066840746;4.1788135;CODE
it is sometimes worthwhile storing the state of a specific transformer;-0.666095;0.94797575;0.63922626;1.7587391;1.2561544;4.7022934;CODE
since it could be used again using a pipeline in gridsearchcv triggers;-1.1058205;-0.62804455;-2.4800966;3.1678433;-0.5691794;2.8326292;CODE
such situations therefore we use the argument memory to enable caching;-2.8926265;-0.16910698;1.0327393;4.223433;1.5552067;3.61158;IRRE
warning;-3.0231862;-0.29702285;2.0558126;3.4345493;-1.4731644;-1.9746032;-
note that this example is however only an illustration since for this;0.22245453;-1.3315351;5.5397916;-2.6057222;-0.27881598;3.2070034;CODE
specific case fitting pca is not necessarily slower than loading the;2.996094;1.0500579;-2.9619393;-0.24666357;-0.7387099;4.4612594;CODE
cache hence use the memory constructor parameter when the fitting;2.0221016;2.216922;-3.4614007;1.7096643;-0.01275372;5.2577195;IRRE
of a transformer is costly;-0.078462206;-0.7955568;3.3338797;1.1509691;0.12537041;2.3146145;CODE
create a temporary folder to store the transformers of the pipeline;-2.2585297;-1.2756472;0.89601797;1.9010366;1.0882126;3.7672737;CODE
this time a cached pipeline will be used within the grid search;-0.17436235;-0.6469394;-0.44228724;4.0253577;0.91429526;4.6339817;CODE
delete the temporary cache before exiting;-4.2884684;2.8023522;1.4708893;2.3355563;-1.8153547;2.6242013;CODE
the pca fitting is only computed at the evaluation of the first;3.809165;0.8498934;-3.6359954;-1.3831959;-2.7623718;2.8079598;-
configuration of the c parameter of the linearsvc classifier the;1.8972739;-1.7264136;-2.9223096;-3.574403;0.64339894;3.4041767;IRRE
other configurations of c will trigger the loading of the cached pca;-0.52645206;-0.26275083;-0.9329252;0.28449625;-0.023722347;4.769328;CODE
estimator data leading to save processing time therefore the use of;3.1559079;-1.1929092;2.4678266;4.457845;-0.65305275;4.0418425;CODE
caching the pipeline using memory is highly beneficial when fitting;1.9222394;-1.1771748;-0.8107886;3.2860153;-0.94180304;4.3072677;CODE
a transformer is costly;-0.040510323;-0.80787206;3.6361487;1.0042348;-0.22199592;2.1597629;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
define a pipeline to search for the best combination of pca truncation;5.570929;-0.035988886;-1.116128;-0.15204042;3.3314855;3.218718;CODE
and classifier regularization;4.966222;-5.1922727;-0.35069454;2.5075264;4.844064;2.4269037;IRRE
define a standard scaler to normalize inputs;4.267353;0.6492586;0.809355;-4.1667933;-0.31459802;4.5956817;CODE
set the tolerance to a large value to make the example faster;4.479349;3.7977722;0.8043724;2.315088;-1.5509769;-0.011941895;IRRE
parameters of pipelines can be set using separated parameter names;-0.6937274;1.4045773;-2.2412682;0.8933324;2.4860923;4.1537037;IRRE
plot the pca spectrum;3.0515754;-1.8521885;2.3051286;-6.046039;-3.9404678;1.3285648;-
for each number of components find the best classifier results;6.308254;-2.368585;0.9769437;-1.0661653;5.90265;-2.0298486;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this dataset is way too high dimensional better do pca;5.817445;-2.3925905;-1.6725005;-3.9695933;0.2879217;2.1521697;CODE
maybe some original features were good too;-1.0606097;-3.401601;1.0481275;1.4494938;-1.6219672;3.1087022;TASK
build estimator from pca and univariate selection;5.4246035;-2.1147895;-1.4172331;0.86094123;1.3404155;3.6759737;CODE
use combined features to transform dataset;5.0162525;-3.137311;1.5330453;-2.1930192;2.9172966;2.4025617;TASK
do grid search over k n components and c;4.528719;-0.5249836;0.23315804;-4.35185;1.4683721;0.8038067;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
synthetic example;-0.105451316;-1.2500681;1.7862746;-0.33663327;1.4164488;-1.6848563;-
a synthetic random regression dataset is generated the targets y are;4.5300465;-2.3355844;-0.35898274;1.5352901;-1.4680593;-0.17399044;IRRE
modified by;-2.1710038;-2.2363017;3.1775198;1.6781155;0.6797185;-2.4190276;-
1 translating all targets such that all entries are;0.3481326;2.471174;0.11016872;-0.5465846;3.4532566;-0.96670365;-
non negative by adding the absolute value of the lowest y and;-0.12798116;2.8522475;2.364836;-4.7862;-3.4209478;-1.926336;TASK
2 applying an exponential function to obtain non linear;-1.2373146;1.4572843;2.2932675;-1.9392222;-2.0813007;-1.0064139;CODE
targets which cannot be fitted using a simple linear model;4.30373;1.8599288;-0.33527714;0.47427613;-2.302372;1.8214126;-
therefore a logarithmic np log1p and an exponential function;-1.9600229;0.53737736;-0.06355513;-2.3489432;-0.33071682;-0.5951146;CODE
np expm1 will be used to transform the targets before training a linear;2.729626;-1.6706522;-2.755286;-1.2749666;-2.7871535;4.333888;CODE
regression model and using it for prediction;2.080673;-2.5744843;4.1917644;4.166639;-0.99623215;-0.6470428;CODE
below we plot the probability density functions of the target;0.57709235;-1.8533037;4.7405286;-1.144085;-3.6140263;1.6584262;CODE
before and after applying the logarithmic functions;-3.3731458;1.4391494;1.609902;0.83631605;-0.651531;-0.5803367;CODE
at first a linear model will be applied on the original targets due to the;2.601516;-0.7093695;2.4006875;2.9695742;-0.7622195;3.685955;CODE
non linearity the model trained will not be precise during;3.4947982;0.2358602;-1.4991621;3.3508952;-3.4070542;0.96156144;-
prediction subsequently a logarithmic function is used to linearize the;5.0138597;-1.5509338;0.58965737;1.0252799;-1.9587915;1.6184753;OUTD
targets allowing better prediction even with a similar linear model as;5.0858088;-1.4904337;0.5753503;4.2785697;-0.7652771;3.8417044;-
reported by the median absolute error medae;3.0604248;1.8284028;-2.404547;0.6030105;-3.2176054;-0.7101323;-
add the score in the legend of each axis;1.4655097;1.0615519;5.1839466;-4.2835097;-1.8861003;0.18998206;CODE
real world data set;6.101225;-2.8244176;3.966298;-2.9170132;2.2390068;-1.517546;IRRE
in a similar manner the ames housing data set is used to show the impact;1.5079142;-2.0428092;2.5293624;1.2016101;0.02465636;0.021041647;IRRE
of transforming the targets before learning a model in this example the;2.3701534;-2.563627;3.2208853;3.3470068;0.02186023;1.0191042;CODE
target to be predicted is the selling price of each house;1.9693038;-1.0543387;2.998793;3.7944117;0.8550589;0.1012025;-
keep only numeric columns;4.4223857;3.1207182;1.0272793;-4.9138627;-0.012958993;-0.67158157;-
remove columns with nan or inf values;3.3787792;4.3870797;-1.1316605;-4.025615;-2.1658201;-1.6672741;IRRE
let the price be in k;-0.31555974;0.20168526;3.4437892;-1.7623993;-0.27531442;-1.7286619;CODE
a class sklearn preprocessing quantiletransformer is used to normalize;4.2311845;-3.5476654;-3.1449351;-2.4069839;-1.439566;1.7050794;CODE
the target distribution before applying a;0.83431196;1.8192126;1.4923241;3.9743843;1.3595288;0.83845365;META
class sklearn linear model ridgecv model;3.1575825;-4.9436383;-4.8735027;-2.5525992;-2.5705457;2.045627;IRRE
the effect of the transformer is weaker than on the synthetic data however;2.8039696;-1.3270377;-0.75138634;0.4231426;-2.6165159;1.9501983;CODE
the transformation results in an increase in math r 2 and large decrease;1.6289527;0.42656144;0.5487386;-2.493609;-5.524213;2.362097;IRRE
of the medae the residual plot predicted target true target vs predicted;2.0658286;0.09622454;0.5982116;3.399438;-4.8103056;1.1109878;-
target without target transformation takes on a curved reverse smile;-0.9246192;0.46685037;0.2133069;-0.91277367;-2.7024314;3.6109076;CODE
shape due to residual values that vary depending on the value of predicted;5.4851255;2.9438229;1.9522423;-0.24063702;-3.433465;3.3739522;IRRE
target with target transformation the shape is more linear indicating;2.3662684;0.62961507;1.6575447;-2.1476617;-3.5157459;3.2493174;CODE
better model fit;2.7521918;-1.498626;3.1949947;1.2132121;-0.005433793;0.98778534;-
plot the actual vs predicted values;3.7931926;0.20742363;3.8275363;-0.17970598;-6.185136;-1.6299607;IRRE
add the score in the legend of each axis;1.4655095;1.0615517;5.1839466;-4.2835097;-1.8861004;0.18998392;CODE
plot the residuals vs the predicted values;2.0430496;1.057065;3.9815066;0.30217397;-6.4956713;0.27432793;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
color samples;4.090205;-1.9263263;3.732512;-0.9457715;2.2906377;-3.6410213;-
compute the likelihood on test data;3.258511;2.9089024;0.45642975;1.4743669;-0.35508534;-3.1879315;CODE
spanning a range of possible shrinkage coefficient values;7.2549243;1.4734945;-0.29515392;-2.5704958;0.10166154;3.5629277;IRRE
under the ground truth model which we would not have access to in real;-0.06866053;-1.7112734;0.35855594;4.047877;0.7188844;1.3205622;-
settings;-4.2340403;-1.8681971;6.994803;0.2633829;-1.2244998;1.7592822;IRRE
compare different approaches to setting the regularization parameter;4.394093;1.1083429;-2.094068;1.7219399;0.24460594;5.59164;IRRE
here we compare 3 approaches;1.3503227;-0.16758573;4.806787;2.8617203;2.4590561;-1.5378315;IRRE
setting the parameter by cross validating the likelihood on three folds;2.103925;2.8447363;-1.4382552;0.29462248;1.2396119;2.1450915;IRRE
according to a grid of potential shrinkage parameters;6.3612003;-0.044263486;0.1511479;-2.7897732;-2.1940858;5.764702;IRRE
a close formula proposed by ledoit and wolf to compute;2.3441007;-0.18852238;-0.2283324;-2.6389163;1.04612;-1.2514148;CODE
the asymptotically optimal regularization parameter minimizing a mse;5.072996;-0.39473295;-2.5539572;1.2922684;0.06257222;6.383536;IRRE
criterion yielding the class sklearn covariance ledoitwolf;3.0196774;-3.6752326;-6.234737;0.8841484;-0.2327244;1.0309808;CODE
covariance estimate;1.4119134;-0.59836596;0.18311137;0.6813299;-2.7082484;3.465374;CODE
an improvement of the ledoit wolf shrinkage the;-2.315748;-2.4194357;1.2581652;1.3663514;-0.86439794;0.60388625;TASK
class sklearn covariance oas proposed by chen et al 1 its;2.8367414;-5.8150024;-6.2054358;-0.035658296;0.4520043;2.2332199;CODE
convergence is significantly better under the assumption that the data;5.83955;0.6705317;-0.11918629;5.6546016;-1.5716587;3.1856184;CODE
are gaussian in particular for small samples;4.4967575;0.3942192;-0.380125;-1.2453258;-1.1359977;2.520342;CODE
gridsearch for an optimal shrinkage coefficient;7.385659;-1.7643964;-0.6188528;-0.89929634;0.4974355;4.7615676;CODE
ledoit wolf optimal shrinkage coefficient estimate;3.6045089;-2.3172941;-1.899778;-0.15966457;-1.1146437;4.268888;IRRE
oas coefficient estimate;2.1128008;0.8404452;-0.37617877;0.021301094;-0.87957054;2.345971;IRRE
plot results;2.7280965;0.63260704;7.251219;-4.383265;-6.2113085;-4.720718;IRRE
to quantify estimation error we plot the likelihood of unseen data for;6.0605707;0.0030914345;1.6951598;1.7558113;-3.1992743;0.95897263;CODE
different values of the shrinkage parameter we also show the choices by;4.419912;1.2440695;-0.62272274;-1.2585613;0.28136024;2.8164396;IRRE
cross validation or with the ledoitwolf and oas estimates;3.3024547;-0.31912103;-1.8062842;4.0610414;1.7874892;0.7618375;CODE
range shrinkage curve;5.239556;0.72821987;1.5623349;-3.3126793;-4.1899986;3.3092604;-
adjust view;-2.0319548;-0.8816636;5.713023;-2.7824793;-2.6124809;4.2780614;-
lw likelihood;2.2173355;-0.07775024;2.4553974;1.5517849;1.1227914;-0.046487287;-
oas likelihood;2.4147837;0.95523876;0.72193885;1.744863;1.7279582;1.4997271;-
best cv estimator likelihood;4.128553;-1.3123666;-0.75570714;3.1253955;-0.41359094;2.695261;-
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
the maximum likelihood estimate corresponds to no shrinkage;2.100907;0.8115944;-2.2099478;1.6986059;-3.070108;6.126555;-
and thus performs poorly the ledoit wolf estimate performs really well;1.3228937;-1.1580521;-2.0621998;2.7489333;-2.636282;0.058898732;CODE
as it is close to the optimal and is not computationally costly in this;4.895296;-1.7000152;1.369991;0.23350535;1.7121061;3.2272334;CODE
example the oas estimate is a bit further away interestingly both;2.3383484;-1.721127;0.37840432;2.617819;-0.11211278;3.1713748;CODE
approaches outperform cross validation which is significantly most;4.8650346;-0.8538335;-0.13629544;5.5242844;1.9219854;-0.67086244;CODE
computationally costly;3.4904292;-4.104542;2.4238434;1.4224334;0.64104766;-0.5456956;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
simulation covariance matrix ar 1 process;1.7095411;-0.7947022;-1.7728554;0.10483191;-3.4799616;4.07155;CODE
plot mse;1.0845809;-1.2806903;3.692832;-2.6342611;-4.920451;-0.66566426;-
plot shrinkage coefficient;4.533292;-0.7488937;2.7054415;-4.7531466;-6.177387;4.113195;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate data;3.5066168;-0.73323363;4.430809;-2.3223333;2.8341281;-3.9849672;-
first we generate a dataset of 125 samples and 2 features both features;5.355178;-3.5834827;0.93972033;-0.05111861;3.9009888;-2.480698;TASK
are gaussian distributed with mean of 0 but feature 1 has a standard;1.1288295;0.23618524;-2.7987401;-0.9451973;-1.3065879;3.2059803;META
deviation equal to 2 and feature 2 has a standard deviation equal to 1 next;3.2339056;0.6234047;-1.413587;-2.0118108;-0.17148846;-1.007119;TASK
25 samples are replaced with gaussian outlier samples where feature 1 has;4.9355054;1.533488;-2.5747883;-0.44541794;-2.0582607;-0.28600112;TASK
a standard deviation equal to 1 and feature 2 has a standard deviation equal;2.2437494;0.08750378;-1.9306002;-1.9099845;0.37421945;-0.501913;TASK
to 7;-1.2114124;-0.5733648;5.3320704;0.36329526;0.27109587;-2.3356802;-
for consistent results;4.1161995;0.7721928;3.4636676;5.7051244;1.4687917;-3.1240308;IRRE
generate gaussian data of shape 125 2;4.4750957;-1.2375448;0.4281034;-6.3741813;-2.2483613;0.68796915;-
add some outliers;4.5602713;-0.09494259;2.9461763;0.4609042;-0.23813012;-1.1692656;TASK
comparison of results;4.457239;3.0892997;3.471242;2.9429834;1.0474658;-6.3152866;IRRE
below we fit mcd and mle based covariance estimators to our data and print;4.7188854;-2.554283;-0.24806786;0.1397479;-0.40272954;3.1343255;CODE
the estimated covariance matrices note that the estimated variance of;2.676701;-2.7080314;-0.95805186;-0.13179177;-2.5861053;5.056601;CODE
feature 2 is much higher with the mle based estimator 7 5 than;2.7505004;-1.1056879;-3.1176949;3.2537599;-1.1432365;2.0976787;TASK
that of the mcd robust estimator 1 2 this shows that the mcd based;2.0519803;-1.0556964;-3.0915136;3.190127;-0.72996515;3.152986;IRRE
robust estimator is much more resistant to the outlier samples which were;4.0754957;0.8571599;-2.7256773;3.584025;-2.8002367;3.6928186;IRRE
designed to have a much larger variance in feature 2;2.509549;-2.334487;-2.107375;2.327451;-0.6875147;2.9784737;TASK
fit a mcd robust estimator to data;5.0806875;0.63453853;-2.156922;2.028896;-1.24238;4.4447517;IRRE
fit a mle estimator to data;3.5951133;0.9831694;1.1712573;1.4551917;-1.6015905;3.0393496;-
to better visualize the difference we plot contours of the;1.8210636;-1.9808437;7.049552;-3.5421476;-3.614322;1.5511652;-
mahalanobis distances calculated by both methods notice that the robust;5.68086;-0.877692;-2.441898;-1.1840206;-1.3525379;3.5485892;-
mcd based mahalanobis distances fit the inlier black points much better;5.7874737;-1.0331727;-2.728944;-1.981835;0.02382246;3.647295;CODE
whereas the mle based distances are more influenced by the outlier;5.362878;-0.3898923;-0.8508703;1.4403406;-0.8203806;3.7705805;-
red points;-0.23205698;-0.099569686;4.94627;-1.0111349;0.43593606;-2.5042725;CODE
plot data set;4.8350544;-0.39743453;6.3810797;-6.1377597;-3.6610541;-1.1927277;IRRE
create meshgrid of feature 1 and feature 2 values;1.5014374;1.0362498;0.20548385;-4.396544;0.780465;1.8030866;IRRE
calculate the mle based mahalanobis distances of the meshgrid;3.7994628;-0.013504048;-1.9748679;-3.527596;-1.8135343;3.2296395;-
calculate the mcd based mahalanobis distances;4.4291954;0.22479902;-1.5156333;-4.2076535;-0.07527409;1.4144529;-
add legend;-3.7498586;-0.7746504;6.0350156;-1.126947;-0.33275634;-0.9298985;TASK
finally we highlight the ability of mcd based mahalanobis distances to;4.2903757;-2.3518634;-0.7108861;-2.0764167;1.162843;2.7544324;CODE
distinguish outliers we take the cubic root of the mahalanobis distances;3.9401085;0.12330604;-1.457081;-2.2819433;0.2644336;0.4194716;-
yielding approximately normal distributions as suggested by wilson and;0.79501355;0.55572385;1.1761822;0.8194167;-2.127006;0.3708797;META
hilferty 2 then plot the values of inlier and outlier samples with;3.3934753;0.2870381;1.9604309;-4.218173;-4.7899833;0.08838844;IRRE
boxplots the distribution of outlier samples is more separated from the;4.223664;1.2229636;1.7427762;-3.0895443;-3.442806;2.3157544;META
distribution of inlier samples for robust mcd based mahalanobis distances;5.8989954;-0.13760996;-3.2004688;-1.0341777;-0.58706254;2.9105916;META
calculate cubic root of mle mahalanobis distances for samples;4.493432;-0.008193108;-2.8797438;-4.313706;-0.890705;1.0177923;CODE
plot boxplots;1.5660056;-0.7049772;5.1054783;-5.810396;-4.5187187;0.47607684;-
plot individual samples;5.8473434;-0.36606595;5.9867563;-4.4619317;-2.5291932;-1.4160756;-
calculate cubic root of mcd mahalanobis distances for samples;4.0408688;-0.021522647;-3.0882595;-4.804407;-1.0643532;0.41473654;CODE
plot boxplots;1.5660056;-0.7049772;5.1054783;-5.810396;-4.5187187;0.47607684;-
plot individual samples;5.8473434;-0.36606595;5.9867563;-4.4619317;-2.5291932;-1.4160756;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
example settings;-3.7010138;-2.9047792;4.544835;1.098162;1.2214457;1.9659005;IRRE
definition of arrays to store results;2.835564;0.96329045;2.143695;-0.2791292;2.8273542;-1.8877177;IRRE
computation;2.188828;0.9901763;4.913888;-3.88869;1.1389743;-5.677442;-
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
add some outliers;4.5602713;-0.09494207;2.9461758;0.46090418;-0.23813006;-1.1692652;TASK
fit a minimum covariance determinant mcd robust estimator to data;4.355178;-0.6006087;-3.867203;0.044565085;-1.7708683;5.37742;IRRE
compare raw robust estimates with the true location and covariance;4.347638;0.8780879;-1.3756535;2.1132095;-2.5514016;4.247005;IRRE
compare estimators learned from the full data set with true;6.3908243;1.5650215;-0.41238374;5.1931973;-0.69382256;0.4927492;IRRE
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
compare with an empirical covariance learned from a pure data set;7.1024537;-2.223077;-1.6608639;1.8662454;0.8182928;0.025449887;IRRE
i e perfect mcd;-1.3986282;-0.86385375;2.1001675;1.2676897;0.15078989;-0.138478;-
display results;0.059281107;1.8744851;5.8914366;-0.5908933;-0.20617604;-4.60396;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate the data;4.3321257;-0.83362;4.9054117;-3.0842;2.5492852;-5.028516;-
estimate the covariance;1.8572091;-0.47905052;0.26290876;0.84553474;-3.149123;3.361622;CODE
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
plot the covariances;1.1634763;-1.8379378;4.0613165;-3.4296014;-5.907078;1.2291396;CODE
plot the precisions;3.0656505;0.56690323;3.7070477;-3.5682836;-6.626071;-2.5042543;-
plot the model selection metric;4.9878407;-3.2203043;2.8315818;-0.83217454;-2.8459127;1.5194782;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
dataset based latent variables model;4.242092;-4.31764;1.8055599;0.5349317;2.3492088;1.7619183;IRRE
2 latents vars;-1.6809739;2.1398022;0.45711416;-1.1222461;1.3412384;-1.8868285;CODE
canonical symmetric pls;-1.7461212;-0.9961383;-1.7040341;-3.423995;3.1588848;0.99851227;-
transform data;5.3359632;0.043964665;4.1123137;-5.5684495;0.5092677;0.048991516;CODE
scatter plot of scores;5.8446007;-0.3560818;4.531508;-4.049987;-4.218869;-1.0120189;-
on diagonal plot x vs y scores on each components;4.445007;0.59649575;2.9693043;-5.081496;-2.7955787;1.2258617;-
off diagonal plot components 1 vs 2 for x and y;1.6077557;0.32728556;2.7277772;-6.789193;-3.905536;2.4654748;CODE
pls regression with multivariate response a k a pls2;1.908121;-0.8436754;-0.14820772;-1.66669;-2.364917;1.2518352;CODE
each yj 1 x1 2 x2 noize;4.0870585;2.2977867;2.2410963;-9.990867;-0.8908223;-0.93022305;-
compare pls2 coef with b;0.6487474;0.60176665;-2.1073203;-0.14801571;0.023246083;-1.7606925;IRRE
pls regression with univariate response a k a pls1;1.9391177;-0.11856844;-0.07463441;-1.0779446;-2.6156704;0.09648515;CODE
note that the number of components exceeds 1 the dimension of y;2.8338594;0.92351395;-0.09025157;-6.466624;-0.84384054;1.2194624;TASK
cca pls mode b with symmetric deflation;-0.89285994;1.3574848;-3.7404811;-2.904594;0.7662725;3.721028;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
the data;3.2368367;-2.6489253;6.994474;-0.047255095;1.1959476;-3.7521517;-
we start by creating a simple dataset with two features before we even dive;3.5992856;-5.0981503;2.2704563;0.67417467;3.4731433;0.065872386;CODE
into pcr and pls we fit a pca estimator to display the two principal;3.2131827;0.9316925;-0.7956318;-3.059807;0.09501604;3.1536531;IRRE
components of this dataset i e the two directions that explain the most;4.528837;-4.9872885;3.3378565;-1.693303;2.0241463;-0.13870157;CODE
variance in the data;3.244694;0.9725794;3.3249235;-0.9070786;-2.1852627;-1.5539228;CODE
comp comp var scale component by its variance explanation power;1.1116318;0.6839966;-1.4789034;-2.2733479;-1.6827428;3.565674;CODE
for the purpose of this example we now define the target y such that it is;-0.61232513;0.90540093;1.973357;2.0940058;0.69684476;1.8983585;CODE
strongly correlated with a direction that has a small variance to this end;2.2518551;1.241832;-0.10709024;0.6999604;-2.7454166;3.534213;CODE
we will project x onto the second component and add some noise to it;-0.72589475;-2.0539935;3.605126;-0.6258862;0.7914853;2.552799;TASK
projection on one component and predictive power;2.783933;-1.2813886;0.70638895;-0.0818035;0.5118428;5.1466236;-
we now create two regressors pcr and pls and for our illustration purposes;1.2049243;-1.5528977;1.8151213;-3.5731547;0.38174412;2.231114;IRRE
we set the number of components to 1 before feeding the data to the pca step;3.273846;0.53826034;-0.74959064;-2.6982298;3.0244267;4.044021;IRRE
of pcr we first standardize it as recommended by good practice the pls;-0.5535107;-0.72486156;-2.0617216;-0.20158291;1.5621445;2.9948494;CODE
estimator has built in scaling capabilities;3.8730643;-3.339627;1.9189273;3.7016754;-1.5200367;6.1923633;-
for both models we plot the projected data onto the first component against;3.462378;-2.0380864;3.5728552;0.3905339;-0.96130496;5.094154;CODE
the target in both cases this projected data is what the regressors will;1.7441885;0.0857004;1.5828341;0.9280468;-1.2303056;3.113214;CODE
use as training data;4.9695396;-5.116979;2.7646413;1.943108;4.3690653;-0.5966944;-
pca pcr named steps pca retrieve the pca step of the pipeline;-0.032227818;-0.8691627;-0.93624043;-1.3393728;1.563464;2.2047374;CODE
as expected the unsupervised pca transformation of pcr has dropped the;1.6960605;0.2075632;-3.3012831;-1.0895051;-2.2255406;3.6578503;CODE
second component i e the direction with the lowest variance despite;2.785136;1.5590428;0.1289353;-3.3900328;-0.43734547;3.5707817;CODE
it being the most predictive direction this is because pca is a completely;2.674498;-3.0484715;0.30042905;2.5802507;0.54667616;3.1100395;CODE
unsupervised transformation and results in the projected data having a low;5.789822;0.34839252;-0.833291;-1.5267698;-2.0470755;4.504648;CODE
predictive power on the target;3.441469;-1.8186514;1.9907905;5.0381618;-0.06314375;1.3573833;-
on the other hand the pls regressor manages to capture the effect of the;-0.12651584;0.6967247;1.0560883;1.9714094;-2.166672;3.555292;-
direction with the lowest variance thanks to its use of target information;4.2854114;-0.902089;2.3804555;-0.0019518106;0.5425294;3.593636;CODE
during the transformation it can recognize that this direction is actually;-0.5349839;-0.9400446;2.1413398;-0.9626524;-2.195635;3.2695072;CODE
the most predictive we note that the first pls component is negatively;-0.09998333;-0.06958135;-0.3480348;0.51965415;-1.0747925;0.8206855;TASK
correlated with the target which comes from the fact that the signs of;1.6966958;1.2384465;3.054842;2.7958648;-0.55176926;0.538876;CODE
eigenvectors are arbitrary;0.07736888;-2.1154826;-2.62793;-2.179069;1.0328623;4.9210086;-
we also print the r squared scores of both estimators which further confirms;1.666987;-0.5521019;-0.98232955;1.8630216;-1.9091823;0.36367744;CODE
that pls is a better alternative than pcr in this case a negative r squared;1.480474;1.0570664;-1.1508737;-2.094223;-0.96154356;0.5687562;CODE
indicates that pcr performs worse than a regressor that would simply predict;2.365439;0.5443358;-1.777958;1.3362051;-2.8414402;-0.0389605;IRRE
the mean of the target;1.7322887;0.51781356;5.07604;3.342104;-1.6677554;0.2153972;-
as a final remark we note that pcr with 2 components performs as well as;1.261102;-1.0586885;-2.0521252;-0.13484693;1.6817806;2.7731454;CODE
pls this is because in this case pcr was able to leverage the second;-2.0305014;0.61022;-0.8241009;1.2878777;0.36965674;2.6263652;CODE
component which has the most preditive power on the target;-1.4426461;-1.2567322;4.3963513;1.1031867;2.5178015;2.7545419;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
ff3333 red;-4.0643787;-0.5891583;2.6798813;-2.8628845;1.1380843;-2.2408154;-
0198e1 blue;-4.39968;0.13182686;0.032698058;-3.7085454;0.6931928;-2.741665;-
bf5fff purple;-2.2922876;-1.3736391;1.6872133;-2.5818567;-0.08364227;-2.098558;-
fcd116 yellow;-4.019806;0.27214542;0.4131443;-1.5317814;0.8785295;-2.2245827;-
ff7216 orange;-2.3347216;-0.7738398;2.761088;-2.030337;1.416294;-2.5184937;CODE
4dbd33 green;-3.2655594;-0.15145321;1.5020428;-3.0351238;2.4000132;-2.3065557;-
87421f brown;-2.6482704;-0.09242018;1.3728409;-2.7199745;0.51626223;-4.3011546;-
use same random seed for multiple calls to make multilabel classification to;2.1196222;-2.0969324;0.35694683;2.079565;6.068925;1.1425705;IRRE
ensure same distributions;1.5495173;2.3819346;0.88302666;3.1074512;2.5199876;1.6737164;META
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
dataset preparation;6.3923426;-4.9874797;1.2885938;-0.41974038;2.9793432;-2.6038294;IRRE
loading and preprocessing the olivetti faces dataset;2.0431912;-4.522019;0.07481747;-1.1037462;-0.44992933;2.3004315;IRRE
display progress logs on stdout;-1.3691101;0.21453272;3.9099276;0.53881705;-2.2304451;-0.63237697;CODE
global centering focus on one feature centering all samples;3.9192486;-0.79702204;1.975818;0.43253428;-1.4593452;6.3071265;TASK
local centering focus on one sample centering all features;3.3439791;-1.1036575;1.9556715;0.22403711;-0.2921302;6.190083;TASK
define a base function to plot the gallery of faces;-0.23711133;-0.6493301;4.850853;-5.14055;-0.31949946;3.0580537;CODE
let s take a look at our data gray color indicates negative values;1.574369;1.9956455;0.013827258;-2.952856;-2.6669598;-2.2125611;IRRE
white indicates positive values;-0.98157966;3.095856;-0.9631618;-3.708538;-1.0084065;-3.3854518;IRRE
decomposition;0.5583266;-0.92230856;2.7297094;-2.5044823;3.2484734;0.124828056;-
initialise different estimators for decomposition and fit each;5.8819094;0.73645914;-1.1084484;0.1687997;0.21165472;7.167231;IRRE
of them on all images and plot some results each estimator extracts;5.0463085;-2.8104093;4.063661;-1.0968531;-2.174198;1.8993462;IRRE
6 components as vectors math h in mathbb r 4096;0.041340824;-1.9142721;-0.9807828;-7.604818;1.1015373;0.6425338;-
we just displayed these vectors in human friendly visualisation as 64x64 pixel images;0.7081753;-5.072698;1.7170374;-5.7038417;-1.7513607;1.6570086;CODE
read more in the ref user guide decompositions;-0.599377;-4.6265006;-1.8033746;-1.4932368;3.823766;2.3014402;CODE
eigenfaces pca using randomized svd;4.944373;-4.2348104;-2.938298;-2.985919;0.9578014;5.4948745;IRRE
linear dimensionality reduction using singular value decomposition svd of the data;6.5689554;-2.00748;-2.7379699;-4.582285;0.5726328;3.4050145;IRRE
to project it to a lower dimensional space;3.6340673;-3.7141125;3.1847248;-4.461706;-0.42780256;3.1203332;-
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
the eigenfaces estimator via the py mod sklearn decomposition pca;3.5162446;-4.855531;-4.799795;-2.7332892;-3.0074446;5.399896;-
also provides a scalar noise variance the mean of pixelwise variance;2.8366237;-4.0349283;-0.4748164;-1.2720927;-1.3476042;4.6720567;CODE
that cannot be displayed as an image;-6.0299134;-0.1601034;3.4876559;-2.55329;-2.3462882;0.8173482;-
non negative components nmf;1.1846238;1.7947075;-1.8239201;-3.0491524;-0.74373275;1.0136802;-
estimate non negative original data as production of two non negative matrices;5.876172;2.167303;-0.9643418;-1.8597591;-1.7912647;3.642147;-
nmf estimator fit faces original non negative dataset;4.931616;0.73230046;-3.031605;-1.7533445;-2.3790207;4.524542;IRRE
independent components fastica;0.66581064;-2.6618974;0.018356575;-2.7183113;3.6421497;2.9654973;CODE
independent component analysis separates a multivariate vectors into additive;4.6582584;-3.1129634;-2.0155823;-2.68786;2.533736;5.066213;CODE
subcomponents that are maximally independent;-0.3105269;1.2181022;0.9803478;-2.1113129;3.9424145;4.039519;CODE
sparse components minibatchsparsepca;2.7552595;-4.40928;-2.611203;-1.7289392;0.95818454;3.886001;IRRE
mini batch sparse pca class sklearn decomposition minibatchsparsepca;4.6766534;-5.365827;-5.396591;-1.7271637;-0.44173232;2.7399373;IRRE
extracts the set of sparse components that best reconstruct the data this;8.11608;-1.5889049;-0.27674;-3.3156805;2.9167025;2.8743162;CODE
variant is faster but less accurate than the similar;4.2327375;-0.84182584;0.0378533;3.6416821;1.7362382;0.058834694;META
class sklearn decomposition sparsepca;5.142453;-6.8262424;-6.111887;-2.1990066;-0.40160373;1.8129824;IRRE
dictionary learning;5.503911;-4.8114634;1.333421;-0.7274465;2.7765653;1.0122256;-
by default class sklearn decomposition minibatchdictionarylearning;3.0202482;-6.4182043;-6.46233;1.147416;-0.10348519;1.7745737;CODE
divides the data into mini batches and optimizes in an online manner by;7.073536;-1.0264051;2.8083107;-1.0062437;3.004855;1.3991369;CODE
cycling over the mini batches for the specified number of iterations;3.2829678;0.5807786;1.7132694;1.0622472;-0.017087411;1.2834998;CODE
cluster centers minibatchkmeans;1.7923446;-2.799364;1.20151;-1.6757711;-1.6497291;3.4685688;-
class sklearn cluster minibatchkmeans is computationally efficient and;5.780195;-7.532368;-3.4747639;-0.76250416;-0.8937245;0.6167707;IRRE
implements on line learning with a;2.2477717;-5.2307525;0.30612317;2.254537;5.305194;-0.31490824;TASK
meth sklearn cluster minibatchkmeans partial fit method that is;6.0464926;-2.8717725;-4.32542;-0.55351084;-3.05838;3.2128048;-
why it could be beneficial to enhance some time consuming algorithms with;2.8565543;-4.663009;1.9136661;3.0149693;1.5641074;1.4585682;-
class sklearn cluster minibatchkmeans;3.4627047;-5.588805;-4.0046005;-1.5685496;-0.81261694;0.49502966;IRRE
factor analysis components fa;1.0509635;-3.292621;0.73027176;-0.83603865;0.93485534;0.24793716;-
class sklearn decomposition factoranalysis is similar to;3.7333229;-5.9273257;-5.4155273;-0.36634418;-0.47737387;2.2691972;IRRE
class sklearn decomposition pca but has the advantage of modelling the;4.4390564;-7.1757874;-2.901043;0.14331725;1.1193019;2.5694132;IRRE
variance in every direction of the input space independently heteroscedastic;2.1865528;-0.51978064;-0.856968;-0.5969048;-1.6415045;4.713098;CODE
noise read more in the ref user guide fa;0.006715236;-2.596483;0.3260791;3.0463362;-0.81393486;0.40997744;CODE
pixelwise variance;2.878243;0.028769353;0.8641328;-4.4302073;-2.670252;1.5961115;CODE
decomposition dictionary learning;5.504257;-5.1599336;-0.7746555;-1.1842436;2.6627436;2.7457752;-
in the further section let s consider ref dictionarylearning more precisely;-0.88890743;-3.7180328;-1.4355794;2.6642113;2.4959383;-0.1935625;CODE
dictionary learning is a problem that amounts to finding a sparse representation;5.9887094;-4.704716;-0.6780516;-0.7824337;1.6303504;3.312898;IRRE
of the input data as a combination of simple elements these simple elements form;5.12344;-0.4786764;3.3015487;-5.468272;3.1514575;-2.5935264;CODE
a dictionary it is possible to constrain the dictionary and or coding coefficients;2.5140378;-1.4495202;-1.382588;-2.1346116;4.2068677;0.7259443;CODE
to be positive to match constraints that may be present in the data;5.7856646;2.5786765;-0.89159685;0.5749683;3.4824336;0.4504891;CODE
class sklearn decomposition minibatchdictionarylearning implements a;3.4220827;-6.904755;-6.1082277;1.4007638;1.5457649;1.1039834;TASK
faster but less accurate version of the dictionary learning algorithm that;5.600142;-5.3874755;-0.6567743;1.6901972;1.7925425;1.4912032;META
is better suited for large datasets read more in the ref user guide;4.1306796;-4.695811;0.19498718;2.0758996;1.2698096;1.1810395;CODE
minibatchdictionarylearning;2.9644434;-5.2401004;-1.49501;2.476663;2.303294;-0.87721336;-
plot the same samples from our dataset but with another colormap;4.023937;0.026882062;2.8916767;-1.8584917;-0.9194544;0.5368211;IRRE
red indicates negative values blue indicates positive values;-2.1312177;3.3663938;-0.41609895;-4.118328;-1.2045052;-4.047026;IRRE
and white represents zeros;-1.7557478;1.3488575;0.6245007;-6.48139;0.23447013;-2.9607599;-
similar to the previous examples we change parameters and train;2.867012;-2.5234044;2.0664642;2.7560096;2.6549602;3.2205803;IRRE
class sklearn decomposition minibatchdictionarylearning estimator on all;4.474989;-5.5239186;-6.2914014;1.8539358;-0.78959405;2.649284;IRRE
images generally the dictionary learning and sparse encoding decompose;4.2890635;-4.715153;0.34650746;-1.7078573;0.89521915;4.0413995;IRRE
input data into the dictionary and the coding coefficients matrices math x;4.6918716;-1.7372849;-1.7202934;-6.774812;0.66215867;0.5605732;CODE
approx uv where math x x 1 x n math x in;2.6507163;2.1297853;0.91256815;-3.4588933;-0.45681152;-0.7176126;-
mathbb r m n dictionary math u in mathbb r m k coding;1.6136565;-2.0200636;-1.7986575;-6.592297;0.90395844;-2.8092875;-
coefficients math v in mathbb r k n;0.74103737;-0.69201964;-0.08200785;-4.904053;-1.0119643;-1.3759388;-
also below are the results when the dictionary and coding;1.1466913;-3.2180727;-0.040283896;-3.1350236;2.4596078;-3.9424791;IRRE
coefficients are positively constrained;0.60030067;1.832303;-1.7162579;-2.0631056;-1.1172237;3.3968253;CODE
dictionary learning positive dictionary;4.058008;-2.8158886;-0.6750153;-1.0157748;1.9589427;-0.0077632517;-
in the following section we enforce positivity when finding the dictionary;-1.5654936;1.8051507;-3.1766112;1.8155059;1.1274981;-0.16856866;CODE
dictionary learning positive code;4.134299;-3.0757458;-2.0414264;-0.37839824;2.7943432;-2.1471941;-
below we constrain the coding coefficients as a positive matrix;2.4242237;0.9239477;-2.105458;-4.803639;1.578475;3.3516278;CODE
dictionary learning positive dictionary code;2.955652;-2.5993097;-2.1463645;-2.1573043;2.3951056;-1.7830753;-
also below are the results if the dictionary values and coding;2.995425;-1.3315868;-1.1390541;-4.494165;1.7471633;-5.2417064;IRRE
coefficients are positively constrained;0.60030067;1.832303;-1.7162579;-2.0631056;-1.1172237;3.3968253;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
1 np sin 2 time signal 1 sinusoidal signal;0.47680867;1.4860083;-0.14017588;-4.1398315;-2.6384757;0.674671;CODE
2 np sign np sin 3 time signal 2 square signal;-0.64287215;0.93628377;-2.0656896;-5.7546663;-2.4096658;0.07170965;CODE
3 signal sawtooth 2 np pi time signal 3 saw tooth signal;-2.4285064;-0.165125;0.9029294;-3.1726193;-0.3167687;-0.18235849;-
s 0 2 np random normal size s shape add noise;2.5484746;-0.67437774;-2.3529093;-4.4804406;-1.8624341;0.82969147;IRRE
s s std axis 0 standardize data;3.6489325;1.1208028;-1.8593012;-7.5602303;-2.9982455;3.3391273;CODE
mix data;5.227763;0.7158745;3.9777613;-2.147883;4.3750734;-1.720141;-
a np array 1 1 1 0 5 2 1 0 1 5 1 0 2 0 mixing matrix;3.6661093;1.1056119;-2.1382647;-8.153405;-1.105781;-0.15608595;-
x np dot s a t generate observations;5.0876565;-1.0167983;-1.8041581;-3.1985981;-2.4701126;0.78936434;CODE
fit ica and pca models;2.6821935;-0.997071;-1.6352834;-1.4672248;1.0445415;4.3806314;-
compute ica;1.9430034;1.0295208;0.04996196;-2.958358;2.0761578;-1.210648;-
s ica fit transform x reconstruct signals;2.4765701;0.82703406;-2.2833555;-3.6115599;-0.91473323;4.3982224;CODE
a ica mixing get estimated mixing matrix;4.5305367;-0.19450697;-1.4659976;-1.4197088;0.6241266;4.316179;IRRE
we can prove that the ica model applies by reverting the unmixing;0.11569713;0.6014003;-1.4910303;2.621609;1.1162025;4.979405;META
for comparison compute pca;5.4426394;-0.16013034;-0.49570972;-2.159258;0.8472503;-1.1442909;CODE
h pca fit transform x reconstruct signals based on orthogonal components;3.3463588;0.6138583;-2.2310627;-5.26847;-0.37808642;6.422568;CODE
plot results;2.7280965;0.63260704;7.251219;-4.383265;-6.2113085;-4.720718;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
mix data;5.227763;0.7158745;3.9777613;-2.147883;4.3750734;-1.720141;-
a np array 1 1 0 2 mixing matrix;3.8274212;1.4653288;-2.0392618;-7.03766;-1.2658787;0.4929167;-
x np dot s a t generate observations;5.087654;-1.0167984;-1.8041577;-3.198598;-2.470113;0.78936577;CODE
s ica ica fit x transform x estimate the sources;2.989411;0.06855673;-2.0834396;-1.7653908;-0.0073441514;4.587171;CODE
plot results;2.7280965;0.63260704;7.251219;-4.383265;-6.2113085;-4.720718;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate distorted image;1.7399614;1.4061825;2.7051775;-3.8981862;-3.4091003;2.2444665;-
convert from uint8 representation with values between 0 and 255 to;1.9502754;2.2952673;-1.3331288;-8.145626;-1.3758633;-1.0093948;IRRE
a floating point representation with values between 0 and 1;2.8162704;1.8051897;0.10754167;-6.205046;-0.7922656;-3.2725368;IRRE
downsample for higher speed;1.9011283;1.0973825;1.559918;-0.6041715;-0.23721033;1.6219691;CODE
distort the right half of the image;-0.41699773;1.8988397;3.6996062;-3.74676;-4.887407;2.3223305;-
display the distorted image;0.0010678152;2.1120698;4.3338556;-3.8384318;-4.0753016;1.6666129;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
projecting data pca vs kernelpca;4.0638556;-4.6786284;-1.0787388;-1.1196593;-0.9883022;4.267717;-
in this section we show the advantages of using a kernel when;0.65313756;-6.411163;0.8907224;0.9048787;1.8015499;3.1771338;CODE
projecting data using a principal component analysis pca we create a;4.395024;-1.9884279;1.6971523;-2.6130898;0.7841697;3.4012804;IRRE
dataset made of two nested circles;5.9651957;-1.2740877;4.185114;-4.3661046;0.65976435;0.5578098;IRRE
let s have a quick first look at the generated dataset;5.528909;-5.2091336;0.36287037;-0.75053513;2.3044326;-1.8776469;IRRE
train ax set ylabel feature 1;3.4714699;-1.3969471;0.054337032;-2.7102892;1.0147569;0.94814736;TASK
train ax set xlabel feature 0;1.2474527;0.21178184;-2.193114;-1.7409471;-0.45799163;2.2151632;TASK
test ax set xlabel feature 0;1.722931;4.008812;-3.9046369;0.32820353;-1.0310776;-1.4426987;IRRE
the samples from each class cannot be linearly separated there is no;5.9964714;1.1356955;-2.3283322;-2.5161653;3.1031783;0.2909573;CODE
straight line that can split the samples of the inner set from the outer;5.211673;0.8978673;3.5978477;-4.0492225;1.8983266;1.183174;IRRE
set;-1.4280705;0.15607189;7.4121943;-1.1588911;1.308024;-3.1926973;IRRE
now we will use pca with and without a kernel to see what is the effect of;1.826544;-4.9444213;0.12724459;1.7084874;-0.2723302;3.0685112;-
using such a kernel the kernel used here is a radial basis function rbf;1.5645663;-1.7698424;-1.5161315;-4.2883253;-1.4479209;2.3744974;CODE
kernel;-0.14416118;-4.1024375;2.9355628;-1.238118;0.22444972;-1.0592741;-
orig data ax set ylabel feature 1;4.1974726;-0.51181674;-0.08681849;-5.0939455;0.6705122;0.8997131;TASK
orig data ax set xlabel feature 0;2.464903;1.41397;-2.7061527;-4.53188;-0.18084314;1.5104624;TASK
pca proj ax set ylabel principal component 1;2.049164;-0.16340666;-2.0764282;-5.5048428;1.1458719;3.4633698;IRRE
pca proj ax set xlabel principal component 0;0.19457152;1.458483;-3.7452815;-5.345426;-0.30363086;4.181319;IRRE
kernel pca proj ax set ylabel principal component 1;2.2137733;-1.4622064;-2.7401817;-5.157489;0.4250119;3.7371995;IRRE
kernel pca proj ax set xlabel principal component 0;0.39684886;0.005539755;-4.404243;-5.0466413;-0.90861726;4.3052173;IRRE
we recall that pca transforms the data linearly intuitively it means that;4.3118114;-2.9741113;0.7459939;-2.2299216;-0.62110084;4.3880944;CODE
the coordinate system will be centered rescaled on each component;2.3724437;0.57863396;3.4736693;-5.2356424;-2.684036;7.086022;CODE
with respected to its variance and finally be rotated;2.2930963;0.8654412;3.0183737;-0.2301355;1.1203747;3.0957859;CODE
the obtained data from this transformation is isotropic and can now be;1.7908323;-0.96604115;0.16062135;-5.7874126;-2.881988;3.119302;CODE
projected on its principal components;4.3865376;-3.0722978;1.4091508;-1.6189681;1.41126;6.057071;CODE
thus looking at the projection made using pca i e the middle figure we;1.3484871;-2.0820088;2.306873;-3.4044101;-1.4347606;4.0269985;-
see that there is no change regarding the scaling indeed the data being two;4.3499336;1.1980915;-0.042812385;-1.8656625;-2.6788232;4.8338675;-
concentric circles centered in zero the original data is already isotropic;3.2876213;1.4057826;0.37001744;-4.8970222;-5.358476;4.502036;CODE
however we can see that the data have been rotated as a;1.9059993;-0.8329329;2.4754932;-2.132741;-1.6000993;2.3458817;-
conclusion we see that such a projection would not help if define a linear;0.9561601;0.6135941;0.5492478;0.08398497;-0.9177936;5.16683;CODE
classifier to distinguish samples from both classes;5.307437;-0.7021853;0.43561935;0.7996761;7.12504;-2.1982515;CODE
using a kernel allows to make a non linear projection here by using an rbf;2.4022324;-2.6371648;-2.663671;-2.4588838;-2.800203;4.7392936;-
kernel we expect that the projection will unfold the dataset while keeping;3.4950237;-1.88928;-0.3256595;0.11150351;-2.4270613;5.005987;IRRE
approximately preserving the relative distances of pairs of data points that;7.3835382;-0.78158385;2.1246414;-3.8920898;0.16121599;4.7983446;CODE
are close to one another in the original space;0.13137996;0.35096237;4.942855;-2.995375;0.16938353;1.897939;CODE
we observe such behaviour in the figure on the right the samples of a given;3.5958245;3.5795047;3.3961473;-1.3998008;-2.2786279;1.3115803;CODE
class are closer to each other than the samples from the opposite class;6.1656246;1.8380003;-1.617294;-1.3637222;0.96973354;-0.85561955;CODE
untangling both sample sets now we can use a linear classifier to separate;8.235804;-1.7359748;0.4029602;0.05179024;5.1865826;2.4314585;IRRE
the samples from the two classes;4.9724426;-1.7538158;0.40827304;0.19876212;4.4072986;-2.5356176;CODE
projecting into the original feature space;2.3622134;-2.762419;1.4130347;-1.3195397;-0.46613398;6.6842666;TASK
one particularity to have in mind when using;-2.077056;-2.7122605;5.097093;3.635125;4.1754103;-0.43848175;-
class sklearn decomposition kernelpca is related to the reconstruction;4.3303876;-7.0263114;-4.8381844;-1.6723082;-0.69728017;3.5133913;CODE
i e the back projection in the original feature space with;-1.9575703;-3.6905296;3.1620824;-2.495627;-0.004465702;5.3198314;TASK
class sklearn decomposition pca the reconstruction will be exact if;4.036117;-3.0757077;-4.603092;-2.615828;0.11416487;1.9527715;CODE
n components is the same than the number of original features;1.5673989;-1.1903614;-0.800824;-2.9722638;4.231378;1.4828941;TASK
this is the case in this example;-2.2002537;0.66125613;4.693576;0.24854335;2.8777857;1.1351517;CODE
we can investigate if we get the original dataset when back projecting with;5.2174563;-1.9125688;0.68410754;3.1972752;-1.6436226;2.516962;IRRE
class sklearn decomposition kernelpca;3.5154629;-7.170167;-6.206867;-1.8191514;0.16286299;1.9135526;IRRE
orig data ax set ylabel feature 1;4.1974726;-0.51181674;-0.08681849;-5.0939455;0.6705122;0.8997131;TASK
orig data ax set xlabel feature 0;2.464903;1.41397;-2.7061527;-4.53188;-0.18084314;1.5104624;TASK
pca back proj ax set xlabel feature 0;-0.337893;0.7126501;-3.3545008;-3.4382756;-0.016081776;4.0009303;TASK
kernel pca back proj ax set xlabel feature 0;0.32546923;-0.38264427;-4.556463;-3.5556383;-0.958998;3.9547424;TASK
while we see a perfect reconstruction with;-0.2919218;-0.07516243;4.1120224;2.489715;-0.12663391;2.9548988;CODE
class sklearn decomposition pca we observe a different result for;3.8727074;-4.162417;-6.7221527;-1.8534898;-1.1797442;1.3397025;IRRE
class sklearn decomposition kernelpca;3.5154629;-7.170167;-6.206867;-1.8191514;0.16286299;1.9135526;IRRE
indeed meth sklearn decomposition kernelpca inverse transform cannot;2.4185257;-2.9702258;-6.685855;-3.0725222;-4.2414713;3.9363434;IRRE
rely on an analytical back projection and thus an exact reconstruction;3.9088247;-0.8099616;1.9658127;-2.2878358;-1.1967185;5.530526;CODE
instead a class sklearn kernel ridge kernelridge is internally trained;1.8484495;-5.669461;-5.931308;1.5005245;-2.0982406;4.0409346;CODE
to learn a mapping from the kernalized pca basis to the original feature;5.084843;-6.109512;-1.7177662;-2.5410674;1.8826836;4.476893;TASK
space this method therefore comes with an approximation introducing small;4.9503303;0.20291936;0.4478572;-1.5465125;-1.578272;1.9566126;CODE
differences when back projecting in the original feature space;2.4282935;-1.3339057;-0.28028217;-0.20885766;-1.4244578;5.8845735;TASK
to improve the reconstruction using;0.5427886;-1.6921048;4.8091106;0.1072281;0.4718233;2.497345;CODE
meth sklearn decomposition kernelpca inverse transform one can tune;4.5955553;-3.9442852;-5.089834;-3.5362318;-2.6648517;3.2918663;IRRE
alpha in class sklearn decomposition kernelpca the regularization term;3.510387;-5.527216;-6.086885;-2.049994;-0.82701784;4.0422473;IRRE
which controls the reliance on the training data during the training of;3.6024497;-4.230683;2.2999434;4.930927;2.0413377;1.847275;-
the mapping;-0.25675625;-2.5647323;6.85786;0.25477463;1.0894212;-0.38942504;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
loading the iris dataset;1.7350526;-3.739179;-0.38398987;-1.66477;-0.5432547;0.07006438;IRRE
the iris dataset is directly available as part of scikit learn it can be loaded;1.3820156;-8.166703;-2.3384986;-1.8316091;-1.773715;-1.0876914;IRRE
using the func sklearn datasets load iris function with the default parameters;2.4724514;-1.8921351;-5.5206566;-1.0011672;-2.8831651;0.60576844;CODE
a class sklearn utils bunch object is returned containing the data the;2.4258397;-1.9641383;-2.1762884;0.8825241;-1.0519063;-3.3563392;IRRE
target values the feature names and the target names;0.92462873;-1.0255744;0.39219886;1.2280806;3.0418098;-0.8819468;IRRE
plot of pairs of features of the iris dataset;3.511371;-2.8591208;2.4540527;-4.908563;-1.3055085;-1.0140277;TASK
let s first plot the pairs of features of the iris dataset;3.017926;-2.064776;2.5985007;-5.590078;-1.2809308;-1.4338427;TASK
rename classes using the iris target names;-2.0465875;-1.0207167;-1.6554338;0.006231818;3.0076942;1.7248927;IRRE
each data point on each scatter plot refers to one of the 150 iris flowers;3.3967915;-0.51059467;2.567118;-4.129023;-1.491778;-0.6350248;CODE
in the dataset with the color indicating their respective type;3.5981007;-1.8371354;0.22889647;-3.6663756;3.3167045;-1.7650973;IRRE
setosa versicolor and virginica;-2.8769925;0.16033934;0.46492454;-0.032162663;-0.41767237;-1.1216439;IRRE
you can already see a pattern regarding the setosa type which is;-0.42766505;-0.9004862;0.6123404;-0.42146948;4.4713216;1.8595177;IRRE
easily identifiable based on its short and wide sepal only;3.5718172;0.65847546;0.04007312;-3.663245;7.6857214;1.2287002;CODE
considering these two dimensions sepal width and length there s still;-0.48696542;1.4305402;2.2574334;-3.7728505;0.76034486;1.9008983;TASK
overlap between the versicolor and virginica types;-1.6641458;-0.40715054;-1.8580765;-0.93352437;0.5189448;0.54241854;IRRE
the diagonal of the plot shows the distribution of each feature we observe;2.7291186;-2.4378738;3.9149568;-3.2660036;-3.3589928;1.7399777;TASK
that the petal width and the petal length are the most discriminant features;3.7381976;-3.502188;0.9606218;-2.848852;3.599748;1.942733;TASK
for the three types;-1.2445843;-2.6957915;4.1337748;-0.29482836;5.403053;-2.425418;CODE
plot a pca representation;3.200065;-2.0902936;2.4213908;-7.8425555;-3.4771545;1.6682204;-
let s apply a principal component analysis pca to the iris dataset;2.4346344;-2.4217927;-1.0777631;-2.9317183;1.1789393;1.8902689;IRRE
and then plot the irises across the first three principal components;2.5170536;-1.6388296;3.53731;-5.90179;-0.1370166;1.3702539;-
this will allow us to better differentiate among the three types;-1.33814;-3.424039;2.0373135;1.8867759;7.272158;-0.12503074;CODE
unused but required import for doing 3d projections with matplotlib 3 2;-2.480073;-3.8260553;-3.9122677;-3.6912203;-5.2357655;2.5204852;CODE
import mpl toolkits mplot3d noqa f401;-3.1103742;-3.7681549;-3.7366135;-5.488973;-3.817242;1.7461501;CODE
add a legend;-2.7995331;-0.67962795;6.1729946;-0.395936;0.08052883;-1.729099;TASK
pca will create 3 new features that are a linear combination of the 4 original;2.093634;-1.7570279;0.5836516;-2.8468037;4.4425983;2.6527143;TASK
features in addition this transformation maximizes the variance with this;3.7018223;-2.4749818;0.7733733;-1.2396266;0.39664173;4.4170113;CODE
transformation we can identify each species using only the first principal component;4.3051977;-1.6022561;0.7462972;-4.1097617;4.227987;3.1052406;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
create the data;1.9284459;-0.89578146;5.4333367;-3.6698885;3.2001276;-4.0194373;IRRE
adding homoscedastic noise;2.083526;-1.0232424;-0.31318134;0.47762853;-1.5781502;2.8723202;TASK
adding heteroscedastic noise;1.6571541;-0.7517608;-1.2633269;0.6793003;-1.6789672;3.518592;TASK
fit the models;3.2636921;-2.6112978;3.3535106;0.81611687;1.545115;0.078293875;-
n components np arange 0 n features 5 options for n components;-0.18129751;-2.4797013;-1.7776481;-3.8494105;4.3508596;1.5726091;TASK
compare with other covariance estimators;2.114705;0.39130938;-0.23129553;3.0471215;-2.1665773;1.8505489;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
percentage of variance explained for each components;3.681637;-1.8000038;1.70957;-1.1239984;-0.23291287;2.0472;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
ubsampling 3 subsampling factor;2.8289735;1.5914285;-1.4069155;-3.233687;0.5302134;1.4919189;-
compute a wavelet dictionary;3.4286284;-1.68976;-0.027231282;-4.3347907;-0.9031088;1.2365087;CODE
generate a signal;1.967884;0.76438725;4.7811065;-1.3980604;0.29681173;-1.4252145;-
list the different sparse coding methods in the following format;4.7769403;-3.5495498;-1.9256552;-3.2892265;3.0586586;0.38188666;CODE
title transform algorithm transform alpha;0.00011628671;-1.4431398;1.4274027;-4.037476;0.4570874;0.9678066;CODE
transform n nozero coefs color;-0.21896467;0.3150955;0.29820934;-5.1936536;-0.40537247;1.074531;CODE
do a wavelet approximation;5.1201053;-0.6443681;1.4939612;-0.50711817;-2.7088242;4.1392694;CODE
soft thresholding debiasing;5.595819;-0.93155104;1.1444046;0.9852194;1.8575716;3.0050669;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load iris data;-0.04747424;-0.44070444;0.3890012;-1.582075;-0.34886584;1.0829302;CODE
plot covariance of iris features;2.7041185;-1.8752083;1.6311141;-3.7830007;-3.9167316;1.7493027;TASK
run factor analysis with varimax rotation;3.1000068;1.1185209;-1.7223676;-2.2562923;-2.0125246;2.9683766;CODE
an example custom estimator implementing a simple classifier;4.2763243;-1.7913392;-0.8738719;1.5707543;2.0229447;1.4175678;TASK
this code snippet defines a custom estimator class called customestimator;0.7146522;-0.104040585;-2.4891682;2.3113766;0.84059507;3.2447224;CODE
that extends both the baseestimator and classifiermixin classes from;1.1977539;-4.9149365;-1.4074569;1.9401613;2.11141;4.1937623;CODE
scikit learn and showcases the usage of the sklearn is fitted method;5.5013595;-9.907768;-3.7105854;1.3951372;-3.01662;-0.9535558;CODE
and the check is fitted utility function;0.5840049;0.9390468;-1.379176;3.3553448;1.512238;0.5999859;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
custom attribute to track if the estimator is fitted;3.3125026;2.732588;0.26045096;3.4061894;-0.48597613;4.6548944;META
perform prediction logic;5.4194794;0.8894479;2.824821;5.694349;3.0160162;-3.9651117;CODE
perform scoring logic;3.470662;2.978524;3.0405054;2.9447815;3.4522223;-5.677836;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
creating the dataset;4.8116126;-3.9983146;3.065582;-2.5796916;3.5601823;-2.7123725;IRRE
the classification dataset is constructed by taking a ten dimensional standard;7.1434426;-6.4158597;-0.048624896;-3.4593515;4.6146564;0.8305892;CODE
normal distribution math x in math r 10 and defining three classes;-0.36136648;1.0229356;0.034404926;-4.0527987;3.9699051;-0.6585535;IRRE
separated by nested concentric ten dimensional spheres such that roughly equal;2.3765512;1.2019627;3.2709746;-4.1022964;0.56703067;2.5178585;CODE
numbers of samples are in each class quantiles of the math chi 2;1.9827693;1.0687824;-0.69508404;-1.942854;1.5613136;-2.112802;IRRE
distribution;0.04318447;-0.20799376;6.2992096;-0.5853259;0.81052047;-3.5302916;META
we split the dataset into 2 sets 70 percent of the samples are used for;7.072918;-1.2987409;3.2375548;0.055168483;2.1950648;-1.4779212;IRRE
training and the remaining 30 percent for testing;3.7715244;-0.6704396;1.9824737;5.6347127;1.2794396;-3.81881;CODE
training the adaboostclassifier;3.280564;-7.0103917;-2.4463365;1.8879385;4.9632273;-0.061332703;IRRE
we train the class sklearn ensemble adaboostclassifier the estimator;4.815233;-7.263556;-4.021063;2.4866686;2.6340888;0.58299696;CODE
utilizes boosting to improve the classification accuracy boosting is a method;4.0229564;-5.8747144;0.22678947;3.2925386;4.014242;0.10074803;IRRE
designed to train weak learners i e estimator that learn from their;4.0366907;-3.5720227;-0.2603719;5.5027785;1.1669648;1.3471377;CODE
predecessor s mistakes;-2.9861817;0.47400331;2.4225276;4.0294003;-0.55836684;-2.5099845;-
here we define the weak learner as a;0.81370026;-4.614382;-0.23965049;4.4772887;0.76659197;0.15206738;CODE
class sklearn tree decisiontreeclassifier and set the maximum number of;1.5265338;-2.907286;-3.3431973;0.7197191;3.039541;-1.174916;IRRE
leaves to 8 in a real setting this parameter should be tuned we set it to a;0.5421088;3.3572023;1.6465776;-0.26697946;-2.1640577;-0.18523155;IRRE
rather low value to limit the runtime of the example;1.5082879;3.6516895;-0.360083;3.4432945;1.037488;-0.74802125;IRRE
the samme algorithm build into the;3.6742013;-3.696225;0.00055518124;0.41256043;3.2533283;-0.06257306;CODE
class sklearn ensemble adaboostclassifier then uses the correct or;2.019396;-3.637741;-6.2383413;1.3717449;3.7593381;-2.3896537;IRRE
incorrect predictions made be the current weak learner to update the sample;4.13599;-2.662996;-3.3065941;7.6258903;-1.3593318;-0.85997224;CODE
weights used for training the consecutive weak learners also the weight of;2.642105;-3.012482;0.39441735;2.4683788;1.7783628;0.72084403;CODE
the weak learner itself is calculated based on its accuracy in classifying the;4.755296;-4.900601;-2.2707777;4.809527;2.4334142;-0.42175567;CODE
training examples the weight of the weak learner determines its influence on;3.1691701;-4.2264194;0.563879;4.6117916;0.9025115;0.4796299;-
the final ensemble prediction;5.817725;-4.2067137;0.7774787;4.151408;2.243653;0.06457265;CODE
analysis;2.6429112;-0.54274994;6.312202;2.2135186;1.0319148;-3.6721046;-
convergence of the adaboostclassifier;3.4469757;-4.4880614;-4.4085636;2.4015672;3.1590743;3.3640454;IRRE
to demonstrate the effectiveness of boosting in improving accuracy we;5.9827456;-4.0635524;0.21239907;3.2791038;1.9800088;-0.63817346;-
evaluate the misclassification error of the boosted trees in comparison to two;3.013924;-1.2673092;-5.0094976;2.4499807;2.7161825;-1.9387054;IRRE
baseline scores the first baseline score is the misclassification error;1.5577704;1.0677868;-3.5029078;1.4690541;0.9644608;-1.5936402;IRRE
obtained from a single weak learner i e;1.8339317;-4.580779;-2.1495733;2.5424798;2.4740534;0.32563823;CODE
class sklearn tree decisiontreeclassifier which serves as a reference;0.51475906;-5.5733113;-4.578834;1.3817544;3.0974362;-0.03671603;CODE
point the second baseline score is obtained from the;2.0862095;2.429114;3.9510915;-0.89091843;1.4138619;-1.3897468;CODE
class sklearn dummy dummyclassifier which predicts the most prevalent;4.1106014;-3.6190073;-2.3841922;2.50338;0.47572297;-2.0808089;IRRE
class in a dataset;4.9182205;-3.6519997;0.4912004;-1.2596426;4.462449;-1.9183372;IRRE
after training the class sklearn tree decisiontreeclassifier model the;1.7962736;-6.4494443;-2.674118;2.0522609;2.3974202;-1.562353;IRRE
achieved error surpasses the expected value that would have been obtained by;0.90371037;5.1977944;-1.5932915;3.1010542;-2.2032955;-1.7007794;IRRE
guessing the most frequent class label as the;3.613522;-3.312853;1.5045315;2.4108753;5.403735;-2.6824555;IRRE
class sklearn dummy dummyclassifier does;1.069557;-3.0595424;-6.140858;0.84494406;0.37302122;-1.7489709;CODE
now we calculate the misclassification error i e 1 accuracy of the;3.5537617;-0.09220957;-3.8512583;1.9009877;1.5301025;-2.299639;IRRE
additive model class sklearn tree decisiontreeclassifier at each;3.3040593;-4.6362414;-4.197677;0.7955059;4.339693;0.87561584;IRRE
boosting iteration on the test set to assess its performance;7.3893394;1.4126344;-1.2059289;6.4060793;2.3325567;-2.396116;IRRE
we use meth sklearn ensemble adaboostclassifier staged predict that makes;4.270842;-5.8986993;-3.984945;3.846366;1.6790682;-0.3682028;IRRE
as many iterations as the number of fitted estimator i e corresponding to;4.9171753;0.9759065;2.4794552;1.2597343;-0.5003924;3.3027825;-
n estimators at iteration n the predictions of adaboost only use the;4.0290747;-1.9838829;-2.8365552;2.4433706;-0.27502522;1.8811852;IRRE
n first weak learners we compare these predictions with the true;4.752087;-3.2343297;-1.533939;5.7422996;0.905708;-1.7438099;IRRE
predictions y test and we therefore conclude on the benefit or not of adding a;2.293846;1.5605818;0.05079136;7.0324874;-0.70401496;-2.6748714;TASK
new weak learner into the chain;1.368927;-5.286466;-0.9287241;5.0109563;0.97559285;-0.1444559;CODE
we plot the misclassification error for the different stages;3.1004922;-1.1206925;-1.6378528;2.2039218;-1.4072616;0.3382768;CODE
the plot shows the missclassification error on the test set after each;2.2797518;2.3777208;-3.772116;1.4265188;-3.9369795;-2.518664;IRRE
boosting iteration we see that the error of the boosted trees converges to an;4.1086087;-1.441302;-3.4504483;2.3069165;0.38854066;0.91403663;-
error of around 0 3 after 50 iterations indicating a significantly higher;2.0004928;4.671272;-2.8610675;0.44094026;-4.25708;-3.898981;-
accuracy compared to a single tree as illustrated by the dashed line in the;3.4236329;-1.7199935;1.4846234;0.88801736;0.043100867;-2.1279795;CODE
plot;-0.1530007;-0.22087865;8.818623;-3.4865117;-5.8780794;-3.9504418;-
the misclassification error jitters because the samme algorithm uses the;3.4445095;-2.1518044;-5.9661674;2.0527868;1.595288;-0.6346298;IRRE
discrete outputs of the weak learners to train the boosted model;4.8016634;-4.202538;0.4204709;2.33619;2.878024;0.6927954;IRRE
the convergence of class sklearn ensemble adaboostclassifier is mainly;5.0319414;-6.852964;-5.5128717;2.2491653;1.7468435;0.5343571;CODE
influenced by the learning rate i e learning rate the number of weak;4.566757;-3.2479923;0.9716855;3.436709;0.47188288;0.28458548;-
learners used n estimators and the expressivity of the weak learners;3.3379133;-3.7293818;-0.88205844;4.3321147;0.85955566;-0.39010945;-
e g max leaf nodes;0.5386807;-2.677983;4.60791;-0.9783081;2.0311728;0.8704557;-
errors and weights of the weak learners;4.0873017;-3.0297334;-1.4991429;4.9045777;0.4179673;-0.808496;-
as previously mentioned adaboost is a forward stagewise additive model we;1.805903;-2.6160514;-1.3263675;2.4679108;4.269189;3.914213;TASK
now focus on understanding the relationship between the attributed weights of;3.9229934;-1.0707827;-0.012338704;-0.11490178;0.9066313;1.4132124;META
the weak learners and their statistical performance;5.019949;-4.7772427;-0.7353063;5.655018;1.0481255;-2.034869;CODE
we use the fitted class sklearn ensemble adaboostclassifier s attributes;5.1951656;-7.960178;-4.1653953;0.4050633;3.8815281;0.39984748;IRRE
estimator errors and estimator weights to investigate this link;1.7978694;-0.041368444;-1.2764543;2.1443732;-3.008198;1.5048804;CODE
on the left plot we show the weighted error of each weak learner on the;4.8158193;-2.9760668;-1.2272099;1.4159383;-2.1038694;1.2097205;-
reweighted training set at each boosting iteration on the right plot we show;5.071131;-1.9264557;0.30773103;-0.08139038;-1.6730654;4.052485;IRRE
the weights associated with each weak learner later used to make the;2.4851453;-4.8414044;0.8023447;3.3872943;0.80819505;1.5537714;OUTD
predictions of the final additive model;3.3639836;-0.9960431;0.9420118;3.7658806;1.8864249;0.639848;TASK
we see that the error of the weak learner is the inverse of the weights it;2.8614676;-3.21165;-2.7556593;4.229672;-1.0610242;3.3947926;-
means that our additive model will trust more a weak learner that makes;1.503864;-3.5132377;-1.1344922;5.46545;2.074735;0.6291117;TASK
smaller errors on the training set by increasing its impact on the final;4.9175787;-0.8260661;-1.3310117;7.2896543;0.26260042;1.03893;IRRE
decision indeed this exactly is the formulation of updating the base;-0.848842;-0.39428997;1.4228796;3.1875796;4.236417;3.298087;CODE
estimators weights after each iteration in adaboost;4.2228055;-0.971709;-1.9406375;2.521571;0.04659352;5.161514;-
dropdown mathematical details;2.0435581;-0.85593194;4.732442;-2.7496068;2.1374936;-2.704012;CODE
the weight associated with a weak learner trained at the stage math m is;2.8085902;-1.4892855;0.63414556;3.0938916;-0.8610397;-1.0327482;-
inversely associated with its misclassification error such that;2.270921;1.4376042;-5.461535;1.0796527;-0.23890342;1.181657;IRRE
math alpha m log frac 1 err m err m log k 1;-1.5661262;1.259655;-0.17905815;-1.7572607;-2.6645052;-3.5897002;-
where math alpha m and math err m are the weight and the error;2.2589638;1.0855372;-1.0229701;0.4123406;-1.7579894;-1.7569776;-
of the math m th weak learner respectively and math k is the number of;2.8884752;-2.939216;0.22751546;0.83106846;2.1964686;-2.5345926;-
classes in our classification problem;4.2558856;-3.1172893;1.4394919;0.13060302;6.9652224;-2.4544249;IRRE
another interesting observation boils down to the fact that the first weak;-1.3376653;-0.6479524;-0.1402326;3.496818;-1.3318579;2.8760242;CODE
learners of the model make fewer errors than later weak learners of the;2.0919244;-1.8042189;-1.324849;6.6552434;-0.3936242;-1.4322146;-
boosting chain;1.6639347;-1.6178992;1.5275285;-0.6227377;3.3895166;0.9309083;-
the intuition behind this observation is the following due to the sample;3.06425;1.288393;3.9849222;1.1960036;-0.9947379;0.5211784;CODE
reweighting later classifiers are forced to try to classify more difficult or;3.386173;-2.5399587;-2.6614475;4.4491725;2.0666282;3.110657;CODE
noisy samples and to ignore already well classified samples therefore the;5.8389764;-0.62863654;-1.5348531;4.6000752;3.958821;-0.17647983;CODE
overall error on the training set will increase that s why the weak learner s;3.4509375;-2.9150608;-3.1651294;5.9051785;-0.20465241;0.82327807;IRRE
weights are built to counter balance the worse performing weak learners;3.8570783;-2.10388;-0.9567448;4.7994576;-0.5102911;-0.23170431;CODE
preparing the data;4.6533084;0.20347433;4.862507;-2.2921865;1.9808745;-4.5799794;-
first we prepare dummy data with a sinusoidal relationship and some gaussian noise;6.7156925;0.28939682;0.38107893;-1.3313988;-0.2309682;2.468559;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
training and prediction with decisiontree and adaboost regressors;4.202962;-5.1291156;-2.425001;1.5116271;2.3957136;1.7820393;-
now we define the classifiers and fit them to the data;5.5557327;-5.4221244;0.3248523;1.8932279;6.0450563;1.7533472;CODE
then we predict on that same data to see how well they could fit it;6.847067;-1.430831;1.7097145;3.742334;0.23403017;1.4025217;-
the first regressor is a decisiontreeregressor with max depth 4;0.9631946;-1.570551;-0.8609461;-2.078879;2.1608286;1.5310038;-
the second regressor is an adaboostregressor with a decisiontreeregressor;0.64251834;-1.8815502;-2.3521278;-0.007877079;1.9875581;2.6509597;-
of max depth 4 as base learner and will be built with n estimators 300;2.4543662;-3.8041599;0.020860607;-0.19887608;2.114919;0.75751483;IRRE
of those base learners;0.924927;-5.375255;0.721461;2.9516215;2.1492043;-2.9649773;-
plotting the results;2.7824183;0.35010907;8.162847;-4.9284263;-5.283578;-4.731769;IRRE
finally we plot how well our two regressors;2.0221846;-0.6977615;4.4270244;-1.5769659;-5.3813176;1.2324648;CODE
single decision tree regressor and adaboost regressor could fit the data;5.2756214;-1.7479093;-1.010979;-1.6507726;2.8233016;2.208411;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
construct dataset;5.689169;-3.8244698;1.1927593;-1.1336418;4.476954;-1.8197742;CODE
create and fit an adaboosted decision tree;3.6748736;-2.2553453;-0.9387709;-0.36455113;6.083009;0.8096346;IRRE
plot the decision boundaries;3.2783208;-1.6897035;7.2941766;-0.6646134;0.0397476;-1.1280327;-
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
plot the two class decision scores;4.030861;-1.4766145;3.7942371;-1.5208905;0.0036784157;-2.7670999;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
settings;-4.2340403;-1.8681971;6.994803;0.2633829;-1.2244998;1.7592822;IRRE
n repeat 50 number of iterations for computing expectations;4.0586796;0.469595;2.3965802;1.8246845;-0.3189077;-0.7325115;CODE
n train 50 size of the training set;2.8387237;-0.38957545;3.3605688;-2.6202612;2.5025978;-1.4508697;IRRE
n test 1000 size of the test set;3.8720431;3.4230387;-0.06371885;0.8113959;0.5531587;-5.337334;IRRE
noise 0 1 standard deviation of the noise;1.0464122;0.35047054;-1.9456688;-1.9722815;-1.9750354;0.05330959;-
change this for exploring the bias variance decomposition of other;4.168194;-2.499385;-2.7894628;1.9458615;0.029004414;3.794288;CODE
estimators this should work well for estimators with high variance e g;4.203499;-0.40844196;2.125227;3.7963095;-0.45862225;3.4790823;CODE
decision trees or knn but poorly for estimators with low variance e g;5.0858703;-3.3892744;-2.0451462;2.255323;0.52281624;1.3012705;CODE
linear models;5.303449;-1.9229746;4.9554467;1.2264682;0.1254217;-0.3154667;-
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
loop over estimators to compare;4.752;3.771303;1.7714214;2.594612;-2.1979616;-0.7253357;IRRE
compute predictions;6.7820625;-1.663276;2.3847785;2.000576;0.16993794;-4.046074;-
bias 2 variance noise decomposition of the mean squared error;2.3782263;-1.9307243;-3.0251157;0.18783975;-2.232578;4.1798906;CODE
plot figures;0.81645286;-1.7687755;8.646222;-4.9672227;-5.6087265;-0.9240211;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate a binary classification dataset;5.0084214;-5.404884;-0.32084277;-2.7885895;4.5116024;-2.832421;IRRE
note setting the warm start construction parameter to true disables;-4.335168;1.4774418;-2.6604006;4.490163;-1.9399498;4.0191607;IRRE
support for parallelized ensembles but is necessary for tracking the oob;5.697711;-5.4710975;-1.7213135;2.1927192;2.1255455;2.7808843;CODE
error trajectory during training;1.4215287;0.7071807;0.07288336;3.6890743;-3.66177;0.149543;-
map a classifier name to a list of n estimators error rate pairs;5.034127;-1.398619;-2.309856;0.38405627;3.4190166;0.73546255;IRRE
range of n estimators values to explore;4.914672;0.84142673;1.7993588;0.13419503;-0.8835526;0.60401845;IRRE
record the oob error for each n estimators i setting;2.4786634;1.9580154;-2.6628804;1.6865273;-0.32228875;0.8435229;CODE
generate the oob error rate vs n estimators plot;3.6293826;-0.25946176;-0.8652337;-0.9757163;-3.0911505;1.0112407;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
first we will create a large dataset and split it into three sets;6.4388742;-4.2036633;3.9354045;-1.7586063;4.234059;-0.3929491;IRRE
a set to train the ensemble methods which are later used to as a feature;5.7021613;-5.641004;1.106372;4.868006;5.830883;1.0388901;CODE
engineering transformer;-1.2903613;-1.8890799;3.4580047;-1.288508;0.35310468;-0.24984963;CODE
a set to train the linear model;6.8229313;-1.8456051;2.913837;0.92214626;4.45705;0.94067806;IRRE
a set to test the linear model;5.646159;3.5265114;1.2708632;2.827082;2.1472964;-3.3732557;IRRE
it is important to split the data in such way to avoid overfitting by leaking;3.878948;-0.21538426;0.97618145;1.9930695;3.6445673;2.138573;CODE
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
for each of the ensemble methods we will use 10 estimators and a maximum;5.520726;-3.3129103;-0.36240017;3.7110844;2.4888947;1.3222287;CODE
depth of 3 levels;0.0012018512;0.81078464;3.6468136;-4.7211604;1.4884852;0.0031602532;-
first we will start by training the random forest and gradient boosting on;4.5683684;-7.2294583;1.5325168;2.2378907;3.4143684;0.87961984;IRRE
the separated training set;4.1983814;-4.553287;2.29298;2.3339043;5.364373;1.4359152;IRRE
notice that class sklearn ensemble histgradientboostingclassifier is much;4.6436462;-5.8892198;-6.1060314;2.1092105;1.158956;0.9918918;IRRE
faster than class sklearn ensemble gradientboostingclassifier starting;4.803164;-5.919978;-4.150364;1.8083736;1.0303948;1.944605;IRRE
with intermediate datasets n samples 10 000 which is not the case of;4.938964;0.569814;-1.7020518;1.7206787;1.9314072;-1.1955799;CODE
the present example;-2.5455763;-1.5560235;5.351052;3.0236893;2.0750365;-1.6709828;-
the class sklearn ensemble randomtreesembedding is an unsupervised method;4.8735104;-6.9729266;-3.6419938;2.0014968;2.3186088;0.108316615;IRRE
and thus does not required to be trained independently;-2.5687077;-2.791548;-0.32342124;3.6018968;2.7914815;0.8346299;CODE
now we will create three pipelines that will use the above embedding as;-1.5902272;-3.3839734;1.1145914;0.21347414;4.363904;5.1171308;IRRE
a preprocessing stage;-1.1117395;-1.5735314;3.9787285;3.6469584;3.011264;0.23112603;-
the random trees embedding can be directly pipelined with the logistic;2.5962846;-5.611447;-0.8104569;1.2727026;4.7760563;2.3045373;IRRE
regression because it is a standard scikit learn transformer;3.770295;-7.290231;-0.5895158;0.7008874;-3.9870396;-0.4199796;CODE
then we can pipeline random forest or gradient boosting with a logistic;5.005575;-7.826937;-0.6662099;3.8757741;4.2151914;1.4850127;CODE
regression however the feature transformation will happen by calling the;2.0449889;-0.7457735;0.1183567;1.3725839;-1.8447468;2.2829766;TASK
method apply the pipeline in scikit learn expects a call to transform;-0.8971464;-4.497712;-5.698001;0.59829897;-5.156869;-0.6617398;CODE
therefore we wrapped the call to apply within a functiontransformer;-3.0854864;2.314836;-0.35827863;0.7445485;-0.7062855;3.550059;CODE
we can finally show the different roc curves for all the models;3.1916125;-5.4619117;-0.35288092;1.9841875;1.4341762;0.034835704;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load dataset;3.8353703;-3.3864453;1.9687643;-0.32892612;0.86885685;0.66142696;TASK
hgbt uses a histogram based algorithm on binned feature values that can;3.617611;-3.1449583;-1.2469139;-3.769318;2.2766519;0.14745645;IRRE
efficiently handle large datasets tens of thousands of samples or more with;6.552919;-3.1142886;1.6336714;1.4992853;2.2143557;0.90769637;IRRE
a high number of features see ref why it s faster the scikit learn;3.1073039;-9.725199;-1.6436342;2.4252033;-1.476356;-1.2800683;TASK
implementation of rf does not use binning and relies on exact splitting which;0.8912853;0.7121806;-2.6698515;-2.0618575;1.770721;1.1285945;TASK
can be computationally expensive;2.3986325;-4.115868;1.7346897;1.4342138;0.17317699;-0.5134553;-
compute score and computation times;5.194879;-0.70076156;1.0817717;-0.4380009;0.8062593;-3.8983305;-
notice that many parts of the implementation of;-2.4900777;-2.1982982;-0.57758033;2.6242566;3.3343432;0.49871102;TASK
class sklearn ensemble histgradientboostingclassifier and;4.3204203;-6.4502783;-5.168856;1.3829855;2.475075;0.6631377;IRRE
class sklearn ensemble histgradientboostingregressor are parallelized by;5.0243883;-6.205096;-4.9532375;0.57706237;0.85325295;1.9399468;IRRE
default;-5.2986646;-1.8012849;4.161423;0.8626395;-0.7494437;1.3156078;CODE
the implementation of class sklearn ensemble randomforestregressor and;4.2731104;-7.2196097;-5.189078;2.9381857;1.0623524;-0.10954657;IRRE
class sklearn ensemble randomforestclassifier can also be run on multiple;1.8843951;-3.761773;-4.468479;3.504639;3.245388;0.58876824;CODE
cores by using the n jobs parameter here set to match the number of;2.8777795;0.7935573;-0.21958873;-1.1357025;0.45871922;-0.073665135;IRRE
physical cores on the host machine see ref parallelism for more;0.3580001;-2.7636545;-0.55781406;1.6589905;-1.5607274;2.355987;CODE
information;-0.70000315;-4.068345;6.323086;2.0275075;2.5622752;-1.4755417;CODE
unlike rf hgbt models offer an early stopping option see;-0.85054445;0.6292046;-0.009475752;3.478159;0.37478775;3.070442;-
ref sphx glr auto examples ensemble plot gradient boosting early stopping py;3.0315292;-4.05728;-3.2687428;2.0068376;-3.5668826;2.9169421;-
to avoid adding new unnecessary trees internally the algorithm uses an;1.2356246;-0.81203485;-1.3027303;1.2182025;4.337262;-0.17300348;CODE
out of sample set to compute the generalization performance of the model at;7.1938515;-0.9655383;-0.88760227;3.5821347;2.4064167;1.9068345;IRRE
each addition of a tree thus if the generalization performance is not;3.6523716;-1.3062391;-0.19510281;2.4536614;6.090236;0.8762489;TASK
improving for more than n iter no change iterations it stops adding trees;0.50350356;-0.8099433;-0.38197646;2.5812051;1.1199725;-0.3690012;TASK
the other parameters of both models were tuned but the procedure is not shown;-0.059389982;1.1844783;-2.7819092;1.4623424;-1.6530213;1.0756445;IRRE
here to keep the example simple;-1.785078;-0.66581315;4.6839046;-1.1989484;0.7076263;-1.6689582;-
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
tuning the n estimators for rf generally results in a waste of computer;4.19231;-0.48539212;-1.462165;3.155086;-0.73090005;1.48058;IRRE
power in practice one just needs to ensure that it is large enough so that;-1.5692321;0.07260359;2.4524121;2.118869;1.6944075;1.6184672;TASK
doubling its value does not lead to a significant improvement of the testing;0.9615972;4.5826225;-1.9434448;5.601707;-2.248032;-3.739229;IRRE
score;-0.7900283;1.0264367;5.1333914;-0.32696462;0.69945973;-6.6552067;-
plot results;2.7280972;0.6326069;7.251218;-4.383266;-6.211307;-4.720718;IRRE
we can use a plotly express scatter;3.7587287;-1.9279013;4.441435;-5.1690764;-5.643238;1.4320326;-
https plotly com python api reference generated plotly express scatter html;-2.381602;-1.8519495;-0.6061919;-3.2771852;-7.794728;1.2249116;CODE
to visualize the trade off between elapsed computing time and mean test score;4.074601;-2.0000505;2.9413927;1.1598701;-2.0319324;-1.959927;IRRE
passing the cursor over a given point displays the corresponding parameters;1.0401896;2.2912514;3.105415;-2.9422288;-2.852307;0.26315537;IRRE
error bars correspond to one standard deviation as computed in the different;1.6466644;2.3392322;-3.0783775;-2.3571286;-1.9669689;0.5479437;IRRE
folds of the cross validation;2.7328165;-0.6049606;1.1570333;1.2402569;2.8079023;0.9842246;-
both hgbt and rf models improve when increasing the number of trees in the;0.33171716;-2.2092378;-0.35972238;1.6630224;1.158652;1.0446985;CODE
ensemble however the scores reach a plateau where adding new trees just;4.719438;-2.722161;0.32291192;4.100698;2.3270664;-0.7234854;CODE
makes fitting and scoring slower the rf model reaches such plateau earlier;4.5944324;-0.2496626;0.20607719;3.8187385;-1.8067682;2.9000614;-
and can never reach the test score of the largest hgbdt model;1.4158828;0.76372015;-3.8414462;3.211864;-0.25808284;-2.909615;IRRE
note that the results shown on the above plot can change slightly across runs;2.5037382;0.50827295;0.8631962;-2.0861936;-6.0248675;1.644794;TASK
and even more significantly when running on other machines try to run this;-1.9470747;-1.3254436;-1.226015;2.9744964;-3.4228408;0.54786664;CODE
example on your own local machine;-2.4788666;-5.266733;2.4490993;0.4600875;0.00960723;0.31351817;-
overall one should often observe that the histogram based gradient boosting;5.1038556;-5.6209345;0.81660956;1.2305943;1.6532416;2.071999;CODE
models uniformly dominate the random forest models in the test score vs;3.4574397;-2.3225462;-2.0293617;6.384238;0.9343813;-2.1666276;CODE
training speed trade off the hgbdt curve should be on the top left of the rf;-1.1270523;-1.2390318;-1.0927373;-0.700836;-1.0006039;2.2355042;-
curve without ever crossing the test score vs prediction speed trade off;4.7368736;0.98979837;0.93354505;5.3177285;-2.7539632;-0.3373659;IRRE
can also be more disputed but it s most often favorable to hgbdt it s always;-1.4346755;-0.3718869;-0.61320543;3.336012;1.8845605;1.011935;META
a good idea to check both kinds of model with hyper parameter tuning and;3.3622363;1.9477168;-1.8573004;4.5756845;1.6002182;0.9929394;IRRE
compare their performance on your specific problem to determine which model is;5.6879663;1.0551282;-1.1531221;4.120362;1.9613345;-1.4287463;CODE
the best fit but hgbt almost always offers a more favorable speed accuracy;1.6021247;-1.2136437;-1.1443495;0.6654044;0.24685885;2.3276207;META
trade off than rf either with the default hyper parameters or including the;0.41034275;0.93161935;-1.276839;-0.14721128;2.3880405;4.0079727;IRRE
hyper parameter tuning cost;3.9705803;-0.90265816;-1.1575483;1.3206667;0.43348756;3.1009145;IRRE
there is one exception to this rule of thumb though when training a;2.4376426;-1.3355161;-0.85685635;5.510635;3.1634085;-0.21162836;CODE
multiclass classification model with a large number of possible classes hgbdt;3.4137251;-5.0949583;-1.701572;0.16438451;5.597287;0.4895134;IRRE
fits internally one tree per class at each boosting iteration while the trees;3.280649;-1.4948342;-2.7943163;1.1380394;3.8617532;3.101923;CODE
used by the rf models are naturally multiclass which should improve the speed;2.3947132;-2.9661245;-0.95235604;2.3743074;3.712618;2.3326046;IRRE
accuracy trade off of the rf models in this case;4.9471993;0.07428817;-1.4562243;4.3663635;-0.096897446;1.3909373;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation and model fitting;7.1482363;-1.4997222;1.8994235;0.11031052;1.4638088;0.42518544;-
we generate a synthetic dataset with only 3 informative features we will;5.4088583;-6.038815;0.29518074;-0.20968133;4.5715885;-1.2655549;TASK
explicitly not shuffle the dataset to ensure that the informative features;6.2338786;-2.3242934;-0.3902833;1.676881;3.726325;2.6093063;CODE
will correspond to the three first columns of x in addition we will split;1.7986366;1.6663792;3.5118177;-8.545787;2.0437531;-3.1262817;TASK
our dataset into training and testing subsets;6.56382;-2.1689346;0.92317396;5.3555245;4.011733;-2.7048757;IRRE
a random forest classifier will be fitted to compute the feature importances;3.698553;-6.6993685;-0.03375239;1.6545774;2.8185003;0.22024645;CODE
feature importance based on mean decrease in impurity;5.478934;-0.8798459;-0.214338;1.0325639;1.0520936;3.089967;CODE
feature importances are provided by the fitted attribute;2.2277973;-1.8599287;0.7156902;0.7863204;1.2918196;4.713158;CODE
feature importances and they are computed as the mean and standard;2.7365236;-4.468468;1.2092043;0.70045066;1.8457673;2.3685455;CODE
deviation of accumulation of the impurity decrease within each tree;0.35080016;1.6036254;0.19965112;1.4650471;-0.37063035;0.39870375;-
warning;-3.0231862;-0.29702285;2.0558126;3.4345493;-1.4731644;-1.9746032;-
impurity based feature importances can be misleading for high;1.3227051;-2.085529;-2.3314352;2.4242268;1.5600948;2.3926296;CODE
cardinality features many unique values see;4.3234363;-0.33110908;0.22082147;-3.1288385;4.78238;-0.9905394;IRRE
ref permutation importance as an alternative below;1.8095503;0.1841644;2.393748;1.6405581;5.668397;1.3144696;CODE
let s plot the impurity based importance;1.0138206;-1.1079063;3.8287587;-1.9411684;-1.1260451;0.19042183;CODE
we observe that as expected the three first features are found important;0.87089026;-3.6934345;1.8222094;1.1525254;2.8955803;1.4339639;CODE
feature importance based on feature permutation;4.7269015;-3.3869562;2.7155457;-1.0104402;4.053785;1.7937227;CODE
permutation feature importance overcomes limitations of the impurity based;2.236238;-1.5989038;-0.12757385;-1.3556191;3.6057732;1.664784;CODE
feature importance they do not have a bias toward high cardinality features;2.9272246;-4.7670484;-0.56028545;1.3630396;2.2596257;2.7330985;CODE
and can be computed on a left out test set;4.528558;2.9259858;-1.6367275;2.857322;3.068323;-4.8531785;IRRE
the computation for full permutation importance is more costly each feature is;4.4105177;-3.088978;1.0487092;-0.81062454;3.8768659;2.070422;CODE
shuffled n times and the model is used to make predictions on the permuted data to see;5.319831;-1.4467698;1.8865144;-0.6683999;2.075483;0.52168274;OUTD
the drop in performance please see ref permutation importance for more details;2.3405159;1.1285169;1.1433625;2.7100875;2.7841957;0.80962163;CODE
we can now plot the importance ranking;2.9640093;-3.595917;5.366279;0.10583851;0.5759682;2.2497206;CODE
the same features are detected as most important using both methods although;2.7597363;-2.856722;-0.45054102;3.108533;3.5941937;1.1030369;CODE
the relative importances vary as seen on the plots mdi is less likely than;1.2506071;-2.3215091;0.24281064;0.011693153;-0.7333544;3.7942634;CODE
permutation importance to fully omit a feature;1.7849814;0.5811553;1.0332079;0.43220168;4.084689;1.4456962;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
plot step 0 02 fine step width for decision surface contours;2.3132262;-1.7049973;0.627751;-4.6298556;-2.5219488;2.795123;CODE
plot step coarser 0 5 step widths for coarse classifier guesses;5.116316;-2.5295396;-1.0245564;-1.6811228;-2.997419;2.166564;CODE
random seed 13 fix the seed on each iteration;0.9933068;0.24232335;0.4709742;1.318531;-1.1578059;-2.1931887;IRRE
load data;0.93180233;-0.1247594;5.3618517;-0.54225874;0.7679921;0.048613176;TASK
we only take the two corresponding features;3.1369839;-1.6201556;1.0762732;-0.76271343;3.877071;1.865158;TASK
shuffle;1.1517164;-0.5439028;5.424595;-0.047424313;2.686807;-2.256504;-
standardize;1.3213675;0.020157853;1.3542682;-1.9349836;1.0452657;2.2776322;-
train;-0.5247103;-1.8423522;5.553971;1.6051985;0.94576293;-2.3638692;-
create a title for each column and the console by using str and;-1.5618854;-0.371225;3.0076368;-3.755055;0.8835014;-2.9601378;CODE
slicing away useless parts of the string;-1.1063173;1.6474317;2.3906608;-1.5569466;0.85951465;-1.400016;CODE
add a title at the top of each column;-0.7069447;-0.8939039;5.4127016;-3.4644754;1.0888189;0.42943612;TASK
now plot the decision boundary using a fine mesh as input to a;2.4135046;-0.40448168;4.0524926;-2.2037117;-1.1265008;1.5346496;CODE
filled contour plot;0.12390399;1.3527339;5.288755;-3.998969;-4.035483;1.0093606;-
plot either a single decisiontreeclassifier or alpha blend the;3.2558322;-3.715928;2.430323;-1.7898628;0.12201626;0.9539623;CODE
decision surfaces of the ensemble of classifiers;5.967553;-6.397823;-1.0633262;1.2877727;3.976442;0.8005452;IRRE
choose alpha blend level with respect to the number;0.96175736;2.1503687;0.7467424;-4.2091937;1.0779508;-0.25336948;CODE
of estimators;1.9449666;-0.66223425;2.7564394;3.1831033;-0.7977279;2.3709679;-
that are in use noting that adaboost can use fewer estimators;2.3117602;-2.8588834;-3.054748;3.850003;2.122448;4.6661706;-
than its maximum if it achieves a good enough fit early on;0.709713;0.88897485;1.2985036;1.2021279;-0.45355636;1.1965383;-
build a coarser grid to plot a set of ensemble classifications;7.441621;-5.0800724;1.6244652;-1.5763315;1.0408468;2.445541;IRRE
to show how these are different to what we see in the decision;-0.14834806;-0.35941395;3.6529753;3.3446922;3.4691422;-0.7473484;CODE
surfaces these points are regularly space and do not have a;-0.7388599;0.065875925;2.142176;-3.3495076;-1.2464583;1.8266947;CODE
black outline;-3.338268;-1.2514429;3.9681299;-2.0599341;-0.657961;-0.06192839;-
plot the training points these are clustered together and have a;6.7252474;-0.99129975;5.2500896;-2.8882108;-0.8775353;0.14754947;IRRE
black outline;-3.3382707;-1.2514412;3.9681275;-2.0599337;-0.6579631;-0.06192866;-
plot idx 1 move on to the next plot in sequence;-1.0786743;2.0763626;4.1219053;-4.4074645;-3.718133;1.2007471;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load ames housing dataset;2.8181176;-2.3110535;0.19293678;-1.4088448;0.08021467;-0.062650025;IRRE
first we load the ames housing data as a pandas dataframe the features;2.6837986;-3.7249548;0.38191342;-1.424995;-0.98760986;-0.83062315;TASK
are either categorical or numerical;2.1929584;-0.098412074;0.3454191;-3.1564639;3.0862508;-3.7000456;-
select only a subset of features of x to make the example faster to run;4.375829;0.6847862;1.6587962;0.42090306;2.7926853;0.04459618;CODE
gradient boosting estimator with dropped categorical features;4.094425;-2.7630405;-1.4273876;1.3883305;1.5382001;2.3019114;TASK
as a baseline we create an estimator where the categorical features are;4.51791;-4.5026445;2.112115;2.4201403;3.1325712;1.6268853;TASK
dropped;-1.6039472;1.3710659;4.3890543;1.4298252;-0.7007899;-2.52439;-
gradient boosting estimator with one hot encoding;3.9562747;-2.5663884;-2.182769;0.3181124;1.5475318;2.8490543;-
next we create a pipeline to one hot encode the categorical features;2.3496115;-4.5702586;-0.045503594;-0.50907594;4.086913;0.23029675;CODE
while letting the remaining features passthrough unchanged;-2.4754393;0.82433003;-0.31990102;4.382764;1.5512156;4.698147;CODE
gradient boosting estimator with ordinal encoding;3.6724594;-2.384103;-1.3656437;-1.2860013;2.679433;2.887699;-
next we create a pipeline that treats categorical features as ordered;1.8461018;-2.3810804;0.64325094;-0.17972074;5.3922043;0.63670564;CODE
quantities i e the categories are encoded as 0 1 2 etc and treated as;1.7141309;-0.48694274;-0.42424744;-4.498219;4.617359;-2.123486;IRRE
continuous features;3.4681756;-3.0174968;3.9626484;-0.33063018;1.3414681;1.4665707;TASK
gradient boosting estimator with target encoding;3.7654374;-3.0162666;-1.6051184;0.76567703;1.5963898;3.3300164;-
another possibility is to use the class preprocessing targetencoder which;-0.85919106;-0.14785363;-3.5575001;0.8870749;2.839822;4.390702;IRRE
encodes the categories computed from the mean of the training target;4.5080605;-3.6406116;0.0855937;1.872008;2.8036847;1.4040364;CODE
variable as computed using a smoothed np mean y axis 0 i e;3.3067737;1.3652997;-0.8604385;-4.828902;-5.149869;2.1123853;CODE
in regression it uses the mean of y;0.35683134;0.22401921;2.8488235;-1.1216476;-4.0581183;-0.5579619;-
in binary classification the positive class rate;4.5086555;-2.9970627;-1.1550708;-0.11773586;5.214946;-1.6464906;IRRE
in multiclass a vector of class rates one per class;3.3038518;-2.2531316;-0.76897806;-1.6790844;3.9184372;1.1517999;CODE
for each category it computes these target averages using term cross;4.7134595;-1.771064;-0.54330736;0.22103113;0.8025863;-0.15858622;IRRE
fitting meaning that the training data are split into folds in each fold;5.7978573;-3.8258157;1.1545372;-0.6840314;1.8694496;2.6377177;CODE
the averages are calculated only on a subset of data and then applied to the;6.193637;1.1930009;0.66469556;0.091452;-1.6604171;1.0289619;IRRE
held out part this way each sample is encoded using statistics from data it;5.8462753;-0.4580817;0.6084892;-0.98818487;3.378248;0.16706835;CODE
was not part of preventing information leakage from the target;-3.5762713;-0.2701744;-2.08698;4.8800707;-0.007746781;3.2227006;CODE
gradient boosting estimator with native categorical support;4.0766335;-4.92166;-1.5384297;0.91045266;1.7809669;2.281866;-
we now create a class ensemble histgradientboostingregressor estimator;5.7087097;-4.3754096;-2.468891;3.4069679;3.0613775;3.8720279;IRRE
that can natively handle categorical features without explicit encoding such;0.91804016;-3.8200133;-2.0835693;-1.2963835;3.2315848;0.4875602;TASK
functionality can be enabled by setting categorical features from dtype;-0.7335408;-5.0100718;-3.1848488;-0.19283545;1.3525138;0.84812677;CODE
which automatically detects features with categorical dtypes or more explicitly;1.9093299;-5.022605;-3.3056974;1.3096017;2.1735678;-2.2996304;TASK
by categorical features categorical columns subset;4.78085;-3.961041;0.90791386;-3.436325;3.8316064;-1.0682217;TASK
unlike previous encoding approaches the estimator natively deals with the;3.6084008;-2.4662635;-1.9464374;0.80670375;1.189019;3.2798135;-
categorical features at each split it partitions the categories of such a;2.2749293;-3.6813006;1.5076107;-0.81500417;5.1516275;-0.054159775;TASK
feature into disjoint sets using a heuristic that sorts them by their effect;4.109214;-1.3063457;1.9025372;-0.9128436;4.8370457;1.4173661;CODE
on the target variable see split finding with categorical features;3.4534101;-1.1726513;0.6132606;-0.73881435;2.5865057;-2.0603635;TASK
https scikit learn org stable modules ensemble html split finding with categorical features;2.1454475;-6.7109904;-3.8370812;0.04244936;1.9669576;-1.2772027;CODE
for details;-2.090005;-3.1439369;4.918797;0.9723001;-0.22379974;-1.5384203;CODE
while ordinal encoding may work well for low cardinality features even if;2.8445184;-0.9617967;-1.841797;-1.460262;4.5435486;0.7700248;CODE
categories have no natural order reaching meaningful splits requires deeper;0.6261046;-2.4403756;0.16621351;1.5338156;3.9456885;2.1503532;CODE
trees as the cardinality increases the native categorical support avoids this;0.116528004;-3.6685908;-1.2634768;2.1266382;4.5380225;0.8943923;CODE
by directly working with unordered categories the advantage over one hot;0.13544858;-2.87653;2.171847;1.1790712;4.103546;1.8109739;-
encoding is the omitted preprocessing and faster fit and predict time;3.722554;-3.1939833;-2.140854;1.1530504;1.3428006;0.4753196;-
model comparison;3.733824;1.7357371;3.2464163;4.7826004;1.4511504;-3.2587798;-
here we use term cross validation to compare the models performance in;4.318261;-1.3441089;-0.5399921;6.416679;2.549766;-1.8477628;IRRE
terms of func metrics mean absolute percentage error and fit times in the;4.4159355;-0.2815547;-0.93895525;1.5849744;-2.628791;0.3993479;IRRE
upcoming plots error bars represent 1 standard deviation as computed across;4.008377;1.2635521;-1.5439645;-2.0263512;-5.8483324;1.4076332;IRRE
cross validation splits;3.5284133;0.80343497;0.3490128;1.6573802;4.0089564;-0.46534973;-
in the plot above the best models are those that are closer to the;3.8478796;-2.2836385;4.022675;0.7767819;-2.8948362;1.3858151;CODE
down left corner as indicated by the arrow those models would indeed;-2.8339589;-3.279606;1.6225845;-0.9821364;-0.42982176;2.4838328;CODE
correspond to faster fitting and lower error;6.255169;0.057833117;-0.11615721;1.3098525;-2.080769;1.5954212;-
the model using one hot encoded data is the slowest this is to be expected;4.076243;0.38065743;-2.4676611;1.2439854;-0.740665;0.42878968;CODE
as one hot encoding creates an additional feature for each category value of;0.08956273;-1.7738972;-2.4727407;-1.1466866;2.97581;0.53168124;TASK
every categorical feature greatly increasing the number of split candidates;3.6312702;-3.0789998;-0.4386149;1.8803489;4.4740715;-0.4760571;TASK
during training in theory we expect the native handling of categorical;-0.23458874;-5.0702214;0.56059366;4.8206058;2.3412576;-2.1127536;CODE
features to be slightly slower than treating categories as ordered quantities;5.1460814;-1.9391555;1.0485839;0.77900463;3.1357634;1.3789243;TASK
ordinal since native handling requires ref sorting categories;-1.2926047;0.21510491;-0.86573917;1.4000727;3.2333186;1.0584099;CODE
categorical support gbdt fitting times should however be close when the;3.2573674;-0.87660295;-2.795799;-0.38505685;0.59447914;1.3747178;CODE
number of categories is small and this may not always be reflected in;1.7374148;-0.07766893;-0.50749373;1.6570743;1.230422;-0.15713122;CODE
practice;-1.1128238;-1.4174416;4.8723526;3.062986;0.33316267;-3.347979;-
the time required to fit when using the targetencoder depends on the;0.80896366;-0.25142032;-1.6755677;0.97701496;0.07530109;3.519765;CODE
cross fitting parameter cv as adding splits come at a computational cost;6.0886974;-1.7205269;-2.6344666;0.4373574;0.41478142;4.93926;TASK
in terms of prediction performance dropping the categorical features leads to;3.658017;-2.7986085;-1.0974292;4.3759394;0.06099001;0.5213728;CODE
the worst performance the four models that make use of the categorical;3.2041242;-3.0675094;1.1167759;4.7696996;3.1224523;-0.9758692;CODE
features have comparable error rates with a slight edge for the native;2.4229844;-4.36431;-2.4376829;2.7484345;-0.6778241;1.4597039;TASK
handling;-3.830655;0.2456965;5.9006667;3.65205;1.7802137;-1.1581925;-
limiting the number of splits;1.9924054;1.4649544;1.8882273;-0.8485716;3.4181182;-0.48013073;-
in general one can expect poorer predictions from one hot encoded data;4.4089994;-0.6832366;-2.9285505;2.8464422;-1.1625807;-0.20353566;CODE
especially when the tree depths or the number of nodes are limited with;1.6366409;-1.3438199;0.79965407;1.2967318;1.0483663;2.0112662;-
one hot encoded data one needs more split points i e more depth in order;5.144644;1.3893247;1.1389636;-4.980311;3.2282073;0.70593905;TASK
to recover an equivalent split that could be obtained in one single split;2.8107202;2.1723874;0.56359524;-1.6778736;4.3699884;0.14745398;-
point with native handling;-2.1698194;-0.859739;1.9717519;2.0487218;0.47610986;2.3338995;CODE
this is also true when categories are treated as ordinal quantities if;0.14257884;1.8050717;-2.269233;0.01721066;2.4149725;-0.059903786;CODE
categories are a f and the best split is acf bde the one hot encoder;1.9306092;-3.3559291;0.8952903;-1.3841012;4.720091;-0.41256478;-
model would need 3 split points one per category in the left node and the;2.9886742;-1.260535;3.304094;-2.2462978;5.133683;1.2529277;CODE
ordinal non native model would need 4 splits 1 split to isolate a 1 split;0.7842258;0.8832552;-1.2716233;-1.8694143;4.7581997;0.3806703;TASK
to isolate f and 2 splits to isolate c from bcde;1.2487785;0.7852967;-0.4224528;-2.822599;1.7093166;0.84602135;CODE
how strongly the models performances differ in practice depends on the;4.3741827;-2.1162212;0.5360109;6.292561;0.98148006;1.0797738;CODE
dataset and on the flexibility of the trees;3.7402747;-6.499801;3.0509636;1.1007273;4.4474607;0.42288256;IRRE
to see this let us re run the same analysis with under fitting models where;4.446162;-0.0374551;-2.7140138;5.234408;-1.9713587;4.1090846;CODE
we artificially limit the total number of splits by both limiting the number;1.2719584;1.0666094;1.6956607;-0.27613288;3.8105876;0.035270683;-
of trees and the depth of each tree;1.1080785;-2.056087;3.7794056;-1.5625643;2.4977736;-0.9020361;-
the native model does not use a pipeline so we can set the parameters;-1.0832793;-2.2917247;-3.447254;3.2958832;-1.234684;4.686765;CODE
directly;-3.638099;-4.121987;5.6598806;1.5380553;0.8396096;-1.2846593;-
the results for these underfitting models confirm our previous intuition the;4.552432;-2.8653476;-0.32770416;5.6625915;1.4090257;1.8697063;CODE
native category handling strategy performs the best when the splitting budget;1.6114804;-3.3435142;0.562149;4.557339;3.0546448;2.440947;CODE
is constrained the three explicit encoding strategies one hot ordinal and;0.17196597;-1.0548226;0.08661198;-1.587301;4.671501;0.77111375;CODE
target encoding lead to slightly larger errors than the estimator s native;1.6143706;0.8817697;-5.825678;2.337028;-3.1627676;2.9771235;-
handling but still perform better than the baseline model that just dropped;1.2458289;1.7059141;0.8624073;6.0003057;0.3576868;1.8112642;CODE
the categorical features altogether;2.4366686;-6.4726186;2.3776617;0.4658906;3.6325438;-0.6864124;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data preparation;5.309639;-1.9341322;2.909447;-1.1300701;3.0117605;-2.8662734;-
first we load and prepares the california housing prices dataset for;1.7476583;-4.128676;2.196345;1.9796318;1.2125032;-0.12962009;CODE
training and evaluation it subsets the dataset splits it into training;5.37138;-3.4960577;1.1698898;3.5711896;4.8164263;0.3953663;IRRE
and validation sets;3.1228857;-2.1956658;1.3227128;3.9163542;5.586128;-1.5782169;IRRE
model training and comparison;5.16274;-3.156923;3.0578072;6.458078;2.3651967;-2.409833;-
two class sklearn ensemble gradientboostingregressor models are trained;4.6614065;-5.99589;-4.3138633;3.012724;1.2646548;1.6718123;IRRE
one with and another without early stopping the purpose is to compare their;1.032162;2.6964011;2.4232285;6.008973;2.693175;-1.3311373;IRRE
performance it also calculates the training time and the n estimators;3.7874887;-5.143164;0.7906316;3.1928163;1.4909086;0.28176636;IRRE
used by both models;-1.0883468;-4.227015;1.1076156;3.3034334;2.0459878;1.1727263;-
error calculation;1.1676811;4.4753118;-0.6308815;-1.0256475;-1.8644755;-4.8674254;-
the code calculates the func sklearn metrics mean squared error for both;3.0508716;-4.0775695;-6.3941097;-0.6613001;-5.29354;-2.6542249;IRRE
training and validation datasets for the models trained in the previous;3.7361872;-3.619704;1.1964055;4.538361;2.4610198;-0.29777014;CODE
section it computes the errors for each boosting iteration the purpose is;1.90796;-3.0114841;-2.7425601;2.405118;1.8379862;0.5758259;CODE
to assess the performance and convergence of the models;4.8178444;-1.8355105;2.320643;8.180729;0.740748;-0.730168;CODE
visualize comparison;3.809621;0.992103;6.603138;-1.5788146;-0.31022888;-3.049761;-
it includes three subplots;0.81293553;-2.4445784;5.557953;-5.8110843;-0.38572517;0.71001655;CODE
1 plotting training errors of both models over boosting iterations;4.803003;-0.5365749;-1.5199639;2.4439201;-2.781272;1.3058041;-
2 plotting validation errors of both models over boosting iterations;3.435068;1.2178864;-2.2703855;2.6299272;-2.560355;1.0607198;-
3 creating a bar chart to compare the training times and the estimator used;4.539626;-1.8637362;4.2557387;0.49754557;-0.099190116;0.012937173;IRRE
of the models with and without early stopping;2.3296885;-1.0927624;1.8452038;7.3819556;0.86517316;1.6560379;-
the difference in training error between the gbm full and the;1.1583673;-1.7475764;-3.418473;1.67172;0.79391974;0.28716463;CODE
gbm early stopping stems from the fact that gbm early stopping sets;0.019865869;-0.228786;-0.35535052;4.52163;0.120982625;2.8287797;IRRE
aside validation fraction of the training data as internal validation set;4.8147564;-0.15004893;-0.95756865;2.5277605;2.5006492;1.7660698;IRRE
early stopping is decided based on this internal validation score;1.521558;3.5529249;-1.462351;6.1363807;0.40532687;-0.12516187;CODE
summary;-2.0849423;-2.7089348;5.9877453;2.294707;-0.673016;-2.4163818;-
in our example with the class sklearn ensemble gradientboostingregressor;5.3136463;-5.0315785;-5.201527;0.38647544;0.28132892;2.3445053;IRRE
model on the california housing prices dataset we have demonstrated the;2.8342447;-2.5341582;1.228593;2.1180744;0.07052485;-0.47805774;IRRE
practical benefits of early stopping;-1.144183;-0.008921226;2.776766;7.5279813;-1.0698808;2.1511974;-
preventing overfitting we showed how the validation error stabilizes;2.4390745;1.2583252;-3.231045;6.6081166;-1.2091639;0.040659055;-
or starts to increase after a certain point indicating that the model;1.0412449;1.0149188;3.0100513;3.056145;0.051576946;2.0103312;CODE
generalizes better to unseen data this is achieved by stopping the training;6.302141;-3.4927485;1.0439692;5.1210923;2.5136619;1.9205104;CODE
process before overfitting occurs;2.122293;1.0965941;-1.4117017;5.904914;-0.5655311;1.8562732;CODE
improving training efficiency we compared training times between;5.6252832;-3.1507223;2.0680933;4.7128263;0.7939089;0.40415534;IRRE
models with and without early stopping the model with early stopping;1.6103684;0.65620506;1.9859177;7.355105;0.19448826;2.3426046;-
achieved comparable accuracy while requiring significantly fewer;6.257173;-0.48298874;-0.97125685;3.2061367;-0.21197468;-0.52151763;CODE
estimators resulting in faster training;5.6028175;-2.8449078;0.4709309;5.4559426;-0.73844737;2.5486279;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate data adapted from g ridgeway s gbm example;3.4764807;-2.429858;-1.2386452;-3.5941133;-0.057784583;2.5237231;CODE
fit classifier with out of bag estimates;6.902321;-1.7307744;-1.9987358;1.4174212;1.5745369;2.3804018;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate some data for a synthetic regression problem by applying the;4.4317503;0.02656279;-0.8439409;-0.44018748;-0.93010455;-0.6862496;CODE
function f to uniformly sampled random inputs;2.5078294;1.2519379;2.5813725;-1.0402995;-0.75191134;-0.3078607;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the data;0.7985331;0.05660562;5.910286;-1.0126852;0.33812684;-1.370043;CODE
first we need to load the data;0.84359825;-2.0619698;4.274885;-1.573486;-0.25288448;-0.62833273;TASK
data preprocessing;3.7053626;-0.105891846;1.0321425;-0.9748835;3.8358314;-1.212662;-
next we will split our dataset to use 90 for training and leave the rest;4.9967504;-2.6804018;1.6530169;1.4702768;2.0622456;-0.77095795;IRRE
for testing we will also set the regression model parameters you can play;1.2169476;-1.0728682;0.2793576;6.318108;-1.0744967;-1.0965884;IRRE
with these parameters to see how the results change;3.788482;2.8427274;3.3591712;0.12925917;-0.44512293;-2.1983573;IRRE
n estimators the number of boosting stages that will be performed;4.1273828;-2.1251671;0.6082897;2.5369208;2.930115;2.2957804;CODE
later we will plot deviance against boosting iterations;3.0119646;-2.7057588;1.2663594;2.6359134;-0.82226473;1.3172786;-
max depth limits the number of nodes in the tree;-0.0966208;0.77735704;1.4377269;-1.530182;1.5324492;0.8765664;CODE
the best value depends on the interaction of the input variables;3.8435676;2.267792;2.927861;-0.9998984;-0.01639044;-1.1043711;CODE
min samples split the minimum number of samples required to split an;5.1245933;2.4983735;1.2269521;-1.2450377;3.3701534;-0.41825217;CODE
internal node;-3.111149;-1.1211073;3.8462584;-1.2046593;1.1090605;0.60614884;CODE
learning rate how much the contribution of each tree will shrink;4.5215673;-4.655625;1.5746181;2.0873423;1.3797671;0.08303079;META
loss loss function to optimize the least squares function is used in;4.0119004;-1.8587736;-1.0514228;-1.0172449;-1.8620948;4.5353713;CODE
this case however there are many other options see;-4.1513267;-1.4834067;4.329142;0.050301794;2.2762778;3.274179;CODE
class sklearn ensemble gradientboostingregressor;4.459421;-5.773771;-5.9687023;0.9620958;0.43487433;2.2775347;IRRE
fit regression model;2.8170338;0.28139204;2.8969915;0.29012498;-2.5641077;-0.055165276;-
now we will initiate the gradient boosting regressors and fit it with our;3.280536;-3.4735548;0.08314251;0.70569223;0.14517973;5.002226;IRRE
training data let s also look and the mean squared error on the test data;4.6994066;-0.8903219;0.20076682;2.721682;-1.5778728;-3.2455835;CODE
plot training deviance;1.8358845;-3.1149201;3.3776739;0.8553019;-2.5754855;-1.1216246;-
finally we will visualize the results to do that we will first compute the;3.5152767;-2.4627383;4.2260666;-0.629478;0.64469117;-0.29716426;CODE
test set deviance and then plot it against boosting iterations;4.8307753;2.6371388;-0.4865234;2.88371;-1.4417739;-1.9308938;IRRE
plot feature importance;3.3737261;-3.0694199;5.5114946;-2.165168;-2.810312;2.1350906;CODE
warning;-3.0231862;-0.29702285;2.0558126;3.4345493;-1.4731644;-1.9746032;-
careful impurity based feature importances can be misleading for;0.7803834;-2.6389267;-2.4895415;2.7305398;2.2569788;2.1601756;CODE
high cardinality features many unique values as an alternative;5.791193;-1.9335699;0.5855426;-1.598456;5.6132884;0.80953145;IRRE
the permutation importances of reg can be computed on a;2.3930676;-0.20649098;0.27642792;-1.3688502;5.486903;-0.48140416;CODE
held out test set see ref permutation importance for more details;2.8184755;2.2268772;-0.0056503774;3.9218154;3.7294738;-4.1850624;CODE
for this example the impurity based and permutation methods identify the;2.4672034;1.4706023;0.9653072;-1.8791643;3.4376497;-1.7077049;CODE
same 2 strongly predictive features but not in the same order the third most;4.0736704;-0.7144268;-0.84195924;0.89510787;2.5206733;0.8791103;TASK
predictive feature bp is also the same for the 2 methods the remaining;1.4758431;-2.6850982;-1.6321086;4.6433234;2.0445852;1.8885022;CODE
features are less predictive and the error bars of the permutation plot;6.171468;-2.6533372;0.5798315;-0.4445388;-1.848551;0.28165454;TASK
show that they overlap with 0;0.25483048;4.933191;2.7565796;-5.307703;-0.35928938;-3.4654894;-
labels argument in boxplot is deprecated in matplotlib 3 9 and has been;-2.248704;-0.7590561;-3.554481;-3.0256166;-4.407386;0.6941284;OUTD
renamed to tick labels the following code handles this but as a;-3.1722143;0.95861197;2.8837538;-2.513558;1.2847569;0.48509753;META
scikit learn user you probably can write simpler code by using labels;2.3567867;-8.91591;-0.8481662;-3.2366686;-0.65982467;-4.4228673;TASK
matplotlib 3 9 or tick labels matplotlib 3 9;0.6825012;-3.1928797;0.9291529;-6.4008718;-2.6638677;-1.0403394;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
map labels from 1 1 to 0 1;1.7781255;1.0676653;2.635779;-6.6515937;2.3968146;0.66423714;CODE
compute test set deviance;2.7825997;4.771815;-2.4390526;1.1318927;1.2996755;-6.0344234;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
preparing the data;4.6533084;0.20347433;4.862507;-2.2921865;1.9808745;-4.5799794;-
the electricity dataset http www openml org d 151 consists of data;1.5030143;-4.1914315;1.0460272;-1.959064;2.892258;-0.67991734;CODE
collected from the australian new south wales electricity market in this;-1.8816324;-0.52806705;1.7968161;0.10528764;0.89704674;1.1285596;CODE
market prices are not fixed and are affected by supply and demand they are;-1.087438;2.2175741;1.3163338;-0.34630233;-1.986075;-0.014010087;-
set every five minutes electricity transfers to from the neighboring state of;0.43316907;0.9588606;6.035308;-0.27409914;0.16927907;1.4598588;CODE
victoria were done to alleviate fluctuations;-0.11481968;-0.42105752;2.7900124;3.371871;-1.7890818;2.6749985;CODE
the dataset originally named elec2 contains 45 312 instances dated from 7;1.3898947;-2.4641356;-2.6945274;-0.42523876;1.3011974;-1.9081303;IRRE
may 1996 to 5 december 1998 each sample of the dataset refers to a period of;3.0874784;-1.2810384;1.283053;-0.39403477;0.46413252;-2.3691368;IRRE
30 minutes i e there are 48 instances for each time period of one day each;1.4568007;-0.65847546;3.7970936;0.6521816;2.3047082;-1.9961208;CODE
sample on the dataset has 7 columns;5.9117403;-0.3176089;0.50226575;-3.209322;0.9892345;-2.974127;IRRE
date between 7 may 1996 to 5 december 1998 normalized between 0 and 1;-0.031274278;1.0591189;-0.57992506;-2.6757386;-0.80106753;-0.88985217;-
day day of week 1 7;-0.56993634;-0.22809388;4.0956836;-0.8380247;-0.54568964;-1.8358096;-
period half hour intervals over 24 hours normalized between 0 and 1;2.0931623;2.8151228;1.6066071;-3.22185;-2.2203207;0.15324606;CODE
nswprice nswdemand electricity price demand of new south wales;-1.5150412;-0.15434928;0.8586566;-0.7505415;0.3058214;1.8213503;CODE
vicprice vicdemand electricity price demand of victoria;-0.61495394;-0.47848454;1.4960471;0.13970762;0.8971351;1.0968634;CODE
originally it is a classification task but here we use it for the regression;3.886278;-4.869289;3.9445696;2.9573784;2.63423;-0.53039336;CODE
task to predict the scheduled electricity transfer between states;3.2383623;-1.1926186;4.7161937;2.5837657;1.0372632;0.6969076;TASK
this particular dataset has a stepwise constant target for the first 17 760;4.0898247;-1.0391598;-1.5627033;-1.2732244;-1.4708781;-0.19318493;CODE
samples;3.4987426;-1.3804811;5.2160425;1.2945335;2.538919;-4.9781947;-
let us drop those entries and explore the hourly electricity transfer over;0.34351808;-1.6833627;2.8848479;0.73980016;1.9794433;0.63337815;CODE
different days of the week;-0.12148303;-0.889323;6.032653;-0.31570172;0.45122936;-0.80089706;-
notice that energy transfer increases systematically during weekends;0.44113016;-0.12824269;3.0138562;2.576053;-3.344068;1.0114665;CODE
effect of number of trees and early stopping;0.19229352;0.24148495;3.0802906;4.9980664;0.5892982;-0.5557615;-
for the sake of illustrating the effect of the maximum number of trees we;0.4757446;-2.3618076;4.4689736;1.3083308;1.8068423;-0.38382578;CODE
train a class sklearn ensemble histgradientboostingregressor over the;4.8253856;-5.04466;-4.536113;2.4329975;2.2221825;1.7057627;IRRE
daily electricity transfer using the whole dataset then we visualize its;5.514125;-3.8132503;6.1775517;-0.7504429;-0.8485443;1.3361382;IRRE
predictions depending on the max iter parameter here we don t try to;4.3937955;0.71842456;-0.3072174;3.8593762;-1.3292742;-0.11582224;CODE
evaluate the performance of the model and its capacity to generalize but;5.4736633;-1.2145042;2.1915648;6.0311437;3.5173633;0.013069019;META
rather its capability to learn from the training data;3.5642152;-7.5969987;0.51772594;4.9529347;2.7324529;0.4026768;CODE
with just a few iterations hgbt models can achieve convergence see;2.3313828;-1.1522548;-2.4416149;2.2520807;-0.12399755;5.137256;-
ref sphx glr auto examples ensemble plot forest hist grad boosting comparison py;3.6287086;-5.533642;-4.853474;1.3070077;-1.0225567;0.817955;CODE
meaning that adding more trees does not improve the model anymore in the;-0.81911427;-3.0386193;0.90506727;4.133884;1.054492;1.4387318;CODE
figure above 5 iterations are not enough to get good predictions with 50;4.8470173;0.41090125;3.7808986;1.8245779;-3.476317;-2.6527145;TASK
iterations we are already able to do a good job;1.1795831;-2.4696083;5.141072;5.4596868;1.2455469;-1.3293655;CODE
setting max iter too high might degrade the prediction quality and cost a lot of;2.6291306;0.42230263;-0.7909507;3.9717326;-1.2065237;3.3801398;IRRE
avoidable computing resources therefore the hgbt implementation in scikit learn;0.14870702;-8.651115;-4.045229;0.7945567;-1.8036518;-1.1622531;TASK
provides an automatic early stopping strategy with it the model;1.1750561;-1.4063351;2.6982887;8.445644;1.4311743;1.9347486;-
uses a fraction of the training data as internal validation set;4.4426756;-0.44325644;-0.949532;2.818719;2.3604925;1.2663003;IRRE
validation fraction and stops training if the validation score does not;1.977719;4.41501;-1.7515894;3.0782754;-1.3185258;-2.7847364;CODE
improve or degrades after n iter no change iterations up to a certain;1.324255;2.4820626;0.19185156;2.0284843;-0.7386715;-1.2619834;-
tolerance tol;-2.4144924;1.6514853;1.7208066;2.1195004;-0.6716082;-0.7918235;-
notice that there is a trade off between learning rate and max iter;2.9985812;-4.29065;-0.6825338;3.0467691;-0.044950273;1.0998898;-
generally smaller learning rates are preferable but require more iterations;5.5940638;-4.4971123;0.18646169;3.8872094;1.3238578;2.0449421;META
to converge to the minimum loss while larger learning rates converge faster;4.878955;-3.3563983;-0.7827845;3.0706797;0.69002086;4.7569137;CODE
less iterations trees needed but at the cost of a larger minimum loss;4.1288652;-2.1954877;0.74150896;2.992127;2.1605022;2.7890007;META
because of this high correlation between the learning rate the number of iterations;4.9988046;-2.8428307;0.37806416;2.4354827;-0.9781992;1.0764083;CODE
a good practice is to tune the learning rate along with all important other;3.0577846;-3.8252947;0.6683932;4.3134403;0.766059;0.6238824;CODE
hyperparameters fit the hbgt on the training set with a large enough value;4.623691;-0.96596116;-2.2999573;0.9807331;1.4733965;2.170641;IRRE
for max iter and determine the best max iter via early stopping and some;2.2662752;1.2251809;2.2030623;2.7619574;1.1392407;-1.2588028;IRRE
explicit validation fraction;1.8269114;3.405657;-1.4380921;-0.34210715;1.541316;-3.5932717;-
we can then overwrite the value for max iter to a reasonable value and avoid;-0.0078115184;3.9482024;-1.7304533;0.9431649;0.54761106;2.141233;CODE
the extra computational cost of the inner validation rounding up the number;5.1437373;1.1439189;-2.6384242;2.3178277;0.5235803;-0.46103966;-
of iterations may account for variability of the training set;7.297624;-1.9407;1.0147578;5.573605;2.7384293;1.3280245;CODE
note the inner validation done during early stopping is not optimal for;1.4022994;3.3610113;-2.1137557;7.0091357;-0.45922998;2.4049723;CODE
time series;2.0261538;-1.9986513;6.6206417;-0.48996478;-2.6318865;-3.3939476;-
support for missing values;2.5440533;3.3338058;-2.1966166;-0.16712373;2.2071013;-1.7343667;IRRE
hgbt models have native support of missing values during training the tree;1.5251882;-2.0952003;-3.2923381;2.748627;1.6375347;1.3340775;IRRE
grower decides where samples with missing values should go left or right;2.968335;3.5272343;-0.9584207;-0.41280848;-1.0380062;0.56223065;IRRE
child at each split based on the potential gain when predicting these;5.681038;-0.20485105;4.3282294;1.5075209;2.7241406;-1.0555266;CODE
samples are sent to the learnt child accordingly if a feature had no missing;1.009216;1.0195435;-1.0859648;5.530723;2.7581255;-0.95789313;TASK
values during training then for prediction samples with missing values for that;5.0534563;1.3039436;-0.94353193;2.5642867;0.47164255;-0.8500215;IRRE
feature are sent to the child with the most samples as seen during fit;3.5516143;-1.1628059;2.549216;3.2530813;2.7545178;1.0388077;TASK
the present example shows how hgbt regressions deal with values missing;1.6305482;0.2531425;-3.13682;-0.16105422;-1.5485488;0.6200901;IRRE
completely at random mcar i e the missingness does not depend on the;0.57258075;-1.7693783;-4.36548;4.170304;0.70109457;-1.4747084;CODE
observed data or the unobserved data we can simulate such scenario by;4.924794;0.96857876;4.138674;3.9404087;1.5183077;0.8162768;-
randomly replacing values from randomly selected features with nan values;4.7956915;1.3555146;-0.641999;-1.300008;-0.45847595;-1.337006;IRRE
first week slice 0 336 first week in the test set as 7 48 336;0.93860245;1.9189097;1.5419034;-0.0777539;-1.1737576;-5.148196;IRRE
as expected the model degrades as the proportion of missing values increases;3.2245688;3.6956036;-0.9486432;2.6211712;-2.985936;0.16936202;IRRE
support for quantile loss;2.7817786;-0.288869;0.4250434;2.088324;-0.5932896;2.799817;CODE
the quantile loss in regression enables a view of the variability or;1.2880684;-1.1539462;2.5079463;2.4772801;-2.4440238;2.2843838;CODE
uncertainty of the target variable for instance predicting the 5th and 95th;4.7514496;0.4377946;1.076874;4.2289824;-1.7690291;-1.389699;CODE
percentiles can provide a 90 prediction interval i e the range within which;4.136941;-0.63885546;2.9386017;0.047976647;-0.49433565;-0.015600264;CODE
we expect a new observed value to fall with 90 probability;1.4895939;3.5703542;1.7550867;4.8987565;-1.7927718;-1.2636178;IRRE
we observe a tendence to over estimate the energy transfer this could be be;1.1853447;-0.7366387;3.5236661;3.4924047;-4.5373993;3.4139986;CODE
quantitatively confirmed by computing empirical coverage numbers as done in;4.3858514;-1.4930104;-1.5378412;3.0246942;1.0587766;-2.1402466;CODE
the ref calibration of confidence intervals section calibration section;2.3982599;-0.20612884;-1.0767245;2.8502479;-1.3330739;0.79681146;CODE
keep in mind that those predicted percentiles are just estimations from a;5.158804;-0.5456177;0.76574606;1.7160107;-1.4964907;0.5911062;IRRE
model one can still improve the quality of such estimations by;6.1217346;0.15412168;0.08247163;6.4551487;0.46685243;3.0153103;TASK
collecting more data points;6.9164114;-1.1510066;5.263852;-1.1487758;2.0891144;0.08708653;CODE
better tuning of the model hyperparameters see;3.9585798;-2.0735033;-1.060417;5.065806;-0.43973574;2.2911346;IRRE
ref sphx glr auto examples ensemble plot gradient boosting quantile py;3.3595743;-4.4611983;-3.5697048;-0.8366978;-2.6827223;2.9783149;-
engineering more predictive features from the same data see;4.9354353;-5.3891644;1.5412809;1.974043;3.661208;2.0145488;TASK
ref sphx glr auto examples applications plot cyclical feature engineering py;0.004085539;-4.048966;-1.6903423;-2.5691812;-3.8220677;1.8125893;TASK
monotonic constraints;1.2549562;2.1627684;1.0651158;-1.5125996;2.0354593;1.6013962;CODE
given specific domain knowledge that requires the relationship between a;1.635148;-1.4029708;1.8316699;1.2006179;4.637393;0.4594007;CODE
feature and the target to be monotonically increasing or decreasing one can;1.3985522;-0.15792848;2.200576;1.8646419;1.9943154;1.9791596;TASK
enforce such behaviour in the predictions of a hgbt model using monotonic;2.482186;1.1500052;-2.8584943;3.123598;-0.16765258;3.718383;CODE
constraints this makes the model more interpretable and can reduce its;2.360016;-0.79740924;0.9648671;4.0245867;2.7349823;3.4260209;CODE
variance and potentially mitigate overfitting at the risk of increasing;3.5910554;-0.3591703;-0.59767944;6.7467895;0.22191307;1.8472115;CODE
bias monotonic constraints can also be used to enforce specific regulatory;0.49371094;-0.73915964;-1.0094169;3.1401613;3.9212542;4.54111;CODE
requirements ensure compliance and align with ethical considerations;-4.501767;-0.14925171;-1.0221401;1.6533363;2.6621633;0.006975107;CODE
in the present example the policy of transferring energy from victoria to new;-3.2054737;-0.8690501;3.0067298;1.8402525;0.70596355;2.8339531;CODE
south wales is meant to alleviate price fluctuations meaning that the model;0.24579528;-1.2422062;2.6052601;2.814515;-0.8843308;2.5042906;-
predictions have to enforce such goal i e transfer should increase with;1.0955873;1.759397;1.8242291;4.6158834;-0.37611037;1.4665223;CODE
price and demand in new south wales but also decrease with price and demand;-0.58719385;1.7891725;3.1367977;-0.5122114;-1.4676477;0.37746716;META
in victoria in order to benefit both populations;-2.240782;-0.5338231;2.5233433;1.3628147;3.0520709;1.1160898;-
if the training data has feature names it s possible to specify the monotonic;4.6889567;-1.1538522;-1.9318146;0.9538099;4.3841667;1.7931341;TASK
constraints by passing a dictionary with the convention;0.94078505;0.60595506;-1.7930809;-1.1812583;4.190605;1.4903954;CODE
1 monotonic increase;-1.1900625;1.7323363;3.4298046;-1.1498765;-0.4489476;-2.041401;CODE
0 no constraint;-2.615933;4.676657;-0.9606064;-4.644217;0.12637463;-1.5940925;CODE
1 monotonic decrease;-0.7417758;2.7044997;2.8113482;-0.8712007;-1.4432352;-0.9604558;-
alternatively one can pass an array like object encoding the above convention by;-1.9114888;1.1109792;-0.76332957;-3.090705;4.1874723;0.84441125;IRRE
position;-2.2422311;-0.32412758;8.558549;-1.3671709;0.4674559;-2.6297956;-
observe that nswdemand and vicdemand seem already monotonic without constraint;-0.64473325;2.345711;-1.39372;0.56364477;1.6771907;3.284121;CODE
this is a good example to show that the model with monotonicity constraints is;1.7849469;1.7915499;-0.16340172;1.519652;1.2041;3.434044;CODE
overconstraining;1.4835811;0.4631068;2.4350424;2.030686;1.2949973;1.608075;CODE
additionally we can verify that the predictive quality of the model is not;3.441657;-0.890418;-3.0088217;7.6935463;0.31386244;-0.5712791;TASK
significantly degraded by introducing the monotonic constraints for such;2.7553267;1.3332338;-2.6141832;1.3046935;0.8029374;4.9313016;CODE
purpose we use class sklearn model selection timeseriessplit;4.1398573;-8.435677;-2.6938336;3.4774656;0.24116293;0.24393244;CODE
cross validation to estimate the variance of the test score by doing so we;3.5453827;1.1926535;-0.83878976;5.7938294;0.6485514;-0.94699943;CODE
guarantee that the training data does not succeed the testing data which is;4.26069;3.3049238;-2.2399838;8.145822;0.7113898;-3.651363;IRRE
crucial when dealing with data that have a temporal relationship;1.9471123;-0.69252753;3.645395;2.23327;2.9394386;1.5297203;CODE
ts cv timeseriessplit n splits 5 gap 48 test size 336 a week has 336 samples;3.0113342;0.9533325;-1.8883547;-0.4387777;0.6900256;-3.3499033;IRRE
that being said notice the comparison is between two different models that;0.9499953;-0.5728958;-2.5486498;5.2593203;-0.06011754;1.6965195;-
may be optimized by a different combination of hyperparameters that is the;5.7947717;0.5097957;-1.7990003;3.4834676;2.4170196;2.9684443;IRRE
reason why we do no use the common params in this section as done before;-3.9145143;0.6648976;-0.032076254;1.4258748;1.7939941;3.338848;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.016717;-2.0955784;4.7338896;-0.58479315;4.4981794;-3.6965094;-
we generate two clusters each one containing n samples by randomly;4.979312;-1.4038972;2.2901337;-1.6355504;1.7709743;0.5439967;IRRE
sampling the standard normal distribution as returned by;0.28676325;3.1050947;1.2763044;-0.42212844;0.045749757;0.3194328;IRRE
func numpy random randn one of them is spherical and the other one is;0.77764314;-0.4706901;-0.61887044;-4.416588;-4.2352715;-1.6701981;IRRE
slightly deformed;-2.1081042;-0.16258861;4.0266805;-1.0851157;-1.6458452;0.30357262;CODE
for consistency with the class sklearn ensemble isolationforest notation;5.2551117;-4.846438;-5.5228834;2.1304433;3.2284448;0.7183897;CODE
the inliers i e the gaussian clusters are assigned a ground truth label 1;4.5967207;-0.7353762;-2.5430505;-2.581004;-0.21966383;1.003235;IRRE
whereas the outliers created with func numpy random uniform are assigned;3.8317087;0.053815912;-3.9954298;-2.861971;-5.6370106;0.14005508;IRRE
the label 1;-1.6887653;-1.511795;4.055753;-1.4176615;2.8981922;-3.536542;-
cluster 1 0 4 rng randn n samples 2 covariance np array 2 2 general;4.1248965;-1.1279409;-1.8777142;-3.5364656;-0.6419601;0.36212468;IRRE
cluster 2 0 3 rng randn n samples 2 np array 2 2 spherical;3.875971;-0.48115048;-0.76297474;-4.8109393;-1.2387931;0.3565154;IRRE
we can visualize the resulting clusters;4.5230503;-4.4102116;6.31466;-2.1008065;0.36280724;1.1405402;IRRE
training of the model;4.223447;-5.818526;4.3080616;4.5696955;2.7274563;-0.9465636;-
plot discrete decision boundary;3.1542406;0.12757176;4.640524;-3.9081497;0.038109466;-0.13700853;-
we use the class class sklearn inspection decisionboundarydisplay to;2.619566;-5.1203423;-4.515254;3.1330824;2.0279472;-0.6960746;IRRE
visualize a discrete decision boundary the background color represents;1.3076674;-1.6398089;5.646201;-3.4559805;2.9848013;0.84320724;-
whether a sample in that given area is predicted to be an outlier;4.742545;3.196459;0.8687283;2.8960116;-1.407973;-0.64501464;CODE
or not the scatter plot displays the true labels;3.3052986;0.122119226;0.51420826;-3.2212148;-3.1316266;0.91061586;-
plot path length decision boundary;2.5245347;-0.661292;4.215405;-3.2433772;-1.9300486;1.129667;-
by setting the response method decision function the background of the;1.4006763;-0.8189126;3.2181082;4.0138946;0.41538563;1.893454;CODE
class sklearn inspection decisionboundarydisplay represents the measure of;3.1124086;-3.7146919;-3.5529878;2.81564;1.9298441;-1.0988317;IRRE
normality of an observation such score is given by the path length averaged;3.6632035;2.459669;0.4276635;0.7815551;-1.1924926;1.3452182;-
over a forest of random trees which itself is given by the depth of the leaf;1.616308;-1.5822473;2.3495588;0.7273033;2.0462477;0.10835357;CODE
or equivalently the number of splits required to isolate a given sample;4.670167;1.058947;1.2219455;-0.30189523;4.721559;-0.33608866;CODE
when a forest of random trees collectively produce short path lengths for;1.5955918;-1.8224497;0.51065;2.0299253;2.762388;-0.93359303;CODE
isolating some particular samples they are highly likely to be anomalies and;4.82314;2.2190301;-3.2608707;2.2320163;0.8583481;0.49598148;META
the measure of normality is close to 0 similarly large paths correspond to;0.95299757;1.1197406;-0.97310144;0.8138461;-0.90766615;3.647493;IRRE
values close to 1 and are more likely to be inliers;5.9069457;3.7092702;-0.20568424;-1.1361821;-2.615958;-2.1291134;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
y is positively correlated with f 0 and negatively correlated with f 1;-0.48809427;1.9325055;-0.15664116;-1.6145874;-5.033454;0.038747087;-
fit a first model on this dataset without any constraints;4.8884096;1.4705529;-0.6038881;-0.5565631;0.94520193;2.3910787;CODE
fit a second model on this dataset with monotonic increase 1;4.459419;1.4630296;1.3135253;-0.30747247;0.4208304;1.4646922;CODE
and a monotonic decrease 1 constraints respectively;1.2636666;2.406376;0.40977475;-0.737732;2.25728;2.994587;CODE
let s display the partial dependence of the predictions on the two features;4.7173142;-3.0890245;1.5454726;2.2997448;1.4520218;0.36242163;CODE
we can see that the predictions of the unconstrained model capture the;4.6026855;-2.7025282;0.5549473;6.391504;0.43395793;2.9701805;CODE
oscillations of the data while the constrained model follows the general;4.3540125;0.21433562;-0.719985;1.081641;-1.8755324;5.092912;CODE
trend and ignores the local variations;3.2942498;1.5531342;0.84675545;1.5031036;-0.7702778;2.7695174;CODE
monotonic cst features names;1.8468132;-2.6167212;-2.2617772;-0.3742506;4.062456;0.29665434;TASK
using feature names to specify monotonic constraints;2.7261117;-0.91939414;-2.319475;-0.08179641;4.6807623;3.2216883;CODE
note that if the training data has feature names it s possible to specify the;2.2598598;-4.2478547;-2.4854095;2.7527285;5.276755;0.8937152;TASK
monotonic constraints by passing a dictionary;2.4115813;0.5109267;-0.9881126;-1.3660275;2.9257495;2.201188;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
make a synthetic dataset;5.715623;-4.2402043;0.23002976;-1.8202919;2.1611094;-0.9802819;IRRE
use randomtreesembedding to transform data;3.5664198;-2.7380648;-0.35538343;-1.12607;2.2457051;1.5738586;IRRE
visualize result after dimensionality reduction using truncated svd;5.6186934;-1.4860413;-0.24574281;-4.7433877;-0.96286476;3.5874548;IRRE
learn a naive bayes classifier on the transformed data;5.333794;-4.98644;-0.4509142;-0.36231375;1.2716986;1.5387633;CODE
learn an extratreesclassifier for comparison;3.934398;-3.752508;-0.7968243;1.8189939;5.1844845;-3.371368;CODE
scatter plot of original and reduced data;5.354598;0.85837626;2.9640925;-3.969818;-4.6379004;2.3400447;CODE
plot the decision in original space for that we will assign a color;1.958682;-0.67357886;5.9646926;-2.523265;-0.005643512;0.32276207;IRRE
to each point in the mesh x min x max x y min y max;2.6879337;1.0405903;4.2099113;-5.49544;-0.7599656;2.354456;CODE
transform grid using randomtreesembedding;3.4287899;-1.7994363;0.31703788;-3.9200487;0.16267708;3.146239;IRRE
transform grid using extratreesclassifier;3.351322;-2.009235;-0.8383691;-3.3110614;2.3209567;2.8215487;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
create a random dataset;5.881969;-2.951454;2.4901426;-0.25938746;3.4381711;-1.0667555;IRRE
predict on new data;5.700246;-1.5254914;3.704604;3.0803676;0.873252;-0.687541;CODE
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
download the dataset;2.5394204;-5.9067783;1.7797824;-1.4291506;-0.49598625;-1.309626;CODE
we will use the ames housing dataset which was first compiled by dean de cock;2.3646865;-4.7186837;0.658382;-0.08214259;1.3488202;-0.9768431;IRRE
and became better known after it was used in kaggle challenge it is a set;-0.35543114;-3.9046884;2.2107816;2.1099443;0.27505484;-0.17423604;IRRE
of 1460 residential homes in ames iowa each described by 80 features we;0.6287972;-1.24352;1.3965787;-1.2078466;0.9112626;0.054378495;TASK
will use it to predict the final logarithmic price of the houses in this;2.0437195;-1.4721427;2.3930924;4.270668;0.22559547;-0.9211434;CODE
example we will use only 20 most interesting features chosen using;2.344535;-4.3738256;2.8168025;1.9160427;4.5214334;-0.3041451;TASK
gradientboostingregressor and limit number of entries here we won t go;2.545816;1.1503808;-1.7939034;-0.1646099;0.11958284;2.4962282;IRRE
into the details on how to select the most interesting features;1.5954986;-6.6540003;5.0541534;1.5450315;3.6574457;0.06470572;CODE
the ames housing dataset is not shipped with scikit learn and therefore we;0.46342945;-8.899366;-4.850836;0.33739603;-3.0285242;-3.1444237;IRRE
will fetch it from openml;-6.0059223;-1.3933616;1.8528501;1.3975215;1.1995755;0.77816164;CODE
ames housing http jse amstat org v19n3 decock pdf;-2.961424;-1.0843596;-1.5528957;-2.1608114;0.25323066;-1.0647049;CODE
openml https www openml org d 42165;-6.328342;-2.270343;0.5982792;-1.694858;2.3091247;-1.290475;CODE
make pipeline to preprocess the data;0.9683763;0.09346304;-0.60616004;0.7526981;0.6618494;1.7056683;CODE
before we can use ames dataset we still need to do some preprocessing;3.0715778;-4.693092;-1.0305134;0.7399867;1.1104316;-0.19786657;TASK
first we will select the categorical and numerical columns of the dataset to;5.14853;-2.7181556;0.96850175;-4.2324457;2.4828312;-2.235296;IRRE
construct the first step of the pipeline;-1.9034528;-1.184616;1.7198783;1.8520714;2.9210486;0.7621496;CODE
then we will need to design preprocessing pipelines which depends on the;-1.3734195;-3.4032223;0.40062562;4.0856795;2.9241273;3.1360517;CODE
ending regressor if the ending regressor is a linear model one needs to;-0.5505101;2.9644525;-0.097854644;-0.01849651;-1.2692549;2.4102094;CODE
one hot encode the categories if the ending regressor is a tree based model;2.3979545;-1.5806282;-1.0095683;-0.13922232;4.0843825;0.9906589;CODE
an ordinal encoder will be sufficient besides numerical values need to be;3.1153662;2.003339;-0.5000898;-6.117439;3.310136;-1.5682657;IRRE
standardized for a linear model while the raw numerical data can be treated;4.5179796;0.2870954;-1.8619188;-0.43568373;0.5810667;2.472371;CODE
as is by a tree based model however both models need an imputer to;1.0682179;-1.5887601;-1.329847;4.0076556;3.358227;1.8872623;-
handle missing values;1.2652166;7.2005014;0.2707016;0.05211455;1.3480096;-2.7265234;IRRE
we will first design the pipeline required for the tree based models;0.66440237;-5.106465;1.2652899;3.4874291;4.698525;1.7189722;CODE
then we will now define the preprocessor used when the ending regressor;-1.5986571;-0.25863862;-2.0227644;1.2176222;1.71752;4.1199117;CODE
is a linear model;2.0280874;-0.6941128;3.493524;0.8541385;-0.5091742;-0.10680805;-
stack of predictors on a single data set;5.9413004;-2.083905;1.3747067;-0.4255312;2.1199539;2.9114528;IRRE
it is sometimes tedious to find the model which will best perform on a given;5.643014;-2.2655942;1.6169642;3.6741734;1.0701984;-0.30909997;CODE
dataset stacking provide an alternative by combining the outputs of several;5.7789345;-2.3641145;1.1502723;-0.9630882;4.0363135;1.1140218;IRRE
learners without the need to choose a model specifically the performance of;4.0113244;-4.5196204;2.1271932;6.9522986;1.7406851;-1.5631279;TASK
stacking is usually close to the best model and sometimes it can outperform;2.0452008;-2.5712943;2.0840852;3.6245341;1.1993818;2.0606284;CODE
the prediction performance of each individual model;6.6058598;-5.3501143;2.3143325;5.582421;1.6782732;0.5599014;CODE
here we combine 3 learners linear and non linear and use a ridge regressor;4.8437767;-2.7304795;-1.0109786;-2.9144306;-0.8365081;1.9119796;IRRE
to combine their outputs together;1.4235325;0.1821606;4.5650873;-3.3237853;2.6345265;-1.111746;IRRE
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
although we will make new pipelines with the processors which we wrote in;-1.5051415;-4.7578726;-0.3045299;3.044949;0.7373429;1.7303276;CODE
the previous section for the 3 learners the final estimator;1.3562893;-3.674111;0.7224568;4.727707;0.44108734;0.213089;CODE
class sklearn linear model ridgecv does not need preprocessing of;2.2995503;-3.641679;-6.985173;-1.0777452;-2.9444096;3.5669036;CODE
the data as it will be fed with the already preprocessed output from the 3;1.325537;-0.0936692;1.2733649;-1.8572648;2.5993066;0.46201116;CODE
learners;0.19697368;-6.1344047;3.1843936;2.5980332;0.46282005;-5.677365;-
measure and plot the results;3.5479743;1.5015372;7.7584877;-2.2725549;-3.9247;-3.811038;IRRE
now we can use ames housing dataset to make the predictions we check the;3.0672848;-2.828674;0.9154398;4.1224985;0.1172925;-1.457037;IRRE
performance of each individual predictor as well as of the stack of the;6.011945;-3.378072;1.6757964;2.8719187;1.87535;0.8365911;CODE
regressors;1.7630011;-0.38902798;3.4197032;-2.4072657;-0.4279244;-0.29497933;-
the stacked regressor will combine the strengths of the different regressors;3.297571;0.78434986;1.4199196;-1.4438802;0.8641607;2.7872963;-
however we also see that training the stacked regressor is much more;4.0081863;-2.3484023;0.49942225;3.3698757;0.29656628;3.80732;-
computationally expensive;3.3180816;-4.26788;2.5269296;0.8577693;0.093481;-0.658155;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we first generate a noisy xor dataset which is a binary classification task;4.8687124;-5.6083345;-0.40805972;0.9199837;3.0402281;0.50460285;IRRE
feature names feature 0 feature 1;-1.8868939;-2.1543663;-1.3706025;-0.4344699;2.6654072;-0.751625;TASK
xor feature 0 noise 0 0 xor feature 1 noise 1 0;1.3889222;0.16413437;-4.679039;-2.1190581;-0.80848545;1.6922711;TASK
ax scatter x feature 0 x feature 1 c y common scatter plot params;3.8677723;-0.57250774;-0.5649025;-6.456222;-4.664986;3.3730469;TASK
due to the inherent non linear separability of the xor dataset tree based;5.834792;-4.2795277;-3.0418935;-1.2634727;2.1148913;1.6288055;IRRE
models would often be preferred however appropriate feature engineering;1.191875;-6.523706;1.0597247;4.9632764;3.233809;2.2050755;TASK
combined with a linear model can yield effective results with the added;6.8465424;-0.7151214;2.8187876;4.552338;2.7521074;-0.21209954;TASK
benefit of producing better calibrated probabilities for samples located in;5.540894;-1.9772961;-0.2812754;3.5116065;-0.38015833;0.593086;CODE
the transition regions affected by noise;1.6504667;-1.6980082;2.2536783;1.1837935;-0.9395334;2.6171823;-
we define and fit the models on the whole dataset;5.9193134;-4.674697;1.6583062;2.490212;3.0689816;1.9577605;IRRE
finally we use class inspection decisionboundarydisplay to plot the;2.416178;-2.5328953;1.9686227;1.0840938;0.9505783;-0.90078616;CODE
predicted probabilities by using a diverging colormap such as rdbu we;4.514346;-2.9517305;0.14712471;0.28838417;0.95467645;0.45367843;-
can ensure that darker colors correspond to predict proba close to either 0;3.0943718;1.1399331;-1.1366589;2.0206847;-1.1859572;-1.2661986;IRRE
or 1 and white corresponds to predict proba of 0 5;2.0052786;0.4040027;0.3947832;-0.38745505;1.5150579;-4.329414;IRRE
x feature 0;-1.3443545;-0.10392656;-0.41573566;-2.6244862;0.33294606;-1.234798;TASK
x feature 1;-0.34652176;-2.4264143;2.3344207;-0.8352687;2.4553423;-0.64552104;TASK
as a sanity check we can verify for a given sample that the probability;3.6577168;3.1329982;-0.09008897;6.046634;1.6154541;-4.2257266;CODE
predicted by the class ensemble votingclassifier is indeed the weighted;4.2558656;-3.2375543;-3.490474;2.7642622;1.1351454;0.230157;IRRE
average of the individual classifiers soft predictions;6.4090276;-5.5111804;-0.52146137;3.6349294;1.5880144;0.3682049;IRRE
in the case of binary classification such as in the present example the;2.7574747;-3.8238711;-0.47368175;0.6995911;8.245417;-2.5807784;CODE
term predict proba arrays contain the probability of belonging to class 0;3.6026452;0.016010072;-3.6573074;0.6131008;2.480724;-1.6872965;CODE
here in red as the first entry and the probability of belonging to class 1;-1.0632716;-0.22779189;1.9992651;0.042725924;4.338017;-4.075436;CODE
here in blue as the second entry;-4.9063163;-1.2915846;4.0380106;-0.85972506;1.3118705;-1.9359887;CODE
test sample pd dataframe feature 0 0 5 feature 1 1 5;2.823366;2.2697628;-3.543896;-1.1713207;-2.453685;-4.431314;TASK
we can see that manual calculation of predicted probabilities above is;2.7527044;-3.5537007;0.48227307;3.7803783;-0.1984467;-0.44550326;-
equivalent to that produced by the votingclassifier;4.424565;-2.7280767;1.1837273;1.8490132;6.8650084;-0.28486246;IRRE
to convert soft predictions into hard predictions when weights are provided;6.053588;-2.4918692;-0.14986938;3.722598;0.43987468;2.5455196;CODE
the weighted average predicted probabilities are computed for each class;6.0652676;-3.5267513;-0.025431877;2.391179;2.4690518;0.59695953;CODE
then the final class label is then derived from the class label with the;-0.972999;-0.40354133;-0.08660943;0.7107806;5.649211;0.97384286;CODE
highest average probability which corresponds to the default threshold at;2.3596523;0.48099044;1.9352572;1.5549608;0.20919266;0.7278373;CODE
predict proba 0 5 in the case of binary classification;3.2144816;-1.3027363;-1.9184881;1.0289398;2.8807733;-3.371098;CODE
this is equivalent to the output of votingclassifier s predict method;4.870577;-3.1957257;0.10547886;0.94394535;3.6354778;-1.8244367;IRRE
soft votes can be thresholded as for any other probabilistic classifier this;3.3367922;-2.4316108;-1.5699836;2.364786;4.960516;1.3099016;CODE
allows you to set a threshold probability at which the positive class will be;2.332428;-1.1477046;0.268566;2.5937357;4.335624;0.73866063;IRRE
predicted instead of simply selecting the class with the highest predicted;3.8735135;-0.77238584;0.4929693;4.4787965;1.8651372;-0.11396159;CODE
probability;-0.84406775;0.0559331;6.8823643;1.6645435;1.7856292;-5.674577;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
training classifiers;5.515106;-6.704598;1.029939;2.3712502;4.756061;-2.0817535;IRRE
first we will load the diabetes dataset and initiate a gradient boosting;5.106081;-4.204999;0.9368697;1.7504908;1.518578;1.7369171;IRRE
regressor a random forest regressor and a linear regression next we will;1.5126419;-3.6092894;0.008718775;1.7605051;-0.11320897;1.1823809;IRRE
use the 3 regressors to build the voting regressor;1.0746295;0.3313029;0.3669048;-3.4203463;2.7084603;2.0120857;IRRE
train classifiers;5.7955775;-5.7352977;1.0241897;1.9356135;4.704562;-1.5685772;IRRE
making predictions;4.056266;-3.6132123;6.080784;5.4475245;-0.08016487;-2.9284363;-
now we will use each of the regressors to make the 20 first predictions;2.7972448;-1.1748598;2.363439;2.4031482;0.25416613;0.36327833;-
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
finally we will visualize the 20 predictions the red stars show the average;3.867562;-2.2263048;4.0739627;1.5029597;-1.6846563;-0.9362244;CODE
prediction made by class ensemble votingregressor;5.1859903;-3.8057353;-2.4281719;3.7917397;2.4947958;-0.07509267;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
the iris dataset;3.9266727;-5.0395927;1.2193297;-1.9065696;0.88625425;-1.3547094;IRRE
some noisy data not correlated;5.407908;1.8271401;-0.6345758;0.9630578;-1.8198862;0.81426966;-
add the noisy data to the informative features;5.28423;-4.3976564;1.7397541;1.9849793;2.4144745;1.8893429;TASK
split dataset to select feature and evaluate the classifier;5.243296;-2.593018;-0.5732307;1.4419785;4.2837124;-1.2784073;IRRE
univariate feature selection;5.484323;-3.5106003;0.90276986;-0.8259433;2.921245;0.18465245;CODE
univariate feature selection with f test for feature scoring;5.048708;-1.9668736;-1.9506181;2.2180526;1.8679806;-2.5636325;CODE
we use the default selection function to select;-1.6361613;-0.6222081;2.117853;1.2570374;1.8374507;2.2864382;CODE
the four most significant features;1.1123744;-5.2502017;4.0142813;-0.69346106;2.4941814;0.24919005;TASK
in the total set of features only the 4 of the original features are significant;2.799228;-1.4400939;1.1906179;-0.74343526;3.3375533;-0.012560174;TASK
we can see that they have the highest score with univariate feature;4.538786;-3.2902362;-0.8489;1.8049883;1.7574632;-0.98496145;TASK
selection;2.2316139;-1.7080317;6.1581593;2.5045087;5.470379;-1.7585709;CODE
compare with svms;5.163429;-3.7049446;0.84171563;1.3566943;1.662178;-1.056272;IRRE
without univariate feature selection;5.7653885;-3.273196;1.1585218;-0.73199165;3.2912123;0.87420744;CODE
after univariate feature selection;2.8465896;-1.4660047;0.18228766;0.6897732;1.7129879;1.7564796;CODE
without univariate feature selection the svm assigns a large weight;5.768761;-3.1473901;-3.1448991;-0.7883022;1.835292;3.27698;CODE
to the first 4 original significant features but also selects many of the;1.1085436;-3.27718;2.0413432;0.0058272216;3.9579518;-0.6903628;TASK
non informative features applying univariate feature selection before;3.4904602;-3.1866276;-1.8715001;1.373327;2.9432497;1.2567567;CODE
the svm increases the svm weight attributed to the significant features;4.545382;-4.770049;-0.12660414;0.29976356;0.7351354;2.0639093;TASK
and will thus improve classification;2.4853709;-5.463551;0.5042871;4.96822;5.029486;-0.04187022;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we will start by generating a binary classification dataset subsequently we;3.6961584;-7.4502044;1.5989511;0.91556305;4.7462525;-2.036378;IRRE
will divide the dataset into two subsets;6.504505;-0.10892295;2.484154;-2.1442568;3.9161856;-0.98459333;IRRE
a common mistake done with feature selection is to search a subset of;2.671426;-0.6990765;-3.1952298;1.9281446;1.1618367;-0.27849495;CODE
discriminative features on the full dataset instead of only using the;4.9427786;-4.3743477;-1.6864723;0.2567433;2.3317084;1.6908853;TASK
training set the usage of scikit learn func sklearn pipeline pipeline;1.6699911;-8.072968;-3.861931;2.2956152;-0.9077518;-0.40860993;CODE
prevents to make such mistake;-4.8558903;3.8219018;-0.64888567;3.5190926;-1.9824631;-2.680098;-
here we will demonstrate how to build a pipeline where the first step will;-1.1520354;-3.2533145;3.0125813;1.8258221;1.7069035;0.7991348;CODE
be the feature selection;2.9413254;-4.24394;2.6272523;3.416387;3.3189929;-0.82147145;TASK
when calling fit on the training data a subset of feature will be selected;4.2042913;-0.35593086;-1.5266316;2.7324224;1.6641862;2.2644472;IRRE
and the index of these selected features will be stored the feature selector;0.5794378;-2.5368874;1.6164252;-0.5094013;4.2835383;2.0094283;TASK
will subsequently reduce the number of features and pass this subset to the;3.7574995;-0.4288481;1.2422388;1.8961619;4.586518;2.2087255;TASK
classifier which will be trained;3.5216606;-4.900018;2.076677;2.665277;5.116416;-1.9561464;IRRE
once the training is complete we can predict on new unseen samples in this;5.715371;-2.9998374;1.2059164;6.528172;2.6346414;-0.14499412;CODE
case the feature selector will only select the most discriminative features;1.2119718;-1.2795932;-2.6101513;1.3526685;2.272827;1.7338877;CODE
based on the information stored during training then the data will be;5.5216026;-1.8057615;1.8569409;2.5862064;4.558276;0.054692194;CODE
passed to the classifier which will make the prediction;1.5930907;-3.5373745;-0.35267326;3.952437;1.40065;-0.57432055;IRRE
here we show the final metrics via a classification report;4.505843;-4.6555;0.14536384;0.5943792;3.3745148;1.0660436;CODE
be aware that you can inspect a step in the pipeline for instance we might;-3.1889532;-3.2496164;-0.90362793;6.090483;0.5248337;-0.061275706;CODE
be interested about the parameters of the classifier since we selected;3.6404366;-3.7018194;1.5228409;2.3458135;4.478853;-0.13304476;CODE
three features we expect to have three coefficients;2.1967738;-2.1901624;-0.10254661;-2.9431257;2.6593359;0.24424697;TASK
however we do not know which features were selected from the original;-1.5722265;-4.424782;0.8091082;1.9958822;2.293646;1.0382115;CODE
dataset we could proceed by several manners here we will invert the;5.534293;-1.885521;2.7043197;-1.1174557;1.581686;-0.0073442906;IRRE
transformation of these coefficients to get information about the original;1.8657482;-0.12970427;1.1231891;-4.694675;-1.5389826;1.3026614;CODE
space;-1.5954374;-2.4337003;6.797447;-1.6146792;0.17572953;-2.5561504;-
we can see that the features with non zero coefficients are the selected;2.1167376;0.022190401;-2.5395098;-1.8417822;1.2373455;1.5574926;TASK
features by the first step;2.753537;-6.1213856;3.7157538;0.50217265;4.448356;-0.32879308;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the digits dataset;4.139511;-1.3671632;0.37185895;-3.4946282;0.23420542;-2.4100306;IRRE
plot pixel ranking;4.352371;-0.8703746;5.312331;-5.124272;-3.3122826;0.9718166;-
add annotations for pixel numbers;0.3767994;-1.9864677;0.7365918;-3.6093445;0.5603871;1.4448531;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.016717;-2.0955784;4.7338896;-0.58479315;4.4981794;-3.6965094;-
we build a classification task using 3 informative features the introduction;2.5115921;-5.737327;2.1994412;0.41193044;6.3059125;-0.84896636;CODE
of 2 additional redundant i e correlated features has the effect that the;1.6313317;-0.7246555;0.63061655;0.57678145;3.1889741;2.5766094;TASK
selected features vary depending on the cross validation fold the remaining;2.4084213;0.95367056;-0.7753944;2.2122805;1.3397423;1.5632813;CODE
features are non informative as they are drawn at random;2.4957209;-4.103282;0.11615994;2.370685;1.6912658;0.82542163;IRRE
model training and selection;6.022274;-4.475163;3.219024;5.848515;4.6378455;0.2538353;CODE
we create the rfe object and compute the cross validated scores the scoring;3.3691766;-0.91061145;0.18032049;1.8564653;4.8902087;-2.0840077;IRRE
strategy accuracy optimizes the proportion of correctly classified samples;6.472354;-0.8065676;-0.49240074;5.197468;2.7047603;-0.3433791;IRRE
min features to select 1 minimum number of features to consider;3.9997017;-0.5168455;1.6899447;-1.3940635;4.3396363;0.07471354;TASK
in the present case the model with 3 features which corresponds to the true;0.8046868;-0.39446047;1.0840389;1.8386933;4.585763;-0.42728496;CODE
generative model is found to be the most optimal;3.5170634;-2.1891818;2.5159662;3.0325131;3.9842806;3.4603505;-
plot number of features vs cross validation scores;3.8623936;-1.1371628;1.4093403;0.55316836;-1.5075402;-1.8245338;TASK
from the plot above one can further notice a plateau of equivalent scores;4.230324;1.3420173;1.1891546;0.47283107;-3.7429032;-0.6695562;CODE
similar mean value and overlapping errorbars for 3 to 5 selected features;4.0797896;2.180557;-0.0048241527;-1.159884;0.7823536;0.72480446;CODE
this is the result of introducing correlated features indeed the optimal;5.9738503;-3.215855;0.18571106;1.5644382;1.7913324;6.529487;CODE
model selected by the rfe can lie within this range depending on the;2.0836365;2.14179;-1.0344925;2.291259;0.65460324;1.2503234;CODE
cross validation technique the test accuracy decreases above 5 selected;2.5027401;2.9641936;-1.8462462;4.9456086;-0.28933504;-2.786117;IRRE
features this is keeping non informative features leads to over fitting and;2.1367512;-3.507208;-0.80735046;2.8431616;2.0394776;3.5614023;TASK
is therefore detrimental for the statistical performance of the models;4.3359904;-1.4545909;-1.0211815;7.600467;-0.3830107;1.3992394;CODE
mask of features selected by the rfe;3.0437472;-1.0396394;-0.044526566;-0.5503607;3.7505934;3.819643;TASK
in the five folds the selected features are consistent this is good news;0.61131793;-1.6069396;1.8378823;0.74405575;2.1165807;3.430453;CODE
it means that the selection is stable across folds and it confirms that;-1.1806278;-1.5066128;1.7355076;1.0045513;1.1555791;1.8710741;CODE
these features are the most informative ones;1.8454251;-7.939937;4.6754327;0.9721305;3.5610023;0.27472398;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
loading the data;0.18666792;-0.14836968;5.812513;-0.5148239;0.26003522;-1.1118855;CODE
we first load the diabetes dataset which is available from within;3.3886685;-3.33542;0.9489047;0.6553878;1.7076269;0.57649136;CODE
scikit learn and print its description;0.42493713;-10.47644;-1.432857;-1.8972777;-1.3179115;-4.017695;CODE
feature importance from coefficients;4.4329166;-3.0456016;0.48729986;-1.391341;1.5448306;2.863577;CODE
to get an idea of the importance of the features we are going to use the;-0.5199195;-8.363163;4.660814;3.3051364;2.5185597;1.1705749;CODE
class sklearn linear model ridgecv estimator the features with the;4.56489;-5.597242;-4.427886;-1.5268999;-2.2415166;2.0609636;TASK
highest absolute coef value are considered the most important;2.607619;0.69186085;-0.24098203;-0.18229644;0.59997505;-0.10381888;CODE
we can observe the coefficients directly without needing to scale them or;4.77579;-1.0179366;1.5398182;0.024975691;-3.2234626;4.6024566;CODE
scale the data because from the description above we know that the features;6.397014;-3.121278;3.9679096;-1.3602376;1.3799028;2.2453635;CODE
were already standardized;-1.5126888;-1.9837321;-1.2165326;2.4844525;1.0467128;0.29213983;CODE
for a more complete example on the interpretations of the coefficients of;-0.26515758;0.31969872;0.15323499;-1.3964902;1.0810491;0.06257509;CODE
linear models you may refer to;5.050897;-3.6038244;5.2647614;2.8070557;1.1143289;0.2996342;-
ref sphx glr auto examples inspection plot linear model coefficient interpretation py noqa e501;0.60058224;-0.24191974;-5.158765;-2.4067535;-4.125672;0.02839069;CODE
selecting features based on importance;3.7537105;-1.7945633;3.5408125;0.5521342;4.2593145;0.9280102;CODE
now we want to select the two features which are the most important according;0.17466217;-3.9866307;4.015945;1.6045548;4.5297246;1.6892805;CODE
to the coefficients the class sklearn feature selection selectfrommodel;4.3009806;-4.8339524;-3.4524891;-0.03821142;1.06966;0.037840277;CODE
is meant just for that class sklearn feature selection selectfrommodel;1.197028;-5.6350436;-3.1985292;3.0316784;2.0706155;0.5341441;CODE
accepts a threshold parameter and will select the features whose importance;4.024162;-0.9643946;0.77170306;0.8555497;3.8886173;2.580407;CODE
defined by the coefficients are above this threshold;1.8349739;2.22711;-1.7235442;-1.3866082;0.18814817;1.0793194;CODE
since we want to select only 2 features we will set this threshold slightly;0.8420988;-1.0371215;-0.014386064;1.6082882;3.3972642;1.5646577;CODE
above the coefficient of third most important feature;2.8613188;-2.7357216;2.2984548;-2.2584715;2.8574438;0.7368828;CODE
selecting features with sequential feature selection;3.2928364;-1.6727675;2.7730062;0.54475105;4.7457695;0.7089248;TASK
another way of selecting features is to use;0.46061802;-3.1816008;3.0849597;2.6100826;4.723164;1.0627201;TASK
class sklearn feature selection sequentialfeatureselector;2.3773713;-4.330673;-4.0809536;1.3164934;2.2237275;-0.0020159855;CODE
sfs sfs is a greedy procedure where at each iteration we choose the best;2.7229571;-3.3947651;2.7056704;3.3850136;3.0866857;-1.2574418;IRRE
new feature to add to our selected features based a cross validation score;1.9727657;-3.3781085;1.1972747;2.6677942;3.5680745;-1.2172498;TASK
that is we start with 0 features and choose the best single feature with the;0.6301161;-2.2737281;1.321516;0.96513927;3.2589366;0.7210547;TASK
highest score the procedure is repeated until we reach the desired number of;2.3741264;2.9187567;2.6959379;2.3441787;3.6958091;-3.813774;-
selected features;1.6077766;-2.7339451;4.8271427;0.67622066;4.0085983;-0.17829889;TASK
we can also go in the reverse direction backward sfs i e start with all;-2.668243;-2.706051;3.9509575;-0.25711423;0.16777703;0.5490425;CODE
the features and greedily choose features to remove one by one we illustrate;1.3632603;-2.9844673;3.0740678;0.4829152;4.1755223;2.7345104;TASK
both approaches here;-1.6452935;-0.60596466;5.333046;2.4225376;0.61332077;-1.4024996;-
interestingly forward and backward selection have selected the same set of;0.101842;0.42887348;0.7656445;1.3093938;2.5836446;1.1833311;CODE
features in general this isn t the case and the two methods would lead to;0.9063542;-4.1191344;1.5430514;4.546954;4.074179;4.2454553;CODE
different results;0.21500957;2.1502378;2.023064;0.45507565;-1.0851072;-5.0852795;IRRE
we also note that the features selected by sfs differ from those selected by;-0.14493978;-5.7975354;-0.8834838;1.8000857;2.8789346;1.0009011;CODE
feature importance sfs selects bmi instead of s1 this does sound;0.3132063;-0.8667837;-1.8336909;1.0642493;-1.0881746;2.4365346;CODE
reasonable though since bmi corresponds to the third most important;1.061648;1.4218451;1.233553;0.5728079;0.7650088;1.202735;CODE
feature according to the coefficients it is quite remarkable considering;3.7950914;-3.983385;0.12600708;-1.6223915;0.29620504;0.33424833;TASK
that sfs makes no use of the coefficients at all;-0.6420182;-1.066134;-2.846728;-2.577778;-2.5652034;-0.16135074;-
to finish with we should note that;-3.01653;-0.79541725;3.6669;4.0924926;-0.8173806;-0.39023855;TASK
class sklearn feature selection selectfrommodel is significantly faster;4.353485;-4.810913;-4.3198323;3.0871754;-0.6585807;1.0414928;CODE
than sfs indeed class sklearn feature selection selectfrommodel only;2.013014;-4.9496193;-5.666997;2.995032;0.8972526;0.8005954;CODE
needs to fit a model once while sfs needs to cross validate many different;2.8521245;1.2129294;-2.5489328;3.8435643;4.786062;1.3135802;TASK
models for each of the iterations sfs however works with any model while;1.6494937;-0.74226004;-2.5935628;4.20552;-0.1445193;0.6833648;CODE
class sklearn feature selection selectfrommodel requires the underlying;2.0249107;-3.9316046;-6.7345443;3.4796426;0.39560303;2.5689778;CODE
estimator to expose a coef attribute or a feature importances;3.3107874;-2.3490586;-0.8469435;3.3809931;1.1472809;4.9189095;CODE
attribute the forward sfs is faster than the backward sfs because it only;0.27941254;-1.0386549;-0.2439238;0.054444496;0.65948576;2.8367305;META
needs to perform n features to select 2 iterations while the backward;2.5760133;2.0360048;1.258513;-0.66934854;2.5208385;-0.24468143;CODE
sfs needs to perform n features n features to select 8 iterations;2.4738476;-1.3724538;0.43148223;-0.4521069;2.9706385;-0.8985958;TASK
using negative tolerance values;1.719768;5.3863564;-0.87954324;0.7510261;-2.0818908;-1.1438384;IRRE
class sklearn feature selection sequentialfeatureselector can be used;2.645432;-4.6882854;-3.560269;1.444924;2.7523224;0.29459116;CODE
to remove features present in the dataset and return a;3.7682607;1.595576;-0.13421533;0.42688522;1.3778679;-0.3602176;IRRE
smaller subset of the original features with direction backward;4.1058207;-0.87874013;2.100242;-2.5674977;1.5492427;3.9796638;TASK
and a negative value of tol;-2.5868795;2.8173816;-0.18838277;-1.9666902;1.9598596;-1.4482597;IRRE
we begin by loading the breast cancer dataset consisting of 30 different;4.8041267;-3.5604846;1.7130429;0.15105575;2.8095534;-1.0769075;IRRE
features and 569 samples;5.386855;-4.2262635;-0.7074287;0.37726903;3.6619952;-3.2592766;TASK
we will make use of the class sklearn linear model logisticregression;4.570632;-5.3449326;-2.4635909;1.6786715;-0.68580407;-1.0501493;IRRE
estimator with class sklearn feature selection sequentialfeatureselector;3.6936147;-3.7292397;-4.613346;2.4820592;0.552293;1.8625556;CODE
to perform the feature selection;3.5118635;-4.3941855;2.8750184;2.0734584;4.2909737;-0.93481153;CODE
we can see that the number of features selected tend to increase as negative;2.8912666;-1.272021;0.96365047;2.171967;0.82352054;1.1923891;CODE
values of tol approach to zero the time taken for feature selection also;4.244825;-0.27834865;-1.8242663;2.217826;0.9708703;1.2375668;IRRE
decreases as the values of tol come closer to zero;0.5804894;4.53816;0.5347629;-2.8495216;-4.9558544;0.55709064;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
setting a decision threshold for a pre fitted classifier;4.9033413;-0.954262;-1.2131275;2.7360783;2.516649;2.4470043;IRRE
fitted classifiers in scikit learn use an arbitrary decision threshold to decide;6.5245533;-6.024775;-4.958329;2.6306925;0.8951949;0.18774483;IRRE
which class the given sample belongs to the decision threshold is either 0 0 on the;3.0777376;2.602474;-2.509453;-0.8228757;2.5588243;-3.2427123;IRRE
value returned by term decision function or 0 5 on the probability returned by;0.97900546;2.7283099;0.44715708;0.7977628;0.7813056;-2.2190287;IRRE
term predict proba;2.6711905;-1.1020961;1.3326806;3.4091153;0.91086274;-2.2140405;-
however one might want to set a custom decision threshold we can do this by;2.1268628;0.5241473;1.0695288;4.2019916;4.1613126;3.414894;CODE
using class sklearn model selection fixedthresholdclassifier and wrapping the;2.7581358;-3.7112343;-3.9457805;2.4573507;0.23162809;1.8041149;IRRE
classifier with class sklearn frozen frozenestimator;2.019297;-3.4622486;-3.8208983;0.28775424;-1.5848144;1.3886209;IRRE
now imagine you d want to set a different decision threshold on the probability;2.883606;-0.12834872;3.0617416;3.8977294;3.5312917;1.8896075;IRRE
estimates we can do this by wrapping the classifier with;7.7293773;-1.7404335;0.4164774;3.00645;3.937926;2.1689787;CODE
class sklearn frozen frozenestimator and passing it to;-0.26609594;-2.0977576;-2.8085399;0.5579764;-2.8546736;2.1029246;IRRE
class sklearn model selection fixedthresholdclassifier;3.5576117;-4.569404;-4.8728447;2.6933482;0.61969167;2.2729044;CODE
note that in the above piece of code calling fit on;0.2692516;3.7087827;-1.7766955;-1.1458489;0.64843744;1.872817;TASK
class sklearn model selection fixedthresholdclassifier does not refit the;0.9993676;-3.737221;-6.2892313;3.6668925;-1.0390044;2.5338383;CODE
underlying classifier;4.580694;-5.290961;0.4917128;1.5262984;5.283552;0.68712026;IRRE
now let s see how the predictions changed with respect to the probability;2.0379195;-1.8661038;2.2151797;4.5286274;-2.260336;-0.50087196;CODE
threshold;1.9324853;0.88612324;3.9160545;0.19162998;0.8255056;-3.2432754;-
we see that the probability estimates stay the same but since a different decision;2.0185506;1.2461789;0.36015618;5.40834;-0.4653601;4.1378236;META
threshold is used the predicted classes are different;4.5094404;-0.4577559;-2.681783;2.7029195;0.8965125;-0.41100192;IRRE
please refer to;-2.3408654;-3.371929;5.3658957;2.9556413;-0.70941615;-1.8326217;-
ref sphx glr auto examples model selection plot cost sensitive learning py;3.067219;-4.6333795;-3.519748;2.0941715;-1.7618893;2.6270955;CODE
to learn about cost sensitive learning and decision threshold tuning;5.0942264;-5.59872;-1.1867467;4.4994636;1.8589735;-0.37075424;-
calibration of a pre fitted classifier;4.5038486;-1.6535734;-1.7789288;0.6324267;-0.38769832;2.2507262;IRRE
you can use class sklearn frozen frozenestimator to calibrate a pre fitted;3.3726735;-1.2791251;-2.1359422;0.449619;-4.293342;3.3305087;IRRE
classifier using class sklearn calibration calibratedclassifiercv;3.0358188;-4.067994;-6.232486;-1.327145;-1.463271;-1.1188947;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generating a dataset;7.0245724;-4.352481;2.5597222;-1.5548781;2.9721124;-2.7307184;IRRE
we create a synthetic dataset the true generative process will take a 1 d;4.600638;-3.013831;1.3037169;-0.33497608;2.1292276;1.3371241;IRRE
vector and compute its sine note that the period of this sine is thus;-1.4248165;0.70295894;1.8980601;-3.7598264;-3.37695;-1.0548786;CODE
math 2 pi we will reuse this information later in this example;-0.6492468;1.0074791;4.90539;-2.3753967;-0.33312497;-1.5884403;CODE
now we can imagine a scenario where we get observations from this true;3.116545;-0.400053;4.999047;5.2813272;0.13500686;0.34603786;CODE
process however we will add some challenges;-2.4237328;-3.1243536;4.6518364;3.9601474;1.3367146;-2.8174632;TASK
the measurements will be noisy;4.3719196;0.7210856;4.4652357;1.8433746;-1.0068305;0.57073927;-
only samples from the beginning of the signal will be available;1.8052721;3.8884718;1.9189314;1.9360831;0.5443166;0.40094256;CODE
let s plot the true signal and the noisy measurements available for training;6.4231157;-1.966079;3.378352;2.4429007;-2.1739764;-0.27474666;CODE
limitations of a simple linear model;3.341988;0.5544299;0.60397696;0.31518728;-0.79691577;1.4877917;-
first we would like to highlight the limitations of a linear model given;3.9596732;-0.97873586;1.8998718;1.8581214;0.6248002;1.0587267;-
our dataset we fit a class sklearn linear model ridge and check the;6.1587534;-2.9542537;-3.472614;-0.5278625;-1.5895131;0.05810888;IRRE
predictions of this model on our dataset;4.355932;-2.4463;1.9513456;4.1509633;-0.4026189;-2.3810596;IRRE
such a ridge regressor underfits data since it is not expressive enough;5.968564;-1.6959935;-0.99264365;-2.2617793;-1.7655623;4.356899;CODE
kernel methods kernel ridge and gaussian process;3.521294;-4.619476;-1.9707135;-0.35100117;-2.6231651;5.634154;-
kernel ridge;3.4968019;-3.8374388;0.69622517;-3.9051914;-2.1886342;4.5035987;-
we can make the previous linear model more expressive by using a so called;2.4192889;-1.8685637;1.3099195;2.7918224;2.2501297;3.9697328;IRRE
kernel a kernel is an embedding from the original feature space to another;0.74994105;-4.371967;-0.79263836;-0.38287455;0.48852068;4.694399;TASK
one simply put it is used to map our original data into a newer and more;-0.7020183;-4.2292733;3.566023;-1.5023886;3.5718088;1.3115578;CODE
complex feature space this new space is explicitly defined by the choice of;-0.7648306;-1.8518684;0.29326147;-0.6959623;3.2585428;4.348374;CODE
kernel;-0.14416118;-4.1024375;2.9355628;-1.238118;0.22444972;-1.0592741;-
in our case we know that the true generative process is a periodic function;-1.1329182;-1.1193241;2.161448;3.7571507;1.0697794;3.8949587;CODE
we can use a class sklearn gaussian process kernels expsinesquared kernel;3.661864;-5.822779;-4.199252;-0.27812403;-1.3883281;4.0041466;IRRE
which allows recovering the periodicity the class;0.2802031;-2.8137307;1.8393594;1.2568151;2.6844923;2.7847705;IRRE
class sklearn kernel ridge kernelridge will accept such a kernel;1.7666965;-4.988566;-5.63375;-1.4224129;-1.4480394;3.534517;IRRE
using this model together with a kernel is equivalent to embed the data;3.792423;-4.6510205;-0.58212376;0.06645743;1.7466476;4.948401;CODE
using the mapping function of the kernel and then apply a ridge regression;4.3318195;-1.8545972;-0.023236921;-1.9487607;-3.2094133;4.2635403;CODE
in practice the data are not mapped explicitly instead the dot product;2.1257174;-1.6705893;-3.0652113;-3.7184837;-0.07952913;3.6751018;CODE
between samples in the higher dimensional feature space is computed using the;6.2964563;-2.4918563;-1.3097491;-3.5142417;1.6397804;2.5723195;TASK
kernel trick;1.4156947;-2.2597973;0.9391728;-1.9896173;-1.016275;1.2544056;-
thus let s use such a class sklearn kernel ridge kernelridge;3.5595782;-5.977575;-4.3918867;-1.3400801;-0.49564907;2.4382935;CODE
this fitted model is not accurate indeed we did not set the parameters of;1.9755006;2.0701342;-3.1981213;1.2528082;-4.113384;0.9217063;IRRE
the kernel and instead used the default ones we can inspect them;-2.8515456;-3.8623412;-0.61829835;-0.21896179;-1.8196826;0.36803332;CODE
our kernel has two parameters the length scale and the periodicity for our;1.9520452;-1.5112382;1.2531868;-2.7942371;-1.4345938;3.6945245;IRRE
dataset we use sin as the generative process implying a;2.1959713;-1.9971166;1.6540691;1.1214286;0.6166054;0.93527496;IRRE
math 2 pi periodicity for the signal the default value of the parameter;-0.94348764;2.6750631;1.4381342;-2.130777;-3.4606006;2.5466137;CODE
being math 1 it explains the high frequency observed in the predictions of;4.191078;-4.041708;1.7211002;2.4045405;-3.0189974;-0.43301305;CODE
our model;0.9708286;-2.9543889;4.9106436;3.402203;1.1822491;-1.0691512;-
similar conclusions could be drawn with the length scale parameter thus it;3.0128567;1.5979462;-0.021725843;1.3534734;-1.9148573;1.8287245;IRRE
tells us that the kernel parameters need to be tuned we will use a randomized;4.077654;-2.2404706;-1.5357993;3.285688;0.7938105;2.2607167;IRRE
search to tune the different parameters the kernel ridge model the alpha;5.071471;-2.9813554;-1.399168;-1.1843959;-2.1331499;3.281022;IRRE
parameter and the kernel parameters;0.45126832;-1.5468315;0.58009785;-1.2003015;1.1148665;2.6931028;IRRE
fitting the model is now more computationally expensive since we have to try;6.554306;-3.1436186;-1.0211536;2.8319879;-2.7957118;3.010457;CODE
several combinations of hyperparameters we can have a look at the;4.5476227;-2.768121;1.9451615;1.9979438;3.6791403;-1.1364743;IRRE
hyperparameters found to get some intuitions;3.9390476;-2.9668925;3.643327;3.2076216;1.718962;0.13063647;IRRE
looking at the best parameters we see that they are different from the;2.0760548;-0.042324353;-0.0031663838;1.1244247;0.65157753;1.5578655;IRRE
defaults we also see that the periodicity is closer to the expected value;0.20050567;0.7789338;1.0197834;1.7241598;-2.216808;2.1963418;CODE
math 2 pi we can now inspect the predictions of our tuned kernel ridge;4.484668;-4.2751575;0.04060804;-1.417817;-4.797461;1.7906462;-
we get a much more accurate model we still observe some errors mainly due to;2.3954234;-1.0923083;-1.5101057;8.3982935;-3.5364833;0.68566906;TASK
the noise added to the dataset;6.1489267;-4.5997615;0.14495352;1.8291243;-0.26791063;0.5092751;TASK
gaussian process regression;3.5891466;-2.2232087;0.7878254;0.65199935;-2.3652513;4.1044517;-
now we will use a;-2.719127;-2.0683396;4.46276;3.6108937;1.8666536;-1.4734329;-
class sklearn gaussian process gaussianprocessregressor to fit the same;1.7143092;-2.5010154;-5.4142966;-0.4869396;-1.5622181;5.4461427;IRRE
dataset when training a gaussian process the hyperparameters of the kernel;5.1201677;-5.094074;-0.5571915;1.3896238;0.7889522;3.6972508;IRRE
are optimized during the fitting process there is no need for an external;0.923878;-0.47954026;-1.1126722;1.7201833;-1.5679946;5.0310493;CODE
hyperparameter search here we create a slightly more complex kernel than;4.1372185;-2.5375307;-1.444287;-0.4191857;1.6650845;1.4004437;IRRE
for the kernel ridge regressor we add a;1.4792194;-2.7428606;-0.8387893;-3.254342;-1.6888697;3.938488;TASK
class sklearn gaussian process kernels whitekernel that is used to;0.8516243;-6.0509467;-4.943516;-0.16483405;-1.4306253;3.8919811;IRRE
estimate the noise in the dataset;7.272314;-2.1327446;-0.19685704;2.5965688;-0.8626413;0.51184106;IRRE
the computation cost of training a gaussian process is much less than the;4.447283;-3.277067;-1.9991086;2.0891147;-1.451022;4.0062704;-
kernel ridge that uses a randomized search we can check the parameters of;6.2639213;-1.9422712;-1.4384961;0.0062207016;0.48456073;3.3636842;IRRE
the kernels that we computed;2.4199448;-3.8303668;-0.804118;-2.1485596;-0.64807165;0.80764544;-
indeed we see that the parameters have been optimized looking at the;2.3336017;-3.002302;-0.15711454;3.3015685;-0.53077024;4.066995;IRRE
periodicity parameter we see that we found a period close to the;-0.33204997;1.2532973;2.4052377;-0.65748495;-2.828863;1.9363812;IRRE
theoretical value math 2 pi we can have a look now at the predictions of;0.58757085;-0.6577453;2.7861073;0.64906394;-3.4408;-2.0252192;IRRE
our model;0.9708286;-2.9543889;4.9106436;3.402203;1.1822491;-1.0691512;-
plot the predictions of the kernel ridge;5.1217976;-4.7424507;2.2507384;-2.6625628;-6.1669006;2.4264188;-
plot the predictions of the gaussian process regressor;2.734793;-2.4343612;1.871481;-1.0622516;-5.29521;3.4358883;-
we observe that the results of the kernel ridge and the gaussian process;3.8058274;-4.241524;-0.5662263;-0.70474637;-2.4828439;5.5448527;IRRE
regressor are close however the gaussian process regressor also provide;2.3654063;0.19123274;-2.206707;-1.1241142;-2.571036;4.9414;CODE
an uncertainty information that is not available with a kernel ridge;5.957048;-1.7562115;-1.6982083;0.07694069;-0.5912845;4.820001;CODE
due to the probabilistic formulation of the target functions the;2.895847;-2.5179274;1.337415;4.1788898;1.8356485;2.5695624;CODE
gaussian process can output the standard deviation or the covariance;1.568438;-1.9436197;0.6744502;-0.24221915;-1.4158893;3.305316;IRRE
together with the mean predictions of the target functions;5.9266224;-3.3086376;2.5686696;4.9804015;-0.787754;2.283745;CODE
however it comes at a cost the time to compute the predictions is higher;5.440364;-3.225437;1.0130965;6.0851007;-0.5263073;0.40846696;-
with a gaussian process;2.0674865;-0.97958773;3.126353;-0.4040418;-1.2008197;3.200183;-
final conclusion;-2.393402;1.6188087;4.6782923;3.1616008;0.18020901;-2.5372844;CODE
we can give a final word regarding the possibility of the two models to;0.7804623;-2.872805;2.1866667;6.0724382;3.1566076;3.0978496;CODE
extrapolate indeed we only provided the beginning of the signal as a;2.1214454;2.7506678;1.0006757;-1.2978214;-2.718465;1.449574;-
training set using a periodic kernel forces our model to repeat the pattern;6.2013683;-2.8440025;1.505306;1.3777555;2.1289895;3.6858902;IRRE
found on the training set using this kernel information together with the;2.8549135;-6.84722;-0.9387273;-1.2432314;3.1644146;0.9114118;CODE
capacity of the both models to extrapolate we observe that the models will;3.746619;-1.1198392;1.2125673;5.4781346;1.0304428;1.4266503;-
continue to predict the sine pattern;3.6932747;0.7032476;2.551911;0.94939834;-2.8527348;-1.214462;CODE
gaussian process allows to combine kernels together thus we could associate;3.0996652;-4.662488;-0.42932504;0.3107789;1.2587897;6.9401927;-
the exponential sine squared kernel together with a radial basis function;1.1156411;-2.9643557;0.33126885;-2.5034347;-2.522867;4.4896526;CODE
kernel;-0.14416118;-4.1024375;2.9355628;-1.238118;0.22444972;-1.0592741;-
plot the predictions of the kernel ridge;5.1217976;-4.7424507;2.2507384;-2.6625628;-6.1669006;2.4264188;-
plot the predictions of the gaussian process regressor;2.734793;-2.4343612;1.871481;-1.0622516;-5.29521;3.4358883;-
the effect of using a radial basis function kernel will attenuate the;3.9347653;-0.83425814;-0.74094427;-1.3384763;-2.381557;5.9537144;CODE
periodicity effect once that no sample are available in the training;2.571158;0.2745622;1.273613;4.8188806;0.18092442;1.7103732;CODE
as testing samples get further away from the training ones predictions;5.991292;-1.9159958;-0.566963;8.754468;0.98343915;-1.5309082;IRRE
are converging towards their mean and their standard deviation;3.0794282;0.6442462;0.9207017;2.363124;-2.2633903;1.0528731;-
also increases;-1.7447604;0.11858054;4.446834;0.1472459;-1.5120052;-0.42524776;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
specify gaussian processes with fixed and optimized hyperparameters;3.5375068;-1.8059102;-0.87757874;2.0668907;1.0730686;6.269448;IRRE
plot posteriors;1.1491352;-0.0025322638;6.404295;-2.8200037;-2.2851963;2.0718644;-
plot lml landscape;0.114357315;-1.6149153;4.6443024;-3.9401717;-2.6920671;3.6599786;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
x iris data 2 we only take the first two features;1.7899907;-0.75475687;-0.41098112;-3.4389231;1.9833932;0.6056317;TASK
h 0 02 step size in the mesh;-0.25002378;1.8169312;-0.86498296;-4.06648;-2.6294658;0.9815422;CODE
create a mesh to plot in;0.31906894;-0.3402255;6.213581;-5.609697;-3.8788388;0.40551797;IRRE
plot the predicted probabilities for that we will assign a color to;2.1269026;-2.5371134;3.9002163;-0.51223814;-2.6097956;-0.8526418;IRRE
each point in the mesh x min m max x y min y max;3.0622418;1.1952688;3.3554642;-5.921968;-1.5321852;2.0802057;CODE
put the result into a color plot;1.4292959;0.4262304;5.77492;-3.760507;-3.6140656;-2.4272733;IRRE
plot also the training points;3.8571665;-4.4865284;5.091605;-1.1665463;-2.758238;-0.3909035;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
a few constants;0.093391895;-0.21823186;4.0756855;-2.0504258;-2.0599291;-3.556642;CODE
design of experiments;1.6409559;-2.2927473;4.3648996;4.7288427;0.23883253;-2.8088946;-
observations;4.204419;-0.6465585;6.3965797;2.0005548;0.97933334;-2.493027;-
instantiate and fit gaussian process model;2.7293143;-1.0988177;0.4050985;0.7720905;-1.0428898;4.6130624;-
evaluate real function and the predicted probability;1.3180978;0.46853516;2.2623267;3.0228553;-2.1353536;-2.1394753;CODE
plot the probabilistic classification iso values;5.0710664;-5.558504;1.3883219;-2.9283862;0.743565;0.49153882;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
fit the model;1.4823511;-1.8818417;3.3056083;0.780294;0.86335677;-0.14115296;-
plot the decision function for each datapoint on the grid;4.9865937;-1.4004184;3.8216903;-3.1856446;-1.8156767;1.7032706;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
build the dataset;5.528778;-6.960256;2.65886;-0.086380005;3.0794303;-2.651885;IRRE
we will derive a dataset from the mauna loa observatory that collected air;3.1625016;-4.1834993;2.8697228;0.76394826;-1.1883222;0.21160258;IRRE
samples we are interested in estimating the concentration of co2 and;3.4794023;-1.8215804;2.8251162;1.7851607;-1.3533069;-0.51582056;CODE
extrapolate it for further years first we load the original dataset available;3.667742;-0.4855073;0.511453;1.1561806;-0.3758921;0.49575087;CODE
in openml as a pandas dataframe this will be replaced with polars;-0.6006308;-0.93504465;-2.427921;-4.522461;-2.2158177;0.09318496;CODE
once fetch openml adds a native support for it;-5.7179995;-2.2376277;-1.4323016;3.5473394;-0.6596627;2.7873075;CODE
first we process the original dataframe to create a date column and select;0.4637221;-2.1479275;1.1023749;-1.3306764;-3.173663;-0.043028757;IRRE
it along with the co2 column;-0.6482045;-1.3897842;4.9405403;-3.5200748;-0.92740196;-0.1388677;-
we see that we get co2 concentration for some days from march 1958 to;-0.7921916;-0.20025557;1.7276033;0.9041171;-3.6142147;0.10303381;CODE
december 2001 we can plot the raw information to have a better;0.4976375;-4.324144;4.7260165;-0.24436355;-2.2742972;-1.6025854;CODE
understanding;-0.64874727;-2.5176227;6.711001;1.7925994;1.2395127;-3.788768;-
we will preprocess the dataset by taking a monthly average and drop months;5.3136406;-3.436491;2.7379649;1.8321365;-0.6508749;1.003734;IRRE
for which no measurements were collected such a processing will have a;2.4812746;1.7820516;0.32381308;1.8344043;-0.57692105;-0.9432923;CODE
smoothing effect on the data;6.0664396;-0.4960322;4.027771;0.18596351;-2.0693257;4.2173357;-
the idea in this example will be to predict the co2 concentration in function;3.7339225;-0.9080134;3.1750262;1.0670338;-2.4756286;-0.5172482;CODE
of the date we are as well interested in extrapolating for upcoming year;0.01787248;-1.894426;2.5012915;1.8015367;-0.47503576;-0.15529011;CODE
after 2001;-3.425883;-0.34266466;3.2913034;-0.0708476;0.0036594912;-0.8281382;-
as a first step we will divide the data and the target to estimate the data;6.077203;-1.3079948;3.9273765;2.134484;0.5903614;1.3357505;-
being a date we will convert it into a numeric;0.54462457;-1.2758675;1.9655834;-1.3535731;-0.02652144;-2.729967;CODE
design the proper kernel;2.1927292;-3.3680675;-0.19975324;-1.5145768;1.5344362;1.8968257;-
to design the kernel to use with our gaussian process we can make some;4.0522923;-4.5063376;0.79226714;-0.39724422;0.29392532;4.45978;-
assumption regarding the data at hand we observe that they have several;5.090667;0.40612844;1.969699;2.2731874;3.5714371;-0.4909824;-
characteristics we see a long term rising trend a pronounced seasonal;0.6906955;-2.6408556;2.3967311;1.6403104;-1.5665399;0.9379157;CODE
variation and some smaller irregularities we can use different appropriate;4.5905538;1.0599653;2.5987449;0.94038063;2.591058;1.2725955;CODE
kernel that would capture these features;3.1074142;-5.597502;0.92358655;0.17542496;1.9162841;0.76047415;TASK
first the long term rising trend could be fitted using a radial basis;3.790789;-1.3563554;3.4113345;-0.5893025;-1.5038604;3.2075083;CODE
function rbf kernel with a large length scale parameter the rbf kernel;2.263911;-1.9917213;-2.4257228;-2.1281102;-0.3791146;3.813789;IRRE
with a large length scale enforces this component to be smooth a trending;3.7982137;-0.86660236;1.6809856;-0.50292534;-2.3869205;6.745625;CODE
increase is not enforced as to give a degree of freedom to our model the;-0.16998696;0.15716752;0.5879267;3.625276;0.36794516;3.170042;CODE
specific length scale and the amplitude are free hyperparameters;3.2629166;0.71886533;0.048683636;-2.0125217;-1.682184;3.2765102;IRRE
the seasonal variation is explained by the periodic exponential sine squared;0.531813;-1.1151669;2.3006675;-0.100079715;-3.4423583;2.0313745;CODE
kernel with a fixed periodicity of 1 year the length scale of this periodic;1.9858699;-0.99161166;1.5837256;-3.871488;-1.5757761;2.639295;CODE
component controlling its smoothness is a free parameter in order to allow;-1.9700508;0.9294562;-1.2824174;0.5822609;-0.11907046;7.6448092;IRRE
decaying away from exact periodicity the product with an rbf kernel is;-0.15383184;-0.62582177;-2.6013143;-0.21963713;-0.756926;4.135759;CODE
taken the length scale of this rbf component controls the decay time and is;0.49165756;-0.045909483;0.9178912;-1.445068;-2.5812898;2.960679;CODE
a further free parameter this type of kernel is also known as locally;-0.5554512;-2.9099658;-1.7990192;-1.5927755;1.5874293;4.506558;IRRE
periodic kernel;1.5059614;-2.1097248;2.613593;-2.8869507;0.54877955;2.484652;-
the small irregularities are to be explained by a rational quadratic kernel;2.6560888;-1.7929857;-0.65468055;-2.4286635;-2.1454628;2.5525439;-
component whose length scale and alpha parameter which quantifies the;1.6841681;0.9674145;1.8999628;-4.5732136;0.60476273;3.2467804;IRRE
diffuseness of the length scales are to be determined a rational quadratic;1.5723681;0.18081757;0.4521284;-2.9744291;-3.4118502;3.5829773;-
kernel is equivalent to an rbf kernel with several length scale and will;1.5723653;-2.9898393;-0.5543422;-0.9841945;1.8414739;3.763821;-
better accommodate the different irregularities;2.8146935;1.5452598;3.0329006;0.8585022;2.266357;1.4251896;-
finally the noise in the dataset can be accounted with a kernel consisting;7.4108863;-3.7993333;-2.3928993;1.0330286;1.1037639;2.635427;CODE
of an rbf kernel contribution which shall explain the correlated noise;3.1209095;-3.4306371;-3.4185796;-0.08951527;-1.2216023;4.025871;META
components such as local weather phenomena and a white kernel contribution;1.9263864;-3.2401273;0.34020102;-1.0391536;-0.57648575;1.8550332;META
for the white noise the relative amplitudes and the rbf s length scale are;2.2259996;-0.87639576;-0.10767584;-2.138066;-1.7641172;1.2131746;IRRE
further free parameters;0.9590997;0.76768756;-0.2156902;-1.533007;2.8572242;1.060836;IRRE
thus our final kernel is an addition of all previous kernel;-1.7953286;-0.86187786;0.55284846;0.49032634;1.3132744;2.7056699;TASK
model fitting and extrapolation;5.1135974;-0.15243597;1.855455;0.15395865;-1.0299911;1.9542125;-
now we are ready to use a gaussian process regressor and fit the available;5.0623364;-1.342586;0.18437809;0.36758003;-2.2235913;5.367597;IRRE
data to follow the example from the literature we will subtract the mean;2.97528;0.9137687;4.1047773;2.1089122;-0.45056581;-1.6958833;CODE
from the target we could have used normalize y true however doing so;1.3608731;1.6204209;-1.1826719;0.75625366;-2.1930375;2.7933216;CODE
would have also scaled the target dividing y by its standard deviation;2.6854417;1.58513;0.6161713;-0.79247105;-5.426589;0.42090595;-
thus the hyperparameters of the different kernel would have had different;0.9439886;-0.53001195;-2.6843135;0.70873547;-0.8528588;2.7733083;TASK
meaning since they would not have been expressed in ppm;-3.2256262;0.5677067;0.13525122;1.6136621;2.3227565;0.39936042;-
now we will use the gaussian process to predict on;6.0396023;-3.8419068;2.3790252;4.2998395;-1.2324739;1.5463167;IRRE
training data to inspect the goodness of fit;7.1668053;-2.17184;0.4001974;4.461363;-0.059076883;-2.7732563;-
future data to see the extrapolation done by the model;4.1272483;-1.6694239;3.0659974;3.654306;-0.55836284;0.68251455;TASK
thus we create synthetic data from 1958 to the current month in addition;2.288597;-3.8979437;1.6019461;-0.2991107;0.41881934;-0.9129331;TASK
we need to add the subtracted mean computed during training;2.933841;1.5856462;0.067001976;1.3631968;-0.95845956;1.1422604;TASK
our fitted model is capable to fit previous data properly and extrapolate to;5.7059407;0.88511026;1.5215805;2.0743484;-0.0013132647;2.9617097;CODE
future year with confidence;-0.08249813;-1.0561645;4.256745;3.544673;-0.2566145;-3.4209561;TASK
interpretation of kernel hyperparameters;2.852586;-3.614635;-0.24395828;0.56684697;0.81531256;1.497803;IRRE
now we can have a look at the hyperparameters of the kernel;3.8039396;-4.895203;0.030409122;2.009225;0.30871287;2.748401;IRRE
thus most of the target signal with the mean subtracted is explained by a;3.3202312;1.480417;2.5010262;1.282446;-1.6650441;2.034108;-
long term rising trend for 45 ppm and a length scale of 52 years the;0.7279718;-0.09901705;2.194374;1.243033;-1.1636524;-0.024313658;CODE
periodic component has an amplitude of 2 6ppm a decay time of 90 years and;-0.6137971;0.84447235;2.2776582;-2.5336676;-1.96498;-0.29552785;-
a length scale of 1 5 the long decay time indicates that we have a;1.1570144;0.7034672;1.8100493;-1.4552413;-1.6080064;-2.1624315;IRRE
component very close to a seasonal periodicity the correlated noise has an;2.2214224;0.75663453;0.37843004;-0.8870284;-1.2191919;2.8341312;IRRE
amplitude of 0 2 ppm with a length scale of 0 12 years and a white noise;0.61308277;1.2227266;0.24949381;-2.2105753;-3.0661194;0.4198153;-
contribution of 0 04 ppm thus the overall noise level is very small;0.684721;1.1150749;-3.0869987;-1.00902;-2.1453812;1.4403956;META
indicating that the data can be very well explained by the model;4.2621064;-2.9764135;2.8950589;3.4179573;2.7523172;0.08746757;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
we will work in a setting where x will contain a single feature we create a;-1.2740119;-0.884898;3.001582;2.5187798;5.103999;2.239624;IRRE
function that will generate the target to be predicted we will add an;2.7345097;-1.1629212;3.4185119;3.9409223;1.0568682;-1.4719318;TASK
option to add some noise to the generated target;0.6549322;0.06601585;0.5484872;3.4166374;0.7120053;3.114174;TASK
let s have a look to the target generator where we will not add any noise to;0.20077263;-0.0236352;-0.5659483;3.531962;0.045379434;2.160212;TASK
observe the signal that we would like to predict;5.1824946;-1.71126;4.1107774;5.220615;-1.7432373;0.41588584;-
the target is transforming the input x using a sine function now we will;-1.8066549;1.4346431;2.287885;-2.3511796;-5.7177844;-0.20995961;CODE
generate few noisy training samples to illustrate the noise level we will;6.0786724;-3.848934;1.628699;2.593596;1.5374961;-0.5682801;-
plot the true signal together with the noisy training samples;6.8027554;-0.7527288;1.9658471;0.5703542;-2.43591;0.6006917;-
optimisation of kernel hyperparameters in gpr;3.8702352;-2.413842;-2.4952497;0.28891563;0.98438066;3.2238686;IRRE
now we will create a;-2.2538476;-2.6190012;5.578251;1.3333268;3.319492;-2.214798;IRRE
class sklearn gaussian process gaussianprocessregressor;0.07611501;-4.350924;-5.482445;-0.6627528;-1.5173601;3.949769;IRRE
using an additive kernel adding a;1.2011402;-0.06434252;-1.0256486;-2.8636537;0.73779655;1.2046211;TASK
class sklearn gaussian process kernels rbf and;0.9696013;-5.4505563;-5.0274096;-0.9555071;-1.4681296;2.5189984;IRRE
class sklearn gaussian process kernels whitekernel kernels;1.0460395;-6.0380874;-5.444022;-0.47048464;-1.7107469;3.713298;IRRE
the class sklearn gaussian process kernels whitekernel is a kernel that;1.048646;-6.814959;-3.8949587;-0.40136746;-0.5192551;3.2763531;IRRE
will able to estimate the amount of noise present in the data while the;6.328955;-0.74532515;1.8269767;3.1931875;0.67260176;1.0026585;CODE
class sklearn gaussian process kernels rbf will serve at fitting the;3.5030637;-5.327455;-4.57201;-0.6130085;-1.3117139;3.4991808;IRRE
non linearity between the data and the target;5.4769373;0.7088705;1.9637729;0.9031429;-2.163617;2.039447;-
however we will show that the hyperparameter space contains several local;0.862776;-0.3232507;-1.6928283;2.2386355;3.0218046;3.7373633;IRRE
minima it will highlights the importance of initial hyperparameter values;3.769467;-0.60550344;0.755523;1.7768216;0.010393773;3.082385;IRRE
we will create a model using a kernel with a high noise level and a large;5.2568846;-5.751716;1.1131778;2.2056146;1.4179281;2.1355295;IRRE
length scale which will explain all variations in the data by noise;7.2271;-0.5016566;1.417343;-1.3524451;-0.3081735;1.009003;CODE
we see that the optimum kernel found still has a high noise level and an even;2.9089403;-3.1796796;-2.513507;1.2750263;-0.9995293;3.400037;TASK
larger length scale the length scale reaches the maximum bound that we;1.8796744;1.1396077;3.1693184;-0.96625423;-2.2373478;2.6604009;CODE
allowed for this parameter and we got a warning as a result;-4.9961247;3.9874766;-3.1020212;2.075549;-0.7258275;-0.9740492;IRRE
more importantly we observe that the model does not provide useful;0.40919003;-1.4430568;-1.1467487;7.5359454;-0.7812456;0.66880846;CODE
predictions the mean prediction seems to be constant it does not follow the;2.7299113;0.20144308;-0.1213508;4.5179086;-5.324257;0.91435146;CODE
expected noise free signal;1.6945704;1.3232431;0.72759056;0.5198592;-0.8225599;1.0004189;-
now we will initialize the class sklearn gaussian process kernels rbf;0.83373654;-6.0816426;-4.4960914;-0.17194971;-0.9802435;2.9391537;IRRE
with a larger length scale initial value and the;1.7519912;1.688857;3.496681;-3.0637774;-2.4376328;1.8402771;IRRE
class sklearn gaussian process kernels whitekernel with a smaller initial;1.0767889;-3.935372;-5.5668674;-0.1417574;-2.6234205;4.6946483;IRRE
noise level lower while keeping the parameter bounds unchanged;3.1606762;3.3499305;-2.9988396;0.77235836;-1.8740977;4.8983293;IRRE
first we see that the model s predictions are more precise than the;4.6213465;-3.9663737;0.80106086;7.108654;-1.7270398;1.1098267;IRRE
previous model s this new model is able to estimate the noise free;2.9597814;-1.8792543;-1.5121859;3.3398676;-0.9120505;2.7463696;CODE
functional relationship;-2.0973258;-1.0444491;5.0133944;0.5545347;2.2415338;-0.7492948;CODE
looking at the kernel hyperparameters we see that the best combination found;5.100448;-3.2730124;-0.21159998;0.52051514;2.8263144;1.4021976;IRRE
has a smaller noise level and shorter length scale than the first model;2.0915358;-1.391233;-1.3867503;0.72865206;-1.7298422;2.1239958;CODE
we can inspect the negative log marginal likelihood lml of;-0.9548303;0.48577154;-1.2692701;1.2293758;-0.4321845;1.2207444;-
class sklearn gaussian process gaussianprocessregressor;0.07611501;-4.350924;-5.482445;-0.6627528;-1.5173601;3.949769;IRRE
for different hyperparameters to get a sense of the local minima;4.9412346;-1.2100997;-0.45454916;0.4258952;0.34337294;4.482466;IRRE
we see that there are two local minima that correspond to the combination of;2.0879722;-1.0346963;1.4404197;-2.7967238;1.3949854;2.587791;-
hyperparameters previously found depending on the initial values for the;1.7307199;3.4725273;-0.71737707;2.8495238;-0.56797945;1.3606315;IRRE
hyperparameters the gradient based optimization might or might not;3.8594654;-3.0676963;-0.6151091;3.834438;0.6830072;4.2747474;IRRE
converge to the best model it is thus important to repeat the optimization;4.7999887;-1.3640493;1.6223987;5.2017436;-0.0988427;4.161301;CODE
several times for different initializations this can be done by setting the;-5.061222;1.8591202;-0.120109685;1.3497294;1.1743726;4.2236214;CODE
n restarts optimizer parameter of the;-0.08854458;1.8196507;-1.1201363;0.76732594;-0.9840576;1.9663733;IRRE
class sklearn gaussian process gaussianprocessregressor class;-0.14514142;-4.7188935;-5.800803;-0.91876185;-0.94404036;3.6652246;IRRE
let s try again to fit our model with the bad initial values but this time;2.4670842;3.9846184;-2.0258665;-0.15695632;-4.3922853;0.5486807;CODE
with 10 random restarts;-0.9480473;-0.8175825;4.7695556;3.8382382;1.0805012;-2.1494775;IRRE
as we hoped random restarts allow the optimization to find the best set;3.8883343;-0.5351;1.1938752;3.8064203;1.2796435;1.7120585;IRRE
of hyperparameters despite the bad initial values;1.9805617;4.349453;-1.6949507;2.5490382;-1.4216985;0.18777646;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset generation;6.227099;-4.6965995;2.8726146;-0.024883118;3.8821828;-2.5538309;IRRE
we will start by generating a synthetic dataset the true generative process;3.5195858;-5.0529504;1.4181366;2.5732615;2.908645;1.021006;IRRE
is defined as math f x x sin x;-1.581419;0.5590083;2.4348035;-1.997603;-0.22916204;-1.3923745;CODE
we will use this dataset in the next experiment to illustrate how gaussian;5.6233773;-3.7162473;1.4757745;0.8088295;-1.8159225;0.29644608;IRRE
process regression is working;0.8384488;0.554364;-0.29189146;3.6412344;-4.592333;-0.7205014;-
example with noise free target;1.789609;-0.7385089;0.12319713;1.3259137;0.7548143;2.220207;-
in this first example we will use the true generative process without;-1.9994128;0.37579358;0.6411486;3.9028835;2.129144;2.842483;CODE
adding any noise for training the gaussian process regression we will only;3.381906;-3.4500804;-1.422456;3.6251998;-1.090966;4.3023763;TASK
select few samples;5.204987;2.3490212;3.0407813;0.50722355;4.632969;-2.7778034;CODE
now we fit a gaussian process on these few training data samples we will;7.229017;-2.622153;-0.9123636;1.778606;0.021292288;2.9279046;-
use a radial basis function rbf kernel and a constant parameter to fit the;3.975609;0.6562087;-1.431911;-4.915919;-2.4945705;4.005655;CODE
amplitude;0.37899548;0.7887146;5.0771646;-2.4231124;-2.6755068;-1.1836405;-
after fitting our model we see that the hyperparameters of the kernel have;3.4369543;-3.327679;-1.0641533;2.6850953;-0.81142145;3.1114874;IRRE
been optimized now we will use our kernel to compute the mean prediction;5.9624195;-4.634441;-0.0410024;3.0358896;-1.219496;1.8137006;-
of the full dataset and plot the 95 confidence interval;2.5699437;-0.5420838;2.485457;-0.81443554;-4.1226063;-2.2140837;IRRE
we see that for a prediction made on a data point close to the one from the;5.1731234;-2.1750796;3.149552;2.2284598;-1.043672;1.8801044;CODE
training set the 95 confidence has a small amplitude whenever a sample;3.5981293;1.2270237;-1.5004271;2.1256466;-2.0870535;-0.5126873;IRRE
falls far from training data our model s prediction is less accurate and the;5.3780317;-2.5186093;-1.0555822;5.942123;-2.17342;0.33154607;CODE
model prediction is less precise higher uncertainty;4.231619;-0.96667176;-1.2611954;5.2805066;-2.6495085;2.6570609;CODE
example with noisy targets;3.6442354;-0.71842355;1.6063322;2.988593;-0.03817233;1.7190268;-
we can repeat a similar experiment adding an additional noise to the target;1.6425586;-1.2942959;2.3696332;5.6326675;-1.2746565;1.0054165;TASK
this time it will allow seeing the effect of the noise on the fitted model;1.1147916;-2.9677398;1.2030632;4.469181;-1.2612362;3.3658123;CODE
we add some random gaussian noise to the target with an arbitrary;3.439;-1.639307;0.35840583;1.6844476;0.37418267;4.4397273;IRRE
standard deviation;2.5261939;0.73504263;2.4939368;-1.9512395;-0.79058576;-3.647326;-
we create a similar gaussian process model in addition to the kernel this;3.3269546;-4.072334;1.710086;0.3429972;0.9129559;5.0020924;TASK
time we specify the parameter alpha which can be interpreted as the;-1.2487555;0.22554336;0.7962053;1.0838195;0.8224002;0.9749965;IRRE
variance of a gaussian noise;-0.4295821;-0.7638269;-0.65863353;-0.79791576;-2.647972;2.6150017;CODE
let s plot the mean prediction and the uncertainty region as before;2.2232883;-0.6614885;3.8708913;-0.5411513;-5.5717;0.71760833;CODE
the noise affects the predictions close to the training samples the;5.897463;-3.8733487;-0.20686941;5.6039796;-0.22318426;0.27869016;IRRE
predictive uncertainty near to the training samples is larger because we;6.433181;-0.8777467;-1.2035983;5.286458;-1.2770386;1.4334029;META
explicitly model a given level target noise independent of the input;4.9311004;0.17062292;-0.44923735;1.7183915;0.9682115;4.0792375;CODE
variable;-2.0704978;1.6583673;5.447666;-2.0251834;1.3557013;-5.203915;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
sequence similarity matrix under the kernel;4.4650316;-2.3036833;-0.073563226;-3.3394952;0.6432732;1.7141354;-
regression;4.8113813;-1.4023851;5.968424;1.4558641;-1.5940726;-2.9783654;-
classification;5.668271;-5.8220553;4.2595444;1.7214531;6.909542;-2.19592;IRRE
whether there are a s in the sequence;-0.876517;3.3580391;1.726995;-0.48534214;2.047592;-6.30788;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
helper function;-2.2560544;1.2231622;4.327651;-0.46517372;0.3880871;-2.9166162;CODE
before presenting each individual kernel available for gaussian processes;3.0686157;-3.6395178;-0.56307036;0.35305098;1.6803094;6.3210044;CODE
we will define a helper function allowing us plotting samples drawn from;3.430556;-1.0761515;3.4132683;-1.0475137;-2.2573593;0.109075725;CODE
the gaussian process;2.0719094;-2.1064043;2.5575867;-0.16622889;-1.5925633;3.3908646;-
this function will take a;-0.92738056;2.737213;4.824412;-2.883275;0.04766066;-4.5392146;CODE
class sklearn gaussian process gaussianprocessregressor model and will;0.34237847;-3.9312732;-4.8886266;1.0321407;-1.2214197;2.96386;IRRE
drawn sample from the gaussian process if the model was not fit the samples;3.1606123;2.749982;-0.8036616;2.191484;-2.738925;2.286294;CODE
are drawn from the prior distribution while after model fitting the samples are;1.3344629;1.5096236;1.5591179;2.1963024;-1.1626173;4.0084653;CODE
drawn from the posterior distribution;-0.8203392;0.30871058;4.8010845;0.4537654;0.33844838;1.9813654;META
label f sampled function idx 1;1.6577909;3.3061988;-0.19077946;-4.239293;2.2951958;-0.61630946;CODE
dataset and gaussian process generation;5.0915813;-4.0502906;0.22222;0.59831303;0.23785728;2.6090133;IRRE
we will create a training dataset that we will use in the different sections;4.500934;-6.2306533;3.927914;1.3110751;5.9740524;0.816321;IRRE
kernel cookbook;-0.23948646;-6.5433555;1.257521;0.03397825;-1.4069047;-1.0724682;-
in this section we illustrate some samples drawn from the prior and posterior;1.5111864;-1.7996289;4.5585217;0.900614;2.8886015;1.865142;CODE
distributions of the gaussian process with different kernels;1.0221052;-3.0387027;-0.47728318;-0.029911514;-0.48615083;5.1443663;META
radial basis function kernel;2.2002711;-2.2807214;-0.06246928;-3.7666774;-0.88255876;3.6455994;CODE
plot prior;0.686823;0.45487097;6.081113;-0.88870025;-3.0148387;1.7235895;-
plot posterior;0.25264916;0.6819425;6.151311;-3.0317206;-2.724379;2.0753503;-
rational quadratic kernel;-0.18277898;-2.3718753;-0.2526489;-3.6227093;-0.4288928;2.1143758;-
plot prior;0.686823;0.45487097;6.081113;-0.88870025;-3.0148387;1.7235895;-
plot posterior;0.25264916;0.6819425;6.151311;-3.0317206;-2.724379;2.0753503;-
exp sine squared kernel;1.1658845;-2.4163556;-1.6946247;-3.0970073;-2.7453268;2.9636073;-
plot prior;0.686823;0.45487097;6.081113;-0.88870025;-3.0148387;1.7235895;-
plot posterior;0.25264916;0.6819425;6.151311;-3.0317206;-2.724379;2.0753503;-
dot product kernel;1.3744926;-5.0239606;-1.8430485;-4.4993434;-0.46966544;2.7328546;CODE
plot prior;0.686823;0.45487097;6.081113;-0.88870025;-3.0148387;1.7235895;-
plot posterior;0.25264916;0.6819425;6.151311;-3.0317206;-2.724379;2.0753503;-
mat rn kernel;4.265337;-2.683756;-1.7009419;-4.1264167;-0.6042734;1.3999091;-
plot prior;0.686823;0.45487097;6.081113;-0.88870025;-3.0148387;1.7235895;-
plot posterior;0.25264916;0.6819425;6.151311;-3.0317206;-2.724379;2.0753503;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
to use this experimental feature we need to explicitly ask for it;-1.0877484;-2.7640293;-0.5906602;6.8939953;-1.1575354;0.8373349;TASK
from sklearn experimental import enable iterative imputer noqa f401;2.1473963;-4.167484;-6.167386;0.1567887;-4.6431565;-0.38231748;CODE
2k samples is enough for the purpose of the example;5.5468616;-0.07250584;0.311733;0.59485906;2.1561556;-2.5821757;CODE
remove the following two lines for a slower run with different error bars;0.85157454;5.031065;-0.6800671;0.7247377;-1.6663015;-1.4578099;CODE
we scale data before imputation and training a target estimator;4.8528457;-0.08641901;1.0226682;3.88831;-0.2963051;3.1782165;IRRE
because our target estimator and some of the imputers assume;0.7626829;-0.111307345;-1.6186405;4.140624;-3.4918857;2.9797316;IRRE
that the features have similar scales;4.704049;-4.5074143;3.7730343;-0.99167293;0.9604778;2.4894943;TASK
estimate the score on the entire dataset with no missing values;5.716363;2.3565948;-0.8537154;0.9938863;-0.7054179;-1.5834229;IRRE
add a single missing value to each row;2.9739091;4.2457194;1.9919599;-3.4134066;1.0531611;-2.6829052;TASK
estimate the score after imputation mean and median strategies;2.2673433;2.130108;1.7491232;4.184507;-0.54769546;0.44693673;-
estimate the score after iterative imputation of the missing values;3.2530484;2.8338869;0.14225647;2.5574772;-0.53744966;-0.98539805;IRRE
with different estimators;2.1948595;1.0491973;2.8846772;3.423675;-0.17138335;3.0972161;IRRE
we tuned the hyperparameters of the randomforestregressor to get a good;2.3062475;-3.4371393;-2.3044744;6.6815586;-0.46129456;0.30471605;IRRE
enough predictive performance for a restricted execution time;2.932505;-0.73708624;0.04223662;6.27002;1.8451154;0.71463263;CODE
iterative imputer is sensitive to the tolerance and;-0.5756347;0.89256245;-0.34471974;4.2543874;-1.6519675;0.10258452;-
dependent on the estimator used internally;1.1757822;1.5049355;0.6836414;4.5701795;-0.9383765;5.4318037;CODE
we tuned the tolerance to keep this example run with limited computational;3.6708415;-0.28597894;-0.91624504;3.5669045;-0.82646704;-0.10417433;CODE
resources while not changing the results too much compared to keeping the;2.4680407;-0.5006704;4.7479224;5.8079405;0.5811584;1.3636427;IRRE
stricter default value for the tolerance parameter;-0.92681587;5.3424687;-3.201032;1.5495092;-1.5897617;2.5746815;IRRE
plot california housing results;2.1333916;-1.653416;3.4720123;-0.42056167;-1.9217948;-1.7430543;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
download the data and make missing values sets;3.6470878;1.4760486;0.5220429;-2.193959;-0.47088978;-1.5250348;IRRE
first we download the two datasets diabetes dataset is shipped with;2.1184957;-5.2281404;0.09924739;-0.073468074;0.20415065;-0.35292912;IRRE
scikit learn it has 442 entries each with 10 features california housing;0.9655212;-9.563307;-2.6370578;0.39794186;0.63849837;-3.9313192;TASK
dataset is much larger with 20640 entries and 8 features it needs to be;4.3364587;-2.2114468;-2.008435;-1.4692072;1.0527093;-0.30713627;TASK
downloaded we will only use the first 300 entries for the sake of speeding;-1.6282032;-3.1018374;1.470365;2.2881145;1.4408166;-0.23718272;CODE
up the calculations but feel free to use the whole dataset;6.6778116;-3.6041248;2.5201569;-2.0609794;0.3787189;-1.6165005;IRRE
add missing values in 75 of the lines;2.4139524;3.7369952;2.4802115;-3.4233825;-1.3907511;-3.8340507;IRRE
impute the missing data and score;3.2406049;3.12276;0.8933341;1.7351384;0.4270371;-3.2943103;-
now we will write a function which will score the results on the differently;5.254716;2.4342158;4.4214363;1.3081244;2.2828991;-4.8876157;CODE
imputed data including the case of no imputation for full data;2.0330725;4.1005673;-0.1728889;1.138704;1.7268618;-1.1125144;CODE
we will use class sklearn ensemble randomforestregressor for the target;3.903031;-4.664164;-3.815577;3.4653387;0.5345019;0.25715822;CODE
regression;4.8113813;-1.4023851;5.968424;1.4558641;-1.5940726;-2.9783654;-
to use the experimental iterativeimputer we need to explicitly ask for it;1.3346503;-1.4107414;-2.6441805;4.511024;-3.38712;0.28774852;TASK
from sklearn experimental import enable iterative imputer noqa f401;2.1473963;-4.167484;-6.167386;0.1567887;-4.6431565;-0.38231748;CODE
estimate the score;4.615375;1.943897;3.015598;2.2007213;0.096099295;-3.296373;-
first we want to estimate the score on the original data;5.813525;0.58840793;2.951917;1.3030529;0.5573979;-1.6128294;-
replace missing values by 0;2.0851157;5.726539;-0.24892676;-4.522684;-1.1043344;-3.9788742;IRRE
now we will estimate the score on the data where the missing values are;4.6683793;1.3641663;0.44994408;1.7158046;0.2979222;-2.2088137;IRRE
replaced by 0;-3.0413003;4.4513764;1.0979098;-4.5482826;-1.8050661;-4.8775535;OUTD
impute missing values with mean;2.729246;5.5063767;0.48956603;-0.71048504;-2.600158;-1.6737722;IRRE
knn imputation of the missing values;2.8889897;2.670116;-1.5531847;-1.6184107;0.14594531;-3.099545;IRRE
class sklearn impute knnimputer imputes missing values using the weighted;4.9755864;-0.72758836;-5.5520535;-0.91493636;-2.0159452;-1.1612743;IRRE
or unweighted mean of the desired number of nearest neighbors if your features;7.505871;-1.6283371;1.4411317;-2.4151568;2.0200312;2.0834205;TASK
have vastly different scales as in the california housing dataset;3.809986;-2.3921251;0.49631643;0.38321683;0.13139018;1.384895;CODE
consider re scaling them to potentially improve performance;3.242153;-0.8812701;0.79209036;0.13957576;-0.45857465;4.719251;CODE
iterative imputation of the missing values;3.792296;3.3983738;0.0020710167;0.7170382;0.06256328;-2.001479;IRRE
another option is the class sklearn impute iterativeimputer this uses;5.963504;-3.662503;-3.5829675;1.5679814;-1.8202515;0.5280642;CODE
round robin regression modeling each feature with missing values as a;4.5454617;0.62129754;0.9609813;0.858908;-0.48423246;1.5831928;IRRE
function of other features in turn we use the class s default choice;-1.2178845;-2.7794619;0.29732627;2.4133584;3.9315598;2.4735563;CODE
of the regressor model class sklearn linear model bayesianridge;2.1196766;-4.3885627;-2.7579987;0.9397556;-1.317837;2.0314138;IRRE
to predict missing feature values the performance of the predictor;5.3307467;-0.9559305;-1.0814224;3.1470163;0.37414303;-0.7152841;IRRE
may be negatively affected by vastly different scales of the features;4.2193522;-1.8084427;-0.43881422;1.0626559;-0.9619096;3.725275;TASK
so we re scale the features in the california housing dataset;3.9134605;-4.222998;1.8760068;0.9710938;1.2200332;2.5083275;CODE
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
finally we are going to visualize the score;2.0378246;-0.8392469;6.5889096;0.022309694;-0.45694837;-1.9249097;CODE
plot diabetes results;4.3999023;-0.3458046;4.891047;-1.6975988;-3.4648874;-2.479505;IRRE
plot california dataset results;4.437593;-2.244302;2.9319084;-2.9761043;-3.5924828;-1.5421457;IRRE
you can also try different techniques for instance the median is a more;5.371832;0.43314844;3.5494158;0.6053651;-0.683634;0.33329108;CODE
robust estimator for data with high magnitude variables which could dominate;6.1683273;0.29787704;-0.43934137;1.653526;-2.0561385;4.1433043;CODE
results otherwise known as a long tail;1.5379161;-0.016734561;2.3256757;2.898437;-0.9227845;-2.385719;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the dataset simulated hourly wages;3.6755033;-3.8575423;1.6112944;-0.0837549;-2.0840898;-0.69082695;IRRE
the data generating process is laid out in the code below work experience in;-0.17507264;-2.7228444;0.44467375;-1.3347588;2.1273203;-1.2657405;CODE
years and a measure of ability are drawn from normal distributions the;1.7723895;-0.9762718;3.1482747;0.84929144;0.16018485;-0.196039;META
hourly wage of one of the parents is drawn from beta distribution we then;-1.2045056;0.6734511;2.113775;0.5995699;-1.3225815;-0.47694504;META
create an indicator of college degree which is positively impacted by ability;1.3755147;-1.3634837;1.8079152;2.198133;1.3301686;-0.7757629;IRRE
and parental hourly wage finally we model hourly wages as a linear function;1.0974088;-1.4632065;3.0587342;0.5429135;-1.18507;1.5575895;CODE
of all the previous variables and a random component note that all variables;1.2761139;-0.41258028;2.029393;-0.892654;2.6987946;0.40813023;IRRE
have a positive effect on hourly wages;-0.83698326;-0.009250124;2.3920772;1.4825355;-1.7227006;0.64390236;-
description of the simulated data;6.0374174;-2.8281116;3.8737113;-0.046545595;0.511417;-1.3298892;META
the following plot shows the distribution of each variable and pairwise;0.1203825;-0.43927076;5.298462;-4.9704356;-2.9559186;-2.2308226;IRRE
scatter plots key to our ovb story is the positive relationship between;1.5121281;-4.419225;4.1464963;-1.2295082;-2.8494122;1.4253732;-
ability and college degree;-1.2365466;-2.5824044;1.6308681;1.1350056;-0.28826952;-2.0248792;-
in the next section we train predictive models and we therefore split the;2.730807;-4.9598317;1.6239654;5.0993705;4.2461653;1.4223207;CODE
target column from over features and we split the data into a training and a;6.3856463;-2.99135;2.3214693;0.20886834;3.0540574;-0.5884767;CODE
testing set;2.1398306;4.6689324;1.855855;3.945377;1.7774844;-7.2317634;IRRE
income prediction with fully observed variables;4.1758585;-1.1827965;1.3821392;2.0682225;-0.1820398;1.255866;IRRE
first we train a predictive model a;4.702324;-3.970523;2.6557896;6.237747;2.5965874;0.047933653;-
class sklearn linear model linearregression model in this experiment;2.4894898;-2.8125336;-3.9039898;1.1328654;-3.3879013;-1.1352364;CODE
we assume that all variables used by the true generative model are available;-0.09688276;-1.1677955;-0.5442633;4.2425175;2.6616251;2.9486747;IRRE
this model predicts well the hourly wages as shown by the high r2 score we;2.3400152;-2.6096292;1.3490278;2.794716;-1.60121;-0.2093299;CODE
plot the model coefficients to show that we exactly recover the values of;3.3261154;0.745361;3.4221842;-1.9770297;-5.4190326;0.75192416;IRRE
the true generative model;1.6311452;-1.9781922;2.1618388;4.0365624;3.0699835;1.629261;-
income prediction with partial observations;4.6023464;-0.9958994;2.2359152;1.1762258;0.85897636;1.3279068;-
in practice intellectual abilities are not observed or are only estimated;0.30450082;-1.8305695;0.26319999;3.8972692;0.07702521;-1.841129;CODE
from proxies that inadvertently measure education as well e g by iq tests;0.08727133;-2.5545423;0.88807505;5.0704985;-1.2331933;-1.9564575;IRRE
but omitting the ability feature from a linear model inflates the estimate;3.2686899;0.4470153;-2.5290825;3.6217434;-0.36960077;3.9231405;TASK
via a positive ovb;-2.531727;-0.34583482;1.8239971;0.2309824;2.7143495;0.73372555;-
the predictive power of our model is similar when we omit the ability feature;1.8557974;-2.557363;-1.409752;4.6024776;1.2000113;1.6919471;TASK
in terms of r2 score we now check if the coefficient of the model are;2.1020446;1.9104857;-0.52309364;2.7279556;0.1712979;-2.9933567;IRRE
different from the true generative model;-0.27549326;-0.97401047;0.30883092;3.3005803;1.532642;1.2502713;CODE
to compensate for the omitted variable the model inflates the coefficient of;-0.33918762;3.0611296;-0.1488716;1.0607736;-2.2201743;2.5908418;CODE
the college degree feature therefore interpreting this coefficient value;1.0131692;0.15131348;-0.863844;-1.461313;-0.8120895;-2.0138466;CODE
as a causal effect of the true generative model is incorrect;-1.9612162;0.720599;-0.42326134;5.0404687;-0.31241184;2.587206;-
lessons learned;-2.0263567;-4.053886;2.3760922;3.4337988;-1.2570904;-0.61066455;-
machine learning models are not designed for the estimation of causal;1.0013225;-2.7502959;-1.4420611;5.493033;-1.2145172;1.0072252;CODE
effects while we showed this with a linear model ovb can affect any type of;1.2811245;-0.46654338;0.4091673;1.7470752;0.41436067;2.2426982;CODE
model;1.6850569;-3.146167;5.856185;2.3733578;2.0956028;-1.8042274;-
whenever interpreting a coefficient or a change in predictions brought about;1.822629;-1.3353376;2.0329025;5.7427607;-1.6850705;-0.13572402;CODE
by a change in one of the features it is important to keep in mind;-1.4875667;-3.4699519;4.54177;4.5520277;2.091896;2.8099418;CODE
potentially unobserved variables that could be correlated with both the;0.82714415;1.5406431;0.28215313;2.1606963;1.3810639;2.2620888;IRRE
feature in question and the target variable such variables are called;-0.5258983;-0.8098703;1.1002921;1.8051741;2.3456144;-0.24450897;IRRE
confounding variables https en wikipedia org wiki confounding in;-3.1992092;-0.23828147;-0.25329706;2.266504;-0.3713424;-1.6078143;CODE
order to still estimate causal effect in the presence of confounding;-0.89536846;2.0819027;0.6500209;6.400472;-1.6657506;3.2655795;TASK
researchers usually conduct experiments in which the treatment variable e g;-0.8866579;-2.2446268;2.4406078;6.136678;-1.0174433;-1.5401176;IRRE
college degree is randomized when an experiment is prohibitively expensive;2.0199444;-0.7833349;-1.2317386;6.099168;-1.1434909;-0.71662587;IRRE
or unethical researchers can sometimes use other causal inference techniques;-0.788077;-3.167816;0.26635322;6.4359;-0.9520884;0.36648875;CODE
such as instrumental variables;0.2511722;-1.8000298;1.2497059;0.4942737;3.159948;0.668535;IRRE
https en wikipedia org wiki instrumental variables estimation iv;-0.31739226;-1.5225339;0.22450772;-0.11217165;-0.64973646;2.4212348;CODE
estimations;4.9566965;-0.77949315;4.6781526;3.1874065;-0.59509873;0.63530827;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the dataset wages;4.675478;-4.3663116;1.7151655;0.7280367;-0.104224294;-1.4221575;IRRE
we fetch the data from openml http openml org;-3.4777577;-1.5483294;2.3346465;0.558374;1.7549105;0.25116012;CODE
note that setting the parameter as frame to true will retrieve the data;-0.8683897;4.2758727;1.7625765;-0.045808952;-3.0789375;2.0786557;IRRE
as a pandas dataframe;1.9828105;-3.573106;3.1477368;-3.834279;-2.2440653;-2.5503106;-
then we identify features x and target y the column wage is our;5.7156086;-2.2669835;1.8429371;-0.21598959;3.0321302;-1.2968583;TASK
target variable i e the variable which we want to predict;2.1662433;-2.0075405;3.3945642;2.8371887;0.9207507;-1.1124624;IRRE
note that the dataset contains categorical and numerical variables;5.141569;-3.9292176;-1.815384;-2.3162484;1.8782563;-2.8608027;IRRE
we will need to take this into account when preprocessing the dataset;3.8894262;-2.6809123;-3.3674128;1.6259557;1.5263076;2.559577;CODE
thereafter;-2.887529;-0.4478487;5.18957;2.341175;0.7186975;-1.0331643;-
our target for prediction the wage;2.3998241;-1.941261;2.7975821;5.0788264;-1.9131687;-0.1276064;CODE
wages are described as floating point number in dollars per hour;0.60573953;0.37266096;0.19579971;-2.8818212;-2.7929344;-0.6215195;CODE
we split the sample into a train and a test dataset;5.822403;-1.3244023;2.63077;2.5135155;3.6473796;-2.9330902;IRRE
only the train dataset will be used in the following exploratory analysis;4.541231;-2.1750896;0.38283867;2.6856375;1.5058343;0.6462574;IRRE
this is a way to emulate a real situation where predictions are performed on;3.467446;-3.5181422;4.650997;6.541989;-0.27534238;0.20365304;CODE
an unknown target and we don t want our analysis and decisions to be biased;1.5898702;-0.9018014;1.0726672;6.2001195;-1.043227;-0.13508262;CODE
by our knowledge of the test data;5.631424;-1.8563466;1.6625264;5.195411;2.1707761;-5.232878;IRRE
first let s get some insights by looking at the variables distributions and;2.5718257;-0.94144404;2.1470895;1.4932609;-1.0584502;-2.2881281;CODE
at the pairwise relationships between them only numerical;4.3349175;2.6991248;-0.7524206;-5.908571;1.2536569;-1.0539536;-
variables will be used in the following plot each dot represents a sample;3.9605722;0.01066603;3.831439;-5.629536;-2.9111562;-1.3613383;CODE
marginal dependencies;-0.6611038;-0.75443494;1.6887947;0.8053034;3.4272945;2.441677;CODE
looking closely at the wage distribution reveals that it has a;0.03107929;-0.35837832;0.7360707;1.4005244;-0.55928314;-0.4357903;META
long tail for this reason we should take its logarithm;-2.0600936;0.63563144;1.8491445;1.4520999;-2.6545255;-2.0374594;CODE
to turn it approximately into a normal distribution linear models such;4.596639;-1.7208226;3.1191862;-0.08838883;-0.9179537;3.0245333;META
as ridge or lasso work best for a normal distribution of error;4.35511;-2.307192;-0.94067067;1.0032308;-1.877084;5.314916;META
the wage is increasing when education is increasing;-1.9611734;-1.1376758;2.1931818;1.9965373;-2.34158;0.4955385;-
note that the dependence between wage and education;-0.7709632;-1.5088619;2.325116;2.4290292;-1.7286701;0.19344957;TASK
represented here is a marginal dependence i e it describes the behavior;-0.79601234;-1.0779577;3.1721685;0.573653;2.889853;2.0147305;CODE
of a specific variable without keeping the others fixed;0.93711954;3.9286778;3.831332;-1.7812128;1.3533152;-1.2112072;IRRE
also the experience and age are strongly linearly correlated;2.4144378;-1.4569913;1.5216117;1.2769321;-0.37935865;3.1613388;-
the pipeline;-1.1120932;-3.6747925;4.6040177;3.5959895;0.62268406;-0.6415795;CODE
the machine learning pipeline;4.454076;-6.9995217;1.3352362;3.9970431;3.2948668;-0.8810443;CODE
to design our machine learning pipeline we first manually;3.0118902;-6.888945;1.1252763;3.903807;3.4405437;-0.81375337;CODE
check the type of data that we are dealing with;4.767042;2.280094;0.006011912;0.58500314;3.0915058;-4.212741;-
as seen previously the dataset contains columns with different data types;2.9861748;-1.6811038;-3.2719443;-3.4528773;1.4789441;0.54334575;IRRE
and we need to apply a specific preprocessing for each data types;2.3521833;-1.9209905;-2.6020417;-0.2637198;5.9503517;0.434856;CODE
in particular categorical variables cannot be included in linear model if not;-0.21630073;1.6329913;-3.6356847;-1.6277177;-0.28290665;0.45297807;CODE
coded as integers first in addition to avoid categorical features to be;0.59489393;0.5836348;-1.4813068;-2.8120937;3.761191;-2.8274584;TASK
treated as ordered values we need to one hot encode them;2.4007838;3.071564;-0.938507;-5.5464196;3.6678512;-1.30218;IRRE
our pre processor will;-1.2467798;-1.4567794;1.7623495;3.5406427;-0.8989283;0.3850289;-
one hot encode i e generate a column by category the categorical;2.1933608;-0.9592554;0.36029673;-3.5858016;2.920122;-1.9214401;-
columns only for non binary categorical variables;2.2921584;0.18706591;-1.650615;-5.3474035;2.6488435;-1.1766692;CODE
as a first approach we will see after how the normalisation of numerical;5.3474255;-0.33953622;-2.3263476;-3.0721517;-0.20986229;4.408365;-
values will affect our discussion keep numerical values as they are;2.2015202;1.3434024;0.92173845;-0.19067529;0.42520753;-1.5083047;IRRE
verbose feature names out false avoid to prepend the preprocessor names;-2.394958;-0.29240963;-5.1639256;3.1550622;1.2662998;1.8582352;CODE
we use a ridge regressor;2.747732;-2.4121583;1.8316497;-1.8910989;-1.5225;4.9812527;-
with a very small regularization to model the logarithm of the wage;3.0562136;-0.9315956;0.522397;1.552094;-0.2157085;2.3968534;-
processing the dataset;7.368784;-4.1362886;3.1027572;-0.46787173;3.201155;-2.8559697;IRRE
first we fit the model;1.1382284;-2.2488706;2.9218307;2.1820078;0.40667972;2.0185246;-
then we check the performance of the computed model by plotting its predictions;5.537895;-0.5291944;1.488255;4.872408;-1.1453978;0.14613399;CODE
against the actual values on the test set and by computing;6.107938;6.069491;-0.93272275;2.3341281;-0.49523354;-7.2814064;IRRE
the median absolute error;3.7036092;1.7371781;0.999212;0.044426385;-3.3348198;-0.65711856;-
the model learnt is far from being a good model making accurate predictions;3.775923;-5.00833;-0.11028821;7.594977;-1.5547343;-0.9507396;CODE
this is obvious when looking at the plot above where good predictions;1.748341;-2.304365;2.005551;3.0176978;-5.5980024;1.9114074;IRRE
should lie on the black dashed line;-3.0435073;1.9026884;2.2248504;-1.7371086;-1.1949453;-0.5056915;-
in the following section we will interpret the coefficients of the model;0.03408807;-1.9233134;1.7064849;-0.42386854;-0.074989416;-0.34464738;CODE
while we do so we should keep in mind that any conclusion we draw is;-1.6196272;-0.5062744;3.7770374;4.8792377;-0.27878174;0.7955644;CODE
about the model that we build rather than about the true real world;0.14760011;-4.442398;2.3436675;4.638947;-0.7943849;0.96749616;-
generative process of the data;4.7851367;-2.7543561;4.186344;0.6387013;3.8729222;1.5204905;-
interpreting coefficients scale matters;2.5784295;1.7839456;0.9213303;-1.7798954;-3.4144955;1.0505918;CODE
first of all we can take a look to the values of the coefficients of the;1.3222866;1.5552044;0.44251353;-4.2009788;-2.399091;-0.5358427;IRRE
regressor we have fitted;1.1757337;1.7791629;2.342698;-1.9788865;-1.8955487;1.4905691;-
the age coefficient is expressed in dollars hour per living years while the;-0.42817605;0.16217642;1.3046039;-2.5357223;-1.2434139;0.07345624;CODE
education one is expressed in dollars hour per years of education this;-1.3737036;-2.062349;1.6172305;-0.13471344;0.6254879;-0.3135298;CODE
representation of the coefficients has the benefit of making clear the;1.59796;-1.2724347;0.34654206;-1.8783551;0.6496154;1.7784895;-
practical predictions of the model an increase of math 1 year in age;1.683177;-1.7943594;3.7041082;3.3142848;-3.3051622;-2.0490205;-
means a decrease of math 0 030867 dollars hour while an increase of;0.27731812;1.0875449;1.9135133;-1.2551191;-3.1350443;-2.182525;CODE
math 1 year in education means an increase of math 0 054699;-0.0801847;0.09139391;0.39543366;-0.9675794;-1.8278904;-3.4819412;-
dollars hour on the other hand categorical variables as union or sex are;-0.46037218;-0.13531785;1.2323904;-0.6819064;2.149422;-1.1045488;CODE
adimensional numbers taking either the value 0 or 1 their coefficients;-0.35510534;3.5075455;-0.48249716;-4.7480817;0.4860514;-1.2128766;IRRE
are expressed in dollars hour then we cannot compare the magnitude of;1.3694564;1.8723587;1.0698522;0.17492789;-3.0479677;-1.8678106;IRRE
different coefficients since the features have different natural scales and;3.507664;-2.4596395;-0.017541593;-3.0074697;0.6183909;2.4825392;TASK
hence value ranges because of their different unit of measure this is more;2.9312384;3.8440568;0.9204282;-1.8748652;0.51205397;0.5883813;IRRE
visible if we plot the coefficients;0.43729562;0.46056712;4.182595;-3.7233114;-4.352398;1.2471561;-
indeed from the plot above the most important factor in determining wage;1.0395279;-0.71549267;3.2649615;-0.14206827;-4.8534775;-0.44266838;CODE
appears to be the;-4.7026925;-2.4614327;1.8904146;0.035144184;-0.28680146;-1.5545906;-
variable union even if our intuition might tell us that variables;1.2676543;0.28180465;3.3871844;1.1355964;2.810034;-1.2251316;CODE
like experience should have more impact;-1.3097498;-2.1860523;3.4716487;3.6331244;2.2829263;1.7378498;-
looking at the coefficient plot to gauge feature importance can be;3.7987893;-2.7216165;1.6446491;-1.3277682;-1.9195229;1.9750448;CODE
misleading as some of them vary on a small scale while others like age;0.80184686;0.17300911;-0.032384865;1.1599752;-0.7824047;-0.41360804;CODE
varies a lot more several decades;1.3370599;-0.8710091;3.7899601;1.0932382;0.22895119;0.6946579;CODE
this is visible if we compare the standard deviations of different;2.9436243;0.4991438;1.0958171;-0.13526787;-0.20906964;-0.58143353;IRRE
features;1.4263527;-6.2441335;5.031171;1.4146436;3.9154737;-1.3022918;TASK
multiplying the coefficients by the standard deviation of the related;1.9575548;0.5816305;0.54117477;-2.9548016;-0.9605367;1.72772;-
feature would reduce all the coefficients to the same unit of measure;5.296051;0.3865128;0.20848426;-0.14760353;1.8474377;4.848043;TASK
as we will see ref after scaling num this is equivalent to normalize;1.5151772;0.74419475;0.96531844;-2.1490152;-0.25274026;5.091416;CODE
numerical variables to their standard deviation;4.4883986;-0.06371703;-0.53127486;-3.765967;-0.20669356;0.2656404;IRRE
as math y sum coef i times x i;1.2804488;1.060442;2.3686373;-5.4708724;-0.9812675;-1.738354;-
sum coef i times std i times x i std i;1.1787821;0.80035937;1.521777;-5.361692;1.3623252;-3.1718159;CODE
in that way we emphasize that the;-2.4654944;-1.7049792;2.9976828;3.3130333;0.44355944;2.002701;CODE
greater the variance of a feature the larger the weight of the corresponding;2.9442918;-1.0646424;0.82850844;0.67842406;-0.3880168;3.3643405;TASK
coefficient on the output all else being equal;1.9958802;3.0806653;2.1414785;-3.4276419;-1.2628324;-2.6692154;IRRE
now that the coefficients have been scaled we can safely compare them;4.7335596;1.4888003;-1.8820838;1.1040635;-3.308276;1.0033743;IRRE
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
why does the plot above suggest that an increase in age leads to a;-0.8783652;-0.057605255;2.873441;-0.44282275;-5.671307;0.31095037;CODE
decrease in wage why is the ref initial pairplot;1.206542;2.487257;2.038718;-1.0261174;-5.310382;1.0951909;IRRE
marginal dependencies telling the opposite;-1.8425088;0.611658;0.47616592;1.0095719;2.064114;2.1114485;CODE
this difference is the difference between marginal and conditional dependence;-1.6137447;0.9308968;0.8045636;0.8158179;1.7958133;2.076348;CODE
the plot above tells us about dependencies between a specific feature and;-1.1348013;-3.8447692;1.9353209;0.38319367;0.4484929;1.9933715;TASK
the target when all other features remain constant i e conditional;1.0193379;2.3491023;1.9110657;4.3933024;1.5976557;1.2236515;CODE
dependencies an increase of the age will induce a decrease;-1.6184819;0.6220602;2.5596445;2.894309;-0.1394889;0.6911811;CODE
of the wage when all other features remain constant on the contrary an;1.2206426;0.44914478;2.603011;2.5779924;0.67910177;1.0820516;CODE
increase of the experience will induce an increase of the wage when all;-1.0960393;-1.1350504;2.298237;3.488865;0.55767775;1.9230466;-
other features remain constant;0.45390075;-0.9452865;-0.17889538;2.1861815;-0.24853727;3.809352;CODE
also age experience and education are the three variables that most;-1.5053638;-2.2514808;1.2740891;1.4595413;0.90601283;-0.04948242;IRRE
influence the model;1.1842961;-3.0228014;5.852143;5.6965046;-0.13970271;-0.13773286;-
interpreting coefficients being cautious about causality;-1.1708856;1.2303936;-0.75103766;3.950787;-2.4137013;0.26862693;CODE
linear models are a great tool for measuring statistical association but we;5.661134;-3.2363691;1.7726465;1.974634;1.2371404;-0.61340964;META
should be cautious when making statements about causality after all;-2.8511775;0.8988957;1.3711393;6.4093795;-0.001027371;0.0055965334;-
correlation doesn t always imply causation this is particularly difficult in;-0.40153882;2.0965679;0.34408095;3.397963;-1.6722348;-0.9400594;CODE
the social sciences because the variables we observe only function as proxies;-1.1692532;-2.981045;3.2291248;3.3277764;-1.0200992;0.79071105;IRRE
for the underlying causal process;-1.3370067;-1.9533224;4.8535047;5.575387;0.7261468;1.3924159;CODE
in our particular case we can think of the education of an individual as a;-1.3219038;-2.584369;3.2023067;2.328261;1.7405269;-0.5769696;CODE
proxy for their professional aptitude the real variable we re interested in;-1.5997336;-4.610146;0.9499863;2.4182634;0.36946136;-2.2454772;CODE
but can t observe we d certainly like to think that staying in school for;-0.83528566;-0.94758075;1.2187027;3.6966336;-1.8496726;0.31705406;META
longer would increase technical competency but it s also quite possible that;-0.8903637;-3.4221427;1.4663153;4.1492968;-0.12162035;0.63763666;IRRE
causality goes the other way too that is those who are technically;-3.3072271;-2.2466667;0.59795314;4.2426977;0.13213632;1.6766797;IRRE
competent tend to stay in school for longer;-1.1852092;-1.7469199;0.29386854;4.2911057;-0.7983668;-0.3250177;CODE
an employer is unlikely to care which case it is or if it s a mix of both;-2.1076424;1.6925734;-0.5876524;2.1415148;1.9682984;1.1568265;CODE
as long as they remain convinced that a person with more education is better;-0.2867967;-1.2852856;0.47395298;3.6123958;-0.5383414;1.1330498;CODE
suited for the job they will be happy to pay out a higher wage;-0.7496435;-1.8325653;0.32419947;1.6661307;-1.6568241;1.2374955;CODE
this confounding of effects becomes problematic when thinking about some;-2.0639796;-0.1939981;2.0170443;4.551526;-2.1295955;1.4473159;CODE
form of intervention e g government subsidies of university degrees or;-2.1542861;-2.5102155;0.43269888;2.9749045;1.3892856;2.5515766;CODE
promotional material encouraging individuals to take up higher education;-1.8557229;-3.3508694;1.0879855;1.5502667;1.1162621;0.28729612;-
the usefulness of these measures could end up being overstated especially if;3.1589174;0.79142195;-1.2409853;5.7251883;-0.18574247;1.8841523;CODE
the degree of confounding is strong our model predicts a math 0 054699;2.744184;-1.501407;-2.2589257;3.78391;-1.5125432;-2.8272367;-
increase in hourly wage for each year of education the actual causal effect;-1.5456835;-1.0217099;2.5903628;2.6256196;-2.4890463;1.2489469;CODE
might be lower because of this confounding;-0.09860246;2.8159368;-0.40211293;2.0548184;-2.2216117;0.0051749796;CODE
checking the variability of the coefficients;2.9640787;3.2561023;-0.90794295;0.16070594;-2.1194575;-0.39606953;CODE
we can check the coefficient variability through cross validation;4.762145;-0.7719041;-0.7690267;3.6268802;1.6430371;-1.0199177;CODE
it is a form of data perturbation related to;3.939144;-2.123971;1.2358886;-1.552159;-0.6215923;2.0371435;CODE
resampling https en wikipedia org wiki resampling statistics;3.191166;-4.129239;1.9009578;0.60304695;-0.13227803;0.34963053;CODE
if coefficients vary significantly when changing the input dataset;5.9735227;2.7134383;-1.8416015;0.017935384;-2.9472282;0.67671645;CODE
their robustness is not guaranteed and they should probably be interpreted;-0.35726947;0.039586496;-4.385039;5.955448;0.4018663;1.3110523;CODE
with caution;-1.1610647;-0.4087567;3.8400106;3.5798268;-0.47517857;-1.802213;-
the problem of correlated variables;1.9242263;1.0208333;2.0472019;-1.4253987;-0.33390355;0.87223876;IRRE
the age and experience coefficients are affected by strong variability which;1.697634;-0.90797085;0.9579682;1.5551833;-0.08822288;1.6257299;CODE
might be due to the collinearity between the 2 features as age and;0.50075966;0.15040715;-1.2775406;-1.9305962;-2.416028;2.0220206;TASK
experience vary together in the data their effect is difficult to tease;3.715009;-2.1719046;2.4030492;3.5762634;1.0529805;2.0009503;CODE
apart;-0.50829315;-1.7999481;6.522394;-0.09921172;1.7363751;-1.7341183;-
to verify this interpretation we plot the variability of the age and;1.0329399;0.015299122;3.3739383;-0.99783635;-3.0201786;-1.1005234;CODE
experience coefficient;0.58095515;-0.6279576;3.2036989;-0.39199743;1.1070206;-0.025015905;-
covariation;-1.0805321;-0.6303632;2.6751764;1.7436297;1.4242156;1.7189914;CODE
two regions are populated when the experience coefficient is;0.9278089;2.0866241;2.0729687;-0.44234937;1.9518554;3.1528893;-
positive the age one is negative and vice versa;-1.0980849;2.2849886;2.1563551;0.28244355;0.6797006;-1.7148682;-
to go further we remove one of the two features age and check what is the impact;-1.3446119;-1.7432879;0.59715664;2.803286;1.5672712;1.0449373;TASK
on the model stability;2.2141454;-1.6539707;0.37307203;3.2743073;-1.3397315;3.0373504;-
the estimation of the experience coefficient now shows a much reduced;0.7517973;0.004400181;-0.817523;3.1790485;-1.7373278;3.2723866;-
variability experience remains important for all models trained during;1.9196739;-3.3815887;-0.06778037;6.604421;-0.33483848;2.9244723;CODE
cross validation;2.493245;1.2475493;2.397642;1.889912;3.7310712;-3.8565283;-
scaling num;3.9784334;0.455511;2.7548196;-4.731546;-1.5707604;1.1349683;-
preprocessing numerical variables;2.2373002;1.5293179;-0.8181146;-2.5819254;0.67190236;-0.22757503;IRRE
as said above see ref the pipeline we could also choose to scale;2.3112705;-2.618693;2.00164;2.7393293;0.5180423;4.753986;CODE
numerical values before training the model;5.302533;0.6576826;0.14478546;1.9433724;0.91008455;-0.53099555;IRRE
this can be useful when we apply a similar amount of regularization to all of them;4.4081087;-1.7846782;-0.12252707;2.0054638;4.273201;5.0074353;CODE
in the ridge;-0.87105167;-1.919843;4.708171;-0.83291405;-1.6772796;0.732514;CODE
the preprocessor is redefined in order to subtract the mean and scale;1.8090769;2.5584333;-2.1893256;-1.3833206;-4.921566;2.470567;CODE
variables to unit variance;1.0053233;0.9390914;2.0307806;-1.9824888;-0.67178553;1.281891;CODE
the model will stay unchanged;0.60866666;-0.16858752;2.3989208;5.292174;-0.91279167;2.5066266;-
again we check the performance of the computed;4.1580834;2.2782094;-2.0960422;1.9875381;-0.39561608;-1.1369733;CODE
model using the median absolute error;3.4287484;1.982618;0.54197186;1.2807192;-2.6000745;0.62762135;-
for the coefficient analysis scaling is not needed this time because it;2.7509382;0.53726023;-2.1639419;0.56092733;-3.780194;5.4330277;CODE
was performed during the preprocessing step;-3.3754647;-0.8303999;1.6224585;2.9764438;1.5761019;0.17148669;CODE
we now inspect the coefficients across several cross validation folds;3.1937878;-2.4281366;-1.4736961;2.1286683;1.2937869;1.297407;-
the result is quite similar to the non normalized case;1.5553219;2.213769;-2.376693;-1.4100624;2.439964;3.6039827;IRRE
linear models with regularization;6.5707636;-2.6307733;1.1513264;-0.09967816;0.6328973;5.49093;-
in machine learning practice ridge regression is more often used with;4.087802;-5.745432;-1.4290984;2.1855402;-0.8098653;2.6981058;-
non negligible regularization;4.9399824;0.25244054;-2.1908915;0.6233316;-0.019818898;6.050023;-
above we limited this regularization to a very little amount regularization;2.7209365;-0.8039765;-1.6510743;2.2131863;0.6416252;6.766416;CODE
improves the conditioning of the problem and reduces the variance of the;3.3855011;1.4059982;2.249595;5.8156953;1.0399376;1.9776886;CODE
estimates class sklearn linear model ridgecv applies cross validation;2.6756349;-1.9120824;-7.093441;0.4765128;-3.1177127;2.2097728;IRRE
in order to determine which value of the regularization parameter alpha;2.4234822;1.7036142;-2.4321191;-1.4443126;-0.921845;2.698155;IRRE
is best suited for prediction;5.7589555;-4.39992;3.857058;6.717569;0.64984363;-1.4474787;CODE
alphas np logspace 10 10 21 alpha values to be chosen from by cross validation;1.3488934;1.1898749;-3.442317;0.024958644;0.36052105;-0.80567044;IRRE
first we check which value of math alpha has been selected;0.35893995;3.5586846;1.864937;1.0248557;0.7616332;-4.4644403;IRRE
then we check the quality of the predictions;4.12514;-1.0872184;1.9103683;7.887351;-0.41265562;-2.2298846;-
the ability to reproduce the data of the regularized model is similar to;5.9479723;-3.2509615;0.26445585;3.856452;1.3402455;4.103386;-
the one of the non regularized model;3.6519368;-2.1351721;-1.6698251;1.7917153;1.7962489;5.036855;-
the coefficients are significantly different;1.3428257;2.285797;-1.7882316;-2.943901;-4.2280216;-0.18731973;-
age and experience coefficients are both positive but they now have less;-0.1735209;2.0235803;-1.8748969;-0.41923314;-0.76010853;0.65808964;META
influence on the prediction;4.6414375;-3.753914;4.8537145;6.302522;-1.3598603;-0.72321904;-
the regularization reduces the influence of correlated;5.403932;-1.3063912;-1.3162783;1.9916605;-0.29082778;7.606546;-
variables on the model because the weight is shared between the two;1.9599183;1.4707558;2.0121675;0.8540812;0.81931597;2.6306295;IRRE
predictive variables so neither alone would have strong weights;4.305679;-0.5060585;-0.9098826;1.9936913;-0.18982941;1.5606015;CODE
on the other hand the weights obtained with regularization are more;4.2886567;-1.471352;-0.52330804;1.8129488;0.58856785;6.2241216;-
stable see the ref ridge regression user guide section this;2.8198507;-1.9837846;-0.19783401;2.297327;-3.5171995;3.5055494;CODE
increased stability is visible from the plot obtained from data;3.8715904;0.16352178;2.6081703;-1.6098278;-6.5749636;2.3500514;CODE
perturbations in a cross validation this plot can be compared with;4.631825;2.1507404;-0.067295484;1.3813018;-5.791111;-0.777716;IRRE
the ref previous one covariation;-1.5800794;0.9601451;-0.00077689317;3.1089215;2.339424;2.6370013;CODE
linear models with sparse coefficients;5.6012316;-2.6830018;-0.15196565;-1.1634872;-0.22599398;3.8840656;IRRE
another possibility to take into account correlated variables in the dataset;6.413273;-0.6348131;0.7913274;-0.08804147;1.3731481;1.7163825;CODE
is to estimate sparse coefficients in some way we already did it manually;5.887779;-1.5367708;-1.8835915;0.5232658;-1.0180843;4.9000583;IRRE
when we dropped the age column in a previous ridge estimation;3.359362;-0.43628937;-0.95774025;-1.3235427;-3.4210145;3.1449087;-
lasso models see the ref lasso user guide section estimates sparse;4.056579;-4.5867076;-1.6029961;0.94121575;-0.53360116;3.8267078;IRRE
coefficients class sklearn linear model lassocv applies cross;1.5034165;-3.2042415;-5.980299;-1.6827095;-3.6062663;2.1829605;IRRE
validation in order to determine which value of the regularization parameter;3.6998744;3.9595;-2.77755;1.0362676;1.3249526;1.5970268;IRRE
alpha is best suited for the model estimation;4.6083355;-2.310553;1.829779;2.8905585;-0.75661355;2.5533702;CODE
alphas np logspace 10 10 21 alpha values to be chosen from by cross validation;1.3488938;1.1898743;-3.4423184;0.024959195;0.36052027;-0.80567026;IRRE
first we verify which value of math alpha has been selected;-0.023372026;3.7061517;0.58004844;1.3316612;0.62947667;-4.4753327;IRRE
then we check the quality of the predictions;4.12514;-1.0872184;1.9103683;7.887351;-0.41265562;-2.2298846;-
for our dataset again the model is not very predictive;4.0129604;-1.8139762;-0.61594063;4.4838557;-2.3565392;-1.1882709;CODE
a lasso model identifies the correlation between;5.745277;-2.991106;1.0443285;1.3907884;0.61303645;0.8493992;-
age and experience and suppresses one of them for the sake of the prediction;1.3050351;-0.53331316;1.470296;5.3306994;0.04124074;-0.6656511;CODE
it is important to keep in mind that the coefficients that have been;1.630509;0.34341946;0.24627477;-0.64369524;-1.8331859;0.13494377;CODE
dropped may still be related to the outcome by themselves the model;1.3095738;0.6750656;1.4461055;6.9543242;0.3183125;1.063746;TASK
chose to suppress them because they bring little or no additional;-3.3121169;2.6859741;-0.096394785;3.3572934;0.23832174;1.9532146;IRRE
information on top of the other features additionally this selection;1.6186101;-5.614197;4.410651;0.21255177;4.8591986;1.9627844;CODE
is unstable for correlated features and should be interpreted with;2.244178;0.22324112;-2.8267834;1.9629661;-1.6396303;2.757774;CODE
caution;-2.0322669;-0.34094504;2.9546661;4.323725;-0.32461977;-2.286329;-
indeed we can check the variability of the coefficients across folds;3.4420793;-1.5967039;-1.1772233;0.0036792266;-0.94616705;3.1203604;CODE
we observe that the age and experience coefficients are varying a lot;2.6143641;-1.686902;1.0261256;1.0343438;-0.517526;2.147657;CODE
depending of the fold;-0.1908279;1.1713154;5.720461;0.1509786;1.8000616;-0.32763052;TASK
wrong causal interpretation;-3.5423253;1.7897198;0.71733886;2.9508245;-2.1277754;-0.57767355;META
policy makers might want to know the effect of education on wage to assess;-0.7200494;-1.7927366;1.7619117;4.1286845;-1.1325338;-0.27808815;-
whether or not a certain policy designed to entice people to pursue more;-2.6514287;0.012143354;3.425839;4.3643627;0.8192228;2.0193086;CODE
education would make economic sense while machine learning models are great;2.630049;-4.6917157;1.2288014;4.546464;0.38771868;0.9281644;CODE
for measuring statistical associations they are generally unable to infer;3.5283625;-0.6392804;-2.5322192;4.897888;0.33088854;-1.6904697;CODE
causal effects;-1.9816136;-1.0615915;5.0518694;3.987595;-1.0144485;0.08975841;-
it might be tempting to look at the coefficient of education on wage from our;0.98283833;-1.5084828;3.0001833;2.0169885;-1.9451139;-0.25745672;CODE
last model or any model for that matter and conclude that it captures the;2.8009806;0.3314976;2.0176294;5.590996;3.2326455;0.7811654;IRRE
true effect of a change in the standardized education variable on wages;-0.7560735;0.73815644;1.6273775;2.2679029;-2.799466;1.2954544;CODE
unfortunately there are likely unobserved confounding variables that either;0.3156724;1.8911378;-4.4464936;4.9350333;-1.7785491;1.0921713;CODE
inflate or deflate that coefficient a confounding variable is a variable that;0.5730077;3.4021852;-0.5009338;0.10661933;-0.73006266;0.48127398;CODE
causes both education and wage one example of such variable is ability;-1.3429617;-0.078887634;1.1541553;1.3532861;-0.9191684;-1.2477579;IRRE
presumably more able people are more likely to pursue education while at the;-0.9084829;-2.6439304;0.98959357;4.2367077;-0.9015405;0.40718788;CODE
same time being more likely to earn a higher hourly wage at any level of;-0.69646573;-0.8853506;2.8051324;1.6059006;-1.2628727;1.5412469;-
education in this case ability induces a positive omitted variable bias;-0.9450968;-0.16859744;-0.3503254;3.1349235;-0.5030251;-1.1192784;CODE
https en wikipedia org wiki omitted variable bias ovb on the education;-1.2929258;-3.6117833;-1.4636033;1.0607464;0.121881105;0.44123435;CODE
coefficient thereby exaggerating the effect of education on wages;0.86486477;0.24077381;2.230182;1.9169737;-1.7527623;0.63036233;-
see the ref sphx glr auto examples inspection plot causal interpretation py;-1.73264;-1.7159548;-3.1761012;0.90177786;-2.4800637;-0.2050731;CODE
for a simulated case of ability ovb;1.9102436;-2.7724435;2.4817257;0.6436253;2.9591868;0.48488337;CODE
lessons learned;-2.0263567;-4.053886;2.3760922;3.4337988;-1.2570904;-0.61066455;-
coefficients must be scaled to the same unit of measure to retrieve;3.9738762;2.6768622;-2.072892;-1.5529444;-2.5358863;5.301434;TASK
feature importance scaling them with the standard deviation of the;5.7916846;-3.9839804;0.8559094;-0.97609496;0.13022661;4.15905;CODE
feature is a useful proxy;-2.6805208;-5.2207084;2.5957947;5.2278457;2.2182214;3.05057;TASK
coefficients in multivariate linear models represent the dependency;1.804672;-2.5723877;-0.6803545;-1.3334676;-0.09515493;3.7368126;CODE
between a given feature and the target conditional on the other;1.3885692;1.5774474;2.798959;2.9017537;2.381636;0.1753289;TASK
features;1.4263512;-6.244134;5.031172;1.4146427;3.9154727;-1.3022916;TASK
correlated features induce instabilities in the coefficients of linear;3.7723439;-1.673558;-2.6282732;-1.606536;-0.36357275;4.6380696;TASK
models and their effects cannot be well teased apart;0.4615879;-4.3871093;0.5421121;6.1971126;-0.76306635;1.5891993;-
different linear models respond differently to feature correlation and;2.934824;-0.7713324;-1.8774796;0.97182626;-2.3757975;2.834501;TASK
coefficients could significantly vary from one another;2.6308348;2.578077;-0.99154615;-1.5749469;-2.5398867;0.38645527;CODE
inspecting coefficients across the folds of a cross validation loop;4.673888;1.5367129;-1.5896784;1.0815989;-0.12233695;-0.30226207;IRRE
gives an idea of their stability;1.3660812;-2.5207496;3.5565274;1.2426493;-0.41527578;0.8133981;-
interpreting causality is difficult when there are confounding effects if;-1.8642187;1.596209;0.2690834;5.2145996;-2.3375978;0.21418573;CODE
the relationship between two variables is also affected by something;-1.6551554;0.97500426;2.2986817;-0.5112595;-0.99183154;-0.0952733;IRRE
unobserved we should be careful when making conclusions about causality;-0.82283354;-0.1575845;0.5845172;6.7834764;-0.26624757;1.5695537;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
bike sharing dataset preprocessing;2.9888752;-3.3421543;0.858515;-0.2032629;2.986494;1.1918881;IRRE
we will use the bike sharing dataset the goal is to predict the number of bike;4.0996633;-3.3757668;3.0931523;0.47699955;2.9058583;-1.0295836;IRRE
rentals using weather and season data as well as the datetime information;1.2882953;-2.9391081;1.5334711;-0.21549478;1.7268729;0.95853716;IRRE
make an explicit copy to avoid settingwithcopywarning from pandas;0.24982111;-0.5605263;-4.591608;1.8776133;-4.5140343;2.1988258;CODE
we use only a subset of the data to speed up the example;7.934637;-0.71728396;2.4259288;1.7259076;3.3470514;1.7222021;IRRE
the feature weather has a particularity the category heavy rain is a rare;0.3986348;-3.640787;0.7528701;1.6897781;1.9147656;0.46509957;TASK
category;-1.5686338;-5.4703164;5.099676;1.5150148;3.576304;-3.6392312;-
because of this rare category we collapse it into rain;-1.2611022;-2.1463327;2.6726458;2.698108;2.265937;1.0741059;CODE
we now have a closer look at the year feature;-0.04187629;-3.545005;2.9244354;1.731499;-0.5329149;1.6804888;TASK
we see that we have data from two years we use the first year to train the;2.776323;-4.0413594;2.001784;3.5402668;1.8885182;-0.17927693;CODE
model and the second year to test the model;0.8680054;0.32043305;1.3742874;6.4937143;0.842269;-3.5309234;IRRE
we can check the dataset information to see that we have heterogeneous data types we;3.6875882;-2.2546222;-3.3017356;0.017740767;3.6228309;0.43002605;IRRE
have to preprocess the different columns accordingly;2.3926065;1.4030824;2.9636185;-4.592562;2.161414;0.4112266;-
from the previous information we will consider the category columns as nominal;0.56330943;-3.3778083;-0.02451623;-2.1936755;4.003959;-0.22242485;CODE
categorical features in addition we will consider the date and time information as;1.3619728;-5.787295;2.7577672;0.09592837;3.5798862;-0.43650818;TASK
categorical features as well;1.8040801;-6.9146943;2.834841;-0.66442335;3.52869;-0.8493672;TASK
we manually define the columns containing numerical and categorical;4.208474;-1.9472587;-0.8973332;-5.6216817;4.465419;-1.0271693;CODE
features;1.4263512;-6.244134;5.031172;1.4146427;3.9154727;-1.3022916;TASK
before we go into the details regarding the preprocessing of the different machine;-1.8282434;-2.335759;0.8166348;2.4127345;2.9755957;1.8340552;CODE
learning pipelines we will try to get some additional intuition regarding the dataset;4.9377155;-7.8991036;1.6456695;3.6482985;2.5809827;0.7838616;CODE
that will be helpful to understand the model s statistical performance and results of;4.3213787;-2.8419673;0.77213126;5.4519105;0.918214;0.06387077;IRRE
the partial dependence analysis;3.7462158;-2.1355908;0.71589494;2.8099496;2.7622435;2.5157092;CODE
we plot the average number of bike rentals by grouping the data by season and;5.1478662;-1.5618416;4.9996624;-2.8571281;0.32406667;-0.35104042;-
by year;-1.1902373;-1.8526437;4.066861;0.60280013;-0.28204295;-1.5322676;-
decorate the plot;-1.5505778;-0.5786542;7.916429;-2.1332755;-2.7368858;-0.69915867;-
the first striking difference between the train and test set is that the number of;2.250141;3.1557198;1.6916646;2.7311983;2.0590222;-4.6616645;IRRE
bike rentals is higher in the test set for this reason it will not be surprising to;2.034334;1.180079;-2.2381854;4.230416;0.002070938;-2.0515487;CODE
get a machine learning model that underestimates the number of bike rentals we;5.223695;-1.7097329;1.3416841;2.4544468;2.7072222;-0.21348386;IRRE
also observe that the number of bike rentals is lower during the spring season in;0.66948444;-0.37631032;0.4496538;1.533675;0.060410473;0.9188485;-
addition we see that during working days there is a specific pattern around 6 7;-0.7239274;0.32673863;3.2882416;-0.14903224;0.5113074;-2.750422;TASK
am and 5 6 pm with some peaks of bike rentals we can keep in mind these different;1.128471;-1.1552517;2.4996996;-0.042555343;1.0283692;0.85687965;-
insights and use them to understand the partial dependence plot;2.8539467;-2.8809478;2.6773875;1.3452364;-1.8337046;0.9939952;IRRE
preprocessor for machine learning models;4.959648;-6.595116;-0.96127397;3.4324784;3.0294058;0.34043896;CODE
since we later use two different models a;-0.4657969;-1.9474438;1.3264483;4.855355;2.6889894;2.3445048;IRRE
class sklearn neural network mlpregressor and a;3.7905133;-4.3465695;-4.0064793;1.1154205;-0.11944216;-0.27522013;IRRE
class sklearn ensemble histgradientboostingregressor we create two different;3.9191663;-4.450812;-5.072892;1.1732535;1.9992095;1.4884517;IRRE
preprocessors specific for each model;2.0644095;-1.5473201;-1.1512905;2.1162903;4.847752;3.2848134;CODE
preprocessor for the neural network model;3.6700716;-3.8372424;0.5005525;0.9717221;2.1117258;1.5585428;CODE
we will use a class sklearn preprocessing quantiletransformer to scale the;5.9513073;-2.99277;-1.8818246;-2.238078;-2.6055756;1.7880219;CODE
numerical features and encode the categorical features with a;5.2301216;-2.563989;0.3046903;-4.360351;3.324928;-0.6603632;TASK
class sklearn preprocessing onehotencoder;0.33671582;-3.9270623;-4.5918446;-0.71980244;-1.0854653;-0.17116897;IRRE
preprocessor for the gradient boosting model;5.057664;-5.3939614;-0.8796261;1.0134665;2.2997224;2.7395928;CODE
for the gradient boosting model we leave the numerical features as is and only;4.153542;-4.01446;-1.6887649;-0.15754268;1.9369336;3.5054502;CODE
encode the categorical features using a;3.5590546;-2.2088978;0.13799828;-3.90619;3.3599842;-1.7293488;TASK
class sklearn preprocessing ordinalencoder;0.49587816;-3.3772776;-5.491742;-2.6741872;1.3372664;-1.4543167;IRRE
1 way partial dependence with different models;1.9942673;-0.54598814;0.54817945;2.74094;3.4458077;3.9590678;CODE
in this section we will compute 1 way partial dependence with two different;0.14493027;0.7314762;-1.2797838;-0.906887;4.042909;3.1485102;CODE
machine learning models i a multi layer perceptron and ii a;5.6071777;-3.7977514;0.6442087;2.5008414;1.1321595;1.4640136;-
gradient boosting model with these two models we illustrate how to compute and;3.54856;-3.8897316;0.8678516;0.13792987;3.4381688;1.3381718;IRRE
interpret both partial dependence plot pdp for both numerical and categorical;1.4500734;-0.25409183;-1.3468467;-2.2835;-1.6028209;1.2340057;CODE
features and individual conditional expectation ice;3.1324227;-1.711657;0.9255765;1.1715883;3.304556;2.8585546;TASK
multi layer perceptron;4.6145716;-2.40395;1.4407932;-0.14972234;-0.3599631;2.4886632;-
let s fit a class sklearn neural network mlpregressor and compute;5.188024;-2.96048;-3.997757;0.12525599;-0.24611035;-0.09746687;IRRE
single variable partial dependence plots;2.698434;-1.0742648;3.3562927;-2.0758002;-2.225415;2.4213676;CODE
we configured a pipeline using the preprocessor that we created specifically for the;-2.906514;-1.3047708;-1.9708555;0.27300337;0.101224996;3.8334317;CODE
neural network and tuned the neural network size and learning rate to get a reasonable;4.8139157;-3.390756;2.4889467;1.7167547;0.3346671;1.0525963;-
compromise between training time and predictive performance on a test set;5.5517063;-0.7752038;-0.116333134;7.272321;0.7909331;-0.798513;IRRE
importantly this tabular dataset has very different dynamic ranges for its;4.9629183;0.8317864;0.06368648;-2.35841;-0.016505;-0.46647215;CODE
features neural networks tend to be very sensitive to features with varying;4.432756;-2.0601673;-1.6161472;1.5293263;0.01667485;2.1320434;TASK
scales and forgetting to preprocess the numeric feature would lead to a very;4.696154;-0.5918055;0.9440144;-0.37426;-1.6550407;0.049169466;TASK
poor model;0.68420225;-0.7849348;1.5971612;3.1147342;-1.2074482;-0.943592;-
it would be possible to get even higher predictive performance with a larger;4.592334;-2.1734064;1.5279425;3.1877017;1.8481331;2.739878;CODE
neural network but the training would also be significantly more expensive;3.7424824;-3.6792634;3.724602;1.6952263;2.0968876;1.7625611;META
note that it is important to check that the model is accurate enough on a;2.8566864;1.7659597;-1.3108529;3.2818441;-1.634445;0.088618144;CODE
test set before plotting the partial dependence since there would be little;3.2770169;3.7499986;1.1872262;1.5647218;-2.170636;-1.1045728;IRRE
use in explaining the impact of a given feature on the prediction function of;3.4267273;-3.8030188;1.6321675;5.390574;-0.8297955;0.65808326;TASK
a model with poor predictive performance in this regard our mlp model works;5.784641;-1.8289441;0.51509625;6.4014926;2.4548404;1.3151363;CODE
reasonably well;-0.5106615;-1.7734147;3.346331;2.6030605;-1.6546426;-1.9064248;-
we will plot the averaged partial dependence;2.528418;-1.0769961;4.046256;-0.8215956;-2.5832307;2.5785623;CODE
features of interest;1.8547175;-7.005043;5.5927534;1.2737478;3.8176668;-0.2770373;TASK
type of partial dependence plot;2.4241524;-0.8795598;3.8581347;-2.12808;-1.1450188;2.1074069;CODE
information regarding categorical features;1.4235017;-6.497618;1.4539675;-1.5206729;3.5230446;-1.8601451;TASK
gradient boosting;4.7936234;-4.7648635;2.3607268;-0.15444736;2.2859614;0.8769007;-
let s now fit a class sklearn ensemble histgradientboostingregressor and;4.120146;-5.11958;-4.949256;2.2840962;1.759032;1.1259661;IRRE
compute the partial dependence on the same features we also use the;3.5783064;-1.2361524;0.8643647;-1.358276;3.5439813;1.7480576;TASK
specific preprocessor we created for this model;-0.23297438;-0.33382222;-0.015689513;-0.49622145;3.719723;1.294362;CODE
here we used the default hyperparameters for the gradient boosting model;3.6226294;-5.484448;-0.8736473;2.1330626;1.6065478;3.2383974;CODE
without any preprocessing as tree based models are naturally robust to;3.7829912;-4.4964223;-1.1380314;5.0453744;3.0402753;1.9972683;-
monotonic transformations of numerical features;5.9616303;-2.2575586;-0.46572894;-3.9193134;0.62390465;3.298458;TASK
note that on this tabular dataset gradient boosting machines are both;4.574458;-5.6136117;-0.6935629;-0.015530233;2.8648233;1.6077899;TASK
significantly faster to train and more accurate than neural networks it is;4.5930967;-4.984136;1.6581315;4.1585884;0.011015598;-0.31510282;-
also significantly cheaper to tune their hyperparameters the defaults tend;3.743439;-1.8803039;-1.1083016;4.6067286;0.6918707;2.5693688;CODE
to work well while this is not often the case for neural networks;3.7608914;-4.272775;2.741487;2.5073152;0.26494983;1.3213607;CODE
we will plot the partial dependence for some of the numerical and categorical;3.170665;-2.6140842;2.5954487;-1.8142065;0.56837827;0.3295141;CODE
features;1.4263512;-6.244134;5.031172;1.4146427;3.9154727;-1.3022916;TASK
analysis of the plots;2.6896446;-1.1865385;6.257802;-2.4605844;-5.386828;-1.6492258;-
we will first look at the pdps for the numerical features for both models the;4.340828;-4.4363866;-1.3757042;0.9171137;0.96353006;2.7334528;CODE
general trend of the pdp of the temperature is that the number of bike rentals is;0.47874874;-0.785377;0.43571657;-0.50881535;-0.5911599;0.39677936;CODE
increasing with temperature we can make a similar analysis but with the opposite;2.5058823;0.3074802;2.8955634;2.6715536;-1.7515397;0.4242931;META
trend for the humidity features the number of bike rentals is decreasing when the;0.91638374;0.3852594;1.7356598;0.6266259;-1.5888671;0.66657543;CODE
humidity increases finally we see the same trend for the wind speed feature the;0.31590718;-1.3483499;2.3624723;1.324906;-2.7013807;1.7651349;CODE
number of bike rentals is decreasing when the wind speed is increasing for both;0.11462775;1.8910058;0.27176183;-0.12787604;-0.8645147;0.41743714;CODE
models we also observe that class sklearn neural network mlpregressor has much;4.5884933;-6.2367406;-3.3978822;3.8818383;-0.7805806;0.47829774;IRRE
smoother predictions than class sklearn ensemble histgradientboostingregressor;4.976446;-5.557534;-5.114538;2.9620082;-0.56945485;2.1500063;IRRE
now we will look at the partial dependence plots for the categorical features;2.8170617;-4.8908267;2.3170283;0.14607033;0.69650465;1.5087892;CODE
we observe that the spring season is the lowest bar for the season feature with the;0.8631997;-1.3596971;2.2967494;1.7987567;-0.71410686;2.6637235;TASK
weather feature the rain category is the lowest bar regarding the hour feature;0.049351137;-2.4470913;2.8594544;-1.290592;0.72082704;0.39896354;TASK
we see two peaks around the 7 am and 6 pm these findings are in line with the;1.380061;-1.6986192;3.7558677;0.24448773;-2.2750933;0.18682824;CODE
the observations we made earlier on the dataset;5.1782713;-3.9415128;1.5053432;2.7835464;-0.60069805;-0.51135087;IRRE
however it is worth noting that we are creating potential meaningless;-0.93782526;-0.82326066;2.1157777;3.1301877;-0.22198875;0.5652961;-
synthetic samples if features are correlated;5.67117;-0.50449324;-1.6498595;-0.67626065;1.2831302;0.90768796;TASK
ice vs pdp;-0.98510027;-1.4384615;1.0125767;0.021782883;1.20694;1.1956996;-
ice vs pdp;-0.98510027;-1.4384615;1.0125767;0.021782883;1.20694;1.1956996;-
pdp is an average of the marginal effects of the features we are averaging the;3.6123369;-3.7127244;0.89233106;0.5890855;0.6576535;3.6895113;TASK
response of all samples of the provided set thus some effects could be hidden in;4.3198247;3.0825253;-0.519352;2.2377005;-0.92137975;0.37847984;IRRE
this regard it is possible to plot each individual response this representation is;2.6937995;-1.6973734;6.4924846;-1.874231;-0.97408104;-0.22263439;CODE
called the individual effect plot ice in the plot below we plot 50 randomly;0.15040836;-1.2425355;4.3233643;-2.5067227;-3.4318335;0.7221326;IRRE
selected ices for the temperature and humidity features;1.5471612;-1.670511;3.2208483;-2.526864;1.232164;0.7968372;CODE
we see that the ice for the temperature feature gives us some additional information;0.31492198;-4.419068;3.038889;0.7896462;-1.2329696;1.1729538;TASK
some of the ice lines are flat while some others show a decrease of the dependence;0.30508178;0.53793764;1.8780768;-2.3488793;-2.921514;2.822281;CODE
for temperature above 35 degrees celsius we observe a similar pattern for the;1.7588599;0.45900688;3.8259172;-2.2879357;-1.8342052;-0.9359642;CODE
humidity feature some of the ices lines show a sharp decrease when the humidity is;0.24490678;1.0103124;2.565008;-0.8678796;-2.626929;1.8617722;TASK
above 80;-1.7776284;0.791167;4.7398615;-0.434155;-1.0039204;-3.1038373;-
not all ice lines are parallel this indicates that the model finds;0.57812047;-0.12624548;0.77034134;-0.15682131;-1.7616656;1.0943922;IRRE
interactions between features we can repeat the experiment by constraining the;4.2951593;-3.1859124;2.6325831;4.1765766;1.6141251;1.4102042;CODE
gradient boosting model to not use any interactions between features using the;2.1115637;-1.3658061;-1.1726774;0.78264093;1.0868921;3.244668;TASK
parameter interaction cst;-1.849478;1.7397574;0.3551259;1.5652453;0.49747425;1.7091721;IRRE
2d interaction plots;-0.049773607;-2.563698;6.5600376;-4.539763;-4.5748544;0.59727275;CODE
pdps with two features of interest enable us to visualize interactions among them;-0.7733132;-5.88054;4.449198;-0.70340276;0.863651;2.051172;CODE
however ices cannot be plotted in an easy manner and thus interpreted we will show;-0.5701843;-0.9507278;2.7350147;-2.2416162;-4.4603043;0.93215287;IRRE
the representation of available in;-0.14802653;0.47363394;2.3384674;1.3388468;4.5646577;-0.7366791;-
meth sklearn inspection partialdependencedisplay from estimator that is a 2d;3.5321355;0.08032719;-3.5841477;0.099865094;-3.7719634;2.547894;CODE
heatmap;2.1917276;-2.6945589;5.1910563;-2.2959166;-0.839974;0.63460493;-
the two way partial dependence plot shows the dependence of the number of bike rentals;2.2096117;0.021304766;2.791825;-0.8103614;0.7718601;0.8482529;CODE
on joint values of temperature and humidity;2.164818;1.499431;2.7558832;-3.431837;-0.9776376;-0.04677926;IRRE
we clearly see an interaction between the two features for a temperature higher than;1.5798341;-1.1306391;1.0106184;-1.2302843;-2.4529064;-0.11327334;CODE
20 degrees celsius the humidity has an impact on the number of bike rentals;0.3004667;0.49883887;1.553157;-0.8119035;-1.5677414;-0.09154917;-
that seems independent on the temperature;0.16435522;1.7506142;2.345494;0.6901453;-2.721638;-0.8687128;CODE
on the other hand for temperatures lower than 20 degrees celsius both the;-1.8533577;0.76560885;1.1495605;-0.30884778;-1.8817143;-0.113687634;CODE
temperature and humidity continuously impact the number of bike rentals;1.1775665;0.82249236;1.9622301;0.34552133;-0.21331254;0.2804075;-
furthermore the slope of the of the impact ridge of the 20 degrees celsius;-0.62360585;-1.7226169;1.9975363;-1.8973143;-3.844434;0.54896295;-
threshold is very dependent on the humidity level the ridge is steep under;2.4197452;0.9472644;0.5209291;-0.6411777;-3.9498804;2.4962037;CODE
dry conditions but much smoother under wetter conditions above 70 of humidity;0.50406903;2.3951359;1.5706054;0.84514755;-2.5660384;1.874155;META
we now contrast those results with the same plots computed for the model;4.340209;-1.3426619;2.475088;2.457547;-2.664604;2.5942748;IRRE
constrained to learn a prediction function that does not depend on such;5.1905665;-1.3119993;-1.383915;3.7945178;0.36705863;2.3631268;CODE
non linear feature interactions;3.589803;-3.5395067;1.436968;-0.7338632;-1.4002779;1.910123;TASK
the 1d partial dependence plots for the model constrained to not model feature;3.667401;-1.8537006;-0.5701211;0.20206058;-1.292045;4.5285616;CODE
interactions show local spikes for each features individually in particular for;2.548221;-3.35026;-0.35783833;0.3385093;-1.6785991;3.024382;CODE
for the humidity feature those spikes might be reflecting a degraded behavior;1.6450644;0.22422548;0.38463438;1.7167104;-4.480173;2.2813995;TASK
of the model that attempts to somehow compensate for the forbidden interactions;-2.5378833;-0.9191505;0.91976124;4.512652;-0.24125983;1.8830625;CODE
by overfitting particular training points note that the predictive performance;6.419159;-3.5018022;0.38199162;3.2629652;2.066304;0.54730666;CODE
of this model as measured on the test set is significantly worse than that of;4.129367;3.1488516;-2.3376904;5.1346307;-1.9595258;-3.5756388;IRRE
the original unconstrained model;2.7164814;-2.522339;-0.65233237;1.870776;2.0550318;3.8933473;CODE
also note that the number of local spikes visible on those plots is depends on;3.2719195;-2.1584058;2.1390345;-2.016204;-4.173586;2.3397264;TASK
the grid resolution parameter of the pd plot itself;1.87493;0.0050317147;0.054934137;-4.962191;-5.3696976;4.7873063;IRRE
those local spikes result in a noisily gridded 2d pd plot it is quite;3.3633785;-2.0930088;0.21208343;-3.028197;-5.519604;2.6821947;IRRE
challenging to tell whether or not there are no interaction between those;-0.6002511;1.1279688;1.5190175;2.3072953;1.0315909;-4.1661305;CODE
features because of the high frequency oscillations in the humidity feature;2.9459565;-2.0000398;1.7175258;-1.2403548;-1.2306849;2.5205889;TASK
however it can clearly be seen that the simple interaction effect observed when;-2.0509317;-0.3803874;2.359429;2.353745;-2.4764984;1.9490181;CODE
the temperature crosses the 20 degrees boundary is no longer visible for this;-2.829517;3.1113412;1.7183497;-0.36095566;-4.7980785;0.6599419;CODE
model;1.6850569;-3.146167;5.856185;2.3733578;2.0956028;-1.8042274;-
the partial dependence between categorical features will provide a discrete;2.6545846;-2.691652;0.77210295;-1.3298191;5.303719;1.4349267;TASK
representation that can be shown as a heatmap for instance the interaction between;2.454409;-3.314185;3.4730632;-1.8735781;1.2491992;2.8300505;CODE
the season the weather and the target would be as follow;1.0444825;-1.4628193;6.3974366;3.058803;0.57057655;1.058355;IRRE
3d representation;2.7299483;-4.150839;4.509594;-6.556773;1.1066704;1.7223586;-
let s make the same partial dependence plot for the 2 features interaction;0.6136917;-0.48767075;2.515045;-1.3401617;-1.4146824;2.6970115;CODE
this time in 3 dimensions;0.025384305;-1.5719912;5.459839;-4.475265;-0.45784014;0.94766295;CODE
unused but required import for doing 3d projections with matplotlib 3 2;-2.480073;-3.8260553;-3.9122677;-3.6912203;-5.2357655;2.5204852;CODE
import mpl toolkits mplot3d noqa f401;-3.1103742;-3.7681549;-3.7366135;-5.488973;-3.817242;1.7461501;CODE
pretty init view;-2.0454013;-2.3601828;3.2660983;1.1607337;0.21443078;1.8073504;IRRE
plt partial dependence custom values;1.3870292;2.7496893;-2.7664492;-0.6449654;2.2396083;2.2748227;IRRE
custom inspection points;1.150435;1.1291864;1.1094944;0.1178838;3.12577;2.0466452;CODE
none of the examples so far specify which points are evaluated to create the;0.9180023;0.0640978;0.74836;-3.5487585;2.5089948;0.9690998;IRRE
partial dependence plots by default we use percentiles defined by the input dataset;5.031689;-2.1185195;1.4104464;-0.93091637;-1.8488984;3.1884787;CODE
in some cases it can be helpful to specify the exact points where you would like the;-0.07552326;-1.4377563;5.0364275;-1.1733228;2.7905786;2.1126285;CODE
model evaluated for instance if a user wants to test the model behavior on;0.3091005;2.1059096;0.92902535;9.171823;0.96132815;-1.7270232;IRRE
out of distribution data or compare two models that were fit on slightly different;3.8942797;3.048865;0.16773659;4.162229;-1.2753011;0.55812395;IRRE
data the custom values parameter allows the user to pass in the values that they;1.4882357;2.9967272;2.4672756;-1.7564586;2.3191295;0.5935631;IRRE
want the model to be evaluated on this overrides the grid resolution and;1.7594113;2.1423385;-0.29023206;1.3431958;-0.78620374;4.405655;CODE
percentiles parameters let s return to our gradient boosting example above;4.17344;-0.8193117;0.6310528;-2.4117968;-0.8298642;1.0396298;IRRE
but with custom values;-1.5367616;3.3278549;2.2923844;-0.7682384;4.896431;-2.036323;IRRE
we set custom values for temp feature;-0.65806067;0.950169;-0.32836992;0.8473996;0.29225433;1.0751008;IRRE
all other features are evaluated based on the data;4.6066914;-1.0397401;-0.42512986;2.310708;4.0781846;-0.88136965;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data loading and feature engineering;3.3135827;-4.681839;1.0566866;2.3590603;3.815675;1.2510597;TASK
let s use pandas to load a copy of the titanic dataset the following shows;2.3117297;-4.1550617;-0.6692058;-2.2848458;-2.3588736;-1.3931304;CODE
how to apply separate preprocessing on numerical and categorical features;2.9980037;-0.80919784;-2.1530006;-1.154825;2.6770427;0.3922538;TASK
we further include two random variables that are not correlated in any way;-0.16929191;1.7134337;-0.2850719;0.6656253;0.93297607;2.2454162;CODE
with the target variable survived;-0.98935187;1.7812643;2.1676638;3.3407297;-0.84304434;-0.97919655;IRRE
random num is a high cardinality numerical variable as many unique;3.2758372;0.3557506;-1.1242832;-1.653502;3.3254063;0.02231042;IRRE
values as records;3.5185525;3.2451901;3.7886896;-3.0583398;5.9179707;-3.3173313;IRRE
random cat is a low cardinality categorical variable 3 possible;-0.00083443715;0.63189936;-0.16731751;-1.1471817;3.8898118;-2.1351244;IRRE
values;2.3852327;2.8150017;4.596041;-3.805712;2.3660839;-6.126723;IRRE
we define a predictive model based on a random forest therefore we will make;3.3997166;-6.996718;0.48949778;5.31763;4.382521;-0.030710325;CODE
the following preprocessing steps;-2.138236;0.07708839;1.7587855;-1.2252833;3.1019163;-0.6210841;-
use class sklearn preprocessing ordinalencoder to encode the;0.96280706;-2.570244;-4.634906;-4.2637086;0.3421198;-1.7051342;IRRE
categorical features;3.0647922;-4.9467726;3.0004318;-1.7614312;3.929344;-2.221263;TASK
use class sklearn impute simpleimputer to fill missing values for;3.6738517;-0.17443137;-3.8354557;-0.43524477;-1.9897774;-2.1231956;IRRE
numerical features using a mean strategy;8.060519;-1.5732765;2.3085673;-0.9505324;0.7498469;1.6366421;TASK
accuracy of the model;4.3127217;-0.18953498;1.5055784;3.6382208;-1.6627793;-2.9662538;-
before inspecting the feature importances it is important to check that;-1.4607408;-3.08569;-0.6251768;5.126277;0.911112;1.7399995;CODE
the model predictive performance is high enough indeed there would be little;4.6845493;-1.4798434;-0.8534338;6.6688237;0.49641648;1.8463775;CODE
interest in inspecting the important features of a non predictive model;2.7062652;-3.6285985;-0.3896156;5.641155;0.69100845;-0.89623207;CODE
here one can observe that the train accuracy is very high the forest model;3.266952;-4.252892;-0.0043078423;4.667092;-0.3760657;0.22322895;CODE
has enough capacity to completely memorize the training set but it can still;2.1794367;-3.4581063;1.5152241;3.204342;1.6244271;-0.21264978;TASK
generalize well enough to the test set thanks to the built in bagging of;5.2496166;-0.763165;-0.34840804;5.2279034;3.7067275;-2.847197;IRRE
random forests;6.315423;-7.2474236;2.821761;2.309195;3.2108507;-2.3577583;IRRE
it might be possible to trade some accuracy on the training set for a;4.964699;-4.031375;-0.18004447;4.31144;2.371545;0.4039203;CODE
slightly better accuracy on the test set by limiting the capacity of the;6.491312;3.209534;-2.5161712;5.986897;0.061141793;-3.8684266;IRRE
trees for instance by setting min samples leaf 5 or;4.289788;-1.129416;1.0793452;-0.0041413573;5.5848274;0.37513;CODE
min samples leaf 10 so as to limit overfitting while not introducing too;3.0797052;1.7780535;-0.4631273;2.294637;1.7116139;1.106073;CODE
much underfitting;2.2893858;-1.7312009;0.6937615;3.0885286;-0.9465212;-0.21669246;-
however let us keep our high capacity random forest model for now so that we can;1.8021232;-5.63388;-0.056987144;4.6291776;3.4222665;1.3031915;CODE
illustrate some pitfalls about feature importance on variables with many;2.9214408;-2.3250117;1.2947116;0.6372852;1.3882959;0.7656279;CODE
unique values;4.2392697;3.3239224;3.2328136;-3.7954879;5.334161;-3.6728487;IRRE
tree s feature importance from mean decrease in impurity mdi;1.7037277;-0.6085295;-2.703467;0.906603;1.9297501;2.3556013;CODE
the impurity based feature importance ranks the numerical features to be the;3.968271;-2.8952444;-0.93872476;-1.711398;2.0769708;1.8440889;TASK
most important features as a result the non predictive random num;5.0128417;-3.896921;-0.8019163;1.7797221;2.7771764;0.25308347;IRRE
variable is ranked as one of the most important features;2.022879;-1.7865659;1.4661117;0.69831175;2.7424133;-0.19437392;CODE
this problem stems from two limitations of impurity based feature;-0.11264947;1.5689695;-3.9634352;0.0061795893;1.1153045;3.1542053;CODE
importances;-1.2544496;-4.6459875;6.5095162;1.6847134;2.4500782;0.11776742;CODE
impurity based importances are biased towards high cardinality features;3.6896713;-2.538678;-1.5837606;-0.34368354;3.194875;1.8069911;CODE
impurity based importances are computed on training set statistics and;5.78267;-3.0422318;-0.5602086;2.2318757;2.9475985;0.67938554;CODE
therefore do not reflect the ability of feature to be useful to make;-1.9555887;-1.0811076;-0.98111457;4.5016932;1.23394;1.7954667;CODE
predictions that generalize to the test set when the model has enough;5.888838;1.0436463;0.26346934;8.013825;1.3452548;-1.6639456;IRRE
capacity;-0.55867386;-0.8094855;4.803916;0.27669227;1.8751402;-2.9809437;-
the bias towards high cardinality features explains why the random num has;4.0065084;-3.489465;-1.239391;0.58098465;2.1658785;0.1389565;IRRE
a really large importance in comparison with random cat while we would;1.0594387;-3.7528396;2.463504;3.1973267;0.90298176;0.5802185;CODE
expect that both random features have a null importance;0.6965319;1.2506547;-2.6827514;3.028594;1.2341816;1.509908;CODE
the fact that we use training set statistics explains why both the;5.006139;-3.5233586;1.3855606;5.157453;1.4172363;0.80886793;IRRE
random num and random cat features have a non null importance;1.4737868;-0.35360563;-3.4169996;-0.91335684;0.8258829;1.5680636;IRRE
as an alternative the permutation importances of rf are computed on a;3.4804168;-0.29480258;0.18033329;-0.309201;5.2452784;1.2502435;CODE
held out test set this shows that the low cardinality categorical feature;2.1413224;0.45503417;-2.849326;2.8733811;2.4439976;-3.5646493;IRRE
sex and pclass are the most important features indeed permuting the;0.11042848;-4.087184;2.4997232;0.26311934;5.4972353;-0.7450333;CODE
values of these features will lead to the most decrease in accuracy score of the;5.3476624;-2.4759865;-0.53290564;2.9879713;0.7767779;-0.9117252;IRRE
model on the test set;3.4666407;1.5662737;0.57231635;5.1940084;2.4893513;-3.6889234;IRRE
also note that both random features have very low importances close to 0 as;2.217529;-2.7191687;-2.722267;1.1182934;1.4348657;1.7855186;CODE
expected;-3.2850702;0.7571462;4.6494393;1.9062778;-1.262508;-3.4222221;-
it is also possible to compute the permutation importances on the training;5.6045327;-5.1026835;1.5562483;2.32541;5.996883;0.49004465;CODE
set this reveals that random num and random cat get a significantly;2.7786024;0.42680895;0.68465465;1.108944;0.7860251;-2.55097;IRRE
higher importance ranking than when computed on the test set the difference;4.960162;2.9850717;-1.4466368;3.257688;1.4343755;-0.9792013;CODE
between those two plots is a confirmation that the rf model has enough;0.6865201;-0.65450466;1.9233028;1.0812049;-3.0095925;0.81486416;IRRE
capacity to use that random numerical and categorical features to overfit;4.7536173;-2.672778;-0.66763157;2.1459606;3.278425;0.0006095915;IRRE
we can further retry the experiment by limiting the capacity of the trees;-0.15570685;-1.1193609;0.4951741;5.466576;-1.323159;-1.5159508;CODE
to overfit by setting min samples leaf at 20 data points;6.009072;1.996336;0.02982294;-0.5757341;-0.38276866;2.6655467;IRRE
observing the accuracy score on the training and testing set we observe that;5.635969;-0.86321473;-0.70090514;7.0686636;0.72765493;-3.9823694;IRRE
the two metrics are very similar now therefore our model is not overfitting;3.48391;0.2511969;-3.537876;2.6482997;-3.1387327;2.2364802;CODE
anymore we can then check the permutation importances with this new model;2.147122;-1.6218052;0.79592294;3.7835844;4.1941013;0.7446646;CODE
now we can observe that on both sets the random num and random cat;1.2644527;-0.8601584;1.1993169;1.4508468;2.0338962;0.11546041;IRRE
features have a lower importance compared to the overfitting random forest;2.8837883;-5.350637;-1.3701129;3.0951486;1.4589593;1.4180181;CODE
however the conclusions regarding the importance of the other features are;1.4147794;-4.196806;2.9240453;1.5421318;3.1961353;1.9722579;CODE
still valid;-3.6765983;1.7044861;1.3821486;1.6155373;1.3274119;-3.2656603;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
random forest feature importance on breast cancer data;4.387454;-5.396952;-0.32436663;1.8092388;2.3291397;0.85157293;CODE
first we define a function to ease the plotting;1.784538;-1.876929;6.461561;-3.8653748;-4.529255;1.2842318;CODE
labels argument in boxplot is deprecated in matplotlib 3 9 and has been;-2.2487037;-0.7590558;-3.5544822;-3.0256171;-4.407386;0.6941293;OUTD
renamed to tick labels the following code handles this but as a;-3.1722143;0.95861197;2.8837538;-2.513558;1.2847569;0.48509753;META
scikit learn user you probably can write simpler code by using labels;2.3567867;-8.91591;-0.8481662;-3.2366686;-0.65982467;-4.4228673;TASK
matplotlib 3 9 or tick labels matplotlib 3 9;0.6825012;-3.1928797;0.9291529;-6.4008718;-2.6638677;-1.0403394;-
we then train a class sklearn ensemble randomforestclassifier on the;4.263918;-7.088473;-2.0954819;4.114428;3.0392153;-0.643394;IRRE
ref breast cancer dataset and evaluate its accuracy on a test set;5.602166;-0.0055214963;-1.2681661;4.193215;0.5876996;-3.401503;IRRE
next we plot the tree based feature importance and the permutation;4.0540996;-4.658992;3.9904845;-1.7328515;2.5672166;1.0757271;CODE
importance the permutation importance is calculated on the training set to;4.8181825;-3.4869587;2.0943234;1.171947;4.6887684;0.31984502;CODE
show how much the model relies on each feature during training;5.4682617;-1.8002253;1.6424998;4.599072;1.3317052;-0.35564762;TASK
the plot on the left shows the gini importance of the model as the;-0.74884105;-2.9292853;4.6048517;1.598966;-1.9536065;1.6464329;CODE
scikit learn implementation of;2.7412436;-12.291261;-4.055769;-0.041048292;-3.268193;-3.6314826;TASK
class sklearn ensemble randomforestclassifier uses a random subsets of;3.4942224;-4.660278;-5.0118876;2.538118;2.357078;-0.07382225;IRRE
math sqrt n text features features at each split it is able to dilute;3.665458;-0.28534833;0.062064342;-3.1158457;0.0562833;-0.970845;TASK
the dominance of any single correlated feature as a result the individual;2.144025;0.025373442;1.8465904;-0.30333924;1.8170996;1.982885;TASK
feature importance may be distributed more evenly among the correlated;5.1633677;-1.6510692;1.0268139;0.36080277;0.4280783;4.2336197;CODE
features since the features have large cardinality and the classifier is;3.4338908;-4.512691;0.06788259;0.6146526;3.670593;0.295856;TASK
non overfitted we can relatively trust those values;3.0692425;1.6855688;-1.4446417;3.6224456;-0.31253895;-0.6145626;IRRE
the permutation importance on the right plot shows that permuting a feature;2.2741323;-2.2069309;3.7627366;-3.1477473;-0.96430933;1.4272846;CODE
drops the accuracy by at most 0 012 which would suggest that none of the;3.631427;1.4297042;-3.9194615;2.0067992;-1.6288444;-3.0003505;-
features are important this is in contradiction with the high test accuracy;4.1737556;-1.7635124;-3.2579648;4.6374803;0.36819443;-2.2565138;CODE
computed as baseline some feature must be important;4.2530794;-0.095878;-0.8194966;2.4468555;2.5631788;2.1320605;TASK
similarly the change in accuracy score computed on the test set appears to be;3.1428616;1.0877855;-3.8397858;3.3800068;-1.267681;-2.075031;IRRE
driven by chance;-0.025943937;-2.2143424;4.55684;4.3778353;0.032540474;-0.8660351;-
nevertheless one can still compute a meaningful permutation importance in the;2.0736053;-0.6742036;1.7596027;0.53770477;4.6901417;0.59514695;CODE
presence of correlated features as demonstrated in the following section;2.994973;-0.41049182;0.16257897;-0.66189945;1.4343061;2.5104642;TASK
handling multicollinear features;3.5525725;-0.85152143;-0.657589;-0.80785877;1.1561152;3.395574;TASK
when features are collinear permuting one feature has little effect on the;2.6671455;-0.20266075;-0.16980252;-0.5531222;0.82992333;1.5317272;TASK
models performance because it can get the same information from a correlated;5.0814524;-0.7319952;2.2491698;5.295644;2.5794723;3.4270015;CODE
feature note that this is not the case for all predictive models and depends;3.1815305;-2.7369084;-1.7542278;6.5726714;1.705044;4.0242977;CODE
on their underlying implementation;-0.059744302;-5.9247966;1.3997873;2.8940802;3.569751;0.5790413;TASK
one way to handle multicollinear features is by performing hierarchical;3.4262135;-2.6921265;0.72326595;-1.0178925;1.983829;4.346604;CODE
clustering on the spearman rank order correlations picking a threshold and;5.1073403;-1.2532681;0.06445807;-0.28235698;1.3196933;2.7119198;-
keeping a single feature from each cluster first we plot a heatmap of the;5.544488;-1.4278773;2.9791892;-2.2987566;-1.1729023;4.0952134;TASK
correlated features;5.6614466;-3.1520202;2.2846854;-1.9043795;2.3005555;1.9794434;TASK
ensure the correlation matrix is symmetric;2.3083584;1.2007394;-2.6653864;-2.6942432;-2.38256;3.5724914;-
we convert the correlation matrix to a distance matrix before performing;5.934201;-0.65028596;0.8542267;-2.7234468;-1.7322131;4.7513165;CODE
hierarchical clustering using ward s linkage;3.6580338;-1.8699341;2.0471578;-1.2220051;2.6171565;2.7532327;-
next we manually pick a threshold by visual inspection of the dendrogram to;3.238239;-0.88941073;1.5556381;-1.8776873;-0.1620788;1.3523072;CODE
group our features into clusters and choose a feature from each cluster to;4.303392;-3.5060818;2.7166784;-0.57561547;3.273134;2.2842548;TASK
keep select those features from our dataset and train a new random forest;3.0604386;-5.708891;-0.20447586;3.096597;3.446309;0.4561282;CODE
the test accuracy of the new random forest did not change much compared to the;2.2245367;-3.1493819;-3.3287299;6.329453;-0.37421337;-2.4001632;IRRE
random forest trained on the complete dataset;4.4763966;-6.7608476;-0.9069676;4.26527;3.2526858;-0.079145;CODE
we can finally explore the permutation importance of the selected subset of;3.4850218;-2.554966;3.8013532;1.4813695;6.0748305;0.1781601;CODE
features;1.4263512;-6.244134;5.031172;1.4146427;3.9154727;-1.3022916;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
preparing the data;4.653309;0.20347352;4.862508;-2.292187;1.9808731;-4.579979;-
load the covtype dataset which contains 581 012 samples;3.5346003;-0.41605338;-3.7396138;-2.4882784;-0.6571927;-1.5451472;IRRE
with 54 features each distributed among 6 classes the goal of this dataset;4.126713;-5.122598;0.7108273;0.021098677;4.74366;-1.9651833;IRRE
is to predict forest cover type from cartographic variables only;2.4795144;-2.862336;-0.9135564;1.363449;1.7296777;2.0874445;CODE
no remotely sensed data after loading we transform it into a binary;-0.92131597;-0.3831721;-1.8967333;-1.5206312;-1.1794848;1.242201;CODE
classification problem to match the version of the dataset in the;6.3358097;-1.3705935;-0.3461877;0.66019255;4.033429;-2.24567;IRRE
libsvm webpage 2 which was the one used in 1;-4.716825;-5.157312;0.022995288;-0.57687443;1.63882;1.1950074;-
y y 2 1 we will try to separate class 2 from the other 6 classes;-0.9426648;-2.509219;0.14589195;1.304778;4.048006;-1.0669466;CODE
partitioning the data;5.4966507;-0.9842299;4.8699408;-4.11641;3.098885;-0.7872267;-
here we select 5 000 samples for training and 10 000 for testing;4.0625257;-2.0205605;1.3257239;2.5811973;2.974054;-4.4077387;CODE
to actually reproduce the results in the original tensor sketch paper;1.3136835;-3.9629734;-1.4769703;-1.354227;-3.5356085;2.0474153;IRRE
select 100 000 for training;3.3649063;-1.2681782;1.0083597;1.1562052;2.3516133;-2.4452305;CODE
feature normalization;5.1528716;-3.610809;1.9636552;-1.4956919;2.3583272;3.1419177;TASK
now scale features to the range 0 1 to match the format of the dataset in;5.6103554;-0.305947;-0.4595125;-4.219252;-0.9412149;1.8404291;TASK
the libsvm webpage and then normalize to unit length as done in the;0.37546003;-2.0129075;-0.13591127;-3.602621;1.6157017;4.003258;CODE
original tensor sketch paper 1;-1.7810518;-3.965186;-1.6681597;-4.371076;-2.9349678;2.0382297;-
establishing a baseline model;3.100929;-0.9313879;2.830073;4.6760144;2.4789846;0.9987961;-
as a baseline train a linear svm on the original features and print the;4.444764;-4.4009986;2.2845943;-2.0585606;1.8000767;1.6378207;CODE
accuracy we also measure and store accuracies and training times to;5.4352684;-4.152004;2.7065628;5.4020624;2.3346813;-0.5720003;-
plot them later;0.31032383;-1.8239694;7.581502;0.08134428;-3.3604133;-1.4040831;-
establishing the kernel approximation model;5.760249;-3.025162;-0.2896914;0.94484407;-0.8171271;2.5225196;-
then we train linear svms on the features generated by;5.688217;-5.9648433;0.5305521;0.49373895;3.549637;2.0936105;TASK
class polynomialcountsketch with different values for n components;2.3472574;0.7532963;-2.9996989;-3.4750552;4.4685698;1.6596104;IRRE
showing that these kernel feature approximations improve the accuracy;6.9739456;-3.9842737;-1.8159305;1.124829;-0.7609504;2.2716246;TASK
of linear classification in typical application scenarios n components;5.616165;-5.713652;-0.62290263;-0.08792868;6.361825;2.094672;CODE
should be larger than the number of features in the input representation;3.699938;-0.6890401;-1.2797109;-3.111319;1.231671;-0.82617724;CODE
in order to achieve an improvement with respect to linear classification;6.773482;-4.9729476;-0.1382032;1.1924107;4.9190893;1.6456076;TASK
as a rule of thumb the optimum of evaluation score run time cost is;2.4297616;0.24459355;0.2620327;4.228779;2.5891705;-0.69173753;CODE
typically achieved at around n components 10 n features though this;0.66297996;-5.5765367;1.0827107;-0.8127798;4.433352;3.095595;TASK
might depend on the specific dataset being handled note that since the;4.099944;-2.1389863;-1.6961285;3.7830257;1.9768884;1.8679103;CODE
original samples have 54 features the explicit feature map of the;3.8156786;-3.8538847;-0.19301352;-1.5952293;3.5049257;-0.25428453;TASK
polynomial kernel of degree four would have approximately 8 5 million;1.1413025;-2.2983773;0.26840773;-2.9513888;0.9509006;-0.62003493;-
features precisely 54 4 thanks to class polynomialcountsketch we can;1.3931777;-3.607385;-0.90995616;-3.0047116;4.0073247;-3.9203782;TASK
condense most of the discriminative information of that feature space into a;5.1470585;-3.6775777;0.00885924;-0.92819875;4.453704;3.1801953;CODE
much more compact representation while we run the experiment only a single time;3.4162633;-1.5446554;0.91073185;4.536212;-1.019794;1.3930444;CODE
n runs 1 in this example in practice one should repeat the experiment several;1.5323644;1.8840396;1.3080772;2.4585166;1.230546;-4.10748;CODE
times to compensate for the stochastic nature of class polynomialcountsketch;2.0109956;-1.7140672;-2.3798184;1.469761;2.1673005;2.0741198;CODE
establishing the kernelized svm model;4.596306;-5.4772897;-1.1690384;-0.11185104;1.2440661;2.1507888;-
train a kernelized svm to see how well class polynomialcountsketch;4.9110723;-5.394508;-3.0948293;-0.35931462;1.4447702;1.2040461;IRRE
is approximating the performance of the kernel this of course may take;5.47425;-2.293973;-0.7804455;2.2456305;-0.3803886;3.6834414;CODE
some time as the svc class has a relatively poor scalability this is the;2.7979667;-4.523231;-4.0252104;1.3159266;1.4112356;4.2138352;CODE
reason why kernel approximators are so useful;4.6245728;-4.860186;0.42457694;2.1501498;-2.4463413;4.5773697;-
comparing the results;4.198664;3.5831258;4.196686;2.0575678;0.65175337;-8.158082;IRRE
finally plot the results of the different methods against their training;4.6133003;-5.5403595;3.1850019;4.433861;-1.0437777;-1.7481238;CODE
times as we can see the kernelized svm achieves a higher accuracy;5.062674;-5.7570004;-1.065491;1.0452718;-0.9358115;2.7845893;-
but its training time is much larger and most importantly will grow;1.2282332;-1.4796875;2.4540226;3.37572;-0.095080175;1.9128683;CODE
much faster if the number of training samples increases;6.020109;-2.0840867;1.8937372;4.09082;2.629941;-0.10693894;-
references;-2.055842;-4.578016;4.8864408;3.3061564;1.3981156;-2.6630578;CODE
1 pham ninh and rasmus pagh fast and scalable polynomial kernels via;2.5134902;-3.3842838;-2.7764828;-3.335772;1.1619409;3.6202354;-
explicit feature maps kdd 13 2013;0.4814277;-5.0228405;-1.9707234;-1.6305748;3.176195;1.7786723;TASK
https doi org 10 1145 2487575 2487591;-5.2751045;-2.8767922;1.0682365;-0.99038094;-1.4615802;-2.884408;CODE
2 libsvm binary datasets repository;1.1489785;-4.555192;-3.5480487;-2.698076;2.1674466;0.44080782;IRRE
https www csie ntu edu tw cjlin libsvmtools datasets binary html;-1.3307443;-4.806989;-3.3358428;-4.4963894;0.49979907;-2.1586392;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
models robustness to recover the ground truth weights;4.8620043;-0.6654032;-2.67212;4.0334105;0.3519852;2.959144;-
generate synthetic dataset;5.188225;-4.1678243;-0.58644694;-1.7688833;1.610775;-1.9116857;IRRE
we generate a dataset where x and y are linearly linked 10 of the;6.3067074;-1.7826258;3.2454536;-5.3720503;1.5277042;-1.5400183;IRRE
features of x will be used to generate y the other features are not;0.38881138;-1.1455393;-0.1521036;-0.21804675;2.944973;-0.8096633;TASK
useful at predicting y in addition we generate a dataset where n samples;7.941653;-4.238058;2.7110417;1.6881508;0.9806081;-1.0276871;TASK
n features such a setting is challenging for an ols model and leads;3.6906054;-3.2008073;0.8178958;0.7133335;1.6033962;1.4733219;TASK
potentially to arbitrary large weights having a prior on the weights and a;4.321269;-0.003303667;1.243814;3.5095859;4.0561566;5.267452;-
penalty alleviates the problem finally gaussian noise is added;3.649805;-0.50640297;-3.4172823;1.247634;-1.5933421;5.0426393;CODE
fit the regressors;3.3038151;1.253979;2.20034;-3.5449326;-1.6213439;1.7191361;-
we now fit both bayesian models and the ols to later compare the models;2.6323035;-2.5453613;0.23358753;4.303865;-0.5223939;3.1201692;IRRE
coefficients;0.15426266;0.67609924;3.312631;-3.863873;-0.4028686;-2.718493;-
plot the true and estimated coefficients;2.6392238;0.7016954;3.6323035;-3.0761883;-5.9460425;0.23101449;-
now we compare the coefficients of each model with the weights of;4.783149;-0.78616375;0.8370914;2.5914783;0.45572737;1.9958831;IRRE
the true generative model;1.6311452;-1.9781922;2.1618388;4.0365624;3.0699835;1.629261;-
due to the added noise none of the models recover the true weights indeed;4.5128384;-0.31784508;-3.2316363;4.0362134;-2.6385603;3.5003796;TASK
all models always have more than 10 non zero coefficients compared to the ols;1.0921926;1.5278239;-3.698975;-1.4106454;-2.2848384;-0.12340851;IRRE
estimator the coefficients using a bayesian ridge regression are slightly;2.3499162;-1.6267161;-2.658621;-0.29165924;-4.4757705;4.1118646;-
shifted toward zero which stabilises them the ard regression provides a;2.089675;1.8327966;-1.9036912;0.13058849;-3.5388863;3.107606;-
sparser solution some of the non informative coefficients are set exactly to;3.9202087;0.21128963;-5.277695;-1.62701;-0.38533;4.5209537;IRRE
zero while shifting others closer to zero some non informative coefficients;3.1610072;3.4642522;-2.3711395;-4.9227595;-1.2830949;1.8717858;CODE
are still present and retain large values;3.1620286;2.110429;0.87196064;0.68319744;-0.37293145;-0.66171217;IRRE
plot the marginal log likelihood;-0.29877007;-1.4072199;3.267196;-2.751248;-3.5026302;1.0253574;-
indeed both models minimize the log likelihood up to an arbitrary cutoff;2.6136382;-0.09410501;-2.1796358;5.6407695;0.16210185;5.3731713;-
defined by the max iter parameter;-0.29946607;2.891274;-0.9812306;-0.7885998;2.3530498;1.7220328;IRRE
bayesian regressions with polynomial feature expansion;3.9051156;-3.2003734;-0.5928369;0.5019352;0.8719602;2.9970698;TASK
generate synthetic dataset;5.188225;-4.1678243;-0.58644694;-1.7688833;1.610775;-1.9116857;IRRE
we create a target that is a non linear function of the input feature;3.337619;-1.483475;1.6375685;0.7908678;-0.014157186;2.510537;CODE
noise following a standard uniform distribution is added;0.21584064;2.25028;-0.6215211;-0.20507488;-1.7913039;2.4095647;TASK
sort the data to make plotting easier later;5.041098;0.5470986;5.6928844;-4.312301;-4.416404;1.0105317;-
extrapolation;3.404052;1.659605;4.6277366;-1.4836293;-0.64558154;-1.9206165;-
fit the regressors;3.3038151;1.253979;2.20034;-3.5449326;-1.6213439;1.7191361;-
here we try a degree 10 polynomial to potentially overfit though the bayesian;2.8748066;-0.58169585;-0.3591163;1.0776563;1.1206287;0.053410858;CODE
linear models regularize the size of the polynomial coefficients as;4.835048;-0.6569503;-0.9448206;-0.5913278;-0.37165916;5.879377;-
fit intercept true by default for;1.75994;3.3047678;-1.565116;-0.11972004;-3.4229858;3.6783004;CODE
class sklearn linear model ardregression and;3.3542602;-4.1396737;-4.587207;0.37623376;-1.510381;0.5018832;IRRE
class sklearn linear model bayesianridge then;2.733076;-5.0096183;-2.7176125;0.7884424;0.8466831;0.62763333;IRRE
class sklearn preprocessing polynomialfeatures should not introduce an;-0.030101867;-4.6371517;-6.723318;0.21203716;-1.241708;0.11314128;CODE
additional bias feature by setting return std true the bayesian regressors;2.3057346;-0.35048747;-3.576507;0.7832055;0.366093;3.5398126;TASK
return the standard deviation of the posterior distribution for the model;-0.786859;0.8091041;0.06754082;0.38939172;-0.23862728;2.589159;CODE
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
plotting polynomial regressions with std errors of the scores;3.2847927;-0.06985792;-0.53509957;-3.1675153;-3.586569;0.47633177;CODE
the error bars represent one standard deviation of the predicted gaussian;3.0143769;-1.3395106;-1.8361841;-2.4200573;-2.7095332;1.1662382;IRRE
distribution of the query points notice that the ard regression captures the;3.3404438;0.14364998;-0.8663631;1.949441;-0.19683777;2.2145476;CODE
ground truth the best when using the default parameters in both models but;1.4069501;1.8063272;-1.9930768;4.2345185;1.1478424;3.9695454;IRRE
further reducing the lambda init hyperparameter of the bayesian ridge can;1.99211;-2.0949662;-2.40592;0.95829535;-0.50564766;4.173808;IRRE
reduce its bias see example;3.0695508;1.5818161;0.97444785;2.513802;0.31295922;0.94219065;-
ref sphx glr auto examples linear model plot bayesian ridge curvefit py;1.2844303;-3.9629776;-3.0190952;-2.8069782;-5.3487787;3.5536523;-
finally due to the intrinsic limitations of a polynomial regression both;4.1284375;-3.0975726;-1.5773288;1.949222;-1.7536969;1.4486359;CODE
models fail when extrapolating;2.177121;2.2282422;-2.8147955;2.8254454;-2.4154332;0.47428298;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sinusoidal data with noise;5.684338;0.5623302;2.0509999;-2.421689;-1.8742406;0.8074084;-
fit by cubic polynomial;2.0343153;1.59483;0.10317973;-3.8435435;-1.0066043;1.0168688;-
plot the true and predicted curves with log marginal likelihood l;1.7120626;-0.90682894;2.678047;-0.6686082;-4.030356;1.503627;-
bayesian ridge regression with different initial value pairs;2.8494987;0.12373278;-1.1499797;-1.5753595;-1.48354;4.358653;IRRE
init 1 np var y train 1 0 default values;0.4348253;2.025092;-3.0206032;-2.7890425;-1.4270717;0.15283747;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
let s start by loading the dataset and creating some sample weights;7.607806;-3.09664;1.3553883;0.09943943;2.1680865;0.5565369;CODE
normalize the sample weights;5.7823105;1.0870442;1.225712;-1.6932889;0.19684109;2.942512;-
to fit the elastic net using the precompute option together with the sample;2.808242;-0.79310495;0.51314586;-0.15830162;-0.8121347;4.5485625;-
weights we must first center the design matrix and rescale it by the;4.02371;-0.19494186;0.8237801;-3.4633071;-0.85880667;5.7993646;-
normalized weights prior to computing the gram matrix;3.7467453;-2.5231764;-1.6883754;-2.2976706;-0.9238052;5.2799025;-
we can now proceed with fitting we must passed the centered design matrix to;3.2662137;0.38573012;-1.6480604;-2.901333;-1.1767766;6.485457;-
fit otherwise the elastic net estimator will detect that it is uncentered;3.7421234;3.2230399;-1.7392179;0.5197402;-4.1840506;5.856363;IRRE
and discard the gram matrix we passed however if we pass the scaled design;3.9201415;0.5590814;-3.030678;-1.5723344;-0.009007002;6.5130095;-
matrix the preprocessing code will incorrectly rescale it a second time;3.1306212;2.532895;-1.8840384;-3.7460856;-5.3343754;3.3550048;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate toy data;3.3090737;-2.5622265;4.804453;-2.1856937;2.9990218;-3.1775522;-
add four strong outliers to the dataset;5.1247525;0.8856564;0.48913324;-1.0342712;-0.23977125;0.72476244;TASK
fit the huber regressor over a series of epsilon values;3.2741487;2.0707085;-3.081271;-1.2166305;-3.6705484;3.9819646;IRRE
fit a ridge regressor to compare it to huber regressor;2.96217;0.3455867;-1.4429142;-1.2290899;-3.1885135;4.9230046;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate synthetic dataset;5.188225;-4.1678243;-0.58644694;-1.7688833;1.610775;-1.9116857;IRRE
we generate a dataset where the number of samples is lower than the total;7.3393683;1.4786706;1.9845569;-0.36693445;2.3990905;-2.467109;IRRE
number of features this leads to an underdetermined system i e the solution;4.519673;-0.9080074;0.032090507;-2.093449;2.654491;0.38023365;CODE
is not unique and thus we cannot apply an ref ordinary least squares by;3.2175105;0.6805308;-2.768331;-0.71889573;-0.92890215;3.3191385;CODE
itself regularization introduces a penalty term to the objective function;2.1542673;-2.1686444;-2.1970274;2.6872678;0.8239645;7.8795056;CODE
which modifies the optimization problem and can help alleviate the;2.4622009;-1.366827;2.0393822;1.7429904;2.2255723;3.8722377;-
underdetermined nature of the system;1.4242598;0.8721845;0.56604546;-1.2515668;0.8484272;2.7182608;CODE
the target y is a linear combination with alternating signs of sinusoidal;0.96922356;1.2766151;3.406123;-3.1012173;-4.440822;0.7367108;-
signals only the 10 lowest out of the 100 frequencies in x are used to;2.2734287;2.8949864;1.4017725;-3.2582517;-1.0111244;-0.6481542;OUTD
generate y while the rest of the features are not informative this results;4.614925;-0.17057563;0.28454715;-1.1728727;1.3183752;-1.6519302;CODE
in a high dimensional sparse feature space where some degree of;5.000661;-3.4027522;-1.0817701;-3.5937567;2.1847942;3.844887;TASK
l1 penalization is necessary;0.44588196;0.08032184;-1.9127557;3.0908055;2.1825917;4.483218;-
true coef n informative 0 sparsify coef;0.7440101;-1.0443848;-4.3856034;1.629976;2.0661001;-0.18312766;CODE
some of the informative features have close frequencies to induce;4.338216;-4.044948;2.2293925;1.8526987;2.3144276;1.5680997;CODE
anti correlations;1.831814;0.35657805;1.138112;0.37995476;-1.2935019;-0.9034933;-
a random phase is introduced using func numpy random random sample;2.2564409;-1.9378705;-2.1371284;-3.03097;-3.0018384;0.23300685;IRRE
and some gaussian noise implemented by func numpy random normal;3.1876566;-3.9161289;-2.5552666;-1.9830604;-2.5117402;2.6862984;IRRE
is added to both the features and the target;-3.0094323;-4.476811;3.2197158;2.8375664;2.334558;2.2423825;TASK
such sparse noisy and correlated features can be obtained for instance from;6.9968657;-4.4120855;0.6057463;-0.84842306;2.0430176;2.9927185;CODE
sensor nodes monitoring some environmental variables as they typically register;1.4131517;-0.9056321;0.074399345;1.4034084;2.5734127;2.8755393;IRRE
similar values depending on their positions spatial correlations;6.617571;2.1521645;2.8095043;-4.3248563;0.39409766;1.2917066;IRRE
we can visualize the target;1.4722631;-4.003831;7.935652;1.8679668;-0.5291965;0.7350594;-
we split the data into train and test sets for simplicity in practice one;7.6397166;-2.7187064;2.6406517;3.0890374;4.518236;-2.1736422;IRRE
should use a class sklearn model selection timeseriessplit;3.477248;-5.1616654;-3.9776924;3.3394322;0.32522687;0.8078752;CODE
cross validation to estimate the variance of the test score here we set;3.3150108;2.224542;-0.7733597;4.705355;0.038208995;-2.0106966;IRRE
shuffle false as we must not use training data that succeed the testing;5.0702486;2.7704184;-1.725705;5.9571676;2.8059988;-2.1550453;IRRE
data when dealing with data that have a temporal relationship;2.4304013;-0.42804894;4.414752;0.1851269;3.2702734;0.43146956;CODE
in the following we compute the performance of three l1 based models in terms;3.8032374;-1.3640094;-0.86620647;2.4379897;2.6736896;2.0881126;CODE
of the goodness of fit math r 2 score and the fitting time then we make a;5.5420494;0.860738;0.898443;1.852155;-0.91854787;-3.69978;-
plot to compare the sparsity of the estimated coefficients with respect to the;4.9073706;1.2874728;0.85914546;-2.4939766;-5.264598;2.5481265;IRRE
ground truth coefficients and finally we analyze the previous results;3.1177576;-1.2750655;-4.2213845;0.007588509;0.33790147;-0.10172711;CODE
lasso;4.181782;-2.6999912;2.6781456;0.28771806;-0.4959582;1.1440676;-
in this example we demo a class sklearn linear model lasso with a fixed;2.8493052;-2.5330248;-3.0494773;0.9299122;-1.7798716;0.9559609;CODE
value of the regularization parameter alpha in practice the optimal;3.1826265;-0.43316963;-1.3636903;0.945289;-0.596215;5.197455;IRRE
parameter alpha should be selected by passing a;-1.8587923;3.280659;0.3490832;0.77267057;0.66026354;1.3104016;IRRE
class sklearn model selection timeseriessplit cross validation strategy to a;4.6508565;-2.938286;-4.0478725;5.227299;0.9222863;-0.10381217;CODE
class sklearn linear model lassocv to keep the example simple and fast to;4.9883957;-4.6786942;-2.5625374;0.011063102;-2.6242845;1.5529583;IRRE
execute we directly set the optimal value for alpha here;1.782584;3.3425047;1.2142816;-0.06771244;-0.27206352;-0.45083645;IRRE
automatic relevance determination ard;2.9329612;-0.9540282;-0.25620997;2.5093746;4.949376;-0.61823046;-
an ard regression is the bayesian version of the lasso it can produce;2.3689427;-3.6667774;-0.09814792;3.037919;0.51905805;3.3256857;META
interval estimates for all of the parameters including the error variance if;2.262694;2.9896343;-0.46421188;0.90435934;-2.8712332;2.436513;CODE
required it is a suitable option when the signals have gaussian noise see;1.2355363;0.42457724;-0.77858067;-0.10531634;0.3945041;5.5597677;CODE
the example ref sphx glr auto examples linear model plot ard py for a;1.1444728;-2.5646212;-2.2226322;-2.7280838;-4.1115475;2.5025346;CODE
comparison of class sklearn linear model ardregression and;4.3005686;-3.1672575;-4.4931893;2.0838892;-1.5023738;-0.42553675;IRRE
class sklearn linear model bayesianridge regressors;2.645592;-5.0704293;-3.9936965;-0.1922074;-0.85950273;2.1616235;IRRE
elasticnet;0.3933512;-3.555719;1.5724002;0.61604035;0.90968114;2.031841;-
class sklearn linear model elasticnet is a middle ground between;2.5117414;-3.5171657;-4.636691;-0.87307245;-3.5761168;3.242908;IRRE
class sklearn linear model lasso and class sklearn linear model ridge;3.6418624;-5.4446225;-5.0575676;-1.1671877;-2.5127528;2.6642253;IRRE
as it combines a l1 and a l2 penalty the amount of regularization is;2.4784346;0.0034069219;-1.5775076;2.059867;2.5002577;5.4015474;-
controlled by the two hyperparameters l1 ratio and alpha for l1 ratio;2.072213;1.7099794;-0.085910626;-0.15506631;-0.8307892;2.2084801;IRRE
0 the penalty is pure l2 and the model is equivalent to a;0.51163805;1.9541842;-2.0987046;1.397555;0.7576643;0.88138944;-
class sklearn linear model ridge similarly l1 ratio 1 is a pure l1;2.5249157;-2.034994;-4.1551037;-2.679871;-1.4620817;2.2347412;IRRE
penalty and the model is equivalent to a class sklearn linear model lasso;2.8533454;-3.8641293;-3.3372266;2.4715512;-0.84386486;3.359363;IRRE
for 0 l1 ratio 1 the penalty is a combination of l1 and l2;-0.004480513;2.780316;-0.092710055;-0.6676133;0.93941045;0.45684284;CODE
as done before we train the model with fix values for alpha and l1 ratio;3.730858;-0.2806139;-0.09064419;1.1641711;-0.6645084;0.31913096;CODE
to select their optimal value we used an;5.236557;2.6704834;3.3278325;0.032650474;3.3089135;-1.5388404;IRRE
class sklearn linear model elasticnetcv not shown here to keep the;0.57305217;-2.8664753;-4.891447;-1.2027143;-4.788064;2.2874656;IRRE
example simple;-1.4677968;-1.0267029;5.4328613;-0.14058816;1.7472314;-4.0266166;-
plot and analysis of the results;3.7486525;0.50662065;6.640256;-1.9774469;-4.761733;-4.503064;IRRE
in this section we use a heatmap to visualize the sparsity of the true;3.5164545;-2.4787772;3.446873;-0.28859463;-1.0999054;2.1333108;CODE
and estimated coefficients of the respective linear models;3.3747954;-2.262104;1.5567406;1.5122811;-0.29521063;3.3456526;-
in the present example class sklearn linear model elasticnet yields the;3.8677418;-5.0677924;-3.6439412;-1.6781689;-2.0133154;2.6201053;CODE
best score and captures the most of the predictive features yet still fails;4.0277925;-2.1006367;-2.1540463;4.5662293;-0.6394753;-1.2758274;TASK
at finding all the true components notice that both;-0.50174093;0.5314155;0.12572867;0.6152457;2.1231844;-0.9935578;-
class sklearn linear model elasticnet and;3.2688248;-5.5401664;-4.61857;-0.78167313;-1.8184991;2.5574784;IRRE
class sklearn linear model ardregression result in a less sparse model;4.9418416;-3.1893888;-5.9345264;0.8874828;-2.3247442;2.7300005;IRRE
than a class sklearn linear model lasso;5.4518023;-4.6963553;-3.508018;0.8901844;-0.6525995;1.8810741;IRRE
conclusions;-1.6387572;0.64541024;5.2424517;5.0831895;0.45962253;-4.938849;-
class sklearn linear model lasso is known to recover sparse data;4.9475646;-5.6229663;-4.6914015;0.6929361;-2.3741736;2.778159;IRRE
effectively but does not perform well with highly correlated features indeed;4.8145833;-2.2254834;-2.5996988;2.8145561;-0.20904842;1.5309995;CODE
if several correlated features contribute to the target;4.476745;-0.27468812;0.8609911;1.331208;2.6281755;1.7974992;TASK
class sklearn linear model lasso would end up selecting a single one of;4.1451025;-2.5476472;-3.5574784;1.406418;0.59257025;2.5399292;CODE
them in the case of sparse yet non correlated features a;5.459064;-2.1100674;-1.3191836;-0.1667513;2.054565;3.5867977;TASK
class sklearn linear model lasso model would be more suitable;5.6273756;-4.935946;-1.5998023;0.7280328;-0.6620149;1.6721791;IRRE
class sklearn linear model elasticnet introduces some sparsity on the;3.7692113;-4.446139;-5.656713;-0.28609115;-3.609999;3.4611473;CODE
coefficients and shrinks their values to zero thus in the presence of;2.7224462;2.8905437;-0.5653824;-3.620651;-2.462465;1.8482934;IRRE
correlated features that contribute to the target the model is still able to;2.7494671;-1.2621267;0.27766004;3.6125169;0.061943185;3.5832074;TASK
reduce their weights without setting them exactly to zero this results in a;4.886157;4.394317;0.77649796;-0.8490353;-1.5950834;0.3250737;IRRE
less sparse model than a pure class sklearn linear model lasso and may;4.999929;-4.2069497;-3.8163083;1.5556655;-0.5187834;2.682384;IRRE
capture non predictive features as well;3.3697693;-2.079254;-2.0407317;4.0086584;1.4342179;2.2550015;TASK
class sklearn linear model ardregression is better when handling gaussian;4.414966;-2.861738;-5.542818;0.8320646;-2.494035;3.3223858;IRRE
noise but is still unable to handle correlated features and requires a larger;3.4394538;-0.21768637;-2.9407973;1.6212102;-0.15681323;2.996293;TASK
amount of time due to fitting a prior;3.5691452;1.3007319;0.75298226;3.7259068;0.06291;3.8436053;-
references;-2.055842;-4.578016;4.8864408;3.3061564;1.3981156;-2.6630578;CODE
1 doi lasso type recovery of sparse representations for;4.9752464;-3.2132516;-2.2450151;-1.4646472;0.8412766;4.490454;CODE
high dimensional data n meinshausen b yu the annals of statistics;6.015928;-4.618106;1.1606712;-2.542376;1.1231688;1.1756607;-
2009 vol 37 no 1 246 270 10 1214 07 aos582;-2.5227983;0.7603158;0.6412863;-3.2334528;2.3305664;-4.868216;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
comparing the two lasso implementations on dense data;6.227272;-3.7155387;-3.3670814;1.0124533;-0.8250671;3.118764;TASK
we create a linear regression problem that is suitable for the lasso;5.0767283;-3.2222097;0.57689595;1.6662091;-0.11188995;3.530473;IRRE
that is to say with more features than samples we then store the data;4.8924465;-3.6442354;1.2931572;2.458457;4.4249005;2.0011466;TASK
matrix in both dense the usual and sparse format and train a lasso on;5.780694;-3.0735166;-2.3025403;-1.7531714;-0.8943283;4.5238996;IRRE
each we compute the runtime of both and check that they learned the;1.7881166;-2.0428827;-0.77850693;5.044322;1.807776;-3.6816816;CODE
same model by computing the euclidean norm of the difference between the;3.8021505;1.3136017;1.1373837;-1.3075927;-1.8597977;2.1209946;CODE
coefficients they learned because the data is dense we expect better;6.6344013;-3.0046582;-1.942509;1.534594;-2.3497446;-0.14180757;IRRE
runtime with a dense data format;4.4020557;-1.8514323;-1.619181;-2.3509383;1.9705046;-0.01282271;CODE
create a copy of x in sparse format;2.5403693;0.20474532;-1.3843253;-5.2503104;0.71309;2.2087445;IRRE
compare the regression coefficients;2.5786543;2.8289392;0.9046771;0.56985176;-2.6814234;-2.0264163;IRRE
comparing the two lasso implementations on sparse data;5.5415106;-3.2168534;-2.7791088;0.46374664;-0.39619482;3.3611593;TASK
we make the previous problem sparse by replacing all small values with 0;5.8662376;1.5118124;-3.1649182;-3.2762837;-1.8861415;1.867635;IRRE
and run the same comparisons as above because the data is now sparse we;7.161479;1.0424454;-0.41748178;3.786798;-0.64763194;0.5207797;IRRE
expect the implementation that uses the sparse data format to be faster;6.0740986;-2.2336967;-3.7367136;0.64970726;0.61447114;2.2293003;TASK
make a copy of the previous data;1.632879;1.3951737;3.7532506;-0.41796926;0.30502263;0.43827406;-
make xs sparse by replacing the values lower than 2 5 with 0s;3.988262;2.2469032;-0.52935356;-6.0948553;-1.6929111;0.78812695;IRRE
create a copy of xs in sparse format;1.46347;-0.7865121;-1.8669748;-5.135504;0.43221325;2.5745676;IRRE
compute the proportion of non zero coefficient in the data matrix;4.9525375;2.7141538;-0.7870433;-6.25159;-2.318856;-0.12837462;CODE
compare the regression coefficients;2.5786543;2.8289392;0.9046771;0.56985176;-2.6814234;-2.0264163;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we will use the diabetes dataset;4.2297716;-3.6236238;2.3587217;1.6682247;1.6175218;-0.78433144;IRRE
scikit learn provides an estimator called;5.1900883;-7.7200437;-2.1481743;1.928704;-3.4807243;0.2492948;IRRE
class sklearn linear model lassolarsic that uses either akaike s;2.9590418;-5.6802726;-4.3789926;-0.43015987;-0.4911461;2.337682;IRRE
information criterion aic or the bayesian information criterion bic to;2.1663268;-1.4987162;-1.7896364;3.3018756;3.2027757;1.0386504;CODE
select the best model before fitting;5.0445166;0.8910012;1.3463532;2.559969;1.4655924;2.8184454;CODE
this model we will scale the dataset;6.5556455;-4.536225;4.4172487;1.9824396;1.8499663;0.76587033;CODE
in the following we are going to fit two models to compare the values;5.462385;2.9769263;1.718;2.2285712;1.3533797;-1.6253222;IRRE
reported by aic and bic;-1.9291987;-1.7999015;-3.3497298;1.7743901;0.51031816;-1.6763746;-
to be in line with the definition in zht2007 we need to rescale the;-1.0852964;1.5421656;0.52994204;-2.1691272;0.8176688;4.330729;CODE
aic and the bic indeed zou et al are ignoring some constant terms;-0.9587532;0.4702395;-4.5470276;-0.060445335;-1.5121742;1.3724812;CODE
compared to the original definition of aic derived from the maximum;0.9606281;-1.1009046;-1.8960141;0.8764791;0.6477582;2.290286;IRRE
log likelihood of a linear model you can refer to;2.0108979;-0.42025366;2.4882622;1.0564344;0.07641349;1.5990162;CODE
ref mathematical detail section for the user guide lasso lars ic;3.0295389;-4.4308105;-2.2469046;-1.3158342;-1.1983528;2.9245553;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
x x std axis 0 standardize data easier to set the l1 ratio parameter;4.360527;2.8576186;-1.0897406;-6.7733693;-2.5467517;5.0597444;IRRE
compute paths;0.78534776;0.3241666;3.3782332;-3.3941069;0.055241767;-2.6269293;-
eps 5e 3 the smaller it is the longer is the path;-2.7037485;-0.4712672;2.5281663;-3.21344;-0.029258635;1.4771405;IRRE
display results;0.059281107;1.8744851;5.8914366;-0.5908933;-0.20617604;-4.60396;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
in this example we will use the diabetes dataset;5.7412424;-2.5087404;2.6878233;-0.5574174;2.4225094;-0.9397638;IRRE
in addition we add some random features to the original data to;4.767358;-4.8894725;2.1152525;2.4094367;3.7813044;1.2049232;TASK
better illustrate the feature selection performed by the lasso model;4.7355204;-5.4107833;1.2433556;1.3409959;0.42551008;1.735408;CODE
show only a subset of the columns;3.7224648;2.595432;2.7464054;-3.5907218;1.4184284;-1.5782228;IRRE
selecting lasso via an information criterion;5.5936728;-1.7878263;-1.9808664;2.149557;1.9520309;3.7709227;CODE
class sklearn linear model lassolarsic provides a lasso estimator that;4.4188614;-7.277468;-3.2847574;0.8960369;-1.3872998;2.9768481;IRRE
uses the akaike information criterion aic or the bayes information;1.9909892;-1.4005649;-1.5045322;3.1737304;3.6652129;0.8685374;CODE
criterion bic to select the optimal value of the regularization;5.7594166;0.9816017;-3.046549;0.32154453;2.245021;4.4696507;IRRE
parameter alpha;-1.2890209;1.5832393;1.3349392;-1.78582;-0.1264874;-1.1306239;IRRE
before fitting the model we will standardize the data with a;4.545063;0.5188859;0.5766959;0.8635927;1.1332772;2.929907;CODE
class sklearn preprocessing standardscaler in addition we will;2.2871144;-4.8379793;-5.1772075;1.5128702;-0.82050794;-0.17782028;TASK
measure the time to fit and tune the hyperparameter alpha in order to;3.682649;0.40492675;1.5421802;2.6458783;-1.1654037;0.9040334;IRRE
compare with the cross validation strategy;3.9700663;1.9580932;1.8636206;6.4468303;2.4589722;-3.2852652;IRRE
we will first fit a lasso model with the aic criterion;4.2628736;-2.4418766;-1.5927814;3.5030696;-0.3426936;2.2539968;-
we store the aic metric for each value of alpha used during fit;4.5060244;-1.3921297;0.091615334;0.33266908;1.0251718;2.1565962;CODE
now we perform the same analysis using the bic criterion;3.530042;1.562535;-1.9378229;3.46375;2.2415655;0.28816968;CODE
we can check which value of alpha leads to the minimum aic and bic;1.8056259;2.6534607;-2.652765;-0.53276026;0.90047497;-1.6079062;IRRE
finally we can plot the aic and bic values for the different alpha values;2.0437233;-0.8124607;1.9856269;-4.2277746;-3.1709077;-0.35125902;IRRE
the vertical lines in the plot correspond to the alpha chosen for each;0.9201616;0.0729488;3.16694;-5.625261;-4.3854933;-0.1352578;CODE
criterion the selected alpha corresponds to the minimum of the aic or bic;1.5836084;2.0337193;-1.9585963;0.43844253;2.6596491;-0.37838006;CODE
criterion;1.9584426;3.243533;2.1377485;4.09536;3.3799002;-2.920891;-
model selection with an information criterion is very fast it relies on;6.3231344;-1.884722;-1.6385213;5.618906;2.6206613;2.411644;CODE
computing the criterion on the in sample set provided to fit both criteria;5.3592143;4.2229953;-0.3282859;1.4761256;3.6536858;-1.4263769;IRRE
estimate the model generalization error based on the training set error and;6.3903904;-1.326435;-2.9028938;4.3076706;1.5208213;2.6943753;IRRE
penalize this overly optimistic error however this penalty relies on a;0.4897319;4.8198905;-2.8441463;5.6385713;-1.171373;0.18285125;CODE
proper estimation of the degrees of freedom and the noise variance both are;2.8990872;-0.659455;-2.6514711;0.983679;-0.98525065;3.0394628;CODE
derived for large samples asymptotic results and assume the model is;3.8104122;-0.016114762;-2.1356008;4.892067;-1.9705003;2.2075;IRRE
correct i e that the data are actually generated by this model;4.575719;-2.7240174;0.4603033;2.0865254;1.9804032;1.336976;META
these models also tend to break when the problem is badly conditioned more;3.362313;0.6208338;-0.09883053;7.142523;0.7285115;1.1982766;CODE
features than samples it is then required to provide an estimate of the;5.072364;-2.3469617;-0.9149905;3.6964831;3.4605348;1.1972525;TASK
noise variance;1.825798;-0.7795941;0.76644546;0.50578964;-1.5795915;1.2743934;CODE
selecting lasso via cross validation;3.9083629;-1.4105229;-2.6163087;1.2249631;0.86944747;2.5508952;CODE
the lasso estimator can be implemented with different solvers coordinate;4.7704587;-2.8524868;-2.4045236;-0.42816785;-2.2730045;6.185926;TASK
descent and least angle regression they differ with regards to their;2.390361;-1.7114236;-0.5940415;0.5028922;-2.3745751;3.8361266;-
execution speed and sources of numerical errors;2.4103744;-0.22330378;-1.7656723;3.0282812;-1.6388862;-2.9422994;-
in scikit learn two different estimators are available with integrated;2.4857447;-7.441014;-4.760702;1.6381749;-3.1318204;1.5384675;IRRE
cross validation class sklearn linear model lassocv and;3.3574688;-3.9409;-5.0360765;0.3183102;-2.075719;-0.1300682;IRRE
class sklearn linear model lassolarscv that respectively solve the;4.0396237;-5.6069646;-4.242869;-2.0476484;-1.5959209;1.5984521;IRRE
problem with coordinate descent and least angle regression;2.3859107;0.019474247;-2.052929;-1.2606255;-4.502296;3.592011;-
in the remainder of this section we will present both approaches for both;-2.8565671;-1.6385525;2.467152;2.5335553;3.482062;2.765951;CODE
algorithms we will use a 20 fold cross validation strategy;4.18776;-1.5682917;1.6015301;4.6294637;4.722147;-1.2766626;-
lasso via coordinate descent;4.608577;-3.0316305;-1.5117251;-1.680662;-1.3323439;5.4261622;-
let s start by making the hyperparameter tuning using;4.344861;-1.28068;1.0477035;2.348701;1.2923893;-0.2492453;IRRE
class sklearn linear model lassocv;3.6514137;-5.549193;-4.9871364;-1.9052231;-2.9632719;1.2393583;IRRE
lasso via least angle regression;3.9644043;-2.726589;-1.3538442;-0.7313986;-2.1772401;5.6021695;-
let s start by making the hyperparameter tuning using;4.344861;-1.28068;1.0477035;2.348701;1.2923893;-0.2492453;IRRE
class sklearn linear model lassolarscv;3.8414156;-6.3149295;-5.280486;-2.1762824;-2.2355163;1.3800231;IRRE
summary of cross validation approach;3.756318;-0.32877725;0.5823938;4.104333;3.4802272;-1.9051315;-
both algorithms give roughly the same results;4.460271;-0.60989255;-2.433562;0.4156472;-0.32736054;-0.10256417;IRRE
lars computes a solution path only for each kink in the path as a result it;-0.7063759;-2.4280164;-2.9072766;0.029846314;-3.7380607;2.3659391;CODE
is very efficient when there are only of few kinks which is the case if;1.7093672;-1.0738407;2.5099285;1.1843736;0.9315633;0.96134686;CODE
there are few features or samples also it is able to compute the full path;1.8387074;-4.645923;-0.11462874;0.7912698;1.5485516;0.1454879;TASK
without setting any hyperparameter on the opposite coordinate descent;3.280163;0.97678596;-0.9728109;1.0142466;-0.99091905;5.5512266;IRRE
computes the path points on a pre specified grid here we use the default;2.5220542;0.8812818;1.0126559;-3.9990263;-2.8992922;2.5031798;IRRE
thus it is more efficient if the number of grid points is smaller than the;4.663906;1.3484771;2.2918298;-2.3154314;-0.42112494;3.2936306;CODE
number of kinks in the path such a strategy can be interesting if the number;0.73147345;-0.767805;4.2602787;-0.61686796;0.88168645;-2.0031643;CODE
of features is really large and there are enough samples to be selected in;5.565728;-3.1810825;0.07627954;2.2660816;2.637277;0.5128108;TASK
each of the cross validation fold in terms of numerical errors for heavily;4.371458;-0.16746707;-2.2855666;3.2443752;1.4213309;0.32762897;CODE
correlated variables lars will accumulate more errors while the coordinate;2.8594768;1.7159091;-3.4310634;-0.95701414;-4.9219217;3.2493653;CODE
descent algorithm will only sample the path on a grid;3.4317749;1.7076504;-1.6649934;0.8171918;-2.7374518;4.012819;CODE
note how the optimal value of alpha varies for each fold this illustrates;3.3422046;0.8959646;1.3061489;-3.0102477;-0.5860462;1.8487934;CODE
why nested cross validation is a good strategy when trying to evaluate the;2.2368553;2.3324337;0.39441428;5.857467;2.5256376;-0.8144039;CODE
performance of a method for which a parameter is chosen by cross validation;4.063574;1.5082393;-0.49239576;5.3548293;2.1819127;1.4318391;CODE
this choice of parameter may not be optimal for a final evaluation on;1.8167887;5.1564813;-2.6200128;4.3112836;1.0493957;0.64604884;CODE
unseen test set only;2.0343592;4.3038883;-0.62448907;3.9758506;1.1765903;-4.11811;IRRE
conclusion;-1.760038;1.090336;5.187227;3.9331748;0.70637256;-3.3991337;-
in this tutorial we presented two approaches for selecting the best;3.8004427;-3.328294;3.422972;1.8592054;5.4370713;1.0173119;CODE
hyperparameter alpha one strategy finds the optimal value of alpha;2.4181206;1.5025532;0.69802904;2.1521864;-0.08679243;1.4598422;IRRE
by only using the training set and some information criterion and another;5.414237;-3.1354072;1.5478002;3.6341844;4.895504;-0.45872417;IRRE
strategy is based on cross validation;2.299248;0.100368954;3.6769793;6.001625;3.3195438;-0.38151282;CODE
in this example both approaches are working similarly the in sample;2.7988138;3.1693926;1.3584617;2.2275;2.7231107;-0.98618656;CODE
hyperparameter selection even shows its efficacy in terms of computational;5.8840714;-2.9319608;-1.2288948;4.322581;2.1331847;0.8237825;CODE
performance however it can only be used when the number of samples is large;5.1218586;1.1281334;0.26020756;3.2187538;2.7336729;0.57000977;CODE
enough compared to the number of features;3.9109595;-4.746615;2.0210087;1.0974921;2.7584982;-1.4768356;TASK
that s why hyperparameter optimization via cross validation is a safe;3.344164;-0.96300936;-2.098338;5.908973;1.943589;2.4703598;IRRE
strategy it works in different settings;-3.517175;0.77920187;4.4527025;4.6928306;-0.11278986;3.9801292;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
classify small against large digits;4.8823385;-0.1091819;0.2688294;-1.2746929;1.7379098;-3.7287836;IRRE
l1 ratio 0 5 l1 weight in the elastic net regularization;3.5559733;0.5609155;-2.2474494;-2.7613811;-2.0956035;5.036465;CODE
set regularization parameter;2.280594;2.3125975;-1.146418;-0.0697121;0.3795893;6.0607657;IRRE
increase tolerance for short training time;1.6705282;-0.26452348;0.30272335;4.5960555;-0.86287653;1.2496685;IRRE
coef l1 lr contains zeros due to the;-0.01654339;3.3303745;-3.5554364;-2.4998426;-1.7470553;-0.6312103;-
l1 sparsity inducing norm;4.680461;-0.6704486;-3.0198913;-1.9077941;-1.2422495;5.3603454;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset generation;6.227099;-4.6965995;2.8726146;-0.024883118;3.8821828;-2.5538309;IRRE
we generate a synthetic dataset using func sklearn datasets make blobs function;4.736652;-5.6574883;-3.5314515;-2.6982443;-1.7398465;-1.0514091;IRRE
the dataset consists of 1 000 samples from three different classes;6.004566;-2.0036526;-0.069178976;-2.0093875;4.9089346;-2.904286;IRRE
centered around 5 0 0 1 5 and 5 1 after generation we apply a linear;1.5933993;2.0447042;2.4470968;-5.928269;-1.9981072;0.47482866;-
transformation to introduce some correlation between features and make the problem;4.5214615;-1.5051386;1.9012381;-1.401311;1.665452;2.0258982;CODE
more challenging this results in a 2d dataset with three overlapping classes;5.841792;-2.0207877;1.6742249;-3.1898537;2.7685215;-0.66224563;IRRE
suitable for demonstrating the differences between multinomial and one vs rest;1.3793879;-1.4112239;2.9665554;1.2969944;4.197988;-2.5843601;CODE
logistic regression;2.8095508;-1.0302856;3.411831;1.2820225;0.30507645;-3.8180442;-
classifier training;5.4425163;-6.230895;1.8592886;2.111773;4.8729324;-2.6651444;IRRE
we train two different logistic regression classifiers multinomial and one vs rest;3.2612724;-3.6292517;-0.88265795;2.0019274;4.32658;0.24178095;CODE
the multinomial classifier handles all classes simultaneously while the one vs rest;2.0527325;-2.9164288;-0.96742815;1.3734418;4.7251043;0.45753893;CODE
approach trains a binary classifier for each class against all others;4.5238776;-2.578323;-0.5094444;0.8999175;6.695375;-2.1549766;CODE
decision boundaries visualization;2.9013917;-3.3286135;6.5910745;-1.4507562;2.1118538;0.79600036;-
let s visualize the decision boundaries of both models that is provided by the;1.9990382;-2.5205286;4.879526;2.4993205;3.0472429;1.3873022;CODE
method predict of the classifiers;6.376012;-6.036802;-0.20638415;4.6789813;2.5371153;-0.83059096;IRRE
we see that the decision boundaries are different this difference stems from their;-0.51018023;-1.8168795;2.072325;3.41992;2.3368251;2.3194537;CODE
approaches;0.38317597;-3.2738771;7.129842;3.8807297;2.1020591;-2.2581396;-
multinomial logistic regression considers all classes simultaneously during;2.398942;-0.22431494;-2.2844582;1.3362826;4.0217676;0.9490972;IRRE
optimization;4.548215;-0.4810684;4.989825;-1.4967293;0.9694444;0.45591128;-
one vs rest logistic regression fits each class independently against all others;3.1550584;-0.598617;-1.976842;2.35221;3.2986887;1.1712523;CODE
these distinct strategies can lead to varying decision boundaries especially in;2.013025;-1.4414103;3.6628516;4.347739;4.571304;1.8583151;CODE
complex multi class problems;1.3535538;1.1361735;1.2629577;-1.0324873;5.5458884;-0.9996303;IRRE
hyperplanes visualization;1.9716308;-4.5651884;4.831524;-4.5081744;-0.8369343;2.440321;-
we also visualize the hyperplanes that correspond to the line when the probability;2.0270836;-3.0015779;5.1711426;-1.9232512;0.061355;2.7768419;CODE
estimate for a class is of 0 5;2.96021;1.9421327;0.0005112824;0.27119416;0.72860616;-1.8979093;CODE
while the hyperplanes for classes 0 and 2 are quite similar between the two methods;1.3327854;-2.543537;-3.5513928;-1.2749075;1.9464207;2.5112197;CODE
we observe that the hyperplane for class 1 is notably different this difference stems;0.24564843;-2.2699907;-2.5740528;-1.4042593;1.9892771;2.4783506;CODE
from the fundamental approaches of one vs rest and multinomial logistic regression;3.2862926;-2.3777392;1.7711235;2.7908504;3.057347;0.0565895;CODE
for one vs rest logistic regression;1.3187299;-0.8704317;1.5600566;2.7887115;1.5772731;-0.7592181;CODE
each hyperplane is determined independently by considering one class against all;3.4628725;-1.213902;-1.2746686;-1.6965581;4.574982;2.001561;CODE
others;-0.8597164;-3.7788506;5.2788577;1.7256341;0.68676615;-1.885897;-
for class 1 the hyperplane represents the decision boundary that best separates;1.8090963;-2.8838341;0.47790483;-1.2471482;4.495983;2.1796496;CODE
class 1 from the combined classes 0 and 2;-0.41570127;0.112938285;-0.28550756;-1.5702871;5.2803564;-1.157776;CODE
this binary approach can lead to simpler decision boundaries but may not capture;1.2935013;1.5487958;-3.062939;2.5624971;3.563073;-0.27442604;META
complex relationships between all classes simultaneously;1.4041995;-1.298996;2.4470806;-0.32273036;5.6770325;0.8552475;IRRE
there is no possible interpretation of the conditional class probabilities;-1.1231812;-0.28912696;-0.8970875;2.0894086;3.512092;-1.0161761;CODE
for multinomial logistic regression;2.9770572;-2.3772027;1.495993;-0.4638939;3.3562615;-0.6168817;CODE
all hyperplanes are determined simultaneously considering the relationships between;2.6642423;-0.7142636;-0.18893114;-2.3516536;2.373226;3.2611337;-
all classes at once;-0.32681382;-3.7364795;2.575362;3.0157547;5.0298615;-0.6961664;IRRE
the loss minimized by the model is a proper scoring rule which means that the model;3.1121686;-1.5613035;-0.96809524;4.4499288;1.5429766;2.4240596;-
is optimized to estimate the conditional class probabilities that are therefore;3.8117526;-1.5348299;-0.43818232;4.669692;4.439577;2.2878997;CODE
meaningful;-0.58901113;-1.6637177;5.7869835;0.8068214;1.4151796;-1.9160074;-
each hyperplane represents the decision boundary where the probability of one class;2.8943484;-2.8132312;0.9724775;-1.0929619;4.9919996;2.20448;IRRE
becomes higher than the others based on the overall probability distribution;2.1356719;2.0902944;2.5051796;1.1717101;-0.57697636;0.93618023;META
this approach can capture more nuanced relationships between classes potentially;1.7979813;-3.4914682;0.17148261;2.295914;7.0279293;0.18995905;CODE
leading to more accurate classification in multi class problems;5.357189;-3.318526;-1.6469271;3.37964;4.947907;-0.2672458;IRRE
the difference in hyperplanes especially for class 1 highlights how these methods;2.4059417;-3.379453;-2.3109424;-1.0503954;1.9005623;3.1049204;CODE
can produce different decision boundaries despite similar overall accuracy;4.807106;0.5327201;-2.8903997;3.3276353;1.6153008;-0.2146394;-
in practice using multinomial logistic regression is recommended since it minimizes a;2.8954751;-1.9388607;1.063133;2.114771;2.6308815;0.761534;CODE
well formulated loss function leading to better calibrated class probabilities and;5.2225113;-2.9272597;-2.3252342;2.5436893;1.4578738;1.3025873;CODE
thus more interpretable results when it comes to decision boundaries one should;2.6646674;-1.4816877;2.0392609;4.6125216;4.02261;-0.21111365;IRRE
formulate a utility function to transform the class probabilities into a meaningful;2.7959125;-1.8268447;1.251336;1.7004229;4.2558417;-0.0100684315;CODE
quantity for the problem at hand one vs rest allows for different decision boundaries;1.1772553;1.6196892;3.6652877;2.0295522;4.3163767;0.026568964;CODE
but does not allow for fine grained control over the trade off between the classes as;-2.7065778;-2.6012464;-0.90719134;3.9399922;3.1062067;3.649458;CODE
a utility function would;0.6111799;-0.3787081;3.8155406;2.0843391;4.0333004;-0.13833131;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load data;0.93180233;-0.1247594;5.3618517;-0.54225874;0.7679921;0.048613176;TASK
here we remove the third class to make the problem a binary classification;1.1647804;-1.3819196;-2.1899662;-0.8918409;6.2985697;-2.7122045;IRRE
compute regularization path;3.5649185;-0.7374339;-1.1381238;-2.5888863;-0.541467;4.3503103;-
create a pipeline with standardscaler and logisticregression to normalize;2.4929867;0.8663263;-2.9907029;0.77268577;0.28559977;3.9738822;CODE
the data before fitting a linear model in order to speed up convergence and;6.217752;-0.49950263;1.4015387;3.2808986;-1.9148158;3.9865472;CODE
make the coefficients comparable also as a side effect since the data is now;4.5843673;3.1000674;0.44972742;-0.7520026;-3.2781184;3.4334006;-
centered around 0 we don t need to fit an intercept;0.65679544;3.25907;1.1630311;-3.6241498;-5.6362133;2.4925094;CODE
plot regularization path;3.7629263;-1.2667584;2.915886;-3.7697058;-5.094862;5.1215806;-
colorblind friendly palette ibm color blind safe palette;-1.9000103;-1.4534148;-1.5551344;-1.9175028;-0.67947847;1.9592425;CODE
colors 648fff 785ef0 dc267f fe6100;-3.4447973;-1.4170914;0.44251442;-3.6644216;1.0950221;-1.8635958;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate data;3.5066159;-0.7332362;4.43081;-2.3223329;2.8341296;-3.9849672;-
generate some 2d coefficients with sine waves with random frequency and phase;1.7567928;-0.32998896;1.7118126;-4.473311;-2.6559923;1.4600962;IRRE
fit models;5.237897;-3.2392328;2.846709;1.1394173;0.24661694;1.1979944;-
plot support and time series;1.6203159;-3.4577515;5.060562;-0.56724;-5.4256325;1.5166717;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate some random data;4.4217787;-0.4767152;3.467347;-0.34050348;2.171899;-2.4540763;IRRE
threshold coefficients to render them non negative;3.4570625;1.9155322;-0.8184296;-3.2325592;-0.7233335;1.7228858;CODE
add some noise;-1.4457668;-1.5505381;4.398282;1.0434402;-0.40676793;-1.2108043;TASK
split the data in train set and test set;5.806884;1.73485;1.787872;0.59695446;2.4888585;-2.561711;IRRE
fit the non negative least squares;5.4802017;0.5652909;-1.5185791;-3.6876516;-3.8881488;2.3862028;-
fit an ols;1.5388987;-0.38704118;2.2779624;-1.2161083;-0.5488377;0.8674065;-
comparing the regression coefficients between ols and nnls we can observe;2.8052871;0.0014027605;-1.7978929;0.87596136;-2.4312308;0.97766495;-
they are highly correlated the dashed line is the identity relation;-0.5610177;-0.22979327;1.2551343;-3.8342087;0.7513328;0.72054285;-
but the non negative constraint shrinks some to 0;1.3667371;3.2903445;-2.1863866;-2.5582197;-1.1475075;3.3219981;CODE
the non negative least squares inherently yield sparse results;6.0044394;-1.984554;-2.8445513;-0.32703018;-2.4627473;2.9951458;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data loading and preparation;2.7984226;-2.5775115;3.3090281;0.8023811;1.908599;-0.2822312;CODE
load the diabetes dataset for simplicity we only keep a single feature in the data;5.040019;-1.3424567;0.42911488;1.3913943;2.8776417;2.459801;CODE
then we split the data and target into training and test sets;7.1883116;-2.343496;2.3709886;3.6655755;3.4783142;-0.4934919;IRRE
x x 2 use only one feature;-1.5334535;0.8403974;0.2982378;-1.2125138;2.6443512;3.04454;TASK
linear regression model;2.5749838;0.23347346;4.698985;-0.8871506;-1.9504666;-0.8382329;-
we create a linear regression model and fit it on the training data note that by;5.5721188;-4.2620606;2.4005775;1.9220322;1.5693305;0.94736755;TASK
default an intercept is added to the model we can control this behavior by setting;-1.5333781;1.2836399;-0.82233983;2.916818;-2.318918;5.20615;CODE
the fit intercept parameter;3.5195467;1.5567467;0.40429607;-1.7011067;-3.0690887;2.0841246;IRRE
model evaluation;3.667105;-1.065408;3.7214406;5.412883;3.0021594;-2.498694;-
we evaluate the model s performance on the test set using the mean squared error;5.207946;-0.08632272;-1.0881261;6.068591;0.09879708;-2.4575615;IRRE
and the coefficient of determination;3.1754386;-0.6397708;2.7646778;0.9434735;1.8176318;-1.2968355;-
plotting the results;2.7824183;0.35010907;8.162847;-4.9284263;-5.283578;-4.731769;IRRE
finally we visualize the results on the train and test data;5.6101904;-2.4533682;4.089318;2.2839565;0.44895613;-2.5845308;CODE
ols on this single feature subset learns a linear function that minimizes;5.9140177;-2.7193344;-0.7758191;0.044270847;0.13151665;4.4438615;CODE
the mean squared error on the training data we can see how well or poorly;5.47293;-3.2384179;-1.2499033;3.8668551;-2.465943;-1.1242163;-
it generalizes by looking at the r 2 score and mean squared error on the;4.6592007;-0.75372213;-0.44676894;2.7425566;0.030768368;-1.8117284;-
test set in higher dimensions pure ols often overfits especially if the;3.820044;3.019821;-4.3872013;0.5758267;-3.7029898;-0.15376328;IRRE
data is noisy regularization techniques like ridge or lasso can help;7.486055;-2.8406148;-0.9508785;0.14945868;0.33210832;3.4293852;-
reduce that;-1.4392437;1.902385;2.8998108;0.92397255;-1.1376206;-0.2474674;-
ordinary least squares and ridge regression variance;1.0797495;-2.6037242;-0.7456059;-1.2003299;-4.3509235;3.8586962;CODE
next we illustrate the problem of high variance more clearly by using;4.2864027;-0.8255834;1.0355595;1.4756782;0.45527485;0.25440326;CODE
a tiny synthetic dataset we sample only two data points then repeatedly;8.622495;-0.62419313;1.6474981;-0.98693365;0.37686503;-0.7036252;IRRE
add small gaussian noise to them and refit both ols and ridge we plot;4.9555464;-2.050282;0.10656329;-3.2879133;-5.1040382;4.8531547;TASK
each new line to see how much ols can jump around whereas ridge remains;3.1203225;-0.16271134;1.757295;-2.7117798;-3.4451082;1.6713427;CODE
more stable thanks to its penalty term;-0.8405181;0.5941146;2.8486803;3.8709598;-0.4429617;1.3238704;CODE
conclusion;-1.760038;1.090336;5.187227;3.9331748;0.70637256;-3.3991337;-
in the first example we applied ols to a real dataset showing;3.8307116;-1.899986;-0.47327814;-1.1314613;-1.9878423;1.1253717;CODE
how a plain linear model can fit the data by minimizing the squared error;5.879722;-0.51771146;0.055586837;-0.98504025;-2.9293087;3.316476;-
on the training set;1.4760156;-4.4915156;3.5392725;2.5132499;2.7586749;-1.0208386;IRRE
in the second example ols lines varied drastically each time noise;3.1471488;0.92020214;-1.4899503;-0.8089709;-2.8098505;2.395874;CODE
was added reflecting its high variance when data is sparse or noisy by;4.064747;-0.69563484;-2.5672722;2.2688062;-2.079033;2.6663837;CODE
contrast ridge regression introduces a regularization term that shrinks;4.2921515;-2.8829422;-1.0041602;0.5063008;-1.9861165;5.979942;CODE
the coefficients stabilizing predictions;5.1013236;-2.808819;-0.31902903;3.8868413;-2.7984533;2.3486977;-
techniques like class sklearn linear model ridge or;6.486902;-6.9099994;-1.6166098;-0.46192703;-0.6627756;2.4204056;IRRE
class sklearn linear model lasso which applies an l1 penalty are both;2.331714;-2.7822702;-3.9182935;1.0698255;-1.2578229;3.0253778;IRRE
common ways to improve generalization and reduce overfitting a well tuned;5.6021547;-3.3944514;-0.5872285;4.668978;3.1116781;1.4244224;-
ridge or lasso often outperforms pure ols when features are correlated data;5.1055393;-1.574924;-3.7916257;0.09985107;-3.2735512;3.7880793;TASK
is noisy or sample size is small;4.0175514;0.5207594;-0.021571076;3.1156569;-0.63159645;-0.9629025;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate the data;4.332126;-0.83362067;4.90541;-3.0842018;2.5492842;-5.028516;-
y xw;-2.8996716;-1.32718;3.0671217;-2.3501353;-1.0438584;-0.13009764;-
x 0 n nonzero coefs;-0.28000176;2.2123353;-0.34532183;-3.9537635;-0.49279213;-1.5484232;-
distort the clean signal;1.7537687;2.8160565;0.40434948;0.8822683;-2.8507512;3.4265587;TASK
plot the sparse signal;4.6768055;-0.32946506;3.2770412;-4.905976;-5.0373373;2.1912835;IRRE
plot the noise free reconstruction;4.827327;-1.9269916;1.7230288;-3.335762;-4.109204;3.4262595;CODE
plot the noisy reconstruction;5.2283273;-0.987195;3.2176282;-2.3009515;-4.737425;3.1012375;CODE
plot the noisy reconstruction with number of non zeros set by cv;6.933752;0.8999004;-0.8985862;-3.876742;-3.4538877;2.2080815;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the french motor third party liability claims dataset;-0.5124215;-1.3948529;-0.58255816;1.4179801;2.4269013;0.5708253;IRRE
let s load the motor claim dataset from openml;-0.77254105;-0.71713257;-0.3901584;2.0398667;2.9414384;1.6407022;CODE
https www openml org d 41214;-6.092997;-2.6017842;1.1694148;-1.8790966;2.1190841;-1.8318979;CODE
the number of claims claimnb is a positive integer that can be modeled;1.5378394;1.7994709;-0.40613842;1.1109028;4.366708;-2.5768645;CODE
as a poisson distribution it is then assumed to be the number of discrete;-1.345147;1.9165041;2.3454535;-1.0127248;1.5736735;-0.53353065;META
events occurring with a constant rate in a given time interval exposure;0.71886957;1.0670959;4.15794;2.0110602;-0.5117368;0.58640957;CODE
in units of years;0.4413318;-0.55024683;4.2138176;-1.6893476;-0.18412845;-2.1381993;-
here we want to model the frequency y claimnb exposure conditionally;2.9966972;1.6746808;2.2911942;2.4128911;1.7478166;-0.060742944;-
on x via a scaled poisson distribution and use exposure as;0.23491383;1.6687522;3.3766718;-0.13185357;-1.1703743;3.9170523;META
sample weight;4.0873704;1.7719023;2.1019504;1.0490122;0.65234363;-2.1117196;-
the remaining columns can be used to predict the frequency of claim events;4.52703;-1.3766696;2.3047812;2.00078;3.6328022;-1.1288759;OUTD
those columns are very heterogeneous with a mix of categorical and numeric;4.4718447;-1.516606;-0.92243147;-5.27084;1.7265072;-1.6649762;-
variables with different scales possibly very unevenly distributed;4.1095147;3.1274178;0.9996916;-1.0866033;-4.0089917;1.157262;IRRE
in order to fit linear models with those predictors it is therefore;3.365065;-1.145846;-1.2079353;0.74252397;-1.1223683;2.9374566;CODE
necessary to perform standard feature transformations as follows;1.3378713;-2.3615055;-0.71479136;-2.6991153;0.6677777;4.214605;CODE
a constant prediction baseline;6.818474;-3.6238465;0.7960678;4.624083;0.8196368;2.0788202;CODE
it is worth noting that more than 93 of policyholders have zero claims if;-1.9221551;2.0323956;-3.4781997;2.1122768;1.4783566;0.17977923;OUTD
we were to convert this problem into a binary classification task it would;5.240943;-2.0871012;3.6280143;0.30542082;5.086318;-3.9165215;CODE
be significantly imbalanced and even a simplistic model that would only;3.9733465;1.5607473;2.9815278;4.43141;1.3154478;-1.7798016;CODE
predict mean can achieve an accuracy of 93;6.28805;-0.48804018;0.33310983;3.7842884;-2.50151;-2.7322226;-
to evaluate the pertinence of the used metrics we will consider as a;3.2318652;-0.87865585;1.212489;3.1251662;1.0919021;-0.8924786;-
baseline a dummy estimator that constantly predicts the mean frequency of;3.9122503;1.3823276;0.44025996;4.48039;-1.7385075;3.2449245;CODE
the training sample;3.968558;-4.973513;2.749677;3.8935018;3.8412025;-3.4049697;-
let s compute the performance of this constant prediction baseline with 3;4.440828;-0.43655807;-0.86609715;0.044993352;0.875258;-0.7339855;CODE
different regression metrics;3.2352803;-1.2003627;1.2258068;1.0379952;-1.5249388;1.3757172;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we start by defining a function that we intend to approximate and prepare;0.87999535;-1.6420696;3.000673;2.6890125;0.64261466;0.2787269;CODE
plotting it;0.16835505;-0.6505199;8.476472;-5.2349095;-5.527313;-2.8550181;-
extend the test data into the future;2.070566;0.04250638;0.9301054;6.5519576;1.6333604;-3.1778593;CODE
we again plot the underlying splines;1.3106174;-2.3910663;5.250588;-3.038787;-4.2617607;1.4113107;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset generation;6.227099;-4.6965995;2.8726146;-0.024883118;3.8821828;-2.5538309;IRRE
to illustrate the behaviour of quantile regression we will generate two;2.4614484;0.9871907;2.7071712;-0.12933198;-1.2619593;-1.238248;-
synthetic datasets the true generative random processes for both datasets;3.4722936;-4.1102266;-0.8066419;2.9588647;1.7403538;1.8983306;IRRE
will be composed by the same expected value with a linear relationship with a;1.4688928;2.702212;2.696146;0.10735917;1.3605568;0.7517121;IRRE
single feature x;0.22162211;-2.1679952;2.6252;-0.118006974;3.2883155;0.57201976;TASK
we will create two subsequent problems by changing the distribution of the;0.38534278;1.4031434;2.3650918;2.907779;1.0680437;-0.13702832;IRRE
target y while keeping the same expected value;1.4984982;4.2167273;3.590286;1.6601743;-2.0759764;0.03663528;IRRE
in the first case a heteroscedastic normal noise is added;0.028257964;-0.14500435;-1.1083835;0.39992917;-1.2285573;2.8644166;CODE
in the second case an asymmetric pareto noise is added;0.94066346;0.5275594;-1.0539535;1.5879897;1.1066259;3.4770393;CODE
let s first visualize the datasets as well as the distribution of the;5.772784;-4.6556745;4.6475143;-0.884962;-0.007553841;-1.5066634;IRRE
residuals y mean y;0.31229234;2.2341456;3.4389071;-0.5149248;-5.8299394;0.35970086;-
with the heteroscedastic normal distributed target we observe that the;1.4186405;-0.8740864;-0.34749863;1.6112784;-1.8366029;2.4590654;META
variance of the noise is increasing when the value of the feature x is;1.3204771;-0.45362726;-1.4208492;0.4339749;-2.4845579;2.7908688;TASK
increasing;-1.3892055;0.32876757;6.1297436;1.0350363;-0.85351163;-3.6257124;-
with the asymmetric pareto distributed target we observe that the positive;0.9374907;0.4931486;-0.058420725;2.1461387;0.4999031;3.2099175;META
residuals are bounded;0.4484846;2.3140273;1.1042769;1.9654988;-3.7128923;2.1042905;-
these types of noisy targets make the estimation via;4.4916306;-1.6540564;0.5077191;3.2525187;-0.6686608;3.8356922;IRRE
class sklearn linear model linearregression less efficient i e we need;5.676317;-3.5251396;-3.2218187;0.72511184;-1.6468701;1.98832;IRRE
more data to get stable results and in addition large outliers can have a;5.589935;-0.7096357;1.5285902;3.1734433;0.6080017;0.44443363;TASK
huge impact on the fitted coefficients stated otherwise in a setting with;3.5597575;1.6752434;-2.31376;1.1783519;-4.4998484;4.3664;IRRE
constant variance ordinary least squares estimators converge much faster to;4.123757;-0.9828656;-2.0593438;2.1580873;-4.8625298;5.6633983;CODE
the true coefficients with increasing sample size;2.8919709;1.450639;-0.15772782;0.5517753;-0.16086328;0.9926263;-
in this asymmetric setting the median or different quantiles give additional;0.92547673;2.7070944;3.273351;-2.1209977;-0.766948;1.7399203;CODE
insights on top of that median estimation is much more robust to outliers;4.0818114;-1.0080127;0.6011131;2.8265297;-2.4146566;3.6321702;-
and heavy tailed distributions but note that extreme quantiles are estimated;1.8305519;-0.3066911;1.0181925;2.347865;-2.1383054;1.8628691;META
by very few data points 95 quantile are more or less estimated by the 5;3.8145883;2.4525943;-0.7384257;-0.034915667;-2.6840014;-0.8554204;CODE
largest values and thus also a bit sensitive outliers;5.8509808;0.79396844;0.39594406;-1.2552325;-0.81800675;-1.2593062;IRRE
in the remainder of this tutorial we will show how;-2.5690262;-3.807109;2.5397706;-2.1601598;0.4341313;2.9881215;CODE
class sklearn linear model quantileregressor can be used in practice and;4.0581284;-4.3780255;-2.3260026;0.26051402;-0.89070386;1.5196003;IRRE
give the intuition into the properties of the fitted models finally;3.6400287;-2.43143;3.9021134;4.19906;-0.8621218;2.2201235;CODE
we will compare the both class sklearn linear model quantileregressor;3.3517685;-2.6889668;-3.950102;1.808317;-2.547723;0.82278454;IRRE
and class sklearn linear model linearregression;3.9223795;-5.1627116;-4.093202;0.64423275;-0.9253399;0.9289813;IRRE
fitting a quantileregressor;3.616929;2.5548327;-0.25074986;-1.1441783;-2.1754327;2.0465832;-
in this section we want to estimate the conditional median as well as;1.6959877;1.2611146;2.7060058;2.1860192;0.4714802;1.7917119;CODE
a low and high quantile fixed at 5 and 95 respectively thus we will get;1.2554309;3.0685751;2.233591;-0.59930325;-1.3449609;-2.3314884;-
three linear models one for each quantile;2.2734134;0.0959119;2.7061372;-0.8686829;0.47591493;1.2224002;CODE
we will use the quantiles at 5 and 95 to find the outliers in the training;5.2138705;-1.094447;0.70634264;2.270304;-0.6953594;-1.8638817;IRRE
sample beyond the central 90 interval;2.4279547;3.1307442;2.5574946;-0.49854657;-0.79578036;-0.8610317;CODE
now we can plot the three linear models and the distinguished samples that;3.7106926;-3.8526533;2.7138014;-0.6033402;1.1928363;1.457425;-
are within the central 90 interval from samples that are outside this;3.8074431;2.9613538;1.5230346;-1.0717773;-0.63192695;-1.3193594;CODE
interval;-1.8003745;2.6089041;6.329856;-2.2632957;-0.2892649;-4.501036;CODE
since the noise is still normally distributed in particular is symmetric;0.38249806;0.53624785;-1.5847319;-0.5507049;-1.8701932;4.2062263;TASK
the true conditional mean and the true conditional median coincide indeed;-0.37280595;3.4033122;1.1345958;1.670451;-1.3408481;2.4015975;-
we see that the estimated median almost hits the true mean we observe the;2.8032715;1.243571;2.27105;3.9098186;-4.8508153;1.8141142;-
effect of having an increasing noise variance on the 5 and 95 quantiles;0.6810716;0.88841546;1.2023793;1.9178888;-2.0545728;1.1220787;CODE
the slopes of those quantiles are very different and the interval between;1.3643057;2.817643;1.1841093;-3.3624437;-4.070637;0.09809597;CODE
them becomes wider with increasing x;-0.5478288;0.91123605;3.055915;-3.9036279;-2.8921897;2.6769137;-
to get an additional intuition regarding the meaning of the 5 and 95;-0.8691907;-0.8507382;2.6357872;0.53931195;0.8457778;-2.6192176;TASK
quantiles estimators one can count the number of samples above and below the;1.7279992;2.0011227;2.8492577;-0.57845336;-0.21707717;-0.504572;-
predicted quantiles represented by a cross on the above plot considering;2.032799;1.1130128;2.6113129;-1.2955481;-5.2783613;-0.55265236;-
that we have a total of 100 samples;4.6799293;-0.5825499;3.8631384;1.9138587;2.3512542;-3.861895;-
we can repeat the same experiment using the asymmetric pareto distributed;4.058589;0.041449618;2.2745817;4.7176504;1.6433685;1.881689;META
target;-1.7488081;-2.016717;4.768773;1.7985573;-0.7365778;-1.3815873;-
due to the asymmetry of the distribution of the noise we observe that the;1.6001648;-0.29523388;0.7440904;1.6349578;-1.4959395;2.0683336;META
true mean and estimated conditional median are different we also observe;1.1620659;3.6873713;-0.08938507;2.7312908;-3.4193919;3.6640182;-
that each quantile model has different parameters to better fit the desired;3.2374027;0.017564574;2.3419826;0.2877505;2.7731805;2.6130672;IRRE
quantile note that ideally all quantiles would be parallel in this case;1.9194713;2.4670503;2.581622;-2.5065575;0.8633966;0.66188437;CODE
which would become more visible with more data points or less extreme;3.8737347;-0.8405097;4.959751;-1.563572;1.006467;3.5536141;CODE
quantiles e g 10 and 90;1.4287145;2.0400205;3.2304099;-2.271716;-0.39618054;-2.2277713;-
comparing quantileregressor and linearregression;1.7166044;2.5030844;-0.7260199;1.2577412;-2.4946482;1.850022;IRRE
in this section we will linger on the difference regarding the loss functions that;0.94393903;-2.3338463;0.6497766;2.7557917;0.6263142;3.5984898;CODE
class sklearn linear model quantileregressor and;1.924623;-2.343736;-4.071262;-0.05844855;-2.4378839;1.3258142;IRRE
class sklearn linear model linearregression are minimizing;4.1601543;-2.6839116;-5.9908094;0.09510064;-3.9198391;3.2940514;IRRE
indeed class sklearn linear model linearregression is a least squares;3.6297991;-4.234327;-4.838044;0.16191667;-2.7559745;1.880524;IRRE
approach minimizing the mean squared error mse between the training and;5.2818174;-0.8781266;-1.4311444;3.522493;-0.41084892;2.872561;-
predicted targets in contrast;4.100243;-1.934377;2.823033;4.166514;-1.2564813;0.43199348;-
class sklearn linear model quantileregressor with quantile 0 5;1.4676149;-0.3927154;-4.797454;-1.211013;-3.4165065;0.76434946;IRRE
minimizes the mean absolute error mae instead;3.812287;1.0755923;-3.5363233;1.7421236;-3.3148553;4.8940754;-
why does it matter the loss functions specify what exactly the model is aiming;1.5000908;-1.017611;0.0041648685;3.3593369;-0.89295113;3.6040664;CODE
to predict see;2.9936903;-3.0780566;4.8175497;3.753522;-1.3297405;-2.06492;-
ref user guide on the choice of scoring function which scoring function;1.3713042;-1.617151;0.9058237;2.2709103;1.8904938;-2.482245;CODE
in short a model minimizing mse predicts the mean expectation and a model;2.6965334;-1.270721;0.5020828;5.171248;-0.46504745;3.045503;-
minimizing mae predicts the median;4.207651;-0.5794789;0.1727676;3.8717828;-1.9548423;1.8893992;-
let s compute the training errors of such models in terms of mean;4.0708675;-0.9376072;-0.45270318;3.693337;0.003976022;-1.1070445;CODE
squared error and mean absolute error we will use the asymmetric pareto;3.0741951;1.1427501;-0.5557695;1.2824312;-0.9331031;2.8139358;IRRE
distributed target to make it more interesting as mean and median are not;4.0368185;-1.3817558;3.9569926;4.000877;-0.6181131;2.5955553;META
equal;-0.672778;2.152373;4.7423453;0.36144674;1.098367;-5.7088175;-
on the training set we see that mae is lower for;1.9063283;-1.6923673;-1.4554242;3.6208882;0.12502727;0.56367606;IRRE
class sklearn linear model quantileregressor than;1.9611334;-1.3624363;-5.0226307;-0.034459528;-2.5855582;1.7930058;IRRE
class sklearn linear model linearregression in contrast to that mse is;3.0149093;-3.3518744;-4.9722276;1.3239152;-1.8843682;1.9818496;IRRE
lower for class sklearn linear model linearregression than;3.7358239;-2.0877614;-5.2254667;0.16841632;-2.1032138;1.0577775;CODE
class sklearn linear model quantileregressor these results confirms that;3.013305;-2.4609988;-4.924019;0.561019;-2.9174054;0.6946759;IRRE
mae is the loss minimized by class sklearn linear model quantileregressor;3.3276303;-3.2742698;-3.4594343;1.1259625;-1.7873458;2.6293125;IRRE
while mse is the loss minimized;2.4502237;-0.49802575;-0.123994745;3.2486758;0.2269679;3.6279497;CODE
class sklearn linear model linearregression;3.054517;-3.2388875;-4.944976;-0.76814777;-2.5936317;0.45206183;IRRE
we can make a similar evaluation by looking at the test error obtained by;4.0280523;3.6088722;-2.131742;4.1108537;1.8903553;-3.4686453;IRRE
cross validation;2.493245;1.2475493;2.397642;1.889912;3.7310712;-3.8565283;-
we reach similar conclusions on the out of sample evaluation;4.559574;0.8894974;0.65191305;7.079165;3.263769;-1.8534297;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
add outlier data;4.2771983;0.9492155;2.695295;-1.2817978;-0.49159655;0.034765348;TASK
fit line using all data;6.0653734;2.457505;2.152933;-3.5929356;-1.7304401;0.8427706;-
robustly fit linear model with ransac algorithm;6.0855865;-0.45005897;-1.9315404;-0.03577223;-1.0809398;4.0788026;-
predict data of estimated models;4.9886374;-3.1453059;2.4719527;3.54089;-0.3809287;1.7587881;-
compare estimated coefficients;5.0437284;3.6950834;0.03340605;1.8512813;-1.7189455;0.38266042;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
purpose of this example;-1.0687765;0.052461024;5.861767;2.0035715;2.081004;-2.149079;CODE
for the purpose of showing how ridge regularization works we will create a;4.648695;-3.2550814;-0.20851658;-2.0498002;0.0026697859;5.132349;IRRE
non noisy data set then we will train a regularized model on a range of;7.7762647;-1.7151235;0.26223865;3.2056837;2.5135946;2.999164;IRRE
regularization strengths math alpha and plot how the trained;5.817975;-3.3896725;2.5910165;0.19059321;-2.134021;0.98347473;-
coefficients and the mean squared error between those and the original values;2.0793207;2.0997558;0.21213722;-1.22622;-3.9505684;0.4860235;IRRE
behave as functions of the regularization strength;3.555877;-0.9056582;-1.6959885;1.9514393;0.4510656;6.2793612;CODE
creating a non noisy data set;8.063636;-0.18421356;1.4508722;-0.15510663;2.4664283;0.8711723;IRRE
we make a toy data set with 100 samples and 10 features that s suitable to;6.447814;-3.6722262;3.089721;0.75792575;4.8050423;-1.6479803;TASK
detect regression out of the 10 features 8 are informative and contribute to;4.3414693;-2.3441412;0.09609475;2.9240546;1.0030746;-1.5754764;TASK
the regression while the remaining 2 features do not have any effect on the;0.6563412;0.5940307;-0.2093114;1.786855;-0.76657283;1.0433348;CODE
target variable their true coefficients are 0 please note that in this;0.62545;3.8057506;-2.9610462;-2.2880106;-3.043805;-1.8773685;CODE
example the data is non noisy hence we can expect our regression model to;2.813185;0.051830333;0.3268315;2.6682193;-2.1914713;0.7615468;CODE
recover exactly the true coefficients w;2.320369;2.795837;-0.54352605;-2.9296432;-1.5503762;-0.15579753;-
obtain the true coefficients;0.53208345;2.2919521;0.75946265;-2.9625554;-0.9933484;-2.6771493;CODE
training the ridge regressor;4.6950893;-4.5786386;-0.14623478;-0.38395852;-1.7513475;3.9674575;-
we use class sklearn linear model ridge a linear model with l2;4.394979;-5.3341484;-2.382086;-1.6469201;-1.4178157;2.64283;IRRE
regularization we train several models each with a different value for the;5.9455347;-1.9655281;0.4498353;3.042612;5.479755;3.7060974;IRRE
model parameter alpha which is a positive constant that multiplies the;0.03377458;1.5818131;-0.1482476;-0.9378174;-1.578316;0.8864349;IRRE
penalty term controlling the regularization strength for each trained model;5.0637894;-2.037955;-2.0996635;3.4893432;1.4876335;6.3259263;CODE
we then compute the error between the true coefficients w and the;1.8687227;2.2528331;-2.1879823;-1.3783894;-1.9695346;-0.21166368;-
coefficients found by the model clf we store the identified coefficients;3.1999907;-2.3661816;-2.6074555;-0.83510226;0.63012856;2.1493952;-
and the calculated errors for the corresponding coefficients in lists which;5.7541447;-0.64660144;-1.4905118;-1.8037947;-0.005363549;-2.1550887;CODE
makes it convenient for us to plot them;-0.33308145;-3.7723348;5.814472;-0.3256049;-4.4225764;1.5254207;CODE
generate values for alpha that are evenly distributed on a logarithmic scale;3.7885814;1.5234839;1.4499882;-3.4286363;-2.1792328;0.07580294;IRRE
train the model with different regularisation strengths;6.657264;-1.09394;-0.8663588;2.5944316;3.8213122;3.0669208;CODE
plotting trained coefficients and mean squared errors;4.4026103;-2.0694206;0.8399393;-1.2655095;-5.7998085;0.6236728;-
we now plot the 10 different regularized coefficients as a function of the;3.754361;-1.0105519;2.35938;-4.3164754;-2.2348073;2.7636254;CODE
regularization parameter alpha where each color represents a different;3.527138;0.48495755;0.28398383;-2.5515277;1.3471575;4.0907955;IRRE
coefficient;0.32421482;0.7560833;4.558665;-3.0390143;-0.34679845;-2.6751952;-
on the right hand side we plot how the errors of the coefficients from the;0.91386247;-1.1384579;2.040685;-2.378417;-4.7852516;-0.24300252;CODE
estimator change as a function of regularization;2.5385048;-0.6747267;-0.833502;2.454469;-1.6357852;8.189968;CODE
interpreting the plots;0.6153069;-1.2981541;6.3260694;-2.3564212;-5.359004;-1.8202372;CODE
the plot on the left hand side shows how the regularization strength alpha;1.7076845;-2.1323364;0.103531055;-2.291344;-3.7776334;3.3604717;-
affects the ridge regression coefficients smaller values of alpha weak;1.7366683;0.040036064;-2.5365388;-0.39974537;-4.676965;3.6777258;IRRE
regularization allow the coefficients to closely resemble the true;4.641216;-0.7914129;-1.8099502;-0.28480875;0.5994619;6.0388684;CODE
coefficients w used to generate the data set this is because no;4.676103;0.31201094;-0.9333865;-4.2217937;0.0439435;-1.9462692;IRRE
additional noise was added to our artificial data set as alpha increases;4.4248085;-2.9529002;0.620125;1.9051455;-1.1137613;-0.086982;TASK
the coefficients shrink towards zero gradually reducing the impact of the;2.1209426;0.56813043;-1.3285614;-1.5203294;-4.8110943;3.3742747;CODE
features that were formerly more significant;-0.4166007;-4.572664;1.8827242;1.9758539;0.911088;2.1992478;TASK
the right hand side plot shows the mean squared error mse between the;0.74179316;0.57106715;-0.16374779;-1.7504075;-6.7297344;-0.014154611;-
coefficients found by the model and the true coefficients w it provides a;1.2067859;-0.41057;-0.093534596;0.2332316;-0.08477042;-0.58971786;-
measure that relates to how exact our ridge model is in comparison to the true;3.5873358;-1.0104527;0.09830313;1.9520743;-1.4106578;3.294065;IRRE
generative model a low error means that it found coefficients closer to the;2.2060678;1.1379642;-2.5238729;1.7075924;-0.81760514;2.1827025;CODE
ones of the true generative model in this case since our toy data set was;2.9850392;-1.8131592;0.83161235;3.1585083;3.6123104;0.6404316;CODE
non noisy we can see that the least regularized model retrieves coefficients;5.293334;-1.8419437;-3.4775038;2.7850819;-1.0215299;5.040706;-
closest to the true coefficients w error is close to 0;2.5151455;3.7814586;-4.430699;-1.7194031;-4.6720786;-0.18561114;CODE
when alpha is small the model captures the intricate details of the;1.8041464;-3.5592372;4.814135;2.2279909;0.012012069;0.5582831;CODE
training data whether those were caused by noise or by actual information as;6.06122;-2.6112235;-0.36333892;4.606073;2.084059;-0.8266695;CODE
alpha increases the highest coefficients shrink more rapidly rendering;0.8347228;-0.16632228;0.27892804;-2.3382635;-4.4533834;2.942562;CODE
their corresponding features less influential in the training process this;4.2475853;-5.5555024;0.6992015;4.488821;3.1971827;1.3329291;CODE
can enhance a model s ability to generalize to unseen data if there was a lot;5.69606;-2.1745627;2.4574344;4.857449;2.6566374;3.2138062;CODE
of noise to capture but it also poses the risk of losing performance if the;1.3133756;-1.2071326;2.7407148;4.616285;0.8284287;2.576353;IRRE
regularization becomes too strong compared to the amount of noise the data;6.966109;-0.7771723;-2.7756832;0.96296936;-1.434119;5.4169393;IRRE
contained as in this example;-2.2926068;1.850662;2.9629276;-0.42832875;4.3028336;-1.6414121;CODE
in real world scenarios where data typically includes noise selecting an;5.4164276;0.07177798;0.6797368;3.5685756;3.5521905;1.0095901;CODE
appropriate alpha value becomes crucial in striking a balance between an;1.1137267;2.4798577;0.5972092;1.2694212;-1.4806218;-1.941723;IRRE
overfitting and an underfitting model;4.1461253;-1.8665175;0.50352114;4.844401;1.3324848;-0.22944853;-
here we saw that class sklearn linear model ridge adds a penalty to the;4.456151;-4.5948815;-4.3230515;1.511746;-2.6370914;4.7736363;TASK
coefficients to fight overfitting another problem that occurs is linked to;2.704752;1.4699708;-1.3043737;2.2870584;-0.30505145;2.2464073;-
the presence of outliers in the training dataset an outlier is a data point;5.4639325;-0.22957772;-1.0473907;1.2534626;-0.14508814;0.69852185;CODE
that differs significantly from other observations concretely these outliers;4.39447;0.046589654;-0.6931634;1.479098;-1.9652703;-0.6890118;CODE
impact the left hand side term of the loss function that we showed earlier;0.9734216;-0.22933485;0.112705104;2.618529;-3.0072882;2.691462;CODE
some other linear models are formulated to be robust to outliers such as the;4.8972855;-1.2979059;-0.4019304;2.0018718;-0.9238376;2.8608813;CODE
class sklearn linear model huberregressor you can learn more about it in;3.1346424;-6.4046474;-2.7049763;-0.3338147;-1.7101557;0.8057265;IRRE
the ref sphx glr auto examples linear model plot huber vs ridge py example;1.2353446;-4.149116;-2.2931316;-2.100297;-5.2104263;5.1072125;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
x is the 10x10 hilbert matrix;-0.1461797;0.8066872;0.46665585;-6.5215387;-0.58387905;1.1760002;-
compute paths;0.78534687;0.3241666;3.378234;-3.394107;0.05524296;-2.6269283;-
display results;0.059281107;1.8744851;5.8914366;-0.5908933;-0.20617604;-4.60396;IRRE
ax set xlim ax get xlim 1 reverse axis;0.3215889;2.990039;0.62582093;-6.5987935;-2.780676;2.9791121;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
make sure that it x is 2d;-1.4258866;1.4329622;3.5622318;-6.381174;-3.0809848;0.54650784;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
define the estimators to compare;3.0452964;2.2896025;2.2401092;4.0038314;-0.15925981;0.78571254;IRRE
load the dataset;3.3733814;-2.8897374;2.069233;-0.41889125;0.5001514;-0.03551577;IRRE
transform the results in a pandas dataframe for easy plotting;2.6804023;-2.6637895;2.7657576;-4.711696;-7.009803;0.5503989;CODE
define what to plot;0.045323234;-3.3924115;7.9278245;-1.7485503;-3.7277746;0.40418988;CODE
first plot train and test scores;3.54554;0.42705706;3.3758814;0.20669788;-2.7993076;-3.2749858;IRRE
second plot n iter and fit time;2.834746;0.8464876;4.2800264;-4.31465;-6.013964;0.702137;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
we only take the first two features we could;0.3086207;-3.3507636;3.08271;1.7091914;2.4612274;1.2562405;TASK
avoid this ugly slicing by using a two dim dataset;5.6505284;0.41535735;-1.670328;-3.7766712;0.829954;1.8157729;CODE
shuffle;1.1517164;-0.5439028;5.424595;-0.047424313;2.686807;-2.256504;-
standardize;1.3213661;0.02015821;1.3542689;-1.9349823;1.0452663;2.277632;-
plot also the training points;3.8571665;-4.4865284;5.091605;-1.1665463;-2.758238;-0.3909035;CODE
plot the three one against all classifiers;4.338953;-1.9996493;1.6661991;-2.5345144;1.5870774;-2.2438269;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we create 50 separable points;2.666291;0.033736747;3.2414656;-3.5225904;2.9825203;0.8311633;IRRE
fit the model;1.4823515;-1.8818403;3.3056085;0.7802941;0.8633568;-0.14115213;-
plot the line the points and the nearest vectors to the plane;1.5128524;-1.599634;4.0188537;-3.5900824;-4.2008457;-0.17444815;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we create 20 points;0.67531437;-0.38751027;6.176717;-0.6396354;1.4427372;-2.6175084;IRRE
and assign a bigger weight to the last 10 samples;7.424326;0.9504403;2.6629229;0.59039634;1.9730852;-0.03933189;IRRE
plot the weighted data points;5.5515723;-0.68151915;4.373012;-4.85521;-3.8023481;1.0037087;CODE
fit the unweighted model;2.69748;-0.44619092;0.61888874;1.8335;0.38627848;2.367675;-
fit the weighted model;5.794797;0.6967773;1.2359456;1.0047342;0.052612815;1.9862626;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate train data;5.008639;-1.8013539;2.768107;-1.4555813;1.9937072;-1.5770701;-
generate some regular novel observations;6.6711416;-2.3114767;1.4646629;0.69427294;0.13626361;0.4097774;-
generate some abnormal novel observations;5.389696;-1.1086786;1.1809517;1.1423573;-0.67577666;-1.1810746;-
ocsvm hyperparameters;3.101146;-0.7357689;-2.6981735;0.103058144;2.42178;2.6288774;IRRE
fit the one class svm;5.087745;-3.3947217;-0.94563204;-0.9177556;3.2410276;2.1453726;IRRE
fit the one class svm using a kernel approximation and sgd;6.3730807;-3.2850688;-2.8546584;-0.41820124;0.9125127;3.4758077;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we use saga solver;1.9778483;-5.3360744;1.8628799;-0.1719067;-0.47458595;0.22113468;-
turn down for faster run time;-1.2615039;0.59703344;2.7422369;3.54138;-0.41939348;1.1564392;CODE
add initial chance level values for plotting purpose;2.658242;1.4360869;4.0616693;-1.4909303;-2.5912583;0.91795605;IRRE
small number of epochs for fast runtime;3.0639832;-1.4439644;-1.5104192;0.7996729;-1.881072;1.0594876;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
turn down for faster convergence;1.9661644;0.2920028;0.87934095;5.1303916;-2.1901443;1.3698636;CODE
load data from https www openml org d 554;-3.3481424;0.08540846;0.6654659;-0.8974318;-0.7707516;0.57027537;CODE
turn up tolerance for faster convergence;3.3216188;0.38448888;-1.0465865;4.830733;-2.147507;3.0844696;CODE
print best c 4f clf c;0.93129075;0.47770754;0.66863376;-2.3836327;-0.052388843;-2.5360591;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
outliers only in the y direction;3.2662692;2.1670663;1.51259;-1.9207472;-4.0149093;0.19305098;CODE
linear model y 3 x n 2 0 1 2;1.3743372;1.8147699;-0.23043382;-5.2656875;-1.879961;-0.5635015;-
10 outliers;4.4026575;-0.20874037;2.7034347;0.044366483;-0.59928185;-3.1343231;-
outliers in the x direction;3.715453;1.3975773;1.9407715;-1.7830642;-2.4742467;0.07372673;CODE
linear model y 3 x n 2 0 1 2;1.3743372;1.8147699;-0.23043382;-5.2656875;-1.879961;-0.5635015;-
10 outliers;4.4026575;-0.20874037;2.7034347;0.044366483;-0.59928185;-3.1343231;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
fremtpl2freq dataset from https www openml org d 41214;-1.6943794;-1.7116779;-1.2361485;-1.5156664;0.50156146;-0.22076716;CODE
fremtpl2sev dataset from https www openml org d 41215;-1.627456;-2.4304583;-1.5609521;-2.2087998;0.28449866;-0.43023705;CODE
sum claimamount over identical ids;1.562349;2.8924606;-1.208475;-0.08418087;4.6644826;-0.19759442;-
unquote string fields;-2.2829587;2.1271904;-0.34050944;-1.0783117;2.7284815;-2.5782375;IRRE
aggregate observed and predicted variables by feature level;5.290098;-2.130573;0.26403564;1.0121406;0.9778414;2.4600346;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset preparation;6.3923435;-4.9874806;1.2885944;-0.4197396;2.9793432;-2.6038296;IRRE
we start by generating the s curve dataset;4.9280696;-6.6451287;2.4211698;-1.4802995;-0.5448718;-0.47611517;IRRE
unused but required import for doing 3d projections with matplotlib 3 2;-2.480073;-3.8260553;-3.9122677;-3.6912203;-5.2357655;2.5204852;CODE
import mpl toolkits mplot3d noqa f401;-3.1103742;-3.7681549;-3.7366135;-5.488973;-3.817242;1.7461501;CODE
let s look at the original data also define some helping;4.1824827;-1.6551676;2.8295596;-0.3508489;0.14464352;-1.3521906;CODE
functions which we will use further on;-0.63576466;-3.333529;6.4623604;0.9655291;1.4835846;-1.5214756;CODE
define algorithms for the manifold learning;4.7779965;-6.395454;1.8590649;-0.48080894;3.3845015;3.9870913;CODE
manifold learning is an approach to non linear dimensionality reduction;5.070918;-5.392397;-0.010536677;-1.6659337;1.818649;4.4103484;-
algorithms for this task are based on the idea that the dimensionality of;7.205344;-1.4138001;3.5962913;-4.869896;3.90468;1.0200571;CODE
many data sets is only artificially high;7.47111;-0.8595982;-0.3847674;1.356716;1.7060087;-1.0754653;IRRE
read more in the ref user guide manifold;-1.4135588;-5.113931;0.47749856;-1.0788044;-0.10173484;4.8944564;CODE
n neighbors 12 neighborhood which is used to recover the locally linear structure;3.3927147;-2.0698016;0.086253636;-4.0485764;0.7303131;2.773186;IRRE
n components 2 number of coordinates for the manifold;-0.31376767;-0.251426;1.2601088;-7.2741456;1.3288827;2.3026028;CODE
locally linear embeddings;1.5540968;-3.3113458;0.67280984;-1.430358;0.86704934;4.5217185;IRRE
locally linear embedding lle can be thought of as a series of local;0.7041771;-1.9621444;-1.4413359;-0.9077262;1.3620659;5.0855346;IRRE
principal component analyses which are globally compared to find the;5.020482;-2.5272758;0.038785532;0.1575175;1.2680547;3.3833845;IRRE
best non linear embedding;4.941267;-2.8664205;1.2941788;-2.184719;0.29706046;3.8911262;-
read more in the ref user guide locally linear embedding;0.34057653;-4.889588;-0.732983;-1.9617864;-0.41300896;5.502269;CODE
isomap embedding;2.2224717;-2.694533;1.4426519;-3.531566;0.79024124;4.8667216;-
non linear dimensionality reduction through isometric mapping;5.535845;-2.5302823;-1.0307372;-4.024606;0.5279662;5.0702662;-
isomap seeks a lower dimensional embedding which maintains geodesic;1.5135394;-2.76108;-0.28853512;-2.0122476;0.22237256;7.1377735;CODE
distances between all points read more in the ref user guide isomap;2.0552323;-1.2245655;1.5872458;-3.350647;-1.72277;2.4131844;CODE
multidimensional scaling;6.89313;-2.0738494;2.7536619;-6.433933;0.34275308;5.9239373;-
multidimensional scaling mds seeks a low dimensional representation;5.206525;-2.9941876;-0.8715603;-4.5150466;1.255822;5.9008594;-
of the data in which the distances respect well the distances in the;6.7367334;-1.582059;3.5586112;-1.9510137;0.15792966;1.5742211;CODE
original high dimensional space;1.6813285;-2.3005302;1.8293898;-5.1764245;0.99941486;3.6801832;-
read more in the ref user guide multidimensional scaling;3.9675562;-2.646518;0.5515179;-5.221125;-0.82380456;6.6562495;CODE
spectral embedding for non linear dimensionality reduction;4.427711;-3.4895566;-1.8706433;-2.573892;0.9107696;6.555101;CODE
this implementation uses laplacian eigenmaps which finds a low dimensional;6.3506565;-2.765894;-1.8686596;-4.301664;0.23337886;6.178166;TASK
representation of the data using a spectral decomposition of the graph laplacian;5.979995;-3.2461336;1.9682935;-4.777249;0.76873034;4.273915;-
read more in the ref user guide spectral embedding;0.6630529;-5.670528;-1.1324357;-2.4131982;0.04518688;6.0025067;CODE
t distributed stochastic neighbor embedding;4.7327642;-3.6293347;-0.083888985;-0.87341887;1.777342;3.9701042;META
it converts similarities between data points to joint probabilities and;5.502681;-5.199652;2.1289926;-1.3236951;2.7689588;0.56636024;CODE
tries to minimize the kullback leibler divergence between the joint probabilities;1.8561518;-0.9618775;-1.3107867;1.0346211;1.2030294;3.043055;CODE
of the low dimensional embedding and the high dimensional data t sne has a cost;4.6793613;-3.3726404;-1.0307235;-2.6981208;1.3120637;4.5495486;-
function that is not convex i e with different initializations we can get;0.09375261;2.2474616;1.4626746;-1.776869;-1.9458456;2.0749142;IRRE
different results read more in the ref user guide t sne;-0.2802264;0.48679182;-2.279527;2.4812484;-0.20318905;-1.5593199;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load digits dataset;4.3504925;-1.658323;0.32199144;-3.2392602;0.64060694;-1.7657725;TASK
we will load the digits dataset and only use six first of the ten available classes;3.5044005;-1.6674854;-0.36511388;-0.6021702;4.055221;-1.859882;CODE
we can plot the first hundred digits from this data set;4.1914945;-0.82346874;4.541871;-5.623139;-2.882672;-3.4422212;CODE
helper function to plot embedding;0.8627161;-0.87113005;3.5056872;-3.8131294;-3.5075247;2.1053596;CODE
below we will use different techniques to embed the digits dataset we will plot;3.6970823;-2.56326;2.4544914;-5.922519;-2.865505;-0.5408944;IRRE
the projection of the original data onto each embedding it will allow us to;3.719857;-2.0419056;1.8766534;-2.0536523;2.1652;6.195;-
check whether or digits are grouped together in the embedding space or;2.3091774;2.6030214;-0.3351105;-2.8236704;3.1755993;-2.0102322;CODE
scattered across it;-0.6757294;-0.9977594;7.022772;0.12075469;-0.53489506;-0.15598105;-
hown images np array 1 0 1 0 just something big;2.813405;-0.07973457;-0.0660836;-6.568106;-3.6643062;-0.9409218;-
plot every digit on the embedding;2.2038004;0.0138236685;3.166086;-6.971002;-2.1220114;-0.53881055;-
show an annotation box for a group of digits;0.36617187;-0.43228415;2.5639853;-2.7600842;1.6482713;-2.2747214;CODE
don t show points that are too close;2.5091136;2.2507062;4.419347;-1.8331164;-0.41207448;-1.4449815;CODE
embedding techniques comparison;3.7971818;-1.4739316;1.4397904;-0.68102163;2.732781;1.6049312;-
below we compare different techniques however there are a couple of things;2.6178694;-1.7096702;3.2709932;4.125385;1.2666509;-0.57093453;IRRE
to note;-2.5877986;-1.8616489;3.8645587;2.1774364;-1.6877816;-1.7580891;TASK
the class sklearn ensemble randomtreesembedding is not;0.6033609;-4.9032454;-5.85023;1.690181;0.40654168;-1.2780486;IRRE
technically a manifold embedding method as it learn a high dimensional;2.8288848;-5.4258804;0.6828706;-1.1191912;1.9601021;4.7893424;IRRE
representation on which we apply a dimensionality reduction method;5.7313614;-3.6038954;-0.45563757;-3.27149;3.8623464;3.8195777;-
however it is often useful to cast a dataset into a representation in;4.4087973;-3.4561598;-0.3844519;-0.3783942;3.7709596;0.63225293;IRRE
which the classes are linearly separable;1.2454779;-1.0903592;-0.910224;-1.8934546;4.287982;1.165691;IRRE
the class sklearn discriminant analysis lineardiscriminantanalysis and;5.559612;-4.650141;-5.380464;-1.6050482;0.1348423;0.09375997;IRRE
the class sklearn neighbors neighborhoodcomponentsanalysis are supervised;5.8172383;-6.763743;-3.5357578;-0.6828771;0.26403555;1.8520397;CODE
dimensionality reduction method i e they make use of the provided labels;5.2790537;-3.8853652;0.48020035;-4.385115;3.6233747;2.0038595;-
contrary to other methods;0.8208342;0.112024166;1.7649536;3.5413198;0.7887167;-0.2792931;-
the class sklearn manifold tsne is initialized with the embedding that is;-0.55272275;-4.087195;-4.0555334;-0.9680482;-0.15209757;4.1618505;IRRE
generated by pca in this example it ensures global stability of the embedding;2.2304404;-1.7682085;-1.2672026;-1.7298102;1.0677991;6.2315297;CODE
i e the embedding does not depend on random initialization;-0.839856;-1.1977706;-1.7049574;1.2792313;1.1837096;5.5036755;CODE
once we declared all the methods of interest we can run and perform the projection;0.7114538;-2.866354;1.5713644;2.9011045;0.89801025;4.3158116;CODE
of the original data we will store the projected data as well as the computational;5.1165733;-4.1623535;2.251085;0.7088211;1.0243328;3.3205018;-
time needed to perform each projection;3.127597;-0.30349872;3.6952121;-1.1050597;-1.1446874;2.5651073;CODE
data flat x shape 1 1 0 01 make x invertible;3.9403136;2.858618;-0.23953772;-8.233979;-2.0819788;1.5017961;-
finally we can plot the resulting projection given by each method;2.6948965;-1.6809815;3.1656985;-1.5799801;-3.554959;3.2646375;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
unused but required import for doing 3d projections with matplotlib 3 2;-2.480073;-3.8260553;-3.9122677;-3.6912203;-5.2357655;2.5204852;CODE
import mpl toolkits mplot3d noqa f401;-3.1103742;-3.7681549;-3.7366135;-5.488973;-3.817242;1.7461501;CODE
variables for manifold learning;3.3480637;-5.258502;1.3091408;-1.8451557;2.3825736;3.7801049;CODE
create our sphere;-1.7590234;-1.9360557;5.4683046;-1.5345443;-0.26851332;-0.06130211;IRRE
sever the poles from the sphere;-1.8523192;0.020037333;3.43337;-1.1389717;-1.9085503;1.6341158;CODE
plot our dataset;5.1474953;-2.9001436;6.294244;-4.1034427;-3.9928653;-1.6648424;IRRE
perform locally linear embedding manifold learning;4.0377884;-4.8553615;0.513941;-1.21917;0.7132346;4.782665;IRRE
perform isomap manifold learning;4.157666;-5.2466106;0.57501215;-2.243944;1.3121133;4.4189396;CODE
perform multi dimensional scaling;6.616516;-1.1838965;2.450889;-7.045503;-1.4549083;5.414903;CODE
perform spectral embedding;2.7620168;-2.1833985;-0.3350473;-3.628048;0.5962792;5.9054575;CODE
perform t distributed stochastic neighbor embedding;5.370628;-3.2655141;-0.6706629;-1.1245937;1.6856546;4.014834;META
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset preparation;6.3923426;-4.9874797;1.2885938;-0.41974038;2.9793432;-2.6038294;IRRE
we start by uniformly generating 20 points in a 2d space;2.6117175;1.0101944;3.9526665;-4.4361124;-0.6694105;0.7380458;CODE
generate the data;4.332126;-0.83362067;4.90541;-3.0842018;2.5492842;-5.028516;-
center the data;4.041758;0.62246567;6.875739;-3.5569363;-1.6511266;1.9990526;-
now we compute pairwise distances between all points and add;3.111471;1.1452678;3.0752351;-4.465984;-0.07969738;-0.1986386;TASK
a small amount of noise to the distance matrix we make sure;7.3842473;-1.4959242;-0.5719194;-1.0106603;-2.4383297;2.0603585;IRRE
to keep the noisy distance matrix symmetric;6.2118807;-0.93749565;-0.7824289;-2.4580102;-0.694436;5.456408;-
compute pairwise euclidean distances;3.4893887;0.4572074;1.8071884;-5.362946;-1.6531975;-0.7156533;CODE
add noise to the distances;5.0449133;-0.64494205;3.3794477;-1.2806677;-0.8284208;1.8364342;TASK
here we compute metric non metric and classical mds of the noisy distance matrix;3.9499662;-1.4890602;-1.4585093;-2.4762654;0.8969555;4.1075387;IRRE
rescaling the non metric mds solution to match the spread of the original data;6.455858;1.2677267;-0.2957737;-2.7356324;-2.353282;4.4467835;CODE
to make the visual comparisons easier we rotate the original data and all mds;3.8608835;-1.3147333;2.3528874;-1.1460005;-0.20654762;1.9340361;-
solutions to their pca axes and flip horizontal and vertical mds axes if needed;1.8387542;-0.936002;1.4774643;-6.0664954;0.52917695;4.502857;-
to match the original data orientation;4.1642466;1.4714421;1.6938154;-4.228776;2.4975066;2.126393;-
rotate the data cmds does not need to be rotated it is inherently pca aligned;0.5019547;0.9626418;-2.6452491;-3.36475;-0.9921587;4.740886;TASK
align the sign of pcs;-0.39071897;0.89894587;2.6084416;-5.1412168;-0.8134432;0.5681608;-
finally we plot the original data and all mds reconstructions;3.3200142;-2.3570933;2.1468537;-1.9436806;-2.3372967;1.7041675;CODE
plot the edges;0.050338272;-0.9133859;7.392213;-5.121104;-4.3092275;-0.079941735;-
a sequence of line0 line1 line2 where;-0.92232174;2.9152195;2.513147;-3.3791823;0.5727096;-2.9035323;CODE
linen x0 y0 x1 y1 xm ym;-1.8716362;2.4427598;1.2831491;-6.010423;0.76823235;0.049917806;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
swiss roll;-2.0869865;0.558448;3.635801;-1.1121557;-0.37876424;-2.7223368;-
we start by generating the swiss roll dataset;3.4257238;-4.8067183;1.6631843;-0.35101825;1.2786499;-1.2502837;IRRE
now let s take a look at our data;3.0397499;-0.93080527;3.8045232;0.4788943;-0.40342316;-2.2449875;CODE
computing the lle and t sne embeddings we find that lle seems to unroll the;0.8625686;-2.8587234;-2.0227964;-1.0134001;0.94485337;2.3536506;-
swiss roll pretty effectively t sne on the other hand is able;-1.3737317;1.2116097;1.1974022;1.1474255;-0.3887355;0.59678847;-
to preserve the general structure of the data but poorly represents the;5.029619;-0.54765105;1.3560222;-2.146958;2.4443977;2.054662;META
continuous nature of our original data instead it seems to unnecessarily;4.892312;-0.87192625;2.0198545;2.637568;-1.4537005;1.8338561;-
clump sections of points together;3.221295;0.70098513;4.3013325;-5.404468;0.000112329384;0.83637017;CODE
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
lle seems to be stretching the points from the center purple;-1.0412022;0.657879;2.676832;-1.6921027;-2.4410985;0.11822994;CODE
of the swiss roll however we observe that this is simply a byproduct;-2.2159157;0.56635743;0.3142047;1.5037535;0.37077203;-0.07480027;CODE
of how the data was generated there is a higher density of points near the;6.000596;-1.900034;2.5232008;-2.783802;-1.9978931;0.48856735;CODE
center of the roll which ultimately affects how lle reconstructs the;-2.304129;0.3008242;2.9864333;-0.3942814;-1.414392;1.6238595;CODE
data in a lower dimension;7.379923;0.80909497;1.8933014;-5.342686;1.2642694;1.9704429;-
swiss hole;-1.7898893;-0.3103629;4.776963;-0.1382711;-1.425533;-2.5055213;-
now let s take a look at how both algorithms deal with us adding a hole to;1.4272528;-0.4681417;-0.31202915;0.86269075;0.6903231;1.0296808;CODE
the data first we generate the swiss hole dataset and plot it;3.9070833;-3.6164348;2.7159529;-2.946577;-3.8206306;-1.2642124;IRRE
computing the lle and t sne embeddings we obtain similar results to the;3.198198;-2.6674113;-1.856438;-3.211543;1.6067499;2.2837162;IRRE
swiss roll lle very capably unrolls the data and even preserves;1.0786158;0.8225553;-1.596758;0.5440083;-1.182779;1.0685565;-
the hole t sne again seems to clump sections of points together but we;-0.29017466;0.969595;1.2807221;-1.2741519;-2.232333;0.6798403;CODE
note that it preserves the general topology of the original data;2.6257496;-1.9229345;0.022889087;-0.38276654;-0.03866854;6.179169;TASK
concluding remarks;-2.5548632;0.6982546;2.7027164;3.9985068;0.4240034;-0.27675796;-
we note that t sne benefits from testing more combinations of parameters;2.816409;-0.03450649;-1.5765777;4.5243354;1.9323941;-0.7750251;IRRE
better results could probably have been obtained by better tuning these;2.968034;0.45113182;-0.54085124;3.1647637;-2.519852;-0.888097;IRRE
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
we observe that as seen in the manifold learning on;2.5429006;-4.409978;1.9052683;0.9199994;1.5122057;5.0424385;CODE
handwritten digits example t sne generally performs better than lle;2.5656147;-1.667597;-1.8503214;-0.5131849;-1.3427156;-1.0954324;CODE
on real world data;5.475095;-3.6377127;3.262163;-0.8568254;1.9076085;-1.5585926;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
another example using s curve;1.0106902;-0.709036;2.9429631;-3.9654665;-2.0898535;-1.7299265;-
another example using a 2d uniform grid;2.3732522;1.3107066;3.8240378;-6.311633;-1.5550144;-0.048077807;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
example settings;-3.7010138;-2.9047792;4.544835;1.098162;1.2214457;1.9659005;IRRE
define outlier anomaly detection methods to be compared;3.7385209;0.48443064;-0.35864356;2.3850343;-0.024513852;-0.20419627;IRRE
the sgdoneclasssvm must be used in a pipeline with a kernel approximation;2.8809168;-4.8369308;-6.269644;1.1690353;1.1470792;3.907898;CODE
to give similar results to the oneclasssvm;3.1468961;-1.2398509;-1.8297936;1.6650866;5.065295;0.25633466;IRRE
define datasets;3.7269547;-4.5972977;1.4159555;-0.10913278;3.2948663;-0.22482036;IRRE
compare given classifiers under given settings;6.3694134;-0.37356815;-0.8886614;1.8964132;3.485372;-2.2253907;IRRE
add outliers;4.893754;0.009817521;2.8067532;-0.11117458;0.08503122;-0.83181834;TASK
fit the data and tag outliers;6.0374246;0.16953456;1.4537989;-0.22062628;0.67777365;0.9088178;-
plot the levels lines and the points;1.113476;-0.62630004;6.167019;-5.0514383;-2.9772518;-0.9506234;CODE
if name local outlier factor lof does not implement predict;3.802271;1.7525649;-5.6830015;2.0446692;-2.0056212;1.960595;TASK
colors np array 377eb8 ff7f00;-1.1050887;0.013507287;-0.83734185;-7.093106;-1.8794135;-2.8595483;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
load data and train model;4.1570277;-2.134765;2.6691494;2.0332713;1.7555351;1.2446288;TASK
for this example we load a blood transfusion service center data set from;1.1864613;-0.41108736;2.3226194;-1.3597496;2.5430906;0.7423016;CODE
openml https www openml org d 1464 this is a binary classification;-2.7256045;-3.9763434;-1.0817518;-1.9184896;5.8963575;-3.1556182;CODE
problem where the target is whether an individual donated blood then the;0.5465499;3.8006208;2.7966034;3.1588094;2.2624128;-3.34473;CODE
data is split into a train and test dataset and a logistic regression is;2.6587124;-1.3514342;0.8605569;2.3782089;1.3912137;-2.1283448;IRRE
fitted with the train dataset;5.2846646;-1.8071164;1.2248621;-0.88735455;0.867173;0.64496183;IRRE
create class confusionmatrixdisplay;1.2747892;0.39281788;-1.4495897;-3.1988342;2.239352;0.7127706;IRRE
with the fitted model we compute the predictions of the model on the test;4.3014536;0.40967366;0.32491946;6.3723598;-0.50486106;-1.1594999;IRRE
dataset these predictions are used to compute the confusion matrix which;5.8923855;-3.1291506;-0.85674536;0.9181023;1.276356;-3.2085195;IRRE
is plotted with the class confusionmatrixdisplay;1.6742697;-0.38113034;0.18708357;-3.7431545;-2.4179218;0.704801;IRRE
create class roccurvedisplay;-0.979865;-3.4781206;-2.1624682;-0.7331177;3.3373435;-0.23152196;IRRE
the roc curve requires either the probabilities or the non thresholded;2.7205782;-2.6081834;-2.4702036;0.595774;1.0592275;0.59936386;CODE
decision values from the estimator since the logistic regression provides;1.6888568;-1.8477395;-0.48486364;2.9462085;0.37413397;1.3017821;IRRE
a decision function we will use it to plot the roc curve;4.374904;-4.3736124;2.0490603;0.3076135;0.35699433;-1.2436115;CODE
create class precisionrecalldisplay;-0.49887455;0.24259113;-1.655862;-0.079361945;-0.25780052;1.1010206;IRRE
similarly the precision recall curve can be plotted using y score from;4.6666603;-2.9467084;1.5803453;-0.4197439;-1.9727169;-2.0169125;IRRE
the prevision sections;-2.321512;-3.643721;3.8352163;1.7947217;2.5625632;1.5241452;META
combining the display objects into a single plot;1.9940386;-0.0127522545;6.578992;-3.6490154;-1.8131446;1.7584761;CODE
the display objects store the computed values that were passed as arguments;-0.3730474;1.8720826;1.8768307;-0.18784323;0.79773843;0.74050677;IRRE
this allows for the visualizations to be easliy combined using matplotlib s;2.1446998;-6.342177;3.5163987;-5.1582804;-3.8951526;0.5277511;CODE
api in the following example we place the displays next to each other in a;-3.0578277;0.2252197;5.290304;-2.4042954;0.3918076;2.7158713;CODE
row;0.43681723;0.3956876;7.2724924;-3.6712785;1.8318598;-3.4862943;-
sphinx gallery thumbnail number 4;-4.1622796;-1.045713;0.69986063;-2.7914124;0.088549845;0.91196156;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
compact text representation;1.4480627;-3.7934542;2.8761783;-2.8096068;2.9666924;0.46177065;-
estimators will only show the parameters that have been set to non default;0.18398285;3.4561408;-2.0407517;2.038437;-4.3260856;4.1565957;IRRE
values when displayed as a string this reduces the visual noise and makes it;0.3524596;2.951656;2.3344986;-1.7472776;-0.6700618;-0.39191216;CODE
easier to spot what the differences are when comparing instances;2.887922;1.2667816;1.0991423;4.3244853;3.0107005;-3.0914452;-
rich html representation;-0.654407;-3.94961;2.679789;-1.9977508;2.3083816;1.4375994;-
in notebooks estimators and pipelines will use a rich html representation;0.28695172;-4.907589;0.8887319;1.356323;-0.610658;3.0791097;TASK
this is particularly useful to summarise the;-0.609227;-5.2994657;5.8299985;2.0198839;1.8276637;-0.40506113;IRRE
structure of pipelines and other composite estimators with interactivity to;2.7777917;-0.92319983;-0.39469576;3.620265;0.64838606;5.349005;CODE
provide detail click on the example image below to expand pipeline;-2.6936734;-1.786669;2.6240437;-0.75123936;0.54811037;3.3818169;CODE
elements see ref visualizing composite estimators for how you can use;2.379056;-0.7337218;2.2773526;-0.12744415;-0.23085663;4.0943303;CODE
this feature;-1.3789902;-3.2816565;5.2319517;2.6757522;1.1352788;2.4339228;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
fit isotonicregression and linearregression models;4.1069303;-1.0961369;-1.2785593;2.126238;-1.6000884;4.9455104;-
lr fit x np newaxis y x needs to be 2d for linearregression;4.083542;1.4433202;-3.2880127;-5.865359;-3.9049656;4.874877;CODE
plot results;2.728097;0.6326074;7.251219;-4.3832655;-6.211308;-4.720717;IRRE
note that we explicitly passed out of bounds clip to the constructor of;-3.2835357;0.4140439;-3.1048276;1.3385402;0.900425;2.7201943;CODE
isotonicregression to control the way the model extrapolates outside of the;2.791256;1.0286646;0.4318233;2.941842;-1.0510365;6.148293;-
range of data observed in the training set this clipping extrapolation can;6.3602533;0.053655777;-0.5107383;0.51632166;-0.38935402;1.5857408;CODE
be seen on the plot of the decision function on the right hand;-0.25511348;-1.3686614;4.9671206;0.24372126;-0.94954413;-0.532145;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
theoretical bounds;0.90625745;1.3052101;2.827533;1.2230117;-0.7246119;-2.7117004;-
the distortion introduced by a random projection p is asserted by;1.3754315;-0.10852104;0.17551005;-0.93025106;-0.038691666;5.123784;CODE
the fact that p is defining an eps embedding with good probability;1.3942808;-1.0990208;-0.99093586;-0.014458177;2.6084795;4.552506;CODE
as defined by;-1.1157779;0.6046992;1.8500457;0.8958544;4.6615887;-2.49584;CODE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
1 eps u v 2 p u p v 2 1 eps u v 2;-1.363508;0.2823219;2.3985195;-4.6732764;3.7343588;-2.0166895;-
where u and v are any rows taken from a dataset of shape n samples;5.3881493;-0.9234477;0.63168657;-5.6086736;1.8766603;-1.0005738;CODE
n features and p is a projection by a random gaussian n 0 1 matrix;3.0671108;-2.0916781;-1.7573601;-3.756147;-0.2034727;4.428819;IRRE
of shape n components n features or a sparse achlioptas matrix;5.9993396;-4.4407725;-0.047858015;-4.0151405;1.8267198;4.153414;TASK
the minimum number of components to guarantees the eps embedding is;1.3024056;-0.68912834;-1.7258486;-2.612445;2.4045918;5.2931;-
given by;-1.140203;-0.7330367;4.1998105;1.2644435;0.76474035;-4.636011;-
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
n components geq 4 log n samples eps 2 2 eps 3 3;2.4414377;0.41963422;-1.0853189;-5.793329;2.7955549;-0.8352753;-
the first plot shows that with an increasing number of samples n samples;2.85945;-0.02168285;3.3520057;-1.6252345;-3.3289864;-1.4771755;-
the minimal number of dimensions n components increased logarithmically;2.7204792;-0.848497;-1.3906194;-5.0686173;1.0778958;3.862983;IRRE
in order to guarantee an eps embedding;0.91820353;-0.3008486;-1.3198293;-1.1788089;0.6316808;5.3507724;-
range of admissible distortions;2.9736254;2.344703;-0.5905879;-1.661159;-0.021223735;2.215804;-
range of number of samples observation to embed;5.3888617;2.1702042;1.7489054;-2.1086266;1.2189565;1.5725615;-
the second plot shows that an increase of the admissible;-2.5835419;-0.0380158;3.1610913;0.6524347;-2.4153085;1.2898275;-
distortion eps allows to reduce drastically the minimal number of;2.7019112;0.044253867;0.3908345;-1.739025;-0.46269402;3.9287598;IRRE
dimensions n components for a given number of samples n samples;5.5085907;-0.719858;0.2733692;-5.410218;3.0233097;1.4003685;CODE
range of admissible distortions;2.9736254;2.344703;-0.5905879;-1.661159;-0.021223735;2.215804;-
range of number of samples observation to embed;5.3888617;2.1702042;1.7489054;-2.1086266;1.2189565;1.5725615;-
empirical validation;6.0213256;-1.0561006;0.8196071;6.287529;2.0817294;-4.3212113;-
we validate the above bounds on the 20 newsgroups text document;-0.050716024;0.40937957;0.96188563;2.9682822;2.5767176;-1.7465411;CODE
tf idf word frequencies dataset or on the digits dataset;3.8113992;-2.596202;-0.7731382;-1.5121447;1.5421616;-0.7287771;IRRE
for the 20 newsgroups dataset some 300 documents with 100k;2.5106723;-3.6412222;1.4919218;0.7543381;1.9998033;-0.62444353;CODE
features in total are projected using a sparse random matrix to smaller;7.650801;-2.6181014;-1.581276;-1.6528994;0.61658704;4.838728;IRRE
euclidean spaces with various values for the target number of dimensions;4.171404;0.23825945;1.7210113;-5.594848;1.508523;1.0609361;CODE
n components;0.24123365;-1.3953292;2.6840322;-5.3998485;4.5323806;-0.93594706;-
for the digits dataset some 8x8 gray level pixels data for 300;4.516282;-2.1795187;1.2185879;-6.606437;0.0813689;-0.5975838;CODE
handwritten digits pictures are randomly projected to spaces for various;2.7208874;-1.2530478;1.6402625;-2.9555106;-1.0971509;1.9031881;CODE
larger number of dimensions n components;2.9201224;-1.2198348;1.2499391;-6.3269687;2.8838093;2.559544;-
the default dataset is the 20 newsgroups dataset to run the example on the;0.5208082;-3.5351741;0.6719141;0.32430163;1.1283613;1.0848819;CODE
digits dataset pass the use digits dataset command line argument to;0.99154955;-0.062384304;-2.8572452;-2.7173014;-0.60626245;-1.4205307;IRRE
this script;-2.654885;-0.72076696;6.431277;-0.51246977;0.2742447;-4.987943;CODE
for each value of n components we plot;3.6131103;-0.4286295;4.32557;-7.8808694;-0.91496164;-0.32416037;CODE
2d distribution of sample pairs with pairwise distances in original;3.4473026;-0.16917628;2.2817404;-4.1730924;-0.6067254;1.4942789;META
and projected spaces as x and y axis respectively;1.4471449;-1.2000952;3.8594258;-5.521408;-1.7227842;3.6965218;-
1d histogram of the ratio of those distances projected original;5.6475935;-0.23041226;2.3229895;-5.122933;-2.184306;2.558402;CODE
select only non identical samples pairs;5.0984545;4.0735354;0.5594017;-2.2255778;3.487809;-2.500845;CODE
todo compute the expected value of eps and add them to the previous plot;1.3208979;1.361369;2.8003237;-2.8270404;-5.121029;0.91294956;TASK
as vertical lines region;-1.141931;-0.28978387;7.0122833;-5.316943;0.93844765;0.44181615;IRRE
we can see that for low values of n components the distribution is wide;2.9667761;0.11867321;-0.9734656;-2.217206;0.36954343;2.5068364;IRRE
with many distorted pairs and a skewed distribution due to the hard;5.1083574;0.6387958;1.5118941;-2.1724985;0.5684133;1.4443012;META
limit of zero ratio on the left as distances are always positives;0.060928922;2.7810423;0.332263;-1.6810677;-3.779946;1.5253962;-
while for larger values of n components the distortion is controlled;4.4684963;1.9427068;0.2515335;-4.203297;-0.3668566;3.8634;IRRE
and the distances are well preserved by the random projection;3.9643402;-1.7257584;1.7066404;-0.023938414;-0.23318437;5.4297686;IRRE
remarks;-1.9784744;-2.6008368;4.556365;3.1249938;0.9298268;-1.5444163;-
according to the jl lemma projecting 300 samples without too much distortion;3.4861336;0.940196;-1.5923431;-0.15108663;-0.15776742;3.7191973;-
will require at least several thousands dimensions irrespective of the;1.4361761;-1.789051;1.8841954;-2.6716661;3.0244582;3.0249968;CODE
number of features of the original dataset;4.464594;-4.134391;0.3919244;-1.8333801;2.2281144;-1.9692191;TASK
hence using random projections on the digits dataset which only has 64;5.7736397;-0.7309714;-1.0817544;-2.4291043;1.4366361;-0.8513528;IRRE
features in the input space does not make sense it does not allow;-2.5325222;-0.4457855;-0.99467075;-0.7585427;0.31252038;0.81758356;CODE
for dimensionality reduction in this case;4.841977;-0.5098194;0.31637552;-4.989999;2.8906853;1.8054341;CODE
on the twenty newsgroups on the other hand the dimensionality can be;1.6926079;-2.481737;3.013228;-0.75987005;2.5007696;2.015912;CODE
decreased from 56 436 down to 10 000 while reasonably preserving;2.030156;2.46307;-0.4153598;-0.3403263;-2.0001802;-0.3696047;CODE
pairwise distances;3.819307;1.1231358;3.3071086;-5.4049735;0.078791894;-1.0797776;-
python package and dataset imports load dataset;1.0621643;-4.335327;-2.687013;-0.38291872;-2.6659975;-0.32104868;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
standard scientific python imports;-0.747768;-6.5026984;-2.853305;-1.463533;-2.846401;-2.6265972;CODE
import datasets classifiers and performance metrics;5.9398413;-6.844338;-3.0860803;2.6194992;1.7301787;-0.18695627;CODE
the digits dataset;5.2950287;-4.658916;1.8081675;-2.957077;1.6072919;-3.8572066;IRRE
timing and accuracy plots;4.3779473;-2.7820425;3.8042796;0.44520167;-4.4234886;-0.5481369;-
to apply a classifier on this data we need to flatten the image to;4.8243146;-2.1154826;1.1239872;-2.6425426;0.058137152;1.4304394;CODE
turn the data in a samples feature matrix;6.636363;-1.055923;0.8143994;-4.045217;-0.7275832;1.745705;TASK
we learn the digits on the first half of the digits;1.2155733;-2.577425;4.2733555;-1.2757485;-0.0001250163;-3.375868;-
now predict the value of the digit on the second half;1.770391;1.4584664;4.6216354;-0.43568635;-0.31282097;-6.117853;IRRE
data test scaler transform data test;4.966078;4.143768;-2.0006902;0.04658121;-2.8340695;-1.1506894;IRRE
create a classifier a support vector classifier;3.740607;-5.158089;-1.1258487;-0.7856627;4.049637;0.6213188;IRRE
create pipeline from kernel approximation;4.5906672;-2.1285675;-1.0920227;0.105128035;-0.7920844;3.5553217;CODE
and linear svm;5.354639;-6.407599;0.58302003;-1.0966806;1.5788593;2.1999497;-
fit and predict using linear and kernel svm;5.5505443;-4.3018227;-0.11767707;-0.62791365;-0.42556128;1.4700285;IRRE
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
second y axis for timings;0.55704427;-0.40123338;4.2980013;-3.9575052;-3.4770806;1.5631235;CODE
horizontal lines for exact rbf and linear kernels;2.3679411;-1.7798544;-1.7846106;-5.3152204;-0.08091845;3.3526049;CODE
vertical line for dataset dimensionality 64;2.617068;-1.3851436;-0.14638454;-7.652303;-1.0179323;1.4396133;IRRE
legends and labels;-0.038518522;-2.7599604;4.5842752;0.14481866;3.1937437;-1.1073428;CODE
decision surfaces of rbf kernel svm and linear svm;4.1941442;-5.5365667;-2.4263783;-1.8831555;1.921257;3.6159654;-
the second plot visualized the decision surfaces of the rbf kernel svm and;4.836402;-6.431223;0.3458892;-2.0173879;0.2786117;2.2878196;-
the linear svm with approximate kernel maps;6.2312326;-4.4600806;0.61577266;-1.7708696;0.4969354;4.005654;-
the plot shows decision surfaces of the classifiers projected onto;4.595683;-6.36393;0.75897557;-1.3051242;1.4618226;1.271396;CODE
the first two principal components of the data this visualization should;3.7862751;-3.6749904;5.087579;-5.630595;0.8902789;1.9704734;CODE
be taken with a grain of salt since it is just an interesting slice through;-1.4251873;-0.2301388;2.6245506;0.9723305;-0.5324019;-0.11365482;CODE
the decision surface in 64 dimensions in particular note that;2.346374;-4.472461;-0.17521155;-3.9788241;2.7561057;1.8031478;TASK
a datapoint represented as a dot does not necessarily be classified;1.7866863;-1.0443108;-2.9976358;-3.2424254;1.47946;0.95969576;CODE
into the region it is lying in since it will not lie on the plane;-3.0952976;2.746161;2.6558967;0.038308818;-2.9415774;0.6781065;CODE
that the first two principal components span;1.7129536;-3.09678;1.2925016;-2.7721996;2.5151908;2.973296;-
the usage of class rbfsampler and class nystroem is described in detail;1.081785;-3.4133155;-2.7922344;-0.28496653;2.4810855;0.36026073;IRRE
in ref kernel approximation;3.412961;-2.6563096;-1.0569018;0.27309483;-1.1194632;4.564348;-
visualize the decision surface projected down to the first;3.1679752;-2.866684;5.6662607;-1.6848401;1.4960641;2.4509528;CODE
two principal components of the dataset;4.83248;-2.3073568;0.89187264;-4.0342946;3.2438333;2.0288138;IRRE
generate grid along first two principal components;3.4281769;0.41544494;1.4776096;-6.727416;1.2890924;4.3524795;-
steps along first component;-2.4348166;1.250809;4.5114293;-1.7101887;2.387478;2.2973967;-
steps along second component;-2.3890164;1.0713342;4.718831;-1.551986;2.434885;2.9347599;-
combine;-0.77452725;0.17648678;7.2063265;0.26399717;3.3851898;-2.4942536;-
title for the plots;-2.0247223;-4.1743655;7.7277465;-1.7129519;-2.2795992;-0.35375;CODE
predict and plot;4.3560634;-2.1467;6.1855354;-1.1989244;-5.414713;-2.4396327;-
plot the decision boundary for that we will assign a color to each;2.4560258;-1.6418927;5.445053;-2.621385;0.95969707;-0.08623329;IRRE
point in the mesh x min x max x y min y max;1.3513005;1.6070616;2.7779777;-5.594809;-2.0461638;1.9067987;CODE
put the result into a color plot;1.4292973;0.42623058;5.7749205;-3.7605076;-3.6140647;-2.4272738;IRRE
lv eps 0 01 adjust a mapping from calculated contour levels to color;1.4372901;0.85019743;-0.04188288;-4.907912;-1.525504;2.9234023;CODE
plot also the training points;3.8571665;-4.4865284;5.091605;-1.1665463;-2.758238;-0.3909035;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
add noise to targets;1.5080409;-0.466762;1.2343596;2.5179448;-0.38013557;2.7145147;TASK
construct the kernel based regression models;5.5370226;-4.829912;1.6157757;1.0128895;1.7319959;1.0890198;CODE
compare times of svr and kernel ridge regression;3.9595573;-2.7346544;-1.6093613;0.14884694;-3.4514675;2.9403505;IRRE
look at the results;2.5092244;-0.38132167;3.4986203;2.1920757;-0.2511635;-5.1504464;IRRE
the previous figure compares the learned model of krr and svr when both;3.5227926;-5.020329;-1.7052934;-0.22915322;-2.1711981;0.7894598;IRRE
complexity regularization and bandwidth of the rbf kernel are optimized using;3.2711608;-3.5486543;-3.0266106;-1.9917635;0.6486308;4.6550374;META
grid search the learned functions are very similar however fitting krr is;6.1738873;-3.267517;-2.1243916;-2.2585363;-1.2138417;0.70027596;CODE
approximately 3 4 times faster than fitting svr both with grid search;4.8789353;-1.3034734;-2.7473862;-1.492122;-2.0223684;3.0537145;-
prediction of 100000 target values could be in theory approximately three;6.8634367;-1.3415654;0.9509446;1.8186404;0.83658034;-1.8318471;IRRE
times faster with svr since it has learned a sparse model using only;4.5663443;-3.8127613;-2.7756443;0.92333746;-0.8298543;3.1653194;IRRE
approximately 1 3 of the training datapoints as support vectors however in;4.9689484;-3.5227385;-2.516735;-1.3446248;0.72820115;1.1376382;CODE
practice this is not necessarily the case because of implementation details;-2.335446;0.14262424;0.6624911;5.322924;5.065872;1.4188915;TASK
in the way the kernel function is computed for each model that can make the;2.9860923;-4.776667;-0.032626756;0.3333934;1.4931343;3.6996512;CODE
krr model as fast or even faster despite computing more arithmetic;3.6900756;-0.96349686;-2.1798544;-0.8535872;-2.836203;1.0028774;-
operations;-1.9267284;-0.45448324;6.6748886;-0.4861135;2.9013078;-4.003018;-
visualize training and prediction times;6.2843394;-6.104533;4.897274;1.0694413;-1.2383424;0.53638273;-
this figure compares the time for fitting and prediction of krr and svr for;5.113791;-3.9508817;-0.84043443;-0.68646014;-3.4891205;1.2568215;CODE
different sizes of the training set fitting krr is faster than svr for;4.1900787;-3.3228452;-3.9269433;-0.7960064;-1.3182671;3.3987126;IRRE
medium sized training sets less than a few thousand samples however for;5.728811;-1.3537403;-1.1050144;2.202794;0.31628877;-0.24270682;IRRE
larger training sets svr scales better with regard to prediction time svr;7.0770264;-3.8760517;-1.1839606;1.3378214;-0.5378147;3.7779317;IRRE
should be faster than krr for all sizes of the training set because of the;3.761439;-3.270766;-1.1532551;1.6515676;0.40093222;2.5881789;IRRE
learned sparse solution however this is not necessarily the case in practice;5.4020977;-3.3972657;-2.4385536;1.0419811;-0.14280292;3.6217575;CODE
because of implementation details note that the degree of sparsity and thus;1.7330151;-1.8164465;-2.3730016;-0.369614;1.0876427;2.649561;TASK
the prediction time depends on the parameters epsilon and c of the svr;4.4339113;-2.6508539;-2.717252;1.9813186;-2.0909476;2.2882342;IRRE
visualize the learning curves;5.135545;-7.275434;4.977915;-0.3931455;-1.8295524;-0.45227855;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
metadata routing is only available if explicitly enabled;-4.306386;-0.35841104;-2.4732268;1.5303398;-1.0781218;5.727445;-
this utility function is a dummy to check if a metadata is passed;-3.885259;2.979307;-4.5481696;4.105306;1.3030683;-0.52563447;CODE
a utility function to nicely print the routing information of an object;-0.3363343;-2.5047219;2.3020046;-1.3567563;2.5409029;1.6929438;CODE
consuming estimator;1.4402232;1.3859228;1.2097998;3.9164796;-0.9709425;2.7027655;-
here we demonstrate how an estimator can expose the required api to support;2.4364777;-4.7344737;1.0605979;4.274569;0.55441594;3.6268234;CODE
metadata routing as a consumer imagine a simple classifier accepting;1.1442424;-4.4282293;0.25286686;2.3409028;6.0310593;4.3098445;IRRE
sample weight as a metadata on its fit and groups in its;5.073886;-0.9811084;0.0049715578;1.6493009;3.589406;2.4349327;IRRE
predict method;5.83021;-1.3401557;2.7168152;4.0154014;-0.6976001;-2.0190487;-
all classifiers need to expose a classes attribute once they re fit;2.502858;-3.0704093;-3.9583786;2.620957;3.0984657;4.990372;IRRE
return a constant value of 1 not a very smart classifier;4.1989293;2.016741;-1.2713047;1.3146094;2.1614954;-3.5386066;IRRE
the above estimator now has all it needs to consume metadata this is;-0.10598364;-1.2079797;-2.1393416;3.4877858;-0.43311152;5.2485995;TASK
accomplished by some magic done in class base baseestimator there are;1.3468382;-1.3379483;1.1168224;0.28469878;3.6066582;1.8956431;CODE
now three methods exposed by the above class set fit request;3.406149;-0.57341045;-1.3153938;3.4173532;3.1976507;2.630023;IRRE
set predict request and get metadata routing there is also a;0.045180377;-2.210539;-0.14490336;4.245673;0.008953665;4.517839;IRRE
set score request for sample weight which is present since;2.8641617;4.087222;0.6863174;2.7099671;1.4145992;-0.72959816;CODE
class base classifiermixin implements a score method accepting;1.4099407;-2.644835;-4.6963058;3.026627;1.31554;0.47256806;IRRE
sample weight the same applies to regressors which inherit from;2.404143;1.922018;-1.975326;0.057719175;1.0358934;3.0851865;META
class base regressormixin;-0.3879018;-1.4993018;-4.052045;-0.8633838;0.37086082;3.252784;IRRE
by default no metadata is requested which we can see as;-6.8752556;-1.6341665;-2.418225;1.5436467;-0.84165365;4.194288;CODE
the above output means that sample weight and groups are not;2.3238485;2.4145901;-2.0472329;-1.0849857;-0.56614393;-2.3408623;IRRE
requested by exampleclassifier and if a router is given those metadata it;-0.11157883;-2.0479348;-2.874369;4.230126;5.311474;3.0041316;IRRE
should raise an error since the user has not explicitly set whether they are;-2.5630243;6.83211;-3.5209105;5.5129848;0.44176826;-2.7979689;TASK
required or not the same is true for sample weight in the score;2.2867239;3.4515784;-1.6547961;3.2572846;1.6433716;-0.73417294;CODE
method which is inherited from class base classifiermixin in order to;-0.63195723;-2.371796;-2.7988274;2.9158587;1.6251049;1.9121562;CODE
explicitly set request values for those metadata we can use these methods;-2.3062308;-0.13936833;-1.6575097;3.4897065;3.305531;5.857328;IRRE
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
please note that as long as the above estimator is not used in a;1.7388334;2.6670034;-0.64700586;2.40812;-2.111903;3.1085057;TASK
meta estimator the user does not need to set any requests for the;-1.237236;2.5962212;-1.1657097;6.035723;-2.7609289;4.9492764;CODE
metadata and the set values are ignored since a consumer does not;-1.426875;3.4360573;-2.644926;2.449471;1.0919878;1.9461745;IRRE
validate or route given metadata a simple usage of the above estimator;1.5244037;1.248456;-1.9267124;4.1509004;2.4099393;2.6346312;-
would work as expected;-3.6261547;1.707442;4.618827;1.2379826;0.45021847;-0.04871027;-
routing meta estimator;1.2474636;-0.063123204;0.71654516;2.2647157;-0.42615554;5.185247;-
now we show how to design a meta estimator to be a router as a simplified;1.3993685;-1.5374966;1.461628;3.4258995;1.5524828;4.930775;-
example here is a meta estimator which doesn t do much other than routing;2.090225;-1.2481184;0.8871879;3.3225632;-0.62879425;5.989385;CODE
the metadata;-2.7511394;-6.102347;3.5456793;1.517954;3.9818826;-1.3379785;-
this method defines the routing for this meta estimator;0.6397703;-1.3714145;0.91812;2.215556;0.92201227;4.917951;CODE
in order to do so a metadatarouter instance is created and the;-5.4177904;-1.8394806;-0.09358991;3.2393985;1.3008311;5.643996;TASK
routing is added to it more explanations follow below;-3.9269757;-1.7307231;4.6958084;-0.845316;-0.37783566;3.1849716;TASK
get routing for object returns a copy of the metadatarouter;-3.387203;-0.7963076;-1.2497057;2.548212;-0.8247512;4.8770943;CODE
constructed by the above get metadata routing method that is;-2.9146554;-1.9165225;-1.0752015;1.7264764;2.6200614;4.629361;CODE
internally called;-5.7590427;-0.35351074;3.5051138;2.9272785;1.4990382;0.09617902;IRRE
meta estimators are responsible for validating the given metadata;0.56279033;-0.7574517;-3.5370128;4.26598;0.7422391;1.7443993;CODE
method refers to the parent s method i e fit in this example;0.06370705;0.89048755;0.7645282;2.0529652;1.9135096;0.19851978;CODE
metadatarouter route params maps the given metadata to the metadata;-2.2102537;-1.1549516;0.12670332;0.55763155;1.0584359;5.915577;-
required by the underlying estimator based on the routing information;1.939416;0.16965078;0.52758175;2.167015;0.6588759;6.6930537;CODE
defined by the metadatarouter the output of type bunch has a key;-4.09006;-0.014237356;-3.2422702;1.0450505;1.2678132;2.9727077;IRRE
for each consuming object and those hold keys for their consuming;-0.82373273;-1.0863988;4.405319;1.2886316;5.1127872;1.034787;CODE
methods which then contain key for the metadata which should be;-1.7379956;-1.5486414;-0.95373297;1.3986067;4.7075386;2.1252337;CODE
routed to them;-3.0680873;-2.4206457;5.262836;0.099239126;0.3413009;2.497965;-
a sub estimator is fitted and its classes are attributed to the;3.7745035;-0.5603593;-0.55118614;1.7585069;1.7649672;3.0293205;IRRE
meta estimator;1.7135577;0.2744647;1.2494229;3.9200594;-0.78462017;1.4164535;-
as in fit we get a copy of the object s metadatarouter;-1.7146585;-3.998409;-1.4698027;2.4101448;1.1718013;5.5912976;IRRE
then we validate the given metadata;-0.67946494;0.22124782;-1.8836719;3.555462;4.857852;-1.2912089;-
and then prepare the input to the underlying predict method;4.8869557;-1.3696499;1.954864;3.712602;1.0118098;-0.37856013;CODE
let s break down different parts of the above code;-2.7912924;2.3323915;2.6633322;-2.5989861;1.9727149;-4.956736;CODE
first the meth utils metadata routing get routing for object takes our;-1.6376861;-2.1135757;0.06415605;0.2707993;0.39319006;3.2569752;CODE
meta estimator self and returns a;0.14857817;3.07212;-1.0332466;3.1905417;-1.9906832;1.7050458;CODE
class utils metadata routing metadatarouter or a;-2.9155638;-3.4938898;-1.3820784;1.74636;3.2943885;4.061036;IRRE
class utils metadata routing metadatarequest if the object is a consumer;-2.5946352;-0.5199375;-2.557411;3.1647024;3.0633767;4.6028895;CODE
based on the output of the estimator s get metadata routing method;0.7524805;-1.3316655;-0.8219194;2.2991354;0.98777723;5.2231207;IRRE
then in each method we use the route params method to construct a;-0.7587521;0.1682869;2.0013788;2.6550477;3.729791;3.6645248;CODE
dictionary of the form object name method name metadata;-2.4202697;-2.7877452;-2.2376997;0.52111495;2.8686502;2.149341;CODE
value to pass to the underlying estimator s method the object name;0.9072068;1.7946968;-0.6790982;3.0462;0.7472429;4.0363235;IRRE
estimator in the above routed params estimator fit example is the;0.74714303;1.4939291;0.18267882;-0.6113771;-1.9251877;6.0377107;CODE
same as the one added in the get metadata routing validate metadata;-3.6732836;-0.22328843;-3.2946622;2.9368513;2.7577865;2.668138;TASK
makes sure all given metadata are requested to avoid silent bugs;-3.8482583;-0.18692645;-3.8036506;6.3737245;1.914245;2.0026958;CODE
next we illustrate the different behaviors and notably the type of errors;-0.45831048;-0.5526744;1.3709142;4.414641;-0.76042753;-2.873887;-
raised;-2.9600315;-1.8210149;3.9522715;0.11989731;-0.2886347;-1.9953514;CODE
note that the above example is calling our utility function;-2.3559773;1.0792048;0.66842407;1.1224394;1.2058824;0.26889235;TASK
check metadata via the exampleclassifier it checks that;0.016232748;-0.58613044;-3.9531763;4.5114837;4.210033;-0.29293633;IRRE
sample weight is correctly passed to it if it is not like in the;2.7678735;4.351872;-2.1476245;2.396124;-0.74178654;0.5601634;CODE
following example it would print that sample weight is none;1.9962945;3.461108;-2.4105022;-1.0580765;-0.75282913;-2.1627185;CODE
if we pass an unknown metadata an error is raised;-2.891311;2.8693874;-4.7586336;5.313437;0.31459516;1.0396378;CODE
and if we pass a metadata which is not explicitly requested;-3.57022;0.94432706;-2.0584638;5.102444;3.4387624;4.0759835;TASK
also if we explicitly set it as not requested but it is provided;-6.8938694;0.6625976;-0.37735775;4.8545203;1.2319411;5.160029;IRRE
another concept to introduce is aliased metadata this is when an;-2.940668;-2.5748336;-0.17024876;1.6657423;6.928676;3.6134834;CODE
estimator requests a metadata with a different variable name than the default;-1.3154855;1.7995155;-3.194074;2.7665048;-0.2910252;5.0442924;CODE
variable name for instance in a setting where there are two estimators in a;1.1146502;1.4678411;1.471646;1.4147614;3.1776936;3.471044;IRRE
pipeline one could request sample weight1 and the other;1.4482448;1.836005;-0.5153459;2.2923236;2.7142048;2.2567587;CODE
sample weight2 note that this doesn t change what the estimator expects;2.0013816;2.261425;-2.6019347;2.0412765;-2.5842612;2.6024194;CODE
it only tells the meta estimator how to map the provided metadata to what is;-1.4087256;-0.95727813;-2.6355383;1.7965759;-0.37281796;4.2942457;-
required here s an example where we pass aliased sample weight to the;4.554089;1.9810128;-1.3400266;-0.5417364;2.0495129;2.9426765;CODE
meta estimator but the meta estimator understands that;-0.036990467;0.28911236;-0.75681984;4.7617707;-1.4179585;2.6386662;META
aliased sample weight is an alias for sample weight and passes it as;2.8341787;1.2629653;-2.0909235;0.641074;1.5372546;3.0427275;CODE
sample weight to the underlying estimator;3.1032903;1.0800955;-0.078900404;2.8968868;-0.16052848;3.956725;-
passing sample weight here will fail since it is requested with an;2.1572397;4.9937387;-2.1065304;2.6829858;0.8046708;0.32177228;CODE
alias and sample weight with that name is not requested;-0.7821755;2.58703;-3.02612;1.2086617;1.0025512;1.9931054;CODE
this leads us to the get metadata routing the way routing works in;-2.935499;-2.349328;-0.45275164;2.1937194;1.5735321;5.7133927;CODE
scikit learn is that consumers request what they need and routers pass that;-0.9183206;-8.134682;-0.76272494;3.3904347;-0.45003012;0.42607647;CODE
along additionally a router exposes what it requires itself so that it can;-1.6549186;-2.0689993;3.2377336;1.8991337;1.6742526;5.0350547;CODE
be used inside another router e g a pipeline inside a grid search object;-0.6115215;-0.118289374;1.5098754;1.7380389;1.4961611;4.714561;CODE
the output of the get metadata routing which is a dictionary;-2.3276012;-2.5901432;-1.5570592;0.6050588;0.88761467;2.0256047;IRRE
representation of a class utils metadata routing metadatarouter includes;-2.5637715;-3.4596612;-2.594223;1.5017004;4.01255;4.283003;CODE
the complete tree of requested metadata by all nested objects and their;-1.0230854;-2.6118298;0.5339399;3.1538339;6.15852;2.3737671;CODE
corresponding method routings i e which method of a sub estimator is used;1.9478773;-0.56935114;1.4280967;1.4496733;0.6784665;4.1183686;CODE
in which method of a meta estimator;0.9619511;-0.37977248;0.82735485;4.8081193;0.15971172;2.7480192;CODE
as you can see the only metadata requested for method fit is;-1.3473585;-1.2129078;-4.457776;3.8931212;0.25632024;3.5553904;CODE
sample weight with aliased sample weight as the alias the;3.9333985;2.1885388;-1.206203;-0.11724992;1.2068875;3.0262136;-
utils metadata routing metadatarouter class enables us to easily create;-3.5097187;-3.8001206;-1.1599904;1.0245885;1.73768;5.1292524;IRRE
the routing object which would create the output we need for our;-0.9835206;-0.5486559;3.706193;-1.508159;2.0421076;1.7155219;IRRE
get metadata routing;-2.3260825;-1.8688512;0.571401;0.6660823;1.4509593;3.937876;-
in order to understand how aliases work in meta estimators imagine our;1.0424534;-0.5352648;0.07816511;2.4034066;0.4086387;3.9687414;-
meta estimator inside another one;1.6125062;2.335673;0.37278163;3.971564;-0.4037695;3.6418996;-
in the above example this is how the fit method of meta meta est;1.2300355;0.5329889;1.1078709;1.4677601;0.5373572;2.1924393;CODE
will call their sub estimator s fit methods;4.0971212;-1.3081329;-0.6223408;3.4273806;0.06879512;3.909038;IRRE
user feeds my weights as aliased sample weight into meta meta est;1.8896408;0.54031223;-1.5685909;2.1159923;-0.12126287;4.131136;CODE
meta meta est fit x y aliased sample weight my weights;2.6728995;1.9197905;-1.1112479;1.0653608;-0.65522736;3.5820193;-
the first sub estimator meta est expects aliased sample weight;1.3545116;2.3844569;-4.0235925;1.9510156;-1.7825029;3.604278;-
self estimator fit x y aliased sample weight aliased sample weight;3.863044;1.9463108;-3.0705864;0.63742286;-2.8458855;5.1047673;CODE
the second sub estimator est expects sample weight;1.5634627;2.742233;-2.2050922;1.5343475;-1.5678483;2.0766873;-
self estimator fit x y sample weight aliased sample weight;3.8340368;2.0975423;-2.730562;0.7482528;-3.0154316;4.495767;CODE
consuming and routing meta estimator;1.1346183;-0.046135027;0.44149154;3.6110048;0.68112713;6.1090627;-
for a slightly more complex example consider a meta estimator that routes;1.9373044;0.92057836;1.8488346;4.1321244;0.14283082;5.1022644;META
metadata to an underlying estimator as before but it also uses some metadata;-0.503083;-1.0020463;-2.3307195;2.7779253;0.80286765;6.516584;META
in its own methods this meta estimator is a consumer and a router at the;0.5525652;-1.3211356;1.0278094;4.1560616;1.0862238;4.596953;IRRE
same time implementing one is very similar to what we had before but with a;-2.3862717;-2.624581;2.2219043;3.7792816;3.8575072;2.4490597;TASK
few tweaks;-3.152494;-4.1790357;3.4071486;2.9864511;-0.6087102;1.2713984;-
defining metadata routing request values for usage in the meta estimator;-0.62422955;0.03763568;-1.30921;1.7038211;2.1300242;6.2962146;CODE
defining metadata routing request values for usage in the sub estimator;0.43179464;0.3976398;-1.1636671;1.4395664;2.1867483;6.5463815;CODE
since sample weight is used and consumed here it should be defined as;0.9765176;2.163337;-0.027123755;1.8222737;2.2010324;0.98368627;CODE
an explicit argument in the method s signature all other metadata which;-2.8231108;-0.2064416;-4.859089;3.378903;4.2564883;2.6380758;CODE
are only routed will be passed as fit params;-1.3148;3.2373;-1.3279655;1.7068055;1.2151669;6.6621804;-
we add sample weight to the fit params dictionary;5.399932;-0.77395827;-1.4305972;0.18978871;1.2500858;2.7459645;TASK
as in fit we get a copy of the object s metadatarouter;-1.7146585;-3.998409;-1.4698027;2.4101448;1.1718013;5.5912976;IRRE
we validate the given metadata;-0.39396182;0.038645815;-1.5030874;3.0619292;4.8156223;-2.6862044;-
and then prepare the input to the underlying predict method;4.8869557;-1.3696499;1.954864;3.712602;1.0118098;-0.37856013;CODE
the key parts where the above meta estimator differs from our previous;0.79049456;-0.252571;-0.51304835;4.563658;-2.1436613;3.1941488;CODE
meta estimator is accepting sample weight explicitly in fit and;1.0752283;1.9915265;-4.273617;3.0162172;-2.5467436;3.9894605;-
including it in fit params since sample weight is an explicit;3.7006881;2.3401043;-3.0577688;1.7400311;0.4926878;3.4780293;-
argument we can be sure that set fit request sample weight is;4.206914;2.7335842;-2.7032015;4.765573;0.5000953;3.5969923;IRRE
present for this method the meta estimator is both a consumer as well as a;0.9669866;0.5656343;0.25576133;4.197205;1.2346172;2.6593575;CODE
router of sample weight;3.3113415;1.5013857;0.41324344;0.30377942;0.50316495;3.1325665;-
in get metadata routing we add self to the routing using;-3.989726;-0.95502836;-0.17629027;0.7609647;0.68540883;5.6431537;TASK
add self request to indicate this estimator is consuming;-0.3697316;2.8595026;0.74627167;4.956533;-1.5433459;3.9164414;CODE
sample weight as well as being a router which also adds a;1.3230945;-0.8955377;2.0070121;1.783651;2.6974947;1.9369633;TASK
self request key to the routing info as illustrated below now let s;-4.486026;-0.82554513;2.4924135;-1.3644735;0.24120262;3.1075985;CODE
look at some examples;-0.3091465;-2.6502426;3.7954066;1.3324547;1.7279637;-2.8795052;-
no metadata requested;-6.4663877;-1.35594;-1.6652911;0.3995785;-1.435104;0.5370949;CODE
sample weight requested by sub estimator;2.7444897;2.3182225;-1.0522352;1.6585789;-0.47522762;2.96764;CODE
sample weight requested by meta estimator;1.793266;1.7558775;-1.6102785;3.1684623;-0.7407117;2.8104763;CODE
note the difference in the requested metadata representations above;-3.7202222;-4.6047482;-2.7926247;0.49053198;2.5664759;3.5724883;CODE
we can also alias the metadata to pass different values to the fit methods;4.1954803;-0.52304363;-1.5470219;2.2004323;2.925224;6.2424374;IRRE
of the meta and the sub estimator;0.81723833;-0.6100829;1.6048945;4.1854553;0.21580595;2.6340618;-
however fit of the meta estimator only needs the alias for the;0.28174207;1.7836666;-3.2601054;2.5594597;-1.6957533;6.3445444;TASK
sub estimator and addresses their own sample weight as sample weight since;2.4715953;1.3756046;-1.0203335;2.4422994;0.4564604;2.6380515;TASK
it doesn t validate and route its own required metadata;-5.515895;0.4299374;-4.508416;3.0208025;1.0447886;2.438752;CODE
alias only on the sub estimator;0.90095073;2.7348936;-0.5730323;2.2239556;-0.6384595;5.271554;-
this is useful when we don t want the meta estimator to use the metadata but;-1.3335664;-1.5321721;-1.2189394;4.512092;0.22151975;5.6664977;CODE
the sub estimator should;2.2417443;1.8332872;0.87019473;3.3568628;-1.4142087;2.7982302;-
the meta estimator cannot use aliased sample weight because it expects;1.2309736;2.4362013;-4.6264443;2.2751312;-1.8189728;4.237243;-
it passed as sample weight this would apply even if;2.0986826;3.9345367;-1.4787186;3.9680436;1.355858;1.3002981;CODE
set fit request sample weight true was set on it;1.6557752;3.0755749;-2.2260747;2.8591647;-2.409149;3.5674822;IRRE
simple pipeline;0.3208496;-0.43838525;2.7833757;0.0737484;1.2781886;-0.9235487;CODE
a slightly more complicated use case is a meta estimator resembling a;2.164303;-1.2419385;0.4909849;5.5243764;2.1567943;2.9012551;CODE
class pipeline pipeline here is a meta estimator which accepts a;1.8344698;-0.5849956;-2.6805139;3.6596568;2.0962975;2.1232038;CODE
transformer and a classifier when calling its fit method it applies the;3.460956;0.24547303;-1.8519393;1.9361321;0.034126136;3.0215092;IRRE
transformer s fit and transform before running the classifier on the;2.969136;-0.72065884;-0.86106396;1.4478028;0.9853777;3.424345;CODE
transformed data upon predict it applies the transformer s transform;2.9940834;-0.7128872;0.63997936;0.39633077;-1.4182807;3.8138742;CODE
before predicting with the classifier s predict method on the transformed;2.7850873;-2.3595884;-1.0313601;2.931488;-0.7756839;3.5914767;CODE
new data;3.1077406;-1.1326772;4.634708;-0.0461328;2.6068125;-2.6628804;CODE
we add the routing for the transformer;-3.3164766;-2.546912;3.8610666;-1.1510806;-0.008207048;4.787869;CODE
the metadata is routed such that it retraces how;-4.200159;-1.5530435;1.470991;1.6645976;1.3391197;5.963016;-
simplepipeline internally calls the transformer s fit and;-1.469516;0.3412206;-0.33843565;-0.5365978;-0.5689563;4.9688673;CODE
transform methods in its own methods fit and predict;6.0023518;-3.4678557;0.14734411;3.0985794;-0.89340097;3.4325647;IRRE
we add the routing for the classifier;1.4725846;-5.656198;0.6495432;2.0464506;4.6679797;3.6976705;CODE
note the usage of class utils metadata routing methodmapping to;-2.7455285;-3.8099334;-2.4798794;2.8640232;2.620239;5.3075995;TASK
declare which methods of the child estimator callee are used in which;0.82370114;1.5559933;-0.06846989;2.684363;4.056292;2.4993963;IRRE
methods of the meta estimator caller as you can see simplepipeline uses;0.51711667;-1.2544025;-1.0405736;3.480351;-0.32287088;4.122947;IRRE
the transformer s transform and fit methods in fit and its;2.9151924;-0.84718823;1.5653585;-0.2452088;0.079824425;3.2863607;CODE
transform method in predict and that s what you see implemented in;3.6732094;-3.4913473;0.46541762;0.9923056;-0.61233383;2.2173195;TASK
the routing structure of the pipeline class;-0.48012018;-3.1228354;1.1892543;0.99569505;3.491172;3.3959165;CODE
another difference in the above example with the previous ones is the usage;-0.8715382;0.346704;0.85139406;1.7797514;1.2580059;0.7279791;CODE
of func utils metadata routing process routing which processes the input;-2.9422975;-2.8934639;0.17564598;1.547097;2.2078218;2.944228;CODE
parameters does the required validation and returns the routed params;-1.453696;2.9474924;-0.39478767;2.5222206;1.5949278;3.198532;CODE
which we had created in previous examples this reduces the boilerplate code;-3.0426197;-2.094541;0.21329075;2.5436711;4.5394983;1.345529;IRRE
a developer needs to write in each meta estimator s method developers are;-1.3723663;-3.932874;-1.9309391;4.881346;-0.30834773;1.251104;TASK
strongly recommended to use this function unless there is a good reason;0.7702919;2.3785717;2.8397763;2.1906142;-0.20644656;-0.039981052;CODE
against it;-0.9227929;-0.5493115;3.7296433;3.485014;-0.8680877;-1.1677324;-
in order to test the above pipeline let s add an example transformer;-0.649238;3.1864028;-1.1785609;2.0309038;-0.60061795;-1.7780198;CODE
note that in the above example we have implemented fit transform which;5.0372677;0.9970148;0.37576377;-2.6777976;-1.5842791;5.8335047;TASK
calls fit and transform with the appropriate metadata this is only;0.37477887;0.32156038;-2.360503;0.7590814;1.6098462;4.8209066;CODE
required if transform accepts metadata since the default fit transform;0.30912954;2.5318544;-4.577635;0.027397934;-0.11084058;5.8072114;CODE
implementation in class base transformermixin doesn t pass metadata to;-3.1372578;-1.229536;-4.8567104;1.2715235;-0.86801606;4.6472263;CODE
transform;0.119849384;-0.7246064;5.7246265;-4.0461097;-0.9593361;-1.0896541;CODE
now we can test our pipeline and see if metadata is correctly passed around;-3.1055443;0.21761481;-4.5252604;6.2648005;1.5268217;0.2050881;IRRE
this example uses our simplepipeline our exampletransformer and our;-2.5830288;-0.24332054;1.403083;-1.6355634;0.2704733;2.6437614;CODE
routerconsumerclassifier which uses our exampleclassifier;-0.1045081;-2.3914876;-1.8822662;0.84203136;5.377783;2.1783767;IRRE
we set transformer s fit to receive sample weight;3.5649257;2.2884185;0.30246824;0.45038974;-0.25887534;3.8831882;IRRE
we set transformer s transform to receive groups;-0.58872896;0.0008466939;2.7262585;-1.4891032;2.0491164;3.5687275;CODE
we want this sub estimator to receive sample weight in fit;3.937182;1.1655235;-0.08832038;1.3119458;-0.33571786;2.4341345;CODE
but not groups in predict;3.2264526;-1.401827;0.5108878;2.7572446;-0.3129747;-1.836987;META
and we want the meta estimator to receive sample weight as well;1.9075677;-0.61249393;-0.9353314;4.7290235;0.3197612;3.9622674;-
deprecation default value change;-2.3489642;4.1832285;-1.101465;1.3911947;-1.0962481;2.641705;IRRE
in this section we show how one should handle the case where a router becomes;-3.0822985;0.60204476;3.1196706;1.8636996;2.3126621;3.7196946;CODE
also a consumer especially when it consumes the same metadata as its;-1.3578372;-2.2210152;1.0685282;3.310697;3.2819302;3.655861;-
sub estimator or a consumer starts consuming a metadata which it wasn t in;0.015854;1.8905181;-2.3696072;4.2988067;-0.6092703;4.2061257;-
an older release in this case a warning should be raised for a while to;-4.420919;-0.76530904;-1.4080521;6.5026727;-0.9504427;0.74881107;CODE
let users know the behavior is changed from previous versions;-3.0580714;0.39096278;1.7085007;5.8169675;-0.7668352;2.1786115;CODE
as explained above this is a valid usage if my weights aren t supposed;-0.06931132;1.2727106;0.1735704;2.576055;-0.52072734;2.58976;CODE
to be passed as sample weight to metaregressor;2.019026;2.899691;-2.5552287;3.2015219;1.0594085;3.2303858;-
now imagine we further develop metaregressor and it now also consumes;-3.2268322;-1.4420794;2.96311;4.3727784;-0.29433772;2.9304347;IRRE
sample weight;4.0873704;1.7719023;2.1019504;1.0490122;0.65234363;-2.1117196;-
show warning to remind user to explicitly set the value with;-2.6410358;4.8252845;0.13240877;4.326077;-1.1985868;0.39146346;IRRE
set method request sample weight boolean;2.0131238;4.9282384;-1.9279218;4.4970894;2.2688477;0.8384917;CODE
the above implementation is almost the same as metaregressor and;-1.1827362;0.027630368;-0.9012748;2.2791026;1.8994484;3.3959389;TASK
because of the default request value defined in metadata request fit;-2.231558;2.322294;-3.4803908;2.1664493;-1.05578;6.259449;CODE
there is a warning raised when fitted;-2.3436315;2.1222723;-1.4492491;2.7627845;-2.0868719;1.7520028;CODE
when an estimator consumes a metadata which it didn t consume before the;-0.22646838;2.9059508;-1.3776151;5.3612084;-1.4915398;4.5712714;CODE
following pattern can be used to warn the users about it;-2.915489;2.3818772;2.0865054;4.6954045;2.7466996;-0.76507586;OUTD
at the end we disable the configuration flag for metadata routing;-4.9244604;-0.34461844;-2.2304597;1.9984857;-0.81904763;6.315665;CODE
third party development and scikit learn dependency;-2.5169814;-11.959299;-4.1078053;2.2788534;-1.6159558;-2.8187463;CODE
as seen above information is communicated between classes using;-2.0654767;-4.224665;1.3791004;1.0464276;6.904411;0.65498376;CODE
class utils metadata routing metadatarequest and;-4.02656;-2.8432088;-2.732947;2.0933375;2.5334718;3.990543;CODE
class utils metadata routing metadatarouter it is strongly not advised;-3.3384693;-2.5144806;-2.476797;2.1777678;1.8428077;5.277306;IRRE
but possible to vendor the tools related to metadata routing if you strictly;-2.8408854;-4.745389;-0.4053735;1.0360465;3.3720167;5.432178;CODE
want to have a scikit learn compatible estimator without depending on the;4.4907393;-7.081647;-4.0222635;2.2582219;-3.5049253;-0.17400204;TASK
scikit learn package if all of the following conditions are met you do not;1.49835;-5.4492707;-4.1674633;1.3060697;-1.8032827;-6.293219;CODE
need to modify your code at all;-4.7737803;1.543575;3.254707;-0.6434004;0.035728827;-1.9046606;TASK
your estimator inherits from class base baseestimator;0.99217;1.2628596;-3.008124;1.8637675;-0.71820354;4.3945966;CODE
the parameters consumed by your estimator s methods e g fit are;4.183746;0.3297807;-0.9886432;3.318964;-2.1293716;4.2321825;IRRE
explicitly defined in the method s signature as opposed to being;-3.120901;0.94851094;-4.3081574;2.8880339;2.5687416;3.0721326;CODE
args or kwargs;-1.7332801;-1.893811;3.0015862;1.9407401;0.44239536;0.30250344;IRRE
your estimator does not route any metadata to the underlying objects i e;-0.097188674;0.35387737;-3.1035056;2.6123257;-2.5139966;4.7596374;CODE
it s not a router;-3.736537;-1.1481999;2.3687098;-1.1162955;-0.7387164;0.8053862;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
get the separating hyperplane;2.5293767;0.05700953;1.0520486;-4.999097;0.755174;2.0702198;-
xx np linspace min x 5 max x 5 make sure the line is long enough;-0.328235;2.434051;-1.5151011;-8.118092;-3.0780709;-1.2729316;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
load the faces datasets;1.7787753;-3.721451;0.9385367;-1.9884355;-0.31935182;2.6212265;IRRE
test data targets 30 test on independent people;3.066158;2.2690942;-0.17519335;3.9212978;0.84703994;-4.9880424;IRRE
test on a subset of people;4.0450153;3.6930583;2.5625427;4.1398997;2.6104398;-6.7001987;IRRE
upper half of the faces;-2.2626085;-0.2023581;5.444248;-3.6895456;0.0791815;-1.0753254;-
lower half of the faces;-1.8161114;0.44378877;4.6841145;-3.563613;-0.5399693;-0.3725606;-
fit estimators;5.140086;-0.45757875;1.4378445;1.8025403;-2.662266;3.530698;IRRE
plot the completed faces;0.346679;-0.67992806;6.8234;-4.001233;-2.4787307;-0.13616388;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset preprocessing and model training;4.8563356;-4.96827;-0.07288463;3.224823;2.6148303;0.03796594;IRRE
different outlier detection models require different preprocessing in the;3.0152776;0.21635073;-3.5000598;3.277217;-0.48095685;2.3124847;CODE
presence of categorical variables;0.08955753;1.9273193;-0.22347021;-0.640067;2.5613203;-1.7679688;IRRE
class sklearn preprocessing ordinalencoder is often a good strategy for;2.675002;-4.5022683;-3.7732623;-1.9658083;2.4040964;-1.4491942;CODE
tree based models such as class sklearn ensemble isolationforest whereas;3.1568563;-7.0022216;-3.593756;3.7798562;2.9123013;0.76699376;CODE
neighbors based models such as class sklearn neighbors localoutlierfactor;5.461092;-5.251422;-3.0365372;0.79044694;0.72697073;3.2759495;IRRE
would be impacted by the ordering induced by ordinal encoding to avoid;0.4829952;1.4560297;-0.29494825;-0.957135;4.996521;1.3766416;CODE
inducing an ordering on should rather use;0.6608932;0.58942276;2.4259853;2.83568;4.201562;0.7629447;CODE
class sklearn preprocessing onehotencoder;0.33671498;-3.9270613;-4.5918436;-0.7198016;-1.085464;-0.17116986;IRRE
neighbors based models may also require scaling of the numerical features see;6.3829474;-3.749676;-1.7669921;-0.5326595;-0.31484708;5.495048;TASK
for instance ref neighbors scaling in the presence of outliers a good;6.1665115;-1.2305607;0.80044675;2.8786972;-1.1719232;3.639081;CODE
option is to use a class sklearn preprocessing robustscaler;4.2278013;-2.6156185;-5.334985;-1.3412386;-5.152589;4.593987;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
train models on the diabetes dataset;5.406046;-2.870045;0.92003804;1.8789443;1.6538483;0.3804345;IRRE
first we train a decision tree and a multi layer perceptron on the diabetes;4.5568275;-3.6340249;1.2474433;2.5157614;3.1990426;0.30711567;-
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
plotting partial dependence for two features;2.7282326;-1.1014936;3.4703205;-3.523994;-1.8360627;1.6110471;CODE
we plot partial dependence curves for features age and bmi body mass;3.9184477;-1.8073235;2.0833485;-1.834168;-2.489547;2.278983;CODE
index for the decision tree with two features;2.112684;-1.1300795;-0.033325024;-2.5919695;4.2010093;-0.906646;TASK
func sklearn inspection partialdependencedisplay from estimator expects to plot;0.8860405;-0.025056057;-4.835638;1.849454;-6.61355;1.9682139;CODE
two curves here the plot function place a grid of two plots using the space;1.8314006;0.791912;4.942725;-4.1992693;-5.7842474;2.0226476;CODE
defined by ax;0.6016841;0.4519365;0.3074898;-3.2562122;1.9305303;0.94814277;CODE
the partial dependence curves can be plotted for the multi layer perceptron;4.170386;-4.729094;1.3332328;-0.4331554;-2.6486962;2.4400418;CODE
in this case line kw is passed to;-2.7122846;1.4283848;0.7501385;0.49788016;1.5422187;0.70756495;CODE
func sklearn inspection partialdependencedisplay from estimator to change the;1.8038912;-0.13076185;-4.9833584;4.183099;-2.61675;2.1726062;CODE
color of the curve;-1.3485758;-0.5774108;4.8685365;-2.4612489;-2.6061525;-1.5023569;-
plotting partial dependence of the two models together;1.5097057;-0.8458248;3.5862973;-0.4861313;-2.7281344;2.9023147;CODE
the tree disp and mlp disp;1.349627;-2.7545593;-0.22674075;0.27988386;3.8326051;-0.23206995;-
class sklearn inspection partialdependencedisplay objects contain all the;-1.2270542;-0.7149896;-5.1268044;2.209022;1.7805548;-1.9761336;CODE
computed information needed to recreate the partial dependence curves this;3.3873377;-1.5992064;0.18888038;-1.4264783;-0.4733614;2.9816306;CODE
means we can easily create additional plots without needing to recompute the;-0.9631661;-4.0383105;3.5761797;0.7610775;-2.1030943;3.3424873;TASK
curves;0.99191177;-1.5341109;6.932674;-3.3817167;-3.4643686;-1.7690781;-
one way to plot the curves is to place them in the same figure with the;1.0609167;-1.1096102;6.5121164;-3.7787526;-4.964488;1.65909;CODE
curves of each model on each row first we create a figure with two axes;3.8508425;-1.1962664;6.0342436;-4.497618;-2.6333418;3.246584;IRRE
within two rows and one column the two axes are passed to the;2.387269;3.7272925;3.2693307;-7.397689;-2.0485904;-0.19526939;CODE
func sklearn inspection partialdependencedisplay plot functions of;0.8307795;-2.006323;-2.185551;0.008203688;-3.9121978;-0.08733939;CODE
tree disp and mlp disp the given axes will be used by the plotting;2.58408;-0.28392923;1.1803038;-5.2278104;-1.8123491;2.1618078;-
function to draw the partial dependence the resulting plot places the;1.697541;0.33079207;4.7465925;-3.936474;-3.905435;1.6128387;CODE
decision tree partial dependence curves in the first row of the;4.5070553;-2.4877646;-0.7903432;-0.98647064;2.6649776;2.4359217;CODE
multi layer perceptron in the second row;4.2832093;0.63765126;1.0298805;-2.607307;-0.13373789;1.6782489;CODE
another way to compare the curves is to plot them on top of each other here;3.1657076;1.9672292;4.059863;-2.2467442;-4.555286;-1.3436486;IRRE
we create a figure with one row and two columns the axes are passed into the;2.0662408;0.07499901;6.8796453;-7.0924067;-2.1351144;1.3914837;IRRE
func sklearn inspection partialdependencedisplay plot function as a list;1.6164374;-0.6023933;-1.5096115;-0.21368004;-3.0028417;-0.35744405;CODE
which will plot the partial dependence curves of each model on the same axes;2.4114065;-2.3301568;3.9032748;-1.2981684;-2.4230034;4.180519;CODE
the length of the axes list must be equal to the number of plots drawn;1.968785;2.0561395;3.6327198;-4.80383;-5.028716;0.9293893;TASK
sphinx gallery thumbnail number 4;-4.1622796;-1.045713;0.69986063;-2.7914124;0.088549845;0.91196156;-
tree disp axes is a numpy array container the axes used to draw the;1.2434804;-2.9430203;1.4620155;-7.495007;-3.253268;0.91467535;OUTD
partial dependence plots this can be passed to mlp disp to have the same;2.9092023;-0.31587914;-0.2202406;-0.75260305;1.021135;3.7872968;CODE
affect of drawing the plots on top of each other furthermore the;-0.21860819;0.056274366;7.973666;-2.1894217;-4.300491;2.477508;-
mlp disp figure stores the figure which allows for resizing the figure;1.0738609;-0.7203755;1.8823117;-2.741099;-1.3837496;5.0686812;CODE
after calling plot in this case tree disp axes has two dimensions thus;0.3120253;1.1319321;-0.4728641;-5.8586984;-4.8994665;2.9748986;CODE
plot will only show the y label and y ticks on the left most plot;0.32438597;1.6018201;3.2565045;-4.407682;-5.7387357;0.3008288;-
plotting partial dependence for one feature;3.0843093;-0.9627973;3.7272089;-3.5106623;-1.5580039;2.0028734;CODE
here we plot the partial dependence curves for a single feature age on;3.1927114;-3.3352282;1.6704854;-1.7071465;-1.3143855;1.8657886;CODE
the same axes in this case tree disp axes is passed into the second;-0.51476747;1.4749539;2.0598881;-4.97284;-0.6651729;1.8145343;CODE
plot function;0.5058855;1.0418826;6.364498;-4.795493;-6.017456;-2.3967426;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
displaying a pipeline with a preprocessing step and classifier;1.0613782;-2.5643165;-0.165745;1.6616548;2.8443894;1.4137149;CODE
this section constructs a class sklearn pipeline pipeline with a preprocessing;-0.39222503;-5.992127;-4.103612;1.0493969;1.1384485;0.72597975;CODE
step class sklearn preprocessing standardscaler and classifier;2.2743518;-3.56946;-6.234935;1.1751573;-0.5427549;1.1407435;IRRE
class sklearn linear model logisticregression and displays its visual;2.1854732;-4.664885;-1.7793406;-1.8286543;-2.9196131;0.42482898;IRRE
representation;-0.7608903;-2.367999;4.962392;-1.9334484;2.9168937;-1.2665551;-
to visualize the diagram the default is display diagram;-3.661887;-2.5101082;5.8421407;-3.2789178;-1.6039315;2.4094806;CODE
pipe click on the diagram below to see the details of each step;-2.2994797;-1.1409965;4.7484694;-2.29101;0.69580203;0.031790152;CODE
to view the text pipeline change to display text;-3.6325123;-0.44090402;2.2260137;0.8303787;-1.3408334;1.4937955;CODE
put back the default display;-4.7741423;2.6174583;4.5145454;-0.80444026;-2.917957;4.739694;CODE
displaying a pipeline chaining multiple preprocessing steps classifier;1.26682;-1.6573821;-0.1299347;1.4897715;3.591674;1.4070553;CODE
this section constructs a class sklearn pipeline pipeline with multiple;-0.7274741;-4.3718524;-3.710677;0.48336312;2.4904678;0.702277;CODE
preprocessing steps class sklearn preprocessing polynomialfeatures and;1.081307;-4.7194953;-4.7663813;-0.22616544;-0.8227172;-0.22723494;TASK
class sklearn preprocessing standardscaler and a classifier step;2.4642272;-4.307797;-5.8372297;1.7112921;-0.4055903;1.0186439;IRRE
class sklearn linear model logisticregression and displays its visual;2.1854732;-4.664885;-1.7793406;-1.8286543;-2.9196131;0.42482898;IRRE
representation;-0.76088876;-2.3680007;4.962392;-1.9334469;2.9168952;-1.2665561;-
pipe click on the diagram below to see the details of each step;-2.2994797;-1.1409965;4.7484694;-2.29101;0.69580203;0.031790152;CODE
displaying a pipeline and dimensionality reduction and classifier;3.8183029;-4.4419055;0.4633196;-1.2632025;3.862038;1.5885596;CODE
this section constructs a class sklearn pipeline pipeline with a;-0.78627634;-6.05218;-3.9856992;0.6913107;1.6280658;0.29099032;CODE
dimensionality reduction step class sklearn decomposition pca;5.087719;-4.788929;-5.3975477;-2.7872562;0.50619763;2.7610307;IRRE
a classifier class sklearn svm svc and displays its visual;2.1474001;-5.589023;-2.2480323;-2.5543227;-0.22710125;0.651391;IRRE
representation;-0.7608903;-2.367999;4.962392;-1.9334484;2.9168937;-1.2665551;-
pipe click on the diagram below to see the details of each step;-2.2994797;-1.1409965;4.7484694;-2.29101;0.69580203;0.031790152;CODE
displaying a complex pipeline chaining a column transformer;1.3051888;-0.108637355;1.6906911;-3.9655733;0.36882332;3.1075869;CODE
this section constructs a complex class sklearn pipeline pipeline with a;0.20918563;-5.9440494;-3.544618;0.52013606;2.3012495;0.35993415;CODE
class sklearn compose columntransformer and a classifier;3.2171595;-4.6792665;-5.099394;-0.74963075;1.6821637;0.74116635;IRRE
class sklearn linear model logisticregression and displays its visual;2.1854732;-4.664885;-1.7793406;-1.8286543;-2.9196131;0.42482898;IRRE
representation;-0.76088876;-2.3680007;4.962392;-1.9334469;2.9168952;-1.2665561;-
pipe click on the diagram below to see the details of each step;-2.2994797;-1.1409965;4.7484694;-2.29101;0.69580203;0.031790152;CODE
displaying a grid search over a pipeline with a classifier;3.9861362;-2.2561166;0.0016547678;0.5263323;3.052698;1.5266508;CODE
this section constructs a class sklearn model selection gridsearchcv;3.5276892;-5.80299;-4.3668113;-0.30385566;0.69834703;0.7520367;CODE
over a class sklearn pipeline pipeline with;1.5254755;-4.722132;-4.196538;2.1236;0.7106156;0.89980114;CODE
class sklearn ensemble randomforestclassifier and displays its visual;1.734824;-5.682549;-2.642625;0.6641503;-0.57663083;-0.076605216;IRRE
representation;-0.76088876;-2.3680007;4.962392;-1.9334469;2.9168952;-1.2665561;-
grid search click on the diagram below to see the details of each step;-0.027255239;-1.1175092;5.825402;-4.865231;1.1255177;1.0773454;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load data and train a svc;4.4349923;-3.5300906;0.14998183;-0.54584837;1.2407444;1.67649;TASK
first we load the wine dataset and convert it to a binary classification;2.286143;-5.3854613;-0.46732128;-0.7802237;4.0817122;-1.9180888;IRRE
problem then we train a support vector classifier on a training dataset;4.849414;-3.3662274;-2.2801368;0.7702201;2.4357364;0.31389385;IRRE
plotting the roc curve;3.057204;-2.628726;2.531946;-4.159738;-3.3150175;-1.8895036;-
next we plot the roc curve with a single call to;3.8018858;-2.9039698;2.7562797;0.67623585;-0.489648;-1.3751928;IRRE
func sklearn metrics roccurvedisplay from estimator the returned;3.3411994;-3.8073344;-5.5343866;2.0214827;-3.073258;1.0686134;CODE
svc disp object allows us to continue using the already computed roc curve;1.7263906;-3.2407184;-3.2927604;1.2173015;0.9892984;2.6319976;CODE
for the svc in future plots;2.3487313;-5.990747;2.247267;-1.1737128;-2.766475;1.5829426;CODE
training a random forest and plotting the roc curve;4.027037;-6.305779;0.49861035;0.0697352;0.21850994;-1.6686804;IRRE
we train a random forest classifier and create a plot comparing it to the svc;5.7893143;-6.252526;0.55048895;1.6435149;0.6094305;-1.7310168;IRRE
roc curve notice how svc disp uses;1.749274;-3.391135;-3.094371;0.29527515;0.13249284;-0.07879816;-
func sklearn metrics roccurvedisplay plot to plot the svc roc curve;3.6322758;-5.4921317;-2.6853263;-1.8984782;-3.2561944;0.09071259;-
without recomputing the values of the roc curve itself furthermore we;4.7243433;-1.9687734;-1.4702655;1.211392;1.1961191;0.531299;IRRE
pass alpha 0 8 to the plot functions to adjust the alpha values of the;1.019905;1.1705836;2.1957085;-4.3975587;-6.3909283;1.150823;IRRE
curves;0.99191177;-1.5341109;6.932674;-3.3817167;-3.4643686;-1.7690781;-
first we load the iris dataset as a dataframe to demonstrate the set output api;3.7079036;-3.6653082;-1.0763294;-2.5369818;-1.1379926;-1.048793;IRRE
to configure an estimator such as class preprocessing standardscaler to return;1.3685497;1.1674559;-3.0103204;3.8127208;-0.6940171;4.6802845;IRRE
dataframes call set output this feature requires pandas to be installed;-0.6952412;-2.8496978;-3.9643047;-1.0153208;-4.6321917;0.51968086;IRRE
set output can be called after fit to configure transform after the fact;1.7121196;2.612605;0.04784908;-0.57390434;-1.904094;5.0277143;IRRE
in a class pipeline pipeline set output configures all steps to output;-0.9702096;-0.11004879;-1.3159533;2.178172;0.5104182;1.3525587;IRRE
dataframes;3.624378;-3.1048534;4.469008;-3.5065384;-2.1974485;-4.1047473;-
each transformer in the pipeline is configured to return dataframes this;1.6941147;-0.20142521;-1.2815173;-0.8892966;-2.536121;1.3063227;CODE
means that the final logistic regression step contains the feature names of the input;0.07570338;-2.8051279;-0.94379836;1.2931762;2.2319808;-0.9796618;CODE
note if one uses the method set params the transformer will be;-1.0749913;1.949476;-0.78346807;1.0176613;-0.88769436;3.1064196;TASK
replaced by a new one with the default output format;-2.798798;0.034725826;-0.69309956;-1.5834287;0.0009915575;0.9457345;CODE
to keep the intended behavior use set output on the new transformer;-1.3588486;3.3661954;0.7548196;2.6197822;-1.1549444;4.6611505;CODE
beforehand;-3.4759786;-0.16959761;6.5545187;4.381383;0.65088695;-0.5278874;CODE
next we load the titanic dataset to demonstrate set output with;3.9536738;-2.7214499;2.0523095;-0.06557323;0.14509624;-1.3310032;IRRE
class compose columntransformer and heterogeneous data;2.8022506;-0.5076654;-3.1307294;-1.8315562;4.258411;3.1686485;IRRE
the set output api can be configured globally by using func set config and;-1.2878789;-0.8094576;0.05599021;1.983682;-0.1197693;4.373709;IRRE
setting transform output to pandas;1.8490323;-1.8846468;-0.6174163;-4.4499054;-5.1107306;0.7268212;IRRE
with the global configuration all transformers output dataframes this allows us to;1.6209167;-1.6286135;-1.1924254;-1.0675634;-1.6467949;4.2403207;CODE
easily plot the logistic regression coefficients with the corresponding feature names;3.8571985;-4.6314716;1.3492709;-2.8105426;-1.49123;1.2519339;TASK
in order to demonstrate the func config context functionality below let;-4.8684916;0.28583983;1.6332557;1.6110344;0.82708496;4.0595694;CODE
us first reset transform output to its default value;-1.6996597;2.5372503;-0.05045408;-1.1272693;-3.0568893;2.5630345;IRRE
when configuring the output type with func config context the;-3.6439002;0.5441697;-2.776878;1.0153297;-1.0254864;2.976426;IRRE
configuration at the time when transform or fit transform are;1.5839875;1.743539;1.9697909;-1.1416055;0.03448603;5.927421;CODE
called is what counts setting these only when you construct or fit;0.63692623;2.246124;-0.14565873;2.0216482;5.024994;0.5586449;IRRE
the transformer has no effect;-3.955129;1.4885495;0.7535644;0.19650817;-3.5052617;0.66025066;CODE
the output of transform will be a pandas dataframe;1.2613597;-1.3710896;0.1413307;-5.274198;-4.7232714;-0.89230275;IRRE
outside of the context manager the output will be a numpy array;-1.129951;0.17737979;-2.0961447;-3.1896486;-5.778339;2.0525448;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
ellipse needs degrees;-0.02398138;0.84468335;1.7330188;-3.8190098;-3.4004223;-1.0498918;TASK
eigenvector normalization;3.005071;-2.4355736;-1.96804;-3.6694188;-0.55266714;5.6440325;-
ell set facecolor 56b4e9;-4.6858015;-0.66045076;-0.6328074;-2.522572;0.5455998;2.972916;IRRE
color 56b4e9;-4.1259084;-0.73555386;1.5554929;-3.3988204;2.1401339;-2.3980079;-
parameters of the dataset;6.2155724;-1.7273549;1.4264275;-2.1849625;1.9431484;-0.22400703;IRRE
colors np array 0072b2 f0e442 d55e00;-0.64983535;-0.7467704;-1.421687;-5.945331;-1.1824857;-2.6594768;-
mean precision prior 0 8 to minimize the influence of the prior;3.8053174;1.8402891;-0.5230374;1.5352378;-1.1903925;3.4928422;-
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
plot results in two different figures;0.91365004;2.5381942;5.8244705;-2.9364157;-5.794643;-0.9444292;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
as the dp will not use every component it has access to;-3.8988745;0.31712344;0.44557405;2.0631127;2.557446;5.603927;-
unless it needs it we shouldn t plot the redundant;-0.7701869;-0.2902057;3.671809;1.3463187;-0.60065436;3.4222136;TASK
components;-2.2539375;-3.654502;5.4550385;-1.3878381;3.7480423;-0.10934003;-
plot an ellipse to show the gaussian component;0.5864457;-1.050971;2.6279697;-4.4001384;-4.8965335;2.6477532;IRRE
angle 180 0 angle np pi convert to degrees;-1.3710098;0.7390761;0.0942693;-5.276066;-3.7858298;-0.3295829;-
number of samples per component;4.2900934;0.48229483;1.3280412;-1.5419434;3.566905;-0.035819575;-
generate random sample two components;3.6311238;1.0245985;1.5959493;-2.041531;3.9380195;0.63168013;IRRE
fit a gaussian mixture with em using five components;5.1075535;1.1702735;0.4078181;-3.7177327;0.9666089;4.1103206;-
fit a dirichlet process gaussian mixture using five components;4.034439;0.11452804;-0.056909002;-1.9160082;0.115561046;5.00909;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
angle 180 angle np pi convert to degrees;-1.1759182;0.2969468;0.5127809;-4.8984284;-3.7889893;-0.057857797;-
break up the dataset into non overlapping training 75 and testing;6.219926;1.0995657;-0.2004565;3.325349;2.0813432;-1.3955938;IRRE
25 sets;1.7450647;0.3371415;5.7899523;-1.2303413;2.5088882;-4.282257;IRRE
only take the first fold;-1.3709149;1.7488754;4.6439385;-0.7015783;1.439693;0.38332826;-
try gmms using different types of covariances;3.058612;-1.4670769;-2.118016;1.4127382;0.0017464503;4.1122136;CODE
since we have class labels for the training data we can;4.043936;-5.118777;-0.043063454;1.7997066;6.073145;1.3310486;CODE
initialize the gmm parameters in a supervised manner;4.0012803;-0.6801403;-0.82244;1.0009277;2.5034435;4.031545;IRRE
train the other parameters using the em algorithm;5.3471727;-1.4391532;2.0427184;-0.10970121;3.025264;1.015841;IRRE
plot the test data with crosses;2.8246255;3.0485122;3.8214839;-3.0285084;-4.56028;-5.2567296;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate some data;4.357832;-0.6496195;4.4381747;-2.5545719;2.4259079;-4.16194;-
run a gaussianmixture with max iter 0 to output the initialization means;3.5222714;3.121794;-2.8627741;-1.5133108;-3.4075582;3.596647;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate random sample two components;3.6311238;1.0245985;1.5959493;-2.041531;3.9380195;0.63168013;IRRE
generate spherical data centered on 20 20;3.1282446;0.99486244;3.078817;-4.5763683;-2.6439989;0.7097262;CODE
generate zero centered stretched gaussian data;5.560199;0.54035157;-0.9658449;-5.288963;-4.093905;4.3301907;-
concatenate the two datasets into the final training set;4.7315874;-1.208459;0.8275053;-0.3494392;2.9593942;0.19190535;IRRE
fit a gaussian mixture model with two components;4.529058;1.2327747;0.19323178;-2.4290462;0.6743802;5.035872;-
display predicted scores by the model as a contour plot;3.7416308;-1.1301404;3.316722;-0.33298942;-3.6759782;1.3244112;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
we generate two components each one containing n samples by randomly;5.184931;-0.4790897;1.6909128;-2.5261815;4.0243564;0.3809772;IRRE
sampling the standard normal distribution as returned by numpy random randn;0.60638386;-0.28188315;-1.9814843;-3.6145415;-4.216732;0.74663705;IRRE
one component is kept spherical yet shifted and re scaled the other one is;-0.3799611;2.66384;1.524236;-2.7580066;-4.1223097;5.383094;TASK
deformed to have a more general covariance matrix;2.9232209;-1.2284241;-1.013428;-2.9468195;-1.1651802;7.5575376;CODE
component 1 np dot np random randn n samples 2 c general;3.0863922;-2.5497088;-3.376311;-3.7269993;1.8345717;0.65995294;IRRE
component 2 0 7 np random randn n samples 2 np array 4 1 spherical;2.167929;0.013546712;-1.680202;-5.772285;0.083699144;0.30733293;IRRE
we can visualize the different components;1.2433784;-6.294541;7.359764;-1.5785788;2.5154963;1.1363205;-
model training and selection;6.022274;-4.475163;3.219024;5.848515;4.6378455;0.2538353;CODE
we vary the number of components from 1 to 6 and the type of covariance;3.1421077;-1.0246257;0.49957612;-2.6945891;1.6544559;2.1098683;CODE
parameters to use;-0.582733;2.3843815;3.388893;-1.5174742;3.1743257;-0.12968317;IRRE
full each component has its own general covariance matrix;2.3942704;-1.0455692;-1.016264;-3.9328604;0.6361342;6.3485494;CODE
tied all components share the same general covariance matrix;1.962517;-1.6197323;-1.1988431;-2.4949372;0.34843466;7.976849;CODE
diag each component has its own diagonal covariance matrix;1.7549373;-1.2541739;-2.0033863;-4.410065;-0.09445348;5.198653;CODE
spherical each component has its own single variance;2.0780892;0.756946;0.6369018;-2.5618534;0.16595;4.5281506;CODE
we score the different models and keep the best model the lowest bic this;4.3649173;-1.1739308;0.225712;4.164354;4.2596188;0.98844725;CODE
is done by using class sklearn model selection gridsearchcv and a;4.8537254;-4.114754;-3.1242878;0.349586;0.76122785;0.128962;CODE
user defined score function which returns the negative bic score as;1.3659992;3.3924804;-1.5253323;-1.4601169;0.40738118;-2.8022757;CODE
class sklearn model selection gridsearchcv is designed to maximize a;5.4457803;-4.133762;-4.1223216;0.24954563;-0.020674791;1.4732338;CODE
score maximizing the negative bic is equivalent to minimizing the bic;2.4417977;0.754086;-1.3980569;0.9586615;1.8302867;1.9128389;-
the best set of parameters and estimator are stored in best parameters and;4.877632;-0.8279637;1.5858436;2.1757894;1.727776;3.3649318;IRRE
best estimator respectively;4.343714;0.30184764;2.393344;3.7909842;-0.091070496;2.3958943;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
as the dp will not use every component it has access to;-3.8988745;0.31712344;0.44557405;2.0631127;2.557446;5.603927;-
unless it needs it we shouldn t plot the redundant;-0.7701869;-0.2902057;3.671809;1.3463187;-0.60065436;3.4222136;TASK
components;-2.2539375;-3.654502;5.4550385;-1.3878381;3.7480423;-0.10934003;-
plot an ellipse to show the gaussian component;0.5864457;-1.050971;2.6279697;-4.4001384;-4.8965335;2.6477532;IRRE
angle 180 0 angle np pi convert to degrees;-1.3710098;0.7390761;0.0942693;-5.276066;-3.7858298;-0.3295829;-
as the dp will not use every component it has access to;-3.8988745;0.31712344;0.44557405;2.0631127;2.557446;5.603927;-
unless it needs it we shouldn t plot the redundant;-0.7701869;-0.2902057;3.671809;1.3463187;-0.60065436;3.4222136;TASK
components;-2.2539375;-3.654502;5.4550385;-1.3878381;3.7480423;-0.10934003;-
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
generate random sample following a sine curve;1.932961;1.0327221;3.1557944;-0.556576;-2.173124;-0.24566723;IRRE
fit a gaussian mixture with em using ten components;5.521086;1.2494532;0.78083736;-3.72327;0.8901601;4.1113634;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
split the data into a training set and a test set;7.250792;0.32431918;1.9390848;2.1137006;3.7319605;-3.4346256;IRRE
run classifier using a model that is too regularized c too low to see;3.8118265;-0.43873712;-3.3225677;1.7470766;-0.101281695;1.9360793;CODE
the impact on the results;2.9153736;-2.3317418;3.615195;6.8750796;0.008802508;-2.63173;IRRE
plot non normalized confusion matrix;4.776119;0.613945;0.50464875;-5.3452506;-3.4271185;1.2837927;-
binary classification;4.78392;-4.7145796;1.6389602;-1.798624;6.7510824;-4.3394766;IRRE
for binary problems func sklearn metrics confusion matrix has the ravel method;4.414102;-3.7810214;-5.209387;-2.2165017;-0.22948347;-2.3461695;CODE
we can use get counts of true negatives false positives false negatives and;1.4620492;2.8740797;-0.17240173;1.8006059;2.6489937;-5.7474875;-
true positives;-0.2993366;0.1430807;2.7028646;2.9863415;-0.4148517;-3.7856176;-
to obtain true negatives false positives false negatives and true;1.0922712;2.7452593;-0.28932035;1.4646832;3.144026;-5.2305436;CODE
positives counts at different thresholds one can use;3.1822555;3.726967;0.36580718;0.41860443;2.3929935;-3.072597;-
func sklearn metrics confusion matrix at thresholds;6.006015;-2.968211;-4.536021;-0.82563514;-1.99592;0.28949144;-
this is fundamental for binary classification;4.0416436;-5.312676;0.4885207;-1.2828128;6.3697443;-2.7685008;CODE
metrics like func sklearn metrics roc auc score and;3.6038673;-5.7156963;-2.0953312;1.0566409;0.48180586;-1.6832699;-
func sklearn metrics det curve;3.5560582;-4.604421;-2.0671067;-2.9106345;-4.589807;0.26388338;-
plot tns fps fns and tps vs thresholds;3.0373535;-0.7342399;1.3205392;-2.3238854;-3.7587202;2.0646281;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
cost sensitive learning with constant gains and costs;5.373044;-3.399176;0.007632488;4.383667;3.0467756;2.4254024;CODE
in this first section we illustrate the use of the;-2.6286414;-3.337095;5.828223;1.459504;2.9835398;0.2174098;CODE
class sklearn model selection tunedthresholdclassifiercv in a setting of;4.14704;-3.6903038;-5.8329725;1.5803076;-0.67470664;2.4017534;IRRE
cost sensitive learning when the gains and costs associated to each entry of the;4.6740026;-3.3877802;1.2073344;5.4756875;4.014979;1.5750494;CODE
confusion matrix are constant we use the problematic presented in 2 using the;1.649787;2.49664;-2.4192476;-2.3141594;-0.0041775657;-2.2151065;IRRE
statlog german credit dataset 1;2.2744157;-1.3356888;-1.2612246;-1.194319;2.040964;-2.0555806;IRRE
statlog german credit dataset;2.5473917;-2.5373228;-0.93731743;-1.1386756;2.475524;-1.4068967;IRRE
we fetch the german credit dataset from openml;-0.25529358;-3.1834824;-1.4258711;-0.040959325;3.946537;0.105091706;CODE
we check the feature types available in x;-2.0414045;-3.2867572;-1.4466969;1.4424945;2.3518465;-1.7053673;TASK
many features are categorical and usually string encoded we need to encode;0.4359602;-3.843168;-0.91736364;-1.1730968;3.6377633;-0.13849095;TASK
these categories when we develop our predictive model let s check the targets;2.0954201;-3.0982087;2.583966;5.16246;2.213583;-2.1269739;CODE
another observation is that the dataset is imbalanced we would need to be careful;5.5170283;-1.6399307;-2.2253711;4.301045;-0.124969214;0.5424312;TASK
when evaluating our predictive model and use a family of metrics that are adapted;5.140904;-3.0483782;0.90386003;5.434866;1.9016514;1.7695396;CODE
to this setting;-2.770315;-1.9152429;6.8807364;1.3825411;0.5442464;3.0887046;IRRE
in addition we observe that the target is string encoded some metrics;2.5815144;-1.7397847;-1.9399487;2.1301365;0.83335525;-0.073192105;TASK
e g precision and recall require to provide the label of interest also called;1.1304939;-3.3399882;1.355778;3.1371684;5.7712493;0.12921222;IRRE
the positive label here we define that our goal is to predict whether or not;1.8710572;-0.4867342;2.5538402;5.5897555;1.4887987;-2.0872736;CODE
a sample is a bad credit;0.88331413;1.8786898;-2.248418;3.6355534;1.3803105;-3.380124;-
to carry our analysis we split our dataset using a single stratified split;6.69278;-3.0474045;0.9731397;1.6503779;4.1650457;0.2001111;IRRE
we are ready to design our predictive model and the associated evaluation strategy;3.4460032;-4.401818;3.321905;6.6809015;2.8813288;-0.571556;CODE
evaluation metrics;4.273139;-2.0216415;2.278006;3.818416;2.3573487;-1.7111546;-
in this section we define a set of metrics that we use later to see;1.5640299;-3.6166365;3.488217;1.0207071;3.2593982;3.0019228;CODE
the effect of tuning the cut off point we evaluate the predictive model using;5.3251677;-1.4213964;1.1681948;5.3427634;-1.314518;1.5340023;CODE
the receiver operating characteristic roc curve and the precision recall curve;5.090205;-4.6534314;-2.47681;3.3072643;2.9192088;-1.5415136;IRRE
the values reported on these plots are therefore the true positive rate tpr;0.8073593;1.5444522;-0.38216794;-2.559709;-5.1355352;-1.1498975;IRRE
also known as the recall or the sensitivity and the false positive rate fpr;0.6070037;-0.04912663;-0.029499954;5.1799455;1.6785043;-0.87402713;IRRE
also known as the specificity for the roc curve and the precision and recall for;3.5013554;-5.0504518;-0.74605644;2.0756516;3.946466;-1.1958538;CODE
the precision recall curve;5.448342;-2.9706645;0.3268256;3.150491;1.5729187;-2.2629328;IRRE
from these four metrics scikit learn does not provide a scorer for the fpr we;2.3775272;-4.149269;-4.4039006;1.1538243;-2.1096795;-2.6904788;CODE
therefore need to define a small custom function to compute it;1.5643588;2.8996122;1.3794161;-1.291737;1.1649895;-1.1270325;CODE
as previously stated the positive label is not defined as the value 1 and calling;-3.4921513;4.425426;-2.1723711;-2.0502715;1.197656;-2.6366222;IRRE
some of the metrics with this non standard value raise an error we need to;2.9928238;3.5375013;-3.7875862;0.39233428;-2.5644748;-0.25583345;CODE
provide the indication of the positive label to the metrics;3.2343605;0.50110656;1.0940007;-0.65161306;2.3238792;-0.5062456;-
we therefore need to define a scikit learn scorer using;1.9817536;-7.2467413;-2.3564773;2.0215209;0.5206206;-3.014073;CODE
func sklearn metrics make scorer where the information is passed we store all;4.055961;-4.0532136;-1.7110583;1.0279694;0.59231466;-0.8358235;CODE
the custom scorers in a dictionary to use them we need to pass the fitted model;1.6401644;-0.7574212;-1.5018591;1.4782681;3.1551678;1.4473745;TASK
the data and the target on which we want to evaluate the predictive model;4.162759;-2.4351172;2.6369553;6.924395;1.8973981;-1.1437432;-
tpr score recall score tpr and recall are the same metric;2.128123;-0.9270343;-1.626714;2.373452;2.3582368;-0.5367706;IRRE
in addition the original research 1 defines a custom business metric we;0.36435312;-1.5653075;0.76464564;1.8732096;2.557344;1.5822732;CODE
call a business metric any metric function that aims at quantifying how the;1.592864;-0.27093163;2.8510091;1.4451278;1.226978;0.89443684;IRRE
predictions correct or wrong might impact the business value of deploying a;0.9174577;-0.73034483;0.6667476;6.7644;0.027973417;0.8376878;IRRE
given machine learning model in a specific application context for our;4.996254;-6.1938567;3.02356;4.043593;5.112009;1.0737512;CODE
credit prediction task the authors provide a custom cost matrix which;4.7982283;-2.730167;-0.28978455;0.4018916;1.9413123;0.31369787;TASK
encodes that classifying a bad credit as good is 5 times more costly on;2.3075924;0.16646051;-1.2095913;2.5329218;3.2921076;-0.96110946;IRRE
average than the opposite it is less costly for the financing institution to;-0.17586032;1.3170087;-0.08912099;1.8894525;-0.6630711;2.6323473;CODE
not grant a credit to a potential customer that will not default and;-1.8504692;1.9276919;-0.8365093;1.4200374;0.95821095;1.6847563;CODE
therefore miss a good customer that would have otherwise both reimbursed the;-3.556764;2.253517;-0.4213884;3.890044;-0.5158642;1.5330304;CODE
credit and paid interests than to grant a credit to a customer that will;-1.0037724;-1.3113458;0.5993005;0.080436245;3.7024136;1.5407982;CODE
default;-5.2986646;-1.8012849;4.161423;0.8626395;-0.7494437;1.3156078;CODE
we define a python function that weighs the confusion matrix and returns the;4.0109644;-0.703551;-1.0819877;-1.8721828;0.25302413;-3.0791984;CODE
overall cost;-0.124193765;-0.88669664;2.1826227;0.21318996;-0.92244685;0.25678897;-
the rows of the confusion matrix hold the counts of observed classes;4.524148;-0.031699408;-1.1621616;0.013483266;3.9024255;-1.0751578;IRRE
while the columns hold counts of predicted classes recall that here we;4.6111975;-1.4560342;-0.57072186;1.7925566;1.73084;-2.5389595;CODE
consider bad as the positive class second row and column;3.3767207;2.5371754;-0.22064102;-2.6255221;2.3662136;-3.3005986;IRRE
scikit learn model selection tools expect that we follow a convention;1.7630656;-8.126816;-4.8038325;3.5573459;-0.5609876;-0.37717202;CODE
that higher means better hence the following gain matrix assigns;1.7272408;0.8720512;-0.96087646;-4.160245;0.5559208;1.7659786;IRRE
negative gains costs to the two kinds of prediction errors;3.212534;-0.66572255;-0.7651043;5.4372306;-1.5590839;1.3261276;-
a gain of 1 for each false positive good credit labeled as bad;1.4924307;2.7190433;-1.7328705;0.67707205;1.8765275;-3.4490762;CODE
a gain of 5 for each false negative bad credit labeled as good;1.1386364;1.757482;-0.40822214;0.54656965;1.9593072;-3.1274204;CODE
a 0 gain for true positives and true negatives;-0.5605499;2.1478045;0.018611664;-1.934671;0.036954466;-1.7316908;CODE
note that theoretically given that our model is calibrated and our data;5.7286453;-1.1014254;-0.15740246;4.012114;-1.3216971;1.2903737;TASK
set representative and large enough we do not need to tune the;3.5067713;0.9472273;1.5174034;1.4429283;2.1015213;1.3427887;TASK
threshold but can safely set it to 1 5 of the cost ratio as stated by;1.673838;1.9777132;0.28170657;1.4575251;1.1729947;0.92849874;IRRE
eq 2 in elkan s paper 2;-3.3294158;-0.15634601;-2.9967372;-1.246533;1.9754103;1.74307;-
0 1 1 gain for false positives;1.7096633;4.521661;-2.2437932;-1.2303078;-0.15005602;-3.8454962;CODE
5 0 5 gain for false negatives;1.3422005;3.202967;-0.34820518;-2.3086805;-0.70661056;-3.383237;CODE
vanilla predictive model;2.995701;-3.3862092;1.2751701;4.2973504;2.6357613;0.85358196;-
we use class sklearn ensemble histgradientboostingclassifier as a predictive model;5.0046506;-7.660149;-2.88776;2.681691;2.645682;1.0456079;IRRE
that natively handles categorical features and missing values;1.2141063;-3.5804708;-0.72257096;0.71546966;3.0297906;-1.2379454;IRRE
we evaluate the performance of our predictive model using the roc and precision recall;5.6662865;-4.8921847;-0.41505456;5.0450253;2.5427878;-1.1045907;IRRE
curves;0.99191177;-1.5341109;6.932674;-3.3817167;-3.4643686;-1.7690781;-
we recall that these curves give insights on the statistical performance of the;5.76274;-3.929079;2.5676835;1.3668337;-2.7650611;0.16299994;IRRE
predictive model for different cut off points for the precision recall curve the;6.0119367;-1.6770006;0.8635095;3.432048;1.2884883;0.35234433;CODE
reported metrics are the precision and recall and for the roc curve the reported;3.638016;-4.4229774;-0.61100847;2.1807268;1.6921146;-2.0840302;IRRE
metrics are the tpr same as recall and fpr;2.4487338;-2.5103166;-0.7375655;2.1897428;1.551012;0.5234423;IRRE
here the different cut off points correspond to different levels of posterior;1.7146051;1.8047031;1.0440208;-0.9746909;1.4752164;3.599492;CODE
probability estimates ranging between 0 and 1 by default model predict uses a;2.6424456;0.119859956;-2.3098047;3.8264923;-1.7268391;1.6005394;CODE
cut off point at a probability estimate of 0 5 the metrics for such a cut off point;3.200634;1.1178341;1.4850384;-0.30038452;-1.539793;1.4606726;CODE
are reported with the blue dot on the curves it corresponds to the statistical;1.7639973;-1.287453;1.2865548;-1.1486404;-2.9258583;-1.4418687;CODE
performance of the model when using model predict;4.1184235;-1.6593931;1.3732498;5.6089115;-0.8042167;0.17830928;CODE
however we recall that the original aim was to minimize the cost or maximize the;-1.0028669;-1.6470264;2.8820302;3.8394318;-0.12352147;4.550465;IRRE
gain as defined by the business metric we can compute the value of the business;0.41335788;-0.077257775;2.9193494;-0.2663095;2.7591257;0.7132843;IRRE
metric;2.5457833;-1.0446596;4.489258;-1.1067176;0.29979572;-1.8043784;-
at this stage we don t know if any other cut off can lead to a greater gain to find;0.58101004;0.6859992;2.1531808;4.099483;-0.95317084;1.3041054;CODE
the optimal one we need to compute the cost gain using the business metric for all;3.2004595;-0.34758785;2.2403314;0.99431235;2.786085;3.088664;CODE
possible cut off points and choose the best this strategy can be quite tedious to;3.6893299;0.6782397;4.5939484;2.068754;3.1914952;1.3108716;CODE
implement by hand but the;-4.0827894;-1.9779578;5.037023;1.7129449;4.0146437;-0.6654412;TASK
class sklearn model selection tunedthresholdclassifiercv class is here to help us;4.1204567;-4.699833;-4.826705;0.43651384;-0.13157466;0.6183831;CODE
it automatically computes the cost gain for all possible cut off points and optimizes;4.160196;-3.7859125;0.6779972;1.767919;0.9548771;1.8168737;CODE
for the scoring;-0.56635445;-0.34221295;5.8875494;1.9246358;-0.24947503;-3.6998792;CODE
cost sensitive learning example;5.093694;-3.2606316;-0.13157481;4.3209505;2.9061587;-0.09600097;-
tuning the cut off point;3.5678575;0.45974582;2.3190672;0.88849866;-1.8306448;1.5489156;CODE
we use class sklearn model selection tunedthresholdclassifiercv to tune the;5.482088;-6.0544477;-3.460222;1.7438166;-0.012316014;0.9394964;CODE
cut off point we need to provide the business metric to optimize as well as the;2.3128316;-0.5067002;1.5592612;2.2767673;1.1674533;3.8189151;TASK
positive label internally the optimum cut off point is chosen such that it maximizes;2.141992;1.1665428;1.0190128;-1.3606786;1.6791725;3.124278;CODE
the business metric via cross validation by default a 5 fold stratified;3.4012258;-0.5079074;-1.1823705;2.3636892;3.9351733;0.561619;CODE
cross validation is used;0.24212617;0.34588802;1.474902;2.5562477;2.8535588;-2.7251368;-
tore cv results true necessary to inspect all results;1.0374982;1.3372037;-3.1681697;4.6168475;-1.0893674;-1.8781582;IRRE
we plot the roc and precision recall curves for the vanilla model and the tuned model;4.701313;-5.166757;-0.08241094;2.030551;0.43394426;-0.7566525;IRRE
also we plot the cut off points that would be used by each model because we are;5.243476;-3.8331366;3.3064668;1.764033;-0.7676927;2.797141;CODE
reusing the same code later we define a function that generates the plots;0.93159026;-0.15073562;3.3655217;-1.1437991;-1.9882156;1.8478055;CODE
the first remark is that both classifiers have exactly the same roc and;1.9411792;-3.353772;-4.1827745;0.3363156;3.701916;0.36558095;IRRE
precision recall curves it is expected because by default the classifier is fitted;3.7792008;-0.42642352;-3.6147366;1.6909307;-2.7533925;1.303728;IRRE
on the same training data in a later section we discuss more in detail the;2.8178446;-6.0135045;2.3478127;3.3756447;5.165678;0.7829328;-
available options regarding model refitting and cross validation;1.7897937;-1.6753131;0.3561892;6.048079;3.4681547;2.532368;-
the second remark is that the cut off points of the vanilla and tuned model are;1.7062107;-0.46640018;-1.0957596;2.2228534;0.62064356;3.0814214;CODE
different to understand why the tuned model has chosen this cut off point we can;1.5507185;0.21695018;0.75699514;1.4578449;-2.1124208;2.2745578;CODE
look at the right hand side plot that plots the objective score that is our exactly;3.0649672;-1.1668742;2.5363967;1.01818;-2.6706932;-0.7245332;IRRE
the same as our business metric we see that the optimum threshold corresponds to the;3.0732238;-0.59296393;1.6640594;2.0965424;1.48033;2.36034;-
maximum of the objective score this maximum is reached for a decision threshold;3.1479037;0.30653217;-0.2559067;1.1510924;1.8500278;-0.4603793;CODE
much lower than 0 5 the tuned model enjoys a much higher recall at the cost of;2.4387715;0.7925447;-0.6302548;2.6489432;-0.1382981;-0.6463729;IRRE
of significantly lower precision the tuned model is much more eager to;4.6252584;-0.17047493;-1.9586958;3.3104186;-2.941513;0.94727373;-
predict the bad class label to larger fraction of individuals;6.279354;-0.42412856;0.33743614;2.3320014;2.592622;-2.5131185;IRRE
we can now check if choosing this cut off point leads to a better score on the testing;2.2419744;2.5360563;-1.4157025;5.9618974;0.05115566;-1.6538877;IRRE
set;-1.4280705;0.15607189;7.4121943;-1.1588911;1.308024;-3.1926973;IRRE
we observe that tuning the decision threshold almost improves our business gains;3.157819;-1.9750906;2.4265616;4.961691;0.88895535;1.3090922;-
by factor of 2;-2.3428226;1.2397223;3.891402;-2.1484447;-0.5842251;-4.461765;-
tunedthresholdclassifiercv no cv;1.8158689;-1.7984412;-5.704751;0.67753;-1.692677;1.906446;IRRE
consideration regarding model refitting and cross validation;1.8157595;-1.062548;0.49537843;6.4789753;3.0743096;1.6302258;-
in the above experiment we used the default setting of the;-1.6558162;0.71980983;0.044567607;3.1394205;-3.8211823;3.3034453;CODE
class sklearn model selection tunedthresholdclassifiercv in particular the;4.3015757;-4.457345;-5.413865;1.0070497;-0.26347828;1.7585535;CODE
cut off point is tuned using a 5 fold stratified cross validation also the;2.3984;1.7045481;-1.6682979;1.210718;1.0874914;0.03534712;CODE
underlying predictive model is refitted on the entire training data once the cut off;2.8801806;-2.2357714;-1.2889603;5.3929296;0.8568399;4.9251785;CODE
point is chosen;-0.49076247;1.0358145;5.455064;0.19429433;1.0059922;0.040202454;CODE
these two strategies can be changed by providing the refit and cv parameters;-0.18697545;-1.896844;-0.6294413;3.15789;2.460957;4.672978;IRRE
for instance one could provide a fitted estimator and set cv prefit in which;3.7759662;-0.93794113;-0.5584285;4.98279;0.7168835;5.467314;IRRE
case the cut off point is found on the entire dataset provided at fitting time;5.2293215;0.78803176;-3.305914;-1.3764261;-4.6297894;3.916214;CODE
also the underlying classifier is not be refitted by setting refit false here we;-0.1437132;-0.77739924;-5.0832796;2.7792091;0.5686335;3.0199769;IRRE
can try to do such experiment;0.4886377;-0.10620176;5.4236474;2.9922445;-1.6930809;-2.2995703;CODE
then we evaluate our model with the same approach as before;2.3271463;0.016294973;2.0024788;8.1287775;2.5779788;0.7751037;CODE
we observe the that the optimum cut off point is different from the one found;3.208024;1.4061838;0.6567586;1.14938;-2.0651398;4.5627856;CODE
in the previous experiment if we look at the right hand side plot we;-0.4751282;-1.0302352;3.7690656;1.6994153;-6.985403;-0.018679306;CODE
observe that the business gain has large plateau of near optimal 0 gain for a;1.6024715;2.4905875;0.54440886;1.125779;-0.9137824;2.149668;CODE
large span of decision thresholds this behavior is symptomatic of an;3.4231217;0.647724;-1.459835;4.2245817;-0.0026852742;0.27533558;CODE
overfitting because we disable cross validation we tuned the cut off point;2.9839542;0.6724265;-1.6261767;4.840952;-1.4173963;1.6820782;CODE
on the same set as the model was trained on and this is the reason for the;-0.0768177;-1.0172967;-0.8047981;4.0062537;-1.5439682;2.124951;CODE
observed overfitting;5.419486;-0.19653977;-1.5380707;4.981324;-0.99937546;-0.54955;CODE
this option should therefore be used with caution one needs to make sure that the;-4.466302;1.2497213;-0.51591337;5.252337;2.0631597;2.4625797;CODE
data provided at fitting time to the;6.8348064;-0.987084;3.6328838;-0.38458565;-0.71858495;1.1110489;-
class sklearn model selection tunedthresholdclassifiercv is not the same as the;2.3437793;-3.3618042;-6.946251;1.1136565;-2.0668886;0.99904907;CODE
data used to train the underlying classifier this could happen sometimes when the;2.9044194;-1.7982941;-1.9137707;3.216681;1.2323856;-0.9008697;CODE
idea is just to tune the predictive model on a completely new validation set without a;3.7482822;-0.5021752;-0.7446096;6.9529414;2.6520011;2.087504;CODE
costly complete refit;0.3185146;-1.7483214;1.1725471;0.9561656;1.1218513;1.6614295;CODE
when cross validation is too costly a potential alternative is to use a;2.4302485;0.46647295;-0.10707856;5.947081;2.8332076;0.8250749;-
single train test split by providing a floating number in range 0 1 to the cv;4.9595146;4.1347737;-2.449468;-0.41449055;0.9770625;-3.001462;CODE
parameter it splits the data into a training and testing set let s explore this;5.2997828;-1.1077588;1.8064413;2.2739825;4.5119967;-1.9603897;IRRE
option;-3.8225517;-0.8791506;7.2907867;1.2090216;0.7346304;-0.981287;-
regarding the cut off point we observe that the optimum is similar to the multiple;4.6337357;1.9018762;-0.17820324;0.7254377;1.5261196;4.946032;CODE
repeated cross validation case however be aware that a single split does not account;1.9608011;3.750581;-1.2877882;3.4299858;4.17953;0.041812375;CODE
for the variability of the fit predict process and thus we are unable to know if there;3.6847985;-0.86210114;-0.5647205;5.0668645;-2.5874016;1.3613001;CODE
is any variance in the cut off point the repeated cross validation averages out;2.755132;2.0175133;-1.3023964;2.5824454;-1.2572502;1.5834666;CODE
this effect;-2.2144082;-2.1726253;7.3435774;1.0816888;-1.4132154;0.12745495;CODE
another observation concerns the roc and precision recall curves of the tuned model;5.2132435;-3.8170555;-1.521134;3.57881;1.0791218;0.040786043;IRRE
as expected these curves differ from those of the vanilla model given that we;1.0948687;-0.80786437;-0.028921908;0.7426;-3.1322823;1.6958357;CODE
trained the underlying classifier on a subset of the data provided during fitting and;6.4648056;-3.7764742;0.5296764;2.935175;4.35336;3.3581166;IRRE
reserved a validation set for tuning the cut off point;1.7236739;3.371351;-2.9232814;3.1847239;-0.09660166;2.1505675;CODE
cost sensitive learning when gains and costs are not constant;4.8265743;-2.063404;-0.055375837;5.1818013;2.0725787;2.9653664;CODE
as stated in 2 gains and costs are generally not constant in real world problems;0.52210903;0.34412155;1.6241139;1.5799059;-0.09456227;2.4918556;CODE
in this section we use a similar example as in 2 for the problem of;-1.153338;0.9840848;1.1360508;0.12949741;4.311309;1.6451625;CODE
detecting fraud in credit card transaction records;2.8798084;0.68142825;0.67091614;1.1155995;2.5949414;-1.1924982;-
the credit card dataset;3.7641468;-3.8804836;0.7260252;0.34064376;3.1944897;-0.7665204;IRRE
the dataset contains information about credit card records from which some are;3.1933806;-2.5615633;-0.13240768;-0.58438206;3.5379703;-0.907249;CODE
fraudulent and others are legitimate the goal is therefore to predict whether or;1.2497602;0.34321454;-0.5942705;4.526696;2.1342242;-2.7588468;CODE
not a credit card record is fraudulent;-0.47745436;2.1666515;-1.3303636;-0.08467108;1.8135908;-0.3633635;-
first we check the class distribution of the datasets;6.9979935;-2.689988;-1.6930754;1.5119044;2.420914;-1.6550611;IRRE
the dataset is highly imbalanced with fraudulent transaction representing only 0 17;3.9746912;1.3784692;-2.834745;0.30957744;-0.68485254;-1.8530678;IRRE
of the data since we are interested in training a machine learning model we should;5.3467836;-7.0120053;2.819417;4.6108413;2.559008;-0.09044354;CODE
also make sure that we have enough samples in the minority class to train the model;4.8452044;-2.1305702;-0.5152545;5.9621997;2.707588;-0.6318567;CODE
we observe that we have around 500 samples that is on the low end of the number of;5.0528517;0.34040937;1.980832;2.2309399;0.31846586;-2.4217396;CODE
samples required to train a machine learning model in addition of the target;3.9970863;-3.2326207;1.8472375;4.6016965;4.6214733;-0.115399286;TASK
distribution we check the distribution of the amount of the;0.52486575;1.9262857;4.649249;1.7390088;0.92192;-3.5446782;META
fraudulent transactions;-1.6755409;1.4470596;1.5608652;-0.045260366;-0.3741349;-0.9659661;-
addressing the problem with a business metric;1.5639956;0.14081384;3.0257382;1.5534533;2.2928348;0.58458763;TASK
now we create the business metric that depends on the amount of each transaction we;2.724911;-0.38387743;4.1908436;0.52026516;3.509434;1.8738264;IRRE
define the cost matrix similarly to 2 accepting a legitimate transaction provides;1.6156687;1.1347849;-1.2398145;-2.2924924;2.8880107;2.3254075;CODE
a gain of 2 of the amount of the transaction however accepting a fraudulent;-2.5463665;2.700495;1.2376026;-0.15534228;-0.52514476;-1.0109338;-
transaction result in a loss of the amount of the transaction as stated in 2 the;-2.541422;3.3512712;1.1011484;0.7641223;-0.65706915;-1.3301748;IRRE
gain and loss related to refusals of fraudulent and legitimate transactions are not;-2.5235941;1.7571089;-0.6823317;-0.14421946;-0.33888516;-0.30027583;-
trivial to define here we define that a refusal of a legitimate transaction;-3.7934945;2.2768495;0.39915583;0.7382372;0.4552979;-0.31716567;CODE
is estimated to a loss of 5 while the refusal of a fraudulent transaction is;-1.5273213;3.0698495;0.63496584;1.2649412;-0.75976956;-0.7817415;CODE
estimated to a gain of 50 therefore we define the following function to;1.8780601;1.2163234;2.3957655;0.21660775;-0.8730197;0.575904;CODE
compute the total benefit of a given decision;1.8795557;1.0992985;3.964986;1.6680582;3.1985817;-1.6830342;CODE
from this business metric we create a scikit learn scorer that given a fitted;4.2264733;-7.6445785;-1.8319098;1.8496414;0.034298573;-2.1658278;CODE
classifier and a test set compute the business metric in this regard we use;5.0385013;-1.364537;0.28954282;3.0985854;4.694966;-2.0349317;IRRE
the func sklearn metrics make scorer factory the variable amount is an;3.4186451;-1.7809238;-2.2001283;-0.12286952;-0.030342665;-1.8240234;IRRE
additional metadata to be passed to the scorer and we need to use;-2.739035;-2.1614575;0.67298746;2.3112864;3.8507009;1.3046995;TASK
ref metadata routing metadata routing to take into account this information;-1.361181;-1.3388629;-0.015815442;0.8453098;2.646097;4.4059052;CODE
so at this stage we observe that the amount of the transaction is used twice once;-1.97018;1.5835608;3.3354993;4.3905025;1.0242021;1.2115116;CODE
as a feature to train our predictive model and once as a metadata to compute the;3.788927;-7.0920863;1.2969218;5.567924;4.787237;1.4567041;TASK
the business metric and thus the statistical performance of our model when used as a;2.296552;-2.0029619;3.1370165;4.608736;2.4046085;0.6308168;CODE
feature we are only required to have a column in data that contains the amount of;4.0600133;1.7180803;0.7861904;-1.0375597;2.968349;-0.43434498;TASK
each transaction to use this information as metadata we need to have an external;-1.8505623;-1.5190744;0.64497304;0.37921423;4.764444;4.424664;CODE
variable that we can pass to the scorer or the model that internally routes this;0.24125695;-0.06999179;2.3774054;3.3761148;3.7441437;2.5745535;CODE
metadata to the scorer so let s create this variable;-1.1538959;0.25367782;2.10002;-0.2702869;4.1532593;-1.1393386;CODE
we first evaluate some baseline policies to serve as reference recall that;-1.3759706;-2.0249505;1.0061831;6.9811845;4.6568537;1.3043587;IRRE
class 0 is the legitimate class and class 1 is the fraudulent class;-1.9091617;-0.6539072;-2.9619546;0.744844;3.980019;-3.0607543;IRRE
a policy that considers all transactions as legitimate would create a profit of;-2.4723694;0.89929646;0.8067788;1.3650761;2.3907073;1.0549525;IRRE
around 220 000 we make the same evaluation for a classifier that predicts all;5.2732153;-4.9631066;-0.097886;4.170465;2.5216315;-2.738195;CODE
transactions as fraudulent;-1.8991258;1.5197572;0.97494215;0.5401919;0.06837753;-0.32893255;-
such a policy would entail a catastrophic loss around 670 000 this is;-0.2980622;0.4984527;0.70994014;4.9728737;0.17346844;1.3892939;CODE
expected since the vast majority of the transactions are legitimate and the;-1.5994487;0.58621776;1.6881474;2.7723994;-0.9897932;-0.33915406;-
policy would refuse them at a non trivial cost;-1.8972121;2.4729497;-0.41426355;3.3142347;1.5450623;3.1410084;IRRE
a predictive model that adapts the accept reject decisions on a per;2.576629;-0.4916865;1.9535466;5.9004226;2.4576042;0.028611816;-
transaction basis should ideally allow us to make a profit larger than the;0.18143052;-0.24163973;1.832038;-1.0944556;2.3411272;3.927435;-
220 000 of the best of our constant baseline policies;0.4976004;-1.1440922;2.7035568;4.816906;1.9633532;0.595134;CODE
we start with a logistic regression model with the default decision threshold;3.2688124;-2.4662344;2.0608585;4.156057;1.8663881;0.66989577;CODE
at 0 5 here we tune the hyperparameter c of the logistic regression with a;3.133341;-0.7464935;-0.44514692;1.5967731;-0.45942;-2.2261176;IRRE
proper scoring rule the log loss to ensure that the model s probabilistic;2.2502031;-1.0801066;-0.88269037;5.207235;2.039069;0.80313647;CODE
predictions returned by its predict proba method are as accurate as;5.08114;-2.4037747;-1.0427008;6.169426;-1.7642059;-0.9128548;IRRE
possible irrespectively of the choice of the value of the decision;0.19714916;1.6986871;4.1179667;4.190912;3.5992668;-0.5183183;IRRE
threshold;1.9324853;0.88612324;3.9160545;0.19162998;0.8255056;-3.2432754;-
the business metric shows that our predictive model with a default decision;2.2604141;-1.676164;1.3805536;5.363541;1.7992941;2.2171097;CODE
threshold is already winning over the baseline in terms of profit and it would be;1.5313754;0.9632741;2.0018547;2.127655;1.2095598;0.8927804;CODE
already beneficial to use it to accept or reject transactions instead of;-4.2589364;-1.9684551;2.3988385;4.0232134;1.1003599;2.244869;CODE
accepting all transactions;-2.494311;1.5214174;3.8467865;0.86417294;1.017433;0.36377686;-
tuning the decision threshold;6.1851997;-1.2496142;1.1485246;4.7057424;2.76619;-0.3046971;-
now the question is is our model optimum for the type of decision that we want to do;3.5955613;-0.6098131;3.6260226;5.353743;4.3850765;3.2906537;CODE
up to now we did not optimize the decision threshold we use the;1.8276572;-0.3224353;-1.0812559;4.8479304;0.51360035;2.854866;IRRE
class sklearn model selection tunedthresholdclassifiercv to optimize the decision;5.48559;-4.689214;-4.7169137;2.2479644;0.40692887;1.9278342;CODE
given our business scorer to avoid a nested cross validation we will use the;1.5680175;1.2867796;0.9205439;4.7280354;5.2851954;0.106646106;IRRE
best estimator found during the previous grid search;5.3501167;0.7033388;0.5540609;2.5771194;-1.0528153;3.6917796;IRRE
since our business scorer requires the amount of each transaction we need to pass;-0.55335325;2.5211542;1.6855597;0.49793598;3.552983;0.7335941;TASK
this information in the fit method the;4.141941;0.20764834;2.2179139;-0.6963073;0.3933024;0.5161876;CODE
class sklearn model selection tunedthresholdclassifiercv is in charge of;2.95164;-3.5835822;-6.8043804;1.7654337;-1.514414;1.6955055;CODE
automatically dispatching this metadata to the underlying scorer;0.21869147;-1.5102081;-0.0053393305;3.2704272;4.3715997;2.2147207;IRRE
we observe that the tuned decision threshold is far away from the default 0 5;3.896713;-0.5795791;-1.6338321;3.3041651;-0.5270644;0.97241557;CODE
we observe that tuning the decision threshold increases the expected profit;3.2455957;-1.9581449;1.7141927;4.4007635;-0.1994026;0.7681607;-
when deploying our model as indicated by the business metric it is therefore;-1.5786958;-0.8180447;0.05634629;3.395635;1.8868924;2.2519407;CODE
valuable whenever possible to optimize the decision threshold with respect;3.1560934;-1.6652954;2.901007;4.600325;4.936019;1.0599545;CODE
to the business metric;1.1773908;-1.5592599;4.972247;1.996462;1.8106354;-0.5771167;-
manually setting the decision threshold instead of tuning it;3.5940568;0.24088587;-0.44891196;4.2047143;0.4355863;2.5967925;IRRE
in the previous example we used the;-1.2380247;-0.9224644;3.421768;0.27553403;2.4317446;-0.26145327;CODE
class sklearn model selection tunedthresholdclassifiercv to find the optimal;6.2686415;-4.1700716;-4.380932;1.5936596;0.076956965;1.6120884;CODE
decision threshold however in some cases we might have some prior knowledge about;3.2325242;-1.2949852;0.57579225;6.251634;2.9918087;0.5967692;CODE
the problem at hand and we might be happy to set the decision threshold manually;1.873832;-1.3768387;-0.32168522;4.741217;2.2288594;2.327506;IRRE
the class class sklearn model selection fixedthresholdclassifier allows us to;4.3939924;-5.45716;-3.9217613;2.3508744;0.964786;2.8689053;CODE
manually set the decision threshold at prediction time it behave as the previous;3.8920605;0.19602029;-0.4700148;4.9343143;-0.40457937;3.4324882;IRRE
tuned model but no search is performed during the fitting process note that here;1.552488;1.6051439;-2.6428564;1.3671124;-2.9899971;0.31283385;TASK
we use class sklearn frozen frozenestimator to wrap the predictive model to;3.3386486;-4.4314227;-1.8576194;1.913045;-2.306225;3.2195902;IRRE
avoid any refitting;-1.6381909;-0.025515636;1.298404;3.7613149;0.74830014;2.1352456;CODE
here we will reuse the decision threshold found in the previous section to create a;1.9436166;-0.38751337;0.9478934;2.554672;5.648581;0.50740075;IRRE
new model and check that it gives the same results;1.7421986;3.0321956;-0.29344726;5.3559813;1.1679523;-2.3697908;IRRE
we observe that we obtained the exact same results but the fitting process;6.5344787;1.2932969;-1.7957569;0.3663147;-2.9255579;3.6966414;IRRE
was much faster since we did not perform any hyper parameter search;2.4394636;-1.453591;-1.1567906;2.345838;0.022636209;0.74806666;IRRE
finally the estimate of the average business metric itself can be unreliable in;2.7830744;0.5422345;0.12673047;3.89574;-2.044943;1.8216573;CODE
particular when the number of data points in the minority class is very small;7.163643;1.683953;-0.91181666;-0.453407;1.47875;-1.147226;CODE
any business impact estimated by cross validation of a business metric on;2.5637422;1.0442836;-0.869142;3.8827124;1.6459821;1.983009;IRRE
historical data offline evaluation should ideally be confirmed by a b testing;1.544428;1.7031641;-1.494139;5.3184257;0.30591714;-1.1700773;IRRE
on live data online evaluation note however that a b testing models is;2.2137089;-1.4127017;-0.79413086;5.339374;1.5640087;-1.5912353;TASK
beyond the scope of the scikit learn library itself;-0.013115654;-13.87545;-2.830052;1.845976;-2.690272;-3.6500444;CODE
at the end we disable the configuration flag for metadata routing;-4.9244604;-0.34461844;-2.2304597;1.9984857;-0.81904763;6.315665;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
visualize our data;5.065977;-4.047928;8.501136;-3.691142;-0.12894437;-1.1113541;-
first we must understand the structure of our data it has 100 randomly;6.0440254;-0.6555881;3.6226943;-0.88489026;0.58109534;-2.886748;IRRE
generated input datapoints 3 classes split unevenly across datapoints;4.755621;0.89036524;-1.6632091;-2.799893;2.3933606;1.0458896;CODE
and 10 groups split evenly across datapoints;6.0347333;0.21058975;3.8076036;-3.2618368;1.3995755;-0.682575;CODE
as we ll see some cross validation objects do specific things with;-0.21235935;-1.4847412;-0.696773;5.733495;4.20669;0.39900035;CODE
labeled data others behave differently with grouped data and others;4.7846937;0.4700225;0.6667469;-0.077207774;3.4278278;0.39178574;CODE
do not use this information;-1.9951351;0.3623051;2.7298024;0.26640007;0.94219136;-3.1211243;CODE
to begin we ll visualize our data;3.5248945;-5.467844;7.508438;-1.5130838;0.65263325;-1.6678789;-
generate the class group data;2.970185;-1.7812284;1.5180618;-1.4191984;4.158863;-1.4748322;IRRE
generate uneven groups;4.009922;1.9645422;3.6725006;-3.942971;2.5522778;-1.3279798;-
visualize dataset groups;4.3108587;-4.681245;4.034727;-3.793087;0.087413885;0.6122499;IRRE
define a function to visualize cross validation behavior;2.8862164;1.0668678;2.843591;1.9216137;1.1711949;-0.6681809;CODE
we ll define a function that lets us visualize the behavior of each;2.5216987;-2.602663;8.073863;-0.8280842;2.0341752;-0.77675855;CODE
cross validation object we ll perform 4 splits of the data on each;4.7780514;0.50558126;1.5518736;0.61640286;5.0296;-1.1164893;CODE
split we ll visualize the indices chosen for the training set;5.8926067;-4.2754426;2.885401;-2.850166;3.4135697;0.06898899;IRRE
in blue and the test set in red;-1.4496069;0.41999474;2.3669863;1.7364622;1.9605408;-5.7122684;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we will load the diabetes dataset and create an instance of a linear;6.970929;-1.9333878;1.4623398;-0.72482234;2.2310717;0.6524172;IRRE
regression model;2.3866684;-0.2821941;5.6052012;1.2422508;-1.0823168;-2.3090656;-
func sklearn model selection cross val predict returns an array of the;3.3799047;-1.0102934;-3.8739016;0.93055534;-2.760721;-1.4094489;CODE
same size of y where each entry is a prediction obtained by cross;6.0494957;0.9024108;2.2545545;-2.288566;-1.5359926;0.50689363;CODE
validation;0.96128136;3.4564455;2.1926434;3.8922412;3.9736893;-5.883083;-
since cv 10 it means that we trained 10 models and each model was;0.94483614;-2.5936258;0.1634877;2.0888603;2.790746;-0.9412432;-
used to predict on one of the 10 folds we can now use the;1.8816905;-4.35967;2.9739878;2.4236746;0.36088672;-0.4614164;IRRE
class sklearn metrics predictionerrordisplay to visualize the;4.820404;-5.7619643;-2.4776342;0.21491942;-3.8732803;-0.9380584;IRRE
prediction errors;3.8111079;-0.9120129;0.2368998;4.4524093;-2.68746;-3.6592755;-
on the left axis we plot the observed values math y vs the predicted;2.3345933;-0.092199735;4.3012514;-1.3363134;-7.1865015;-0.9309703;IRRE
values math hat y given by the models on the right axis we plot the;2.1359174;-0.14242685;3.5837553;-4.677768;-5.3737283;-0.33626145;IRRE
residuals i e the difference between the observed values and the predicted;1.6144395;1.7100706;2.9766548;2.5514398;-3.480775;-0.19010432;IRRE
values vs the predicted values;5.25338;0.86650974;1.9290913;1.305152;-1.6580399;-3.101915;IRRE
it is important to note that we used;-3.6468656;-2.3223658;3.863829;3.1588912;0.7158389;-0.21179752;CODE
func sklearn model selection cross val predict for visualization;4.359036;-5.503589;-0.44788182;-0.43803895;-2.3789759;0.9106334;CODE
purpose only in this example;-3.0927577;-0.24167202;4.928727;3.1300356;3.2954412;-0.88649917;CODE
it would be problematic to;-3.1054125;-0.28011993;1.9993697;2.3675375;1.2278376;2.0793815;-
quantitatively assess the model performance by computing a single;6.3738155;-0.6959196;0.15762234;5.150225;2.7523677;-0.77949286;CODE
performance metric from the concatenated predictions returned by;6.405265;-1.8778855;0.088922046;3.3680055;1.7184504;-0.7411119;CODE
func sklearn model selection cross val predict;3.6375637;-2.9382985;-3.4692466;1.6873854;-1.0002042;-0.39069358;CODE
when the different cv folds vary by size and distributions;4.177175;-0.26545736;-1.0524296;0.39283764;0.7435661;4.636763;META
it is recommended to compute per fold performance metrics using;4.2991104;-2.0861597;-0.5637345;1.6548601;1.9902155;0.86858654;CODE
func sklearn model selection cross val score or;4.0108995;-2.5097165;-2.8807867;1.673972;0.49135986;-2.597928;CODE
func sklearn model selection cross validate instead;2.3618593;-0.30505303;-6.7469187;3.8710918;-0.118655734;-0.94050395;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate synthetic data;4.5756354;-2.3727534;0.245031;-2.5042067;1.6931053;-2.2762578;-
define the classifiers;3.4714296;-6.11052;0.06371739;1.6715608;6.207526;-0.69205993;CODE
here we define two different classifiers the goal is to visually compare their;3.7651312;-2.5803385;0.5650591;0.36171928;5.2497125;-0.27747977;IRRE
statistical performance across thresholds using the roc and det curves;6.6082425;-3.0444808;-1.4290186;1.6516256;1.3071055;-0.04823875;CODE
compare roc and det curves;4.105424;-1.8070662;-1.1507556;-0.6064851;-0.5488752;-0.786887;IRRE
det curves are commonly plotted in normal deviate scale to achieve this the;2.5591164;-0.9570183;3.4020703;-4.4553246;-3.9755728;2.1078484;CODE
det display transforms the error rates as returned by the;1.2358027;2.919038;-2.1487124;-1.3300716;-3.335535;-0.14153175;CODE
func sklearn metrics det curve and the axis scale using;3.9894392;-3.537581;-1.702563;-4.3406367;-6.396846;0.92138904;-
scipy stats norm;4.9902005;-2.6110628;-2.289819;-4.3711267;-5.4524975;-1.945091;-
notice that it is easier to visually assess the overall performance of;3.0540767;-1.7987964;3.1426365;4.1024837;1.1347717;0.5498278;CODE
different classification algorithms using det curves than using roc curves as;4.001569;-3.7674701;-1.8790902;-0.34921178;1.2198579;0.48857266;IRRE
roc curves are plot in a linear scale different classifiers usually appear;4.071626;-2.9617379;-1.7340968;-2.3130097;-2.2566903;2.1876228;IRRE
similar for a large part of the plot and differ the most in the top left;3.0748088;-0.8318171;6.997798;-2.575078;-3.8438368;0.35602558;CODE
corner of the graph on the other hand because det curves represent straight;-0.9188229;-0.24819954;3.4288256;-4.269522;-3.9261482;0.9518834;-
lines in normal deviate scale they tend to be distinguishable as a whole and;1.9964349;1.314167;0.47711396;-2.567522;-0.87525094;2.4208534;CODE
the area of interest spans a large part of the plot;2.836429;-1.058244;6.6950116;-1.8532904;-4.029931;2.787186;CODE
det curves give direct feedback of the detection error tradeoff to aid in;3.7116663;-0.3332865;-2.3098683;1.7198693;-2.7001197;0.8153403;-
operating point analysis the user can then decide the fnr they are willing to;2.2812824;-1.2244422;-0.6127063;3.15027;3.043324;0.14455698;CODE
accept at the expense of the fpr or vice versa;-3.9582045;0.82393247;1.3829385;2.1436439;2.171372;1.5005275;-
non informative classifier baseline for the roc and det curves;4.8822684;-5.0491023;-2.4323075;0.47286952;1.7603831;0.074626684;CODE
the diagonal black dotted lines in the plots above correspond to a;0.009233786;-0.38966155;2.9327667;-5.581593;-3.7673147;0.5436223;CODE
class sklearn dummy dummyclassifier using the default prior strategy to;1.9681568;-1.1214628;-3.9698496;3.508335;1.2324526;1.4916648;CODE
serve as baseline for comparison with other classifiers this classifier makes;4.236223;0.35406858;-1.6716136;2.6927712;3.9501064;0.02928996;CODE
constant predictions independent of the input features in x making it a;5.3030434;-1.1203256;0.18487482;1.5057452;-0.16113958;1.0396453;CODE
non informative classifier;4.1441107;-5.1473603;-1.3984452;1.886227;4.7223253;-0.31795937;CODE
to further understand the non informative baseline of the roc and det curves;3.7338364;-3.6657376;-1.6606709;0.05606285;0.7810831;-0.43253386;CODE
we recall the following mathematical definitions;1.0978372;-0.96673197;3.4780474;-1.0951273;3.6461456;0.9352596;IRRE
math text fpr frac text fp text fp text tn;-0.8893819;0.24657004;0.8320187;-3.9248695;0.3920274;-3.277412;-
math text fnr frac text fn text tp text fn;-0.05714703;0.013222913;-0.27531272;-4.560111;0.75216633;-3.3385406;-
math text tpr frac text tp text tp text fn;-0.9856382;0.46043724;0.31263375;-4.008734;0.603397;-3.0481606;-
a classifier that always predict the positive class would have no true;2.9806721;-0.54242927;-2.4734695;3.9814987;2.0584717;-0.73559964;IRRE
negatives nor false negatives giving math text fpr text tpr 1 and;-1.4032795;4.2399583;-2.7485716;-1.4498156;-1.4072744;-4.5808225;IRRE
math text fnr 0 i e;-0.1677944;0.81865287;-0.2865693;-4.6656837;-0.28030926;-5.206798;-
a single point in the upper right corner of the roc plane;-1.4006753;-1.0101148;1.5013961;-4.551356;-1.3901534;0.73723376;CODE
a single point in the lower right corner of the det plane;-1.2951317;1.3154643;2.6523325;-5.616953;-2.3258781;1.0746701;CODE
similarly a classifier that always predict the negative class would have no;2.3325117;-1.0116553;-1.0821809;3.0237494;1.9279191;-0.22349261;IRRE
true positives nor false positives thus math text fpr text tpr 0;-0.9432825;4.072925;-2.8936975;0.14668013;-0.08373549;-5.9461617;-
and math text fnr 1 i e;-0.37142372;-2.965391;-0.43057248;-2.0663404;1.4592252;-3.9574277;-
a single point in the lower left corner of the roc plane;-0.53858525;-0.84901464;0.81905115;-4.625504;-1.4854344;1.0890868;CODE
a single point in the upper left corner of the det plane;-1.3634353;1.6215522;2.5259845;-5.485913;-2.2861588;1.1297759;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the dataset;5.277134;-6.8034644;3.6287587;0.55348897;2.3989208;-2.8354812;IRRE
we will work with the digits dataset the goal is to classify handwritten;4.4553995;-5.019768;0.77523535;-0.8072898;2.4436219;-1.5501729;IRRE
digits images;1.9659846;-1.2457527;5.7092676;-4.8778315;0.13236865;-1.7343315;-
we transform the problem into a binary classification for easier;5.7475047;-3.4129717;1.9420382;-0.12883246;5.937621;-2.3904405;CODE
understanding the goal is to identify whether a digit is 8 or not;0.3271104;1.8377521;1.5389208;-2.0544899;1.802422;-5.424623;-
in order to train a classifier on images we need to flatten them into vectors;4.764633;-4.4208198;0.09880131;-2.0043814;0.8148534;2.966989;CODE
each image of 8 by 8 pixels needs to be transformed to a vector of 64 pixels;2.3374689;0.108428545;1.4990859;-6.4902406;-3.5117424;3.4459372;TASK
thus we will get a final data array of shape n images n pixels;5.081052;-0.6924408;3.7047079;-5.2193675;-0.040561374;2.8610027;CODE
as presented in the introduction the data will be split into a training;4.72287;-7.215386;2.492233;2.8011518;5.0611887;-0.2429856;CODE
and a testing set of equal size;4.220765;2.0452003;0.6508379;3.6861148;3.9840512;-2.0266395;IRRE
define our grid search strategy;3.3230615;-1.7390684;3.9484234;1.6450527;2.5740926;1.4532611;CODE
we will select a classifier by searching the best hyper parameters on folds;4.101117;-3.5640714;-0.29287294;0.8804463;3.903423;1.4306175;IRRE
of the training set to do this we need to define;1.8280966;-4.962504;4.03148;3.0479853;5.409352;0.5455729;CODE
the scores to select the best candidate;3.6793501;-1.2752899;3.6961973;2.4460776;3.7735207;-4.6135273;CODE
we can also define a function to be passed to the refit parameter of the;-2.1297204;-0.6839456;-0.7958673;1.6336132;1.9966018;4.225609;CODE
class sklearn model selection gridsearchcv instance it will implement the;3.0029335;-4.7788935;-4.5110965;1.3483378;0.29959476;1.3160015;CODE
custom strategy to select the best candidate from the cv results attribute;5.2986097;0.05100314;0.5682236;3.2975097;3.4656997;0.8074986;CODE
of the class sklearn model selection gridsearchcv once the candidate is;4.2739615;-4.026835;-4.0615273;1.4185065;1.0035589;0.09417318;CODE
selected it is automatically refitted by the;-4.1745048;-2.178246;3.1289856;1.9637221;2.0743306;3.5150821;IRRE
class sklearn model selection gridsearchcv instance;2.8091924;-4.446002;-5.335593;1.0014018;-0.4115381;0.7451756;CODE
here the strategy is to short list the models which are the best in terms of;3.5528195;-3.1370125;1.85317;3.3131075;3.8985517;0.8105409;CODE
precision and recall from the selected models we finally select the fastest;5.3853707;-4.011843;0.8666198;5.195973;2.7677524;0.16832276;CODE
model at predicting notice that these custom choices are completely;1.636411;-0.24868454;-0.71520275;5.320502;0.98725116;0.1493959;CODE
arbitrary;-0.13913737;-0.72523516;2.2436078;0.3155569;5.024316;-1.7922772;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
introduction;-2.25563;-4.974679;5.4843717;0.9232891;1.6598917;-1.9715575;CODE
when tuning hyperparameters we often want to balance model complexity and;4.420316;-1.5814593;-0.49597645;5.361446;1.1622665;2.8504248;IRRE
performance the one standard error rule is a common approach select the simplest;3.7611415;2.2856526;0.10774505;3.4477649;3.0089905;-1.3207806;CODE
model whose performance is within one standard error of the best model s performance;3.8442204;1.973506;-0.7068152;5.260835;1.2813843;0.8494872;CODE
this helps to avoid overfitting by preferring simpler models when their performance is;4.2464924;-2.3836467;-1.0240932;6.2324815;1.6260085;3.862208;CODE
statistically comparable to more complex ones;6.240925;-2.2275977;4.264237;2.5959466;1.9134054;-0.9815055;IRRE
helper functions;-2.2546968;-0.75392056;3.996788;0.25188038;0.45613816;-2.1225598;CODE
we define two helper functions;-2.8012033;0.30123606;2.7420304;1.2736603;2.1167877;1.5513955;CODE
1 lower bound calculates the threshold for acceptable performance;3.364313;1.6107706;-1.9165636;1.9818888;0.18165448;-0.8553895;CODE
best score 1 std;0.34300497;1.9362507;1.7434586;-1.0091105;1.1389841;-3.4702015;CODE
2 best low complexity selects the model with the fewest pca components that;4.9514604;-0.7847543;-1.9726154;0.5871649;3.8238394;2.5806131;META
exceeds this threshold;-0.32985446;2.2141988;1.3641981;1.7797505;-0.92086595;-2.7890873;CODE
set up the pipeline and parameter grid;1.145845;0.42177054;1.7801902;-1.7927867;0.5004589;4.1781015;IRRE
we create a pipeline with two steps;-1.1550893;-0.42135963;2.8718774;1.3518896;3.0654752;0.84163976;CODE
1 dimensionality reduction using pca;6.6435986;-1.993059;-0.9186844;-5.879853;1.1573994;3.4252107;-
2 classification using logisticregression;4.7137294;-1.8055403;-1.6855726;0.8027776;5.722329;-1.2928106;IRRE
we ll search over different numbers of pca components to find the optimal complexity;5.6655374;-1.1374748;-1.2681191;-1.9945368;3.5992458;3.02637;META
perform the search with gridsearchcv;1.3871325;0.4609348;-1.1483848;-0.8798038;-1.3258094;-0.116383895;CODE
we use gridsearchcv with our custom best low complexity function as the refit;4.1995416;-3.6730237;-1.8934258;0.28427535;1.3268096;2.5699227;META
parameter this function will select the model with the fewest pca components that;3.8731763;1.2488049;-1.0050447;-1.4033178;3.001436;2.4818807;CODE
still performs within one standard deviation of the best model;4.511056;1.2745261;-1.8924686;4.3792186;-1.126246;1.1760092;TASK
use a non stratified cv strategy to make sure that the inter fold;2.766343;1.9867632;-2.342457;2.620178;3.740013;2.418091;CODE
standard deviation of the test scores is informative;2.551172;0.065203734;-0.8852684;2.6240954;0.6384435;-3.7833467;IRRE
n jobs 1 increase this on your machine to use more physical cores;-0.78213465;-2.163624;0.4350649;0.074536756;-1.0852785;1.3463857;IRRE
load the digits dataset and fit the model;5.8729916;0.018865714;-0.31327975;-1.6429758;0.1509552;-1.0606751;IRRE
visualize the results;4.3798275;-2.13001;7.9000635;-1.9602988;-0.21193363;-3.3246593;IRRE
we ll create a bar chart showing the test scores for different numbers of pca;3.6984322;-0.5302725;2.3694632;-2.6538353;1.597343;-2.4021745;IRRE
components along with horizontal lines indicating the best score and the;2.3968809;-0.3263648;5.263493;-2.2901464;3.4912405;-0.63896596;-
one standard deviation threshold;3.2491457;1.8261111;-0.18045658;-0.78726745;0.25082377;-1.3201009;-
create a polars dataframe for better data manipulation and visualization;2.2444515;-2.8908756;3.4490612;-4.5717616;-2.4969323;-1.0620067;IRRE
sort by number of components;2.6338236;0.84542316;2.854956;-4.4444585;3.4860575;-0.06992155;-
calculate the lower bound threshold;2.4998405;2.5281637;0.5672627;-0.41573203;-0.3878533;-1.9823254;-
get the best model information;3.6066797;-3.972481;2.4732027;3.3821313;2.9309728;0.5416497;CODE
add a column to mark the selected model;1.5836327;-0.82426715;2.6666403;0.60273254;1.7095311;2.1029503;TASK
get the number of cv splits from the results;4.749574;0.8184601;0.4505634;-1.023818;2.3069618;-3.0360785;IRRE
extract individual scores for each split;4.768734;-0.47163716;2.0119815;-1.4780968;2.6732533;-2.694047;CODE
calculate mean and std of test scores;2.8321202;3.3194406;0.603649;-1.2363263;-0.31316662;-4.3622603;CODE
find best score and threshold;5.875209;1.3864596;2.6630177;-0.1960738;1.6939073;-3.966909;-
create a single figure for visualization;1.2506613;-1.6304781;7.9704313;-4.29846;-0.46379492;2.4141836;IRRE
plot individual points;4.092125;-0.026107809;6.922323;-6.755777;-4.109501;-0.35060513;CODE
plot individual test points;5.2647066;2.2722013;4.5535297;-3.6043324;-4.243161;-3.1771193;IRRE
plot individual train points;5.250848;-0.42488787;5.5879154;-4.9872518;-2.1236565;0.48136255;CODE
plot mean lines with error bands;2.8370817;2.6563504;2.3784165;-1.864546;-5.5221024;0.9047293;-
add threshold lines;1.6993053;0.76839226;3.947694;-3.5485103;-0.07762127;1.116188;TASK
color 9b59b6 purple;-2.7572944;0.29251412;1.6447355;-3.114935;2.4907262;-2.0603423;-
color e67e22 orange;-2.6303556;0.024001876;1.6945082;-2.2125115;1.9581697;-1.4043587;-
highlight selected model;0.6770084;-1.5863887;2.4823015;2.515856;1.8169839;2.2845807;CODE
color 9b59b6 purple;-2.7572944;0.29251412;1.6447355;-3.114935;2.4907262;-2.0603423;-
set titles and labels;-2.1502726;-1.3188492;5.250395;-1.3731568;3.9847457;0.319824;IRRE
set axis properties;1.1299088;1.4786364;4.2235484;-5.242538;-1.8006278;4.376883;IRRE
adjust layout;-2.6615272;-0.50347966;6.065951;-4.1317134;-0.29151687;4.241158;-
print the results;0.3690858;0.7737538;4.365928;-2.6709056;0.06621746;-7.371239;IRRE
we print information about the selected model including its complexity and;3.0539863;-2.5340357;1.7617813;0.8629183;4.4532413;0.07692833;CODE
performance we also show a summary table of all models using polars;3.8378096;-3.2205079;-0.540157;-0.14291604;1.1426374;0.6821323;CODE
create a summary table with polars;1.6411937;1.4940543;3.87349;-4.3627677;1.07722;-1.9889965;IRRE
add a column to mark the selected model;1.5836327;-0.82426715;2.6666403;0.60273254;1.7095311;2.1029503;TASK
conclusion;-1.760038;1.090336;5.187227;3.9331748;0.70637256;-3.3991337;-
the one standard error rule helps us select a simpler model fewer pca components;2.296631;0.68922526;-4.116548;1.0920074;1.8745382;2.9628844;CODE
while maintaining performance statistically comparable to the best model;6.1878567;-0.7797634;2.885231;7.824992;2.2269704;2.348229;CODE
this approach can help prevent overfitting and improve model interpretability;3.4016535;-1.9065478;-0.97322214;5.851888;3.1940868;0.8777494;CODE
and efficiency;0.12516876;-2.4273612;5.364335;3.1818237;1.9266894;0.13637866;CODE
in this example we ve seen how to implement this rule using a custom refit;-1.3680567;0.7849594;-0.31452554;0.5217108;2.712005;4.382262;CODE
callable with class sklearn model selection gridsearchcv;2.03121;-3.4969046;-5.402749;1.9135745;0.05098358;1.9909134;IRRE
key takeaways;-2.300701;-1.2104683;3.8978336;-0.7642804;1.7346194;-1.9976664;-
1 the one standard error rule provides a good rule of thumb to select simpler models;2.6132216;-0.9724088;-1.6986619;5.792216;2.0630012;0.08186568;CODE
2 custom refit callables in class sklearn model selection gridsearchcv allow for;-0.005262973;-2.6313484;-5.0908875;1.8566402;1.4859252;4.2122974;CODE
flexible model selection strategies;5.204755;-2.901358;1.725136;5.7536435;4.4108214;2.4708123;CODE
3 visualizing both train and test scores helps identify potential overfitting;3.814501;-1.7967453;0.14650878;2.5392246;0.24652156;-1.8597373;IRRE
this approach can be applied to other model selection scenarios where balancing;5.02872;-0.7331932;0.19215871;6.2722373;5.726283;4.0175114;CODE
complexity and performance is important or in cases where a use case specific;0.6663787;-1.4748565;2.524211;3.629247;4.35172;0.022844583;CODE
selection of the best model is desired;5.5647664;-1.716033;3.27017;5.217479;4.36499;1.4090796;CODE
display the figure;-2.6384306;0.4688597;8.343162;-3.1030397;-3.9256866;-0.1240834;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we will start by simulating moon shaped data where the ideal separation;4.678401;-2.4562995;2.5338142;-1.455184;0.75388825;2.0634897;-
between classes is non linear adding to it a moderate degree of noise;5.0833464;-0.76079446;-1.9108475;0.19435364;0.6767487;1.9765298;TASK
datapoints will belong to one of two possible classes to be predicted by two;5.673108;0.1420713;-0.43848735;0.7048343;3.9948204;-0.052471057;CODE
features we will simulate 50 samples for each class;6.227793;-3.6500666;0.6997228;3.3394186;4.572987;-1.9964695;CODE
we will compare the performance of class sklearn svm svc estimators that;5.15662;-6.335315;-3.6030824;2.5207217;-0.54424024;0.89804745;IRRE
vary on their kernel parameter to decide which choice of this;4.034134;0.008912503;-1.0531312;-0.45628107;1.9275618;2.4868517;CODE
hyper parameter predicts our simulated data best;6.7218804;-2.7113934;0.3679111;3.0039358;-0.022516456;1.6843306;IRRE
we will evaluate the performance of the models using;4.707405;-5.245856;2.1483023;6.332344;3.0660002;-0.29761055;CODE
class sklearn model selection repeatedstratifiedkfold repeating 10 times;2.5426319;-2.5110939;-2.9805007;2.024764;0.80047244;0.75116825;CODE
a 10 fold stratified cross validation using a different randomization of the;3.8475454;0.32033905;-1.5149566;3.7652085;4.5542264;-0.5287914;IRRE
data in each repetition the performance will be evaluated using;6.9876814;0.3453081;3.6668348;2.3257504;4.916589;-3.3029346;CODE
class sklearn metrics roc auc score;3.669472;-5.587502;-4.2739763;0.3388016;0.3518944;-2.3038938;IRRE
we can now inspect the results of our search sorted by their;-0.70956814;-3.4013107;1.3086799;2.6132245;0.47505218;-0.3989261;IRRE
mean test score;1.152814;4.0331764;1.6002961;1.3991693;-1.2743808;-5.3759933;IRRE
we can see that the estimator using the rbf kernel performed best;4.146928;-2.815356;-2.888546;3.0090947;-1.8023959;3.1814833;CODE
closely followed by linear both estimators with a poly kernel;4.011374;-1.8557355;-2.1580713;0.21833129;-0.085807525;6.494596;CODE
performed worse with the one using a two degree polynomial achieving a much;0.16026889;1.8750126;-0.9591864;-0.115119144;-2.9909117;-1.4873368;CODE
lower performance than all other models;2.5387716;-1.093776;-1.5809549;4.4005895;-0.92284805;1.5548042;CODE
usually the analysis just ends here but half the story is missing the;-0.5188947;0.032403868;2.2766492;3.8544683;-2.8423512;-0.562198;META
output of class sklearn model selection gridsearchcv does not provide;1.2145513;-2.7967904;-6.944338;0.30439937;-2.6484373;-0.29227334;CODE
information on the certainty of the differences between the models;3.2297227;-2.5942366;1.3713652;6.701398;1.356328;0.057872895;CODE
we don t know if these are statistically significant;1.5064199;0.78625417;0.48757434;2.7261324;-1.8156493;-4.891374;IRRE
to evaluate this we need to conduct a statistical test;1.8233082;2.4283092;3.9823267;4.3796444;1.6788421;-7.5869346;TASK
specifically to contrast the performance of two models we should;3.7878826;-2.2731056;2.6507766;7.170017;2.1777651;1.4652302;IRRE
statistically compare their auc scores there are 100 samples auc;3.933805;-0.8003901;0.6299355;2.3770895;1.0892636;-4.6520724;IRRE
scores for each model as we repreated 10 times a 10 fold cross validation;4.3032928;-0.9483364;0.16479647;2.3150582;2.4942017;-0.5877893;CODE
however the scores of the models are not independent all models are;2.3603992;0.18277188;-2.1946437;3.3018675;1.0158153;0.60161686;CODE
evaluated on the same 100 partitions increasing the correlation;4.973099;1.1284999;-0.2069847;0.7817748;1.1458902;0.18960585;CODE
between the performance of the models;4.713543;-3.6646104;2.3025718;5.611412;2.0965796;0.8338942;CODE
since some partitions of the data can make the distinction of the classes;4.040475;-2.6190045;-1.6101812;-0.19096814;7.665159;1.1033086;IRRE
particularly easy or hard to find for all models the models scores will;4.187454;-4.3415103;0.31170034;3.821236;1.6556803;-1.5966338;META
co vary;-0.29747123;-0.67401886;3.7197888;0.24154532;-1.633383;-0.5805203;CODE
let s inspect this partition effect by plotting the performance of all models;3.4588342;-2.026804;0.47009143;-0.16488966;-1.104861;2.325458;CODE
in each fold and calculating the correlation between models across folds;3.6364863;-2.1006262;0.5074176;-0.44242603;0.70652586;2.6684775;-
create df of model scores ordered by performance;5.2516313;0.78081083;0.822794;-0.09315424;0.9352756;0.005094573;IRRE
plot 30 examples of dependency between cv fold and auc scores;3.2427094;-3.2588224;-0.52645123;-0.7605635;-0.34226966;-0.4939059;CODE
print correlation of auc scores across folds;4.103194;-2.1030602;-0.7755919;-2.5929508;-0.43269837;-0.3667935;CODE
we can observe that the performance of the models highly depends on the fold;4.450807;-3.1464474;0.49556035;4.4777164;1.5066144;3.2520328;CODE
as a consequence if we assume independence between samples we will be;2.2972705;1.4958951;0.69721586;3.1599436;2.6048357;0.90903246;CODE
underestimating the variance computed in our statistical tests increasing;3.3747241;1.7469633;-1.7203797;6.885656;-3.4165776;-1.3419709;IRRE
the number of false positive errors i e detecting a significant difference;3.034508;4.279065;-1.1222721;3.2235713;1.092806;-7.522365;-
between models when such does not exist 1;0.85902184;3.3189414;-0.50277567;3.3619921;3.4648762;0.42008823;TASK
several variance corrected statistical tests have been developed for these;1.8369458;0.013332765;-2.5347698;5.2334075;-1.4247462;-3.0589309;CODE
cases in this example we will show how to implement one of them the so;-1.6674255;0.7626662;2.5486703;-0.96383905;6.3936787;-0.25311428;CODE
called nadeau and bengio s corrected t test under two different statistical;-0.23381537;3.0350752;-2.2950375;3.1785965;-0.19631997;-2.5004096;IRRE
frameworks frequentist and bayesian;2.2622552;-5.294637;2.4769843;6.1388717;1.6320539;0.9541535;-
comparing two models frequentist approach;2.8649864;-0.11068075;1.3177164;6.621554;0.60310125;-0.5247557;-
we can start by asking is the first model significantly better than the;1.3036114;-2.7910018;2.6632383;4.868877;0.479458;-0.75556505;-
second model when ranked by mean test score;2.3955445;2.5827634;0.35768133;3.79373;1.2352281;0.39079773;IRRE
to answer this question using a frequentist approach we could;1.7875202;-1.228325;5.5556865;5.28424;2.7259648;-0.9737362;CODE
run a paired t test and compute the p value this is also known as;1.7958059;4.7037835;1.1662428;1.3546829;0.22292444;-4.599489;IRRE
diebold mariano test in the forecast literature 5;1.5811036;0.7028696;-1.428841;4.064684;-1.1384223;-2.0362122;CODE
many variants of such a t test have been developed to account for the;1.861222;2.891751;-1.8271946;4.8656726;-0.8671319;-4.1941485;CODE
non independence of samples problem;1.770614;3.7909107;0.5202774;-0.71239716;1.0774127;-1.8662982;CODE
described in the previous section we will use the one proven to obtain the;-2.5441787;-2.4317203;0.83098465;2.1749747;3.3755484;0.18559231;CODE
highest replicability scores which rate how similar the performance of a;4.7449303;0.2516721;1.1260761;3.864828;1.91458;-1.4968343;CODE
model is when evaluating it on different random partitions of the same;3.2539816;0.30401966;-1.2210641;4.4520097;2.785058;0.7292647;IRRE
dataset while maintaining a low rate of false positives and false negatives;6.8864756;1.4887594;-0.6933203;2.4513578;2.257552;-2.521734;CODE
the nadeau and bengio s corrected t test 2 that uses a 10 times repeated;0.11302334;3.0502098;-1.8094527;4.5845513;0.9510738;-4.2343144;IRRE
10 fold cross validation 3;1.8670304;1.71155;0.51834327;-0.009946105;3.5523875;-3.3196542;-
this corrected paired t test is computed as;0.75773704;4.1214;-3.5654523;2.6368418;-1.539212;-3.0981212;IRRE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
t frac frac 1 k cdot r sum i 1 k sum j 1 r x ij;0.81430304;1.0865533;1.7078649;-5.2167044;-1.5204768;-1.8369278;CODE
sqrt frac 1 k cdot r frac n test n train hat sigma 2;2.3186014;1.3887333;-1.2656741;-1.3662039;-0.8397068;-4.048394;IRRE
where math k is the number of folds;-0.07639253;-1.5475111;2.271968;-3.6538954;0.76695293;-1.281477;-
math r the number of repetitions in the cross validation;1.9656018;1.0635643;1.590202;0.5921783;2.8437731;-4.0016575;CODE
math x is the difference in performance of the models;3.6959336;-1.6635158;1.4790928;2.1004007;0.5000892;-0.1635335;CODE
math n test is the number of samples used for testing;1.991356;2.7011864;0.70890445;1.2003044;1.1240222;-6.4552436;IRRE
math n train is the number of samples used for training;3.8061423;-1.4043505;2.0454454;-0.2845099;2.767833;-3.0575998;CODE
and math hat sigma 2 represents the variance of the observed;0.5626099;-0.20216243;-0.109208636;0.04602666;-1.1135215;0.29056364;CODE
differences;-1.9576571;-0.9835015;5.914867;1.4192206;0.96908283;-2.7626731;-
let s implement a corrected right tailed paired t test to evaluate if the;0.42719993;4.7996264;-0.3392665;3.603756;-0.7733618;-4.5348973;TASK
performance of the first model is significantly better than that of the;2.742614;-1.7494253;-0.2828694;5.004077;0.21209118;0.3425663;CODE
second model our null hypothesis is that the second model performs at least;1.6505293;2.8859315;0.09305488;5.3376064;-0.9358064;-0.43830898;CODE
as good as the first model;-0.09498009;-2.2438123;3.0409143;3.2980962;-0.7903859;-0.69457984;-
kr k times r r times repeated k fold crossvalidation;2.528375;-0.19662951;-1.007625;-2.2807193;2.5040104;-0.18763833;-
kr equals the number of times the model was evaluated;2.7860441;0.60464996;-0.004406339;1.4921267;0.9031258;-1.5213052;-
p val t sf np abs t stat df right tailed t test;0.2782417;2.0754855;-3.2650478;0.8866591;-3.6828218;-3.4343238;IRRE
model 1 scores model scores iloc 0 values scores of the best model;3.9352808;0.4495461;-1.5260748;2.1166105;0.5241348;-0.9844557;IRRE
model 2 scores model scores iloc 1 values scores of the second best model;3.7277427;0.15994768;-0.3831731;2.0862982;1.0307775;-0.35917243;IRRE
n differences shape 0 number of test sets;5.7113404;4.046003;-0.22383589;-1.7197605;1.2497772;-4.386847;IRRE
we can compare the corrected t and p values with the uncorrected ones;3.8917234;2.97756;-1.2848688;0.91029596;-0.8708357;-3.5958438;IRRE
using the conventional significance alpha level at p 0 05 we observe that;0.13864008;1.3137548;-2.3776307;1.8966283;-1.2474318;-2.9792626;-
the uncorrected t test concludes that the first model is significantly better;1.3324105;2.24669;-1.0866683;5.772672;-2.2147837;-3.2046456;IRRE
than the second;-1.4360169;0.75795;5.411065;1.2514378;-0.32139298;-2.2768526;-
with the corrected approach in contrast we fail to detect this difference;1.4496058;3.8054583;-2.1531115;4.876081;-0.73448694;-0.0005116613;CODE
in the latter case however the frequentist approach does not let us;-0.6134561;-1.072144;2.2141473;5.853281;0.59359187;1.3458282;CODE
conclude that the first and second model have an equivalent performance if;2.8158937;3.6050594;0.8349977;5.714634;3.0147495;1.0647522;CODE
we wanted to make this assertion we need to use a bayesian approach;2.4581163;0.5808631;3.5778546;5.5199714;2.3462114;-0.3503112;CODE
comparing two models bayesian approach;1.1786373;0.6270129;1.679443;5.18198;1.10664;0.29241922;-
we can use bayesian estimation to calculate the probability that the first;1.9414251;0.49736694;4.8362236;2.739645;3.213876;-0.31410307;-
model is better than the second bayesian estimation will output a;2.0172417;0.024489442;0.8030826;4.8694406;0.019671533;1.3721373;IRRE
distribution followed by the mean math mu of the differences in the;0.5282314;1.825197;3.2781432;0.020143185;-1.0598488;-0.6309;META
performance of two models;4.1712694;-0.8265876;1.0386275;5.0894265;1.6718546;0.6602675;CODE
to obtain the posterior distribution we need to define a prior that models;-1.3663354;-0.6730528;2.0611665;2.2368646;3.172016;3.8600736;CODE
our beliefs of how the mean is distributed before looking at the data;3.0587695;-0.4885567;4.322873;4.0528784;-1.6623373;0.91119915;META
and multiply it by a likelihood function that computes how likely our;3.627336;-0.24479504;3.4624827;1.1685821;-0.0829524;-0.5306496;CODE
observed differences are given the values that the mean of differences;3.101393;2.856492;3.798175;0.6018752;-1.181613;-1.228836;IRRE
could take;-2.267113;0.5817999;4.118927;0.7838732;-0.8302472;-1.7187735;-
bayesian estimation can be carried out in many forms to answer our question;3.870138;-1.0702055;4.5070543;3.9741871;2.223595;1.7850763;CODE
but in this example we will implement the approach suggested by benavoli and;1.1981732;-0.6196967;2.2245483;2.2635403;4.4497576;4.3705196;CODE
colleagues 4;-1.5859165;-2.9580336;4.529128;-0.53519;-0.9906072;-3.9628935;-
one way of defining our posterior using a closed form expression is to select;-1.162532;1.3282977;1.7576103;0.89142865;6.3854523;1.5436919;CODE
a prior conjugate to the likelihood function benavoli and colleagues 4;0.5701405;-0.7297618;-1.3708221;1.258039;0.032466326;3.3184578;CODE
show that when comparing the performance of two classifiers we can model the;4.859855;-0.68185174;-0.931435;4.318276;3.6757386;-0.5980892;CODE
prior as a normal gamma distribution with both mean and variance unknown;-2.0846937;0.8164864;0.604341;0.84958714;0.21992788;3.9627967;META
conjugate to a normal likelihood to thus express the posterior as a normal;-2.0665329;1.1780974;1.3414316;0.4228156;1.6746974;4.8673844;-
distribution;0.043183383;-0.20799337;6.2992086;-0.5853247;0.8105195;-3.5302904;META
marginalizing out the variance from this normal posterior we can define the;-0.8287475;0.30245367;1.5353156;0.7919729;3.1648352;5.240529;CODE
posterior of the mean parameter as a student s t distribution specifically;-0.6708194;-0.09441482;1.5694926;1.1443589;0.42791575;2.774284;IRRE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
st mu n 1 overline x frac 1 n frac n test n train;2.7531312;1.8171666;-0.21681535;-1.9035124;1.0837604;-3.3210683;IRRE
hat sigma 2;-1.0718224;-0.024938097;2.0291708;0.5275222;0.9548095;-1.3464946;-
where math n is the total number of samples;2.9317007;0.32055214;1.8810147;-2.3031812;2.1283658;-3.2750354;-
math overline x represents the mean difference in the scores;2.385226;2.285663;2.5613346;-2.9919076;-2.7021334;-2.5757637;CODE
math n test is the number of samples used for testing;1.991356;2.7011864;0.70890445;1.2003044;1.1240222;-6.4552436;IRRE
math n train is the number of samples used for training;3.8061423;-1.4043505;2.0454454;-0.2845099;2.767833;-3.0575998;CODE
and math hat sigma 2 represents the variance of the observed;0.5626099;-0.20216243;-0.109208636;0.04602666;-1.1135215;0.29056364;CODE
differences;-1.9576571;-0.9835015;5.914867;1.4192206;0.96908283;-2.7626731;-
notice that we are using nadeau and bengio s corrected variance in our;1.5648985;1.0385578;-1.7443886;2.076092;-0.6744281;1.0062609;CODE
bayesian approach as well;4.0210743;-2.9963887;5.522059;3.9210634;2.4881;-0.632496;-
let s compute and plot the posterior;-0.49751157;0.4628321;5.212558;-2.237958;-0.678676;0.07175474;CODE
initialize random variable;-2.548422;1.5627984;2.1109915;0.6058829;0.8640733;-0.47075784;IRRE
let s plot the posterior distribution;-1.5717505;-0.55213624;5.3299055;-2.3570309;-1.7750553;0.5348373;META
we can calculate the probability that the first model is better than the;3.7459404;-0.54434633;2.321308;6.453737;2.6023788;-0.019805625;-
second by computing the area under the curve of the posterior distribution;-0.38679036;-1.2971019;3.5907896;-0.26684767;-0.7076696;2.7345757;META
from zero to infinity and also the reverse we can calculate the probability;-1.476038;1.0841463;3.5540557;0.09363958;-0.8344973;-1.8943871;IRRE
that the second model is better than the first by computing the area under;3.870721;-0.34335366;2.678921;1.5081605;0.09027783;2.1211758;-
the curve from minus infinity to zero;-1.757066;1.7269166;3.0916705;-2.4428525;-5.3505845;0.60154873;IRRE
in contrast with the frequentist approach we can compute the probability;2.8453786;-2.7633822;3.5913513;5.309072;1.9923884;0.23127182;-
that one model is better than the other;0.20881028;-3.3047934;1.8860167;3.1380858;-0.2990415;1.1033198;-
note that we obtained similar results as those in the frequentist approach;4.7387414;-2.1655855;0.17311308;4.2284093;1.7570468;1.5159876;TASK
given our choice of priors we are essentially performing the same;2.0581353;0.9045786;3.4739087;6.2430596;2.6013105;2.7915921;CODE
computations but we are allowed to make different assertions;1.2259349;3.4405322;-1.7919935;2.1744688;1.3791542;-2.7639253;META
region of practical equivalence;-0.8002223;2.5978715;2.588649;0.5150273;2.5124586;2.0191102;-
sometimes we are interested in determining the probabilities that our models;3.4050596;-4.6693006;2.9925191;6.2373376;1.4729323;-0.61285037;CODE
have an equivalent performance where equivalent is defined in a practical;3.0059183;0.9812084;0.718647;5.394072;3.7342649;1.2306147;CODE
way a naive approach 4 would be to define estimators as practically;4.9021235;-1.8745571;2.9455101;4.86391;1.7673739;1.9389073;IRRE
equivalent when they differ by less than 1 in their accuracy but we could;5.3742495;0.9447096;-0.07538874;2.7211485;2.7858825;-2.1624787;META
also define this practical equivalence taking into account the problem we are;-0.3141593;0.59126174;1.0341696;3.8820152;2.885144;1.8478297;CODE
trying to solve for example a difference of 5 in accuracy would mean an;3.802279;2.3713403;2.6711242;-0.14673066;0.11800308;-5.29433;CODE
increase of 1000 in sales and we consider any quantity above that as;0.9020871;0.80312806;2.8382695;0.003880802;1.2191354;-0.82810193;-
relevant for our business;-1.9354289;-1.1710525;5.2045236;2.8389091;3.2883565;0.12373687;CODE
in this example we are going to define the;-1.9416012;0.83507067;4.8098288;1.4826392;4.182619;-0.086055115;CODE
region of practical equivalence rope to be math 0 01 0 01 that is;-1.5671976;3.2259114;0.83998865;-2.9248915;-0.9186186;-1.3623513;-
we will consider two models as practically equivalent if they differ by less;2.8632145;0.27353603;-0.5049183;4.847935;2.9118316;2.9773054;IRRE
than 1 in their performance;2.1958883;1.1952238;2.6128073;1.3440841;1.430451;-4.124601;CODE
to compute the probabilities of the classifiers being practically equivalent;5.738249;-3.8008697;-2.0703273;2.646021;5.138418;0.67854846;IRRE
we calculate the area under the curve of the posterior over the rope;-1.1444801;0.19335468;5.139066;-0.346071;-1.6196418;2.164535;-
interval;-1.8003745;2.6089041;6.329856;-2.2632957;-0.2892649;-4.501036;CODE
we can plot how the posterior is distributed over the rope interval;0.37231338;-0.6265894;5.268897;0.487744;-1.5210178;3.1974552;CODE
as suggested in 4 we can further interpret these probabilities using the;1.2900296;-0.42397717;1.817108;0.46764788;2.4727833;-2.9858828;CODE
same criteria as the frequentist approach is the probability of falling;2.0156014;-0.9281388;3.7299783;5.051698;-0.64494944;-0.36885008;-
inside the rope bigger than 95 alpha value of 5 in that case we can;-1.9764445;2.6729853;2.2842894;-0.06734024;-1.649261;-1.7693634;CODE
conclude that both models are practically equivalent;1.4233181;1.6599388;-0.5458929;5.4526463;1.5113018;2.3820896;IRRE
the bayesian estimation approach also allows us to compute how uncertain we;3.6378036;-1.3048643;2.2579188;5.055832;-0.23755121;1.356839;META
are about our estimation of the difference this can be calculated using;5.089868;1.706881;2.2143152;2.5162804;0.56566805;-0.56448716;CODE
credible intervals for a given probability they show the range of values;2.3221314;1.6671388;1.597466;1.5451669;-1.1296299;-1.8918394;IRRE
that the estimated quantity in our case the mean difference in;2.411307;2.3083413;3.9254367;2.412735;-0.9676537;0.7323785;IRRE
performance can take;1.7000213;-0.48453447;4.852868;4.1259055;0.74656564;-1.7200354;CODE
for example a 50 credible interval x y tells us that there is a 50;1.1312709;2.5124223;-0.15667269;2.011154;0.3575834;-2.2398677;CODE
probability that the true mean difference of performance between models is;3.584275;0.6834735;1.6513084;6.377869;0.04109091;0.61000264;CODE
between x and y;-0.91878873;1.267695;6.8721457;-4.7232604;-0.39845064;-4.1388655;-
let s determine the credible intervals of our data using 50 75 and 95;3.1477666;2.0297012;0.8591768;1.2528157;-0.73301727;-4.582843;CODE
as shown in the table there is a 50 probability that the true mean;1.1937585;2.683403;2.3823483;0.86233455;-0.6013376;-3.4286594;CODE
difference between models will be between 0 000977 and 0 019023 70;-0.00046965675;-0.15773135;-3.1804523;-1.3615826;0.51628065;-2.0897508;-
probability that it will be between 0 005422 and 0 025422 and 95;-0.30136842;1.121856;1.0809038;-1.4475698;-0.11972415;-4.239372;-
probability that it will be between 0 016445 and 0 036445;-1.3411615;1.235559;1.3727185;-3.0833397;1.3074677;-3.7428708;-
pairwise comparison of all models frequentist approach;3.9984033;-0.60982364;-0.5259029;4.832808;1.2855092;0.26813537;-
we could also be interested in comparing the performance of all our models;4.5608616;-4.487352;0.8476988;6.5427155;1.4822888;0.28879553;CODE
evaluated with class sklearn model selection gridsearchcv in this case;3.9053092;-2.220628;-5.67356;1.6155437;-0.9478646;-1.1295916;CODE
we would be running our statistical test multiple times which leads us to;1.8202913;1.1568117;2.9972901;7.072945;1.5629251;-4.4075527;CODE
the multiple comparisons problem;3.7885368;3.8403835;2.7419665;2.9332438;1.9360245;-5.34051;-
https en wikipedia org wiki multiple comparisons problem;-0.51829344;0.05605955;0.22663456;1.034229;1.1729373;-4.621318;CODE
there are many possible ways to tackle this problem but a standard approach;3.0663218;3.2122118;4.358285;-1.4810764;4.5779696;-0.44967848;CODE
is to apply a bonferroni correction;0.18615222;1.8730545;0.20346567;1.48759;-1.0686542;0.31264648;-
https en wikipedia org wiki bonferroni correction bonferroni can be;-1.42858;-1.8602468;0.95183754;0.60231745;-0.5863726;-0.6711671;CODE
computed by multiplying the p value by the number of comparisons we are;2.8534558;4.3661313;0.6236473;-0.03333428;-0.5615419;-3.5118966;IRRE
testing;0.41263783;2.6793628;3.7061396;7.3983064;-0.056313585;-9.434767;IRRE
let s compare the performance of the models using the corrected t test;3.4230783;1.6248286;-2.0459151;6.6002917;-2.0188646;-3.7335668;IRRE
p val n comparisons implement bonferroni correction;3.0876572;1.4758031;-2.4468002;1.0059158;-1.1697223;-1.6745166;TASK
bonferroni can output p values higher than 1;1.506325;3.6376143;-1.8681917;-1.5893196;-2.7832534;-1.2571483;IRRE
we observe that after correcting for multiple comparisons the only model;2.1794615;1.9586717;-0.70442134;7.629754;-0.23784655;0.023128644;CODE
that significantly differs from the others is 2 poly;0.13933995;0.269023;1.2907294;-1.9950866;2.871305;-2.0654883;CODE
rbf the model ranked first by;3.351258;-1.3485864;-0.4622103;1.5759462;3.2888389;0.31932887;-
class sklearn model selection gridsearchcv does not significantly;3.902457;-2.8342721;-6.74292;1.7039099;-2.7939503;0.6084744;CODE
differ from linear or 3 poly;0.9120126;0.29724726;1.3137125;-5.0365834;2.6183789;-0.48190027;CODE
pairwise comparison of all models bayesian approach;3.022893;-0.06176375;-0.44027376;3.708928;1.6555977;0.5624145;-
when using bayesian estimation to compare multiple models we don t need to;1.5468578;-0.004823675;0.3203128;5.4772954;0.6004806;3.17074;TASK
correct for multiple comparisons for reasons why see 4;0.5847677;4.121153;1.0204586;1.8663694;0.93330514;-3.6795063;CODE
we can carry out our pairwise comparisons the same way as in the first;3.5335639;1.2319441;1.3805106;3.1237464;3.5089655;-1.1568764;CODE
section;-4.17123;-2.589122;6.224334;0.34122834;2.9793594;-1.002325;-
using the bayesian approach we can compute the probability that a model;2.5062509;-2.5170777;3.2004392;5.1816897;2.6505613;0.13625218;-
performs better worse or practically equivalent to another;1.0322441;0.5375953;2.580723;6.258159;-0.080195196;-0.8087703;IRRE
results show that the model ranked first by;3.1802213;0.53012466;0.96876377;1.7549729;1.2584573;-0.98610187;IRRE
class sklearn model selection gridsearchcv rbf has approximately a;4.878914;-2.86047;-5.8154764;-0.8828222;-0.8495649;-0.180791;CODE
6 8 chance of being worse than linear and a 1 8 chance of being worse;3.5292766;1.1989713;0.85175407;0.8415871;-1.0801919;-1.1544806;IRRE
than 3 poly;-1.0336492;2.0428436;3.1799543;-3.1257164;2.9850795;-2.80437;-
rbf and linear have a 43 probability of being practically;2.543124;0.60338825;-0.013009912;-1.2640333;0.8009281;-0.7339158;IRRE
equivalent while rbf and 3 poly have a 10 chance of being so;-0.21892768;1.2252734;-1.0115842;-0.51330626;4.1779423;-1.0681381;CODE
similarly to the conclusions obtained using the frequentist approach all;1.9975346;-2.4084966;2.096852;5.7385335;1.5670781;0.0074736634;-
models have a 100 probability of being better than 2 poly and none have;2.2728171;1.2851663;-0.41565865;3.5620108;1.9745592;-2.1205087;-
a practically equivalent performance with the latter;3.663888;-2.0674033;2.8340073;4.75843;3.5482798;1.7228746;IRRE
take home messages;-3.1533787;-0.06359204;4.3255625;1.3888717;-0.7090182;0.50089514;-
small differences in performance measures might easily turn out to be;4.665326;-0.1918829;-0.64483386;6.2263017;0.53535116;0.9938617;CODE
merely by chance but not because one model predicts systematically better;3.9207604;-1.4092515;1.2522137;8.218848;-0.70320845;0.62131155;IRRE
than the other as shown in this example statistics can tell you how;4.286335;1.3475226;3.846656;-0.21057516;0.23251352;-2.0316834;CODE
likely that is;-1.867489;-2.3636749;0.99555796;2.0380034;-1.0454928;-0.05701314;-
when statistically comparing the performance of two models evaluated in;3.4698873;0.36724862;0.0023696956;7.425965;-0.18150663;-1.5975913;IRRE
gridsearchcv it is necessary to correct the calculated variance which;3.5223234;1.1214834;-3.1696815;0.36250868;-2.6420302;0.6036327;CODE
could be underestimated since the scores of the models are not independent;4.6608353;-0.4139559;-1.7406359;5.353336;-0.74342936;-0.26470518;CODE
from each other;-2.4402564;-2.4959357;7.137789;-0.48789442;0.53444594;-1.8099025;CODE
a frequentist approach that uses a variance corrected paired t test can;4.0676837;1.06783;-0.63697505;7.403998;0.52096164;-1.1751435;IRRE
tell us if the performance of one model is better than another with a;3.1240957;-0.33840773;1.785699;5.059532;1.5654697;-0.4743827;CODE
degree of certainty above chance;1.5625105;0.054034453;1.2201096;3.8599412;1.0922732;-2.4389906;CODE
a bayesian approach can provide the probabilities of one model being;3.6519182;-3.142689;3.414365;4.9836564;4.100402;1.2612613;-
better worse or practically equivalent than another it can also tell us;1.1823628;-0.39670938;2.923935;4.7617946;-0.5521252;-1.8108873;IRRE
how confident we are of knowing that the true differences of our models;3.397346;-2.1529837;1.4863404;8.154863;0.17176336;-1.0070347;-
fall under a certain range of values;4.0549994;5.5535655;3.328478;-2.9381623;-0.44269237;-3.620802;IRRE
if multiple models are statistically compared a multiple comparisons;2.6391366;1.5936792;0.8342385;5.6296496;0.9865752;-0.21240231;IRRE
correction is needed when using the frequentist approach;1.7497399;0.6914827;-0.7534833;4.742623;-0.40264836;-0.8220279;-
rubric references;-1.30285;-4.5029125;2.0068364;-0.5395812;0.9139038;-2.8480213;CODE
1 dietterich t g 1998 approximate statistical tests for;4.671299;1.0198463;-1.7891815;3.828874;-1.6303337;-2.0304868;IRRE
comparing supervised classification learning algorithms;5.57548;-4.3375554;-1.0828727;2.8278434;3.639218;-0.8457624;CODE
http web cs iastate edu jtian cs573 papers dietterich 98 pdf;-2.8042538;-3.1016815;0.4533079;0.08096099;1.9572061;0.5009691;CODE
neural computation 10 7;2.6498485;-1.5206263;1.8578023;-1.5472131;2.007647;-2.210199;-
2 nadeau c bengio y 2000 inference for the generalization;3.5304081;-1.588366;-2.3647938;0.9504573;2.5205061;1.6499652;CODE
error;-5.63395;2.4462695;1.2432225;-0.761733;-1.536994;-4.77406;-
https papers nips cc paper 1661 inference for the generalization error pdf;0.20739792;-1.5711529;-5.685318;2.0468802;0.40131065;2.0666595;CODE
in advances in neural information processing systems;1.9586035;-1.3628602;1.4453499;-1.3472936;1.6609976;1.9086202;CODE
3 bouckaert r r frank e 2004 evaluating the replicability;-0.4564811;-0.92243207;-1.8415738;1.5760239;0.56201965;-1.079281;-
of significance tests for comparing learning algorithms;5.9405165;-2.5410533;-0.7125498;5.9075656;1.7913957;-4.121758;IRRE
https www cms waikato ac nz ml publications 2004 bouckaert frank pdf;-2.9583566;-2.6550026;1.4419891;-0.17166227;0.98229456;0.009595647;CODE
in pacific asia conference on knowledge discovery and data mining;1.9650527;-4.2275887;0.99552065;1.9093019;3.594828;-0.046495244;-
4 benavoli a corani g dem ar j zaffalon m 2017 time;-1.503597;0.23208432;1.7335036;-1.5611137;1.2860547;-1.6685332;-
for a change a tutorial for comparing multiple classifiers through;3.1924727;-4.26277;-1.3036162;3.1541886;3.9699512;-2.6994348;CODE
bayesian analysis;2.486448;-1.595535;5.0685077;3.9152417;1.9657001;-1.4849339;-
http www jmlr org papers volume18 16 305 16 305 pdf;-4.263178;-3.5516622;-0.81940025;0.065545954;2.0623412;0.32691002;CODE
the journal of machine learning research 18 1 see the python;3.2298574;-9.839663;-1.7446649;2.8644214;0.7601851;-2.3427348;CODE
library that accompanies this paper here;-1.1754291;-7.4340067;0.562674;0.15886289;0.8310798;1.8483924;CODE
https github com janezd baycomp;-4.370024;-6.9150443;1.4059702;-1.3133336;-0.42230627;-1.1046944;CODE
5 diebold f x mariano r s 1995 comparing predictive accuracy;3.8277252;-1.0621436;-2.5491762;2.4175622;0.0089292275;-1.5558326;-
http www est uc3m es esp nueva docencia comp col get lade tecnicas prediccion practicas0708 comparing 20predictive 20accuracy 20 dielbold pdf;-0.6938284;-1.3002511;-3.8242385;0.43888694;0.6087716;-1.2437183;CODE
journal of business economic statistics 20 1 134 144;-1.6289687;-1.0005752;1.9430505;0.5393771;0.9909675;0.21829756;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data loading;0.9534975;-0.6701537;4.9427156;0.32689142;0.121804215;0.2571383;CODE
we load two categories from the training set you can adjust the number of;2.4077413;-3.6373153;1.527593;1.3161315;5.259438;0.18059906;CODE
categories by adding their names to the list or setting categories none when;-0.9260919;-1.1191404;1.0374558;2.0565767;2.2080781;0.26849294;TASK
calling the dataset loader func sklearn datasets fetch 20newsgroups to get;1.8842883;-2.5734017;-2.9198077;1.2165831;-1.378891;0.31434113;IRRE
the 20 of them;-0.5644722;-0.41822016;4.8104477;0.76433206;0.09188395;-3.9228797;-
pipeline with hyperparameter tuning;3.5139189;-0.041624773;-1.1481663;3.2242928;1.619086;2.4578803;CODE
we define a pipeline combining a text feature vectorizer with a simple;2.5117097;-5.0065866;0.3890632;0.33709285;3.4622133;2.2682076;CODE
classifier yet effective for text classification;4.022509;-5.6137013;-0.6963111;4.5977306;2.970715;-0.8788653;CODE
we define a grid of hyperparameters to be explored by the;4.4361343;-2.7314568;1.7284051;0.5900504;3.520293;2.5429406;CODE
class sklearn model selection randomizedsearchcv using a;5.222904;-4.800987;-5.60933;2.227213;1.1078824;-0.12154929;IRRE
class sklearn model selection gridsearchcv instead would explore all the;3.2741208;-3.9561634;-3.7663019;1.8489243;-0.6628017;1.8669962;CODE
possible combinations on the grid which can be costly to compute whereas the;4.7135267;-0.8367842;2.2451363;-2.1928697;2.9732158;-0.08889644;-
parameter n iter of the class sklearn model selection randomizedsearchcv;3.8704212;-4.650133;-6.02827;1.6423358;0.7676436;0.551417;IRRE
controls the number of different random combination that are evaluated notice;0.5365231;1.6886625;1.3813008;3.456567;4.8531356;-1.9329484;IRRE
that setting n iter larger than the number of possible combinations in a;1.655882;0.52294606;1.2927631;-2.753683;2.3505921;-2.786674;IRRE
grid would lead to repeating already explored combinations we search for the;3.0315819;-1.2605214;4.1657305;-0.07214916;3.593656;0.9536112;CODE
best parameter combination for both the feature extraction vect and the;3.2666194;-3.528498;-1.324632;-0.10095978;4.4812703;1.9873372;TASK
classifier clf;3.4033215;-5.014963;-1.8394111;0.9694159;3.6432521;-1.5858436;IRRE
vect ngram range 1 1 1 2 unigrams or bigrams;1.2187818;0.97881097;0.6142474;-5.8683114;0.7722258;-0.09134595;-
in this case n iter 40 is not an exhaustive search of the hyperparameters;1.5088392;1.4329;-2.645246;1.668743;0.21490255;-0.34466395;CODE
grid in practice it would be interesting to increase the parameter n iter;0.42070812;-0.7467012;2.733102;-1.693128;1.6032255;3.6729727;IRRE
to get a more informative analysis as a consequence the computional time;1.8389966;-4.856258;2.6633751;3.8638093;0.91257674;-1.9759109;CODE
increases we can reduce it by taking advantage of the parallelisation over;2.1422613;-1.9347981;3.1425173;1.7465065;0.13740736;4.175396;-
the parameter combinations evaluation by increasing the number of cpus used;4.41165;-1.306258;0.55949646;0.11327355;3.0275233;-0.060176417;IRRE
via the parameter n jobs;0.67256063;-0.53363204;1.4632752;0.2588837;3.6215775;0.30222255;IRRE
the prefixes vect and clf are required to avoid possible ambiguities in;-2.7089126;-1.6622581;-2.8839245;-1.0076255;2.8991108;0.09569592;CODE
the pipeline but are not necessary for visualizing the results because of;1.90518;-2.1471558;1.581071;2.1694558;-0.15583327;0.98428094;CODE
this we define a function that will rename the tuned hyperparameters and;2.18219;-0.8002855;0.93572015;0.57772523;3.0739284;2.1305766;CODE
improve the readability;-0.52873933;-1.3909279;1.7553631;2.0209625;0.93080246;-3.1765897;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
learning curve;6.0015316;-5.5462685;3.8412647;0.75879085;-1.4137529;-0.8485809;-
learning curves show the effect of adding more samples during the training;4.660666;-3.8469262;2.708593;3.6452913;-0.35129848;0.34716815;TASK
process the effect is depicted by checking the statistical performance of;3.7917016;-0.1279813;2.6443138;5.796619;0.38361618;-1.4310912;CODE
the model in terms of training score and testing score;2.924013;-2.8433988;1.3922987;5.2826533;2.1660614;-3.7845807;IRRE
here we compute the learning curve of a naive bayes classifier and a svm;4.7591276;-6.251996;0.33681104;-0.012445864;2.3973236;-0.30056453;IRRE
classifier with a rbf kernel using the digits dataset;4.7431316;-3.9943943;-3.5046232;-2.4400816;2.501017;-1.0210979;IRRE
the meth sklearn model selection learningcurvedisplay from estimator;5.848834;-5.3006415;-2.8505027;3.8630908;-0.36963126;2.027763;CODE
displays the learning curve given the dataset and the predictive model to;5.030838;-6.2030864;2.30486;1.0901642;-2.0400145;-0.01469557;IRRE
analyze to get an estimate of the scores uncertainty this method uses;5.0607657;1.1542662;1.3289946;3.804102;-0.6102008;-2.0296783;CODE
a cross validation procedure;3.08847;1.1238403;1.2653028;3.0136497;5.882644;-3.4863207;-
we first analyze the learning curve of the naive bayes classifier its shape;4.8091173;-5.916;0.8692034;1.3045107;2.3582728;0.08834158;IRRE
can be found in more complex datasets very often the training score is very;6.8821173;-5.212285;-1.8965153;2.9857898;1.324545;-2.2908945;IRRE
high when using few samples for training and decreases when increasing the;4.188567;0.9562339;-0.41790265;2.7649388;-1.3795847;-0.80001;CODE
number of samples whereas the test score is very low at the beginning and;2.7988498;4.3877835;-1.5590225;2.1149943;-0.676813;-5.355856;IRRE
then increases when adding samples the training and test scores become more;3.7490075;0.5338638;0.9142697;4.168442;0.58063287;-1.4289533;TASK
realistic when all the samples are used for training;6.8202524;-1.5379698;1.2706407;6.046123;0.96453077;-0.7797818;CODE
we see another typical learning curve for the svm classifier with rbf kernel;4.1673126;-7.4661827;-1.9097062;-0.17230956;0.7146965;1.9984462;IRRE
the training score remains high regardless of the size of the training set;3.4258263;1.1213156;-1.4797833;2.7134712;-0.41617164;0.5103684;IRRE
on the other hand the test score increases with the size of the training;3.0246518;0.52538204;0.15486622;4.909381;1.0699195;-0.71498424;IRRE
dataset indeed it increases up to a point where it reaches a plateau;5.5247273;-2.2239687;3.415693;-0.23978297;-2.5919235;2.2607985;IRRE
observing such a plateau is an indication that it might not be useful to;1.9726632;0.7190134;2.4505575;5.3747334;-3.445676;2.448068;-
acquire new data to train the model since the generalization performance of;5.478652;-3.7794015;1.0721989;4.167093;4.3941307;2.1224875;CODE
the model will not increase anymore;-2.4884248;-0.74061316;1.4015002;2.0479684;-3.262682;1.3103626;OUTD
complexity analysis;2.7954674;-0.40480107;2.4564009;0.56013143;2.244385;-3.6083088;META
in addition to these learning curves it is also possible to look at the;5.662364;-7.3706546;2.4231002;2.4267237;-0.13555692;0.30817753;TASK
scalability of the predictive models in terms of training and scoring times;6.0722795;-5.927134;0.12482297;5.193443;1.8683248;1.4120058;CODE
the class sklearn model selection learningcurvedisplay class does not;0.3282485;-4.6863422;-6.571333;1.784915;-0.6012478;0.48528573;CODE
provide such information we need to resort to the;-2.8502567;-3.2410438;3.2222784;2.6474273;1.3746804;-0.690028;TASK
func sklearn model selection learning curve function instead and make;3.302921;-4.080272;-3.520682;1.1451594;-2.9922266;0.91052705;CODE
the plot manually;-0.08330566;-3.0696378;7.1971865;-3.1146188;-6.189009;-0.77256167;-
scalability regarding the fit time;5.210042;-1.4871547;1.1519837;2.154077;-0.2476114;2.9751654;-
scalability regarding the score time;4.8909225;-1.9126694;1.852353;2.3800626;2.5108478;-0.7546109;-
we see that the scalability of the svm and naive bayes classifiers is very;4.910297;-6.972684;-1.4218931;2.056428;1.6726936;1.3155872;IRRE
different the svm classifier complexity at fit and score time increases;5.1949816;-3.0961444;-3.0209837;0.45757133;0.6289513;1.7009898;IRRE
rapidly with the number of samples indeed it is known that the fit time;7.1792994;-1.1498696;1.0680015;2.7944565;-0.68501383;-0.19252662;CODE
complexity of this classifier is more than quadratic with the number of;3.672579;-1.2855536;-2.2948754;-0.7529122;2.5583816;-1.247162;CODE
samples which makes it hard to scale to dataset with more than a few;7.319289;-1.5829186;1.94774;0.345076;0.39912608;0.48595172;IRRE
10 000 samples in contrast the naive bayes classifier scales much better;5.586665;-4.0517135;-1.7025157;2.5290806;1.489155;-1.392697;IRRE
with a lower complexity at fit and score time;6.3336287;-1.3886943;0.6100114;2.6806228;3.2285008;-0.038437292;META
subsequently we can check the trade off between increased training time and;1.9408851;-2.4198318;1.587054;5.9981647;0.9901619;1.1542681;-
the cross validation score;3.0729089;-0.49764904;1.0937072;2.3632903;2.0002873;-4.762267;-
in these plots we can look for the inflection point for which the;0.4761897;0.45361283;4.2273674;-2.0516522;-4.315058;0.12951927;CODE
cross validation score does not increase anymore and only the training time;1.3076547;1.3000832;-1.9736307;2.6135406;-2.134372;-0.34159765;CODE
increases;-0.99501455;0.08633936;6.301317;0.09659627;-0.92323613;-2.7355933;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
pre test vs post test analysis;0.515278;2.0477502;0.84323245;5.6736627;-0.34831396;-3.5222578;IRRE
suppose we have a population of subjects with physiological measurements x;2.9484355;2.734987;4.5469885;1.3469969;0.6044763;-0.6878262;-
that can hopefully serve as indirect bio markers of the disease and actual;-0.79029465;-1.2520763;0.02956956;0.45651007;1.1651351;-0.6285687;-
disease indicators y ground truth most of the people in the population do;1.1562194;-1.1259958;2.0065062;1.5803354;-0.39509937;-1.6319932;CODE
not carry the disease but a minority in this case around 10 does;-1.7107527;2.2595317;-0.55583024;2.1286497;0.7879923;-0.5524361;CODE
a machine learning model is built to diagnose if a person with some given;4.60365;-2.6614506;1.1288341;4.741807;3.4149535;-3.27529;-
physiological measurements is likely to carry the disease of interest to;0.6147113;-0.87978417;2.3133636;3.111895;-1.0349008;-0.8249349;CODE
evaluate the model we need to assess its performance on a held out test set;3.5121717;1.2603621;1.2422191;8.190537;1.1512944;-4.4205594;IRRE
then we can fit our diagnosis model and compute the positive likelihood;4.603283;-0.023393055;-0.21167853;3.5970945;1.4412447;-0.36332804;-
ratio to evaluate the usefulness of this classifier as a disease diagnosis;4.761692;-1.5371047;-0.47914118;2.0114126;3.4927638;-3.3687847;CODE
tool;-2.6299195;-5.1957707;5.1992955;1.7252177;-1.0991374;-2.7721534;-
since the positive class likelihood ratio is much larger than 1 0 it means;0.7431033;1.6796997;-5.2654676;0.25936222;-0.2743994;0.534396;IRRE
that the machine learning based diagnosis tool is useful the post test odds;3.9149225;-3.7252674;0.21139449;5.67709;0.9463522;-4.058864;IRRE
that the condition is truly present given a positive test result are more than;0.16507387;6.413137;-1.0666229;2.9310803;1.6671621;-5.021356;IRRE
12 times larger than the pre test odds;1.7031801;2.5294726;1.1739163;3.5587273;-1.6808519;-4.16118;IRRE
cross validation of likelihood ratios;3.9964583;1.5499513;-1.6294316;2.9067907;1.364979;-0.05814688;-
we assess the variability of the measurements for the class likelihood ratios;4.924286;-2.2258327;-0.9655891;4.4987392;2.631863;-0.08320549;CODE
in some particular cases;-1.3369673;-1.0700144;5.5413384;2.6318202;3.8167112;-1.5572866;CODE
we first validate the class sklearn linear model logisticregression model;2.991921;-4.3425894;-5.9886055;3.7454076;-0.5586116;-1.685259;IRRE
with default hyperparameters as used in the previous section;-1.0690131;0.9977254;0.3420172;3.1382976;2.3730688;4.5201406;CODE
we confirm that the model is useful the post test odds are between 12 and 20;1.5940418;-0.14553638;0.5509714;6.787954;-0.17115226;-4.766043;IRRE
times larger than the pre test odds;2.2355332;3.1462889;1.5100313;3.8996048;-2.0971575;-3.8890882;IRRE
on the contrary let s consider a dummy model that will output random;2.148756;0.7792612;1.3103007;4.079558;1.8967104;-0.4191332;IRRE
predictions with similar odds as the average disease prevalence in the;3.0677433;-0.07196259;2.290881;3.7080302;-0.1195754;-1.8756379;CODE
training set;2.5613565;-3.9551353;3.8796027;0.98318845;2.6271846;-1.2734559;IRRE
here both class likelihood ratios are compatible with 1 0 which makes this;1.167259;2.2795537;-5.259945;-0.0011213539;0.25324446;0.7958454;CODE
classifier useless as a diagnostic tool to improve disease detection;2.7962496;-2.5832434;-1.7516059;2.7283597;1.6702313;-1.7382438;IRRE
another option for the dummy model is to always predict the most frequent;4.549778;0.86203617;2.381097;5.5704694;2.056618;0.7687831;CODE
class which in this case is no disease;-3.0509028;0.53286165;-0.35478303;1.2379043;4.021555;-2.6148906;CODE
the absence of positive predictions means there will be no true positives nor;0.9835696;0.9273405;-1.0977837;5.1750712;-1.1213888;-1.2659009;-
false positives leading to an undefined lr that by no means should be;-2.4312134;6.7299695;-4.505495;0.08279813;-2.1050055;-4.6867537;CODE
interpreted as an infinite lr the classifier perfectly identifying;2.2068644;-0.8449821;-4.079052;0.9587003;2.8314974;-0.2298841;IRRE
positive cases in such situation the;-1.9199476;1.7131709;3.8913052;3.4449072;2.0245163;-2.5331647;CODE
func sklearn metrics class likelihood ratios function returns nan and;3.1007192;-1.1357851;-6.2299843;-1.7942795;-4.7512636;-1.2487073;CODE
raises a warning by default indeed the value of lr helps us discard this;-3.454541;4.075366;-4.334217;2.9230022;-1.2116374;1.444243;CODE
model;1.6850569;-3.146167;5.856185;2.3733578;2.0956028;-1.8042274;-
a similar scenario may arise when cross validating highly imbalanced data with;4.3426504;3.2974358;-3.598014;5.0712476;1.9136527;-1.1733279;-
few samples some folds will have no samples with the disease and therefore;0.76093704;3.2784636;-2.3441658;0.8329959;-0.24850151;-0.94123673;CODE
they will output no true positives nor false negatives when used for testing;-0.05199552;4.157287;-4.1022577;3.2159455;-0.80415195;-5.5955215;IRRE
mathematically this leads to an infinite lr which should also not be;-1.5435619;3.7229974;-0.06913412;-0.76291484;-0.41342288;0.7257226;IRRE
interpreted as the model perfectly identifying positive cases such event;0.6566074;1.4088844;-0.27340788;4.602528;1.85758;-0.74664986;CODE
leads to a higher variance of the estimated likelihood ratios but can still;0.6069813;2.1285062;-2.4653647;2.9434922;-4.0164475;3.872746;TASK
be interpreted as an increment of the post test odds of having the condition;-0.91427475;5.8450284;0.42396832;3.639999;1.183464;-5.5602374;IRRE
invariance with respect to prevalence;2.2578208;0.7514888;0.5759514;1.6251367;1.1227825;1.3919461;CODE
the likelihood ratios are independent of the disease prevalence and can be;1.2054791;1.1908396;0.29486793;1.030958;0.83407897;0.0153350085;CODE
extrapolated between populations regardless of any possible class imbalance;6.5972166;2.8318088;-1.5130755;2.738843;2.583264;0.23849058;IRRE
as long as the same model is applied to all of them notice that in the;2.372011;-0.647534;0.55183077;5.0631847;6.03193;3.5208573;CODE
plots below the decision boundary is constant see;1.5444399;0.3439947;2.5687788;-2.2674603;-3.4222033;2.7480445;CODE
ref sphx glr auto examples svm plot separating hyperplane unbalanced py for;2.5548456;-2.4534333;-4.515505;-3.3253663;-3.8623745;4.3802366;CODE
a study of the boundary decision for unbalanced classes;4.891012;0.48953575;-0.17867725;2.4554517;5.812351;0.56496423;CODE
here we train a class sklearn linear model logisticregression base model;4.1207805;-6.652204;-2.6169856;1.0495249;0.53960806;-0.51158285;IRRE
on a case control study with a prevalence of 50 it is then evaluated over;-0.7402102;1.2233126;1.2281681;4.5107627;1.5830927;-2.0385761;CODE
populations with varying prevalence we use the;1.8015885;-0.5260218;1.7282096;2.2772386;2.4092128;-0.85811675;IRRE
func sklearn datasets make classification function to ensure the;4.403603;-3.593348;-5.078697;1.5846189;-0.62619674;-0.6197085;IRRE
data generating process is always the same as shown in the plots below the;2.8849275;0.22618765;1.3925935;-3.0417845;-4.666317;1.9464031;CODE
label 1 corresponds to the positive class disease whereas the label 0;-0.80892897;0.852776;-2.6028144;-1.7016066;2.594613;-2.1921215;IRRE
stands for no disease;-3.5652924;1.3276114;-0.9143113;-0.23060596;1.2655337;-2.0970778;CODE
fit and evaluate base model on balanced classes;4.4930835;0.49821427;-1.4896626;1.9768549;4.3672304;-0.36021185;IRRE
we will now show the decision boundary for each level of prevalence note that;1.8005753;-1.389188;1.4524376;3.1886334;4.574444;0.07239172;CODE
we only plot a subset of the original data to better assess the linear model;6.857196;1.0284437;3.3865247;1.5813749;-2.8985775;2.129195;IRRE
decision boundary;1.028218;-1.2365232;4.423771;2.0452394;4.748018;-0.16094814;-
down sample for plotting;4.5322456;0.61688256;4.477624;-2.5173159;-3.6833022;-1.3518646;CODE
plot fixed decision boundary of base model with varying prevalence;4.201939;0.47065333;2.549112;-0.11242849;-0.58830494;2.3260493;CODE
we define a function for bootstrapping;1.4298012;-1.0629394;2.3755748;1.7157435;3.647095;1.1903054;CODE
we score the base model for each prevalence using bootstrapping;4.635044;-2.4123747;0.56208414;2.3510249;3.3379164;-0.7793531;CODE
in the plots below we observe that the class likelihood ratios re computed;3.578717;-2.869463;-0.754129;0.17267966;-0.5012799;2.021805;CODE
with different prevalences are indeed constant within one standard deviation;2.012132;2.5353875;-1.8970484;0.59695584;-0.4891416;0.9984843;CODE
of those computed with on balanced classes;3.0612233;0.35022467;-0.99878126;-0.49599922;5.0692234;-1.7034259;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
running gridsearchcv using multiple evaluation metrics;4.569054;-0.8643528;-2.7732532;1.644391;0.033879943;1.3978196;CODE
the scorers can be either one of the predefined metric strings or a scorer;1.8431869;0.03338779;1.1048206;-0.9236956;3.296415;-1.8054148;CODE
callable like the one returned by make scorer;-2.2851157;0.8211058;2.9950132;3.0708075;1.6315694;-0.45860168;IRRE
setting refit auc refits an estimator on the whole dataset with the;1.7472105;-1.7044542;-2.1844127;3.0880568;-1.5505779;4.174891;IRRE
parameter setting that has the best cross validated auc score;2.629707;1.540204;-2.541815;2.845062;2.6203072;0.73977804;IRRE
that estimator is made available at gs best estimator along with;1.3801004;-1.1909161;-0.64253753;3.7394314;-1.3486394;4.1854157;IRRE
parameters like gs best score gs best params and;3.1144595;0.0218182;2.6265562;1.6181158;3.5767682;-0.655118;IRRE
gs best index;1.7808278;-0.9889056;2.5489364;0.40096375;1.7402276;-0.31522852;-
plotting the result;0.6651905;1.3204132;7.769098;-5.323328;-5.8007326;-4.950775;IRRE
get the regular numpy array from the maskedarray;2.3529642;0.7110173;-2.3799748;-4.343953;-4.64231;1.0148939;CODE
plot a dotted vertical line at the best score for that scorer marked by x;2.6248844;2.1978943;5.6693864;-4.0972114;-2.5468838;-1.7196698;CODE
annotate the best score for that scorer;1.4558282;0.7981742;3.099744;0.70183665;1.0119181;-3.254278;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
number of random trials;-0.39386585;-0.09108754;3.1417158;2.888224;1.652631;-3.81699;IRRE
load the dataset;3.3733814;-2.8897374;2.069233;-0.41889125;0.5001514;-0.03551577;IRRE
set up possible values of parameters to optimize over;5.870514;2.670044;1.5145537;-0.5202558;2.7147312;2.2371087;IRRE
we will use a support vector classifier with rbf kernel;4.411644;-6.469745;-2.5267968;-0.63043565;2.9376419;0.9421384;IRRE
arrays to store scores;4.6579275;1.2297218;3.2597024;-2.5305288;1.9534082;-3.6956584;-
loop for each trial;2.3752196;1.2139977;5.025948;1.2391086;1.5909939;-5.252168;CODE
choose cross validation techniques for the inner and outer loops;4.0051394;0.57738686;0.8388527;2.0985193;2.700061;-2.0873923;IRRE
independently of the dataset;6.9373617;-2.8370397;2.8819292;0.29424718;4.089162;0.35836804;IRRE
e g groupkfold leaveoneout leaveonegroupout etc;-3.9081132;-3.8272922;3.468527;-0.29669797;1.8426665;1.375955;-
non nested parameter search and scoring;4.708722;1.8828384;0.23052746;1.9808079;4.7669563;-1.8035823;IRRE
nested cv with parameter optimization;4.606032;0.7646497;-1.2385424;0.56634456;3.3536556;3.6541932;IRRE
plot scores on each trial for nested and non nested cv;4.3855124;-0.2166298;1.3261732;0.15912652;-1.0483181;-0.37241706;CODE
plot bar chart of the difference;2.2166755;0.9997059;6.3221235;-4.352223;-3.8247342;-0.932144;IRRE
plt xlabel individual trial;-1.3169625;-0.44127244;0.25581175;1.6662112;2.3962822;-1.4845439;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
we will use the ref iris dataset which consists of measurements taken;2.8428102;-2.5469968;1.0778798;-0.53470933;0.58072;-0.5547401;IRRE
from 3 iris species our model will use the measurements to predict;1.9020113;-1.1289623;1.0188624;0.5730695;0.60949343;-0.6026458;IRRE
the iris species;-2.1172283;-2.231967;1.955046;-0.6070076;0.21704587;-1.5150234;-
for comparison we also generate some random feature data i e 20 features;4.7755337;-3.3806036;0.5605094;2.6370595;2.7626464;-2.026193;TASK
uncorrelated with the class labels in the iris dataset;4.345478;-1.9646199;-3.639025;-1.2034444;1.1928585;-0.67679656;IRRE
use same number of samples as in iris and 20 features;3.7481;0.8549297;0.09783434;-1.1817485;4.141926;-0.90434563;TASK
permutation test score;2.8014135;3.6624632;1.0153825;0.8936172;2.8606484;-6.5420966;IRRE
next we calculate the;-1.0475824;0.10456557;5.0398254;-0.87157655;0.58150476;-5.1721773;-
func sklearn model selection permutation test score for both the original;3.2392328;-0.1913497;-3.7238576;2.755506;0.5026335;-3.5293214;CODE
iris dataset where there s a strong relationship between features and labels and;4.0515556;-4.877394;0.35023588;-1.6095188;3.4687192;-0.9836455;TASK
the randomly generated features with iris labels where no dependency between features;3.0499918;-2.4056423;-1.7720518;-0.7599262;3.834257;0.2296616;TASK
and labels is expected we use the;-0.4245513;-2.4652019;2.196712;1.442459;2.787267;0.2863549;IRRE
class sklearn svm svc classifier and ref accuracy score to evaluate;4.236615;-3.7219377;-4.437702;1.4110092;0.10513527;-2.036809;IRRE
the model at each round;2.8643546;-2.0137508;5.6092834;0.7305438;0.74872726;-1.1948885;-
func sklearn model selection permutation test score generates a null;2.1866877;1.2903357;-6.550821;2.3155203;-1.3511057;-3.3831842;IRRE
distribution by calculating the accuracy of the classifier;5.485832;-3.3402493;-0.17907232;2.4415898;2.3459265;-1.9007018;IRRE
on 1000 different permutations of the dataset where features;5.8858767;-3.5616026;1.1728657;-1.5161291;4.103807;-1.4789307;TASK
remain the same but labels undergo different random permutations this is the;0.8180097;0.93661565;2.8107452;-0.5468622;4.4237185;-0.22888939;CODE
distribution for the null hypothesis which states there is no dependency;-0.8804063;2.496637;-0.49816224;1.7054666;0.3940929;0.3466868;CODE
between the features and labels an empirical p value is then calculated as;4.201981;-1.6452614;-1.5610154;-1.5158508;1.7957317;-0.8238243;TASK
the proportion of permutations for which the score obtained by the model trained on;5.3718743;-1.9417393;2.553703;3.5373278;3.6828744;-3.0000758;CODE
the permutation is greater than or equal to the score obtained using the original;2.459814;3.0684288;1.5421389;-0.9084744;2.832902;-5.2269206;-
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
original data;2.8858964;-0.85375965;4.0901446;-1.0256882;1.5062646;-2.2374332;-
below we plot a histogram of the permutation scores the null;3.493049;1.9343531;2.4509206;-4.242542;-0.60095763;-3.4389038;-
distribution the red line indicates the score obtained by the classifier;2.2737744;-1.4525882;0.37881166;-0.64207613;1.8198005;-2.8631358;IRRE
on the original data without permuted labels the score is much better than those;6.321183;-0.92560846;-0.37559524;-0.38611445;4.0081587;0.15611456;-
obtained by using permuted data and the p value is thus very low this indicates that;4.416354;3.6599314;-2.8250463;-3.4862099;0.108625434;-1.6222047;IRRE
there is a low likelihood that this good score would be obtained by chance;3.5085359;1.1749072;-0.062205918;4.835077;0.8295129;-3.7380676;CODE
alone it provides evidence that the iris dataset contains real dependency;2.3061702;-3.9619348;-1.4431257;1.7099837;1.5080999;-0.06694162;IRRE
between features and labels and the classifier was able to utilize this;2.5171125;-6.5430064;1.0313343;1.3186942;5.96811;1.3505536;CODE
to obtain good results the low p value can lead us to reject the null hypothesis;0.8499452;3.7033253;-2.4341812;3.334538;-2.005509;-2.4966347;IRRE
random data;5.7039175;-0.84195787;4.7827897;0.5816592;2.5215657;-3.0452847;IRRE
below we plot the null distribution for the randomized data the permutation;3.4734366;-0.2765114;2.1669505;-3.0716076;-1.018487;0.18369935;IRRE
scores are similar to those obtained using the original iris dataset;3.9034984;-2.0549634;-0.23549077;-0.8203222;0.18893509;-2.5380592;IRRE
because the permutation always destroys any feature label dependency present;-0.22331083;-0.85787183;-2.3700812;1.0600024;3.5741887;2.0456414;TASK
the score obtained on the randomized data in this case;5.890954;-0.27907932;0.81412834;1.1034182;2.269103;-2.6474352;CODE
though is very poor this results in a large p value confirming that there was no;0.8045994;3.8987532;-3.760004;3.319744;-1.1306162;-1.5940095;IRRE
feature label dependency in the randomized data;4.688772;-3.4601777;-1.0808861;1.8880703;5.3797064;3.2371395;CODE
another possible reason for obtaining a high p value could be that the classifier;2.781288;0.32217804;-4.3875656;1.5919755;0.31321773;-0.3897972;IRRE
was not able to use the structure in the data in this case the p value;1.5856113;4.4219103;-1.4282802;-4.5876985;-0.6355403;-2.0094135;CODE
would only be low for classifiers that are able to utilize the dependency;3.0142229;-4.0094666;-3.329775;3.4556227;5.3530426;2.9054585;CODE
present in our case above where the data is random all classifiers would;5.6378393;-2.8691049;-1.4501647;3.320837;6.0612974;0.21158673;IRRE
have a high p value as there is no structure present in the data we might or might;4.226573;2.6822133;-0.5783249;0.5005651;2.3825645;-0.8955501;CODE
not fail to reject the null hypothesis depending on whether the p value is high on a;0.44587067;7.0567937;-2.1357703;2.7812426;-1.6339438;-1.6887525;TASK
more appropriate estimator as well;2.4370706;0.26790237;2.5819662;3.9993036;-0.5202829;1.8391207;-
finally note that this test has been shown to produce low p values even;1.8313873;4.260535;-5.021492;2.7123802;-2.3661883;-3.6636782;IRRE
if there is only weak structure in the data 1;5.0578547;2.5613773;-1.0630438;0.32080504;2.8862188;1.4201082;CODE
rubric references;-1.30285;-4.5029125;2.0068364;-0.5395812;0.9139038;-2.8480213;CODE
1 ojala and garriga permutation tests for studying classifier;5.1542625;-2.2011154;-2.2289827;3.3196154;4.4940395;-4.014434;IRRE
performance;1.8491132;-2.365384;6.1062574;3.9124064;1.6088448;-2.9575753;CODE
http www jmlr org papers volume11 ojala10a ojala10a pdf the;-3.9769034;-3.7448761;-0.19348067;-0.0524725;2.2120388;-0.04546015;CODE
journal of machine learning research 2010 vol 11;3.6688187;-7.340797;-1.0463345;3.9177139;3.2590227;0.38880602;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
in binary classification settings;3.6038048;-4.4682846;-0.24586554;-1.0789037;5.7299995;-1.8075873;IRRE
dataset and model;4.8665743;-3.9352114;3.018915;1.0060478;2.9573286;-1.8361574;IRRE
we will use a linear svc classifier to differentiate two types of irises;3.0951984;-2.0495589;-0.70521957;-1.7086262;3.4070249;-0.40802127;IRRE
add noisy features;3.8630214;-3.1041553;0.8816835;2.473678;1.8770723;2.378101;TASK
limit to the two first classes and split into training and test;3.2709773;1.6492858;0.50989586;3.9098892;4.8865037;-2.3241134;IRRE
linear svc will expect each feature to have a similar range of values thus;7.17611;-0.022181323;-3.1784294;-2.6719868;-0.5273531;2.373704;IRRE
we will first scale the data using a;6.8635273;-0.6501396;4.7368197;-1.1293721;0.63932705;0.67980444;CODE
class sklearn preprocessing standardscaler;1.6901857;-3.3535168;-6.4043374;0.74439675;-1.5943408;0.5507111;IRRE
plot the precision recall curve;4.0399647;-1.2444792;1.9011627;-0.61466026;-3.4902232;-1.9388449;IRRE
to plot the precision recall curve you should use;3.1763942;-1.1722133;1.6305331;0.11448029;-3.6076891;-1.0766319;IRRE
class sklearn metrics precisionrecalldisplay indeed there is two;3.1076894;-4.6725273;-5.031497;0.93535846;-2.0630777;-0.2775634;IRRE
methods available depending if you already computed the predictions of the;5.862597;-3.5010183;3.2105699;5.596931;0.6672254;-1.2935996;CODE
classifier or not;3.5369935;-4.501692;0.91088814;3.3489766;5.2993646;-2.3022313;IRRE
let s first plot the precision recall curve without the classifier;4.1737328;-2.0784442;1.1586556;0.20397645;-1.8414657;-0.23964263;IRRE
predictions we use;4.015256;-3.984008;5.575695;7.0879655;0.1790109;-2.215647;-
func sklearn metrics precisionrecalldisplay from estimator that;3.6473858;-3.2915773;-5.367831;2.1538122;-5.1917324;2.7251468;IRRE
computes the predictions for us before plotting the curve;3.307976;-1.3888493;3.0655158;1.7931312;-6.413095;-1.1163093;CODE
if we already got the estimated probabilities or scores for;3.603832;-1.385442;3.1296737;4.790317;1.9935179;-1.4288875;CODE
our model then we can use;-0.20161174;-3.930858;3.9350927;2.2249272;2.234937;1.3823849;-
func sklearn metrics precisionrecalldisplay from predictions;4.864289;-4.7425723;-4.3669076;2.6440284;-4.503498;0.76941985;IRRE
in multi label settings;-1.709627;-0.8127761;2.4709096;-2.2220836;4.4770555;2.7009501;IRRE
the precision recall curve does not support the multilabel setting however;1.7089218;-1.083394;-2.337487;0.25019765;1.532213;1.9977295;IRRE
one can decide how to handle this case we show such an example below;-1.9128876;5.5784903;3.306298;0.6294402;3.8939536;-1.1155144;CODE
create multi label data fit and predict;5.1812673;-1.4002732;1.539147;-1.206436;3.2506301;0.7988888;IRRE
we create a multi label dataset to illustrate the precision recall in;4.851014;-3.9962015;1.653577;0.053220067;2.8985057;-1.1919193;IRRE
multi label settings;-0.10487084;-0.6164386;3.3065002;-2.2031279;4.888875;3.3091156;IRRE
use label binarize to be multi label like settings;0.5033611;1.2297652;0.4828507;-3.5857863;3.979099;2.644747;IRRE
split into training and test;4.514259;-0.85170764;2.1649175;5.149614;3.4820554;-3.9553711;IRRE
we use class sklearn multiclass onevsrestclassifier for multi label;2.4543111;-5.398542;-2.8529453;-1.6514404;3.723086;0.10675426;CODE
prediction;5.387814;-2.5664148;6.164522;4.8268886;0.24309698;-2.5988457;-
the average precision score in multi label settings;4.875288;-0.95954496;0.27062875;0.23549145;1.9490526;-0.6006379;IRRE
for each class;1.334574;-4.6309524;4.593857;1.5261005;6.2162085;-3.759834;CODE
a micro average quantifying score on all classes jointly;5.116675;-2.955139;-0.15996116;2.7403274;3.521238;-2.309199;CODE
plot the micro averaged precision recall curve;4.839305;-2.1427925;1.6486775;0.272974;-3.2773361;-0.66552943;IRRE
plot precision recall curve for each class and iso f1 curves;4.6537027;-2.8584635;-0.08633668;-0.9110982;-1.2479665;-0.29502916;CODE
setup plot details;0.36400467;-1.06227;6.333664;-5.4393153;-3.7418964;0.3606207;IRRE
add the legend for the iso f1 curves;-1.7762234;-2.5118492;2.5338147;-3.2835755;-2.114095;1.4267792;CODE
set the legend and the axes;-2.690583;0.65076834;6.79644;-3.7549486;-3.0435386;2.0625205;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
get some data;2.1838129;0.3437108;6.4423876;-0.6453847;1.5117098;-4.4130654;-
build a classifier;4.88408;-5.379965;1.8435973;1.1047344;5.7853117;-2.4324412;IRRE
utility function to report best scores;4.719733;0.063318074;1.6739645;2.1371965;1.7179503;-1.3766936;CODE
specify parameters and distributions to sample from;2.8393948;0.42438224;0.5923653;0.9063501;3.6181138;2.2456102;IRRE
run randomized search;2.5772526;-0.28420037;0.956782;4.5550013;2.5405273;-0.61865425;IRRE
use a full grid over all parameters;3.263074;3.0996351;2.4002283;-3.2989414;0.44583717;4.5263;IRRE
run grid search;1.4888761;0.80106616;2.4930189;-0.68657404;-0.2593335;0.098434225;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load and prepare data;2.5494869;0.66157496;3.472986;1.1374639;2.4774883;-1.0889354;CODE
we import the ref iris dataset which contains 3 classes each one;1.5549233;-3.5180595;-2.3001435;-1.3463991;3.7317388;-0.7920927;CODE
corresponding to a type of iris plant one class is linearly separable from;-0.4578242;0.45268372;-2.0243201;-1.6750056;2.9818947;2.212336;CODE
the other 2 the latter are not linearly separable from each other;0.4649756;0.26016772;-0.02794776;-2.8894384;1.146504;1.4571298;CODE
here we binarize the output and add noisy features to make the problem harder;6.19781;-0.29663825;-0.18656465;-1.44762;0.24597843;0.18508111;TASK
we train a class sklearn linear model logisticregression model which can;4.589621;-6.808351;-2.362122;2.5288825;1.0997096;-0.33547673;IRRE
naturally handle multiclass problems thanks to the use of the multinomial;2.9658473;-2.3709033;-1.8610317;1.4280317;6.3855104;0.3458258;IRRE
formulation;0.04233324;-0.8272874;3.8479102;-0.44516134;4.283174;0.05836582;CODE
one vs rest multiclass roc;1.2847532;-2.2577703;-1.270653;1.4493331;3.8727486;-0.16216706;IRRE
the one vs the rest ovr multiclass strategy also known as one vs all;-0.37949723;-2.0454729;0.5072179;2.939148;4.244456;1.4398884;IRRE
consists in computing a roc curve per each of the n classes in each step a;4.883216;-5.195501;0.20097199;-0.79978794;4.3333344;-2.4158583;IRRE
given class is regarded as the positive class and the remaining classes are;0.94227004;0.17239065;0.9911449;-0.48168495;5.5999937;-1.4846349;CODE
regarded as the negative class as a bulk;1.2279416;-1.4593366;-0.117646046;1.8619694;3.6165378;1.0727794;IRRE
note one should not confuse the ovr strategy used for the evaluation;0.9679791;0.39060146;0.6302684;4.662435;3.157449;0.34636202;TASK
of multiclass classifiers with the ovr strategy used to train a;4.3121777;-4.770605;-1.1519802;2.5301883;5.7419596;1.1875434;IRRE
multiclass classifier by fitting a set of binary classifiers for instance;5.4643307;-4.5782137;-2.4574957;0.13281083;5.872569;0.97375745;IRRE
via the class sklearn multiclass onevsrestclassifier meta estimator;4.1670895;-5.4582276;-5.2828393;1.5025722;1.1300892;0.8146447;IRRE
the ovr roc evaluation can be used to scrutinize any kind of classification;4.300095;-4.2083445;-2.248299;2.1014268;5.2547183;-0.71813715;CODE
models irrespectively of how they were trained see ref multiclass;1.8127472;-4.3979945;0.115954064;4.8780193;3.6173484;1.811897;IRRE
in this section we use a class sklearn preprocessing labelbinarizer to;1.1998105;-5.342385;-5.3565235;-2.039497;2.5173037;-0.72767174;CODE
binarize the target by one hot encoding in a ovr fashion this means that the;0.54311216;-0.27742127;-0.7798549;-1.980512;1.9050572;0.48604363;CODE
target of shape n samples is mapped to a target of shape n samples;5.1647153;-0.45349553;0.8590451;-1.2511139;0.5206758;2.741057;-
n classes;1.3021176;-3.3430412;2.289159;-1.5024759;6.364399;-5.037882;IRRE
y onehot test shape n samples n classes;4.7489114;1.1349595;0.10558521;-1.3165777;1.8022473;-4.104959;IRRE
we can as well easily check the encoding of a specific class;-0.76577824;-1.4368694;-3.5106306;0.91884255;4.142557;-2.1146202;IRRE
roc curve showing a specific class;2.4135897;-1.5410687;-1.7132081;-1.6912673;1.0537592;-2.9408796;IRRE
in the following plot we show the resulting roc curve when regarding the iris;1.0720602;-1.182996;0.17240101;-2.7521386;-1.5808508;-1.3459909;IRRE
flowers as either virginica class id 2 or non virginica the rest;-1.8726697;0.13954341;1.1414229;-0.3670561;4.085232;-1.143492;CODE
roc curve using micro averaged ovr;4.616311;-2.4322193;-1.5734936;-0.08378148;0.13755813;-0.52534926;CODE
micro averaging aggregates the contributions from all the classes using;4.962438;-3.2164347;0.364129;1.1341296;1.5691998;0.57979643;IRRE
func numpy ravel to compute the average metrics as follows;3.9014404;-1.7036552;-1.2507087;-5.7313886;-6.4911556;-0.31460744;-
math tpr frac sum c tp c sum c tp c fn c;-0.4967785;0.54924995;0.7675338;-3.3011813;-0.27793023;-2.7736797;-
math fpr frac sum c fp c sum c fp c tn c;-0.59591025;0.73133665;1.3057066;-3.0034103;-0.23037085;-3.0799966;-
we can briefly demo the effect of func numpy ravel;0.24291307;-4.2074895;-0.7557929;-1.8134183;-4.49721;-0.36192167;-
in a multi class classification setup with highly imbalanced classes;4.9686775;-2.0078726;-0.81989247;2.3761814;4.7793536;-0.017667275;IRRE
micro averaging is preferable over macro averaging in such cases one can;4.0040355;0.36153325;0.979806;1.5490624;-0.06833687;3.1009266;CODE
alternatively use a weighted macro averaging not demonstrated here;6.242389;2.2716649;0.031960778;-0.5027542;-1.310928;2.3637109;CODE
in the case where the main interest is not the plot but the roc auc score;1.8428307;-2.989984;1.8141681;0.9286909;0.04525176;-0.57665676;CODE
itself we can reproduce the value shown in the plot using;1.4045649;-0.43866488;3.521485;-3.3080935;-5.4483585;-0.16093528;IRRE
class sklearn metrics roc auc score;3.669472;-5.587502;-4.2739763;0.3388016;0.3518944;-2.3038938;IRRE
this is equivalent to computing the roc curve with;5.215639;-2.7222009;0.26736495;-0.939161;3.2107954;-1.792426;CODE
class sklearn metrics roc curve and then the area under the curve with;3.1185393;-3.8102083;-2.332314;-0.931232;-0.7103314;-0.28260112;IRRE
class sklearn metrics auc for the raveled true and predicted classes;4.9795084;-6.538405;-4.955117;1.9340528;0.16936809;-1.1102586;CODE
store the fpr tpr and roc auc for all averaging strategies;2.4993157;-1.8592851;-0.115556724;2.8008595;1.0554557;2.3264098;IRRE
compute micro average roc curve and roc area;3.6196787;-2.6684563;-0.23819421;-1.3178924;-0.7377135;-1.2391503;-
note by default the computation of the roc curve adds a single point at;2.7754934;-1.2227733;-3.2354124;-0.6744419;-0.19981356;-0.52225137;TASK
the maximal false positive rate by using linear interpolation and the;5.8201947;3.410525;-0.78881645;0.7858388;-0.2566029;-1.4559764;CODE
mcclish correction doi analyzing a portion of the roc curve med decis;1.8489466;-1.7860851;-2.8672435;1.3578813;-0.270289;-2.3927433;CODE
making 1989 jul sep 9 3 190 5 10 1177 0272989x8900900307;-0.73697674;-0.061669342;1.0460154;-4.3315797;0.4190021;-4.2720714;-
roc curve using the ovr macro average;4.6074653;-2.9276168;-1.1613809;-0.6689064;0.7600396;-0.8459219;CODE
obtaining the macro average requires computing the metric independently for;3.90369;-0.042940583;-1.1382849;-0.6805908;-1.4348729;2.672595;CODE
each class and then taking the average over them hence treating all classes;4.854156;-0.98788005;1.0400044;1.7886848;4.0279193;0.9042617;IRRE
equally a priori we first aggregate the true false positive rates per class;4.1624413;2.1167908;-0.5785187;2.6758108;4.4569073;-2.8282433;IRRE
math tpr frac 1 c sum c frac tp c tp c fn c;-0.545351;0.7451205;0.7457941;-3.5435717;-0.44538018;-2.976904;-
math fpr frac 1 c sum c frac fp c fp c tn c;-0.59163505;0.94877553;1.3512229;-3.252843;-0.33639959;-3.3102212;-
where c is the total number of classes;0.7647127;-1.7415204;0.799526;-2.359511;5.24599;-3.4875083;IRRE
interpolate all roc curves at these points;5.5114603;-1.1123526;-0.4126805;-2.8326418;-0.510992;0.82400703;CODE
mean tpr np interp fpr grid fpr i tpr i linear interpolation;4.6883326;0.7846983;-2.0336432;-4.5692606;-2.3434632;3.1518524;CODE
average it and compute auc;3.416467;-0.48808727;0.50249183;-0.48871863;-1.5851077;-1.3820171;-
this computation is equivalent to simply calling;-0.7659043;2.8791482;1.080785;-1.1868743;1.800133;-1.3101683;IRRE
plot all ovr roc curves together;4.0502787;-2.419555;1.2715441;-4.785158;-1.9952545;0.6472037;-
one vs one multiclass roc;1.9237171;-2.1447647;-1.1240143;0.4672976;4.029266;-0.79509914;IRRE
the one vs one ovo multiclass strategy consists in fitting one classifier;4.022563;-2.7855122;-1.9758627;2.4206927;3.5311902;1.5293269;IRRE
per class pair since it requires to train n classes n classes 1 2;2.543227;-1.8200727;-0.51409954;-1.1641408;6.371747;-1.9968265;CODE
classifiers this method is usually slower than one vs rest due to its;4.9850183;-1.6956345;-1.5782169;3.6336217;3.3163111;-0.14228433;CODE
o n classes 2 complexity;0.85041106;-1.756254;-0.7479857;-1.2944417;4.0312037;-2.0588584;IRRE
in this section we demonstrate the macro averaged auc using the ovo scheme;2.012372;-3.417245;-1.9847678;-0.52611065;-0.026820507;2.5315943;CODE
for the 3 possible combinations in the ref iris dataset setosa vs;2.4643583;-2.1591144;-0.9481031;-0.842305;2.816583;-1.8360201;IRRE
versicolor versicolor vs virginica and virginica vs setosa notice;-2.3504226;0.45228437;-1.2146981;2.199263;-0.64026666;0.07564078;IRRE
that micro averaging is not defined for the ovo scheme;1.0014377;-0.43798462;-3.3671763;0.49190134;-2.4419398;4.107404;CODE
roc curve using the ovo macro average;5.3005033;-2.9806957;-1.445676;-0.6559154;0.5044105;-1.0643171;CODE
in the ovo scheme the first step is to identify all possible unique;1.9594038;-0.050017197;-1.758108;-0.021851417;5.4174128;0.3055437;CODE
combinations of pairs the computation of scores is done by treating one of;4.3122663;0.45454502;0.5282548;-1.5959296;3.8063886;-3.975924;CODE
the elements in a given pair as the positive class and the other element as;0.2548799;0.6143121;1.1833326;-3.223601;4.862508;-2.5394628;IRRE
the negative class then re computing the score by inversing the roles and;1.7284822;-0.7163959;-0.24348503;1.885718;3.1584377;-1.9002517;IRRE
taking the mean of both scores;1.4315689;3.0897377;3.9261775;0.3893035;-0.4200954;-2.7208714;-
one can also assert that the macro average we computed by hand is equivalent;3.4877589;1.1645521;-0.57235295;2.302444;0.5493795;1.0283194;CODE
to the implemented average macro option of the;1.9463508;-0.23812836;1.929865;0.6467121;1.5138206;1.9730473;TASK
class sklearn metrics roc auc score function;3.690142;-4.818048;-4.7709866;-0.7149469;0.03978559;-1.6842742;CODE
plot all ovo roc curves together;4.4836273;-2.4774745;1.5576484;-4.468211;-2.2601373;0.6438409;-
we confirm that the classes versicolor and virginica are not well;-1.3929268;-2.6180737;-2.923879;3.533331;0.41674078;-1.3592244;IRRE
identified by a linear classifier notice that the virginica vs the rest;4.3201847;-1.772342;-2.3935225;-1.3472908;2.2187119;0.2548641;IRRE
roc auc score 0 77 is between the ovo roc auc scores for versicolor vs;0.80248356;-1.1293072;-2.300096;0.02187172;0.37410018;-2.4378724;CODE
virginica 0 64 and setosa vs virginica 0 90 indeed the ovo;-0.28295663;-1.1332383;-0.99017966;0.38043827;-0.4886624;-0.03725331;IRRE
strategy gives additional information on the confusion between a pair of;0.8364124;0.66335183;3.6861203;2.7000823;4.464963;-1.147815;TASK
classes at the expense of computational cost when the number of classes;4.203792;-4.048738;-0.36734357;1.9138618;4.644331;0.28579286;IRRE
is large;-0.6477774;0.0060709217;4.801635;0.110043794;-0.4652352;-1.3357085;-
the ovo strategy is recommended if the user is mainly interested in correctly;0.57423896;-0.9729321;2.2844083;4.6410766;1.859836;2.70092;CODE
identifying a particular class or subset of classes whereas evaluating the;3.6105788;0.42133114;-0.9950567;2.3776605;6.6434755;-3.2830467;IRRE
global performance of a classifier can still be summarized via a given;6.247548;-2.6864147;-0.79711884;4.3348994;3.2903955;2.6783633;CODE
averaging strategy;3.8656552;0.09327298;5.860553;3.668778;0.14939916;0.72324026;-
when dealing with imbalanced datasets choosing the appropriate metric based on;5.5159473;-0.21071471;0.081637785;3.4362032;1.2882012;0.125802;CODE
the business context or problem you are addressing is crucial;-3.1649795;-2.4608924;4.1738;3.5050857;2.743431;2.175246;TASK
it is also essential to select an appropriate averaging method micro vs macro;3.7241719;-0.6054665;0.3836357;3.3840928;-0.61883944;2.7776332;CODE
depending on the desired outcome;1.5205098;3.144005;6.8409643;4.7247186;2.7481933;-2.2246222;CODE
micro averaging aggregates metrics across all instances treating each;4.9364367;-1.3396394;-0.13338464;1.5921978;1.0514593;2.7500224;-
individual instance equally regardless of its class this approach is useful;3.6398094;0.6304601;2.4303608;4.1758866;6.5307055;1.2724572;CODE
when evaluating overall performance but note that it can be dominated by;4.4251785;0.8989688;2.560857;5.2510076;2.6852312;-0.29151487;CODE
the majority class in imbalanced datasets;6.1717043;-1.7318385;-0.50249887;2.5257976;3.065052;-1.138997;IRRE
macro averaging calculates metrics for each class independently and then;5.2869964;-0.98987085;-0.5584254;0.59583783;1.507086;1.611573;CODE
averages them giving equal weight to each class this is particularly useful;6.477537;-1.0457649;2.2772834;1.3897703;3.3225257;-1.1992263;CODE
when you want under represented classes to be considered as important as highly;0.43578807;-3.6050277;0.5829356;1.2182027;5.2507153;0.7352673;CODE
populated classes;-0.3460062;-1.4366261;2.558791;2.4210002;5.723924;-0.8625251;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load and prepare data;2.5494869;0.66157496;3.472986;1.1374639;2.4774883;-1.0889354;CODE
we import the ref iris dataset which contains 3 classes each one;1.5549233;-3.5180595;-2.3001435;-1.3463991;3.7317388;-0.7920927;CODE
corresponding to a type of iris plant one class is linearly separable from;-0.4578233;0.45268363;-2.0243208;-1.6750051;2.9818947;2.2123368;CODE
the other 2 the latter are not linearly separable from each other;0.4649756;0.26016772;-0.02794776;-2.8894384;1.146504;1.4571298;CODE
in the following we binarize the dataset by dropping the virginica class;4.9536047;-1.5093966;-3.4022;-1.4596932;1.5108119;-0.5715922;IRRE
class id 2 this means that the versicolor class class id 1 is;-4.0496182;-0.68018454;-2.055349;-1.8499397;4.5746818;-1.6819761;CODE
regarded as the positive class and setosa as the negative class;-0.51474494;-1.6352884;0.8975272;0.84644;2.8181405;0.5141363;IRRE
class id 0;-4.386921;0.8378925;-2.1824877;-1.9089636;3.0515106;-2.7705054;IRRE
we also add noisy features to make the problem harder;3.1480281;-3.8702948;1.7202599;3.4473095;1.3796223;2.3747945;TASK
classification and roc analysis;5.524758;-4.1482263;-0.39197326;0.43386802;3.2372797;-2.6161404;IRRE
here we run func sklearn model selection cross validate on a;3.4589517;-1.7573223;-5.9895678;3.7629213;0.9990104;-2.5502489;CODE
class sklearn svm svc classifier then use the computed cross validation results;3.6450846;-2.3366992;-5.3853035;0.72698194;0.9089983;-0.6768478;IRRE
to plot the roc curves fold wise notice that the baseline to define the chance;3.4330425;-2.2331378;0.85648364;0.665048;-1.3980877;-0.2788294;CODE
level dashed roc curve is a classifier that would always predict the most;3.2911265;-4.251902;0.7039665;1.0116353;1.6582248;-1.2998924;IRRE
frequent class;2.253474;-2.0319462;3.8402288;2.5630722;3.9750297;-3.2508852;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
from sklearn experimental import enable halving search cv noqa f401;1.9050133;-1.1410071;-6.8692355;-0.5317155;-4.109496;-0.66295934;CODE
we first define the parameter space for an class sklearn svm svc;1.5643873;-5.61931;-4.241943;-1.5439014;1.7694525;3.1798246;CODE
estimator and compute the time required to train a;3.6560555;-0.60878366;2.55808;3.532067;0.559949;0.76726013;IRRE
class sklearn model selection halvinggridsearchcv instance as well as a;4.054044;-2.8961637;-5.595589;1.8091351;0.5240382;1.6841418;CODE
class sklearn model selection gridsearchcv instance;2.8091924;-4.446002;-5.335593;1.0014018;-0.4115381;0.7451756;CODE
we now plot heatmaps for both search estimators;4.4820037;-2.310889;2.041435;1.8618072;-2.6354842;3.028357;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
from sklearn experimental import enable halving search cv noqa f401;1.9050133;-1.1410071;-6.8692355;-0.5317155;-4.109496;-0.66295934;CODE
we first define the parameter space and train a;1.3497258;-2.663415;0.5375528;1.4154962;4.3714676;3.108082;CODE
class sklearn model selection halvingrandomsearchcv instance;4.275749;-3.167895;-6.2830825;2.260151;0.017192397;0.59627116;IRRE
we can now use the cv results attribute of the search estimator to inspect;1.730534;-1.418616;-3.0993326;5.178368;-0.25793028;1.4266068;IRRE
and plot the evolution of the search;2.4143116;-4.1595697;5.5396433;1.5298694;-0.7889766;-0.8926134;-
number of candidates and amount of resource at each iteration;4.5183015;0.20005861;2.9530787;2.3043294;3.9567025;-1.8081042;-
at the first iteration a small amount of resources is used the resource;0.88226604;-0.4404411;3.968047;3.9290967;0.060979906;1.6290902;-
here is the number of samples that the estimators are trained on all;4.1230574;-2.5576286;1.0197154;3.2013133;0.6989429;-0.484561;CODE
candidates are evaluated;1.57729;0.59955764;1.7501515;4.440352;4.601754;-3.7868328;-
at the second iteration only the best half of the candidates is evaluated;3.3949516;3.5119085;1.320283;3.882167;3.1406708;-2.9406734;-
the number of allocated resources is doubled candidates are evaluated on;1.5676742;0.5332352;1.913762;1.6998864;2.8802636;-0.21213631;CODE
twice as many samples;4.4829483;2.1442444;2.6666334;0.8618194;2.3702638;-3.008504;-
this process is repeated until the last iteration where only 2 candidates;0.53469276;3.1688244;2.4374006;3.1174674;3.2692873;-2.4171383;CODE
are left the best candidate is the candidate that has the best score at the;1.5535926;0.5388782;2.8046396;2.480112;1.6412555;-1.9635239;-
last iteration;0.08020824;2.3181841;5.7957115;0.8360525;-0.12541443;-4.401283;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
we generate a regression dataset that contains many features relative to the;6.703205;-3.900496;2.3348;0.16113456;2.6626012;0.4662536;TASK
number of samples however only 10 of the features are informative in this context;4.6596537;-2.0057514;0.44836286;1.3920571;3.7195;-2.3287804;CODE
linear models exposing l1 penalization are commonly used to recover a sparse;5.6805053;-2.5814574;-0.9889461;1.2175897;-0.91936654;4.866993;IRRE
set of coefficients;2.4165823;1.6644652;2.0895147;-4.186238;2.7664173;-0.9970963;IRRE
model definition;0.7465067;-2.2261548;2.783539;3.7367473;2.1234202;1.9427968;IRRE
here we do not use a model that only exposes an l1 penalty instead we use;1.4119262;1.2861714;-2.1283944;5.267851;0.96817595;4.739918;CODE
an class sklearn linear model elasticnet model that exposes both l1 and l2;3.0242527;-4.7104726;-2.4343975;0.34283167;-0.28637245;2.6190934;IRRE
penalties;-1.7482144;0.68610215;4.9740105;1.2730111;0.24099156;-1.7667499;-
we fix the l1 ratio parameter such that the solution found by the model is still;1.1373146;2.8146753;-3.3375878;1.6499276;-4.880568;3.6833086;TASK
sparse therefore this type of model tries to find a sparse solution but at the same;3.274539;0.87803334;-1.9819074;1.4603032;-1.5112492;2.8213918;IRRE
time also tries to shrink all coefficients towards zero;1.3211586;1.5662434;-2.4253554;-1.8633474;-5.0610447;1.6531676;-
in addition we force the coefficients of the model to be positive since we know that;1.2084162;0.65610206;-0.9334094;3.6096106;-2.7093346;2.5055535;TASK
make regression generates a response with a positive signal so we use this;1.4121928;1.8693943;1.6323347;2.480363;-1.2650512;0.10171978;CODE
pre knowledge to get a better model;2.085059;-4.2170587;2.864872;6.707544;1.2962136;0.100502916;-
evaluate the impact of the regularization parameter;4.448892;1.3140864;-2.5160785;2.0206175;-1.079827;4.608332;IRRE
to evaluate the impact of the regularization parameter we use a validation;4.774206;1.5194104;-2.5389307;4.938852;0.84053236;2.8790247;IRRE
curve this curve shows the training and test scores of the model for different;2.9287164;-1.6944523;3.0223196;0.8930128;-1.4448452;-2.6516027;CODE
values of the regularization parameter;2.760589;1.2421558;-2.2609198;-1.2898825;-0.45709807;4.44307;IRRE
the regularization alpha is a parameter applied to the coefficients of the model;1.8919017;-1.7122769;-1.2509552;0.3300025;-0.7656773;5.133398;IRRE
when it tends to zero no regularization is applied and the model tries to fit the;3.1614397;1.8488543;-3.8737803;2.1637084;-3.2832167;5.0949864;CODE
training data with the least amount of error however it leads to overfitting when;5.435882;0.5366283;-2.31579;3.5906334;-1.1931893;-0.5019154;-
features are noisy when alpha increases the model coefficients are constrained;3.9088376;-1.006407;-3.159386;1.8871404;-1.9763296;4.5286136;TASK
and thus the model cannot fit the training data as closely avoiding overfitting;3.3629644;-0.98688346;-2.1575203;3.629593;0.021691311;2.626364;CODE
however if too much regularization is applied the model underfits the data and;6.0462294;0.7037461;-1.5262303;3.8902884;1.4954963;5.672334;-
is not able to properly capture the signal;-1.786216;3.6279097;0.27237052;0.03391594;-4.63541;-0.57498854;CODE
the validation curve helps in finding a good trade off between both extremes the;4.733179;0.53786284;1.442067;3.670361;-0.42175898;0.20514886;-
model is not regularized and thus flexible enough to fit the signal but not too;2.8240137;0.5990461;-2.1535573;0.85813457;-1.864947;5.40848;META
flexible to overfit the class sklearn model selection validationcurvedisplay;3.4705493;-2.2059305;-5.613132;5.280234;1.1596552;0.82860327;CODE
allows us to display the training and validation scores across a range of alpha;2.6963494;-3.372331;1.9274046;1.1180761;1.5556589;-1.110598;-
values;2.3852327;2.8150017;4.596041;-3.805712;2.3660839;-6.126723;IRRE
to find the optimal regularization parameter we can select the value of alpha;4.2948017;0.64141905;-0.7338832;-1.8799474;-0.12715627;3.576968;IRRE
that maximizes the validation score;2.5084312;1.3065987;0.21842855;3.6431918;3.57954;-0.24777907;-
coefficients comparison;2.877261;4.1159167;1.5843303;-0.7766831;-0.6170052;-2.8243108;-
now that we have identified the optimal regularization parameter we can compare the;6.3370624;-0.17004663;-2.5811086;1.8946165;1.4244976;5.8304563;IRRE
true coefficients and the estimated coefficients;1.4566135;1.0959543;-0.18193573;0.60479504;-1.8213185;1.3460072;-
first let s set the regularization parameter to the optimal value and fit the;6.1789827;0.73293906;0.30700102;-1.88024;0.72280544;4.9347935;IRRE
model on the training data in addition we ll show the test score for this model;3.6893806;-1.4016181;1.1157011;3.4432478;1.9032527;-4.6844163;CODE
now we plot the true coefficients and the estimated coefficients;2.1342916;-0.53289133;3.2626693;-1.0479459;-4.8384705;1.7934946;-
while the original coefficients are sparse the estimated coefficients are not;3.9107997;0.9447771;-4.5550604;-1.2909051;-3.6730568;4.796568;IRRE
as sparse the reason is that we fixed the l1 ratio parameter to 0 9 we could;4.263871;0.89836174;-3.6396787;-1.8016429;-3.2544434;2.999625;IRRE
force the model to get a sparser solution by increasing the l1 ratio parameter;3.706741;1.6707988;-2.778077;0.6395608;-2.3732543;5.9036355;IRRE
however we observed that for the estimated coefficients that are close to zero in;3.295826;2.0575516;-2.5805793;0.7324571;-3.8996031;2.285933;CODE
the true generative model our model shrinks them towards zero so we don t recover;0.5412392;1.1766076;-1.5476221;3.0977495;-1.4250965;3.8177087;CODE
the true coefficients but we get a sensible outcome in line with the performance;5.7604494;1.5934029;0.24472022;3.2330952;0.42613944;0.43630314;CODE
obtained on the test set;2.4433177;3.7225287;0.05344373;1.170287;1.9714246;-5.577256;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the diabetes dataset;4.9063787;-3.647652;1.4920483;0.51821995;0.95658505;-0.74466115;IRRE
to illustrate the tuning of the decision threshold we will use the diabetes dataset;5.974907;-2.2398899;1.3037922;2.862012;1.6277978;0.0062624216;IRRE
this dataset is available on openml https www openml org d 37 we use the;0.88988584;-4.88187;0.29701504;-1.9233884;4.179606;0.21144035;CODE
func sklearn datasets fetch openml function to fetch this dataset;1.5165766;-3.7784827;-3.3208222;-0.11901349;-1.1564783;-1.0754973;CODE
we look at the target to understand the type of problem we are dealing with;-0.7128701;-2.6517422;4.063074;4.4814806;-0.22364031;-1.297885;-
we can see that we are dealing with a binary classification problem since the;2.939709;-5.3226757;-1.2743059;3.0010276;4.681062;-1.3530861;IRRE
labels are not encoded as 0 and 1 we make it explicit that we consider the class;-1.6374012;0.08618585;-3.5425494;-2.5226808;3.7524757;-0.462173;TASK
labeled tested negative as the negative class which is also the most frequent;2.1443062;1.6045097;-1.1357375;4.218665;3.681533;-4.1170526;IRRE
and the class labeled tested positive the positive as the positive class;0.015742226;0.0016155863;-2.3952396;2.9612331;5.313981;-3.8718045;IRRE
we can also observe that this binary problem is slightly imbalanced where we have;2.7360482;1.6063137;-2.4904833;0.6448552;1.6494987;-1.4797449;CODE
around twice more samples from the negative class than from the positive class when;4.7217216;2.3467631;-2.002109;1.258619;1.3681606;-2.692463;CODE
it comes to evaluation we should consider this aspect to interpret the results;2.3159606;-0.19424047;2.1241422;5.5323462;2.8331134;-2.2099495;CODE
our vanilla classifier;2.7499166;-4.4953275;1.8606608;2.7943244;5.364076;-1.7261828;IRRE
we define a basic predictive model composed of a scaler followed by a logistic;4.2411013;-3.3315496;1.8936032;2.6002164;1.72436;2.2607102;CODE
regression classifier;5.338545;-4.0480204;1.1790689;0.97288877;2.3403203;-2.1519032;IRRE
we evaluate our model using cross validation we use the accuracy and the balanced;4.426743;-1.6320233;0.48945752;5.514545;2.8099756;-2.535555;IRRE
accuracy to report the performance of our model the balanced accuracy is a metric;4.922518;-0.6292399;0.5171541;4.7899194;0.8826985;-2.5872998;CODE
that is less sensitive to class imbalance and will allow us to put the accuracy;4.5627937;-0.43421894;-1.2857497;4.513725;2.759565;0.16928343;IRRE
score in perspective;2.1819775;-1.1626376;5.0455184;1.0260038;0.80963343;-2.0928462;-
cross validation allows us to study the variance of the decision threshold across;3.6695035;-2.9014862;0.3814702;5.674091;1.8087494;0.30232966;CODE
different splits of the data however the dataset is rather small and it would be;7.0422287;-0.9685487;2.0116541;-2.0896165;2.7537816;0.95104444;IRRE
detrimental to use more than 5 folds to evaluate the dispersion therefore we use;2.2109106;1.2707388;0.53361696;-0.4159072;0.16746385;1.4271611;CODE
a class sklearn model selection repeatedstratifiedkfold where we apply several;5.249264;-4.6885095;-2.6259406;2.062563;3.5278378;2.071813;CODE
repetitions of 5 fold cross validation;2.6587994;0.5666509;1.3068132;2.2467093;4.0156484;-2.2317014;-
our predictive model succeeds to grasp the relationship between the data and the;3.7638156;-4.468211;3.795493;5.561099;1.1654775;0.85280776;-
target the training and testing scores are close to each other meaning that our;3.030438;-0.40529972;0.76528627;5.746992;1.434793;-2.4112961;IRRE
predictive model is not overfitting we can also observe that the balanced accuracy is;4.522119;-0.5883568;-3.2134597;5.830552;-1.1947783;0.085033074;-
lower than the accuracy due to the class imbalance previously mentioned;4.772109;0.48254243;-3.2290623;3.2880578;0.09026901;-1.6904889;IRRE
for this classifier we let the decision threshold used convert the probability of;4.239011;-2.4837837;0.39264628;1.7953726;4.2430363;-0.766732;CODE
the positive class into a class prediction to its default value 0 5 however this;2.6395748;1.1946707;-2.337448;1.6239339;0.2871153;-1.5354906;CODE
threshold might not be optimal if our interest is to maximize the balanced accuracy;6.0725465;0.60470855;-0.25289595;3.901453;0.66990256;0.744195;CODE
we should select another threshold that would maximize this metric;4.5580735;0.49687287;1.2645651;2.0257092;1.6473677;1.0390477;CODE
the class sklearn model selection tunedthresholdclassifiercv meta estimator allows;5.4871387;-5.4132805;-5.303934;2.4299848;-0.5306355;2.3164954;CODE
to tune the decision threshold of a classifier given a metric of interest;6.9940987;-3.2399013;-0.09949676;2.7626646;3.6680877;0.6624477;CODE
tuning the decision threshold;6.1851997;-1.2496142;1.1485246;4.7057424;2.76619;-0.3046971;-
we create a class sklearn model selection tunedthresholdclassifiercv and;5.7041693;-6.1127076;-3.7949622;1.6480962;1.2773172;1.4449316;IRRE
configure it to maximize the balanced accuracy we evaluate the model using the same;4.702182;-0.2656326;-1.883578;5.443222;0.22382382;1.4483075;-
cross validation strategy as previously;1.9124876;1.721401;1.9465953;5.539726;3.2894933;0.9613079;-
in comparison with the vanilla model we observe that the balanced accuracy score;5.048855;-2.1425612;-1.2732046;6.0298057;1.3418837;-1.7238733;-
increased of course it comes at the cost of a lower accuracy score it means that;3.0437672;-1.3652121;-0.37389934;5.746262;0.7056402;-0.61439633;CODE
our model is now more sensitive to the positive class but makes more mistakes on the;1.4597853;-0.34268758;-0.4253701;6.5577416;-0.075330965;-0.5604279;IRRE
negative class;-0.64677244;0.21782897;0.5897904;0.24254104;2.4993932;-2.3422;IRRE
however it is important to note that this tuned predictive model is internally the;2.787539;-3.35514;-0.47901976;5.0317793;0.62683064;2.826508;CODE
same model as the vanilla model they have the same fitted coefficients;0.55167544;0.5639846;-0.26949358;0.50942475;-0.2766262;2.856199;-
only the decision threshold of each model was changed during the cross validation;2.5059645;1.4593954;-1.569848;3.885315;-0.21995701;1.8481067;CODE
in average a decision threshold around 0 32 maximizes the balanced accuracy which is;5.04078;0.517523;-0.8906301;1.9908706;0.54532933;-1.0594558;-
different from the default decision threshold of 0 5 thus tuning the decision;2.3126745;1.0570195;-1.368685;2.245641;-0.024555054;0.3336254;CODE
threshold is particularly important when the output of the predictive model;4.358532;-0.7574421;0.53565794;3.6239362;0.111495115;1.9321101;CODE
is used to make decisions besides the metric used to tune the decision threshold;3.5240486;-2.5643938;1.7770059;4.0329003;2.3288093;1.3927373;OUTD
should be chosen carefully here we used the balanced accuracy but it might not be;3.624265;1.8384147;-1.03635;1.919046;-1.4925557;-1.3586078;META
the most appropriate metric for the problem at hand the choice of the right metric;4.2165647;-0.13244037;2.9445012;1.9183484;0.87061965;-0.023979936;CODE
is usually problem dependent and might require some domain knowledge refer to the;-0.8609308;-3.353202;0.98858124;3.6953425;3.5469677;0.34121287;CODE
example entitled;-4.637273;-1.3436399;2.1890862;1.6006685;3.9448903;-1.3896483;-
ref sphx glr auto examples model selection plot cost sensitive learning py;3.067219;-4.6333795;-3.519748;2.0941715;-1.7618893;2.6270955;CODE
for more details;-3.480828;-3.12476;4.442992;1.1291379;0.046866957;-1.9306489;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
evaluate the models using crossvalidation;3.2767832;0.27107865;-0.7984828;3.8464713;3.2127244;-1.6551036;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the yeast uci dataset;3.911143;-6.4352937;-0.72946244;-0.14085495;0.5306079;-2.1811318;IRRE
in this example we use a uci dataset 1 generally referred as the yeast;2.974631;-4.181206;-0.7173086;-0.4045966;2.0200386;-0.7029085;CODE
dataset we use the func sklearn datasets fetch openml function to load;1.4808271;-4.7157187;-3.1817303;0.62970155;-0.6736854;-0.05130235;IRRE
the dataset from openml;1.2005979;-5.200646;0.7031697;-0.1072208;4.2193813;0.1772596;CODE
to know the type of data science problem we are dealing with we can check;4.347445;-2.7167566;0.5972337;2.1216478;2.7275603;-4.1205325;-
the target for which we want to build a predictive model;3.3978703;-5.623559;3.6019733;6.4913154;2.1412194;0.6643422;CODE
we see that the target is discrete and composed of 10 classes we therefore;1.1342599;-0.7863547;1.9647056;1.8569394;4.617695;-0.88901734;CODE
deal with a multiclass classification problem;3.721748;-1.7839018;-1.2951438;0.9689607;5.7761774;-0.16677928;IRRE
strategies comparison;1.7476898;0.26093724;5.138309;5.7850776;1.3540506;-2.469336;-
in the following experiment we use a;0.4184957;2.4806745;4.0647564;2.8123965;-0.43761763;-3.328872;CODE
class sklearn tree decisiontreeclassifier and a;2.0431297;-5.0189023;-4.1972923;0.9039797;2.7870622;-2.0623674;IRRE
class sklearn model selection repeatedstratifiedkfold cross validation;3.0116537;-2.7888782;-4.9246254;3.004242;1.3857745;0.474139;CODE
with 3 splits and 5 repetitions;0.98584104;-0.6123479;5.8615265;-0.031931695;3.9565108;-2.7109308;-
we compare the following strategies;1.6202327;0.183141;5.746129;5.730598;2.0402539;-0.15896694;IRRE
class sklearn tree decisiontreeclassifier can handle multiclass;1.7923101;-5.536612;-4.3878045;1.1606712;4.1724677;0.7427269;IRRE
classification without needing any special adjustments it works by breaking;4.440686;-3.5016234;0.26612225;3.909244;4.5697474;0.08313097;CODE
down the training data into smaller subsets and focusing on the most common;9.215748;-3.2349942;2.119121;1.9376314;4.9290185;1.6746591;CODE
class in each subset by repeating this process the model can accurately;6.5586576;-0.9573925;1.5522219;4.157642;5.6988373;0.7625476;IRRE
classify input data into multiple different classes;5.9765778;-2.4121838;1.924266;-1.3294948;7.0427027;-1.5166881;CODE
class sklearn multiclass onevsoneclassifier trains a set of binary;2.1641197;-3.5336456;-5.3514357;-1.6332542;3.0852787;-0.9820469;IRRE
classifiers where each classifier is trained to distinguish between;4.437898;-3.5389078;1.6501247;1.5242542;7.160845;-1.0804967;IRRE
two classes;-0.42966914;-1.2711517;2.8943155;0.2246248;6.1959276;-2.135165;IRRE
class sklearn multiclass onevsrestclassifier trains a set of binary;2.2236514;-4.2144866;-5.2844863;-1.5531977;3.6423278;-1.1800165;IRRE
classifiers where each classifier is trained to distinguish between;4.437898;-3.5389078;1.6501247;1.5242542;7.160845;-1.0804967;IRRE
one class and the rest of the classes;0.105362564;-2.5492656;3.0586994;1.1581565;7.3503118;-1.3096888;IRRE
class sklearn multiclass outputcodeclassifier trains a set of binary;2.0628924;-4.7333384;-5.098662;-1.2664812;2.9139633;-1.02064;IRRE
classifiers where each classifier is trained to distinguish between;4.437898;-3.5389078;1.6501247;1.5242542;7.160845;-1.0804967;IRRE
a set of classes from the rest of the classes the set of classes is;0.48741692;-2.6529229;2.6812134;0.060587864;5.4191613;-0.5908487;IRRE
defined by a codebook which is randomly generated in scikit learn this;1.0568871;-8.115748;-3.3955796;-0.5669728;-0.14261338;-5.116776;CODE
method exposes a parameter code size to control the size of the codebook;-0.7692391;-0.51472443;-0.6525113;1.3612714;0.14343613;1.8431376;IRRE
we set it above one since we are not interested in compressing the class;-0.5582697;-1.2845781;1.6843685;1.6617254;2.455282;1.354246;IRRE
representation;-0.7608903;-2.367999;4.962392;-1.9334484;2.9168937;-1.2665551;-
we can now compare the statistical performance of the different strategies;4.208641;-1.9880235;3.434354;8.104371;1.9681165;0.8187218;IRRE
we plot the score distribution of the different strategies;2.99417;-1.9568027;6.351342;2.0947075;-0.3429327;-0.4830603;META
at a first glance we can see that the built in strategy of the decision;-1.2438424;-1.8762524;4.395628;5.26847;1.7434347;1.0923134;-
tree classifier is working quite well one vs one and the error correcting;1.5358269;-1.3735702;-4.1667924;2.5482175;1.7679973;-3.0095716;IRRE
output code strategies are working even better however the;0.82664275;-0.002680441;0.29352772;2.4185748;-0.4198772;-2.0606952;IRRE
one vs rest strategy is not working as well as the other strategies;-2.643896;1.8193204;2.1181781;4.261538;-0.66163164;1.1993885;-
indeed these results reproduce something reported in the literature;1.1438589;-2.8473344;-1.9823972;3.7992053;-0.65631384;-0.96968186;IRRE
as in 2 however the story is not as simple as it seems;-2.490739;-1.6070434;3.63125;1.3608925;0.2794697;-0.7688453;-
the importance of hyperparameters search;3.3468351;-3.9376473;1.3881342;6.0070715;2.8990676;0.53774023;CODE
it was later shown in 3 that the multiclass strategies would show similar;-0.68341494;-3.7791495;1.0441512;2.303246;3.8562584;2.036535;CODE
scores if the hyperparameters of the base classifiers are first optimized;4.9681554;-2.2602117;-1.0051438;3.3926857;3.9345052;0.41767943;IRRE
here we try to reproduce such result by at least optimizing the depth of the;4.5836835;1.0142986;1.7898768;-1.7356435;-1.6125226;4.3971515;IRRE
base decision tree;2.5432634;-2.7070272;1.7627556;-0.014048812;6.705146;-1.8522334;-
we can see that once the hyperparameters are optimized all multiclass;3.390583;-2.5960941;-3.3449616;4.249421;3.6096466;4.348327;IRRE
strategies have similar performance as discussed in 3;1.0987781;-2.6507192;3.922456;5.452416;2.9605439;2.0235658;CODE
conclusion;-1.7600391;1.0903363;5.187226;3.933175;0.70637393;-3.3991342;-
we can get some intuition behind those results;3.0190403;-2.6565647;3.0200543;2.722984;-1.0798178;-0.044803604;IRRE
first the reason for which one vs one and error correcting output code are;-0.85220253;1.9486287;-2.0374658;0.47032043;-1.0076013;-4.6023703;IRRE
outperforming the tree when the hyperparameters are not optimized relies on;4.034204;-0.27496806;-2.4980104;4.890959;1.302264;1.7123314;IRRE
fact that they ensemble a larger number of classifiers the ensembling;5.430591;-5.7763877;-1.9835151;3.1683817;3.953489;-0.18158972;IRRE
improves the generalization performance this is a bit similar why a bagging;5.458748;-3.1776378;0.56220996;3.3954778;3.276406;2.8178408;CODE
classifier generally performs better than a single decision tree if no care;3.5631478;-3.4609451;-2.9739838;3.74513;2.2737367;-0.8354293;CODE
is taken to optimize the hyperparameters;4.2295494;-1.0968485;0.93175757;3.5113876;1.7210575;2.9115756;IRRE
then we see the importance of optimizing the hyperparameters indeed it;4.4790974;-2.7133524;0.8562849;5.520775;1.5319707;4.071698;CODE
should be regularly explored when developing predictive models even if;2.5449467;-5.3051014;0.6845354;8.961444;0.5280849;1.0691509;CODE
techniques such as ensembling help at reducing this impact;4.113826;-2.0863192;0.41892344;4.874338;1.913966;0.76152134;CODE
finally it is important to recall that the estimators in scikit learn;4.6672897;-8.575486;-3.3167417;3.1996732;-5.044634;-0.59964305;CODE
are developed with a specific strategy to handle multiclass classification;3.315841;-5.4951396;0.114988975;3.3452477;6.6167936;1.8345312;IRRE
out of the box so for these estimators it means that there is no need to;1.2615008;-0.72080284;-0.48792648;3.9658403;-1.7523462;2.0064936;TASK
use different strategies these strategies are mainly useful for third party;-2.4641562;-1.524631;3.441149;2.6159446;2.8890424;2.1466808;CODE
estimators supporting only binary classification in all cases we also show;3.519847;-2.3037083;-3.6132567;2.4712138;3.3993964;1.0513016;CODE
that the hyperparameters should be optimized;4.128333;-1.7469083;0.68767405;3.8392978;2.6545503;1.8136543;IRRE
references;-2.055842;-4.578016;4.8864408;3.3061564;1.3981156;-2.6630578;CODE
1 https archive ics uci edu ml datasets yeast;1.5106764;-5.852469;-3.001908;-0.40865338;-0.13658187;-1.4593922;IRRE
2 reducing multiclass to binary a unifying approach for margin classifiers;5.655306;-4.699384;-2.187064;-0.21066135;5.2648363;1.6059686;CODE
allwein erin l robert e schapire and yoram singer;-1.5079134;-0.11581548;0.29449654;-0.9546555;0.09033207;1.188594;CODE
journal of machine learning research 1 dec 2000 113 141;3.2701054;-6.371095;-0.70554155;3.3382416;3.198573;0.5959866;-
https www jmlr org papers volume1 allwein00a allwein00a pdf;-4.393728;-2.8384058;0.52795756;-0.66597325;1.6735185;-0.38151282;CODE
3 in defense of one vs all classification;1.5865332;-1.6702793;-1.06665;3.068145;7.5879374;-2.2277877;CODE
journal of machine learning research 5 jan 2004 101 141;3.3996015;-5.436358;-0.16726324;3.8047717;3.3506796;0.6971289;-
https www jmlr org papers volume5 rifkin04a rifkin04a pdf;-4.3452916;-3.6336133;-0.9276862;-0.6138434;1.7129927;-0.14230192;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
loading a dataset;3.1638367;-2.9220173;1.7227827;0.14410491;0.79779756;0.05522044;IRRE
for this example we use the yeast;-1.1192114;-2.234772;3.6471677;0.500972;0.6661613;0.2428767;CODE
https www openml org d 40597 dataset which contains;-1.7503607;-3.6056018;-0.6224441;-1.1665137;2.3165238;-0.9740954;CODE
2 417 datapoints each with 103 features and 14 possible labels each;3.8703048;-1.9658377;0.10378169;-3.4519753;2.9934769;-1.760379;TASK
data point has at least one label as a baseline we first train a logistic;5.1706533;-0.7156044;0.5324512;0.5891511;3.9251907;-0.07762067;CODE
regression classifier for each of the 14 labels to evaluate the performance of;5.580946;-2.8573027;1.2328887;1.0944675;3.5442443;-2.9514325;CODE
these classifiers we predict on a held out test set and calculate the;6.6261697;-2.5771527;-1.149783;5.089865;3.9579763;-4.072885;IRRE
jaccard similarity for each sample;6.684018;-0.20813689;1.4149104;-1.4162862;2.0174673;-0.5939231;CODE
load a multi label dataset from https www openml org d 40597;-0.17952025;-1.8680658;-0.64537984;-1.1656907;3.0400107;1.7762841;CODE
fit models;5.237896;-3.2392323;2.846708;1.1394159;0.24661753;1.1979936;-
we fit class sklearn linear model logisticregression wrapped by;4.310364;-3.4913175;-4.2492127;-0.19123691;-1.3280015;1.509595;IRRE
class sklearn multiclass onevsrestclassifier and ensemble of multiple;3.3394563;-4.9432445;-4.2787905;0.07952045;3.7888458;-0.73420763;IRRE
class sklearn multioutput classifierchain;3.3635368;-6.6279626;-4.584462;0.13762027;2.1900637;-0.81167585;IRRE
logisticregression wrapped by onevsrestclassifier;1.5232178;-2.2886312;-4.7266126;1.8044353;2.2813118;1.1330111;IRRE
since by default class sklearn linear model logisticregression can t;0.08732581;-1.7146811;-7.052396;0.20380199;-3.5043314;0.2537259;CODE
handle data with multiple targets we need to use;2.9670703;1.6228168;3.0442922;1.5860673;4.661358;1.7572333;TASK
class sklearn multiclass onevsrestclassifier;2.049336;-4.7853155;-4.808777;-0.6607354;2.230694;-0.5507213;IRRE
after fitting the model we calculate jaccard similarity;5.298111;-1.4390153;0.042785905;0.2843822;-0.51054835;0.99967206;-
chain of binary classifiers;3.0386016;-3.9992096;-1.7969826;0.33602816;5.9503527;-0.6542314;IRRE
because the models in each chain are arranged randomly there is significant;2.3634975;0.1267759;-0.3918808;2.2854142;-0.010337259;0.76949704;IRRE
variation in performance among the chains presumably there is an optimal;2.4424193;0.44086906;1.6109333;3.0232549;1.8152064;2.3903255;CODE
ordering of the classes in a chain that will yield the best performance;2.8990963;-0.47677678;1.7095155;1.7808617;5.20273;0.9892051;CODE
however we do not know that ordering a priori instead we can build a;-2.7557108;-1.1561348;1.0495774;2.9026656;5.4530973;1.469284;CODE
voting ensemble of classifier chains by averaging the binary predictions of;5.904089;-4.3381405;-1.3412565;1.7861904;3.7731702;-0.043208048;IRRE
the chains and apply a threshold of 0 5 the jaccard similarity score of the;4.7957106;-1.0853729;1.9536514;-0.9470236;2.0934672;-2.770396;CODE
ensemble is greater than that of the independent models and tends to exceed;3.935803;-0.8217939;-2.185778;3.699161;1.6378222;1.0375344;CODE
the score of each chain in the ensemble although this is not guaranteed;3.1697917;0.31140938;-0.28059357;3.326353;2.956631;-2.215753;CODE
with randomly ordered chains;0.9816039;0.70852894;4.1600976;-1.2876798;3.616695;-1.0633024;IRRE
plot results;2.7280965;0.63260704;7.251219;-4.383265;-6.2113085;-4.720718;IRRE
plot the jaccard similarity scores for the independent model each of the;5.359375;-2.7004244;2.774647;-1.156486;-1.4686424;-0.29419196;CODE
chains and the ensemble note that the vertical axis on this plot does;1.872611;-0.7767666;2.995116;-2.8715615;-2.7059493;1.442691;CODE
not begin at 0;-2.8443868;3.730244;2.2832186;-2.327385;-4.023534;-3.208354;-
results interpretation;1.2859799;1.070043;3.235535;2.664484;0.66348714;-5.7255816;IRRE
there are three main takeaways from this plot;-1.3663828;-0.6114034;4.954713;-0.9730639;-1.9419184;-0.26419905;CODE
independent model wrapped by class sklearn multiclass onevsrestclassifier;1.9728866;-4.228996;-5.0811195;1.0664599;1.8340647;1.722855;CODE
performs worse than the ensemble of classifier chains and some of individual chains;5.8353953;-3.7172985;-2.867868;3.864783;2.8286934;-0.32832304;IRRE
this is caused by the fact that the logistic regression doesn t model relationship;-0.3604589;1.5289097;-3.6919734;0.86691546;-3.1262763;-0.85377777;CODE
between the labels;0.6319378;-1.2184196;7.660009;-3.3494697;3.0883095;-1.1443732;-
class sklearn multioutput classifierchain takes advantage of correlation;4.2470846;-5.8290615;-4.468834;0.98522997;1.251474;1.2312219;IRRE
among labels but due to random nature of labels ordering it could yield worse;3.4949868;-0.21349765;2.2858107;1.6304691;4.529543;0.027109817;IRRE
result than an independent model;1.5632126;2.697314;2.7317147;2.4964497;1.0634072;-1.3477682;IRRE
an ensemble of chains performs better because it not only captures relationship;3.7247446;-2.1858883;1.2157685;3.6026435;4.135341;1.0449041;CODE
between labels but also does not make strong assumptions about their correct order;1.167532;2.9618137;-0.06577993;-0.19569117;3.3318923;0.26491678;META
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
first we try to import the packages and warn the user in case they are;-5.3149576;-2.2714865;-3.6031892;1.9924923;-3.1512144;-0.16937758;CODE
missing;-5.0286274;-0.24083768;3.136673;-0.9322111;-0.3847307;-2.6291027;-
we define a wrapper class for implementing the scikit learn api to the;-0.7175136;-11.94682;-3.7234871;2.4199138;-0.21063665;-1.983811;CODE
nmslib as well as a loading function;-0.8520478;-3.1772668;-1.0104772;0.33028048;0.34261426;1.888122;CODE
we benchmark the different exact approximate nearest neighbors transformers;5.196153;-1.4603912;-0.4409653;-1.0845946;-0.5385993;3.0215497;CODE
tsne requires a certain number of neighbors which depends on the;0.88799345;1.5741756;0.49459583;-0.052270215;1.0593953;1.4404916;CODE
perplexity parameter;-0.27494305;3.5146937;-0.9976838;-3.1200347;0.7112106;0.9314381;IRRE
add one since we include each sample as its own neighbor;3.0777435;0.52955645;2.6297162;-0.9494869;4.6322923;0.17829807;CODE
init random pca cannot be used with precomputed distances;2.736152;0.8650771;-4.061802;-1.4042307;-1.644999;3.6984243;IRRE
sample output;3.7625487;2.1796162;3.2031777;-1.6427609;0.7993147;-6.813072;IRRE
benchmarking on mnist 10000;4.876708;-2.9236767;-1.7684942;2.9029393;-0.8139133;-0.81110823;-
kneighborstransformer 0 007 sec fit;0.4706521;-0.054735456;-2.6666028;-4.6270022;-1.3374852;-0.3645511;CODE
kneighborstransformer 1 139 sec transform;-1.9862549;-1.8892988;-1.729324;-5.523833;-2.1075203;-1.4576492;CODE
nmslibtransformer 0 208 sec fit;-1.5592041;0.9228546;-4.063797;-3.162415;-1.3101856;1.0550665;CODE
nmslibtransformer 0 315 sec transform;-2.7224133;0.12259342;-2.9552317;-4.117737;-2.7356148;-0.5070346;CODE
pynndescenttransformer 4 823 sec fit;-1.7820667;1.6699827;-2.216174;-1.2983605;-1.3360918;2.2556322;CODE
pynndescenttransformer 4 884 sec transform;-3.0166018;0.22736342;-0.09206236;-2.3267417;-2.13541;0.26486543;CODE
pynndescenttransformer 0 744 sec transform;-3.1082003;1.2073739;-2.0861523;-2.843766;-3.119987;0.1499647;CODE
benchmarking on mnist 20000;4.4911985;-2.9095151;-2.1669815;2.6626291;-0.86025167;-0.79839337;-
kneighborstransformer 0 011 sec fit;0.51705116;0.002841542;-2.7330487;-5.121027;-1.249176;-1.2333386;CODE
kneighborstransformer 5 769 sec transform;-1.1020181;-1.5046735;-1.6551379;-5.656321;-2.0737894;-0.34735686;CODE
nmslibtransformer 0 733 sec fit;-0.8134236;0.9625144;-4.3895354;-3.0391114;-1.7446177;0.53530073;CODE
nmslibtransformer 1 077 sec transform;-2.199177;-0.8431588;-2.2804613;-4.516249;-2.0346072;-0.20928225;CODE
pynndescenttransformer 14 448 sec fit;-1.997514;1.0664811;-1.661299;-1.3762482;-1.2387143;1.4596459;CODE
pynndescenttransformer 7 103 sec transform;-3.1123545;0.07043905;-0.6756135;-2.1896374;-2.4660237;0.54935896;CODE
pynndescenttransformer 1 759 sec transform;-3.0074549;0.47368664;-1.0970539;-2.4569998;-2.676038;-0.25464496;CODE
notice that the pynndescenttransformer takes more time during the first;-0.53870094;1.4305046;0.012614661;1.633119;-2.857975;2.9981346;CODE
fit and the first transform due to the overhead of the numba just in time;1.7311699;0.5425212;1.8972286;-1.5427719;-0.05326983;4.234347;CODE
compiler but after the first call the compiled python code is kept in a;-4.805563;0.29165965;-2.2214792;2.19982;-2.4799085;-0.3360754;CODE
cache by numba and subsequent calls do not suffer from this initial overhead;-0.8320163;0.8509691;-0.5295914;2.9761071;-0.34856278;3.9783225;CODE
both class sklearn neighbors kneighborstransformer and nmslibtransformer;2.5188267;-4.957932;-4.8358383;-2.186883;0.5068275;0.8543129;CODE
are only run once here as they would show more stable fit and transform;-0.72106636;0.18445231;0.9535255;2.15808;1.0458435;2.3518164;CODE
times they don t have the cold start problem of pynndescenttransformer;-2.1683002;0.46764034;-0.6113736;2.4118783;-2.291529;1.5381176;CODE
init the plot;-2.744992;-1.3722152;5.649478;0.07313424;-4.7478113;-1.0499347;IRRE
plot tsne embedding which should be very similar across methods;3.1279852;-0.7090096;0.39777803;-1.5135347;-2.5807073;4.2191825;-
sample output;3.7625504;2.1796184;3.2031772;-1.6427622;0.7993137;-6.8130717;IRRE
benchmarking on mnist 10000;4.876708;-2.9236767;-1.7684942;2.9029393;-0.8139133;-0.81110823;-
tsne with internal nearestneighbors 24 828 sec fit transform;2.2418907;1.1414943;-1.5297425;-4.008206;-1.7272556;3.4590569;CODE
tsne with kneighborstransformer 20 111 sec fit transform;-0.4235186;0.63673705;-2.9518006;-3.788073;-1.1625366;2.4389791;CODE
tsne with nmslibtransformer 21 757 sec fit transform;-0.4350834;1.3287781;-3.7723215;-2.6088645;-1.6033686;2.728723;CODE
benchmarking on mnist 20000;4.4911985;-2.9095151;-2.1669815;2.6626291;-0.86025167;-0.79839337;-
tsne with internal nearestneighbors 51 955 sec fit transform;2.2477927;0.89408755;-2.1927006;-4.094771;-1.7841532;2.810326;CODE
tsne with kneighborstransformer 50 994 sec fit transform;-0.22692107;0.82607776;-3.0887887;-3.9740772;-1.0214058;2.3233128;CODE
tsne with nmslibtransformer 43 536 sec fit transform;-0.72087914;1.2192707;-4.0231285;-2.8687265;-1.2171246;2.4332383;CODE
we can observe that the default class sklearn manifold tsne estimator with;2.1933622;-5.037088;-4.919785;1.6123015;-0.8831717;4.6369386;CODE
its internal class sklearn neighbors nearestneighbors implementation is;3.7037566;-5.630711;-3.6867273;-2.9479396;-0.51824135;-0.66228735;TASK
roughly equivalent to the pipeline with class sklearn manifold tsne and;3.239272;-6.923352;-2.4059849;-0.0652585;1.3611469;3.373424;CODE
class sklearn neighbors kneighborstransformer in terms of performance;6.168163;-5.005201;-3.6811392;-1.7958286;0.4164701;1.3324324;CODE
this is expected because both pipelines rely internally on the same;-2.4793115;0.9900537;-3.4664762;3.5505972;-1.0409882;3.3048534;CODE
class sklearn neighbors nearestneighbors implementation that performs;4.8201447;-4.404742;-4.1452665;-2.2278996;-1.046778;-0.2373108;TASK
exacts neighbors search the approximate nmslibtransformer is already;3.4176333;-1.192948;-3.2304215;-2.4002104;-0.70324224;1.5251368;CODE
slightly faster than the exact search on the smallest dataset but this speed;6.925707;-1.9070044;-0.20825398;-0.0064389077;0.616836;-0.8626764;CODE
difference is expected to become more significant on datasets with a larger;6.3886414;1.1148455;-1.1106858;1.688439;-1.9847298;-0.5734427;IRRE
number of samples;3.6382182;1.1615254;2.620109;-0.38537428;2.556823;-4.3489356;-
notice however that not all approximate search methods are guaranteed to;3.655607;0.55778724;-3.3079526;4.7722363;-0.2086621;0.609347;-
improve the speed of the default exact search method indeed the exact search;2.1014907;0.69562495;-0.78941274;3.41514;0.08502761;0.84159595;CODE
implementation significantly improved since scikit learn 1 1 furthermore the;3.0675733;-9.805664;-5.5279603;0.06454283;-3.723292;-2.5429444;TASK
brute force exact search method does not require building an index at fit;3.7332366;2.2838666;-3.350032;0.792557;-0.007119651;-1.2186869;CODE
time so to get an overall performance improvement in the context of the;0.7017113;-2.7186205;3.9864707;5.652472;2.2577293;0.64725167;CODE
class sklearn manifold tsne pipeline the gains of the approximate search;5.115085;-5.6574855;-3.368733;0.97789454;0.32488814;3.0081992;CODE
at transform need to be larger than the extra time spent to build the;-0.7030399;-0.60640395;0.6384596;-1.1525775;-2.263343;3.6482584;TASK
approximate search index at fit time;6.6702814;0.75002843;-0.05086977;0.33316723;-0.07542621;2.0029235;-
finally the tsne algorithm itself is also computationally intensive;3.5427496;-2.9193394;-0.35901672;-0.89941406;0.9443963;1.1390127;CODE
irrespective of the nearest neighbors search so speeding up the nearest;4.5136695;-1.930145;1.8764639;1.3018543;0.46971673;3.4590425;-
neighbors search step by a factor of 5 would not result in a speed up by a;2.4543488;1.3458655;0.15603614;-0.19963542;-1.6663802;-1.0669135;IRRE
factor of 5 for the overall pipeline;0.5365901;-0.32352427;2.0190697;0.14203006;1.3329579;-0.069115505;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the transformer computes the nearest neighbors graph using the maximum number;4.175932;-1.4207852;1.708753;-5.461932;-1.1459105;1.0318304;IRRE
of neighbors necessary in the grid search the classifier model filters the;5.3008227;-3.8319957;0.43900228;0.20061101;3.7986982;1.0148207;CODE
nearest neighbors graph as required by its own n neighbors parameter;3.5180619;-0.15594654;0.8706474;-4.5547624;0.17056006;2.4087071;IRRE
note that we give memory a directory to cache the graph computation;0.4762443;-3.6380625;1.4382429;-0.80859107;0.08146607;2.3650503;TASK
that will be used several times when tuning the hyperparameters of the;-0.69133717;-0.2769377;1.0124242;3.313141;1.4333336;1.9006726;IRRE
classifier;5.3745756;-5.4938235;2.4601512;1.5816466;5.595349;-3.0490239;IRRE
plot the results of the grid search;4.497984;-0.4454899;5.683081;-3.8576722;-3.5968034;-0.95232713;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the data;0.7985331;0.05660562;5.910286;-1.0126852;0.33812684;-1.370043;CODE
in this example we use the iris dataset we split the data into a train and test;4.480344;-1.3365941;0.97292215;-0.05398425;2.0981414;-3.0610237;IRRE
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
k nearest neighbors classifier;6.3629766;-4.463254;-0.579037;-3.0976763;1.9363861;-0.15601642;IRRE
we want to use a k nearest neighbors classifier considering a neighborhood of 11 data;5.9008255;-3.1614425;-0.3177973;-2.5529368;2.512012;0.16552186;CODE
points since our k nearest neighbors model uses euclidean distance to find the;5.7989917;-2.2084763;0.41159493;-2.9271588;-2.0373816;1.2200137;CODE
nearest neighbors it is therefore important to scale the data beforehand refer to;6.5681715;-1.9725904;2.7128007;-0.80603576;0.3350175;4.1123033;CODE
the example entitled;-4.120366;-1.576132;2.4766312;2.4746532;3.5802796;-1.3135642;-
ref sphx glr auto examples preprocessing plot scaling importance py for more;2.0315766;-2.7453287;-1.6174957;-1.620411;-4.581522;4.5698824;CODE
detailed information;-0.6495472;-4.587581;6.0028467;2.0284135;2.5429823;-1.534805;CODE
thus we use a class sklearn pipeline pipeline to chain a scaler before to use;2.574534;-3.849919;-3.290054;1.1968442;-1.1283605;4.8755326;CODE
our classifier;5.6062284;-4.7010756;3.4720619;2.3979564;4.78345;-3.1339655;IRRE
decision boundary;1.028218;-1.2365232;4.423771;2.0452394;4.748018;-0.16094814;-
now we fit two classifiers with different values of the parameter;5.8231745;0.51433545;-1.6700292;0.5922021;4.3748703;2.3454623;IRRE
weights we plot the decision boundary of each classifier as well as the original;5.3800807;-4.003451;2.7985032;-0.75168693;1.8963301;2.7771263;IRRE
dataset to observe the difference;6.957137;0.23483674;3.7579768;0.7857896;0.61935306;-3.0783873;IRRE
conclusion;-1.760038;1.090336;5.187227;3.9331748;0.70637256;-3.3991337;-
we observe that the parameter weights has an impact on the decision boundary when;4.2296057;-0.98555;-0.50927883;3.675786;2.7039745;4.905698;IRRE
weights unifom all nearest neighbors will have the same impact on the decision;6.6420255;-0.6449116;0.58074677;2.5523443;2.5830095;3.7772775;-
whereas when weights distance the weight given to each neighbor is proportional;4.641234;0.07784317;1.3776205;-1.37328;-0.6751456;3.6548953;-
to the inverse of the distance from that neighbor to the query point;3.122959;0.70050997;3.1616127;-2.4946446;0.7699172;2.1605947;CODE
in some cases taking the distance into account might improve the model;6.1799984;-0.4175916;2.3752935;4.691266;0.89723265;3.6661766;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the data;0.7985331;0.05660562;5.910286;-1.0126852;0.33812684;-1.370043;CODE
project the 64 dimensional data to a lower dimension;6.3930416;-1.2146405;0.1680899;-6.547022;0.4944311;1.5810388;-
use grid search cross validation to optimize the bandwidth;4.3028965;1.1187271;-0.85947764;1.8860672;1.757151;2.9761193;-
use the best estimator to compute the kernel density estimate;4.0081625;-1.5798945;-0.6270001;0.67549914;-1.9085784;3.8112886;IRRE
sample 44 new points from the data;5.754923;1.4399074;3.1836686;-2.3897207;1.0024107;-3.1544688;CODE
turn data into a 4x11 grid;2.9558542;1.0720553;2.9408367;-7.873365;0.54500467;2.0695934;CODE
plot real digits and resampled digits;3.6664786;1.6018469;2.7339442;-4.1642947;-5.3424044;-2.4913235;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
plot the progression of histograms to kernels;4.4757276;-3.2222712;2.9659564;-5.187076;-2.6781409;0.7931062;-
histogram 1;2.7444413;-1.0640291;5.088093;-5.0800624;-0.18639596;-4.3295984;-
ax 0 0 hist x 0 bins bins fc aaaaff density true;0.08646089;2.4945858;-3.156957;-5.1829457;-1.8357723;-1.3543078;-
histogram 2;2.3939447;-1.5157746;5.3449287;-4.6833234;-0.1928977;-4.1183066;-
ax 0 1 hist x 0 bins bins 0 75 fc aaaaff density true;0.7030318;2.769827;-2.819624;-5.774754;-2.1777453;-1.7509669;-
tophat kde;-1.403468;-2.976889;1.9954362;0.113128334;0.00038886513;0.3718389;-
ax 1 0 fill x plot 0 np exp log dens fc aaaaff;1.4885254;1.1139892;-0.41879982;-6.799418;-4.4217176;-0.5330155;-
gaussian kde;3.0685937;-2.458433;-0.6290677;-4.4044213;-1.0088509;1.6720302;-
ax 1 1 fill x plot 0 np exp log dens fc aaaaff;1.5072305;1.0796916;-0.17718959;-6.6298413;-4.375663;-0.38388652;-
plot all available kernels;3.3124797;-3.7579348;2.7305446;-3.0807555;-2.2726593;1.5132619;-
axi fill x plot 0 np exp log dens k fc aaaaff;1.7110999;0.70320445;-0.22900724;-6.3784404;-4.454004;-0.57359004;-
plot a 1d density example;0.7613986;0.043124568;3.1848795;-5.98852;-4.9543037;0.6536687;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate normal not abnormal training observations;5.2920012;0.34615475;-1.114141;0.42193595;0.67443633;0.6416133;-
generate new normal not abnormal observations;3.2218554;2.0219085;-0.31236744;-0.6015224;-0.36771402;1.4099731;CODE
generate some abnormal novel observations;5.389696;-1.1086786;1.1809517;1.1423573;-0.67577666;-1.1810746;-
fit the model for novelty detection novelty true;3.7049942;-1.3634517;0.55475926;2.9004066;2.3609197;1.5051485;CODE
do not use predict decision function and score samples on x train as this;4.3273582;1.1767491;-1.311709;2.2167397;0.82827455;-0.8600395;CODE
would give wrong results but only on new unseen data not used in x train;3.5395067;1.0879873;-1.7204646;1.8443861;-0.6637195;-0.52523386;META
e g x test x outliers or the meshgrid;4.1944094;0.52770287;-0.6696752;2.9582868;-0.7671723;-0.49076968;IRRE
plot the learned frontier the points and the nearest vectors to the plane;3.758133;-3.9415486;3.0212216;-3.715088;-5.1427326;1.3946241;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate data with outliers;6.1071014;0.91620106;1.7046562;-1.6389949;-0.5194978;-1.007186;-
fit the model for outlier detection default;4.372565;1.2251968;-1.373015;1.3731261;-1.4538429;2.06299;CODE
use fit predict to compute the predicted labels of the training samples;5.7368584;-2.4626658;-0.16469145;2.395212;0.37486026;0.2826255;-
when lof is used for outlier detection the estimator has no predict;3.3481705;1.2158451;-4.234848;2.157712;-3.9006119;1.8780948;CODE
decision function and score samples methods;5.7534065;-1.3937445;0.7783521;4.0397725;3.4712398;-1.7053915;CODE
plot results;2.7280972;0.6326069;7.251218;-4.383266;-6.211307;-4.720718;IRRE
plot circles with radius proportional to the outlier scores;4.1822767;1.1461828;3.8621275;-2.6159244;-4.9633627;1.2584729;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
we only take two features we could avoid this ugly;-0.75661933;-2.4291553;1.5621475;1.7895281;2.1918683;2.4348354;CODE
slicing by using a two dim dataset;5.4138145;-0.5458843;-1.0651379;-4.0028644;1.552618;1.7348677;IRRE
h 0 05 step size in the mesh;0.74738085;1.7144243;-1.0352572;-3.4012294;-2.7977061;1.1370537;CODE
create color maps;0.56659913;-2.7982113;3.9693801;-4.440927;1.520608;1.0986661;IRRE
cmap light listedcolormap ffaaaa aaffaa aaaaff;-2.7286303;-1.3438044;1.7499703;-1.7912952;0.90064377;0.019718185;-
cmap bold listedcolormap ff0000 00ff00 0000ff;-4.0671124;-0.042569418;-2.0817711;-2.1516771;0.27754596;1.0955077;-
plot also the training and testing points;4.3641148;-3.0837271;4.7333665;0.33819526;-3.1076214;-2.2697105;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load digits dataset;4.3504925;-1.6583225;0.32199317;-3.2392607;0.6406084;-1.7657715;TASK
split into train test;4.2921104;2.1375556;1.6620575;3.7252765;3.0538309;-4.069842;CODE
reduce dimension to 2 with pca;4.2428184;1.0749161;-0.6753054;-5.825892;1.0812204;4.169289;-
reduce dimension to 2 with lineardiscriminantanalysis;5.29653;1.9317918;-2.2296143;-5.043056;-0.13167976;4.0498977;-
reduce dimension to 2 with neighborhoodcomponentanalysis;4.2463183;1.0932126;-0.95547026;-4.9647326;0.913763;5.264483;-
use a nearest neighbor classifier to evaluate the methods;6.7011147;-2.00859;-1.0120827;2.3504283;3.1485877;-2.4194894;IRRE
make a list of the methods to be compared;3.261909;1.1139038;2.7575123;4.8314557;1.5710572;-3.640552;IRRE
plt figure;-0.68226016;-0.9015278;5.5699043;-3.4513502;-2.01065;-2.3537288;-
plt subplot 1 3 i 1 aspect 1;1.1349044;0.68689746;2.6210992;-7.934736;-4.17597;0.7303994;-
fit the method s model;4.3424034;1.4701552;0.59725446;3.024671;0.7188829;0.4791118;-
fit a nearest neighbor classifier on the embedded training set;6.251063;-3.7884963;-2.9218464;0.1379821;2.4574764;3.149095;IRRE
compute the nearest neighbor accuracy on the embedded test set;7.2686787;0.54846376;-4.0575647;2.2394993;0.378048;-2.7649162;IRRE
embed the data set in 2 dimensions using the fitted model;4.9254293;-0.65746856;0.78790385;-3.634829;-0.7074987;4.9057803;IRRE
plot the projected points and show the evaluation score;3.483796;0.5952889;4.4053974;-2.2723186;-3.5834277;-0.6278199;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
original points;-1.2156774;-0.72204643;2.9436057;-0.4553606;-0.27677584;-1.5555283;CODE
first we create a data set of 9 samples from 3 classes and plot the points;5.942566;-1.7310059;4.105584;-3.8845942;1.8320522;-1.1114957;IRRE
in the original space for this example we focus on the classification of;2.2268765;-4.05889;2.7548337;1.7107445;6.9751763;0.6499746;CODE
point no 3 the thickness of a link between point no 3 and another point;-1.3999267;1.8501366;4.0248785;-5.4878664;-0.11823668;0.060730144;CODE
is proportional to their distance;3.6871312;0.4021789;4.9119587;-1.7248698;-1.2586408;1.8912312;-
ax axis equal so that boundaries are displayed correctly as circles;1.5062162;2.4190004;4.0876665;-5.4834237;-5.046419;2.9040608;-
compute exponentiated distances use the log sum exp trick to;2.203593;0.43034208;-0.39736652;-3.539936;-1.3044157;0.65956247;IRRE
avoid numerical instabilities;4.2770977;2.7556808;-2.1155784;-0.9636447;-1.4863864;0.24342827;CODE
learning an embedding;4.8164935;-4.032364;3.7228086;-1.4635696;2.6547115;2.3738103;-
we use class sklearn neighbors neighborhoodcomponentsanalysis to learn an;5.239244;-7.2024226;-2.2008955;0.05959392;0.7336374;0.4151317;IRRE
embedding and plot the points after the transformation we then take the;2.8722556;-0.32599774;5.76081;-5.26981;-4.012843;4.6683173;CODE
embedding and find the nearest neighbors;5.637658;-1.0395725;2.6072173;-4.583104;1.356325;1.3031735;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
we only take the first two features we could avoid this ugly;-0.6362951;-2.60033;1.722617;1.962089;1.9477669;2.8841977;CODE
slicing by using a two dim dataset;5.4138145;-0.5458843;-1.0651379;-4.0028644;1.552618;1.7348677;IRRE
create color maps;0.56659913;-2.7982113;3.9693801;-4.440927;1.520608;1.0986661;IRRE
we create an instance of nearest centroid classifier and fit the data;6.996163;-1.6218953;2.3206863;-1.1995536;3.4746006;2.3147817;IRRE
plot also the training points;3.8571665;-4.4865284;5.091605;-1.1665463;-2.758238;-0.3909035;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
here we generate a few data points to use to train the model we also generate;6.2967086;-4.463676;4.0651474;1.5165861;3.4719884;-0.69059706;CODE
data in the whole range of the training data to visualize how the model would;7.194416;-3.7969077;5.2696395;-1.1511611;0.9724949;0.43706033;CODE
react in that whole region;-2.9539664;-0.07542924;6.041199;-1.4649187;-1.6308681;1.2944287;CODE
add noise to targets;1.5080409;-0.466762;1.2343596;2.5179448;-0.38013557;2.7145147;TASK
fit regression model;2.8170338;0.28139204;2.8969915;0.29012498;-2.5641077;-0.055165276;-
here we train a model and visualize how uniform and distance;5.0852337;-3.867211;5.714486;-0.16629094;0.33646163;0.14828582;CODE
weights in prediction effect predicted values;4.717869;-1.3911163;0.5694513;2.085985;-1.7791431;2.2692935;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
if basemap is available we ll use it;-2.2474754;-4.820522;3.34049;-0.019303557;1.0938623;3.0692682;CODE
otherwise we ll improvise later;-1.3241091;-2.0078855;3.4649837;4.2516494;0.76506215;0.68537974;-
x y coordinates for corner cells;0.42943436;-0.15855147;3.4682386;-8.578858;-3.992921;1.0000855;CODE
x coordinates of the grid cells;1.1938763;0.97250885;3.1347892;-7.352223;-2.9789383;1.3927096;-
y coordinates of the grid cells;0.9027665;0.42357472;3.3228528;-6.7840323;-4.5404034;1.127217;-
get matrices arrays of species ids and locations;4.571627;0.5335721;0.9800513;-4.2550063;0.8292433;-0.42047277;-
xtrain np pi 180 0 convert lat long to radians;0.01061642;-0.16471;-1.1624538;-4.749054;-4.8791156;0.569425;-
set up the data grid for the contour plot;1.9549901;-1.1339663;4.016125;-5.1776505;-3.2790787;3.7976549;IRRE
plot map of south america with distributions of each species;2.548796;-1.3677312;4.8237095;-2.3370447;-1.4491032;1.1558393;META
construct a kernel density estimate of the distribution;3.4480531;-2.0794547;0.2513919;-0.9005882;0.04034186;3.5866382;CODE
evaluate only on the land 9999 indicates ocean;0.20968485;2.8611546;0.8507776;-0.7751405;0.26709312;-3.1787605;-
plot contours of the density;-0.6164818;-1.0744632;4.6382346;-3.662456;-4.330964;1.1029483;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
h 0 02 step size in the mesh;-0.25002378;1.8169312;-0.86498296;-4.06648;-2.6294658;0.9815422;CODE
iterate over datasets;6.4263754;-1.8027627;1.7486563;-0.48532283;1.8628664;-2.1361394;IRRE
split into training and test part;3.705093;-0.5595804;2.1801941;4.682013;4.0611243;-3.3438048;IRRE
just plot the dataset first;4.6126723;-1.8153832;5.1297517;-3.8354614;-2.9007008;0.21076585;IRRE
cm bright listedcolormap ff0000 0000ff;-3.4484696;-1.4411412;-0.33886743;-2.8114066;-0.35755786;0.74768466;-
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
and testing points;1.7337205;-0.19041012;2.6997192;3.6949828;0.9770017;-3.6819532;IRRE
iterate over classifiers;5.9412785;-3.1765063;0.2761596;0.36291677;4.695798;-2.4316916;IRRE
plot the decision boundary for that we will assign a color to each;2.4560258;-1.6418927;5.445053;-2.621385;0.95969707;-0.08623329;IRRE
point in the mesh x min x max x y min y max;1.3513005;1.6070616;2.7779777;-5.594809;-2.0461638;1.9067987;CODE
put the result into a color plot;1.4292959;0.4262304;5.77492;-3.760507;-3.6140656;-2.4272733;IRRE
plot also the training points;3.8571665;-4.4865284;5.091605;-1.1665463;-2.758238;-0.3909035;CODE
and testing points;1.7337205;-0.19041012;2.6997192;3.6949828;0.9770017;-3.6819532;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
different learning rate schedules and momentum parameters;3.4815967;-3.6765256;0.7390963;3.1898763;0.33006665;1.8261645;IRRE
for each dataset plot learning for each learning strategy;5.40384;-6.1107974;3.681204;0.62512064;-0.60404426;1.874113;CODE
digits is larger but converges fairly quickly;1.3766237;1.0894176;0.33006224;-0.41301042;-2.8718154;-2.6878426;META
some parameter combinations will not converge as can be seen on the;1.0517591;3.96372;-2.4232807;-0.57997555;-2.239434;-0.74951804;IRRE
plots so they are ignored here;-1.9987276;-1.242239;4.5755467;-0.75412095;-6.104972;0.71545863;-
load generate some toy datasets;5.397099;-4.0946193;1.892281;-0.34425288;2.471936;0.093229964;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
load data from https www openml org d 554;-3.3481424;0.08540846;0.6654659;-0.8974318;-0.7707516;0.57027537;CODE
split data into train partition and test partition;4.798673;0.46257633;0.37642652;0.8466975;2.19572;-2.1522837;IRRE
this example won t converge because of resource usage constraints on;0.076883495;4.065959;0.9216416;2.8893595;-1.6700311;1.164542;CODE
our continuous integration infrastructure so we catch the warning and;-3.5410297;-2.6569712;1.5074397;4.5367994;-0.7687637;-0.11699279;CODE
ignore it here;-3.1029027;0.58527666;0.715371;2.030791;-1.1458098;-1.4897172;-
use global min max to ensure all weights are shown on the same scale;4.7253017;3.5672395;1.6421803;-1.1123863;-0.52876556;5.2833905;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate data;3.5066168;-0.73323363;4.430809;-2.3223333;2.8341281;-3.9849672;-
in order to learn good latent representations from a small dataset we;5.5353374;-5.424969;0.545537;0.25632295;0.9650321;1.3908658;IRRE
artificially generate more labeled data by perturbing the training data with;7.9544992;-3.2128026;1.0795139;1.6011045;5.0958757;1.3212415;-
linear shifts of 1 pixel in each direction;3.2438197;0.50419444;3.1102784;-7.0761113;-3.1546443;3.5954003;-
x minmax scale x feature range 0 1 0 1 scaling;3.6201556;0.8665677;-1.2782184;-5.4635806;-2.0058737;4.112805;TASK
models definition;1.2333096;-3.0789244;2.7687428;4.4339147;2.2824929;1.4677775;IRRE
we build a classification pipeline with a bernoullirbm feature extractor and;4.4611692;-6.90474;-0.637049;0.65413475;5.22134;0.016796425;CODE
a class logisticregression sklearn linear model logisticregression;4.6761336;-5.067537;-4.3404818;1.2761322;-0.46494386;-0.23755158;IRRE
classifier;5.3745756;-5.4938235;2.4601512;1.5816466;5.595349;-3.0490239;IRRE
training;0.52897406;-5.414448;4.7018986;3.2398877;0.97651243;-2.6999364;-
the hyperparameters of the entire model learning rate hidden layer size;4.3602395;-4.457529;-0.09135234;2.516315;0.97725564;3.732629;IRRE
regularization were optimized by grid search but the search is not;3.2906334;0.4749131;-3.4240448;-0.41642165;-1.3172688;4.3375235;META
reproduced here because of runtime constraints;1.5352852;2.1195836;-2.844095;0.3432219;0.78140277;2.586332;CODE
hyper parameters these were set by cross validation;2.7098706;0.21479313;-1.658511;0.22648048;2.412149;0.41512328;IRRE
using a gridsearchcv here we are not performing cross validation to;1.4384543;1.715719;-4.050526;0.7994017;-1.9081964;-0.9364612;CODE
save time;-1.525489;-1.8698952;5.673651;3.9735115;-0.39303535;-0.79367864;CODE
more components tend to give better prediction performance but larger;4.7044163;-2.8629231;0.6675901;2.4744494;0.3596694;3.2104614;CODE
fitting time;4.2499895;-0.9459351;4.6178503;0.42062867;-2.9277945;-0.035625383;-
training rbm logistic pipeline;2.7508817;-3.4890254;-1.3237315;0.9947231;2.5789056;0.47459108;CODE
training the logistic regression classifier directly on the pixel;3.4326375;-5.097961;-0.0030082527;-0.0485948;-0.1849461;2.7798493;IRRE
evaluation;0.679902;-0.37662563;4.4817553;4.398665;2.8523319;-5.4748178;-
the features extracted by the bernoullirbm help improve the classification;4.799956;-5.753037;-0.623761;0.0122062;4.264421;-0.3449617;TASK
accuracy with respect to the logistic regression on raw pixels;4.9441323;-1.654412;-1.7132566;-0.02487531;-3.3562696;1.362407;-
plotting;1.0655625;-0.83037513;8.169972;-6.384913;-6.763113;-2.0687423;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
take only 2 features to make visualization easier;2.2530272;-2.1742642;4.4411755;-2.311092;1.5591235;2.4789906;TASK
feature medinc has a long tail distribution;3.5690844;-3.9552932;-1.7879807;1.7918018;0.62152517;1.4091169;TASK
feature aveoccup has a few but very large outliers;4.036089;-3.1825335;-1.0652828;1.8426125;0.093361296;0.4102646;TASK
scale the output between 0 and 1 for the colorbar;2.034527;1.5003049;2.838096;-5.0819287;-2.8844016;2.1460118;IRRE
plasma does not exist in matplotlib 1 5;-1.32371;-2.4352658;-3.4112394;-4.427086;-7.0693197;-1.1684507;TASK
define the axis for the first plot;-0.13000274;0.6496075;5.693223;-5.864489;-3.7816613;1.804123;CODE
define the axis for the zoomed in plot;0.22519499;0.33409992;4.986065;-5.659224;-4.773305;4.0273027;CODE
define the axis for the colorbar;-0.6278454;-1.5270246;4.3092785;-6.0230265;-1.242709;2.7026582;CODE
the scatter plot;3.715957;-2.857525;5.920888;-4.491506;-6.0562334;-0.09851526;-
removing the top and the right spine for aesthetics;-2.1780198;-0.46102726;4.897356;-1.8182482;0.6678511;4.373842;CODE
make nice axis layout;1.4563214;-1.4618765;6.2329187;-7.4268613;-2.768905;4.602122;-
histogram for axis x1 feature 5;2.5455544;-0.99540097;2.8585575;-6.671767;-1.5459261;0.06723066;TASK
histogram for axis x0 feature 0;1.9301116;-0.030939361;0.9896071;-7.0851173;-2.5978162;1.2208248;TASK
two plots will be shown for each scaler normalizer transformer the left;0.45506144;0.23084976;4.028131;-4.0351186;-4.4142838;4.7646837;CODE
figure will show a scatter plot of the full data set while the right figure;2.8888588;0.16391826;4.6959968;-3.6972742;-5.714312;1.8536693;CODE
will exclude the extreme values considering only 99 of the data set;5.961898;4.2225804;-0.275549;-1.4919554;0.878225;-1.2019941;IRRE
excluding marginal outliers in addition the marginal distributions for each;3.2201846;1.6372911;-0.59244376;-0.07610184;0.094300576;3.2912233;CODE
feature will be shown on the sides of the scatter plot;1.0410911;-3.0570803;4.77769;-2.8524604;-4.2679625;2.3242984;TASK
zoom in;-2.3829086;-1.6936979;7.0944734;-0.8148586;-2.6688702;0.8875607;-
results;-0.124750376;-1.7336558;6.189961;3.2482023;0.4808949;-6.011475;IRRE
original data;2.8858962;-0.8537612;4.090144;-1.0256886;1.5062635;-2.2374325;-
each transformation is plotted showing two transformed features with the;1.2128735;-1.1103054;3.70175;-5.8804536;-4.6939826;1.8086537;CODE
left plot showing the entire dataset and the right zoomed in to show the;1.881248;-0.6269078;4.9739428;-4.785904;-5.6588655;1.7089634;IRRE
dataset without the marginal outliers a large majority of the samples are;5.418164;0.4958537;0.22879615;0.5638675;-0.36204088;1.2066718;IRRE
compacted to a specific range 0 10 for the median income and 0 6 for;2.0756562;1.9103354;1.3937237;-1.9598299;0.093958475;-0.25675246;CODE
the average house occupancy note that there are some marginal outliers some;2.4879255;0.16457313;0.707975;1.3128992;-0.80076647;0.5088202;TASK
blocks have average occupancy of more than 1200 therefore a specific;1.5701215;2.2099798;0.4652834;-0.8925262;-0.30640176;-1.0439919;CODE
pre processing can be very beneficial depending of the application in the;-0.22172575;-3.361808;1.3489207;4.596848;1.9293423;2.7028868;CODE
following we present some insights and behaviors of those pre processing;0.2380121;-2.9184911;2.3337443;2.7943823;0.6165018;0.65443134;-
methods in the presence of marginal outliers;6.12838;-0.50629073;0.0458161;2.768888;0.72246236;2.4780788;CODE
plot all scaling standard scaler section;1.6600857;0.27181235;3.5804374;-4.8662834;-5.4674354;5.088969;-
standardscaler;-1.4714613;-0.61137325;1.1097603;0.82475424;-0.073882304;0.61834717;-
class sklearn preprocessing standardscaler removes the mean and scales;1.9452124;-1.2823439;-6.013013;0.9617235;-4.4833026;2.8984885;IRRE
the data to unit variance the scaling shrinks the range of the feature;5.205167;-0.9299136;-0.6223183;-0.8871698;-4.6014366;5.4109282;TASK
values as shown in the left figure below;1.117292;1.4606743;5.297775;-6.469604;-0.40780196;-2.4628208;IRRE
however the outliers have an influence when computing the empirical mean and;4.71315;-0.111088865;0.08090114;1.2499747;-2.9722087;0.6410359;-
standard deviation note in particular that because the outliers on each;3.769994;1.5717088;0.33843192;-1.646275;-0.92512536;-0.9764685;TASK
feature have different magnitudes the spread of the transformed data on;5.0655317;-0.9236371;0.30633444;-1.8437831;-3.5642345;4.015101;CODE
each feature is very different most of the data lie in the 2 4 range for;3.7406604;-0.4826499;-0.53109056;-2.413304;1.1942959;1.0113913;CODE
the transformed median income feature while the same data is squeezed in the;2.816544;-1.0500324;0.869922;0.20313406;-2.3114085;3.9244394;CODE
smaller 0 2 0 2 range for the transformed average house occupancy;2.6785362;1.7499187;0.30403063;-2.5823874;-1.8961449;1.747589;CODE
class sklearn preprocessing standardscaler therefore cannot guarantee;0.6642119;-2.0328643;-8.279826;2.0241826;-2.7601483;0.19890493;CODE
balanced feature scales in the;5.7038374;-3.3302112;1.771731;0.1707184;0.95903754;1.619343;TASK
presence of outliers;5.554042;1.6967599;1.0796725;1.911348;-0.5183614;-0.13291419;-
plot all scaling minmax scaler section;2.464955;-0.07043495;3.533357;-4.9047112;-4.904358;4.77133;-
minmaxscaler;3.8535051;-0.6861173;1.0675157;-2.8157873;-0.86644346;2.8808646;-
class sklearn preprocessing minmaxscaler rescales the data set such that;5.374044;-2.362926;-4.5205154;-1.812415;-3.1328228;4.3413925;IRRE
all feature values are in;-0.9650836;0.9948115;-1.5202361;-0.77435863;0.38065282;-1.947313;IRRE
the range 0 1 as shown in the right panel below however this scaling;-0.4983466;2.378086;1.223905;-5.8989105;-5.6912103;3.0376844;CODE
compresses all inliers into the narrow range 0 0 005 for the transformed;4.441681;1.4034407;-2.6062164;-3.2767868;-4.051316;2.427034;CODE
average house occupancy;0.75077444;0.9117008;1.323121;-0.3577037;-1.0591278;0.41617182;-
both class sklearn preprocessing standardscaler and;1.3761432;-4.0971017;-5.898548;1.2875274;-1.2558889;0.24851893;IRRE
class sklearn preprocessing minmaxscaler are very sensitive to the;3.572303;-2.2086809;-7.4514933;-0.69591016;-4.452379;2.2100224;IRRE
presence of outliers;5.554042;1.6967599;1.0796725;1.911348;-0.5183614;-0.13291419;-
plot all scaling max abs scaler section;2.1313214;1.0860254;3.0980973;-4.1767745;-4.9013042;3.7608511;-
maxabsscaler;-1.039501;0.34201375;3.5684302;-0.3151043;-0.6038355;0.11335118;-
class sklearn preprocessing maxabsscaler is similar to;3.5887408;-3.6397333;-4.235652;0.37553602;-1.4328396;1.6766541;IRRE
class sklearn preprocessing minmaxscaler except that the;4.0957212;-2.7281709;-5.0673075;-1.5223416;-2.0692644;1.984464;CODE
values are mapped across several ranges depending on whether negative;4.568121;5.3067822;0.9644385;-3.9530492;0.34727228;-1.0184637;IRRE
or positive values are present if only positive values are present the;0.89582515;5.213094;0.66294104;-1.7068456;2.230246;-3.7331789;IRRE
range is 0 1 if only negative values are present the range is 1 0;0.95405775;5.786629;0.36991563;-5.5107794;-1.8110862;-4.3139887;IRRE
if both negative and positive values are present the range is 1 1;0.27392858;4.6394935;1.0176126;-4.4943337;-0.4243596;-5.256581;IRRE
on positive only data both class sklearn preprocessing minmaxscaler;5.170063;-0.32405594;-5.2413826;-1.0040823;-1.0727786;1.6256992;IRRE
and class sklearn preprocessing maxabsscaler behave similarly;2.9679856;-2.4927187;-5.44131;1.4545304;-1.7081578;2.3941612;IRRE
class sklearn preprocessing maxabsscaler therefore also suffers from;2.869149;-1.9960666;-6.4839845;1.4201872;-3.3520317;1.1119372;CODE
the presence of large outliers;5.462159;-1.226699;1.6067015;3.045236;-0.6524196;0.12302998;-
plot all scaling robust scaler section;3.112674;-0.10628285;2.3534682;-3.5016117;-5.75249;5.3963103;-
robustscaler;4.213498;-1.9946779;0.30809596;-2.2292461;-3.8743494;4.1401467;-
unlike the previous scalers the centering and scaling statistics of;4.1300144;-1.6205143;3.0300317;-1.7953807;-3.945893;4.350882;-
class sklearn preprocessing robustscaler;3.646206;-4.3918314;-5.7228208;-1.1177137;-4.100452;2.8536916;IRRE
are based on percentiles and are therefore not influenced by a small;3.9889877;0.45058984;0.5473131;0.16539225;-1.385862;1.3307395;CODE
number of very large marginal outliers consequently the resulting range of;3.6020777;2.1640873;-0.37606803;-0.3215211;-2.461442;1.1103567;IRRE
the transformed feature values is larger than for the previous scalers and;3.2029974;-0.11068174;-2.0829017;-2.7711864;-5.3797417;4.955324;IRRE
more importantly are approximately similar for both features most of the;1.9640875;-4.653856;2.4807198;0.31011525;2.337241;2.6205535;CODE
transformed values lie in a 2 3 range as seen in the zoomed in figure;0.32334757;2.2902427;1.7418886;-6.1736226;-5.937173;2.8339722;IRRE
note that the outliers themselves are still present in the transformed data;4.636327;-0.024616895;-0.935989;-0.20361808;-3.179577;3.2773023;TASK
if a separate outlier clipping is desirable a non linear transformation is;3.595158;1.3927732;-1.1531414;-0.4884838;-2.461817;5.3990235;CODE
required see below;-3.0196154;-0.44989595;4.9678693;-3.1264753;2.8614995;-2.8407094;CODE
plot all scaling power transformer section;1.5504435;-0.6181378;4.109459;-4.7362437;-4.323984;4.1745543;CODE
powertransformer;-2.6116138;-2.3605094;1.8584335;-1.7908931;0.9483647;1.8247405;CODE
class sklearn preprocessing powertransformer applies a power;-0.4861441;-2.991762;-5.910221;0.07993251;-1.6201614;1.2316375;CODE
transformation to each feature to make the data more gaussian like in order;7.309488;-1.1977761;2.1895387;-4.513227;0.11484328;5.0391126;TASK
to stabilize variance and minimize skewness currently the yeo johnson;2.4639924;-2.5658278;0.8764799;2.636848;0.24528608;3.918972;CODE
and box cox transforms are supported and the optimal;2.1511216;-3.1877334;-1.077643;-1.1757752;1.5802479;5.7296834;CODE
scaling factor is determined via maximum likelihood estimation in both;3.657076;0.46479592;-1.0650209;-0.6341289;-3.2594151;6.797563;-
methods by default class sklearn preprocessing powertransformer applies;-0.51237226;-3.9008791;-6.6320534;2.2389565;-1.8636794;2.2200117;CODE
zero mean unit variance normalization note that;1.6050034;0.71741897;-2.220203;-2.0166588;-2.4560845;4.3622403;TASK
box cox can only be applied to strictly positive data income and average;-0.3813551;1.8124701;-3.614654;-0.71858484;-0.80465436;1.4049187;-
house occupancy happen to be strictly positive but if negative values are;0.3056985;4.777804;-0.70230675;-0.86483127;-0.23393098;-1.5595752;IRRE
present the yeo johnson transformed is preferred;-1.714068;-0.7715486;2.336071;1.9106989;1.2370868;3.7649362;CODE
plot all scaling quantile transformer section;2.4062076;-0.2702591;3.1009188;-4.998505;-5.506812;4.1034174;CODE
quantiletransformer uniform output;1.9685433;2.9544113;-0.92007524;-3.6976428;-1.6340292;0.48215404;CODE
class sklearn preprocessing quantiletransformer applies a non linear;2.3903744;-1.7236075;-6.0442314;-1.0983851;-4.185138;2.1737604;CODE
transformation such that the;-1.3739053;-0.000162681;5.3321996;-2.0339594;-0.05476543;0.85548145;CODE
probability density function of each feature will be mapped to a uniform;4.0015774;-1.469404;1.508799;-2.3774867;1.05335;3.419978;CODE
or gaussian distribution in this case all the data including outliers;6.6974716;0.10209874;2.177847;-0.6828211;0.100305595;1.9102713;CODE
will be mapped to a uniform distribution with the range 0 1 making;1.0830278;1.9130696;2.2041473;-2.4998052;0.8448428;0.29268694;META
outliers indistinguishable from inliers;5.148095;2.0521917;-0.8717281;-0.42711323;-0.54453653;0.020052865;CODE
class sklearn preprocessing robustscaler and;3.7917702;-4.491464;-5.7152195;-0.8359598;-3.8690655;2.6273832;IRRE
class sklearn preprocessing quantiletransformer are robust to outliers in;5.3383293;-3.107516;-4.8685465;0.6301557;-3.3285892;1.3307272;CODE
the sense that adding or removing outliers in the training set will yield;5.1711316;-2.0056865;-0.8736782;4.6210656;0.9326975;1.9719769;IRRE
approximately the same transformation but contrary to;1.1418617;2.61887;2.3497403;-1.6212462;-2.0345595;3.3033774;META
class sklearn preprocessing robustscaler;3.646206;-4.3918314;-5.7228208;-1.1177137;-4.100452;2.8536916;IRRE
class sklearn preprocessing quantiletransformer will also automatically;1.3408237;-2.8874562;-5.2528667;0.43411356;-2.0458956;1.7893366;CODE
collapse any outlier by setting them to the a priori defined range boundaries;6.0609436;2.9480073;0.1019878;-0.9990254;-0.578809;2.967275;IRRE
0 and 1 this can result in saturation artifacts for extreme values;1.1618668;2.9980567;-2.6908538;-3.0104349;-2.8274438;-0.18865447;IRRE
quantiletransformer gaussian output;2.4423666;1.1686529;-1.2035118;-3.4129338;-3.0369596;2.4193947;CODE
to map to a gaussian distribution set the parameter;2.388354;0.7690405;1.3335793;-2.528729;0.11994902;4.487165;IRRE
output distribution normal;0.45054758;1.4178627;1.9571652;-3.1158323;-1.7142968;-1.2040539;IRRE
plot all scaling normalizer section;2.6183848;-0.5981707;3.1711795;-4.601124;-4.6258535;6.092095;-
normalizer;0.41277078;-2.1050944;3.1331322;-0.22302496;1.5787536;4.166338;-
the class sklearn preprocessing normalizer rescales the vector for each;4.0482664;-4.0428777;-4.825782;-2.9313765;-2.9484055;5.000179;CODE
sample to have unit norm;4.3132997;2.2789416;1.8941401;-2.1221015;0.87531835;0.30667603;CODE
independently of the distribution of the samples it can be seen on both;3.1631846;1.6689065;2.9105353;-0.009745684;2.7777884;1.9338559;META
figures below where all samples are mapped onto the unit circle in our;4.411601;-1.0112851;6.050565;-4.5777435;-0.4435375;1.3246471;CODE
example the two selected features have only positive values therefore the;1.6027381;2.6181028;0.5983639;-2.8501549;1.5999999;-2.571105;CODE
transformed data only lie in the positive quadrant this would not be the;1.1776235;2.599889;0.22140092;-5.82602;-5.0476036;1.6994975;CODE
case if some original features had a mix of positive and negative values;3.0486224;2.107457;-0.16330749;-1.4144036;1.8488431;0.014720693;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
construct the dataset;6.3169947;-3.2909539;2.044399;-2.0982502;4.5225635;-2.4439666;CODE
transform the dataset with kbinsdiscretizer;5.0977097;-1.7270104;-2.0779178;-4.222613;1.9572296;2.7783227;IRRE
predict with original dataset;5.382649;-1.742798;1.3632824;2.10646;-0.4238117;-0.48714435;IRRE
predict with transformed dataset;5.1967826;-1.6905298;0.7925176;-0.90775365;-1.7015393;2.1810555;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
h 0 02 step size in the mesh;-0.2500239;1.8169311;-0.86498314;-4.0664797;-2.629466;0.98154175;CODE
list of estimator param grid where param grid is used in gridsearchcv;3.2849834;-1.2362064;-1.6463274;-1.4270544;-1.3487825;2.462297;-
the parameter spaces in this example are limited to a narrow band to reduce;2.1591973;2.4242637;-0.3619645;-2.133274;0.05695126;3.74987;CODE
its runtime in a real use case a broader search space for the algorithms;1.579971;-4.7576127;0.26040673;2.4533875;2.7764814;0.4094463;CODE
should be used;-3.4907978;-0.9384182;4.4703255;4.197145;0.636036;-0.7073064;-
cm bright listedcolormap b30065 178000;-3.711068;-1.4424822;-0.38774225;-2.9700909;0.6458503;0.2658366;-
iterate over datasets;6.4263773;-1.802763;1.7486569;-0.48532277;1.8628672;-2.1361396;IRRE
split into training and test part;3.705093;-0.5595804;2.1801941;4.682013;4.0611243;-3.3438048;IRRE
create the grid for background colors;-0.5741313;-0.82189953;5.040742;-4.457917;0.49795485;1.8570267;IRRE
plot the dataset first;4.2835755;-0.9787889;5.573654;-4.1852655;-3.5100272;-0.3613919;IRRE
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
and testing points;1.733721;-0.19040988;2.699719;3.694981;0.97700197;-3.6819525;IRRE
iterate over classifiers;5.9412785;-3.1765063;0.2761596;0.36291677;4.695798;-2.4316916;IRRE
plot the decision boundary for that we will assign a color to each;2.4560258;-1.6418927;5.445053;-2.621385;0.95969707;-0.08623329;IRRE
point in the mesh x min x max y min y max;1.1828301;1.5850599;2.92813;-5.410248;-2.2440908;1.8685607;CODE
put the result into a color plot;1.4292959;0.4262304;5.77492;-3.760507;-3.6140656;-2.4272733;IRRE
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
and testing points;1.733721;-0.19040988;2.699719;3.694981;0.97700197;-3.6819525;IRRE
add suptitles above the figure;-2.367318;0.8376972;5.521106;-1.812723;-2.8180783;2.681481;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
construct the datasets;6.839055;-4.200832;1.9265655;-1.7168479;4.8106523;-2.2709458;CODE
transform the dataset with kbinsdiscretizer;5.0977097;-1.7270104;-2.0779178;-4.222613;1.9572296;2.7783227;IRRE
horizontal stripes;-1.5702397;1.419857;5.1996937;-5.3883924;0.7399417;-2.014476;-
vertical stripes;-1.39816;0.42397693;5.1507554;-4.6498766;1.1019142;-1.6926606;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
n quantiles is set to the training set size rather than the default value;1.8312453;1.4105833;-2.2043068;-1.5878346;-2.698474;2.235681;IRRE
to avoid a warning being raised by this example;-2.3406985;3.1141293;0.21583453;5.690741;0.83464444;-2.440937;CODE
lognormal distribution;-0.7784991;-0.24065031;0.8867054;-1.1909664;-0.8256797;0.46182436;META
chi squared distribution;-1.2017245;0.35104632;2.5367792;-2.2311413;-1.6138741;-2.796318;META
weibull distribution;-1.3313508;-1.0750353;1.512588;-1.9916347;0.03745609;-1.1315571;META
gaussian distribution;0.040972736;-0.4796167;2.9712083;-2.8783927;-1.378404;-0.5236629;META
uniform distribution;-0.91370636;1.0833548;4.89477;-2.0308259;-0.29121903;-3.010795;META
bimodal distribution;0.67483395;0.4772485;3.0384402;-2.2137878;0.13453111;0.90591216;META
create plots;0.5480987;-2.3963354;7.2060604;-5.3621335;-4.3458843;0.21216081;IRRE
colors d81b60 0188ff ffc107 b7a2ff 000000 2ec5ac;-3.1000774;-0.89456;-0.20957482;-5.5195627;2.293716;-2.3751242;-
perform power transforms and quantile transform;1.1541368;0.34485546;1.675099;-3.285775;-1.7252922;1.6994404;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load and prepare data;2.5494869;0.66157496;3.472986;1.1374639;2.4774883;-1.0889354;CODE
the dataset used is the ref wine dataset available at uci this dataset has;2.5177891;-5.585508;-0.10819215;0.09798116;2.1213374;-1.6633829;IRRE
continuous features that are heterogeneous in scale due to differing;5.170152;-1.701834;1.3185328;-2.244384;1.6717277;4.370319;TASK
properties that they measure e g alcohol content and malic acid;0.833502;-0.77485174;0.63425016;1.0295243;1.9350168;-2.0395572;-
neighbors scaling;6.426419;-1.6725115;2.706202;-3.2637186;-1.0670507;3.4637542;-
effect of rescaling on a k neighbors models;6.3178077;-2.6217597;1.193858;0.77498853;-2.0478067;5.0091147;-
for the sake of visualizing the decision boundary of a;1.7325834;-2.2780573;6.7100897;0.68624824;3.102631;0.080186635;CODE
class sklearn neighbors kneighborsclassifier in this section we select a;3.7674348;-4.4987254;-2.0710528;-2.5414336;2.8359487;-1.6885136;CODE
subset of 2 features that have values with different orders of magnitude;6.455023;1.1430483;1.259439;-3.8133903;2.00831;-0.24507333;IRRE
keep in mind that using a subset of the features to train the model may likely;4.9743004;-4.022717;1.7583281;4.1382694;4.8692393;2.181262;TASK
leave out feature with high predictive impact resulting in a decision;2.789745;-1.1384398;0.20888808;6.0113726;1.2272208;3.421112;TASK
boundary that is much worse in comparison to a model trained on the full set;4.004632;0.24017301;1.7857155;4.1993766;0.94754463;2.244917;IRRE
of features;2.4325182;-6.1336236;3.7596862;1.1239958;4.4028053;-0.6257595;TASK
here the decision boundary shows that fitting scaled or non scaled data lead;6.1372213;-1.2106712;-0.20303959;-0.070422366;-1.2248652;1.8220623;CODE
to completely different models the reason is that the variable proline has;-1.1364772;0.16642335;-1.453096;2.085681;-0.4363883;0.5501376;CODE
values which vary between 0 and 1 000 whereas the variable hue varies;2.5856092;2.3873844;0.8608803;-4.0283694;-2.8763552;-2.4363794;IRRE
between 1 and 10 because of this distances between samples are mostly;6.198661;1.578896;2.1761012;-1.7882068;-0.62905383;-1.7207175;CODE
impacted by differences in values of proline while values of the hue will;0.8949197;1.9555311;0.18476394;-0.5354944;-2.6852138;-0.4232162;IRRE
be comparatively ignored if one uses;1.1151942;2.2926753;0.22202191;5.7416234;0.58615583;1.5914412;-
class sklearn preprocessing standardscaler to normalize this database;3.071073;-1.9499369;-5.0568233;-0.92795616;0.32743895;0.8463533;CODE
both scaled values lay approximately between 3 and 3 and the neighbors;4.565428;2.385517;2.005533;-6.2780294;-3.1451058;1.6584302;IRRE
structure will be impacted more or less equivalently by both variables;0.23160979;1.7324781;1.2905241;0.9955378;2.6572235;2.4319606;CODE
effect of rescaling on a pca dimensional reduction;5.75509;-1.2934511;-0.36212832;-2.6914988;-1.0385245;7.1549735;-
dimensional reduction using class sklearn decomposition pca consists of;4.8755846;-4.812862;-4.2930155;-3.194892;1.2065835;2.4844341;IRRE
finding the features that maximize the variance if one feature varies more;5.3666563;-0.98923105;1.7017719;0.1428271;1.0201243;2.3069785;TASK
than the others only because of their respective scales;3.1181655;0.61292475;3.675823;-0.43313023;-0.4981956;-0.48766;-
class sklearn decomposition pca would determine that such feature;5.1038537;-4.3606296;-4.0065527;-1.6456528;1.649905;2.0256486;TASK
dominates the direction of the principal components;2.968898;-2.087014;0.85998017;-2.7637987;0.5338767;6.0284553;IRRE
we can inspect the first principal components using all the original features;0.53102714;-3.4984834;0.38236517;0.17782632;3.360719;2.4612305;TASK
indeed we find that the proline feature dominates the direction of the first;-0.011027874;-1.5725622;1.7738057;-1.5914028;-1.9230307;3.3113708;TASK
principal component without scaling being about two orders of magnitude above;4.319368;0.9357336;-0.7920487;-4.3932967;-1.5193403;6.980413;-
the other features this is contrasted when observing the first principal;0.5010936;-1.6028483;3.0468833;1.2193745;1.4184608;2.2265923;TASK
component for the scaled version of the data where the orders of magnitude;5.6264467;-0.5832098;1.6798037;-3.6361213;-0.49110362;4.3933253;META
are roughly the same across all the features;2.935683;-4.878486;1.9625665;-0.30009538;3.1785185;1.631916;TASK
we can visualize the distribution of the principal components in both cases;4.3452377;-4.0107255;3.6676998;-2.5344138;0.77410734;4.324371;META
from the plot above we observe that scaling the features before reducing the;3.9645221;-2.3513317;2.1075714;-1.3317717;-3.9966211;5.850243;CODE
dimensionality results in components with the same order of magnitude in this;3.8353279;0.30654255;-0.4399952;-6.4984365;-0.379456;2.5613797;CODE
case it also improves the separability of the classes indeed in the next;-1.4234582;-2.3918843;-1.6050171;4.7373614;6.6655602;3.8203201;CODE
section we confirm that a better separability has a good repercussion on the;-2.1890774;-1.4276357;0.5240204;4.4844294;4.413577;3.9619937;-
overall model s performance;4.40629;-3.7083027;2.0465977;4.5291924;1.7733955;0.27938306;CODE
effect of rescaling on model s performance;4.875061;-0.530042;2.540107;3.4307237;-1.5096506;4.964664;CODE
first we show how the optimal regularization of a;4.314648;-0.9332646;-0.6227451;-0.5092066;1.5756754;6.8744826;-
class sklearn linear model logisticregressioncv depends on the scaling or;3.9709103;-2.4695938;-4.736579;-0.8678798;-2.6883516;3.9622898;CODE
non scaling of the data;7.34726;1.7515535;2.2564118;-3.6018155;-2.5699337;3.3995628;-
the need for regularization is higher lower values of c for the data that;5.4764566;-0.28228465;-3.5226812;-2.0894766;-2.248432;3.232692;IRRE
was not scaled before applying pca we now evaluate the effect of scaling on;2.866955;0.15420757;-1.4746121;0.22840303;-2.9288635;4.773722;CODE
the accuracy and the mean log loss of the optimal models;5.1229315;-2.8780596;0.40764576;6.048836;-0.45861655;2.4093018;-
a clear difference in prediction accuracies is observed when the data is;6.2088075;-0.7294033;-0.39950123;6.387526;-0.31505316;0.49431026;-
scaled before class sklearn decomposition pca as it vastly outperforms;6.042128;-4.2893987;-6.3161554;-0.73502505;-2.1115966;3.9065242;CODE
the unscaled version this corresponds to the intuition obtained from the plot;0.9641832;-1.6284016;2.7472992;-1.9014622;-5.485182;3.731802;CODE
in the previous section where the components become linearly separable when;0.042214897;-0.84772724;-1.2191395;-3.1638389;1.4556346;5.3926873;CODE
scaling before using class sklearn decomposition pca;6.0594172;-3.8199582;-4.7199783;-2.0330596;-0.7475442;5.1260786;CODE
notice that in this case the models with scaled features perform better than;4.587432;-0.68651223;-2.695044;1.9816242;-2.7360907;3.7157063;CODE
the models with non scaled features because all the variables are expected to;3.715583;-0.039992113;-1.4441187;1.1335279;-1.8177538;3.4879441;TASK
be predictive and we rather avoid some of them being comparatively ignored;3.6491015;-1.2189193;0.29093325;6.6018205;0.41154924;1.3184086;CODE
if the variables in lower scales were not predictive one may experience a;3.209602;1.9159739;-0.75049275;4.021194;-1.2927151;0.6129454;IRRE
decrease of the performance after scaling the features noisy features would;5.651252;-2.0546591;-0.24340203;2.2001145;-1.0358557;5.9088635;TASK
contribute more to the prediction after scaling and therefore scaling would;4.6391697;-2.7920496;3.1896503;3.0185254;-2.4668558;5.7643332;META
increase overfitting;3.7656577;-1.0983586;0.7273508;2.909488;0.09775839;1.6200856;-
last but not least we observe that one achieves a lower log loss by means of;0.97982335;0.13377677;-0.04397721;3.4932375;-1.1396368;1.8421874;META
the scaling step;2.8288252;-2.3592591;3.7570117;-1.4320604;-2.4489334;3.5702639;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
loading data from openml;-3.0649357;-0.023433348;2.4347434;0.9537488;1.1505435;1.7816092;CODE
first we load the wine reviews dataset where the target is the points given;3.561732;-2.477115;0.8866059;0.079195425;0.4421754;-1.9008065;CODE
be a reviewer;-1.3198969;-1.9279381;2.3132637;5.553742;-0.6793013;-3.796084;-
for this example we use the following subset of numerical and categorical;3.5625067;1.3182822;1.3655552;-2.411762;5.2202153;-2.9726858;IRRE
features in the data the target are continuous values from 80 to 100;5.983878;1.1379266;2.052112;-1.2469913;-1.7034097;-0.6982415;IRRE
training and evaluating pipelines with different encoders;3.4799542;-3.6336584;-0.49605232;2.9819775;2.9416249;0.8889933;CODE
in this section we will evaluate pipelines with;-0.7677891;-2.820163;-0.38443846;3.623012;3.0000951;-0.6801;CODE
class sklearn ensemble histgradientboostingregressor with different encoding;3.368375;-4.519695;-7.019717;0.17085786;1.3955033;1.4111876;IRRE
strategies first we list out the encoders we will be using to preprocess;1.626357;-3.4213545;1.1407934;0.16723078;3.1946416;0.8978584;-
the categorical features;3.5362551;-5.8817763;3.3070595;-0.35734275;3.7737942;-1.6400975;TASK
next we evaluate the models using cross validation and record the results;4.5141354;-2.8109264;0.4621705;5.8529096;4.2592306;-2.2173524;IRRE
native categorical feature support;0.30662823;-7.248759;-1.112627;0.687864;2.9047892;0.40020004;TASK
in this section we build and evaluate a pipeline that uses native categorical;0.009674696;-5.2850757;-1.7280203;2.8186255;4.764868;-1.4961756;CODE
feature support in class sklearn ensemble histgradientboostingregressor;3.541911;-7.2421017;-6.374723;2.6191833;1.614836;1.7309996;TASK
which only supports up to 255 unique categories in our dataset the most of;3.3625395;-4.942553;-0.46031284;-0.6695333;5.0178843;-0.5710479;IRRE
the categorical features have more than 255 unique categories;1.2024442;-3.711128;-1.0916141;-2.197891;3.9103858;-2.0362606;TASK
to workaround the limitation above we group the categorical features into;2.3282082;-1.4488397;-1.3247504;0.88183194;3.1175334;2.5516827;TASK
low cardinality and high cardinality features the high cardinality features;3.6193292;-3.44068;-0.18022466;-0.97364396;3.9364884;1.2953081;TASK
will be target encoded and the low cardinality features will use the native;-0.41315305;-5.20416;-1.446793;0.9051348;3.5035384;2.6265054;TASK
categorical feature in gradient boosting;3.265075;-4.128945;-0.063637294;-1.1075703;2.9919906;0.28940198;TASK
the output of the of the preprocessor must be set to pandas so the;0.90938085;-1.3910898;-5.889043;-2.9192638;-5.6652203;-1.0096338;IRRE
gradient boosting model can detect the low cardinality features;5.6053953;-2.7638876;-1.4072791;0.6498745;3.982167;1.4388489;TASK
finally we evaluate the pipeline using cross validation and record the results;1.7762105;-1.0482396;-2.0388033;4.48253;2.719652;-1.1665123;CODE
plotting the results;2.7824183;0.35010907;8.162847;-4.9284263;-5.283578;-4.731769;IRRE
in this section we display the results by plotting the test and train scores;2.846122;-1.3739281;4.380067;-0.2153711;-0.7350879;-3.4531927;IRRE
when evaluating the predictive performance on the test set dropping the;4.775489;1.821362;-1.5384406;8.9332;0.16216028;-2.9346194;IRRE
categories perform the worst and the target encoders performs the best this;2.6588178;-2.8328211;0.5407615;1.9039317;2.2239928;1.140574;CODE
can be explained as follows;-1.4165056;-2.3291833;6.224141;0.37716594;0.06253985;-1.0025185;-
dropping the categorical features makes the pipeline less expressive and;0.2980414;-3.3216255;-1.748119;4.11495;2.0924888;2.1000538;TASK
underfitting as a result;4.1835027;0.5734926;-0.74036384;3.9882302;0.2047868;-2.190267;IRRE
due to the high cardinality and to reduce the training time the one hot;2.6161892;-2.0339215;0.55865103;3.6109877;1.8070436;0.7901999;-
encoding scheme uses max categories 20 which prevents the features from;-0.6970666;-1.5641952;-4.282391;-0.97787094;2.3527844;0.5895993;TASK
expanding too much which can result in underfitting;3.0800092;0.9585502;-0.59889907;2.1510487;-0.7465014;1.7037183;IRRE
if we had not set max categories 20 the one hot encoding scheme would have;0.17779478;-1.7558382;-1.7758218;-0.21105927;2.968026;0.7149905;IRRE
likely made the pipeline overfitting as the number of features explodes with rare;0.8807552;-3.0783749;-3.534942;3.8792598;-0.44182107;1.2450083;TASK
category occurrences that are correlated with the target by chance on the training;4.702104;-3.4096937;1.6802709;5.3210807;4.2212358;-0.9425642;-
set only;-2.1740625;1.9245272;5.6782303;1.1505806;0.5069111;-0.9418538;IRRE
the ordinal encoding imposes an arbitrary order to the features which are then;-0.2714179;-1.0182117;-0.48690498;-2.6257749;3.953057;1.9394248;TASK
treated as numerical values by the;4.112667;3.5497143;0.37352765;-4.37354;0.8849557;-3.4371905;IRRE
class sklearn ensemble histgradientboostingregressor since this;5.02334;-5.3780055;-4.738557;1.623554;1.5732691;0.9284383;CODE
model groups numerical features in 256 bins per feature many unrelated categories;4.230953;-3.6447499;-2.142156;-2.1847103;2.500963;-0.59725946;TASK
can be grouped together and as a result overall pipeline can underfit;1.0595769;-0.25166768;0.85704243;2.148242;4.196033;2.688218;IRRE
when using the target encoder the same binning happens but since the encoded;-2.0881715;2.4849281;-3.504022;-1.0112662;-1.2876868;2.3670974;META
values are statistically ordered by marginal association with the target variable;2.1973362;0.9129093;1.4549587;-1.3447136;1.6418176;0.50306755;IRRE
the binning use by the class sklearn ensemble histgradientboostingregressor;5.972599;-6.2582474;-4.8965526;0.3711072;1.2790143;0.35154295;IRRE
makes sense and leads to good results the combination of smoothed target;4.3927126;-0.88433194;1.457302;3.4610233;-0.9685059;4.7293663;IRRE
encoding and binning works as a good regularizing strategy against;2.8161647;-1.8029256;-1.5098113;-0.09248045;2.0101688;1.5982982;-
overfitting while not limiting the expressiveness of the pipeline too much;1.3627769;-1.4925549;-1.8229618;5.18545;1.6044937;2.1207461;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
create synthetic dataset;5.1566057;-4.37834;-0.038017713;-2.1208584;2.4361072;-1.26846;IRRE
for this example we build a dataset with three categorical features;3.057729;-3.6869175;1.8321289;-2.5835326;4.697455;-1.7377187;CODE
an informative feature with medium cardinality informative;3.6860054;-4.134844;2.4951413;0.045147214;5.202621;1.9144148;CODE
an uninformative feature with medium cardinality shuffled;3.9713523;-0.8176164;1.2181422;-2.86707;4.62659;1.6255244;TASK
an uninformative feature with high cardinality near unique;3.1730845;-0.6690472;-0.08280019;-1.291376;5.516754;1.0670192;CODE
first we generate the informative feature;2.4833028;-6.9399285;3.6840816;2.0655637;4.049788;-0.048459966;TASK
remove the linear relationship between y and the bin index by permuting the;2.5744984;3.4204648;0.882317;-6.554453;-0.9663285;-1.6225559;-
values of x informative;1.3722571;0.8170756;1.2916318;-1.6871731;2.0809395;-1.9052495;IRRE
the uninformative feature with medium cardinality is generated by permuting the;1.3575352;-1.2060952;0.5381355;-1.7269408;4.9079003;1.4139892;TASK
informative feature and removing the relationship with the target;1.7809051;-1.5294695;2.1627002;2.8606825;3.3224113;2.0956662;TASK
the uninformative feature with high cardinality is generated so that it is;1.1537163;-1.2489552;-1.4911608;0.59519553;3.6501102;1.1882943;TASK
independent of the target variable we will show that target encoding without;0.040700134;0.681902;-2.14872;0.20004411;1.7369063;0.7729633;CODE
term cross fitting will cause catastrophic overfitting for the downstream;2.1549623;-0.5251197;-3.4913318;2.8590822;-2.140103;3.6966166;CODE
regressor these high cardinality features are basically unique identifiers;3.9880488;-2.5081735;-3.1927752;-2.1172214;5.1312494;1.7048506;TASK
for samples which should generally be removed from machine learning datasets;5.6512;-2.9165246;-0.8814568;3.325725;2.119208;0.35837275;CODE
in this example we generate them to show how class targetencoder s default;-1.904507;-2.6454184;-3.0656612;0.6597755;2.8906412;1.886012;CODE
term cross fitting behavior mitigates the overfitting issue automatically;3.0981324;-1.1153295;-4.479227;4.080827;-1.4369736;4.3594313;IRRE
finally we assemble the dataset and perform a train test split;6.5384283;-2.0239384;0.035874598;2.6194186;3.5467334;-3.1036987;CODE
training a ridge regressor;4.3069515;-3.607069;-0.58659494;-1.1950377;-1.681176;4.4153786;-
in this section we train a ridge regressor on the dataset with and without;4.1819324;-3.9048889;-0.3099147;-1.4943466;0.0073713707;3.6408684;CODE
encoding and explore the influence of target encoder with and without the;2.4139545;-2.075032;1.036509;0.42165872;1.8225353;1.6974658;-
internal term cross fitting first we see the ridge model trained on the;2.6198528;-3.4251773;-0.884967;0.7194125;-1.9671261;4.512069;CODE
raw features will have low performance this is because we permuted the order;1.9117718;-2.4891145;-1.9415784;2.4838693;2.4562833;3.358043;CODE
of the informative feature meaning x informative is not informative when;-1.3383789;-2.4661644;-1.422561;2.3073027;1.8352348;1.694237;CODE
raw;-1.703097;-2.0485945;3.762058;1.1054344;0.5821826;-2.3169827;-
configure transformers to always output dataframes;1.8587515;0.5014361;-0.595342;-0.880037;-3.2465222;3.4464397;IRRE
next we create a pipeline with the target encoder and ridge model the pipeline;3.2989278;-2.8081267;-0.44505888;-1.341196;0.9724453;4.7716136;CODE
uses meth targetencoder fit transform which uses term cross fitting we;2.8297935;-1.4421731;-2.474007;-1.6845812;-1.2769932;3.555453;CODE
see that the model fits the data well and generalizes to the test set;6.5484996;1.3180269;-0.39445168;4.519945;2.0147822;-1.6523473;IRRE
the coefficients of the linear model shows that most of the weight is on the;3.3214872;0.4368516;1.1358576;-0.2937272;-2.0606363;2.2288146;-
feature at column index 0 which is the informative feature;1.7596614;-0.99852073;-0.59313273;-3.1261878;2.1238587;-0.21245402;TASK
while meth targetencoder fit transform uses an internal;0.7607575;0.6965486;-3.4305644;-0.9438339;-3.4456122;4.8140655;CODE
term cross fitting scheme to learn encodings for the training set;5.18902;-5.110026;-1.6118952;-0.9111654;1.9483657;1.0194594;IRRE
meth targetencoder fit followed by meth targetencoder transform does not;0.5846289;1.2970238;-4.0107746;-1.3053266;-3.2721858;3.9310637;CODE
it uses the complete training set to learn encodings and to transform the;0.9829905;-7.492142;1.2664196;-0.3639986;1.6046016;-0.055455163;CODE
categorical features thus we can use meth targetencoder fit followed by;3.3650534;-3.192857;-1.2900324;0.3283512;2.6270106;1.6005747;TASK
meth targetencoder transform to disable the term cross fitting this;1.3811433;1.0304542;-3.3663056;-0.99415165;-2.1227567;4.4321365;CODE
encoding is then passed to the ridge model;1.4805988;-2.2308967;-3.290044;-2.7568066;-0.43389872;4.1470666;-
we evaluate the model that did not use term cross fitting when encoding and;3.2180245;-2.4713166;-2.8269193;2.0787477;0.9890328;0.89304805;IRRE
see that it overfits;-1.8991675;-0.3230088;2.1996832;2.321513;-1.5076782;0.16961418;-
the ridge model overfits because it assigns much more weight to the;2.2664752;-0.8782985;0.14739597;1.2715853;-2.1451755;4.104049;IRRE
uninformative extremely high cardinality near unique and medium;1.9550146;0.6608525;-0.64969283;-0.607907;2.9880884;1.015785;CODE
cardinality shuffled features than when the model used;4.140994;-0.7009019;-0.21471736;-0.7128934;3.5364344;0.79177004;TASK
term cross fitting to encode the features;5.600555;-4.107099;-0.41775936;-1.9307898;1.9713451;2.5291274;TASK
conclusion;-1.760038;1.090336;5.187227;3.9331748;0.70637256;-3.3991337;-
this example demonstrates the importance of class targetencoder s internal;0.21709546;-4.4490147;-2.1413033;2.1061325;3.0679982;2.9471467;CODE
term cross fitting it is important to use;2.2293398;-1.985796;1.3221812;0.34228092;1.7934812;3.757937;CODE
meth targetencoder fit transform to encode training data before passing it;4.231818;-0.47847375;-2.7142599;-0.3188405;-2.0997484;4.4513316;CODE
to a machine learning model when a class targetencoder is a part of a;2.9788837;-3.5184186;-0.27709776;3.9560118;5.0378823;1.603109;IRRE
class sklearn pipeline pipeline and the pipeline is fitted the pipeline;1.1421087;-2.7724907;-4.0879235;1.4924794;-1.5065563;1.3987662;CODE
will correctly call meth targetencoder fit transform and use;1.0895845;0.7348203;-2.787717;-1.2062432;-2.137264;3.6921062;IRRE
term cross fitting when encoding the training data;4.79924;-2.9223735;-1.7321037;1.0106183e-05;1.5157921;1.889014;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
new plotting api;-1.87957;-4.9298024;3.1338599;-2.8614554;-6.1289372;0.8727197;CODE
a new plotting api is available for creating visualizations this new api;-1.6860249;-6.512899;4.3250546;-3.5189104;-4.6522074;1.6051832;CODE
allows for quickly adjusting the visuals of a plot without involving any;-0.025402846;-3.5096622;4.70786;0.28091037;-4.7732134;3.5143428;CODE
recomputation it is also possible to add different plots to the same;-0.2607658;0.021869892;2.327018;-0.41398543;-2.2008517;4.1575003;TASK
figure the following example illustrates plot roc curve;2.8942363;-1.1363119;2.3031301;-4.4952774;-3.3282573;-3.079173;-
but other plots utilities are supported like;-2.664729;-4.689808;0.15040562;-1.5176448;-3.9165788;3.1357706;META
plot partial dependence;2.0734575;0.49115327;4.782565;-2.587458;-2.8453002;1.2143519;CODE
plot precision recall curve and;4.531436;-0.8562586;1.8526375;-0.956729;-3.9542983;-1.5196611;IRRE
plot confusion matrix read more about this new api in the;2.287049;-2.746919;1.2847332;-4.5898614;-3.7870376;0.25099212;CODE
ref user guide visualizations;-2.4264555;-5.3750153;5.57619;-0.5310726;-0.74232906;0.61668766;-
from sklearn metrics import plot roc curve;3.4022534;-5.5986648;-3.7165267;-3.017755;-4.8214355;-1.0460275;CODE
plot roc curve has been removed in version 1 2 from 1 2 use roccurvedisplay instead;-0.8492971;-2.0169172;-3.000757;-1.2506765;-4.1469574;1.4653679;OUTD
svc disp plot roc curve svc x test y test;2.8110368;-0.9059934;-1.4713669;-2.8524375;-2.6446836;-1.7447636;IRRE
rfc disp plot roc curve rfc x test y test ax svc disp ax;1.5526571;-0.105088316;-2.1986434;-3.472591;-1.1559272;-2.1941814;IRRE
stacking classifier and regressor;3.64081;-1.7207453;-0.513633;-1.3454789;2.153086;1.9606342;IRRE
class ensemble stackingclassifier and;3.989889;-4.2191043;-0.47464404;2.305029;4.7290382;0.4603822;IRRE
class ensemble stackingregressor;3.2357318;-2.4052393;-1.5125381;2.531845;3.1886518;1.8570249;IRRE
allow you to have a stack of estimators with a final classifier or;4.4611263;-1.7960966;0.27645433;4.39045;3.697957;4.1018796;CODE
a regressor;1.0213262;0.35677278;4.1405363;-0.87564814;-0.7200176;-0.10243194;-
stacked generalization consists in stacking the output of individual;5.048767;-2.7963402;0.48564014;-0.6030844;3.7905571;2.9411201;IRRE
estimators and use a classifier to compute the final prediction stacking;5.206399;-2.6044886;1.4698293;3.7346745;2.721276;2.0641305;CODE
allows to use the strength of each individual estimator by using their output;4.910843;-1.0648814;1.2136613;2.1108212;1.2186497;3.1622727;IRRE
as input of a final estimator;1.631374;1.4990416;2.0034814;3.3730721;-0.84555835;2.9177618;CODE
base estimators are fitted on the full x while;1.489642;3.3175728;-1.3843231;-0.38100564;-3.7130313;5.0986285;CODE
the final estimator is trained using cross validated predictions of the;3.6238782;-2.3687437;0.38809228;6.2541747;1.1565465;1.0998722;CODE
base estimators using cross val predict;3.8050497;-1.174912;-1.526331;1.1685;-0.7872944;2.0806072;-
read more in the ref user guide stacking;-3.891229;-2.7616324;2.4924953;2.0584912;1.7840356;0.9824592;CODE
permutation based feature importance;5.056896;-3.5780208;2.6709251;-1.1740036;4.4508767;1.6368932;CODE
the func inspection permutation importance can be used to get an;1.414891;0.67709666;0.60949826;2.4713953;6.350458;-1.7868989;CODE
estimate of the importance of each feature for any fitted estimator;4.897833;-1.9579144;1.1053057;1.9372824;0.242044;5.6345496;CODE
labels argument in boxplot is deprecated in matplotlib 3 9 and has been;-2.2487037;-0.7590558;-3.5544822;-3.0256171;-4.407386;0.6941293;OUTD
renamed to tick labels the following code handles this but as a;-3.1722143;0.95861197;2.8837538;-2.513558;1.2847569;0.48509753;META
scikit learn user you probably can write simpler code by using labels;2.3567867;-8.91591;-0.8481662;-3.2366686;-0.65982467;-4.4228673;TASK
matplotlib 3 9 or tick labels matplotlib 3 9;0.6825012;-3.1928797;0.9291529;-6.4008718;-2.6638677;-1.0403394;-
native support for missing values for gradient boosting;3.929578;-3.2109587;-3.1584604;0.6645291;0.690482;2.1237226;IRRE
the class ensemble histgradientboostingclassifier;4.8620934;-5.9579515;-2.0345285;2.149245;4.6834497;1.4866717;IRRE
and class ensemble histgradientboostingregressor now have native;1.3592939;-6.7522807;-4.770276;4.4013386;3.0687165;3.4095106;IRRE
support for missing values nans this means that there is no need for;2.2711768;3.086302;-3.038885;-2.026773;-2.460261;-2.7829804;CODE
imputing data when training or predicting;4.9240117;-0.23425804;0.7232418;4.8278956;1.4509971;0.30550602;-
precomputed sparse nearest neighbors graph;5.5239916;-2.0837586;0.26948684;-4.2191668;-0.4387733;2.104709;IRRE
most estimators based on nearest neighbors graphs now accept precomputed;5.3157854;-1.7063446;-1.3328512;0.67876303;-1.3486247;4.7063336;IRRE
sparse graphs as input to reuse the same graph for multiple estimator fits;6.597852;-0.365324;-0.2946064;-0.95290595;-0.309227;7.0093665;IRRE
to use this feature in a pipeline one can use the memory parameter along;-1.5322194;0.7692136;-1.4102283;2.3057609;2.5920718;3.764238;IRRE
with one of the two new transformers;-3.3154366;-0.76991016;4.665583;0.09642261;0.26750207;0.3388571;CODE
class neighbors kneighborstransformer and;2.9892015;-3.296912;-1.8237787;-2.3563433;3.1205425;0.5470842;IRRE
class neighbors radiusneighborstransformer the precomputation;2.0369575;-3.7135537;-0.68759024;-1.7978662;0.90199715;1.2561485;CODE
can also be performed by custom estimators to use alternative;3.6738398;1.0159097;-0.14802584;4.553199;1.2826031;4.934508;CODE
implementations such as approximate nearest neighbors methods;6.5886316;-3.9893937;-0.527334;-1.1328547;0.05897716;1.7673335;TASK
see more details in the ref user guide neighbors transformer;0.7424708;-1.7791114;0.6789096;-2.647201;-0.4179128;3.265047;CODE
we can decrease the number of neighbors and the graph will not be;1.9962764;0.48941436;3.5114717;-1.8995115;-1.8256986;1.0144821;IRRE
recomputed;-3.6184518;-2.2671366;1.1505629;3.338152;0.035030875;-0.861418;-
knn based imputation;2.8050082;0.8322616;-1.2880388;0.27070117;2.6706688;-1.9435041;-
we now support imputation for completing missing values using k nearest;4.4371433;1.3394898;-1.6221889;0.19797742;1.2696708;-0.6027046;IRRE
neighbors;0.8530716;-2.17196;5.184574;-0.5413345;-0.057199594;-1.4358174;-
each sample s missing values are imputed using the mean value from;3.0456293;4.723798;-0.4778908;-0.764373;-1.7062593;-2.349321;IRRE
n neighbors nearest neighbors found in the training set two samples are;5.98335;-2.0106592;-1.2833968;-2.2336538;0.94618887;-0.90268636;IRRE
close if the features that neither is missing are close;0.46095446;1.8042579;0.931273;2.1212513;1.3811506;-0.6762825;CODE
by default a euclidean distance metric;1.8578343;-1.0599117;1.4912728;-1.7317342;-1.7017887;2.4077263;CODE
that supports missing values;0.7538482;3.0650856;-0.16415355;-0.93942916;2.4291613;-1.5246385;IRRE
func sklearn metrics pairwise nan euclidean distances is used to find the nearest;4.221787;-2.489203;-3.0901597;-3.5115147;-4.2952585;-0.4433604;OUTD
neighbors;0.8530716;-2.17196;5.184574;-0.5413345;-0.057199594;-1.4358174;-
read more in the ref user guide knnimpute;-3.000806;-4.3407936;0.075976364;1.1617178;1.1285744;-0.19059604;CODE
tree pruning;0.6649556;-1.1408331;3.0950577;-0.032769915;2.8949273;-1.6273515;CODE
it is now possible to prune most tree based estimators once the trees are;2.6779451;-2.4401543;-0.24955142;3.202498;1.5836213;4.308043;CODE
built the pruning is based on minimal cost complexity read more in the;2.0994802;-1.6222441;-0.1481247;1.0107166;3.0299022;1.1346964;CODE
ref user guide minimal cost complexity pruning for details;1.7742226;-2.1105964;0.06827461;0.105647236;3.9264505;0.23737188;CODE
retrieve dataframes from openml;-0.67305577;-1.588873;-0.14373511;-1.0596849;-1.0782984;0.2901621;CODE
func datasets fetch openml can now return pandas dataframe and thus;-0.66286623;-2.1111794;-3.8806264;0.6634386;-3.077629;0.14196034;IRRE
properly handle datasets with heterogeneous data;5.706703;-1.5735368;-1.2593075;0.046279687;4.155217;1.7989686;IRRE
checking scikit learn compatibility of an estimator;2.1261582;-5.635621;-7.8617783;3.8171782;-4.9809647;-1.3321077;-
developers can check the compatibility of their scikit learn compatible;-0.63054776;-11.5313;-5.9105177;2.8540301;-2.9823318;-4.508747;-
estimators using func utils estimator checks check estimator for;0.8002312;3.4941528;-4.842931;4.5989537;-3.2047358;-0.432741;CODE
instance the check estimator linearsvc passes;2.4207833;1.8794997;-3.6040812;1.9068627;-1.2217666;2.0487034;-
we now provide a pytest specific decorator which allows pytest;-3.6648192;-2.9190304;-1.0255052;1.0307646;0.34885773;3.3515341;IRRE
to run all checks independently and report the checks that are failing;-1.0963978;1.8937321;0.39511618;4.4513125;1.8757854;-3.3087535;CODE
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
this entry was slightly updated in version 0 24 where passing classes;-5.7340136;-1.8931634;-4.7552285;2.582747;2.7039707;0.7830384;CODE
isn t supported anymore pass instances instead;-5.9245577;0.6106829;-2.6588013;3.0760999;-0.89221954;1.8304149;OUTD
roc auc now supports multiclass classification;0.92424273;-5.8006654;-3.3689315;0.53121674;2.9383128;1.5168775;IRRE
the func sklearn metrics roc auc score function can also be used in multi class;3.8329742;-4.8786635;-3.5171506;-0.18448383;3.013582;-1.1180371;CODE
classification two averaging strategies are currently supported the;5.4401703;-3.42625;1.6125509;4.0589914;3.3756518;2.6434295;IRRE
one vs one algorithm computes the average of the pairwise roc auc scores and;4.6163187;-1.9365494;-2.023082;0.9833608;1.4272587;-1.4114298;IRRE
the one vs rest algorithm computes the average of the roc auc scores for each;3.663688;-2.8427489;-1.2313323;1.3104323;1.3501567;-1.6138409;CODE
class against all other classes in both cases the multiclass roc auc scores;2.5046399;-2.0483835;-3.0622902;1.27858;4.08722;-1.4713503;CODE
are computed from the probability estimates that a sample belongs to a;3.1000583;0.25108734;0.6849605;2.5103285;2.122153;1.640754;IRRE
particular class according to the model the ovo and ovr algorithms support;3.4825566;-2.97554;-1.5631562;-0.47985047;4.35319;2.6462722;CODE
weighting uniformly average macro and weighting by the prevalence;4.700648;0.6526029;1.0034035;1.9883891;0.9960751;1.3850777;CODE
average weighted;4.788817;1.5960845;3.6424491;0.086660534;-1.0451605;0.19548555;-
read more in the ref user guide roc metrics;3.038149;-4.605142;-2.2388318;1.2645437;1.2702854;-1.608344;CODE
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
generalized linear models and poisson loss for gradient boosting;5.4823637;-4.249727;0.37645873;1.3430594;1.6035907;4.2172637;CODE
long awaited generalized linear models with non normal loss functions are now;2.9055922;-3.6662364;-1.2299565;2.4502044;-0.9042888;4.264626;CODE
available in particular three new regressors were implemented;0.39302605;-2.8554533;-0.31851012;-1.9275368;1.5999961;2.8691146;TASK
class sklearn linear model poissonregressor;1.6839077;-2.4435327;-4.0449605;-0.25083047;-2.2689955;2.0370045;IRRE
class sklearn linear model gammaregressor and;0.76414883;-3.2775717;-4.3590064;-0.16291082;-2.762758;1.3522239;IRRE
class sklearn linear model tweedieregressor the poisson regressor can be;1.0731843;-2.3770921;-3.706455;-1.4936929;-2.0686116;3.2495742;IRRE
used to model positive integer counts or relative frequencies read more in;3.5339084;-0.11741937;1.2451762;-1.6021982;1.4618518;-2.4324622;CODE
the ref user guide generalized linear regression additionally;2.8570755;-5.3835387;-0.061258864;2.445489;-1.4552996;2.3729734;TASK
class sklearn ensemble histgradientboostingregressor supports a new;4.583763;-7.083938;-5.6686144;1.7241496;1.5647107;2.2046976;CODE
poisson loss as well;2.497535;0.20528665;2.9957488;3.2563143;-1.0830666;1.6962453;-
positive integer target correlated with x 5 with many zeros;1.9449401;3.6292129;-0.3480367;-3.0962152;-0.8531748;-0.24412127;CODE
rich visual representation of estimators;5.0089993;-4.2830515;3.8877249;-1.2273589;-1.9315283;4.2188783;-
estimators can now be visualized in notebooks by enabling the;1.8710423;-6.2811265;2.831936;0.91586655;-3.353319;3.3875694;TASK
display diagram option this is particularly useful to summarise the;-1.9561827;-2.5790753;7.881507;-3.464367;1.1211871;1.5002614;IRRE
structure of pipelines and other composite estimators with interactivity to;2.7777917;-0.92319983;-0.39469576;3.620265;0.64838606;5.349005;CODE
provide detail click on the example image below to expand pipeline;-2.6936734;-1.786669;2.6240437;-0.75123936;0.54811037;3.3818169;CODE
elements see ref visualizing composite estimators for how you can use;2.379056;-0.7337218;2.2773526;-0.12744415;-0.23085663;4.0943303;CODE
this feature;-1.3789893;-3.281656;5.231952;2.6757517;1.1352781;2.4339209;TASK
scalability and stability improvements to kmeans;3.2685373;-3.1537037;-0.4465949;-0.68426675;-1.2198851;3.4398859;TASK
the class sklearn cluster kmeans estimator was entirely re worked and it;3.1635072;-4.8535542;-4.627681;1.0398345;-2.9080145;2.679349;IRRE
is now significantly faster and more stable in addition the elkan algorithm;2.9814746;-3.6554039;-2.2661712;0.49465695;-0.0071162386;1.595739;TASK
is now compatible with sparse matrices the estimator uses openmp based;4.3172655;-2.0290039;-4.277918;-1.7048833;-2.9407384;5.86486;IRRE
parallelism instead of relying on joblib so the n jobs parameter has no;-1.2052176;-2.1658268;-1.9317003;1.1935909;-1.152637;1.8388635;IRRE
effect anymore for more details on how to control the number of threads;-1.3455393;-0.5472538;3.8002965;2.6108217;-0.62145144;2.4035149;CODE
please refer to our ref parallelism notes;-0.82712376;-2.382524;1.8314252;3.0466428;2.022394;2.530081;TASK
improvements to the histogram based gradient boosting estimators;5.5105386;-4.9331336;0.56502825;0.28287554;1.0874002;2.3484707;TASK
various improvements were made to;-2.6868274;-5.054548;2.7738914;4.1398687;0.5480694;1.3163823;TASK
class sklearn ensemble histgradientboostingclassifier and;4.3204203;-6.4502783;-5.168856;1.3829855;2.475075;0.6631377;IRRE
class sklearn ensemble histgradientboostingregressor on top of the;3.9527438;-5.1848326;-5.2793493;1.3645991;0.5784593;2.4532466;IRRE
poisson loss mentioned above these estimators now support ref sample;0.97920877;0.7185039;-1.336804;3.186996;-1.3754326;3.472541;-
weights sw hgbdt also an automatic early stopping criterion was added;0.804397;0.05877925;-3.3784282;4.488499;-0.37040254;2.7396824;TASK
early stopping is enabled by default when the number of samples exceeds 10k;1.4241579;2.4929025;-2.7579358;5.526069;-2.299328;2.0990577;CODE
finally users can now define ref monotonic constraints;-1.0114727;1.5984379;-1.2444712;1.8462507;2.8173566;3.3608682;CODE
monotonic cst gbdt to constrain the predictions based on the variations of;4.8495054;-1.0313373;-2.7964818;2.1205275;0.3366321;1.4058641;CODE
specific features in the following example we construct a target that is;0.87097144;-0.15871942;1.6457986;1.7478371;4.269763;-0.13036078;CODE
generally positively correlated with the first feature with some noise;3.6048124;-0.50047356;-0.96045923;1.26731;-0.18486914;2.5240974;TASK
applying monotoinc constraints allows the prediction to capture the global;3.4565098;-2.7499514;-0.33403206;3.4852376;0.56891894;3.5843937;CODE
effect of the first feature instead of fitting the noise for a usecase;1.8305178;-0.49170643;-0.9349082;3.3712034;1.2913767;3.8957093;CODE
example see ref sphx glr auto examples ensemble plot hgbt regression py;2.0396595;-4.6306567;-3.6624172;-1.5110188;-3.2486174;1.5300363;-
from sklearn inspection import plot partial dependence;2.8782823;-2.345886;-3.01211;-0.94296175;-4.7110863;0.2756191;CODE
plot partial dependence has been removed in version 1 2 from 1 2 use;-2.0793595;-0.06980898;-0.24327567;-0.7285366;-4.4965343;3.9249744;CODE
partialdependencedisplay instead;-5.298649;1.8338215;0.724024;3.2593112;1.6144311;3.456184;CODE
disp plot partial dependence;2.5326796;0.6407063;2.4470818;-2.4446068;-1.2727287;1.8730859;CODE
plot partial dependence;2.0734575;0.49115327;4.782565;-2.587458;-2.8453002;1.2143519;CODE
sample weight support for lasso and elasticnet;4.6159143;-3.9517982;-2.8191202;1.249321;-0.50614655;3.9855359;CODE
the two linear regressors class sklearn linear model lasso and;4.012601;-5.1327434;-3.1442416;0.1332083;-1.8199215;1.5828629;IRRE
class sklearn linear model elasticnet now support sample weights;3.349607;-4.831706;-5.2966886;1.5148588;-1.4056392;3.6005096;IRRE
ruff noqa cpy001 e501;-4.708646;0.40756392;-1.3329889;-4.0188212;0.8740261;-2.627956;-
successive halving estimators for tuning hyper parameters;5.266347;0.1706877;-2.352552;1.5184581;0.06794075;4.798224;IRRE
successive halving a state of the art method is now available to;1.669549;-0.64234877;1.0645835;3.3209314;2.1800432;1.7917014;CODE
explore the space of the parameters and identify their best combination;6.1716475;0.4219429;2.2897494;-1.5345252;3.7101357;-0.53700614;IRRE
class sklearn model selection halvinggridsearchcv and;4.940147;-3.151759;-5.4002843;1.1015531;-0.008238162;0.8800236;CODE
class sklearn model selection halvingrandomsearchcv can be;4.8093333;-3.3623111;-5.814192;1.7664822;0.63548577;0.4760062;IRRE
used as drop in replacement for;-3.700824;0.23909272;2.1235063;-0.08803195;1.4055719;-0.9366473;CODE
class sklearn model selection gridsearchcv and;3.8668756;-4.5050564;-5.1836176;0.24145155;-0.35608724;0.15634297;CODE
class sklearn model selection randomizedsearchcv;5.039283;-5.821034;-5.536437;2.4846253;0.81388414;0.608573;IRRE
successive halving is an iterative selection process illustrated in the;3.9194496;-0.2771509;3.0566468;1.465907;3.2813816;0.8487922;CODE
figure below the first iteration is run with a small amount of resources;0.98007643;1.7304741;4.1336117;0.55732465;-4.7441483;1.3469588;CODE
where the resource typically corresponds to the number of training samples;4.050373;-4.065779;1.6389468;2.0613682;4.092931;0.9316609;IRRE
but can also be an arbitrary integer parameter such as n estimators in a;2.314893;2.2290282;-1.4258126;-0.6058697;1.9893998;2.8924816;IRRE
random forest only a subset of the parameter candidates are selected for the;2.407242;-1.1625307;-3.677038;3.6083915;3.2332852;0.9522226;IRRE
next iteration which will be run with an increasing amount of allocated;1.0656102;1.776053;3.590235;1.1959127;1.2849839;-0.8283008;CODE
resources only a subset of candidates will last until the end of the;0.3809898;0.7649043;3.4612973;4.9714603;3.8451288;1.4477841;CODE
iteration process and the best parameter candidate is the one that has the;2.034395;0.80955046;2.11035;4.0703187;3.0554004;0.04606548;IRRE
highest score on the last iteration;3.1612413;1.1230779;2.0768223;1.591514;0.16024342;-4.5231104;-
read more in the ref user guide successive halving user guide note;-2.4298031;0.7440904;1.0433377;0.9522648;1.1810659;-0.10859917;CODE
the successive halving estimators are still term experimental;3.1362584;0.13240162;-0.7823793;4.5134625;-1.3509529;2.7944765;TASK
experimental;-0.59253085;-1.8307672;5.366724;4.942911;-1.8854616;-5.5418334;-
figure model selection images sphx glr plot successive halving iterations 001 png;2.0306268;0.47231194;0.47250527;-1.8961536;-3.864882;3.3024535;CODE
target model selection plot successive halving iterations html;3.5696156;0.24697618;2.918531;1.362361;-2.937312;2.9069953;CODE
align center;-0.9558346;1.6558096;5.799503;-3.1601973;-2.9029808;1.1326162;-
from sklearn experimental import enable halving search cv noqa f401;1.9050133;-1.1410071;-6.8692355;-0.5317155;-4.109496;-0.66295934;CODE
native support for categorical features in histgradientboosting estimators;4.318733;-5.471682;-1.6987418;1.5890975;2.4497738;3.0120344;TASK
class sklearn ensemble histgradientboostingclassifier and;4.3204203;-6.4502783;-5.168856;1.3829855;2.475075;0.6631377;IRRE
class sklearn ensemble histgradientboostingregressor now have native;1.9434457;-7.0593057;-6.9740295;3.0676024;0.33710906;1.916679;IRRE
support for categorical features they can consider splits on non ordered;2.0462594;-3.3036315;-0.3907433;-0.27895737;5.1802435;1.2906324;TASK
categorical data read more in the ref user guide;0.76092315;-2.7719133;0.40958166;0.3935729;2.662403;-2.031001;CODE
categorical support gbdt;-0.39342162;-3.262763;-3.024395;-1.4816481;3.7964437;-0.6432758;-
figure ensemble images sphx glr plot gradient boosting categorical 001 png;3.4069183;-3.8491395;-1.3144656;-1.9963733;-0.094253056;2.207183;-
target ensemble plot gradient boosting categorical html;3.9974065;-4.8674912;-0.15646127;0.15631907;0.58956444;1.8784949;-
align center;-0.9558346;1.6558096;5.799503;-3.1601973;-2.9029808;1.1326162;-
the plot shows that the new native support for categorical features leads to;-0.1716865;-7.6598997;-0.13599801;0.56638104;-1.0150111;0.4840531;CODE
fitting times that are comparable to models where the categories are treated;5.0180163;-1.410176;1.1484671;3.4793925;0.69036686;2.5106487;CODE
as ordered quantities i e simply ordinal encoded native support is also;-0.62194276;-0.5595999;-0.55909675;-4.810118;5.373439;-0.34222;-
more expressive than both one hot encoding and ordinal encoding however to;0.3284417;-1.3696154;-0.15552534;-1.3325907;3.1232522;0.69569254;CODE
use the new categorical features parameter it is still required to;-1.4686207;-0.1509545;-2.5392988;1.3842795;2.999047;2.2939634;TASK
preprocess the data within a pipeline as demonstrated in this ref example;0.8454146;-0.64098233;-0.13338012;1.3812687;1.6192621;1.2302072;CODE
sphx glr auto examples ensemble plot gradient boosting categorical py;3.3581948;-5.6361976;-3.7355583;-0.8025524;-1.2480977;2.036575;-
improved performances of histgradientboosting estimators;4.79737;-2.1274755;-0.6638735;2.329508;-0.50380194;4.364735;CODE
the memory footprint of class ensemble histgradientboostingregressor and;3.8388288;-5.1593943;-3.1046565;2.2579226;2.9987895;2.6266406;IRRE
class ensemble histgradientboostingclassifier has been significantly;4.1573567;-5.758041;-3.2810059;2.2845564;2.9895208;1.2596976;IRRE
improved during calls to fit in addition histogram initialization is now;2.0767124;-0.21273749;-0.3017932;0.44128653;-0.9485905;2.276465;IRRE
done in parallel which results in slight speed improvements;2.5282595;-0.9090913;2.309242;0.69361484;0.33627984;1.5233744;TASK
see more in the benchmark page;3.0162203;-4.069122;1.1424178;1.8988646;0.7325786;-0.19467156;CODE
https scikit learn org scikit learn benchmarks;3.3473399;-9.971329;-4.79464;1.5466622;-3.2945006;-3.8850112;CODE
new self training meta estimator;2.341155;-3.5657327;-0.50015277;4.9983563;-0.10184767;1.5958054;CODE
a new self training implementation based on yarowski s algorithm;4.2075243;-2.4425597;-0.020660242;0.052836183;0.99966896;0.8558503;CODE
https doi org 10 3115 981658 981684 can now be used with any;-5.1486473;-3.13144;-2.7035987;-1.0251355;0.53610975;0.23121281;CODE
classifier that implements term predict proba the sub classifier;3.7985706;-4.422941;-1.54697;2.9117594;3.9743059;0.19498403;IRRE
will behave as a;-2.3837535;-0.44766155;3.054292;3.5946364;1.9908147;-2.912125;-
semi supervised classifier allowing it to learn from unlabeled data;3.9889584;-3.4099352;-0.15076035;0.13294573;4.4915624;1.6780747;CODE
read more in the ref user guide self training;-1.046902;-5.222955;0.7930403;3.9078324;1.0969009;-0.67751753;CODE
new sequentialfeatureselector transformer;-2.06414;-1.0990154;-0.4964806;-0.44729215;2.035906;2.2468724;CODE
a new iterative transformer to select features is available;2.8045661;-2.974373;1.1296409;-1.6365519;1.5283942;3.4465187;CODE
class sklearn feature selection sequentialfeatureselector;2.3773713;-4.330673;-4.0809536;1.3164934;2.2237275;-0.0020159855;CODE
sequential feature selection can add features one at a time forward;1.4755099;-2.2355273;2.2595959;2.4251695;4.4896603;2.8085322;TASK
selection or remove features from the list of the available features;1.142338;-0.7971024;1.7746844;2.0993514;3.689854;1.5208637;TASK
backward selection based on a cross validated score maximization;5.2389812;-0.47536057;-0.8296744;3.115501;3.5547576;-0.0028876811;CODE
see the ref user guide sequential feature selection;1.3055532;-2.0292382;1.661158;1.8871509;4.4229717;1.7244796;TASK
new polynomialcountsketch kernel approximation function;3.2387245;-2.4606879;-2.572683;-1.9717301;-0.8069037;3.2792745;CODE
the new class sklearn kernel approximation polynomialcountsketch;4.416496;-5.8203883;-5.192377;-1.43953;-0.6379368;1.7575864;CODE
approximates a polynomial expansion of a feature space when used with linear;4.9467115;-2.126878;-1.9819108;-1.1746131;-0.1133702;5.4648232;TASK
models but uses much less memory than;0.9493943;-2.1578922;-0.64303607;2.8134835;0.14548148;0.79660416;META
class sklearn preprocessing polynomialfeatures;1.6468174;-5.807999;-5.3099318;-0.6094704;-0.4586033;-0.24341954;TASK
for comparison here is the score of a linear baseline for the same data;5.330615;0.4430663;1.1660335;0.5362064;0.5109201;-2.3669114;CODE
individual conditional expectation plots;2.0047064;-0.38018772;4.7277;-0.9364825;-1.7441832;2.3698032;-
a new kind of partial dependence plot is available the individual;3.2212188;-2.7319827;4.432152;-0.6349887;-1.0679108;1.7836168;CODE
conditional expectation ice plot ice plots visualize the dependence of the;1.1152114;-0.8345885;4.0561523;-1.7978771;-2.6254613;1.5078788;CODE
prediction on a feature for each sample separately with one line per sample;6.7269096;-1.5684463;1.7059053;1.3597898;2.1964915;0.25900635;CODE
see the ref user guide individual conditional;-1.985882;3.1156938;1.6424547;4.5051746;4.0640984;-1.1582305;-
from sklearn inspection import plot partial dependence;2.8782823;-2.345886;-3.01211;-0.94296175;-4.7110863;0.2756191;CODE
plot partial dependence has been removed in version 1 2 from 1 2 use;-2.0793595;-0.06980898;-0.24327567;-0.7285366;-4.4965343;3.9249744;CODE
partialdependencedisplay instead;-5.298649;1.8338215;0.724024;3.2593112;1.6144311;3.456184;CODE
display plot partial dependence;2.0364478;1.5810984;4.503819;-2.838036;-2.4313388;1.486838;CODE
new poisson splitting criterion for decisiontreeregressor;3.8431034;-0.91222864;-3.401717;1.1787747;3.6945693;2.928755;CODE
the integration of poisson regression estimation continues from version 0 23;-0.7232094;0.16699822;-1.4910218;1.8192872;-3.9431894;1.8574166;CODE
class sklearn tree decisiontreeregressor now supports a new poisson;1.596236;-5.4126515;-4.1927667;1.7910453;2.3255424;1.7224371;CODE
splitting criterion setting criterion poisson might be a good choice;6.054997;1.3225706;-0.33878812;3.6041808;3.3279166;3.11649;IRRE
if your target is a count or a frequency;3.262934;2.0733767;4.251419;2.341021;2.4813743;-2.2169983;-
positive integer target correlated with x 5 with many zeros;1.9449401;3.6292129;-0.3480367;-3.0962152;-0.8531748;-0.24412127;CODE
new documentation improvements;-5.2936482;-7.3618326;0.9560534;4.6615357;1.5022016;0.10189937;CODE
new examples and documentation pages have been added in a continuous effort;-5.129046;-6.4380097;1.8539468;4.1572814;1.3596556;0.10479209;CODE
to improve the understanding of machine learning practices;2.780841;-6.8866014;1.3674576;5.2556415;2.4787667;-2.7461643;-
a new section about ref common pitfalls and recommended;-3.9066904;0.12350271;-0.32709798;6.8310943;1.6155016;0.32152918;CODE
practices common pitfalls;-3.5383856;0.15182352;0.23547673;5.1729884;0.015215133;-0.38342726;-
an example illustrating how to ref statistically compare the performance of;4.216465;1.0501244;2.953337;6.465797;0.7629408;-3.7194753;IRRE
models sphx glr auto examples model selection plot grid search stats py;3.304722;-3.2778282;-2.1023328;-0.4862939;-2.102451;2.272999;CODE
evaluated using class sklearn model selection gridsearchcv;4.5202093;-3.213683;-5.563364;1.8080131;-0.60339254;-1.6215062;CODE
an example on how to ref interpret coefficients of linear models;1.5254335;-1.1408255;0.8843656;0.48493522;-1.677608;-0.06894274;CODE
sphx glr auto examples inspection plot linear model coefficient interpretation py;1.0909005;-1.2381355;-4.484665;-2.2153804;-4.0694733;0.5222516;CODE
an ref example;-1.9709699;0.32160336;4.721355;3.7543745;2.3754275;-2.4054585;-
sphx glr auto examples cross decomposition plot pcr vs pls py;0.9307922;-2.796869;-3.383056;-3.1918564;-3.1724517;3.6078126;-
comparing principal component regression and partial least squares;3.6011035;-0.7673951;-0.5043716;0.32911053;-1.5907359;3.5981913;-
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
keyword and positional arguments;-2.5489;-0.05640978;2.3119702;0.1568246;3.961745;-0.097495094;-
the scikit learn api exposes many functions and methods which have many input;1.217703;-10.993402;-2.3330152;1.8529255;-1.3748192;-3.1830096;CODE
parameters for example before this release one could instantiate a;-4.7696857;-0.83000267;-0.4397313;4.3426046;3.1043508;2.0421062;CODE
class ensemble histgradientboostingregressor as;4.6252365;-4.221206;-3.4902885;2.4981446;4.3279843;2.8829803;IRRE
histgradientboostingregressor squared error 0 1 100 31 none;0.4167038;0.875573;-6.963016;-1.1601489;-4.0339394;-0.24269451;-
20 0 0 255 none none false auto loss 0 1 10 1e 7;1.4078385;2.734768;-1.4507493;-2.904639;-2.0636377;-2.8752284;-
0 none;-2.2766032;2.1748118;1.9245709;-2.9180634;-1.5324376;-6.352817;-
understanding the above code requires the reader to go to the api;-6.221758;-0.20196888;0.6800155;3.136743;0.51957566;-0.9772837;CODE
documentation and to check each and every parameter for its position and;-2.790624;-1.3613219;2.6835296;0.65946764;3.3878605;-1.3159101;CODE
its meaning to improve the readability of code written based on scikit learn;-0.019368352;-9.682665;-3.8069508;1.0342885;-2.114826;-5.293339;CODE
now users have to provide most parameters with their names as keyword;-2.3752215;-0.47076216;-0.084519155;2.0452719;4.705983;2.022745;IRRE
arguments instead of positional arguments for example the above code would;-2.693761;3.3300996;1.219838;-2.441565;0.62672603;-1.6015381;CODE
histgradientboostingregressor;-1.2286627;-1.7787497;-1.5934788;1.7159128;1.1304374;2.522649;-
loss squared error;2.4311316;0.7756363;-1.5582399;-0.066318154;-3.473326;-0.28147644;-
learning rate 0 1;3.970103;-2.8112586;-0.022305762;0.704046;-0.6692128;-1.6299711;-
max iter 100;-1.2282578;1.3526878;2.9991782;-1.0060946;-0.86151606;-2.233009;-
max leaf nodes 31;-0.5160979;0.0638657;1.9264225;-3.2329507;0.84275204;-1.6693184;-
max depth none;-0.87822044;2.4313302;3.2912333;-2.8988748;0.10237438;-1.5868741;-
min samples leaf 20;2.0007374;2.0326247;0.9470869;-0.5715106;0.9406007;-2.4284346;-
l2 regularization 0 0;2.1300986;1.3914713;-3.062979;-2.715753;-1.421021;4.080336;-
max bins 255;-0.5356508;0.3488863;-0.24873203;-4.097769;0.99068606;-3.0056365;-
categorical features none;-0.67582303;-1.303333;-1.9469341;-1.4503354;0.7178896;-3.259675;TASK
monotonic cst none;0.16645181;3.7104127;-1.0601107;-0.7597571;-1.3185489;-2.8416545;-
warm start false;-1.8700786;3.1631024;0.8995269;3.470192;-2.6050427;-1.4371542;-
early stopping auto;-1.2982398;0.641529;2.4779413;5.51256;-1.2027152;0.702183;-
scoring loss;0.6605376;-0.049357075;3.493967;0.52053624;-1.3328415;-4.4974523;-
validation fraction 0 1;1.0649428;4.8375115;-1.4269849;-1.3430442;0.66997;-5.6526036;-
n iter no change 10;-3.0522406;0.63915;2.6218836;-1.6823523;-0.29509252;-2.383898;-
tol 1e 7;-2.856064;0.13164528;1.4580201;-0.87961376;0.34962347;-1.5408474;-
verbose 0;-3.4828126;2.3582067;1.0407898;-0.4830044;-1.0881774;-3.9319263;IRRE
random state none;-1.6380002;2.5868933;1.029541;0.94496304;-0.55696684;-4.274137;IRRE
which is much more readable positional arguments have been deprecated since;-4.8125916;-1.4776591;-0.28923866;1.080176;1.3211976;1.4731634;CODE
version 0 23 and will now raise a typeerror a limited number of;-3.0032365;0.694483;-6.3690968;2.3637307;-2.2661664;-4.0485716;META
positional arguments are still allowed in some cases for example in;-4.0379543;3.224737;-0.5071261;0.6055932;1.9800081;1.2538723;CODE
class decomposition pca where pca 10 is still allowed but pca 10;1.3371705;-0.19001533;-3.5447462;-1.295559;4.0688987;3.490822;TASK
false is not allowed;-4.557043;5.505914;-1.2515097;2.9677258;-1.1040918;-3.7475858;-
spline transformers;-0.79948723;-1.6288303;2.4965773;-2.971992;-1.1870382;2.644463;CODE
one way to add nonlinear terms to a dataset s feature set is to generate;4.796666;-3.760451;-0.773514;-1.2639049;1.2399976;1.7777908;TASK
spline basis functions for continuous numerical features with the new;4.7229667;-3.2633355;-1.3838226;-4.154282;-1.0963541;3.8587363;CODE
class preprocessing splinetransformer splines are piecewise polynomials;0.064391404;-0.95074636;-2.6822345;-3.9434333;-0.25455013;2.33158;CODE
parametrized by their polynomial degree and the positions of the knots the;-2.163356;-0.54463357;2.5129375;-2.9741383;-0.2674361;1.8851423;-
class preprocessing splinetransformer implements a b spline basis;-0.5208595;-1.3853301;-4.270218;-2.7524378;0.31890947;3.9789574;CODE
figure linear model images sphx glr plot polynomial interpolation 001 png;1.423657;-0.76686007;0.031191485;-5.826593;-3.9924488;3.1358998;CODE
target linear model plot polynomial interpolation html;2.8147266;-1.6386123;1.7247514;-3.6121023;-3.820121;3.8575768;CODE
align center;-0.9558346;1.6558104;5.7995033;-3.1601963;-2.902982;1.1326168;-
the following code shows splines in action for more information please;-1.8767991;0.5389475;2.469667;-4.590077;-1.5517776;-0.8589054;CODE
refer to the ref user guide spline transformer;-1.7294636;-1.4203281;0.52328634;-4.1960683;-2.4520557;3.2818413;CODE
quantile regressor;0.97794306;1.8722804;1.1358634;-2.8411288;-2.182561;1.3276613;-
quantile regression estimates the median or other quantiles of math y;1.1285386;0.51535183;2.100701;-0.07583192;-4.004448;0.7426298;IRRE
conditional on math x while ordinary least squares ols estimates the;1.8321959;2.3034768;-0.70625097;0.25480264;-2.2266617;2.3039901;IRRE
conditional mean;-0.41694468;4.413265;4.751381;2.0102181;0.4052529;-1.1644157;-
as a linear model the new class linear model quantileregressor gives;1.8259524;-0.88323206;-0.8163589;0.41611034;-0.23193993;1.7758166;CODE
linear predictions math hat y w x xw for the math q th quantile;3.9168303;-1.3803995;0.3671872;-1.3759705;-1.5417578;1.0498338;CODE
math q in 0 1 the weights or coefficients math w are then found by;1.4440536;0.5632146;0.01071965;-3.762085;-0.42343566;-0.45278725;CODE
the following minimization problem;3.4085662;1.2295098;2.243995;-2.7368155;-0.83209574;3.3351412;-
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
min w frac 1 n text samples;4.198745;-0.6353201;0.36301374;-3.689282;1.8799214;-3.2576432;-
sum i pb q y i x i w alpha w 1;0.05884674;0.5808334;2.0606139;-4.531556;0.31338665;-2.0127406;-
this consists of the pinball loss also known as linear loss;2.5394762;-0.37794113;1.809958;-0.062782936;0.22976223;2.5901635;CODE
see also class sklearn metrics mean pinball loss;4.044936;-4.941505;-1.880704;2.0338984;-2.3392854;-1.0914139;IRRE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
pb q t q max t 0 1 q max t 0;0.54094267;2.5329082;1.2409649;-4.7311;1.1295073;-2.3198345;-
begin cases;-1.9729403;0.9169634;4.8627553;0.6614248;3.931949;-4.094034;CODE
q t t 0;-1.8702242;1.3149055;3.374011;-1.8410403;-0.670921;-2.5177197;-
0 t 0;-1.1549022;2.4492285;2.3539045;-3.28308;-2.392434;-4.1114345;-
1 q t t 0;-1.5674558;1.6472932;3.0641463;-2.8254728;-0.5860873;-2.3697872;-
end cases;-2.3727534;0.35237756;4.742612;2.0554109;1.9308339;-2.5353677;CODE
and the l1 penalty controlled by parameter alpha similar to;1.2948837;0.07442396;-1.220683;1.9582428;0.6998214;4.273083;IRRE
class linear model lasso;4.3817973;-3.4164891;-1.6671683;-0.28063262;-0.068561904;2.6087441;IRRE
please check the following example to see how it works and the ref user;-4.4098663;1.3859117;3.5628326;1.7495562;0.72510636;1.936777;CODE
guide quantile regression for more details;0.6972654;-1.3728886;2.5749555;0.7147478;-2.8682678;0.21091072;CODE
figure linear model images sphx glr plot quantile regression 002 png;1.060497;-0.5005073;0.7186456;-4.481182;-5.7962475;2.6076565;-
target linear model plot quantile regression html;1.0408008;-1.6947296;2.354123;-2.1990607;-5.006131;2.6952214;-
align center;-0.9558346;1.6558104;5.7995033;-3.1601963;-2.902982;1.1326168;-
scale 50;1.7734197;1.4321977;4.4088106;-1.7099046;-1.8012373;-1.7483995;-
feature names support;-3.0203235;-6.4265447;-1.4553701;1.7261754;3.4365635;1.1767657;TASK
when an estimator is passed a pandas dataframe;1.3032951;0.55844307;-1.930259;1.507194;-5.659424;1.5422899;-
https pandas pydata org docs user guide dsintro html dataframe during;-2.9815292;-3.7535641;-2.3101175;-2.977832;-4.5748343;-0.32962725;CODE
term fit the estimator will set a feature names in attribute;2.010059;-0.8933969;-2.0831316;2.3046093;0.1325952;3.549121;TASK
containing the feature names this is a part of;-3.0001416;-6.1135545;1.2458016;1.2856611;5.407689;-0.21358669;TASK
slep007 https scikit learn enhancement proposals readthedocs io en latest slep007 proposal html;-1.5963948;-10.500982;-4.0225797;1.3216726;-2.0162494;-1.2220623;CODE
note that feature names support is only enabled;-5.6465693;-4.807982;-2.4498963;1.9354432;-0.58240587;2.0848303;TASK
when the column names in the dataframe are all strings feature names in;0.96663684;-1.5278378;-2.5823927;-1.6648037;-1.1186903;-1.4527208;CODE
is used to check that the column names of the dataframe passed in;0.09347659;-0.1641035;-1.4731282;-1.3432645;-0.9280955;-3.3835733;OUTD
non term fit such as term predict are consistent with features in;3.0022936;-0.21687837;-4.1359763;2.365035;-0.79231495;1.2306664;TASK
term fit;3.2990377;-1.3667213;1.8021182;2.4993994;0.21135941;-0.59987974;-
the support of term get feature names out is available for transformers;-2.8815348;-4.4926353;-1.492168;2.1226928;1.9141538;1.9902613;CODE
that already had get feature names and transformers with a one to one;-3.6501067;-4.2438216;0.558237;2.435052;1.6531824;1.7062079;CODE
correspondence between input and output such as;1.882503;-0.3235181;1.8338186;-0.8856308;1.345709;-1.114257;CODE
class preprocessing standardscaler term get feature names out support;-1.5806849;-2.3745348;-5.1372256;2.8335533;1.9761044;1.8124491;TASK
will be added to all other transformers in future releases additionally;-4.0760126;-4.381079;1.6931049;0.5226788;0.9870722;1.7725636;TASK
meth compose columntransformer get feature names out is available to;-1.9267291;-2.3558822;-3.7489223;0.026352327;0.84480804;1.760292;CODE
combine feature names of its transformers;-0.0049777646;-2.3898017;0.91521347;-0.9412632;4.435759;2.13863;TASK
when this preprocessor is used with a pipeline the feature names used;-1.913513;-3.3611019;-2.0202336;1.3025676;3.275996;1.3629397;CODE
by the classifier are obtained by slicing and calling;2.5094273;-4.093673;-1.3479943;0.38523817;4.802554;-0.8050448;IRRE
term get feature names out;-1.9499468;-2.6944501;-1.2498859;2.3040698;2.3777864;-0.34250954;TASK
a more flexible plotting api;2.4811099;-5.0577645;4.1862245;-3.572211;-4.4984317;2.0182722;CODE
class metrics confusionmatrixdisplay;4.722109;-1.7607296;-3.6066127;-1.238029;1.5591563;1.0366141;IRRE
class metrics precisionrecalldisplay class metrics detcurvedisplay;3.032731;-2.4695346;-3.2734191;1.215283;0.81588143;0.96494114;IRRE
and class inspection partialdependencedisplay now expose two class;-2.973935;1.5610182;-1.9137439;4.9775233;4.682925;2.7002382;IRRE
methods from estimator and from predictions which allow users to create;3.493334;-3.790089;2.908119;6.7104535;0.426442;1.1930697;IRRE
a plot given the predictions or an estimator this means the corresponding;4.1584997;-2.3654935;6.1682262;0.79162234;-3.8023536;0.68889356;CODE
plot functions are deprecated please check ref example one;-2.0723042;-0.79613304;1.5545658;-3.0753007;-7.2035904;-0.17345677;OUTD
sphx glr auto examples model selection plot confusion matrix py and;2.422103;-2.0781403;-2.8986022;-1.7663487;-2.8208544;1.5984322;CODE
ref example two;-3.2189867;1.1587052;3.5413282;3.352765;2.2267992;-2.9742193;CODE
sphx glr auto examples classification plot digits classification py for;1.4574258;-4.911426;-2.6557596;-2.8524795;-1.7305615;0.33510065;CODE
how to use the new plotting functionalities;-0.55536735;-1.599266;3.7965853;-3.571607;-4.351408;2.198807;CODE
online one class svm;3.0653813;-4.6166596;-0.75355524;0.01346955;2.8672965;1.0725098;IRRE
the new class class linear model sgdoneclasssvm implements an online;2.241997;-6.1653275;-3.3887064;1.3279256;3.8246934;1.9385633;CODE
linear version of the one class svm using a stochastic gradient descent;5.519223;-4.5577784;-2.1954727;0.14970145;2.1855154;3.689844;IRRE
combined with kernel approximation techniques;7.4721813;-3.6244154;-0.175313;-1.2952677;0.16917557;2.666482;-
class linear model sgdoneclasssvm can be used to approximate the solution;5.6207066;-2.845339;-3.1492577;-0.53821176;1.5072546;3.3944082;CODE
of a kernelized one class svm implemented in class svm oneclasssvm with;2.1118867;-3.9291024;-3.5693672;-0.60669273;1.738944;4.2050076;CODE
a fit time complexity linear in the number of samples note that the;5.7948217;0.13895522;-0.047433253;0.12842162;-0.09219857;1.102148;TASK
complexity of a kernelized one class svm is at best quadratic in the number;4.253588;-2.51396;-3.997835;-1.5132378;0.16305551;3.0127048;CODE
of samples class linear model sgdoneclasssvm is thus well suited for;5.296892;-4.9840484;-3.5265749;1.3284172;3.5924652;2.9509048;CODE
datasets with a large number of training samples 10 000 for which the sgd;6.249994;-4.90071;-1.3111029;1.9536988;1.5845187;0.031902924;IRRE
variant can be several orders of magnitude faster please check this;1.3912017;0.97314596;-0.76956;-0.058856543;1.2681915;-2.1798172;CODE
ref example;-2.8613698;0.22860216;4.3832083;3.364573;1.6875598;-2.2500033;-
sphx glr auto examples miscellaneous plot anomaly comparison py to see how;0.5359957;-0.90630686;-3.5383465;-0.9342173;-5.4027023;0.51283944;-
it s used and the ref user guide sgd online one class svm for more;-0.37312427;-7.5071115;-1.4403125;0.89201915;2.120795;1.3822547;CODE
details;-1.9197476;-2.4566455;5.9425316;0.8847738;1.0150981;-1.1708876;-
figure miscellaneous images sphx glr plot anomaly comparison 001 png;-0.49479428;1.4114115;-0.8351147;-3.4141665;-4.4344926;1.1116319;-
target miscellaneous plot anomaly comparison html;0.24066739;1.7844627;0.7881298;-0.28353086;-5.2100234;-0.095126495;-
align center;-0.95583475;1.6558098;5.799505;-3.1601973;-2.9029815;1.1326166;-
histogram based gradient boosting models are now stable;4.527028;-4.7929463;-0.23180261;1.0181818;-0.38713226;2.094266;-
class sklearn ensemble histgradientboostingregressor and;5.101779;-5.989768;-5.371145;1.6807448;1.110624;1.1692147;IRRE
class ensemble histgradientboostingclassifier are no longer experimental;1.866036;-4.0201488;-5.3483806;3.7817717;0.1398044;1.3342437;IRRE
and can simply be imported and used as;-3.8033478;-4.5886507;1.18111;-0.81640655;4.134674;0.29871616;CODE
from sklearn ensemble import histgradientboostingclassifier;2.393677;-6.8044124;-6.314801;0.5075456;0.3364086;0.5889499;CODE
new documentation improvements;-5.2936482;-7.3618326;0.9560534;4.6615357;1.5022016;0.10189937;CODE
this release includes many documentation improvements out of over 2100;-5.280196;-6.8398013;-1.7031404;3.6196785;0.46768624;-0.6687663;CODE
merged pull requests about 800 of them are improvements to our;-2.5194924;-2.836662;2.0386534;4.343616;0.65561754;2.0265112;TASK
documentation;-5.275622;-7.480966;3.7151163;2.304026;2.9932058;-2.7141862;CODE
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
quantile support hgbdt;-0.785519;-0.33915016;-1.6378909;-2.493672;0.13432679;2.3267398;-
quantile loss in class ensemble histgradientboostingregressor;4.3218064;-2.0895848;-3.3270323;1.8042947;0.33763853;2.3334055;IRRE
class ensemble histgradientboostingregressor can model quantiles with;5.3908167;-2.876724;-2.524655;1.6516542;2.3339422;2.7477849;IRRE
loss quantile and the new parameter quantile;0.17748986;0.47364014;0.7271867;0.9431103;-0.69328237;3.005256;IRRE
simple regression function for x cos x;1.3253717;0.75419825;1.9042183;-2.157723;-4.5374527;-0.6023022;CODE
for a usecase example see;-5.0453506;-2.3840475;3.1250658;0.47864893;4.001841;-1.175749;CODE
ref sphx glr auto examples ensemble plot hgbt regression py;1.6750268;-3.9547586;-4.671762;-0.6874636;-3.5508802;1.8107132;-
get feature names out available in all transformers;-1.4648931;-1.1214557;-1.4899176;2.505975;2.5551116;2.888317;TASK
term get feature names out is now available in all transformers thereby;-3.5423615;-2.691996;-2.5782828;2.753889;1.3771839;2.892077;TASK
concluding the implementation of;-1.1329929;-0.21362512;2.5641153;6.7541366;2.552109;0.068118826;TASK
slep007 https scikit learn enhancement proposals readthedocs io en latest slep007 proposal html;-1.5963948;-10.500982;-4.0225797;1.3216726;-2.0162494;-1.2220623;CODE
this enables class pipeline pipeline to construct the output feature names for;-1.4211758;-5.295716;-2.2713065;2.0862126;4.07299;1.283257;CODE
more complex pipelines;0.6370229;-3.64921;2.5130703;2.107688;2.7773368;0.98827565;META
here we slice the pipeline to include all the steps but the last one the output;-1.4653807;1.163792;1.1871228;-0.43762702;-0.33613834;-0.43598148;CODE
feature names of this pipeline slice are the features put into logistic;0.2966925;-5.522438;-1.1100066;0.6372027;3.3473995;1.4260548;CODE
regression these names correspond directly to the coefficients in the logistic;0.84074205;-1.8837471;-1.2402487;-1.1746417;0.77713484;-0.51804626;CODE
regression;4.8113813;-1.4023851;5.968424;1.4558641;-1.5940726;-2.9783654;-
grouping infrequent categories in class preprocessing onehotencoder;2.3748913;-1.3366876;-0.5470511;1.3707715;3.6535718;1.1972017;IRRE
class preprocessing onehotencoder supports aggregating infrequent;3.1934717;-1.20192;-2.3200157;1.1063626;3.3622525;2.6988273;IRRE
categories into a single output for each feature the parameters to enable;1.8896353;-1.7458295;1.9307734;0.18530345;3.2247162;1.3084031;CODE
the gathering of infrequent categories are min frequency and;4.1972303;-1.8425455;2.0657446;3.2304626;2.8235505;-0.026023328;-
max categories see the ref user guide encoder infrequent categories;1.0455228;-3.3196695;-0.9581385;0.021567557;2.395904;0.7906919;-
for more details;-3.480828;-3.12476;4.442992;1.1291379;0.046866957;-1.9306489;CODE
since dog and snake are infrequent categories they are grouped together when;-0.74282634;-2.8800712;1.894313;1.0873398;2.4096997;0.20758766;CODE
transformed;-3.0065103;-0.6892256;5.113641;-2.0017982;-2.1636803;0.43992934;CODE
performance improvements;3.246989;-2.911532;2.8927906;4.6095934;1.5030277;0.6104983;TASK
reductions on pairwise distances for dense float64 datasets has been refactored;5.2425613;-1.7096996;-3.6054094;-3.1122537;-1.0960783;1.0006126;CODE
to better take advantage of non blocking thread parallelism for example;-0.7800425;-1.9548728;1.906926;1.9149121;0.38748175;2.8160052;CODE
meth neighbors nearestneighbors kneighbors and;2.353189;-1.1412317;1.8677253;-2.2652283;-1.2636884;-1.1136923;-
meth neighbors nearestneighbors radius neighbors can respectively be up to 20 and;2.8045506;0.49028632;1.0772746;-3.0089083;-1.731546;-0.232659;-
5 faster than previously in summary the following functions and estimators;4.4759927;-0.1904905;1.350613;1.7227783;-0.85809654;0.27042758;CODE
now benefit from improved performance;0.2988141;-2.5297601;2.513521;4.3022494;1.6338791;1.3717015;CODE
func metrics pairwise distances argmin;3.340752;-2.3420527;-0.7919975;-2.1027715;-0.90540224;3.6219962;-
func metrics pairwise distances argmin min;3.4876559;-1.7751809;-1.0930974;-2.3841536;-0.85172015;3.8156137;-
class cluster affinitypropagation;4.4884067;-4.180234;-2.2872012;-0.16312194;2.1444912;3.8682475;IRRE
class cluster birch;1.5027833;-3.6571;-0.20425493;-0.6621845;3.0741177;0.8692337;IRRE
class cluster meanshift;4.5725493;-1.8777224;-0.73116916;0.62124294;1.7231694;2.6199813;IRRE
class cluster optics;1.8205755;-3.1136477;0.5992814;-1.3108602;0.9139775;2.1155858;IRRE
class cluster spectralclustering;5.643542;-5.219944;-1.5792619;-1.2227774;1.5472689;2.973672;IRRE
func feature selection mutual info regression;4.574552;-3.3029459;-0.7985924;0.8005116;2.8439527;0.5925866;CODE
class neighbors kneighborsclassifier;4.640315;-3.549218;-2.294133;-3.1709566;3.0075457;-0.33298302;IRRE
class neighbors kneighborsregressor;2.3649266;-2.9039876;-0.46729892;-2.4832406;2.496527;0.29030234;IRRE
class neighbors radiusneighborsclassifier;3.5774863;-2.2853968;-1.6252466;-2.5422359;2.4311364;0.28216264;IRRE
class neighbors radiusneighborsregressor;0.9698777;-0.76081496;-0.3724736;-2.3648825;1.4049693;1.9258496;IRRE
class neighbors localoutlierfactor;2.4601142;-1.7549257;-2.830166;0.057781752;1.0759777;3.6591828;IRRE
class neighbors nearestneighbors;4.540132;-1.9645257;-0.23802799;-3.0095377;2.2393925;-0.578176;IRRE
class manifold isomap;0.6452228;-3.8536203;-0.47705686;-2.6416042;2.530337;4.4296613;IRRE
class manifold locallylinearembedding;-1.1043122;-3.9655306;-0.7858468;-0.51965934;1.262693;5.1646333;IRRE
class manifold tsne;-0.46433705;-3.1823452;-0.43360606;-1.7233866;2.2837105;2.5489826;IRRE
func manifold trustworthiness;0.2566846;-2.029322;-1.8678817;2.525413;0.1601481;3.2977848;-
class semi supervised labelpropagation;2.5404935;-4.183684;-1.4127474;-0.5011952;4.1519103;1.6024772;CODE
class semi supervised labelspreading;3.1655915;-3.783603;0.85840553;1.0855414;3.7186956;1.2921414;CODE
to know more about the technical details of this work you can read;-2.6582348;-6.2590137;4.4249716;0.79306436;0.55431455;-0.6851487;CODE
this suite of blog posts https blog scikit learn org technical performances;-0.74624825;-10.544031;-0.38176525;2.3403983;-1.4913964;-3.791748;CODE
moreover the computation of loss functions has been refactored using;2.9186888;-2.8711965;-2.125632;-1.2219552;-0.35675213;2.7228997;OUTD
cython resulting in performance improvements for the following estimators;4.1264086;0.109575175;-1.2895857;1.2265598;-2.9127657;1.1344974;CODE
class linear model logisticregression;2.959428;-1.9384987;-2.875108;0.662767;0.99475056;0.26693392;IRRE
class linear model gammaregressor;0.62471324;-1.0972562;-2.0757723;0.18481839;-0.1673672;3.0911407;IRRE
class linear model poissonregressor;1.1644845;0.20917264;-1.1932298;0.64614594;0.39271984;2.9098358;IRRE
class linear model tweedieregressor;1.2716613;-1.5668305;-3.4144204;-0.55234003;0.1533207;3.7137308;IRRE
class decomposition minibatchnmf an online version of nmf;3.5393937;-5.166941;-3.078613;-0.5283934;2.5528352;2.330385;IRRE
the new class class decomposition minibatchnmf implements a faster but;2.9290025;-4.4408174;-3.0152352;1.0164851;2.7357476;3.284185;CODE
less accurate version of non negative matrix factorization;5.1648874;-1.8666542;-2.7815845;-1.1661599;-1.54187;4.3731623;META
class decomposition nmf class decomposition minibatchnmf divides the;2.2757363;-2.5340483;-4.0501146;-0.4720121;3.4472244;2.2627559;IRRE
data into mini batches and optimizes the nmf model in an online manner by;5.7398214;-2.6063652;0.79431665;1.3680983;1.6795588;2.4113185;CODE
cycling over the mini batches making it better suited for large datasets in;5.8518634;-2.6920466;0.7564301;2.3465986;0.0378691;2.413106;CODE
particular it implements partial fit which can be used for online;2.3867958;-2.3719969;0.46482745;1.124422;2.1773427;4.054017;TASK
learning when the data is not readily available from the start or when the;5.7048683;-3.808356;3.262262;5.3317857;2.826369;-0.59668213;CODE
data does not fit into memory;0.68379676;2.026941;0.3320462;-2.7522874;-1.4290228;-0.12402572;CODE
class cluster bisectingkmeans divide and cluster;2.6420882;-1.2765007;-1.2398328;-1.9169533;2.0677998;0.7207088;IRRE
the new class class cluster bisectingkmeans is a variant of;2.956188;-3.0772386;-1.301707;-1.7725565;2.923794;0.52361184;CODE
class cluster kmeans using divisive hierarchical clustering instead of;3.1294863;-2.4150898;-1.4683782;-1.1130266;2.5100095;2.9517903;CODE
creating all centroids at once centroids are picked progressively based on a;4.8851166;2.510883;2.324756;-2.9293282;1.0134815;2.539553;CODE
previous clustering a cluster is split into two new clusters repeatedly;1.3409191;0.8015656;-0.14045873;0.23714411;-0.7115806;2.7638257;CODE
until the target number of clusters is reached giving a hierarchical;3.5045211;-0.16032206;2.5146558;0.8065372;1.1575787;2.67875;-
structure to the clustering;5.295905;-3.4824235;4.208359;-1.4151092;4.145763;1.7596071;CODE
ruff noqa cpy001 e501;-4.708646;0.40756392;-1.3329889;-4.0188212;0.8740261;-2.627956;-
pandas output with set output api;1.3115369;-1.9182345;-1.2109634;-1.1600884;-2.9061906;-0.7511796;IRRE
scikit learn s transformers now support pandas output with the set output api;0.8171913;-6.62942;-5.281373;-0.663878;-3.7414355;-0.4973531;IRRE
to learn more about the set output api see the example;0.18296075;-2.131499;1.8946595;-0.25038522;1.8057132;-1.413926;IRRE
ref sphx glr auto examples miscellaneous plot set output py and;-1.3834958;-1.5808913;-1.4912261;-3.1129966;-5.2389956;1.2399082;IRRE
this video pandas dataframe output for scikit learn transformers;2.0494142;-7.5030546;-1.817165;-3.022637;-5.0535707;-2.3286858;CODE
some examples https youtu be 5bcg8vfx2x8;-3.4018004;-2.927063;0.42060512;-2.0518718;-0.8902485;-0.3435086;CODE
interaction constraints in histogram based gradient boosting trees;4.2366505;-4.0551643;0.019799495;-1.6693135;2.1634595;2.3483396;CODE
class ensemble histgradientboostingregressor and;4.97161;-4.112652;-3.57256;2.709109;3.843953;2.649187;IRRE
class ensemble histgradientboostingclassifier now supports interaction constraints;2.2993479;-5.1461177;-4.3766947;2.24923;3.6884663;4.3745646;CODE
with the interaction cst parameter for details see the;-2.285429;-0.085338496;1.8148937;0.95470953;0.6843541;2.3858328;CODE
ref user guide interaction cst hgbt in the following example features are not;-4.352578;-1.6161325;-2.79634;1.4905933;0.8420182;0.78335273;CODE
allowed to interact;-8.0437355;-2.0066187;4.0939116;0.965918;-1.2365762;-1.0990478;CODE
new and enhanced displays;-3.1053727;-2.386585;4.6241927;-1.0216244;-0.76150125;2.7112064;CODE
class metrics predictionerrordisplay provides a way to analyze regression;4.9666424;-4.7590528;-2.5136166;4.5434375;-0.46150348;-1.6958303;IRRE
models in a qualitative manner;1.5406303;-4.4148183;4.9262857;4.984101;2.967336;-0.10886997;-
class model selection learningcurvedisplay is now available to plot;1.267575;-6.901135;0.24047191;2.2084906;-0.46147227;3.0162072;CODE
results from func model selection learning curve;5.6550045;-3.780347;-1.0322082;3.4872284;0.25146887;0.212169;CODE
class inspection partialdependencedisplay exposes a new parameter;-3.977298;2.8153052;-4.0415154;5.205823;3.3716452;2.020734;CODE
categorical features to display partial dependence for categorical features;2.5829983;-2.793206;1.0124694;-1.1605532;3.7355607;0.72633284;TASK
using bar plots and heatmaps;2.1153197;-1.6225252;4.086867;-3.2698507;-2.9830306;2.2147474;IRRE
faster parser in func datasets fetch openml;1.3685209;-2.1842945;-1.8064789;2.6325526;2.3724473;0.5324146;IRRE
func datasets fetch openml now supports a new pandas parser that is;-0.65098953;-4.6165133;-4.241434;0.9199;-0.83444583;0.2446048;IRRE
more memory and cpu efficient in v1 4 the default will change to;-1.0649183;-0.094613455;-0.7583781;0.8085382;-0.9253318;3.4770174;CODE
parser auto which will automatically use the pandas parser for dense;1.257691;-2.9094908;-3.6612513;-0.07860869;-1.6841376;0.43822494;IRRE
data and liac arff for sparse data;6.6429234;-2.1788042;-2.0455644;-1.254395;1.1079334;3.4261813;IRRE
experimental array api support in class discriminant analysis lineardiscriminantanalysis;5.925102;-2.7758672;-5.5878515;-1.6535157;1.5022483;-0.40769696;CODE
experimental support for the array api https data apis org array api latest;-0.68358976;-1.1453475;-1.5197455;1.1401929;-1.862277;0.31423864;CODE
specification was added to class discriminant analysis lineardiscriminantanalysis;3.176196;-2.8855245;-5.717488;-1.0615783;2.4674814;0.9559226;TASK
the estimator can now run on any array api compliant libraries such as;0.6943346;-1.7095556;-3.00118;3.0101326;-1.4978539;3.4886034;CODE
cupy https docs cupy dev en stable overview html a gpu accelerated array;-2.320497;-4.5535874;-1.3284595;-2.5453188;-1.3655835;0.9967525;CODE
library for details see the ref user guide array api;-1.54481;-3.8350956;1.2481893;-0.9961826;2.3501682;0.052344814;CODE
improved efficiency of many estimators;6.319696;-0.8528824;1.1809546;3.3339357;0.9205763;3.9744034;CODE
in version 1 1 the efficiency of many estimators relying on the computation of;4.577113;-1.5237168;-0.45073524;2.3254764;0.93343574;3.3611803;META
pairwise distances essentially estimators related to clustering manifold;4.733062;-3.788594;0.49453366;-1.6332034;0.42466995;6.026274;-
learning and neighbors search algorithms was greatly improved for float64;3.8495622;-3.491783;-1.6685585;-4.157411;-1.51794;-0.9046897;CODE
dense input efficiency improvement especially were a reduced memory footprint;0.8007823;-1.5622516;-0.42622638;-0.70719707;-0.46335667;2.4295034;CODE
and a much better scalability on multi core machines;1.3929315;-4.0634875;-0.45307887;2.4712226;1.9936643;3.0527182;-
in version 1 2 the efficiency of these estimators was further improved for all;3.6801562;-1.438065;-1.2336699;3.1446414;-1.243937;2.5913458;META
combinations of dense and sparse inputs on float32 and float64 datasets except;5.5852323;-1.1427227;-3.5697317;-3.2873259;0.11304297;0.86483645;CODE
the sparse dense and dense sparse combinations for the euclidean and squared;5.3651767;-3.270119;-0.575517;-3.4371216;0.24257445;2.778461;IRRE
euclidean distance metrics;2.792894;-1.6840079;3.2236626;-2.5056617;-1.15584;1.1230972;CODE
a detailed list of the impacted estimators can be found in the;0.3305582;-2.298599;0.41882503;4.414368;-1.1215228;1.8538985;CODE
ref changelog release notes 1 2;-5.9211397;-2.5557466;-0.7095684;3.817411;-0.40998885;1.0278665;TASK
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
metadata routing;-2.1099484;-3.1588523;1.3668362;0.83830476;3.6255965;4.243997;-
we are in the process of introducing a new way to route metadata such as;-3.034241;-5.823074;1.9476049;1.7000189;4.477754;4.4137006;CODE
sample weight throughout the codebase which would affect how;3.3411434;0.24090867;-0.1801228;4.157934;2.8507464;0.6712594;-
meta estimators such as class pipeline pipeline and;2.2802985;-3.98091;-1.7690462;5.739657;2.1136997;3.1203783;CODE
class model selection gridsearchcv route metadata while the;0.18338495;-2.8275409;-3.6891391;2.7940779;1.9898648;4.4726844;CODE
infrastructure for this feature is already included in this release the work;-3.5859969;-7.393518;1.374507;2.1880436;1.776272;4.6793194;CODE
is ongoing and not all meta estimators support this new feature you can read;0.1619434;-2.9735453;-1.2763101;5.315107;-0.7718516;4.8081594;CODE
more about this feature in the ref metadata routing user guide;-3.5551946;-2.151154;-0.16242325;2.1208208;2.2716937;6.442238;CODE
metadata routing note that this feature is still under development and;-3.4395297;-4.072744;0.4411406;1.2898408;2.4752293;6.2514334;TASK
not implemented for most meta estimators;0.7283112;-0.8893115;-3.0426993;4.58553;-1.7121148;3.4733095;TASK
third party developers can already start incorporating this into their;-5.0355487;-6.308803;1.4664499;2.0818007;2.2320545;2.018757;CODE
meta estimators for more details see;3.1407282;-1.722059;2.1200237;5.054933;0.3135213;1.2916768;CODE
ref metadata routing developer guide;-3.6868243;-3.774338;-0.11613507;1.0169562;1.9001019;3.2604814;-
sphx glr auto examples miscellaneous plot metadata routing py;-3.4439287;-3.462537;-2.0563607;-1.8377107;-3.731741;4.230101;-
hdbscan hierarchical density based clustering;4.3339014;-3.392611;-0.6865365;-3.5451717;1.3508587;2.1405396;-
originally hosted in the scikit learn contrib repository class cluster hdbscan;0.76268667;-8.178287;-5.189679;-2.1497288;-1.6980197;-0.503261;CODE
has been adpoted into scikit learn it s missing a few features from the original;-1.0115708;-11.519696;-4.1468763;1.7211217;-3.5122018;-1.86685;CODE
implementation which will be added in future releases;-3.233784;-6.2987223;1.8417457;2.9791298;2.759642;0.48974183;TASK
by performing a modified version of class cluster dbscan over multiple epsilon;2.9896846;0.1786401;-3.9082417;-1.1143826;2.5132082;1.8975247;CODE
values simultaneously class cluster hdbscan finds clusters of varying densities;5.4074135;-1.3925725;-3.4966495;-2.5095708;1.0749605;1.5041932;IRRE
making it more robust to parameter selection than class cluster dbscan;4.3211975;-0.84540564;-2.5555804;1.114657;3.7982652;3.3090472;IRRE
more details in the ref user guide hdbscan;-1.1592624;-4.025355;-1.3178947;-2.2289624;1.3575549;-0.051684245;CODE
targetencoder a new category encoding strategy;1.2400432;-3.8408635;-0.1536429;1.4320248;3.4218109;2.1990507;CODE
well suited for categorical features with high cardinality;3.513882;-4.71096;1.410617;-0.4766764;3.6884263;0.21661907;TASK
class preprocessing targetencoder encodes the categories based on a shrunk;2.162749;-1.8137605;-2.2416928;1.2130302;2.371967;2.0871897;CODE
estimate of the average target values for observations belonging to that category;5.741016;-0.1906629;0.724987;2.5681536;0.11201895;1.6636217;IRRE
more details in the ref user guide target encoder;-2.48257;-2.1386044;-2.6069508;-0.30755666;1.3411782;2.21537;CODE
missing values support in decision trees;3.5557487;-0.95601827;-2.7371097;0.7009555;3.1179595;-0.61211663;IRRE
the classes class tree decisiontreeclassifier and;2.8750503;-6.623857;-1.953194;1.8556111;6.0427637;-0.94046485;IRRE
class tree decisiontreeregressor now support missing values for each potential;2.228697;-0.70790964;-5.299073;1.8111247;3.126516;0.887203;IRRE
threshold on the non missing data the splitter will evaluate the split with all the;5.3616486;2.8590953;-0.7933734;-0.22545171;2.0209782;-1.4371276;CODE
missing values going to the left node or the right node;0.5764779;3.9541957;0.84313107;-3.7072544;-1.4712946;-2.2601042;IRRE
see more details in the ref user guide tree missing value support or see;-4.732583;-0.3635228;-4.2229166;0.517325;0.67690647;0.37672973;IRRE
ref sphx glr auto examples ensemble plot hgbt regression py for a usecase;1.5622139;-4.017181;-4.246373;-0.15283972;-3.1885154;2.2300878;CODE
example of this feature in class ensemble histgradientboostingregressor;4.0509377;-3.7610838;-2.0243998;1.551354;3.9996202;2.447252;CODE
new display class model selection validationcurvedisplay;-0.68751085;-0.78370917;-1.9636656;4.5721755;2.5822978;1.284702;CODE
class model selection validationcurvedisplay is now available to plot results;0.87451863;-1.9735137;-2.1543124;4.0977893;-1.2670704;1.6199418;CODE
from func model selection validation curve;3.8179276;0.28376475;-1.9875605;2.941736;0.5729609;-0.4758652;CODE
gamma loss for gradient boosting;3.0468075;-4.0960436;0.09134417;0.5267162;0.65323985;2.658868;CODE
the class class ensemble histgradientboostingregressor supports the;5.437722;-5.173486;-2.687783;2.0083218;5.0713344;2.6447701;IRRE
gamma deviance loss function via loss gamma this loss function is useful for;0.62551373;-2.1835732;-1.0036288;-0.5598064;-1.8283753;2.9741957;CODE
modeling strictly positive targets with a right skewed distribution;2.9573367;1.2457916;-0.7998035;1.6456062;-1.4781293;2.0338478;META
grouping infrequent categories in class preprocessing ordinalencoder;2.2112668;-1.3328701;-1.3117214;-0.048723098;4.48083;0.33008963;IRRE
similarly to class preprocessing onehotencoder the class;-0.56957656;-2.71734;0.13366324;0.05926306;3.1465392;1.6253346;IRRE
class preprocessing ordinalencoder now supports aggregating infrequent categories;1.8525894;-2.7809594;-3.2647986;-0.24500427;4.682379;1.2255589;IRRE
into a single output for each feature the parameters to enable the gathering of;4.4748893;-0.63575834;1.2850596;0.23087704;4.0387716;0.666562;CODE
infrequent categories are min frequency and max categories;2.171292;-1.4758713;0.41109204;1.3158373;1.8046563;1.1207093;-
see the ref user guide encoder infrequent categories for more details;1.7255752;-3.9249566;-0.9851086;1.0443021;3.2493813;1.2294289;CODE
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
histgradientboosting natively supports categorical dtypes in dataframes;2.2198274;-4.9225373;-4.792401;-1.6003897;-0.83198506;0.5918895;-
class ensemble histgradientboostingclassifier and;4.2228317;-4.8578453;-3.047888;2.268569;4.5993905;1.7248741;IRRE
class ensemble histgradientboostingregressor now directly supports dataframes with;3.7741416;-5.3256726;-5.5867014;1.706067;0.02877519;3.1761208;IRRE
categorical features here we have a dataset with a mixture of;4.3021646;-2.5131812;3.5569117;-1.6580205;4.435232;-1.2030243;TASK
categorical and numerical features;4.25721;-2.508726;0.9184981;-3.1429315;3.628609;-2.3428054;TASK
remove redundant and non feature columns;1.8270626;1.2710773;-0.25425163;-2.4358447;2.356096;2.4600806;TASK
by setting categorical features from dtype the gradient boosting classifier;3.3381746;-5.703563;-2.141997;-1.3157436;2.2257373;-0.066742435;IRRE
treats the columns with categorical dtypes as categorical features in the;2.3162382;-2.5364072;-4.244685;-3.2612748;0.6229666;-0.8501846;TASK
algorithm;4.409945;-0.2822192;4.6803837;-2.8470244;3.30263;-4.743204;-
polars output in set output;0.48084334;2.3784034;1.4001235;-3.3573658;-0.5505987;-2.3203402;IRRE
scikit learn s transformers now support polars output with the set output api;-0.75605005;-5.0756106;-4.0598135;-0.64158005;-2.6912718;-0.6352746;IRRE
missing value support for random forest;1.9768107;-2.4747949;-4.7859077;1.8749205;2.2371278;-0.13727501;IRRE
the classes class ensemble randomforestclassifier and;3.923828;-7.395903;-2.134909;3.5246196;4.679057;-1.0466799;IRRE
class ensemble randomforestregressor now support missing values when training;3.5028894;-2.245513;-5.8762627;4.51834;1.4451853;0.67404234;IRRE
every individual tree the splitter evaluates each potential threshold with the;3.05971;-0.46088544;1.0522856;0.59673053;2.9933956;-2.0416932;-
missing values going to the left and right nodes more details in the;1.8694966;2.430598;1.4023489;-5.5777764;-2.2304065;-2.2161717;IRRE
ref user guide tree missing value support;-3.6695554;-0.8060781;-2.3858354;1.3827556;1.2552707;0.13750528;IRRE
add support for monotonic constraints in tree based models;1.7022998;-1.4488289;-1.481114;2.500192;4.818529;3.7140236;CODE
while we added support for monotonic constraints in histogram based gradient boosting;4.7389;-3.6762898;-0.86258537;-2.1727045;1.5761036;3.1907816;CODE
in scikit learn 0 23 we now support this feature for all other tree based models as;0.025761722;-7.5709233;-4.892454;1.7758666;1.176284;1.2289861;CODE
trees random forests extra trees and exact gradient boosting here we show this;3.1828735;-5.3223257;-0.7855445;0.90379494;3.0219207;0.70109636;CODE
feature for random forest on a regression problem;2.8151693;-4.8390746;-1.056083;2.2859173;1.4865772;0.17600416;CODE
enriched estimator displays;3.520777;-2.2354486;-0.05879665;1.2770641;0.88281214;3.6340847;-
estimators displays have been enriched if we look at forest defined above;1.964006;-2.7254755;0.39552885;2.426218;0.38254744;3.0007014;CODE
one can access the documentation of the estimator by clicking on the icon on;0.23277882;-3.658798;-0.62886006;2.7487154;-2.5290089;2.6660886;CODE
the top right corner of the diagram;-4.242838;-3.5594943;5.6437;-3.5690928;-1.6565757;-0.13317297;-
in addition the display changes color from orange to blue when the estimator is;-0.63787544;1.5236331;0.96348184;1.220518;-4.2163954;3.0542393;TASK
fitted you can also get this information by hovering on the icon i;1.2387135;-1.2203102;2.4117417;-1.4649444;-0.0020270303;2.74408;CODE
clone forest the clone is not fitted;-2.3190508;-0.53893274;-1.0692202;0.03681295;-1.6291075;0.79861724;CODE
metadata routing support;-2.8177567;-4.2345986;0.29562372;0.90060633;2.810527;5.079393;-
many meta estimators and cross validation routines now support metadata;0.9095853;-4.057814;-2.8301709;4.6635704;1.9364405;3.2223241;-
routing which are listed in the ref user guide;-3.9798625;-1.9539355;2.1511328;0.60747457;0.6426007;2.4140944;CODE
metadata routing models for instance this is how you can do a nested;0.4344538;-2.416049;3.262874;1.5054926;5.8736396;4.5644946;CODE
cross validation with sample weights and class model selection groupkfold;4.0356;-1.9895732;-2.9103825;4.148786;2.884033;0.55856794;CODE
for now by default metadata routing is disabled and need to be explicitly;-4.705565;-1.4610956;-2.1100516;1.0607725;-1.6065227;6.301184;CODE
enabled;-6.107847;-0.9835417;5.5528316;0.71067846;-0.1426276;-0.27809766;-
setting the flag to the default false to avoid interference with other;-2.6945791;6.1154747;-0.17864758;3.6626377;1.1644186;1.7697524;CODE
scripts;-3.4387228;-4.0084333;5.7345467;1.4871786;-0.6004519;-3.80785;CODE
improved memory and runtime efficiency for pca on sparse data;5.4408894;-1.3791283;-1.9116668;-2.5578122;0.84639806;4.332044;CODE
pca is now able to handle sparse matrices natively for the arpack;3.8571618;-3.66713;-3.9256995;-1.8154701;-0.07426242;5.7162166;CODE
solver by levaraging scipy sparse linalg linearoperator to avoid;3.2669566;-2.491163;-6.225375;-2.4780705;-3.3563716;3.9264524;CODE
materializing large sparse matrices when performing the;5.761957;-2.4156177;-0.9162068;-3.0652573;-1.3535309;5.494991;IRRE
eigenvalue decomposition of the data set covariance matrix;4.2406845;-2.253788;-2.6924796;-3.211234;-0.5618967;5.4794765;IRRE
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
fixedthresholdclassifier setting the decision threshold of a binary classifier;3.4552648;-1.9598057;-2.993089;2.0206904;2.8625305;1.6362804;IRRE
all binary classifiers of scikit learn use a fixed decision threshold of 0 5;3.6551726;-6.1698527;-6.3760786;0.086881265;0.20288035;-2.5996718;CODE
to convert probability estimates i e output of predict proba into class;3.7361357;-2.2823591;0.15032953;1.9179275;2.1982682;0.105831526;IRRE
predictions however 0 5 is almost never the desired threshold for a given;4.565485;1.2164104;-0.08842824;3.7364874;-1.8751377;-1.9137787;CODE
problem class model selection fixedthresholdclassifier allows wrapping any;0.09157835;-0.6536585;-4.1395698;4.245364;1.2007753;4.0011353;CODE
binary classifier and setting a custom decision threshold;3.4568665;-0.98758394;-1.8398445;0.6997665;4.7729893;0.35998273;IRRE
lowering the threshold i e allowing more samples to be classified as the positive;4.6103964;2.6232085;-0.970492;1.9410031;2.7854846;-0.46141505;IRRE
class increases the number of true positives at the cost of more false positives;3.294031;1.0004942;-1.1004803;3.656632;3.8647363;-2.6784093;IRRE
as is well known from the concavity of the roc curve;4.299505;-3.1523907;-2.2984889;0.6014754;0.29457068;0.7097709;CODE
tunedthresholdclassifiercv tuning the decision threshold of a binary classifier;5.1033115;-3.099622;-3.6544347;0.7956125;2.2572756;1.1126758;CODE
the decision threshold of a binary classifier can be tuned to optimize a;5.4798546;-3.414789;-1.1665543;2.7072246;5.155801;0.23298332;CODE
given metric using class model selection tunedthresholdclassifiercv;6.5605884;-2.7997313;-3.4959066;0.22868824;0.9881848;1.892769;CODE
it is particularly useful to find the best decision threshold when the model;4.9383087;-1.6689878;1.5471792;5.707542;2.5108197;0.9027021;CODE
is meant to be deployed in a specific application context where we can assign;-5.2914524;-2.7170932;0.50590074;1.3315879;2.8075461;5.0485835;IRRE
different gains or costs for true positives true negatives false positives;1.6077467;2.0289328;-0.34532303;3.272313;1.502471;-0.83784086;CODE
and false negatives;-0.87517196;1.5981103;0.60781795;2.099139;1.0300971;-3.523373;-
let s illustrate this by considering an arbitrary case where;-0.2909143;2.514639;5.0413637;-0.3082494;3.0690806;-1.1230868;CODE
each true positive gains 1 unit of profit e g euro year of life in good;0.26496497;0.06692604;2.8456326;-1.0792834;1.0374116;-1.0907382;-
health etc;-2.3396165;-1.966157;4.3646984;3.2128801;1.1887004;-2.0249927;-
true negatives gain or cost nothing;-0.20336573;1.9376426;0.82103914;2.3127785;-0.68489116;-0.5574733;-
each false negative costs 2;1.0714246;3.7351506;0.655634;1.0259179;1.2829766;-3.0746012;-
each false positive costs 0 1;2.6530552;4.9161882;-1.7544404;1.8004519;1.5624182;-3.5973775;-
our metric quantifies the average profit per sample which is defined by the;2.967592;0.022678325;2.4911706;0.019959036;0.8923153;0.20364349;CODE
following python function;0.6451297;1.4673622;2.311076;-4.448613;-2.962971;-5.8095336;CODE
it is interesting to observe that the average gain per prediction is negative;3.780163;-1.8059922;0.07732459;4.2310023;-2.7433448;1.76294;CODE
which means that this decision system is making a loss on average;1.8664243;0.058324616;2.5077484;3.876108;0.38007683;0.38961095;CODE
tuning the threshold to optimize this custom metric gives a smaller threshold;4.4144955;1.1568061;-2.3544028;1.4507923;-1.0358863;2.932962;CODE
that allows more samples to be classified as the positive class as a result;3.8823817;-1.079535;-1.4801161;2.9406962;4.9504137;-1.14371;IRRE
the average gain per prediction improves;6.0212545;-3.3576655;1.8322638;4.721226;-0.68164355;1.4519931;-
we observe that tuning the decision threshold can turn a machine;3.8512583;-2.543681;1.878347;5.318184;2.0930715;0.04945071;-
learning based system that makes a loss on average into a beneficial one;5.264983;-3.391301;2.9065297;2.8791971;1.2268203;1.3412825;CODE
in practice defining a meaningful application specific metric might involve;1.4417379;-3.774945;1.3514876;2.9249322;2.8303957;1.2303252;CODE
making those costs for bad predictions and gains for good predictions depend on;4.4056816;-1.9944777;1.2667737;6.7647576;0.87682295;1.484636;CODE
auxiliary metadata specific to each individual data point such as the amount;2.7413983;0.13501216;0.42449492;-2.7583373;5.334836;3.221448;CODE
of a transaction in a fraud detection system;1.5939524;0.8532212;2.0042987;1.340826;3.4148848;-1.5664501;CODE
to achieve this class model selection tunedthresholdclassifiercv;5.441807;-2.2907555;-2.308161;1.0198387;2.3492424;2.5893219;CODE
leverages metadata routing support ref metadata routing user;-3.9918427;-3.4785194;-1.0583285;1.3960013;1.1966313;5.391458;-
guide metadata routing allowing to optimize complex business metrics as;-0.17422837;-3.609696;0.4887908;-0.01899271;3.5685096;4.518886;META
detailed in ref post tuning the decision threshold for cost sensitive;3.2872097;-0.9976973;-1.2126347;6.005776;2.4398506;0.9185848;CODE
learning;2.7681262;-6.3071337;5.0328093;3.2895916;1.751312;-2.726696;-
sphx glr auto examples model selection plot cost sensitive learning py;3.5351653;-4.7805085;-3.221751;1.7167339;-1.7599643;2.8338747;CODE
performance improvements in pca;5.421635;-2.529503;-0.44467527;0.3859009;0.9292638;3.4340298;TASK
class decomposition pca has a new solver covariance eigh which is;3.5299027;-3.7608006;-3.7237003;-1.7618823;1.2975762;4.1209335;CODE
up to an order of magnitude faster and more memory efficient than the other;1.7539556;-3.6604786;2.7760603;0.7732504;1.2826445;0.08527978;IRRE
solvers for datasets with many data points and few features;6.763209;-3.4293196;-1.0246617;-1.4796968;0.53995365;1.4911727;CODE
the new solver also accepts sparse input data;4.299309;-2.7337854;-3.4854338;-1.6936928;-0.32475975;2.6269226;CODE
the full solver has also been improved to use less memory and allows;-0.7457788;-2.2021546;-0.7788906;0.18976873;-0.2528975;1.2305088;-
faster transformation the default svd solver auto option takes;2.2159073;-2.806084;-2.8825712;-1.6733459;-2.3892245;5.0592914;CODE
advantage of the new solver and is now able to select an appropriate solver;-0.85323393;-3.13671;0.4926775;1.581334;-0.16619071;0.96281004;CODE
for sparse datasets;8.260494;-5.974394;0.6143034;-0.44948798;2.117606;1.4071672;IRRE
similarly to most other pca solvers the new covariance eigh solver can leverage;3.7802765;-4.1771007;-3.2387128;-0.20248984;-0.37202868;4.5562053;CODE
gpu computation if the input data is passed as a pytorch or cupy array by;3.5735452;-0.49174175;-1.3063511;-3.3067634;-1.3764096;-1.2579696;CODE
enabling the experimental support for ref array api array api;-1.1689293;0.055930328;-3.2621043;2.2216733;-1.5857418;1.0778033;CODE
columntransformer is subscriptable;-1.2945976;2.6311965;-2.8176057;-2.642235;0.728061;1.6580567;CODE
the transformers of a class compose columntransformer can now be directly;-2.0259206;-0.22774662;-3.5208418;-0.7399815;1.9658122;4.462327;CODE
accessed using indexing by name;-1.7005832;-0.37739602;1.4232448;-1.0192374;3.075957;0.32999662;-
custom imputation strategies for the simpleimputer;2.1612294;0.9109865;0.13609788;4.135775;1.6707265;0.095951095;CODE
class impute simpleimputer now supports custom strategies for imputation;0.9868163;0.19825336;-1.2851962;4.4344926;1.8346916;1.9420565;CODE
using a callable that computes a scalar value from the non missing values of;1.9219456;4.9597864;-2.4627755;0.17628267;-0.13277595;1.1092827;IRRE
a column vector;3.9809225;-0.80148035;1.8797637;-7.7801766;-0.5501754;-1.0434318;-
ruff noqa cpy001 e501;-4.708646;0.40756392;-1.3329889;-4.0188212;0.8740261;-2.627956;-
frozenestimator freezing an estimator;0.62573355;2.0858362;-1.1864824;2.010853;-4.5644984;2.9872365;-
this meta estimator allows you to take an estimator and freeze its fit method meaning;1.7661937;-0.6028546;0.27234015;4.0265746;-1.5071063;3.9517918;IRRE
that calling fit does not perform any operations also fit predict and;3.3479104;1.5267761;-5.239895;3.0198128;-2.1699302;0.006543532;CODE
fit transform call predict and transform respectively without calling fit the;5.341606;1.4152616;-1.0815494;0.860275;-1.3289795;3.9439325;IRRE
original estimator s other methods and properties are left unchanged an interesting;1.2130847;-0.9238977;-1.0071787;5.10792;-2.4879127;4.7065134;CODE
use case for this is to use a pre fitted model as a transformer step in a pipeline;0.16899046;-0.47595558;1.2959615;2.3264494;1.4729515;4.7215147;CODE
or to pass a pre fitted model to some of the meta estimators here s a short example;2.253108;-0.80015224;0.4043811;6.101315;0.7028005;5.4258294;-
fitting the threshold classifier skipped fitting the inner sgdclassifier for more;3.8775702;-1.9404796;-4.912753;0.62222916;0.3220453;3.399333;CODE
details refer to the example ref sphx glr auto examples frozen plot frozen examples py;-2.9627988;-1.6511722;-1.6922725;-1.8586459;-6.0112553;2.4595675;-
transforming data other than x in a pipeline;2.5637949;1.0783947;0.5844102;-2.7706146;1.1000409;1.5278031;CODE
the class pipeline pipeline now supports transforming passed data other than x;0.25059974;-0.81969315;-2.3898976;0.8783979;2.8821025;2.8965569;CODE
if necessary this can be done by setting the new transform input parameter this;-0.5630718;1.5301697;0.20448256;-2.7476933;0.11493001;6.2793164;CODE
is particularly useful when passing a validation set through the pipeline;0.8908468;0.53544873;-1.4539472;6.1573176;2.0036883;1.3667902;IRRE
as an example imagine estimatorwithvalidationset is an estimator which accepts;0.17956284;-0.47014406;-0.80390567;4.9734006;0.24119204;3.8818464;IRRE
a validation set we can now have a pipeline which will transform the validation set;2.2327673;0.17685962;-0.6703585;2.636221;3.3448746;2.2628036;CODE
and pass it to the estimator;1.5165539;0.83140105;1.2663523;3.9215996;-0.7355456;3.9968238;-
with sklearn config context enable metadata routing true;-2.067073;-3.906902;-5.7998943;1.3577578;-2.6464503;5.0926495;-
est gs gridsearchcv;0.73091006;-1.1569304;-0.10555959;-0.8507046;-0.25219944;0.5674398;-
pipeline;-0.8097781;-2.598836;3.7243078;2.2196195;1.0183095;-0.63482714;CODE
standardscaler;-1.471461;-0.61137253;1.1097614;0.824753;-0.07388229;0.61834574;-
estimatorwithvalidationset set fit request x val true y val true;2.7272542;3.548565;-2.3273866;3.0938334;-2.0596144;2.588064;IRRE
telling pipeline to transform these inputs up to the step which is;0.31885594;1.5843132;1.3140626;-0.3260703;0.5944758;0.9594573;CODE
requesting them;-3.7746503;-3.1422107;3.6748695;0.78901;0.71284574;-0.68638396;CODE
transform input x val;0.7713195;2.461696;2.4694867;-5.499474;-1.7176023;-2.1869295;CODE
param grid estimatorwithvalidationset param to optimize list range 5;5.157176;2.3947043;-1.7696807;1.0951251;-0.014925445;2.7806451;IRRE
cv 5;-0.44392782;-2.5586972;1.3383509;0.11390944;2.1126435;-2.1683054;-
fit x y x val x val y val y val;3.762645;1.9155632;2.0049794;-4.041349;-1.1598355;-1.050939;-
in the above code the key parts are the call to set fit request to specify that;-1.1332755;2.0445597;-2.124195;0.42226022;-0.39309877;5.9589667;IRRE
x val and y val are required by the estimatorwithvalidationset fit method and;2.4483702;2.6123421;-2.7762806;0.4689712;-1.9481077;0.99437976;IRRE
the transform input parameter to tell the pipeline to transform x val before;-0.5401228;2.4309719;-0.5082989;-1.3600746;-1.4282956;2.1341147;CODE
passing it to estimatorwithvalidationset fit;2.9013937;2.2334177;-2.2942078;3.9396572;-1.2972367;5.039335;IRRE
note that at this time scikit learn estimators have not yet been extended to accept;3.1309178;-9.080506;-5.300292;3.1166766;-5.022828;0.95490503;TASK
user specified validation sets this feature is released early to collect feedback;-0.38226378;-1.7141664;-1.013074;6.1177382;1.670907;0.87058663;TASK
from third party libraries who might benefit from it;-3.744437;-7.8499813;0.44299555;1.9821688;1.4480035;0.15850276;CODE
multiclass support for logisticregression solver newton cholesky;3.1497667;-5.429239;-5.5553293;1.3168157;1.1119127;1.7240119;CODE
the newton cholesky solver originally introduced in scikit learn version;1.2985548;-7.777681;-4.4840517;-1.5200531;-4.460798;-0.6965349;CODE
1 2 was previously limited to binary;-2.9990404;0.31125876;-3.4518054;-2.6568527;1.932332;-3.7604773;-
class linear model logisticregression and some other generalized linear;2.8263156;-3.1910753;-2.5968115;0.67347234;1.6931443;2.9806104;IRRE
regression estimators namely class linear model poissonregressor;2.029949;-2.3133419;-0.69450647;2.9270082;-0.9127461;2.7710226;IRRE
class linear model gammaregressor and;0.125355;-0.89189285;-1.8319254;0.4737832;-0.18044545;3.0378957;IRRE
class linear model tweedieregressor;1.2716624;-1.566831;-3.4144208;-0.5523394;0.15332028;3.7137303;IRRE
this new release includes support for multiclass multinomial;-0.9702755;-5.0805793;-2.6271389;-0.0081205685;4.6778116;1.3191338;CODE
class linear model logisticregression;2.9594293;-1.9384986;-2.8751078;0.662767;0.9947503;0.26693362;IRRE
this solver is particularly useful when the number of features is small to;3.7655232;-2.762136;-0.82310534;-0.64488333;1.2538984;0.6419749;TASK
medium it has been empirically shown to converge more reliably and faster;3.373178;-3.523783;0.9726932;2.2420921;-2.0371845;2.4165852;IRRE
than other solvers on some medium sized datasets with one hot encoded;6.2725325;-2.1313198;-2.734203;-2.109033;0.5539274;0.013303965;IRRE
categorical features as can be seen in the benchmark results of the;4.7741623;-5.6285214;0.11754342;0.8031891;2.49172;-1.3681866;TASK
pull request;-4.4110374;-1.7090198;3.4401467;3.2529159;0.07084318;0.17161115;CODE
https github com scikit learn scikit learn pull 28840 issuecomment 2065368727;-3.2602863;-8.761318;-7.38708;-0.7639019;-5.666885;-3.1926613;CODE
missing value support for extra trees;-0.29987836;0.16209699;-3.801912;-0.4657298;3.2378273;0.19538696;IRRE
the classes class ensemble extratreesclassifier and;3.2876546;-6.304779;-2.4928815;2.2555354;6.219597;-0.37380555;IRRE
class ensemble extratreesregressor now support missing values more details in the;0.8794381;-1.0550245;-4.870933;2.51941;2.957927;2.1195405;IRRE
ref user guide tree missing value support;-3.6695554;-0.8060781;-2.3858354;1.3827556;1.2552707;0.13750528;IRRE
download any dataset from the web;1.3535995;-4.319593;1.5691065;-0.021060523;0.008704458;-0.2100011;CODE
the function func datasets fetch file allows downloading a file from any given url;-1.2136894;-3.4795644;-0.12525624;2.1128428;-1.258739;0.7724985;CODE
this convenience function provides built in local disk caching sha256 digest;-2.7209675;-1.3696024;-1.7168801;0.35086307;0.6315189;2.2011793;CODE
integrity check and an automated retry mechanism on network error;-1.8418021;1.1258577;-0.9973828;3.8022597;-0.36642987;-0.61120516;CODE
the goal is to provide the same convenience and reliability as dataset fetchers while;2.36028;-4.1493306;0.33582368;5.1447387;3.1974094;1.6676666;IRRE
giving the flexibility to work with data from arbitrary online sources and file;0.3586676;-4.189038;0.11676585;0.46943313;2.6966684;1.1699885;CODE
formats;-1.9291362;-4.589128;2.4385664;-2.039227;3.878188;-2.544834;CODE
the downloaded file can then be loaded with generic or domain specific functions such;-4.5301;-3.069669;-0.9036854;0.56016284;0.52257913;3.607388;CODE
as pandas read csv pandas read parquet etc;1.5977281;-3.7633214;-0.84568715;-1.4756701;-0.94059736;-1.4140178;CODE
array api support;-1.2046576;-0.6906439;0.20753631;0.13437688;0.36315432;0.28347576;CODE
many more estimators and functions have been updated to support array api compatible;1.7047983;-1.8943177;-2.1237762;1.3051509;-1.8023732;2.585878;CODE
inputs since version 1 5 in particular the meta estimators for hyperparameter tuning;2.9867942;-2.167407;-2.7021837;3.654418;-0.05198052;2.3117774;CODE
from the mod sklearn model selection module and the metrics from the;5.8042216;-6.3183556;-3.886042;2.074954;-0.13997725;1.131735;CODE
mod sklearn metrics module;1.8736343;-5.8889627;-4.219404;-0.9426962;-2.8531249;0.099893644;CODE
please refer to the ref array api support array api page for instructions to use;-2.306548;1.4190357;-0.23653722;-1.4707123;-0.42310634;1.6150194;CODE
scikit learn with array api compatible libraries such as pytorch or cupy;1.9599652;-9.213049;-5.489313;-2.3723767;-4.0326443;-3.1721673;CODE
almost complete metadata routing support;-2.337824;-4.1596804;-0.28867084;1.2963557;3.210654;4.7439218;CODE
support for routing metadata has been added to all remaining estimators and;-1.539812;-3.3610182;-1.4574612;2.4046044;0.015147855;6.350657;CODE
functions except adaboost see ref metadata routing user guide metadata routing;-4.781687;-3.1835134;-3.1958892;0.99240875;1.0673624;3.9837627;CODE
for more details;-3.480828;-3.12476;4.442992;1.1291379;0.046866957;-1.9306489;CODE
free threaded cpython 3 13 support;-3.824539;-3.2535064;-2.6415875;-1.6207026;-2.7897317;0.30002096;CODE
scikit learn has preliminary support for free threaded cpython in particular;-1.3163888;-8.402197;-3.2259808;0.7150722;-4.282619;-1.1841215;CODE
free threaded wheels are available for all of our supported platforms;-3.2974393;-3.2095342;-0.8875726;-1.3493801;-0.0503135;2.1814194;CODE
free threaded also known as nogil cpython 3 13 is an experimental version of;-3.6935833;-3.8604844;-1.7364321;-0.91918725;-1.9580938;-0.41996592;CODE
cpython 3 13 which aims at enabling efficient multi threaded use cases by;-2.0410879;-3.0876732;-2.139079;0.09003478;-0.78220624;-0.39610553;CODE
removing the global interpreter lock gil;-6.074043;-0.7172053;-2.1722484;1.2606246;-3.3896058;0.9072261;CODE
for more details about free threaded cpython see py free threading doc https py free threading github io;-2.7128718;-4.9323072;-1.7571137;-0.90563136;-3.9001534;-0.26744;CODE
in particular how to install a free threaded cpython https py free threading github io installing cpython;-3.7076457;-5.6261477;-2.6331954;-0.007820842;-4.6503086;-0.6099318;CODE
and ecosystem compatibility tracking https py free threading github io tracking;-3.5964427;-6.035788;-2.3396945;2.7289934;-3.0537672;0.6295051;CODE
feel free to try free threaded cpython on your use case and report any issues;-3.5847313;-2.8538356;-2.6386263;0.81595814;-4.3932266;-0.13831657;CODE
improvements to the developer api for third party libraries;-4.6030483;-7.4722505;-1.8463668;2.5164113;-1.3373346;-0.0017063172;CODE
we have been working on improving the developer api for third party libraries;-5.5114336;-6.6264358;-2.4139616;2.0738802;-1.7011471;-0.17956214;CODE
this is still a work in progress but a fair amount of work has been done in this;-2.4241674;-2.5350745;2.945687;3.1979187;0.25927895;0.087661155;CODE
release this release includes;-3.7960217;-4.6482043;2.6558557;2.915492;1.1019833;-0.44240528;CODE
func sklearn utils validation validate data is introduced and replaces the;1.6142695;-0.55890113;-5.845875;2.7227638;-1.8545125;-2.7483926;CODE
previously private baseestimator validate data method this function extends;1.2328054;4.071731;-3.3488429;2.8369346;0.99474126;1.5599699;CODE
func sklearn utils validation check array and adds support for remembering;2.4175186;0.19112527;-4.9424744;3.5986245;-0.87075764;-2.8908389;TASK
input feature counts and names;1.4569921;-1.1720921;2.2009926;-0.036150124;4.042717;-4.2831435;TASK
estimator tags are now revamped and a part of the public api via;-0.8694621;-1.5039093;-2.0844162;5.6594977;-0.6512738;4.726364;CODE
class sklearn utils tags estimators should now override the;1.1512614;-3.9019473;-6.307;4.3893447;-2.0119498;2.937696;CODE
meth baseestimator sklearn tags method instead of implementing a more tags;2.0120218;-3.0091355;-3.6250832;2.6591136;-0.52654886;3.438344;TASK
method if you d like to support multiple scikit learn versions you can implement;1.0938206;-10.547619;-3.2495067;1.6903378;-0.11277955;-1.8846687;TASK
both methods in your class;-1.4650524;-0.1435776;3.3487275;1.9556748;2.6648028;-1.5727856;IRRE
as a consequence of developing a public tag api we ve removed the xfail checks;-6.2013273;0.23975223;-2.85859;4.1902714;-0.6077534;1.9265107;CODE
tag and tests which are expected to fail are directly passed to;-2.753426;4.1480355;-2.8583992;8.246225;0.8541855;-2.7015314;IRRE
func sklearn utils estimator checks check estimator and;1.7942786;0.046548408;-6.791849;3.635971;-5.311618;-2.233282;IRRE
func sklearn utils estimator checks parametrize with checks see their;2.640673;-0.34991175;-6.816209;2.397479;-3.9436638;-1.5206819;-
corresponding api docs for more details;-3.9688847;-6.870914;0.61142915;1.7828735;3.0133402;0.39031175;CODE
many tests in the common test suite are updated and raise more helpful error;-0.874091;2.1467462;-4.1730466;5.9858847;-1.4880229;-3.1107695;CODE
messages we ve also added some new tests which should help you more easily fix;-3.5457606;2.7442467;-2.5265505;4.524115;-3.8076212;-1.9311739;TASK
potential issues with your estimators;3.07185;0.993384;0.6358099;5.1921163;-2.8193097;1.6499718;-
an updated version of our ref develop is also available which we recommend you;-4.258871;-5.634091;1.7357017;3.8398566;0.45988217;1.4643449;CODE
check out;-1.9581459;-3.9909241;2.81665;1.3851308;-0.73789805;-1.4092523;-
ruff noqa cpy001;-3.4845154;0.25593638;0.54420626;-3.7498913;1.2983233;-2.7533321;-
improved estimator s html representation;1.9422418;-1.946065;1.9247237;0.27324343;0.60842466;2.9417548;-
the html representation of estimators now includes a section containing the list of;-0.7505896;-2.9424114;1.62654;1.8795164;1.0179487;3.0538425;CODE
parameters and their values non default parameters are highlighted in orange a copy;-3.224499;1.816088;-1.5504055;0.07325539;-0.41705993;2.3794785;IRRE
button is also available to copy the fully qualified parameter name without the;-5.8508825;0.11210372;-0.23865403;2.2455602;1.5087245;4.4131317;IRRE
need to call the get params method it is particularly useful when defining a;-3.353503;2.4343543;1.6383642;1.7622293;2.3399942;0.7383102;CODE
parameter grid for a grid search or a randomized search with a complex pipeline;5.314446;-0.2083133;0.9668032;-0.49453723;3.0664403;2.5397327;IRRE
see the example below and click on the different estimator s blocks to see the;1.7350585;0.28496543;-0.6672424;1.0653601;-2.122428;3.892582;IRRE
improved html representation;0.10125461;-3.704498;4.279331;-2.7806354;2.600465;0.38150305;-
custom validation set for histogram based gradient boosting estimators;4.59189;-2.0205886;-1.8309726;0.63229626;1.2396601;2.3497427;IRRE
the class ensemble histgradientboostingclassifier and;5.2949743;-6.0855775;-2.2988346;2.4844365;4.9486237;1.3903048;IRRE
class ensemble histgradientboostingregressor now support directly passing a custom;0.9227922;-2.979125;-5.2311544;4.409163;3.4359205;5.126821;IRRE
validation set for early stopping to the fit method using the x val y val and;3.5839264;3.1820714;-0.7980488;3.4755468;-1.9635084;0.24203785;IRRE
sample weight val parameters;4.5708838;2.1777992;-1.2003406;-0.16487825;0.018275844;1.1595752;IRRE
in a class pipeline pipeline the validation set x val can be transformed along;1.3451637;1.6494503;-2.7275488;1.4673971;1.9256012;1.7573137;CODE
with x using the transform input parameter;-0.7767096;1.8666186;2.0799172;-4.6245046;-1.5825287;0.09267242;CODE
plotting roc curves from cross validation results;4.046864;-2.1866934;0.14319693;-1.7280143;-2.8149445;-1.3425807;IRRE
the class class metrics roccurvedisplay has a new class method from cv results;4.577322;-5.607469;-4.311569;1.1673181;2.90697;-0.36229834;CODE
that allows to easily plot multiple roc curves from the results of;4.0505037;-4.8762083;1.6370503;-0.7726114;0.5369233;-0.29735386;IRRE
func model selection cross validate;2.6038425;1.731443;-3.4052808;4.1740236;3.3906271;-0.331865;CODE
array api support;-1.2046576;-0.6906439;0.20753631;0.13437688;0.36315432;0.28347576;CODE
several functions have been updated to support array api compatible inputs since;-1.148769;-0.49908337;-1.3790555;-1.0744115;-0.90275484;-0.16865228;CODE
version 1 6 especially metrics from the mod sklearn metrics module;2.616454;-6.8101482;-5.046744;-0.12290856;-2.617598;-0.38742948;CODE
in addition it is no longer required to install the array api compat package to use;-3.8939283;-0.7816514;-4.215947;-1.0830371;-2.870189;1.9699056;CODE
the experimental array api support in scikit learn;2.339566;-8.242338;-4.439477;0.18706596;-2.9872277;-3.5427728;CODE
please refer to the ref array api support array api page for instructions to use;-2.306548;1.4190357;-0.23653722;-1.4707123;-0.42310634;1.6150194;CODE
scikit learn with array api compatible libraries such as pytorch or cupy;1.9599652;-9.213049;-5.489313;-2.3723767;-4.0326443;-3.1721673;CODE
improved api consistency of multi layer perceptron;3.1357813;-2.2003381;-1.3530728;3.1966858;-0.17143717;3.0815005;CODE
the class neural network mlpregressor has a new parameter loss and now supports;3.1561844;-4.2758;-2.2431097;1.825082;1.4233395;2.3484747;IRRE
the poisson loss in addition to the default squared error loss;1.4788227;0.39175794;-0.96034;1.8913239;-3.0894725;2.9138765;TASK
moreover the class neural network mlpclassifier and;5.334371;-6.1560216;-1.1937703;0.56051;4.263195;-0.0027332157;IRRE
class neural network mlpregressor estimators now support sample weights;4.206648;-4.231362;-3.254732;2.8905945;0.71827126;3.1548111;IRRE
these improvements have been made to improve the consistency of these estimators;3.5230377;-0.8621284;-0.70142454;4.174715;-1.8890252;3.622135;TASK
with regard to the other estimators in scikit learn;3.9536076;-7.659625;-2.7078335;3.1651359;-3.4477222;0.22872569;-
migration toward sparse arrays;5.2213697;-1.7254595;-0.3357597;-2.5722697;-0.15395778;2.2434282;IRRE
in order to prepare scipy migration from sparse matrices to sparse arrays https docs scipy org doc scipy reference sparse migration to sparray html;2.4589107;-4.1614933;-4.531062;-3.742265;-4.159644;1.9650302;CODE
all scikit learn estimators that accept sparse matrices as input now also accept;5.0415664;-7.3363175;-5.7538924;-1.1066301;-3.645111;3.0682907;IRRE
sparse arrays;5.9125643;-0.4345232;0.79275924;-4.059527;0.42668748;0.13745837;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
we use the digits dataset we only use a subset of randomly selected samples;6.642074;-0.9703699;0.055949382;0.15794685;3.765121;-1.0708463;IRRE
we selected 340 samples of which only 40 will be associated with a known label;3.871464;0.5644299;-0.35577792;1.2045159;4.689557;-2.4549332;CODE
therefore we store the indices of the 300 other samples for which we are not;5.0612435;1.6652955;-0.28942168;-1.9372032;3.753073;-1.3467672;CODE
supposed to know their labels;0.08261049;-3.3622322;1.8028108;0.63940305;1.747472;-2.4075174;-
shuffle everything around;1.8622441;0.25811774;5.6278896;-0.8171204;2.1872227;0.3479854;-
semi supervised learning;4.9431305;-4.928143;1.5019518;0.96489626;4.161848;1.2862939;CODE
we fit a class sklearn semi supervised labelspreading and use it to predict;4.4327493;-4.989166;-0.8774182;2.3661404;1.7071326;0.30841562;CODE
the unknown labels;1.3901877;-2.3405027;2.3710432;-0.42626444;3.1861317;-2.7059615;-
classification report;2.9042482;-5.3412213;1.0542725;0.0040878984;4.5067835;-3.3571596;IRRE
confusion matrix;3.0279129;1.6355293;1.4027631;-3.788848;1.6128027;-3.3469574;-
plot the most uncertain predictions;5.9234133;-0.45938912;4.264777;2.1196914;-5.125076;-1.294113;META
here we will pick and show the 10 most uncertain predictions;2.5574315;-0.5985252;2.2521157;4.7645054;-0.60836583;-1.9747721;META
pick the top 10 most uncertain labels;3.9365463;-0.0045806966;2.784552;0.4985858;3.2079415;-1.8130492;META
plot;-0.1530007;-0.22087865;8.818623;-3.4865117;-5.8780794;-3.9504418;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
compute the entropies of transduced label distributions;2.982914;-1.6272316;-0.2543514;-2.0572784;2.7706726;1.3806617;META
select up to 5 digit examples that the classifier is most uncertain about;5.313326;-0.19957276;-1.1546042;1.1285592;5.406444;-4.42261;CODE
keep track of indices that we get labels for;4.010366;-1.2467188;1.2070496;-1.9134393;3.4312255;0.64465255;CODE
for more than 5 iterations visualize the gain only on the first 5;4.3292336;0.34815875;4.9065533;-2.5524828;-0.21827783;-0.9612509;CODE
for more than 5 iterations visualize the gain only on the first 5;4.3292336;0.34815875;4.9065533;-2.5524828;-0.21827783;-0.9612509;CODE
labeling 5 points remote from labeled set;2.8227625;-0.5206524;3.539502;-3.6204906;3.375566;-0.54920316;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we generate a dataset with two concentric circles in addition a label;6.383609;-2.0015402;4.6096077;-4.617453;1.6244628;1.2660024;TASK
is associated with each sample of the dataset that is 0 belonging to;3.8128164;1.0060483;-0.7250668;-2.0439625;1.6039678;-1.4382585;IRRE
the outer circle 1 belonging to the inner circle and 1 unknown;-1.5213019;0.6806902;3.1014545;-2.8932528;-0.029792335;-1.0092124;TASK
here all labels but two are tagged as unknown;-2.5264132;-1.2281837;0.22177921;-1.326573;3.4987705;-0.9454768;META
plot raw data;2.9729936;-0.7934863;4.4540024;-5.784595;-5.2344227;-1.4886422;-
the aim of class sklearn semi supervised labelspreading is to associate;3.187411;-5.6316566;-1.8469088;1.2218909;2.5758443;1.1341074;CODE
a label to sample where the label is initially unknown;3.544704;2.3258095;1.3966473;2.332161;4.420639;-1.1172711;IRRE
now we can check which labels have been associated with each sample;3.8855593;-1.0459682;0.7132502;0.27580392;5.6197805;-0.7353184;-
when the label was unknown;-1.3139012;-1.5570004;-0.48611426;1.14282;0.39065596;-1.2813743;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we need manual cross validation so that we don t treat 1 as a separate;1.5799823;2.2389598;-1.1267028;3.251907;5.0165167;0.09100804;CODE
class when computing accuracy;4.805797;-2.1971545;-1.5681936;1.774385;1.9613601;-3.1989064;IRRE
the amount of labeled samples that at the end of fitting;5.620019;0.13784987;1.543155;0.5281942;1.789295;-0.33005425;CODE
the last iteration the classifier labeled a sample in;4.6864324;-1.6357058;0.3366072;1.5668241;4.517644;-2.1034653;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
loading dataset containing first five categories;3.0677187;-2.0774326;0.8207179;0.07419294;2.6825025;-0.09701769;IRRE
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
supervised pipeline;5.123097;-3.4325564;1.1554325;2.486615;4.3216577;1.113479;CODE
selftraining pipeline;1.4382925;-3.5516272;0.7105902;3.3874598;1.3973064;2.0983417;CODE
labelspreading pipeline;1.432816;-2.6503088;1.2516469;1.4592112;2.9956412;2.601304;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
y 10 y rand 0 1 1 set random samples to be unlabeled;3.019208;1.6104945;0.11351144;-1.6410421;0.6586586;-0.4498977;IRRE
we observe that the decision boundaries are already quite similar to those;1.5047797;-2.1616085;3.8707058;4.472448;3.7111928;2.397677;CODE
using the full labeled data available for training even when using a very;5.42005;-1.8093412;-0.234329;2.279791;3.8864024;0.8165698;CODE
small subset of the labels;4.743379;0.28976932;2.1404712;-2.760954;3.9301667;-0.013715543;IRRE
interpretation of predict proba;1.3893118;-0.99662465;1.8593887;3.693872;-0.028034251;-2.2574859;CODE
predict proba in labelspreading;4.183799;-2.1499345;2.4726582;3.4687963;2.2082286;-0.22880161;CODE
class sklearn semi supervised labelspreading constructs a similarity graph;4.0354514;-4.932936;-1.5024356;-0.71595675;2.4512515;0.901058;CODE
from the data by default using an rbf kernel this means each sample is;5.470294;-0.8550362;-2.2094657;-0.9605288;2.2475975;0.22312984;CODE
connected to every other with a weight that decays with their squared;0.9135884;0.42277083;2.7469342;-1.6134151;-0.6537837;2.8066373;-
euclidean distance scaled by a parameter gamma;2.2539937;-0.109884;1.671681;-2.9470096;-3.5475087;4.8568435;IRRE
once we have that weighted graph labels are propagated along the graph;3.1689298;-1.9238861;1.8181008;-1.0208355;1.5811293;5.47799;-
edges each sample gradually takes on a soft label distribution that reflects;4.904725;-1.2819109;1.4465063;-0.7493545;1.02405;3.7331605;META
a weighted average of the labels of its neighbors until the process converges;6.0712113;-0.7193422;2.6972196;-0.34371838;-0.3798634;3.9331408;-
these per sample distributions are stored in label distributions;4.1786675;-2.4671633;1.1040418;-1.2077816;4.435378;1.0744549;META
predict proba computes the class probabilities for a new point by taking a;3.3814166;-1.8156016;0.75132424;2.346268;1.4162862;-0.23140031;CODE
weighted average of the rows in label distributions where the weights come;5.661238;-0.74230057;1.732683;-2.1535883;0.99286664;2.9865434;META
from the rbf kernel similarities between the new point and the training;4.2720566;-5.349051;-0.3363426;0.15128998;1.529104;3.7242296;CODE
samples the averaged values are then renormalized so that they sum to one;4.564604;2.0794127;0.6763571;0.33226728;-1.7628828;1.7879478;IRRE
just keep in mind that these probabilities are graph based scores not;3.8085306;-0.5763641;1.0994225;-0.23348603;1.2536299;-1.8348674;-
calibrated posteriors don t over interpret their absolute values;1.8740665;2.7078903;-1.0941207;-0.06344941;-2.9461598;2.2060623;IRRE
ls ls100 0 fitted labelspreading instance;0.059725385;0.21684237;-1.3103886;-1.0185878;-0.65914744;3.8321242;CODE
x query np array 3 5 1 5 point in the soft blue region;1.5945692;1.9739854;-0.9528193;-8.542932;-1.1613038;-0.1406791;CODE
step 1 similarities between query and all training samples;3.9494164;-3.870344;-0.06497354;2.3764217;5.073289;-0.028044745;CODE
w rbf kernel x query x gamma ls gamma gamma 20 by default;-1.335797;-0.95442045;-3.1787517;-1.4823192;0.567475;2.5015707;CODE
step 2 weighted average of label distributions;4.1188984;-0.75280684;1.1563342;-0.78532237;1.4917047;0.7778207;META
step 3 normalize to sum to 1;0.62109494;2.56475;1.3971139;-4.2240534;-0.18313742;-2.0762286;-
predict proba in selftrainingclassifier;3.9661639;-4.2490296;-1.1012112;4.2702403;2.4610982;-0.5691748;CODE
class sklearn semi supervised selftrainingclassifier works by repeatedly;1.6501776;-3.5585663;-4.6371474;2.6145191;0.13923353;0.1518324;CODE
fitting its base estimator on the currently labeled data then adding;5.421811;0.8779692;0.6547247;0.5660557;2.0010502;3.9730387;TASK
pseudo labels for unlabeled points whose predicted probabilities exceed a;5.642084;0.22975545;-0.36144847;-0.87977475;2.35352;1.0448713;CODE
confidence threshold this process continues until no new points can be;3.2753007;3.323986;1.1673867;3.1591883;-1.1488097;0.34386832;CODE
labeled at which point the classifier has a final fitted base estimator;3.2899997;-0.695614;-0.019458568;0.50515324;2.2465737;3.364908;CODE
stored in the attribute estimator;1.8284725;0.30041102;0.38522068;1.092004;0.99356925;3.7130022;META
when you call predict proba on the selftrainingclassifier it simply;1.0599406;-4.235361;-1.1537127;4.8097463;2.0212889;0.3014623;IRRE
delegates to this final estimator;-0.011097388;1.0984935;1.4093637;4.318963;0.26537484;2.945754;CODE
in both methods semi supervised learning can be understood as constructing a;3.6518657;-5.330869;-0.6910302;1.569828;5.617029;1.700566;CODE
categorical distribution over classes for each sample;3.8727634;-2.327309;0.8330471;-0.4094165;5.463208;-0.9730581;CODE
class sklearn semi supervised labelspreading keeps these distributions soft and;3.5016994;-4.89917;-3.6877258;1.943941;0.78854114;2.4992554;CODE
updates them through graph based propagation;4.3838124;-2.5757723;2.8813515;-1.3348913;2.608175;2.729582;IRRE
predictions including predict proba remain tied to the training set which;3.48093;-2.0321758;0.9102916;5.1437545;0.17356732;1.6386906;IRRE
must be stored for inference;-0.087731585;0.84308267;0.22951072;5.5786157;4.5430813;-0.33497572;TASK
class sklearn semi supervised selftrainingclassifier instead uses these;1.4996134;-5.593101;-4.91428;1.318422;1.1298134;1.0794301;CODE
distributions internally to decide which unlabeled points to assign pseudo labels;4.821409;-0.07355871;-0.5096824;-2.3445272;5.0766973;2.8072338;CODE
during training but at prediction time the returned probabilities come directly from;3.969271;-1.9545007;0.08138304;5.188034;-0.3831149;1.5852638;CODE
the final fitted estimator and therefore the decision rule does not require storing;1.8473108;1.4701102;-2.1851363;3.6165614;0.06500814;5.01638;CODE
the training data;6.2866516;-6.8216796;3.0471172;3.5380445;3.1636884;-1.6623942;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
x iris data 2 we only take the first two features we could;1.63284;-2.0328658;0.3314175;-2.640448;2.2432783;0.35197845;TASK
avoid this ugly slicing by using a two dim dataset;5.6505284;0.41535735;-1.670328;-3.7766712;0.829954;1.8157729;CODE
h 0 02 step size in the mesh;-0.2500239;1.8169311;-0.86498314;-4.0664797;-2.629466;0.98154175;CODE
we create an instance of svm and fit out data;7.4843535;-3.61922;0.93860364;-1.662195;3.2397053;3.1894798;IRRE
plot also the training points;3.8571665;-4.4865284;5.091605;-1.1665463;-2.758238;-0.3909035;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
take the first two features we could avoid this by using a two dim dataset;6.1046786;0.20271997;-0.32770404;-0.46202117;2.1446722;3.4255276;CODE
we create an instance of svm and fit out data we do not scale our;6.189518;-2.2416284;0.080349885;-1.4455386;0.21263263;4.2799997;IRRE
data since we want to plot the support vectors;4.9941196;-4.1989913;3.6230276;-3.1477208;-1.5611058;1.3018637;-
c 1 0 svm regularization parameter;3.6151488;-0.8371925;-4.12869;-3.4027054;-0.3198955;4.2349753;IRRE
title for the plots;-2.0247223;-4.1743655;7.7277465;-1.7129519;-2.2795992;-0.35375;CODE
set up 2x2 grid for plotting;0.57082975;-0.22628881;4.562585;-6.835409;-3.8791664;2.5753164;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
hinge is the standard svm loss;2.1534054;-3.0470073;-1.137018;0.0211632;-0.061655875;3.784051;-
obtain the support vectors through the decision function;5.0979567;-2.5135748;-0.8136709;-1.4341475;3.5501978;1.9985803;CODE
we can also calculate the decision function manually;3.7296803;-2.1976326;1.5392774;2.0747955;3.1147194;-0.6214017;CODE
decision function np dot x clf coef 0 clf intercept 0;1.3707831;0.32727188;-5.330679;-3.687396;-2.5623217;0.49860287;CODE
the support vectors are the samples that lie within the margin;3.6254466;-3.2106736;-0.017927354;-1.6155678;1.0859683;2.78914;CODE
boundaries whose size is conventionally constrained to 1;-0.20091733;2.4507482;1.9243498;-2.7894797;1.1485386;1.8370072;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
generate train data;5.008639;-1.8013539;2.768107;-1.4555813;1.9937072;-1.5770701;-
generate some regular novel observations;6.6711416;-2.3114767;1.4646629;0.69427294;0.13626361;0.4097774;-
generate some abnormal novel observations;5.389696;-1.1086786;1.1809517;1.1423573;-0.67577666;-1.1810746;-
fit the model;1.4823507;-1.8818413;3.3056061;0.78029215;0.8633571;-0.14115278;-
generate grid for the boundary display;0.23182817;0.36342782;5.7962866;-6.0948567;-0.53924525;2.7666054;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
utility class to move the midpoint of a colormap to be around;-0.7612437;-0.72515994;2.4045227;-1.9329892;-0.26289576;5.28111;CODE
the values of interest;1.2636983;-0.8218635;5.5033884;0.26488417;2.001857;-3.3590713;IRRE
load and prepare data set;3.702953;1.0051816;2.207295;-0.011917469;2.82568;-0.5606152;IRRE
dataset for grid search;5.764509;-3.7256544;1.6812007;-2.3577528;2.2899349;-0.17809986;IRRE
dataset for decision function visualization we only keep the first two;5.519864;-2.3746052;3.8966787;-1.5990015;1.8576717;0.7745374;CODE
features in x and sub sample the dataset to keep only 2 classes and;4.8148136;-0.16762646;0.3264197;-1.0933005;5.656123;-0.12919758;IRRE
make it a binary classification problem;4.702529;-2.5440238;2.199157;-0.6632781;6.4810886;-4.6010957;IRRE
it is usually a good idea to scale the data for svm training;6.151762;-4.0505075;1.1405522;-0.14876205;0.73809415;3.9115233;CODE
we are cheating a bit in this example in scaling all of the data;7.3927813;0.06042285;0.31715363;-2.8651156;-1.9576728;2.3640301;CODE
instead of fitting the transformation on the training set and;4.9057913;-2.3077707;-0.797763;0.48754823;-0.6083978;4.4555306;CODE
just applying it on the test set;0.47543857;0.5054974;-0.42146662;3.2204537;2.3000119;-3.3256803;IRRE
train classifiers;5.7955775;-5.735298;1.0241892;1.9356142;4.704562;-1.5685767;IRRE
for an initial search a logarithmic grid with basis;4.314332;1.3412023;0.4265704;-5.31144;0.9519482;0.9188065;IRRE
10 is often helpful using a basis of 2 a finer;2.5851257;0.45109117;1.9789327;-1.8099197;2.754404;-1.0211748;-
tuning can be achieved but at a much higher cost;2.4729998;-1.7842166;1.8240445;2.5717425;-0.19178447;2.484757;META
now we need to fit a classifier for all parameters in the 2d version;4.177859;-2.0803306;-1.3656839;-1.6370474;2.129094;3.4864318;CODE
we use a smaller set of parameters here because it takes a while to train;4.2768297;-2.1707888;1.0421747;3.4354877;1.1656282;2.501952;IRRE
visualization;2.0263047;-4.579504;9.384692;-3.0934663;-0.12108519;-0.48344862;-
draw visualization of parameter effects;0.8785664;-2.434224;5.1112127;-2.6493208;-3.2850308;3.302971;IRRE
evaluate decision function in a grid;3.8821843;1.4368485;1.7273177;-1.1323557;1.38396;-0.8593234;CODE
visualize decision function for these parameters;3.9043903;-0.46187794;4.144054;-3.279453;1.3394227;0.20980294;CODE
visualize parameter s effect on decision function;2.1060727;-0.95783633;3.7340472;0.18749434;0.2510184;2.02594;IRRE
draw heatmap of the validation accuracy as a function of gamma and c;5.044687;-0.760951;0.50581896;-0.7833473;-2.324918;-0.34083274;CODE
the score are encoded as colors with the hot colormap which varies from dark;2.320909;-1.6621497;0.816192;-1.5148555;0.45642465;-1.8071239;CODE
red to bright yellow as the most interesting scores are all located in the;0.63379663;-1.1974943;3.889832;0.5045287;0.2322981;-3.3637514;CODE
0 92 to 0 97 range we use a custom normalizer to set the mid point to 0 92 so;0.4308739;2.9398751;1.6401838;-4.69167;-1.5896125;1.1908493;IRRE
as to make it easier to visualize the small variations of score values in the;5.5982056;-1.1443086;4.3882146;-0.5913199;0.74808186;-1.3133075;IRRE
interesting range while not brutally collapsing all the low score values to;5.2330832;2.0986211;0.9450655;-0.31007725;-0.43734333;-1.8237147;IRRE
the same color;-1.2113643;-1.1744584;6.0426497;-0.64668196;2.1765714;-2.2924075;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
we create 40 separable points;2.6043136;0.40586916;3.544998;-3.7681704;2.8843668;0.6947844;IRRE
fit the model don t regularize for illustration purposes;3.0136793;1.1132884;0.32089847;0.10834047;-3.0896146;6.1530805;CODE
plot the decision function;2.1335628;-0.74811876;5.5165462;-1.8124596;-1.9001198;-1.6515182;CODE
plot support vectors;4.434234;-3.539865;3.3952534;-5.312818;-3.4101791;1.4564376;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we create two clusters of random points;4.7309303;-2.081519;4.2512717;-2.0087693;1.1578994;1.9678487;IRRE
fit the model and get the separating hyperplane;4.5343733;0.32549846;0.55627245;-2.7661514;1.116888;3.069498;-
fit the model and get the separating hyperplane using weighted classes;6.1365423;-1.0004256;-0.96543115;-1.438944;2.7005177;3.117619;IRRE
plot the samples;4.3572598;0.22809322;6.451375;-3.9092667;-4.141;-2.9082193;-
plot the decision functions for both classifiers;4.5367928;-3.6510806;1.4445972;-1.0340797;0.68509614;0.0834036;CODE
plot decision boundary and margins for weighted classes;5.5705547;-2.3819435;2.5224879;-2.1603656;0.7048715;2.3965049;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load some data to play with;1.0889428;0.03831516;5.0863624;-0.063490316;1.5745188;-0.039808832;CODE
add non informative features;0.35916013;-3.541385;0.7297755;1.8133823;3.4625146;1.3009118;TASK
create the pipeline;-2.5362973;-2.87728;2.3451545;1.056672;1.5555975;0.28700012;IRRE
create a feature selection transform a scaler and an instance of svm that we;4.8865414;-2.9009998;0.5836272;-1.7309972;0.9005263;4.923873;IRRE
combine together to have a full blown estimator;3.143206;2.1980753;2.4231331;2.615161;0.041184377;2.792324;-
plot the cross validation score as a function of percentile of features;4.3370934;-0.76496965;1.1586733;-1.7506472;-2.8774996;-0.38693428;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
creating a dataset;5.481897;-3.7172587;3.279065;-2.6376154;3.6190655;-2.6184857;IRRE
we create a two dimensional classification dataset with 16 samples and two classes we;6.2009764;-3.9131122;2.1654315;-2.7599382;5.241685;-0.8905661;IRRE
plot the samples with the colors matching their respective targets;4.5016327;-0.025972476;4.282949;-2.5156524;-2.311073;-1.4910554;-
plotting settings;0.7116444;-0.8828169;6.7459135;-4.7980638;-5.8296146;3.0196729;IRRE
plot samples by color and add legend;1.8209283;0.07527631;3.5074184;-2.4502506;-2.235518;-0.8064424;TASK
we can see that the samples are not clearly separable by a straight line;3.9854958;1.7338185;-2.4596922;-2.219079;-1.9491593;0.12541692;META
training svc model and plotting decision boundaries;5.9859715;-4.6488805;1.844169;-0.8708338;0.26831618;1.6469485;-
we define a function that fits a class sklearn svm svc classifier;4.966099;-5.271124;-3.6060154;-0.8838572;2.3843515;1.8140187;CODE
allowing the kernel parameter as an input and then plots the decision;2.7489154;-1.9448762;2.0372837;-0.3500023;-1.4838746;2.9578903;IRRE
boundaries learned by the model using;3.7959163;-2.8878598;4.7298517;2.1148944;2.1266286;1.3062372;-
class sklearn inspection decisionboundarydisplay;2.1462605;-3.2814744;-5.498066;3.225892;1.0280868;-1.1215799;IRRE
notice that for the sake of simplicity the c parameter is set to its;-1.4200934;2.053714;-2.0387952;-3.5891109;-4.6016564;-0.37032753;IRRE
default value c 1 in this example and the gamma parameter is set to;-2.253022;2.1474638;-0.26230457;-2.0543914;-2.4612057;0.7771957;CODE
gamma 2 across all kernels although it is automatically ignored for the;-1.6176989;-1.2371355;-3.7091076;0.17324546;-2.1947145;3.7948723;IRRE
linear kernel in a real classification task where performance matters;6.5733385;-4.8999734;-0.21474186;1.3434482;2.5997744;2.207264;CODE
parameter tuning by using class sklearn model selection gridsearchcv for;4.8705583;-3.2153618;-5.1417303;1.439573;-0.57901126;1.1977006;CODE
instance is highly recommended to capture different structures within the;-0.15243274;-2.4114807;2.3148363;3.3291612;4.5632515;2.7766974;CODE
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
setting response method predict in;2.0761483;1.1188282;0.97303736;5.5798635;-1.5904553;1.455254;IRRE
class sklearn inspection decisionboundarydisplay colors the areas based;2.6123445;-3.170467;-2.140803;0.047181252;1.1145651;-1.144407;IRRE
on their predicted class using response method decision function allows;4.331126;-3.8044517;0.16329777;4.825315;2.39935;-0.92616737;CODE
us to also plot the decision boundary and the margins to both sides of it;-0.058178607;-2.812301;7.173503;0.5838778;0.7595565;0.49684113;-
finally the support vectors used during training which always lay on the;2.5255787;-4.2580485;0.2804021;2.2224746;1.3799857;3.498293;CODE
margins are identified by means of the support vectors attribute of;1.5516877;-2.3897307;-0.383071;-2.0956862;1.4583253;3.863351;META
the trained svcs and plotted as well;3.7052057;-8.3263445;2.3047318;-0.8400045;-1.6200058;0.19483054;-
train the svc;1.8886081;-4.9883957;0.8136987;1.5138286;1.4123605;-0.4545071;CODE
settings for plotting;-0.97355;-1.7503767;5.7508235;-3.6975417;-6.5997715;2.731916;IRRE
plot decision boundary and margins;2.0331354;-1.1347705;5.131728;-2.8596244;-1.7984273;1.720626;-
plot bigger circles around samples that serve as support vectors;6.124253;-2.3360937;2.882661;-3.1533427;-3.3546808;3.3595223;-
plot samples by color and add legend;1.8209283;0.07527711;3.507418;-2.4502501;-2.235517;-0.8064435;TASK
linear kernel;2.7029963;-2.6358125;1.4614744;-3.0062566;-0.33245054;0.87882316;-
linear kernel is the dot product of the input samples;4.0088153;-4.0606613;-1.7838949;-3.0236554;-0.84375936;3.1997056;CODE
math k mathbf x 1 mathbf x 2 mathbf x 1 top mathbf x 2;2.7430243;-0.7312511;0.19770837;-6.2172117;0.8724354;-1.5574893;-
it is then applied to any combination of two data points samples in the;5.689624;-0.50788665;0.35443717;-1.6608832;3.4597847;0.17328168;CODE
dataset the dot product of the two points determines the;6.5213766;-1.7473644;1.3012766;-5.157068;-0.8647134;-0.2658866;CODE
func sklearn metrics pairwise cosine similarity between both points the;4.143291;-2.6614597;-1.8802745;-2.6888633;-3.556663;0.9084998;CODE
higher the value the more similar the points are;5.527913;1.973505;4.515885;-3.9687128;0.22855382;-0.20908612;IRRE
training a class sklearn svm svc on a linear kernel results in an;3.9349346;-4.2935796;-5.158576;-1.1209408;-1.2301686;0.9209546;IRRE
untransformed feature space where the hyperplane and the margins are;0.9583026;-1.6418235;-1.8469311;-2.2420554;-0.52337116;4.150189;TASK
straight lines due to the lack of expressivity of the linear kernel the;0.66384536;-0.823437;0.24147253;-3.8825586;-1.8573148;2.259369;-
trained classes do not perfectly capture the training data;2.6218479;-0.44527072;-2.965721;2.4833174;-0.15573898;-0.7674935;CODE
polynomial kernel;0.8433255;-2.8571596;0.5495783;-2.7499032;1.1217259;1.4562536;-
the polynomial kernel changes the notion of similarity the kernel function;1.9075739;-3.7553263;-0.13958657;-1.2103099;1.5096457;4.607208;CODE
is defined as;-2.384841;1.0458473;2.6701653;0.99140847;3.899577;0.3897218;CODE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
k mathbf x 1 mathbf x 2 gamma cdot;-0.4612481;-1.3413227;-0.64040387;-6.4371324;-0.22710234;-1.2713044;CODE
mathbf x 1 top mathbf x 2 r d;3.1915376;0.7256078;1.6977557;-6.3413005;0.1586887;-1.9664799;-
where math d is the degree degree of the polynomial math gamma;-2.4409502;-1.5577381;0.7366577;-3.0948076;0.59976494;0.3293634;-
gamma controls the influence of each individual training sample on the;2.0919924;-2.7448823;2.616871;4.3253093;1.1685244;0.79271644;-
decision boundary and math r is the bias term coef0 that shifts the;1.95017;-2.0498312;0.16014066;1.4999791;0.76748955;0.6566963;-
data up or down here we use the default value for the degree of the;2.2039604;0.20191553;1.0444545;-3.0531242;0.88541013;-1.3550575;CODE
polynomial in the kernel function degree 3 when coef0 0 the default;-1.1246985;-1.1665227;-4.398703;-2.9765916;-0.98621565;3.1237907;CODE
the data is only transformed but no additional dimension is added using a;3.2973545;2.5816326;-1.2760888;-5.679276;-2.6929348;2.3589633;TASK
polynomial kernel is equivalent to creating;-0.18330531;-3.322605;-0.70319605;-1.1932124;1.7210279;3.847252;-
class sklearn preprocessing polynomialfeatures and then fitting a;4.2938495;-3.7744443;-4.6846104;-1.2824715;-1.1819348;-0.032115463;TASK
class sklearn svm svc with a linear kernel on the transformed data;4.150537;-5.0796514;-4.6571655;-2.7404575;-2.3275712;3.928021;CODE
although this alternative approach would be computationally expensive for most;4.824404;-2.4761064;0.50690967;1.4008294;3.2848155;3.2393377;CODE
datasets;5.8192816;-6.7717977;3.9816425;-0.06131241;2.8893921;-3.2005186;IRRE
the polynomial kernel with gamma 2 adapts well to the training data;3.9269981;-6.8576627;-1.6957976;-0.4508614;0.66789407;3.5700338;-
causing the margins on both sides of the hyperplane to bend accordingly;-0.471145;-0.26056716;1.1616318;-1.8025863;-2.392297;2.888154;CODE
rbf kernel;-0.10199441;-4.331177;-2.1373515;-1.3932155;0.40402398;0.7544479;-
the radial basis function rbf kernel also known as the gaussian kernel is;1.612874;-3.3360977;-1.1817362;-4.136995;-0.74791604;4.1553507;CODE
the default kernel for support vector machines in scikit learn it measures;4.3990293;-10.291599;-4.0587;1.953719;-0.70097595;0.22825901;CODE
similarity between two data points in infinite dimensions and then approaches;6.829336;1.0434821;1.9768283;-4.5747924;-0.5728182;2.6624203;IRRE
classification by majority vote the kernel function is defined as;3.2136722;-4.055737;-1.721228;-0.85847026;4.750682;1.7057979;CODE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
k mathbf x 1 mathbf x 2 exp left gamma cdot;-1.2531587;-0.36531505;-1.5601834;-5.5146213;-1.4655261;-0.09585582;CODE
mathbf x 1 mathbf x 2 2 right;0.22761117;0.8897122;0.6977615;-6.690628;0.5634679;-2.932538;-
where math gamma gamma controls the influence of each individual;-0.38807315;-1.6371088;4.313299;0.9551452;-0.88896835;0.26973414;-
training sample on the decision boundary;5.8336;-3.1083176;2.1132023;4.5031734;5.7678823;-0.30757228;-
the larger the euclidean distance between two points;2.4337876;-0.43342105;3.881757;-2.199103;-3.1959724;1.9404927;CODE
math mathbf x 1 mathbf x 2 2;0.33116993;0.67389077;0.5220497;-6.2055993;0.9009945;-3.2369704;-
the closer the kernel function is to zero this means that two points far away;1.8625424;-0.22058383;0.104170255;-3.7171993;-4.3240094;2.4355145;CODE
are more likely to be dissimilar;1.9612533;-0.09621937;1.4591535;2.5079975;1.7300384;0.30138522;-
in the plot we can see how the decision boundaries tend to contract around;1.2390764;-2.2044408;5.6170654;1.8027173;-1.6918855;1.7515392;CODE
data points that are close to each other;6.2964807;1.038191;4.3962407;-4.93968;-0.02937853;0.40513462;CODE
sigmoid kernel;4.44448;-4.903092;-1.2130815;-2.9329543;-0.5712314;3.137034;-
the sigmoid kernel function is defined as;2.5446465;-4.704723;-1.7019583;-2.4821773;0.13293383;4.0434537;CODE
math;1.0833545;-1.5695436;6.690605;-0.83639866;-0.32606563;-7.173556;-
k mathbf x 1 mathbf x 2 tanh gamma cdot;-0.9026096;-0.9904232;-0.3704997;-6.660002;-1.034694;-1.618384;CODE
mathbf x 1 top mathbf x 2 r;2.74669;1.1008619;1.6919602;-6.350088;0.12894903;-2.3673825;-
where the kernel coefficient math gamma gamma controls the influence;0.7100804;-3.9177601;0.4958865;-0.6450403;-2.1546898;3.0513818;-
of each individual training sample on the decision boundary and math r is;5.3205924;-2.3321812;1.6092259;2.4589815;4.4556427;-1.6620771;-
the bias term coef0 that shifts the data up or down;4.122641;-1.2131593;-0.94522536;0.4121759;-1.2380643;2.3330057;CODE
in the sigmoid kernel the similarity between two data points is computed;6.6964655;-3.686914;-1.0865015;-3.694386;-0.32164824;2.93039;CODE
using the hyperbolic tangent function math tanh the kernel function;-1.6529918;-1.807474;0.790611;-2.3143594;-3.3250585;2.4385023;CODE
scales and possibly shifts the dot product of the two points;2.854142;-0.13051732;2.6155453;-5.1332307;-3.7627828;3.7053137;CODE
math mathbf x 1 and math mathbf x 2;0.3618546;0.8254741;0.34003007;-4.8705983;1.1123278;-2.4526548;-
we can see that the decision boundaries obtained with the sigmoid kernel;5.5101013;-4.515633;-1.0245708;0.1530089;1.6440623;3.1866355;-
appear curved and irregular the decision boundary tries to separate the;0.72988683;-0.75968903;2.5953112;-0.53781694;-0.25161362;1.9899975;-
classes by fitting a sigmoid shaped curve resulting in a complex boundary;4.6355424;-2.6799977;1.4991692;-2.1113682;0.9191834;3.4270449;IRRE
that may not generalize well to unseen data from this example it becomes;5.8220325;0.405308;0.5128885;0.8207984;2.1853971;0.8125416;CODE
obvious that the sigmoid kernel has very specific use cases when dealing;3.0831196;-4.445811;-3.0452;1.847189;-0.40254554;3.458362;CODE
with data that exhibits a sigmoidal shape in this example careful fine;6.3930664;-0.5196525;0.53167677;-3.6156702;-0.103505306;1.582993;CODE
tuning might find more generalizable decision boundaries because of its;4.438999;-2.7258286;0.9139669;4.7555604;3.5378592;2.8732014;-
specificity the sigmoid kernel is less commonly used in practice compared to;3.5025494;-6.130743;-1.7468935;0.6309443;0.610691;3.405216;IRRE
other kernels;-0.2576207;-6.226898;0.74327904;-0.43260458;0.55905676;1.0110625;-
conclusion;-1.7600391;1.0903363;5.187226;3.933175;0.70637393;-3.3991342;-
in this example we have visualized the decision boundaries trained with the;2.5670075;-3.303129;5.792171;1.7402529;2.9468644;-0.11610344;CODE
provided dataset the plots serve as an intuitive demonstration of how;4.9935603;-5.5069494;6.2208376;-1.5018864;-2.6970367;0.6871469;IRRE
different kernels utilize the training data to determine the classification;5.440195;-6.121794;-0.9822763;1.9227053;2.6669974;1.8794388;IRRE
boundaries;-1.6434424;-1.002054;7.6815934;-0.08176462;1.2331918;-1.6635784;-
the hyperplanes and margins although computed indirectly can be imagined as;1.0250486;-2.0959795;0.78792626;-2.5780435;0.7254334;3.3075242;-
planes in the transformed feature space however in the plots they are;1.052006;-1.2579577;1.2461666;-4.5594087;-5.884336;5.342707;CODE
represented relative to the original feature space resulting in curved;1.1372287;-3.599127;1.3656175;-2.4378076;-0.56422746;5.9706798;TASK
decision boundaries for the polynomial rbf and sigmoid kernels;5.096943;-4.5715733;-2.42623;-1.4499679;2.355541;3.2899485;CODE
please note that the plots do not evaluate the individual kernel s accuracy or;4.2385955;-3.067316;-0.8419041;-1.8908075;-6.214549;0.1812994;TASK
quality they are intended to provide a visual understanding of how the;0.39865068;-3.098654;3.5748937;0.60818267;1.3579258;-0.42124403;CODE
different kernels use the training data;3.9848096;-5.4914412;-1.1041044;1.0660442;0.9687884;2.6942456;IRRE
for a comprehensive evaluation fine tuning of class sklearn svm svc;5.4416094;-5.2087235;-4.7577114;0.81366605;0.48936597;0.24986881;CODE
parameters using techniques such as;2.679702;-0.051577646;2.7434547;0.45462045;2.9760306;0.40234125;IRRE
class sklearn model selection gridsearchcv is recommended to capture the;3.0933704;-4.139094;-4.2632732;1.9398054;-0.6718417;0.15821691;CODE
underlying structures within the data;4.8197308;-1.8942678;2.655399;-1.5689185;5.9129715;0.6643647;CODE
xor dataset;3.5603669;-4.361247;-0.23450226;-3.1077418;1.109875;0.15254934;IRRE
a classical example of a dataset which is not linearly separable is the xor;2.7869809;-0.7270481;-1.4108546;-2.4815955;0.7013638;2.5873334;IRRE
pattern here we demonstrate how different kernels work on such a dataset;7.469677;-4.3694005;-0.7536215;-1.7827076;1.5343605;0.91752267;IRRE
as you can see from the plots above only the rbf kernel can find a;-0.855459;-2.7534602;-2.5792572;-2.591494;-3.6573107;1.2473681;CODE
reasonable decision boundary for the above dataset;7.8429527;-1.527639;1.8001014;1.8709842;4.3092594;0.5936878;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we create 40 separable points;2.6043136;0.40586916;3.544998;-3.7681704;2.8843668;0.6947844;IRRE
figure number;-1.0815421;1.6458988;4.5318594;-2.910963;-1.2616036;-2.8169334;-
fit the model;1.4823511;-1.8818417;3.3056083;0.780294;0.86335677;-0.14115296;-
get the separating hyperplane;2.5293767;0.05700953;1.0520486;-4.999097;0.755174;2.0702198;-
plot the parallels to the separating hyperplane that pass through the;1.8371677;-1.0384785;3.0297236;-4.344633;-3.1275532;2.1013699;-
support vectors margin away from hyperplane in direction;2.2224967;-1.9935935;-0.5321238;-2.4521523;-0.9780619;4.18218;CODE
perpendicular to hyperplane this is sqrt 1 a 2 away vertically in;-1.1811602;-0.4539205;3.175831;-4.5796027;-2.6101248;0.6268216;CODE
2 d;-1.0313914;0.4899042;4.9117785;-3.8950133;1.1814548;-3.6708436;-
plot the line the points and the nearest vectors to the plane;1.5128524;-1.599634;4.0188537;-3.5900824;-4.2008457;-0.17444815;CODE
put the result into a contour plot;0.3016401;1.2603238;6.627513;-3.0065951;-4.2512426;-0.3944781;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
add noise to targets;1.5080409;-0.466762;1.2343596;2.5179448;-0.38013557;2.7145147;TASK
fit regression model;2.8170338;0.28139204;2.8969915;0.29012498;-2.5641077;-0.055165276;-
look at the results;2.5092244;-0.38132167;3.4986203;2.1920757;-0.2511635;-5.1504464;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
data generation;5.0167174;-2.095578;4.733889;-0.584793;4.4981813;-3.6965108;-
in this example we investigate the effect of reparametrizing the regularization;2.8756611;-0.29194176;-0.09549505;0.26270902;0.00502224;6.809471;CODE
parameter c to account for the number of samples when using either l1 or l2;4.021424;3.3135283;-0.09878898;-1.6768013;1.573621;-0.9935321;IRRE
penalty for such purpose we create a synthetic dataset with a large number of;7.2470565;-3.4191113;-0.5709153;1.89332;2.6909525;0.5201395;IRRE
features out of which only a few are informative we therefore expect the;1.9464707;-4.897145;1.0659258;4.2903724;2.802716;0.5941147;CODE
regularization to shrink the coefficients towards zero l2 penalty or exactly;4.286106;-0.1638231;-2.4296749;-0.72289234;-0.90094686;6.8130546;-
zero l1 penalty;-0.923862;3.4817336;-0.86886543;0.67858374;-0.846064;0.4824687;-
l1 penalty case;-1.651011;2.4400365;0.614566;1.827909;1.1144505;0.5958769;CODE
in the l1 case theory says that provided a strong regularization the;0.74262774;-0.63204545;-2.2169082;2.4473991;2.1888325;5.413709;CODE
estimator cannot predict as well as a model knowing the true distribution;0.5116596;0.5304024;-3.1659825;4.953669;-3.9053926;1.3208028;META
even in the limit where the sample size grows to infinity as it may set some;1.8447925;2.1007333;1.5675353;3.2190819;-0.42278966;0.39725357;IRRE
weights of otherwise predictive features to zero which induces a bias it does;3.2360897;-0.68123984;-3.297484;2.023322;-0.5747753;3.4675875;TASK
say however that it is possible to find the right set of non zero parameters;3.9154017;4.6909895;0.19399649;-2.8286896;2.3204658;-0.930319;IRRE
as well as their signs by tuning c;0.9251202;-1.0391335;2.0060818;1.0833316;-0.9256451;-1.5246634;-
we define a linear svc with the l1 penalty;2.7419543;-1.6533666;-2.8768575;-0.8828407;1.0440848;5.631458;CODE
we compute the mean test score for different values of c via;3.3934422;1.3860323;-0.022083318;-0.1385884;0.20219547;-4.016009;IRRE
cross validation;2.493245;1.2475493;2.397642;1.889912;3.7310712;-3.8565283;-
plot results without scaling c;4.639069;1.1273048;3.4161062;-4.5925736;-8.013692;1.7099445;IRRE
plot results by scaling c;4.803995;0.12683482;3.3870516;-5.525936;-8.006607;1.2868887;IRRE
in the region of small c strong regularization all the coefficients;2.22676;-1.194551;-1.8300356;-1.7554382;-1.288407;5.6719995;CODE
learned by the models are zero leading to severe underfitting indeed the;3.763869;-2.592038;-2.7295482;5.820489;-0.84644115;-0.14831279;-
accuracy in this region is at the chance level;3.9046698;0.24290252;1.6494026;3.2730036;-1.7800401;-2.078729;CODE
using the default scale results in a somewhat stable optimal value of c;4.15704;1.1785804;-1.2195714;-1.2738646;-4.910464;3.54213;IRRE
whereas the transition out of the underfitting region depends on the number of;3.2145386;1.1135808;-1.3703078;0.8787201;-0.002567976;4.10048;CODE
training samples the reparametrization leads to even more stable results;6.90351;-3.1209602;-2.6753867;1.8644849;-0.92283773;3.8267245;IRRE
see e g theorem 3 of arxiv on the prediction performance of the lasso;4.0486355;-4.5012217;-2.9453669;3.04816;-1.4279308;4.7196245;CODE
1402 1700 or arxiv simultaneous analysis of lasso and dantzig selector;3.6421807;-2.8660452;-3.3450863;0.9513688;-0.4762422;2.5501719;CODE
0801 1095 where the regularization parameter is always assumed to be;0.61451197;1.6882563;-5.5303535;-1.6300517;0.5032647;2.1084237;IRRE
proportional to 1 sqrt n samples;3.8523705;0.79285973;1.3341042;-1.2485925;-1.7531219;0.4777981;-
l2 penalty case;-1.2554121;2.0109603;1.0617149;1.8400387;1.7730751;0.64460003;CODE
we can do a similar experiment with the l2 penalty in this case the;1.0795624;1.2367904;0.5445537;5.6393313;0.27797404;2.0220606;CODE
theory says that in order to achieve prediction consistency the penalty;2.7668798;-0.44353783;-0.4933278;7.752437;1.0499363;3.8157692;-
parameter should be kept constant as the number of samples grow;4.3268547;4.464927;0.6513499;1.1452289;-0.90141517;2.6596408;IRRE
plot results without scaling c;4.639069;1.1273048;3.4161062;-4.5925736;-8.013692;1.7099445;IRRE
plot results by scaling c;4.803995;0.12683482;3.3870516;-5.525936;-8.006607;1.2868887;IRRE
for the l2 penalty case the reparametrization seems to have a smaller impact;1.0343438;0.17818911;-1.9551067;2.5245695;0.23913875;6.6747165;CODE
on the stability of the optimal value for the regularization the transition;3.665538;0.050361995;0.10321159;0.68207455;-0.0134578;7.537324;IRRE
out of the overfitting region occurs in a more spread range and the accuracy;5.423927;-0.0966235;-0.8423331;2.3802087;-1.7971847;1.7924784;CODE
does not seem to be degraded up to chance level;-0.72362405;0.25925708;-0.21594238;4.7719493;-1.0261196;0.17440297;CODE
try increasing the value to n splits 1 000 for better results in the l2;3.2396424;2.3380055;-2.8029876;-1.5255284;-1.5121555;-0.59992087;CODE
case which is not shown here due to the limitations on the documentation;-6.408054;-1.8199296;-0.83419967;1.1732775;3.6483157;-0.6100692;CODE
builder;-2.7343287;-3.4962957;4.23085;0.35797173;2.3601506;-2.1307387;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
down sample for plotting;4.5322456;0.61688256;4.477624;-2.5173159;-3.6833022;-1.3518646;CODE
we define constant weights as expected by the plotting function;2.629598;0.9027066;1.4880911;-2.0227625;-3.5383518;4.646754;CODE
assign random weights to all points;5.7795076;-0.65176994;2.3962476;-1.3980751;1.4549003;2.723105;IRRE
assign bigger weights to the positive class;4.0041475;0.5832305;-0.14491922;-0.31407064;2.216884;1.7559067;IRRE
this model does not include sample weights;2.002342;-0.9994605;-2.2163827;2.3261414;-0.28340057;0.92511463;CODE
this other model includes sample weights;3.4007423;-1.9363809;0.16980767;2.8685374;2.2688203;1.5959901;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
loading and vectorizing the 20 newsgroups text dataset;3.6790428;-4.038685;2.1734133;-0.6109828;1.4459198;1.3364002;CODE
we define a function to load data from ref 20newsgroups dataset which;1.7294269;-1.0334381;0.91860914;0.8922872;1.836478;1.7904551;CODE
comprises around 18 000 newsgroups posts on 20 topics split in two subsets;1.7033906;-1.255095;3.3193448;0.63455945;2.8630474;0.12604049;CODE
one for training or development and the other one for testing or for;-1.1787797;-5.059084;1.9394333;2.945756;2.4937558;-3.840217;CODE
performance evaluation note that by default the text samples contain some;2.9671016;0.02775819;-1.7264462;3.2180161;3.523793;-2.242209;CODE
message metadata such as headers footers signatures and quotes;-5.360706;-2.4701526;-1.4151422;0.028946642;2.9263453;1.8074603;IRRE
to other posts the fetch 20newsgroups function therefore accepts a;-3.2838125;1.8399415;0.28774953;1.9812367;1.0598704;0.38629502;CODE
parameter named remove to attempt stripping such information that can make;-2.9669857;4.7904034;-1.222995;1.3561491;1.3168397;0.7952642;IRRE
the classification problem too easy this is achieved using simple;6.2741103;-2.4548895;2.2934623;-0.81436163;6.301793;-1.4374996;CODE
heuristics that are neither perfect nor standard hence disabled by default;-1.6113536;-0.2526596;-1.6007594;3.7157476;0.17894349;0.33096924;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
loading text data;-1.0885556;-0.4021618;4.186525;0.093899935;0.11242501;-0.44516024;CODE
we load data from ref 20newsgroups dataset which comprises around 18 000;2.9145663;-1.6873602;0.95206654;-0.0008042944;1.4032859;0.7191274;CODE
newsgroups posts on 20 topics for illustrative purposes and to reduce the;-0.9978787;-2.5750406;3.6753469;2.9303918;1.5024362;0.67991567;CODE
computational cost we select a subset of 4 topics only accounting for around;4.592472;-1.578539;1.1423994;1.5120057;3.842168;1.2229458;CODE
3 400 documents see the example;-2.1863072;-2.2356153;1.0466825;-0.7554999;4.168184;-1.9992381;CODE
ref sphx glr auto examples text plot document classification 20newsgroups py;-1.2089274;-4.959172;-2.3596518;-1.0553254;-1.696311;1.1293918;CODE
to gain intuition on the overlap of such topics;1.10081;-3.717359;4.91162;3.3270435;2.8875735;2.413212;CODE
notice that by default the text samples contain some message metadata such;-3.2380068;-0.529602;-4.0910444;2.2449977;-0.23462382;0.5904656;CODE
as headers footers signatures and quotes to other posts we use;-5.2264376;-2.4422057;0.24726456;-0.38049436;3.6291568;1.3338202;IRRE
the remove parameter from func sklearn datasets fetch 20newsgroups to;1.9279169;-1.1511446;-3.65861;1.1227384;-1.2934774;-0.053164408;IRRE
strip those features and have a more sensible clustering problem;4.88832;-2.1541684;-0.044227242;0.26529256;2.4288318;3.2391572;TASK
quantifying the quality of clustering results;5.439665;-1.9211586;0.5746469;1.9871061;1.3541744;0.41302854;IRRE
in this section we define a function to score different clustering pipelines;4.2463884;-2.020942;-0.2415574;1.4351119;4.1006937;2.4951873;CODE
using several metrics;4.7460165;-0.45433396;3.1437366;-0.54485863;2.0380964;0.75645924;-
clustering algorithms are fundamentally unsupervised learning methods;5.31205;-5.5886207;-0.6590497;1.1741186;1.4719311;3.3152332;CODE
however since we happen to have class labels for this specific dataset it is;2.9787424;-3.9711063;-2.7312758;0.053970102;4.6472006;1.6910251;CODE
possible to use evaluation metrics that leverage this supervised ground;5.597057;-3.4255362;0.38960454;4.322661;4.864078;1.6522968;CODE
truth information to quantify the quality of the resulting clusters examples;5.3767595;-0.9989642;-0.14927708;1.5282658;2.7209332;-0.9180576;IRRE
of such metrics are the following;2.9317234;-0.59213966;2.3579068;-2.5867991;0.019095268;0.62204945;-
homogeneity which quantifies how much clusters contain only members of a;4.8589926;1.3559133;0.11276298;-2.5207276;2.1346211;0.5981176;-
single class;-0.696655;-2.3782032;2.6206808;1.479112;5.6257324;-1.7901796;IRRE
completeness which quantifies how much members of a given class are;1.7655649;0.15533228;0.11788542;2.0195737;5.674283;-1.737872;CODE
assigned to the same clusters;2.3711135;-0.66630477;1.893466;-1.9046615;3.8740652;1.4688104;IRRE
v measure the harmonic mean of completeness and homogeneity;2.2869685;0.9605299;0.21894835;1.7898058;-0.07997648;3.9481118;CODE
rand index which measures how frequently pairs of data points are grouped;6.958072;-1.5472972;2.710481;-3.1834931;1.7359804;-0.60672593;IRRE
consistently according to the result of the clustering algorithm and the;6.1599693;0.74363977;-0.011761284;2.493584;0.99681735;0.013449565;IRRE
ground truth class assignment;0.70464075;1.0794184;-1.7471219;0.9533251;4.5412216;-2.326933;IRRE
adjusted rand index a chance adjusted rand index such that random cluster;3.1728148;0.032709282;-0.717674;0.12805328;1.0862435;2.383935;IRRE
assignment have an ari of 0 0 in expectation;-1.0284932;3.3488135;-0.94666696;-2.210812;-0.8303313;-1.1286575;IRRE
if the ground truth labels are not known evaluation can only be performed;2.1294312;2.5594919;-2.9467485;1.8724266;3.9355729;-1.1534046;CODE
using the model results itself in that case the silhouette coefficient comes in;1.023013;0.274699;-0.33177572;0.38449952;-2.424602;3.4746678;CODE
handy see ref sphx glr auto examples cluster plot kmeans silhouette analysis py;2.6555173;-3.9029205;-1.709972;-3.1809912;-3.3945582;2.2076619;-
for an example on how to do it;-0.6990193;-2.904411;6.6458397;-2.8671107;1.2730601;-1.5040816;CODE
for more reference see ref clustering evaluation;3.7778795;-3.0316088;0.6167537;1.949294;2.8814282;1.2450091;CODE
k means clustering on text features;4.2003636;-3.079158;1.52816;-1.0032196;1.3213559;0.74231815;TASK
two feature extraction methods are used in this example;3.7735002;-1.7902043;1.3683687;-1.4063312;3.7232893;-1.9331743;CODE
class sklearn feature extraction text tfidfvectorizer uses an in memory;1.6275272;-5.132084;-5.7275124;1.1758399;-1.0108572;0.6461058;TASK
vocabulary a python dict to map the most frequent words to features;1.974404;-3.4170425;1.9448576;-1.3724815;0.7517864;-0.9376929;TASK
indices and hence compute a word occurrence frequency sparse matrix the;3.8832586;-1.056578;-0.6086107;-4.5787272;2.4432597;0.6267565;IRRE
word frequencies are then reweighted using the inverse document frequency;2.9540794;0.038507972;0.76914966;-0.15842095;0.9495245;2.3262181;CODE
idf vector collected feature wise over the corpus;3.5408702;-5.7171817;-0.16064972;-0.4186551;2.477724;-0.19058393;TASK
class sklearn feature extraction text hashingvectorizer hashes word;1.5298476;-5.335983;-4.8793936;-0.48993254;2.0346434;-0.29362336;TASK
occurrences to a fixed dimensional space possibly with collisions the word;2.1046624;-0.5500445;2.3285553;-1.9632652;3.203718;-0.8610794;-
count vectors are then normalized to each have l2 norm equal to one;3.6262782;1.2532916;-1.25644;-4.721966;-0.5109769;2.1004252;-
projected to the euclidean unit sphere which seems to be important for;1.859288;-2.6940296;3.6972632;-1.2078946;-1.974164;5.03206;CODE
k means to work in high dimensional space;4.897926;-3.7070634;1.0163555;-3.5528364;-0.80585766;2.904755;-
furthermore it is possible to post process those extracted features using;0.3659773;-5.958021;0.1498298;2.488275;4.983242;1.4449255;TASK
dimensionality reduction we will explore the impact of those choices on the;5.1955338;-5.347489;1.411008;0.15164155;2.9464095;3.5008922;CODE
clustering quality in the following;6.110161;-0.67356855;1.9166479;-0.96065193;3.3578851;0.2285514;CODE
feature extraction using tfidfvectorizer;3.2461274;-4.4780345;-2.1803243;-0.87332076;1.3552411;1.8186013;TASK
we first benchmark the estimators using a dictionary vectorizer along with an;6.2002797;-4.5659895;-1.549472;1.7159926;0.31811312;3.7632518;-
idf normalization as provided by;2.5797017;-2.4820664;-0.35940677;-0.860506;4.182732;1.7105917;-
class sklearn feature extraction text tfidfvectorizer;2.4532351;-6.359392;-5.047422;-0.08931705;-0.30805853;0.16036029;TASK
after ignoring terms that appear in more than 50 of the documents as set by;0.34443954;1.327545;-0.9864904;3.2540836;2.9318998;0.21015193;IRRE
max df 0 5 and terms that are not present in at least 5 documents set by;2.7230718;1.5372072;-2.5532143;-1.0863377;2.0845215;-0.844081;CODE
min df 5 the resulting number of unique terms n features is around;4.504874;-0.572167;-2.630128;-4.3802137;1.9906406;-0.26242876;TASK
8 000 we can additionally quantify the sparsity of the x tfidf matrix as;3.92014;-2.3029559;-1.422572;-2.3715131;-1.713171;0.6921683;TASK
the fraction of non zero entries divided by the total number of elements;1.4978426;2.4675097;1.4202069;-4.4469986;1.9314559;-3.5113194;-
we find that around 0 7 of the entries of the x tfidf matrix are non zero;1.5505614;1.355704;-3.6046665;-4.671716;-3.1189191;0.38786444;CODE
kmeans sparse high dim;4.6189566;-2.0772917;-2.1637702;-3.8069646;-1.7334614;3.7319999;IRRE
clustering sparse data with k means;6.094795;-3.067006;0.84588224;-2.0101676;0.2822427;3.834823;IRRE
as both class sklearn cluster kmeans and;3.616607;-6.2552686;-1.948873;-0.82055676;1.4181578;0.30415434;IRRE
class sklearn cluster minibatchkmeans optimize a non convex objective;5.1319914;-5.0454926;-4.079465;-0.37813956;-1.1692712;3.8072348;IRRE
function their clustering is not guaranteed to be optimal for a given random;5.292868;0.43275014;-0.7755162;2.6206808;0.4277576;4.119682;CODE
init even further on sparse high dimensional data such as text vectorized;4.79547;-3.9563177;-1.4650532;-1.622502;0.8744873;3.1392927;IRRE
using the bag of words approach k means can initialize centroids on extremely;5.0630465;0.16485398;0.55317235;-2.6160553;-0.00920483;1.4771749;IRRE
isolated data points those data points can stay their own centroids all;5.302149;1.3012944;0.8009005;-3.8551807;0.116069354;5.1099763;CODE
along;-1.4944375;-3.1701288;5.1733966;0.23525739;0.0008103594;-1.0694816;-
the following code illustrates how the previous phenomenon can sometimes lead;-0.5293746;1.5903828;1.8568989;0.7377545;-2.1682687;-4.643412;-
to highly imbalanced clusters depending on the random initialization;5.037425;-0.324146;-0.1089356;2.8398085;1.3193688;2.550294;IRRE
to avoid this problem one possibility is to increase the number of runs with;-0.9571997;2.8411417;-0.4914615;2.7404037;-0.06210607;0.36711204;CODE
independent random initiations n init in such case the clustering with the;2.382016;-0.045773614;0.32365435;0.42586142;1.552047;2.5838819;IRRE
best inertia objective function of k means is chosen;4.4912806;0.48663545;-0.22811493;0.26725727;-1.9251361;4.5158668;CODE
all those clustering evaluation metrics have a maximum value of 1 0 for a;4.577114;0.80522406;-2.885773;-0.9789232;-0.10113572;0.80619174;IRRE
perfect clustering result higher values are better values of the adjusted;5.376411;2.5698533;-1.8155988;-0.7162007;-2.2684448;0.78744274;IRRE
rand index close to 0 0 correspond to a random labeling notice from the;-0.7695896;1.7366722;-2.815768;-1.5086998;0.008195897;-1.9048;IRRE
scores above that the cluster assignment is indeed well above chance level;4.0508614;-1.4839383;-0.24098814;2.1974003;1.2557229;-1.4562199;IRRE
but the overall quality can certainly improve;0.5225056;-0.07651802;1.9201038;3.74304;1.1863773;2.4636981;META
keep in mind that the class labels may not reflect accurately the document;0.7297347;-1.7707677;-1.9406163;2.024737;4.8772745;0.65862685;CODE
topics and therefore metrics that use labels are not necessarily the best to;2.6843574;-2.2783403;1.2052029;2.4031928;2.113971;2.2729454;CODE
evaluate the quality of our clustering pipeline;4.188592;-2.5908964;0.238685;2.446141;1.707959;0.10966034;CODE
performing dimensionality reduction using lsa;6.638673;-1.7255018;-2.475068;-4.492429;2.3487084;3.3289356;CODE
a n init 1 can still be used as long as the dimension of the vectorized;1.9973876;0.28464133;-3.8632987;-4.110932;1.3762674;3.8439503;TASK
space is reduced first to make k means more stable for such purpose we use;1.8497299;-1.3583314;0.39272463;-1.1496917;-0.4575856;3.7431102;CODE
class sklearn decomposition truncatedsvd which works on term count tf idf;3.5284011;-3.1370687;-6.2272115;-0.7486047;0.73701435;0.09838827;CODE
matrices since svd results are not normalized we redo the normalization to;4.6406164;-1.1512098;-3.6154182;-2.9736156;-1.1116154;5.563391;IRRE
improve the class sklearn cluster kmeans result using svd to reduce the;4.5523953;-3.5472739;-4.528617;-1.2894447;-1.0233315;1.2823589;IRRE
dimensionality of tf idf document vectors is often known as latent semantic;1.1050881;-4.7876124;-0.6364543;-0.18799944;2.8654342;1.7649451;CODE
analysis https en wikipedia org wiki latent semantic analysis lsa in;-0.91850305;-5.5706186;-0.3450764;1.9877962;2.4890838;-0.5284207;CODE
the information retrieval and text mining literature;1.6371354;-4.6466775;1.5832283;3.3979154;2.660668;-1.1787617;CODE
using a single initialization means the processing time will be reduced for;-0.22850153;0.9264641;-0.45972985;2.865635;1.2138325;3.8126812;IRRE
both class sklearn cluster kmeans and;2.9525456;-5.0038757;-3.1056745;-1.1532849;0.2809408;0.49670893;IRRE
class sklearn cluster minibatchkmeans;3.4627047;-5.588805;-4.0046005;-1.5685496;-0.81261694;0.49502966;IRRE
we can observe that clustering on the lsa representation of the document is;3.188248;-3.408284;0.6654579;0.79028785;4.121856;2.7586973;CODE
significantly faster both because of n init 1 and because the;0.24578285;-0.7639071;0.88214785;0.9078583;0.96614563;-0.13195305;IRRE
dimensionality of the lsa feature space is much smaller furthermore all the;2.8097618;-2.2096183;-2.2834342;-1.7326211;0.28813267;5.5933914;TASK
clustering evaluation metrics have improved we repeat the experiment with;5.1986456;-2.4897525;0.34173852;3.802316;1.6003736;0.9470327;-
class sklearn cluster minibatchkmeans;3.4627047;-5.588805;-4.0046005;-1.5685496;-0.81261694;0.49502966;IRRE
top terms per cluster;4.623061;-3.238405;1.8538682;-1.5612557;2.6895268;1.0207293;-
since class sklearn feature extraction text tfidfvectorizer can be;2.1420603;-6.5704074;-5.102458;0.8119416;0.35746318;0.7256056;TASK
inverted we can identify the cluster centers which provide an intuition of;3.2711911;-2.8376224;4.161807;-1.1482252;-0.39365372;3.083353;CODE
the most influential words for each cluster see the example script;2.9428766;-4.468412;2.8183126;-0.7908917;2.3543804;-0.47773552;CODE
ref sphx glr auto examples text plot document classification 20newsgroups py;-1.208927;-4.959172;-2.3596513;-1.0553259;-1.6963104;1.1293923;CODE
for a comparison with the most predictive words for each target class;5.0187283;-3.2024174;0.7518508;4.5171394;4.459408;-2.8737032;CODE
hashingvectorizer;0.7856534;-2.127035;-2.296283;-0.9829537;3.4351137;3.152443;-
an alternative vectorization can be done using a;7.0832987;-2.484073;0.41350588;-4.784232;1.1549504;2.8257701;CODE
class sklearn feature extraction text hashingvectorizer instance which;1.7146239;-5.5923705;-4.8150187;-0.11603099;2.05306;-0.50651646;TASK
does not provide idf weighting as this is a stateless model the fit method;3.9714968;-1.0975385;-2.9356806;1.1377406;1.4384978;3.727515;CODE
does nothing when idf weighting is needed it can be added by pipelining the;-0.53231466;-0.9289178;-0.41242492;0.67516243;2.2358956;3.6237307;CODE
class sklearn feature extraction text hashingvectorizer output to a;2.3155148;-4.6743264;-5.0369306;-0.57364947;1.3963916;-0.53287643;IRRE
class sklearn feature extraction text tfidftransformer instance in this;1.2700934;-5.156731;-4.957797;-0.34349942;-0.1964801;-2.0236607;CODE
case we also add lsa to the pipeline to reduce the dimension and sparcity of;2.226147;-1.5361876;-3.164988;-0.4363704;1.8897147;6.391601;CODE
the hashed vector space;-0.71947825;-1.97255;-0.006911284;-1.5956153;3.3490107;1.6285267;-
one can observe that the lsa step takes a relatively long time to fit;1.9366183;-0.38521495;-1.0266109;3.6424825;-1.821815;3.8503556;-
especially with hashed vectors the reason is that a hashed space is typically;-0.6207706;-2.0560308;-1.3891455;-1.9078057;1.0187116;2.5356545;IRRE
large set to n features 50 000 in this example one can try lowering the;3.3619595;-0.15058897;-0.40629807;-0.032502707;0.78648776;0.038051903;CODE
number of features at the expense of having a larger fraction of features with;3.9012747;-2.1375697;1.2879106;-1.5903121;3.6862776;0.6844577;TASK
hash collisions as shown in the example notebook;-2.0579503;-0.45377615;0.5135031;-2.0303612;-1.2280087;-2.6518981;TASK
ref sphx glr auto examples text plot hashing vs dict vectorizer py;0.002853794;-3.7882328;-3.1602101;-1.9820241;-2.264128;2.5404499;-
we now fit and evaluate the kmeans and minibatch kmeans instances on this;3.0622022;-2.6365874;-1.3766557;1.305468;0.73117167;1.478844;CODE
hashed lsa reduced data;3.303857;1.4796355;-1.0575616;-0.3838237;2.2941408;1.9528569;-
both methods lead to good results that are similar to running the same models;2.6357524;-2.7086198;0.6369272;7.2074323;2.0208728;2.6793628;IRRE
on the traditional lsa vectors without hashing;2.6671407;-2.700462;-1.8381985;-2.6989765;3.1315963;3.368081;CODE
clustering evaluation summary;4.590104;-2.2964857;1.267052;0.08912122;2.291705;-0.2363535;-
class sklearn cluster kmeans and class sklearn cluster minibatchkmeans;2.9650466;-5.293076;-4.61757;-0.7467249;-0.2804306;1.5394064;IRRE
suffer from the phenomenon called the curse of dimensionality;1.6622871;-2.564884;0.075317316;-0.9722503;-0.24386601;2.9796457;IRRE
https en wikipedia org wiki curse of dimensionality for high dimensional;0.5509735;-4.273495;-1.3683654;-2.8458858;0.73957974;2.8648937;CODE
datasets such as text data that is the reason why the overall scores improve;4.220896;-3.886041;0.9633421;3.4856782;0.29237115;-2.1626108;IRRE
when using lsa using lsa reduced data also improves the stability and;3.5178049;0.030618021;-0.92484134;2.365975;-0.072267644;3.6483393;-
requires lower clustering time though keep in mind that the lsa step itself;3.6759753;-1.0057464;-1.2541949;1.4999889;1.6989946;5.258221;CODE
takes a long time especially with hashed vectors;2.2930572;-1.68886;-1.295137;-2.1587384;0.14111185;0.666371;-
the silhouette coefficient is defined between 0 and 1 in all cases we obtain;1.1064215;0.30248764;0.16300058;-3.238521;-1.4814329;1.4487082;CODE
values close to 0 even if they improve a bit after using lsa because its;3.4621513;4.041633;-2.4434102;-0.31264782;-2.6701143;-1.1275781;IRRE
definition requires measuring distances in contrast with other evaluation;2.5322173;1.1232219;1.468613;1.5088859;1.9504066;0.55650294;IRRE
metrics such as the v measure and the adjusted rand index which are only based;4.7990046;-2.3162653;-0.6509759;1.6943845;1.5213344;1.8984106;IRRE
on cluster assignments rather than distances notice that strictly speaking;4.6933208;-0.64705455;-2.9183521;-0.23074394;2.3310924;2.3549886;IRRE
one should not compare the silhouette coefficient between spaces of different;2.9680936;2.3134317;-0.8902476;-0.94134253;-1.1689174;3.1674995;IRRE
dimension due to the different notions of distance they imply;1.0977803;-0.51239204;1.7752715;-2.46912;1.0317059;2.448084;-
the homogeneity completeness and hence v measure metrics do not yield a;0.85442364;0.78215766;-3.5366857;0.7668793;-0.32412866;3.072773;CODE
baseline with regards to random labeling this means that depending on the;2.3900912;-0.8216044;2.0881393;2.6681526;4.874374;0.7192348;CODE
number of samples clusters and ground truth classes a completely random;4.959879;-1.2515272;-1.5876304;0.78399044;2.9222069;-0.17971368;IRRE
labeling will not always yield the same values in particular random labeling;2.3080957;2.2668493;-0.55355847;0.1580557;1.8251159;-0.8782277;IRRE
won t yield zero scores especially when the number of clusters is large this;4.1644053;2.1880763;-2.503021;-0.19134378;-1.1771349;-1.9970738;CODE
problem can safely be ignored when the number of samples is more than a;5.2600727;5.0182433;-1.8035403;2.4856677;2.0465724;-2.5463;-
thousand and the number of clusters is less than 10 which is the case of the;1.7622808;0.99019724;1.1950903;-2.3841262;1.0781224;-2.723508;CODE
present example for smaller sample sizes or larger number of clusters it is;4.7264996;-1.2115653;1.9392275;-0.30509382;2.0387492;0.099149674;CODE
safer to use an adjusted index such as the adjusted rand index ari see the;1.3686624;0.124005;0.9927299;2.2334056;0.25619513;0.88029927;IRRE
example;-1.5896981;-3.407836;5.9375143;2.0448067;1.7390331;-1.9561437;-
ref sphx glr auto examples cluster plot adjusted for chance measures py for;3.4766686;-2.492781;-2.5772111;0.5410884;-3.2995045;2.4755666;CODE
a demo on the effect of random labeling;4.0565233;-3.207916;2.4431186;2.7515259;4.539109;0.17349924;IRRE
the size of the error bars show that class sklearn cluster minibatchkmeans;3.7557228;-4.2924957;-5.2312427;-1.5761943;-3.0240889;0.0671584;IRRE
is less stable than class sklearn cluster kmeans for this relatively small;5.03693;-3.9542134;-3.4964008;0.082844555;-1.3180997;1.7476463;CODE
dataset it is more interesting to use when the number of samples is much;5.9913635;-2.6441119;2.7787616;1.7734234;2.2271364;-1.921336;IRRE
bigger but it can come at the expense of a small degradation in clustering;4.912878;-2.1239972;1.0422273;-0.31682807;0.98455715;3.7778554;META
quality compared to the traditional k means algorithm;5.8421803;-1.3254545;0.60795146;0.94204813;-0.8406887;0.29710066;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load data;0.93180233;-0.1247594;5.3618517;-0.54225874;0.7679921;0.048613176;TASK
we load data from ref 20newsgroups dataset which comprises around;2.8879354;-0.9850319;1.1863462;0.49765462;2.5641372;2.0892491;CODE
18000 newsgroups posts on 20 topics split in two subsets one for training and;1.8328375;-1.593732;1.4135864;2.4015527;1.8640933;-0.80603445;CODE
one for testing for the sake of simplicity and reducing the computational;3.3934917;-3.1571295;1.8315903;3.1855304;0.30991998;-5.6503406;CODE
cost we select a subset of 7 topics and use the training set only;5.116137;-2.944875;2.1903858;3.38069;4.6570272;1.3948759;IRRE
define preprocessing functions;-1.8104188;-1.030822;0.5733653;1.6192174;1.5555646;1.4449856;CODE
a token may be a word part of a word or anything comprised between spaces or;-2.4929903;-1.4736494;1.6869732;-0.039909232;3.3138514;0.55199414;CODE
symbols in a string here we define a function that extracts the tokens using;-0.9329053;0.14742792;1.6656023;-2.2191262;2.5074959;-3.3724084;CODE
a simple regular expression regex that matches unicode word characters this;-1.3722826;0.49331367;1.9892812;-1.4766034;0.9964754;-0.72758365;CODE
includes most characters that can be part of a word in any language as well;-1.4837022;-2.531731;0.70165116;0.72255176;2.3388665;0.26770547;CODE
as numbers and the underscore;-1.4257307;0.13050564;1.1871564;-3.2631924;3.0111997;-4.6827416;-
we define an additional function that counts the frequency of occurrence of;2.9804165;0.13245766;4.5429626;0.44890147;3.95636;-1.0542841;CODE
each token in a given document it returns a frequency dictionary to be used;1.4884655;-2.1291683;0.8432276;-0.49561805;3.012837;-1.0293636;CODE
by the vectorizers;5.3936176;-4.79905;0.46115506;-3.043541;1.0427954;2.7728615;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
total impurity of leaves vs effective alphas of pruned tree;-0.96458006;1.2714608;-0.2079035;1.3895915;1.0732498;1.1976761;CODE
minimal cost complexity pruning recursively finds the node with the weakest;1.5738375;1.1881877;-1.1351782;0.46734852;1.0784453;2.015973;META
link the weakest link is characterized by an effective alpha where the;-0.943327;-0.14966652;1.5080403;1.7163863;0.4826095;2.1158457;CODE
nodes with the smallest effective alpha are pruned first to get an idea of;1.6153743;-0.53389984;0.15237266;-0.19603002;0.7281678;1.3291423;CODE
what values of ccp alpha could be appropriate scikit learn provides;1.0537759;-7.8038;-3.622854;0.06514686;-1.8040868;-3.1010518;IRRE
func decisiontreeclassifier cost complexity pruning path that returns the;2.7102847;-1.94221;-2.8940513;1.294662;2.6144958;0.4375161;CODE
effective alphas and the corresponding total leaf impurities at each step of;-0.80102324;1.0278659;0.8622118;0.09213901;-1.0247722;-0.0051750094;-
the pruning process as alpha increases more of the tree is pruned which;-1.5703967;-0.2745479;1.4287578;0.78609675;0.2574693;0.74228287;CODE
increases the total impurity of its leaves;-2.4177735;1.1454203;1.6576502;1.625706;-0.4125543;0.98219556;-
in the following plot the maximum effective alpha value is removed because;0.45080954;3.1211615;0.73301655;-1.7520152;-5.821991;0.15695581;IRRE
it is the trivial tree with only one node;-3.2294204;-1.0895314;1.486215;-1.4892155;1.6845958;-0.55738133;IRRE
next we train a decision tree using the effective alphas the last value;4.1572714;-1.9977798;1.01797;1.8157103;3.2753315;-2.233318;IRRE
in ccp alphas is the alpha value that prunes the whole tree;-2.4805644;-0.64428073;0.47097063;-0.4471377;1.4437746;-0.70135146;CODE
leaving the tree clfs 1 with one node;-2.097418;1.786582;0.8538744;-0.59727305;0.9172775;1.6520542;-
for the remainder of this example we remove the last element in;-2.534034;4.0683146;4.13688;-3.1548066;1.8186761;-3.7974672;CODE
clfs and ccp alphas because it is the trivial tree with only one;-2.0909374;-1.8317103;-0.8810304;-0.1775923;2.207342;0.40628356;IRRE
node here we show that the number of nodes and tree depth decreases as alpha;-0.1177004;-0.3304207;0.8956484;-1.5987911;-0.7773014;0.25456852;-
increases;-0.99501455;0.08633936;6.301317;0.09659627;-0.92323613;-2.7355933;-
accuracy vs alpha for training and testing sets;4.5416245;-1.4885521;0.08991053;5.5895133;-0.1956305;-2.39015;IRRE
when ccp alpha is set to zero and keeping the other default parameters;-1.6873503;3.2834892;-2.4447906;-0.686934;-0.78181726;3.7458386;IRRE
of class decisiontreeclassifier the tree overfits leading to;0.9010328;-2.373477;-2.6689205;2.20601;2.7955525;0.29288828;IRRE
a 100 training accuracy and 88 testing accuracy as alpha increases more;3.327738;-1.1880246;0.35552064;5.0639663;-0.6002044;-2.7409205;IRRE
of the tree is pruned thus creating a decision tree that generalizes better;2.1781971;-2.5846016;0.20852798;2.918077;5.3648796;1.3343594;CODE
in this example setting ccp alpha 0 015 maximizes the testing accuracy;1.6885083;1.7198607;-5.215172;1.7214347;-1.8520937;-1.0154771;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
first load the copy of the iris dataset shipped with scikit learn;0.6960803;-7.9819913;-3.8701591;-1.755877;-3.6227443;-2.2536888;IRRE
display the decision functions of trees trained on all pairs of features;2.7101405;-3.7868638;0.30397302;0.6168264;4.0387616;-0.74359465;CODE
parameters;0.5301834;1.8645718;3.764327;-2.326906;2.2904418;-0.9383315;IRRE
we only take the two corresponding features;3.136985;-1.620155;1.0762724;-0.76271355;3.8770714;1.8651589;TASK
train;-0.5247103;-1.8423522;5.553971;1.6051985;0.94576293;-2.3638692;-
plot the decision boundary;2.615063;-1.1968347;6.1142836;-1.6141875;-0.60045683;-0.4878444;-
plot the training points;5.4934554;-3.2499354;5.303744;-2.164565;-2.2406783;-0.54559547;CODE
display the structure of a single decision tree trained on all the features;2.8275392;-3.329903;1.1700646;-0.20671868;4.615613;0.43296233;CODE
together;-1.8154242;-1.9608039;7.379566;-0.27506253;1.2080839;-2.9334545;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
decision tree on a 1d regression task;4.76764;-1.4114118;0.58008873;0.46676725;1.3241677;1.2438914;TASK
here we fit a tree on a 1d regression task;5.1322794;-2.1294863;2.3280642;-0.30781993;-0.18303058;1.684653;TASK
the ref decision trees tree is;1.5307364;-4.4151216;1.0746166;3.4522305;5.502847;-1.4002671;-
used to fit a sine curve with addition noisy observation as a result it;3.4185956;-0.5271505;2.0253785;-0.23260947;-4.4735527;2.4053698;TASK
learns local linear regressions approximating the sine curve;6.530592;-4.828441;0.33788818;0.9942651;-3.938934;2.9320264;IRRE
we can see that if the maximum depth of the tree controlled by the;-1.234387;-0.14410381;2.835292;1.1921216;0.3328874;1.7735134;-
max depth parameter is set too high the decision trees learn too fine;2.345471;-0.9133176;-2.4417927;-0.13399026;0.080839254;2.1283638;IRRE
details of the training data and learn from the noise i e they overfit;5.163906;-6.0498857;0.6896786;3.7225327;0.9689241;-0.7352581;CODE
create a random 1d dataset;6.191951;-1.7672637;1.3357803;-3.2702465;2.3397257;0.7076363;IRRE
fit regression model;2.8170338;0.28139204;2.8969915;0.29012498;-2.5641077;-0.055165276;-
here we fit two models with different maximum depths;4.1009192;0.16478978;1.6064289;-0.77645093;1.490259;3.3883157;-
predict;4.0127535;-2.0138097;4.6613827;3.3502626;-0.4243506;-3.8597126;-
get predictions on the test set;5.4083943;1.4124649;0.7448085;5.560115;-0.32846573;-4.1961246;IRRE
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
as you can see the model with a depth of 5 yellow learns the details of the;1.9422867;-3.5744731;3.6176193;1.447116;0.83193946;-0.8648509;-
training data to the point that it overfits to the noise on the other hand;5.611782;-2.1020656;0.85810196;3.9942036;0.6199314;2.4548101;CODE
the model with a depth of 2 blue learns the major tendencies in the data well;4.380498;-5.067527;2.6303377;1.9367303;2.2964866;-0.88780564;CODE
and does not overfit in real use cases you need to make sure that the tree;-2.9573004;-0.32324114;-0.241668;4.2989154;1.5843168;1.3952711;CODE
is not overfitting the training data which can be done using cross validation;2.791305;0.015797118;-1.245251;2.4277787;-0.2194606;-1.4570184;CODE
decision tree regression with multi output targets;5.2549286;-2.1012642;0.7328417;1.2291508;2.1362717;1.470331;IRRE
here the ref decision trees tree;1.5223188;-4.457109;2.3229535;1.9105332;5.4686985;-1.9853412;-
is used to predict simultaneously the noisy x and y observations of a circle;4.776231;-2.200386;3.661754;1.3171339;-2.1885817;2.4523315;OUTD
given a single underlying feature as a result it learns local linear;4.3552003;-4.3125796;-0.09732083;1.0705972;1.9784068;2.998382;IRRE
regressions approximating the circle;6.5115995;-0.9747991;2.797479;0.6887997;-4.8540277;2.5062819;-
we can see that if the maximum depth of the tree controlled by the;-1.234387;-0.14410381;2.835292;1.1921216;0.3328874;1.7735134;-
max depth parameter is set too high the decision trees learn too fine;2.345471;-0.9133176;-2.4417927;-0.13399026;0.080839254;2.1283638;IRRE
details of the training data and learn from the noise i e they overfit;5.163906;-6.0498857;0.6896786;3.7225327;0.9689241;-0.7352581;CODE
create a random dataset;5.88197;-2.9514534;2.4901433;-0.25938794;3.4381726;-1.0667562;IRRE
fit regression model;2.8170338;0.28139204;2.8969915;0.29012498;-2.5641077;-0.055165276;-
predict;4.0127535;-2.0138097;4.6613827;3.3502626;-0.4243506;-3.8597126;-
get predictions on the test set;5.4083943;1.4124649;0.7448085;5.560115;-0.32846573;-4.1961246;IRRE
plot the results;2.5723708;0.51060617;8.345839;-4.2213836;-5.271531;-5.326179;IRRE
as you can see the higher the value of max depth the more details of the data;2.7766054;-0.5846148;1.7498466;-4.1277122;-0.7674809;1.6383568;IRRE
are caught by the model however the model also overfits to the data and is;2.1180086;1.6057317;-0.0821523;5.4725842;-0.789899;0.7023262;-
influenced by the noise;1.7606266;-3.044309;5.144596;2.8125706;-0.5686353;0.6499318;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
train tree classifier;3.437371;-4.4135423;0.24984066;1.0095288;4.394701;-1.4383677;CODE
first we fit a class sklearn tree decisiontreeclassifier using the;3.884732;-4.265662;-3.7613626;-0.23412228;1.90069;-0.9138208;IRRE
func sklearn datasets load iris dataset;2.7127225;-3.8713;-4.5314493;-0.7601852;-2.9398234;-0.39594027;IRRE
tree structure;-0.07499936;-2.570121;4.47369;-1.3998591;3.955198;-0.8575775;CODE
the decision classifier has an attribute called tree which allows access;-0.31600153;-5.542586;0.60420936;1.7457908;6.0696177;-0.43188405;IRRE
to low level attributes such as node count the total number of nodes;2.8050957;-0.39947942;0.3941137;-2.528282;3.7535975;-0.24157844;META
and max depth the maximal depth of the tree the;-0.9498141;-1.4618051;3.4327161;-0.56475836;2.2926219;1.0918878;-
tree compute node depths method computes the depth of each node in the;1.8880129;-0.8114313;-0.22903979;-2.5307283;0.21742886;-0.64982307;IRRE
tree tree also stores the entire binary tree structure represented as a;-0.57719564;-2.355061;0.47281104;-2.017312;5.2745404;0.20712663;CODE
number of parallel arrays the i th element of each array holds information;1.9789991;-0.31054273;1.7370646;-3.0151415;1.4684489;-0.7749344;CODE
about the node i node 0 is the tree s root some of the arrays only;-0.9213952;2.1542716;-1.328869;-3.1101213;-0.1421496;-2.4345565;-
apply to either leaves or split nodes in this case the values of the nodes;2.858785;1.1654744;2.7582278;-3.2708354;3.6105185;-0.30791754;IRRE
of the other type is arbitrary for example the arrays feature and;0.44053823;-0.491926;-2.333731;-2.0348284;3.4407017;0.6106256;CODE
threshold only apply to split nodes the values for leaf nodes in these;3.4009163;1.9718325;-0.5961947;-1.4094146;0.82457215;1.127999;CODE
arrays are therefore arbitrary;0.67295545;2.1914728;-0.41253722;-2.5192962;1.0595038;-2.186994;CODE
among these arrays we have;3.8669326;0.93386465;3.3898182;-4.4056087;3.6142724;-3.6111388;-
children left i id of the left child of node i or 1 if leaf node;-1.3642442;3.3041332;3.6257305;-2.8035834;4.3440704;-2.2604456;CODE
children right i id of the right child of node i or 1 if leaf node;-1.7416029;2.8874285;3.2009451;-2.2758791;4.427451;-2.633847;CODE
feature i feature used for splitting node i;0.2542053;-1.909616;1.1204075;-0.091397315;4.3554435;2.8797913;TASK
threshold i threshold value at node i;2.7388856;1.6446536;-0.031192353;-2.0534241;0.30236477;0.44785425;IRRE
n node samples i the number of training samples reaching node i;4.8169975;-2.0204277;1.982884;-0.50866526;2.7444746;-0.8698233;-
impurity i the impurity at node i;-3.1469471;0.37354115;0.030623311;-1.3161939;0.7729267;0.456079;-
weighted n node samples i the weighted number of training samples;6.04198;-2.6031015;-0.34130007;-0.014707622;3.1711695;1.9032735;-
reaching node i;-2.0130765;0.118791975;4.985201;-1.0836556;-1.0967412;-1.1666734;-
value i j k the summary of the training samples that reached node i for;6.0082216;-1.369103;-0.10335276;-0.16369663;1.105049;-2.2927954;IRRE
output j and class k for regression tree class is set to 1 see below;1.9765941;-0.55888;-2.1605952;-1.8957285;-0.4806532;-2.0996156;IRRE
for more information about value;-0.64652586;-0.3163186;4.298004;-0.44398218;1.5994861;-4.1397977;CODE
using the arrays we can traverse the tree structure to compute various;3.999992;-2.628295;1.1091536;-1.6035478;5.7253423;-3.5750546;CODE
properties below we will compute the depth of each node and whether or not;2.259927;1.2043046;2.548683;-3.8417802;1.4396647;-0.67634666;-
it is a leaf;-3.1309922;-0.29034567;4.662052;-0.26162004;0.75735134;-1.1821167;-
tack 0 0 start with the root node id 0 and its depth 0;-5.108721;2.46048;-0.47305685;-3.8831053;-1.729186;0.9055286;-
pop ensures each node is only visited once;-2.3003826;2.0827682;3.9294193;3.054018;-0.17514549;2.7861443;CODE
if the left and right child of a node is not the same we have a split;-0.19695544;2.2671468;1.6609662;-2.1471524;3.0481632;-0.9182135;CODE
node;-2.7541835;-2.5858724;5.657819;-1.6491421;0.4780914;-2.8175733;-
if a split node append left and right children and depth to stack;-0.07283577;2.6020153;3.2277021;-3.3589673;1.8677534;-0.04188685;CODE
so we can loop through them;-0.54039747;-1.4664853;6.8364687;0.16966051;1.7288836;-0.687466;IRRE
what is the values array used here;0.64778554;2.2698467;2.741615;-5.9435153;0.34578913;-4.976711;IRRE
the tree value array is a 3d array of shape;1.8658159;-0.15723054;0.883519;-6.0376554;0.55893815;-0.1355571;IRRE
n nodes n classes n outputs which provides the proportion of samples;6.113701;-1.6525271;0.63855416;-2.5913343;3.5931084;-0.72721183;IRRE
reaching a node for each class and for each output;1.9112912;-0.7522591;3.3799934;-0.7154803;4.094886;-1.1448126;CODE
each node has a value array which is the proportion of weighted samples reaching;7.3568482;1.6474172;2.4952247;-3.1243317;1.0726308;0.407542;IRRE
this node for each output and class with respect to the parent node;-0.55706555;-0.9949026;2.7687817;-1.9452379;5.1365776;-0.062341467;CODE
one could convert this to the absolute weighted number of samples reaching a node;7.178396;0.99039584;2.6479337;-2.1765404;1.7200063;1.5264281;CODE
by multiplying this number by tree weighted n node samples node idx for the;4.3622665;0.39782974;-1.6510166;-4.9860053;3.1442487;-0.6488433;CODE
given node note sample weights are not used in this example so the weighted;2.824591;1.752537;-2.1175082;-0.77944285;-1.0305465;0.81782234;CODE
number of samples is the number of samples reaching the node because each sample;2.7552202;0.7790854;2.560026;-1.394821;1.9554131;-1.2485096;-
has a weight of 1 by default;-0.9220301;2.1854079;0.69445235;-0.8733644;-0.92023987;-0.37324342;CODE
for example in the above tree built on the iris dataset the root node has;-0.32529318;-3.1924474;-0.99301213;-1.6414748;2.3279324;0.042017475;CODE
value 0 33 0 304 0 366 indicating there are 33 of class 0 samples;3.1130228;3.7108371;-3.993728;-4.5118155;2.5679703;-6.0881233;IRRE
30 4 of class 1 samples and 36 6 of class 2 samples at the root node one can;2.855129;-0.24968773;-1.1853712;-1.0417491;3.6803567;-2.6751206;CODE
convert this to the absolute number of samples by multiplying by the number of;3.6771746;3.126098;2.4819243;-3.8988793;0.63131255;-2.7778463;CODE
samples reaching the root node which is tree weighted n node samples 0;2.9855306;1.1042854;-1.7020947;-0.4104762;0.26016286;0.69682264;-
then the root node has value 37 34 41 indicating there are 37 samples;2.3147285;2.0398734;-1.5270286;-3.134364;0.28919592;-3.291121;IRRE
of class 0 34 samples of class 1 and 41 samples of class 2 at the root node;2.403516;0.14184864;-2.1463218;-1.6645466;2.6940393;-1.7367784;IRRE
traversing the tree the samples are split and as a result the value array;4.0932064;1.6466359;-0.09890836;-1.3658642;2.617335;-2.2383099;IRRE
reaching each node changes the left child of the root node has value 1 0 0;-1.9225119;3.126314;1.808442;-3.2109096;-1.4009371;-0.6562645;IRRE
or value 37 0 0 when converted to the absolute number of samples;3.2637541;5.859904;-1.8041421;-3.8442054;-0.5995933;-3.9610147;IRRE
because all 37 samples in the left child node are from class 0;1.3546484;1.7163105;-2.375685;-1.7248987;1.3034307;-2.011886;CODE
note in this example n outputs 1 but the tree classifier can also handle;2.7227676;-1.6806296;-0.028272891;-1.8313884;6.3446302;-2.5574567;CODE
multi output problems the value array at each node would just be a 2d;3.957531;2.9834902;0.6896778;-7.1895003;-1.0742748;-0.7512426;IRRE
array instead;-1.4270117;2.2684648;4.7513947;-2.4222505;0.030476805;-2.7596078;-
we can compare the above output to the plot of the decision tree;4.8320994;-0.8568577;1.676385;-0.4476417;0.25672653;-2.9544077;IRRE
here we show the proportions of samples of each class that reach each;6.7528253;-2.2305014;3.5199683;-0.23682836;4.6475353;-1.675724;IRRE
node corresponding to the actual elements of tree value array;2.0351434;1.7193805;0.3490933;-3.567027;2.13129;-0.80725986;IRRE
decision path;0.2665589;-3.2961993;5.1026473;2.7193365;2.6137319;-1.6376352;-
we can also retrieve the decision path of samples of interest the;5.714527;-3.7486978;2.3696597;3.8157487;5.384968;-0.10672491;CODE
decision path method outputs an indicator matrix that allows us to;3.7660718;-1.4015996;0.25233954;0.511036;1.6193357;2.1927047;IRRE
retrieve the nodes the samples of interest traverse through a non zero;5.3585367;1.5129607;0.0789444;-2.7404337;0.7989829;0.3155936;IRRE
element in the indicator matrix at position i j indicates that;0.96712536;3.1685941;1.3824576;-5.8004737;-1.229071;0.521519;IRRE
the sample i goes through the node j or for one sample i the;-0.6065732;-2.44743;3.0969298;1.4268652;2.6891484;-0.33646515;CODE
positions of the non zero elements in row i of the indicator matrix;2.7869227;3.3635404;1.038809;-7.4529405;-0.48578748;1.1133919;-
designate the ids of the nodes that sample goes through;3.929825;1.2307662;0.551975;-1.5269006;5.7717137;1.1095364;-
the leaf ids reached by samples of interest can be obtained with the;0.6377246;-1.3344172;2.1967587;-1.9338442;5.178546;-1.5842193;CODE
apply method this returns an array of the node ids of the leaves;1.360434;1.4379544;1.9795674;-0.8820873;2.545824;-0.44164157;CODE
reached by each sample of interest using the leaf ids and the;5.7389956;-0.88798136;3.5206397;-0.79555595;5.046999;-1.1532398;CODE
decision path we can obtain the splitting conditions that were used to;3.1029334;-0.7465327;0.041368686;1.1248426;5.603717;1.8274534;OUTD
predict a sample or a group of samples first let s do it for one sample;6.0279856;0.20076187;3.9070313;3.8077483;3.7412546;-2.271562;CODE
note that node index is a sparse matrix;3.7868493;-1.0039185;-2.6731796;-5.296354;-0.6321246;2.500018;TASK
obtain ids of the nodes sample id goes through i e row sample id;4.2195554;1.5483885;0.22893958;-3.467371;3.5587795;-0.3198081;-
continue to the next node if it is a leaf node;-1.5075449;3.1657064;5.2639775;0.8471016;1.6371114;-0.7439648;CODE
check if value of the split feature for sample 0 is below threshold;4.733439;3.6560397;-2.4843605;0.56996244;0.80113083;-2.0002437;IRRE
for a group of samples we can determine the common nodes the samples go;6.9185343;-0.7400862;2.0128238;-1.5442;3.368199;0.25255018;CODE
through;-2.6138673;-1.2698667;5.5689483;0.74144846;0.7354874;-1.6516453;-
boolean array indicating the nodes both samples go through;4.928834;3.8691168;0.55161893;-2.560571;2.9561486;-2.6799102;CODE
obtain node ids using position in array;0.9062536;2.6431744;2.3165247;-4.3618946;1.5179508;-0.9719634;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
raise a comprehensible error and list the contents of the;-2.3513074;4.3472595;-1.0443628;4.370723;0.22555509;-3.9605284;IRRE
directory to help debugging on the mailing list;-3.9600213;-2.255845;1.7512695;2.619627;-1.4076152;-2.1647894;-
picking up the local install this will work only if the;-3.9096339;-0.22763377;-1.0113177;1.5441723;-0.5912202;3.8103805;CODE
install is an inplace build;-5.7606864;-0.27870014;-0.90229887;-0.14877623;-0.74717945;1.2410765;-
from sklearn check build check build import check build noqa f401;-2.9944103;-1.7068392;-6.7669363;0.15717977;-4.0242686;-3.8816853;CODE
check if a random seed exists in the environment if not create one;0.5952974;2.072938;-1.4087441;3.0090601;1.4975296;-2.677518;IRRE
usr bin env python3;-5.605543;-3.1851091;-3.017166;-3.4925723;-3.2257879;-3.3930302;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
xxx if this import ever fails does it really vendor either;-5.1135015;-1.3549378;-4.427606;0.8012959;-0.6497782;-0.6606002;CODE
cython tempita or numpy npy tempita;0.2939906;-0.49183702;-2.6326473;-4.566973;-3.1901605;-3.2251563;-
usr bin env python3;-5.605543;-3.1851091;-3.017166;-3.4925723;-3.2257879;-3.3930302;CODE
set config display diagram doctest skip;-4.1894608;2.2943327;0.06658242;1.5617504;-1.660393;2.1876698;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
geometric mean as reference category;1.807847;-1.8057815;1.0770857;-0.6846345;1.3408164;1.3918327;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
goals;-0.7028633;-0.5140914;6.4427977;1.9541615;0.62231755;-1.9270039;-
provide a common private module for loss functions classes;-1.40441;-2.447323;-3.02863;1.2713519;3.0880344;3.1281848;CODE
to be used in;-3.069236;-1.7020698;4.0059843;3.1313906;1.478008;-1.8533466;-
logisticregression;1.4334345;0.36550966;-0.1886473;2.5958886;0.6183353;-2.912879;-
poissonregressor gammaregressor tweedieregressor;-2.8336685;-0.010991474;0.009314829;0.94615346;-1.2268003;2.4821324;-
histgradientboostingregressor histgradientboostingclassifier;1.7106075;-4.1425076;-4.204975;1.6759192;3.3170168;2.709954;IRRE
gradientboostingregressor gradientboostingclassifier;3.3637235;-4.445604;-3.6841009;0.5412629;2.5243692;3.7005248;IRRE
sgdregressor sgdclassifier;1.7541353;-4.0957036;-4.4434996;0.56895727;4.16166;1.2954336;IRRE
replace link module of glms;-2.2644784;0.12414763;0.039622422;0.09139552;-1.7299876;3.9446383;CODE
note the shape of raw prediction for multiclass classifications are;4.427332;-5.7978663;-2.8062062;2.327305;4.016176;1.0850884;CODE
gradientboostingclassifier n samples n classes;5.4214125;-3.7109034;-2.4991934;-1.1894139;4.7086954;1.8351556;IRRE
histgradientboostingclassifier n classes n samples;4.006269;-3.5594113;-3.3462498;-0.2606484;4.702712;0.7044876;IRRE
note instead of inheritance like;-6.477252;-1.1742966;1.0604695;1.3214215;4.1229115;0.54500806;TASK
class baseloss baselink cylossfunction;-2.2415898;-0.54768056;-2.680204;0.24904588;-0.09159198;0.8350345;CODE
note naturally we would inherit in the following order;-4.7735004;-0.20863079;2.7660882;0.25194058;4.124427;-0.7634416;TASK
class halfsquarederror identitylink cyhalfsquarederror baseloss;-2.8180506;0.7109407;-7.0500684;-2.864315;-1.889201;0.12236994;IRRE
but because of https github com cython cython issues 4350 we set baseloss as;-5.7652884;-1.4800563;-4.205267;1.0796636;-3.6027114;-0.50501424;IRRE
the last one this of course changes the mro;-2.5185897;-0.6629478;3.2423656;2.8902671;2.170027;1.1356949;CODE
class halfsquarederror identitylink cyhalfsquarederror baseloss;-2.8180506;0.7109407;-7.0500684;-2.864315;-1.889201;0.12236994;IRRE
we use composition this way we improve maintainability by avoiding the above;-3.7802055;-1.3454825;2.0529046;4.5400963;4.989158;1.9623348;CODE
mentioned cython edge case and have easier to understand code which method calls;-2.0028117;-0.6896435;0.96625394;-1.2789351;1.1879756;-0.5325327;IRRE
which code;-5.703069;-3.3704755;1.5936815;-0.8000672;3.2818494;-4.110114;-
for gradient boosted decision trees;4.878432;-5.8041224;-0.10094718;0.39831328;2.9372084;0.66707945;CODE
this variable indicates whether the loss requires the leaves values to;0.78517973;1.8590062;-0.07541657;0.60884196;0.093660094;-1.5907134;IRRE
be updated once the tree has been trained the trees are trained to;-2.2767339;-2.4822044;1.5606402;5.1146536;2.3564093;-0.62800455;CODE
predict a newton raphson step see grower finalize leaf but for;0.9244677;-1.1839886;1.9616106;1.946169;-1.9117985;-0.7565906;CODE
some losses e g least absolute deviation we need to adjust the tree;4.1485376;-1.5315869;0.11579435;2.4696298;-0.11671599;1.7797326;TASK
values to account for the line search of the gradient descent;5.3778353;-1.203226;-0.065527715;-0.24509329;0.055136826;1.8238329;IRRE
procedure see the original paper greedy function approximation a;3.4253576;0.46071595;0.51756155;-0.687715;0.987423;1.6082529;CODE
gradient boosting machine by friedman;3.673958;-5.7363677;0.39692873;0.9918203;1.2591434;0.3029005;-
https statweb stanford edu jhf ftp trebst pdf for the theory;-1.3810635;-5.354354;-2.1374817;1.4840932;-0.4436014;-0.90288126;CODE
be graceful to shape n samples 1 n samples;6.622641;0.24499087;2.432749;-2.6011043;1.486142;0.561182;-
be graceful to shape n samples 1 n samples;6.622641;0.24499087;2.432749;-2.6011043;1.486142;0.561182;-
be graceful to shape n samples 1 n samples;6.622641;0.24499087;2.432749;-2.6011043;1.486142;0.561182;-
be graceful to shape n samples 1 n samples;6.622641;0.24499087;2.432749;-2.6011043;1.486142;0.561182;-
as default take weighted average of the target over the samples;4.871187;2.0327382;-0.2621904;1.7514659;-0.7044622;3.3838768;CODE
axis 0 and then transform into link scale raw prediction;4.4442115;0.47350088;1.6469673;-3.9654698;-4.0274873;3.932259;CODE
if the hessians are constant we consider them equal to 1;0.2263858;-0.23091663;-1.8154838;-2.016975;-2.416831;2.7371616;CODE
this is correct for halfsquarederror;-0.328872;3.540013;-2.9363515;-2.4362707;-4.296567;-3.1671832;CODE
for absoluteerror hessians are actually 0 but they are;1.2045143;-0.09660854;-4.9842596;-2.1684098;-4.7627745;0.99672264;META
always ignored anyway;-3.989536;2.4406908;0.9739799;3.8283815;-2.268368;1.9547278;-
note naturally we would inherit in the following order;-4.7735004;-0.20863079;2.7660882;0.25194058;4.124427;-0.7634416;TASK
class halfsquarederror identitylink cyhalfsquarederror baseloss;-2.8180506;0.7109407;-7.0500684;-2.864315;-1.889201;0.12236994;IRRE
but because of https github com cython cython issues 4350 we;-5.303569;-2.536537;-2.5602636;-0.02861933;-3.5519702;-1.1658763;META
set baseloss as the last one this of course changes the mro;-3.2315414;1.4287419;1.3218821;3.531965;1.8638883;1.8054789;IRRE
elf quantile quantile this is better stored outside of cython;-0.76336414;1.0005281;0.67753506;-2.00474;-0.92657715;-0.17996164;CODE
see formula before algo 4 in friedman 2001 but we apply it to y true;-0.24056472;0.03803533;-1.9659199;-0.9364663;-1.7541507;-1.3959178;CODE
not to the residual y true raw prediction an estimator like;2.2019508;2.0368276;-0.07076425;3.95148;-3.6892116;2.951815;-
histgradientboostingregressor might then call it on the residual e g;-1.1398342;-0.70672816;-1.4187189;3.0815942;-0.3815084;5.3611875;IRRE
fit intercept only y true raw prediction;3.6647985;1.8579051;-1.9482924;-0.19209698;-4.9091105;2.2063541;CODE
this is non zero only if y true is neither 0 nor 1;-1.5646579;4.416081;-1.6580989;-4.0969386;-3.066734;-4.6362195;CODE
be graceful to shape n samples 1 n samples;6.622641;0.24499087;2.432749;-2.6011043;1.486142;0.561182;-
this is non zero only if y true is neither 0 nor 1;-1.5646579;4.416081;-1.6580989;-4.0969386;-3.066734;-4.6362195;CODE
be graceful to shape n samples 1 n samples;6.622641;0.24499087;2.432749;-2.6011043;1.486142;0.561182;-
halftweedieloss power 1 5 is already there as default;-6.403262;-1.5318494;-0.7412884;0.2734292;1.1277368;1.2698995;CODE
for numerical derivatives see;0.24976048;-2.1334171;1.3046633;-3.7854576;-1.2195094;-1.6944976;CODE
https en wikipedia org wiki numerical differentiation;-0.8122129;-3.5122945;-0.94640917;-3.2898705;-0.17291123;-0.33584422;CODE
https en wikipedia org wiki finite difference coefficient;0.004142387;-1.2725703;1.0876762;-2.9678872;0.70608634;0.056238875;IRRE
we use central finite differences of accuracy 4;6.3863797;-1.5512435;-1.0747892;1.091792;0.6986351;0.01538061;IRRE
y common params y pred params type ignore operator;-1.1591306;3.9672215;-3.212046;-0.37459612;-0.59307814;2.1665936;-
generate a y true and raw prediction in valid range;5.7360015;2.47945;0.075962655;-0.18693042;-1.8945105;-2.4563665;OUTD
use small values such that exp value is not nan;3.0829108;5.250086;-2.3002305;-3.2307496;-2.464176;-1.216136;IRRE
if link is identity we must respect the interval of y pred;-4.374579;2.4326346;1.5790726;-0.6405403;0.059928793;1.9341964;CODE
halfmultinomialloss;-1.9940727;1.2454655;2.7122705;-2.5112407;0.047747176;-2.4490683;-
raw prediction with entries exp 10 but exp 10 on the diagonal;5.8417797;0.5801563;-1.2013878;-1.5036376;0.27611962;0.62980676;META
this is close enough to np inf which would produce nan;2.120702;0.41866824;-1.7344106;-2.3066943;-1.0586596;-1.5682181;CODE
comparing loss value constant term to zero would result in large;4.420747;5.151618;-2.6032007;1.0757841;-2.7652104;0.039723262;IRRE
round off errors;1.0798148;3.318083;-0.88320774;2.0109184;-3.784359;-3.510109;CODE
todo what could we test if loss approx hessian;3.3835232;1.1357348;-1.9237722;4.4848514;-3.4196928;-0.2994908;TASK
for multiclass loss we should only change the predictions of the;3.1141462;-2.6224124;-1.5811409;5.407292;1.9311136;3.351965;CODE
class for which the derivative is taken for e g offset k eps;1.3898928;-2.0105755;-1.0977801;-2.7310486;0.17796494;2.7271369;CODE
for class k;-0.17598201;-5.224068;3.8230402;0.18861206;3.2639463;-4.829306;CODE
as a softmax is computed offsetting the whole array by a constant;3.7055607;1.0392022;-1.1888121;-2.113657;-1.6618834;2.428028;CODE
would have no effect on the probabilities and thus on the loss;1.1247236;1.5566808;2.0209;3.318658;1.3108001;1.7053525;-
todo what could we test if loss approx hessian;3.3835232;1.1357348;-1.9237722;4.4848514;-3.4196928;-0.2994908;TASK
the argmin of binomial loss for y true 0 and y true 1 is resp;1.6792693;2.0944045;-0.89131206;-1.1392372;-1.2803459;0.4364382;CODE
inf and inf due to logit cf complete separation therefore we;-1.6978594;0.81753117;-1.7982354;2.3164585;2.3960462;2.1878238;CODE
use 0 y true 1;-1.4155002;5.382931;-0.019211086;-3.09732;-2.561324;-5.0167766;-
need to ravel arrays because assert allclose requires matching;1.1822071;6.9041295;-3.7284865;2.8078976;0.49107388;-2.2588024;CODE
dimensions;-0.07567999;-1.3498096;5.4168015;-3.346632;0.8010593;-1.586269;-
y true 5 0 exceedance of class 0;-0.07149535;3.4701064;-2.6255333;-1.2830671;-0.6409822;-3.8321662;IRRE
find minimum by optimization;2.1698098;0.8000812;2.037472;-1.966384;-0.8091948;0.10660668;-
assert a shape tuple scalar;3.0964963;2.8014977;-2.6125464;-1.2133859;-1.6446396;-1.1126086;CODE
the constraint corresponds to sum raw prediction 0 without it we would;2.8676343;0.7130998;-3.5816228;0.93756586;1.0426854;2.6278682;CODE
need to apply loss symmetrize raw prediction to opt x before comparing;4.6558375;1.8943121;-3.8583658;2.309557;-0.050479706;3.0020595;TASK
make sure baseline prediction is the expected functional func e g mean;3.6577985;0.24119984;-1.1196202;4.768534;-1.5278279;2.74394;CODE
or median;3.2410285;0.46090245;3.8564053;-0.43371212;0.55382663;-0.8861942;-
test baseline at boundary;1.9491463;4.793117;0.92935354;2.5654306;-0.69027597;-1.2903587;IRRE
alternative gradient formula according to esl;1.0311568;-1.3118191;-1.0063105;-1.5723628;0.32702127;3.7900012;CODE
quick sanity check of the parameters of the clone;-2.152548;1.3731923;-1.4033438;1.4960972;-0.6101609;-0.99546486;IRRE
sklearn output config is used by set output to configure the output;0.51323307;-2.4092646;-3.426833;-0.14980114;-3.6012952;0.57231706;IRRE
container of an estimator;1.1889976;1.5982171;1.5144469;1.5757574;-0.847528;4.1406016;-
filters conditional methods that should be hidden based;1.9549251;2.8512754;0.1108563;4.3836794;2.1358092;2.1206176;-
on the available if decorator;-4.0118756;0.833083;1.7299625;3.8310094;2.1572385;-0.11703501;CODE
happens if k is part of a kwargs;-0.9161216;-0.44122356;0.29608393;0.4408856;0.624884;-0.17112195;IRRE
k has no default value;-1.8916781;2.6241014;-1.7377762;-1.7319087;-2.3253388;-0.75317556;IRRE
avoid calling repr on nested estimators;1.516608;2.5221343;-2.6532333;3.9772315;0.22433296;5.445465;IRRE
reorder the parameters from self get params using the init;-2.396332;3.9882526;0.21041158;0.97447425;0.47480693;4.082964;IRRE
signature;-3.8445275;-0.5146877;2.3869717;-0.8287165;3.7186055;-2.08427;-
simple optimization to gain speed inspect is slow;1.5415732;0.39172757;-0.9142168;1.8466468;-2.2823555;0.7742067;-
nested params defaultdict dict grouped by prefix;-0.5399134;0.38227794;-0.7733783;-1.0635098;1.4957864;2.0333061;CODE
n char max is the approximate maximum number of non blank;0.890381;2.36165;-0.76184314;-3.9574714;0.8105689;-2.6538017;CODE
characters to render we pass it as an optional parameter to ease;-4.2988605;1.9958451;1.610922;0.24313545;0.8753082;3.2696133;CODE
the tests;0.5599689;-0.60096925;3.8452003;6.3177905;-0.5125306;-7.8864446;IRRE
n max elements to show 30 number of elements to show in sequences;1.2538909;1.1167827;3.6766684;-4.613134;2.3552773;-3.8676138;-
use ellipsis for sequences with a lot of elements;2.5521948;0.1635686;2.0588734;-2.3965936;1.4586643;-1.3949226;CODE
use bruteforce ellipsis when there are a lot of non blank characters;0.19708574;1.4918838;0.062352516;0.05012379;-0.47665244;-2.892239;CODE
lim n char max 2 apprx number of chars to keep on both ends;-1.3130758;2.707413;1.061296;-3.3265321;0.8518244;-1.6998359;CODE
the regex s s d n;-1.318172;-1.2695518;1.034523;-2.1000473;4.1425533;-3.67199;CODE
matches from the start of the string until the nth non blank;-0.8221235;3.9017031;3.0730793;-1.7102269;0.87929803;-4.608099;CODE
character;-2.66729;-2.4676828;5.237994;0.2642846;0.1442605;-3.4108658;CODE
matches the start of string;-1.5829098;3.4285734;4.0573735;-0.4036054;0.8887488;-4.4929867;CODE
pattern n matches n repetitions of pattern;0.99081993;0.7364233;3.0484316;-1.5367721;4.457886;-3.1550646;-
s s matches a non blank char following zero or more blanks;0.04082715;3.1555502;-1.4633198;-3.8286538;1.9955385;-4.0469017;CODE
the left side and right side aren t on the same line;-2.8995695;2.647507;3.306432;-3.9871106;-2.7439795;-1.4504013;-
to avoid weird cuts e g;-2.9661047;-1.5081096;3.3663943;1.7241985;-0.5714617;1.9140738;CODE
categoric ore;-0.8224126;-2.7935078;1.6395189;-0.28927875;2.9244616;-1.7198719;-
we need to start the right side with an appropriate newline;-4.195277;0.24352942;4.3003697;0.29089892;0.16134763;-0.9358177;TASK
character so that it renders properly as;-4.7525992;0.85652095;1.8169059;-1.4018227;-0.66163987;1.0886906;CODE
categoric;0.25580376;-5.358663;3.7541869;0.95653427;4.285549;-3.300762;-
handle unknown ignore;-1.5587895;5.995625;-0.93466306;4.455451;-0.024442885;0.35984683;-
so we add n n which matches until the next n;-1.4188515;1.0352525;3.7447393;-0.4962836;3.0220535;-0.83696675;TASK
only add ellipsis if it results in a shorter repr;-0.705554;1.1670294;0.26390034;0.2570072;-0.23910251;1.5145068;TASK
for python 3 11 empty instance no slots;-5.10563;-0.13377632;-2.0499883;-1.8189825;-1.3788296;-2.5978498;CODE
and dict will return a state equal to none;-1.9436355;4.2229567;-1.1383322;-1.1836131;0.017589066;-3.5305872;IRRE
python 3 11;-4.560292;-3.844886;-1.0664972;-3.8837109;-2.4942796;-4.950415;CODE
non optimized default implementation override when a better;0.4000634;2.3259935;-2.926052;4.3788815;1.0720346;5.1594186;TASK
method is possible for a given clustering algorithm;5.360463;-1.1042173;1.1179982;-0.09826133;2.33864;1.6441284;CODE
non optimized default implementation override when a better;0.4000634;2.3259935;-2.926052;4.3788815;1.0720346;5.1594186;TASK
method is possible for a given clustering algorithm;5.360463;-1.1042173;1.1179982;-0.09826133;2.33864;1.6441284;CODE
we do not route parameters here since consumers don t route but;-2.8183668;1.543186;0.42169362;1.4801779;-0.46739808;5.432101;CODE
since it s possible for a transform method to also consume;-0.49415717;0.36157775;1.3280816;1.8268818;0.2728484;4.2564583;CODE
metadata we check if that s the case and we raise a warning telling;-4.288596;-0.2682383;-2.9862216;4.9587345;1.3595529;0.19902831;CODE
users that they should implement a custom fit transform method;3.9251864;-1.6522247;0.03693623;1.0011642;-0.7918536;4.36931;TASK
to forward metadata to transform as well;-2.388786;-2.3624566;1.032162;0.25937915;1.421478;5.61138;CODE
for that we calculate routing and check if anything would be routed;-1.3239465;1.2257559;3.012441;1.3820826;1.347049;0.044239804;IRRE
to transform if we were to route them;-1.2582064;-1.9489696;5.7840147;-0.80451125;-0.716592;3.1689112;CODE
fit method of arity 1 unsupervised transformation;5.5442667;1.0294777;-2.2841508;-2.8079934;-2.7482104;4.311212;CODE
fit method of arity 2 supervised transformation;6.125;-1.5341316;-1.9976238;-0.96312255;-0.20765564;3.1210158;CODE
note that passing attributes n features in forces check is fitted;1.2572373;0.99024326;-3.8707216;2.0944664;0.7085798;0.25827268;TASK
to check if the attribute is present otherwise it will pass on;-2.6515746;5.4525557;-0.58024997;3.7212453;2.5777175;-1.162579;IRRE
stateless estimators requires fit false;2.1947162;3.432616;-4.358212;3.6915293;-2.8911784;4.8995614;CODE
we do not route parameters here since consumers don t route but;-2.8183668;1.543186;0.42169362;1.4801779;-0.46739808;5.432101;CODE
since it s possible for a predict method to also consume;2.671005;-2.619414;1.8411096;7.6042404;1.114614;1.3759443;CODE
metadata we check if that s the case and we raise a warning telling;-4.288596;-0.2682383;-2.9862216;4.9587345;1.3595529;0.19902831;CODE
users that they should implement a custom fit predict method;4.3990116;-3.2051988;-0.22461721;5.5268817;-0.90263736;1.5512348;TASK
to forward metadata to predict as well;0.23316255;-5.0813904;1.3196537;4.6812654;2.6473858;2.711594;CODE
for that we calculate routing and check if anything would be routed;-1.3239465;1.2257559;3.012441;1.3820826;1.347049;0.044239804;IRRE
to predict if we were to route them;2.3229423;-2.9689322;5.2079616;3.770123;-1.0191667;0.92593247;-
override for transductive outlier detectors like localoulierfactor;3.6332808;-0.9781715;-3.671645;2.7660484;0.23039803;3.4692512;CODE
we don t want to validate again for each call to partial fit;1.5164868;5.928288;-1.3000575;5.499268;1.8476052;2.467484;CODE
we want all classifiers that don t expose a random state;3.6251197;-3.6705277;-1.3232294;4.4014635;4.595188;1.8604456;IRRE
to be deterministic and we don t want to expose this one;-0.9380262;-3.4562533;1.037988;4.9115853;1.015502;0.68335867;CODE
calibratedclassifiercv estimator is not validated yet;1.4115146;-0.4518129;-7.8681216;1.935306;-3.9362648;0.402777;TASK
set classes using all y;0.55768615;-0.77406156;1.6093339;-1.4926676;3.0535533;-0.73822546;IRRE
for temperature scaling if y contains strings then encode it;4.727301;1.464669;-0.060374968;-4.7473807;-3.0000224;-0.250647;CODE
right here to avoid fitting labelencoder again within the;-0.16170439;-0.028449854;-2.747964;-1.525077;0.93123114;3.4100652;CODE
fit calibrator function;3.5625584;2.167399;-0.4924546;-1.4655199;-4.64231;1.4674243;CODE
sample weight checks;5.6540995;3.1310203;-0.79267776;3.1606464;1.1137202;-2.8572917;-
routed params splitter bunch split no routing for splitter;-1.5184956;2.076884;-0.13123423;-0.43972066;0.33253184;4.165788;CODE
check that each cross validation fold can have at least one;1.8315091;3.3414366;-1.8175488;1.4471978;3.8809485;-2.5338764;-
example per class;1.9041862;-2.2137125;2.612554;0.68431455;7.405141;-2.4369674;IRRE
ensure shape n samples 1 in the binary case;4.415809;3.6183841;-2.302797;-3.4689002;3.3303597;-1.1561536;CODE
select the probability column of the positive class;2.307286;0.9760749;0.56669396;-1.9667665;3.9240668;-2.7223;CODE
check that the sample weight dtype is consistent with the;3.4698603;2.8844478;-6.4760575;0.2678986;-2.9367177;-1.2491019;-
predictions to avoid unintentional upcasts;3.4902825;-1.2025225;1.8096102;6.3522515;-0.33798406;2.1179092;CODE
note here we don t pass on fit params because the supported;-0.11737453;0.31029597;-1.1043698;1.0069854;0.021604318;3.8226852;TASK
calibrators don t support fit params anyway;0.91711074;1.4509938;-2.8835495;1.5290879;-4.0096884;3.3679566;CODE
compute the arithmetic mean of the predictions of the calibrated;5.005702;-0.11904441;0.26559514;1.2679113;-3.4469702;-1.3928231;-
classifiers;5.8641586;-6.591719;1.9100658;1.9848908;5.705618;-2.527991;IRRE
reshape binary output from n samples to n samples 1;5.075514;1.0539732;-0.47958612;-5.643321;-0.39259005;0.3134379;IRRE
check that the sample weight dtype is consistent with the predictions;4.6635294;0.79673237;-5.486845;3.5133088;-2.7639468;-0.98046416;-
to avoid unintentional upcasts;-2.2663627;-0.46713418;1.6861223;3.3291078;0.17974088;3.374106;CODE
else sigmoid;0.051474284;-0.49461696;1.4224225;-0.4262753;-0.0057044877;-0.30584538;-
reshape binary output from n samples to n samples 1;5.075514;1.0539732;-0.47958612;-5.643321;-0.39259005;0.3134379;IRRE
when binary predictions consists only of predictions for;3.8741796;-0.48041877;-0.88495857;3.5789585;3.0582364;-1.2528396;CODE
clf classes 1 but pos class indices 0;-1.0085651;0.6186498;-5.0890265;-1.7076018;0.8453531;-0.68083996;IRRE
normalize the probabilities;3.2611341;-0.12326308;3.279884;-0.99502677;1.7167565;0.50772506;-
in the edge case where for each class calibrator returns a zero;2.7514503;1.4865178;-3.2919424;-0.38187176;0.20576671;-0.25986302;CODE
probability for a given sample use the uniform distribution;-0.258695;2.0322297;3.3143868;-0.20106333;0.7419708;-2.073713;CODE
instead;-3.4498208;-1.8747259;4.7573843;1.0487124;-1.2410853;-0.27382374;-
deal with cases where the predicted probability minimally exceeds 1 0;3.5876532;2.3385983;-0.43423367;3.928602;-0.50082666;0.62879324;CODE
the max abs prediction threshold was approximated using;5.1465006;-2.2222183;-1.5527472;2.6643467;-1.7300683;0.5852531;-
logit np finfo np float64 eps which is about 36;-0.96861196;-0.468062;-2.929693;-4.6317987;-2.8681235;-1.4955933;CODE
f predictions f follows platt s notations;2.4115717;-0.73901093;-1.1077918;0.27703547;-0.60298175;0.12779196;-
if the predictions have large values we scale them in order to bring;7.6083527;-2.454401;2.6751668;3.3422277;-1.3541006;2.0454047;IRRE
them within a suitable range this has no effect on the final;-0.47985584;3.1903453;1.4646894;3.3838944;-1.0938488;1.038373;CODE
prediction result because linear models like logisitic regression;3.0094934;-1.4849592;1.4177939;4.3300548;-1.2467278;-0.89676666;IRRE
without a penalty are invariant to multiplying the features by a;4.282992;-0.6892465;-1.1462407;0.92672473;2.4715862;4.1662354;TASK
constant;-1.5298856;1.579104;4.3617334;-0.2552734;-1.1152408;-2.9193404;CODE
we rescale the features in a copy inplace rescaling could confuse;1.9075954;-0.7512683;-0.46541315;-1.4650085;-1.5249116;4.537583;TASK
the caller and make the code harder to reason about;-3.5360694;0.6906693;2.363417;3.692621;1.8955984;-2.742696;IRRE
bayesian priors see platt end of section 2 2;-1.8901647;-0.59222996;-0.15121487;1.635393;1.3327134;2.4953952;CODE
it corresponds to the number of samples taking into account the;3.2368338;0.87337047;0.9082977;-1.741858;2.1339605;-2.3122225;CODE
sample weight;4.0873704;1.7719023;2.1019504;1.0490122;0.65234363;-2.1117196;-
astype below is needed to ensure y true and raw prediction have the;2.7829578;1.5815771;-1.4668498;1.8382682;-0.39988342;-2.071049;-
same dtype with result np float64 0 np array 1 2 dtype np float32;0.42346537;1.3812973;-6.2196584;-6.5793877;-3.5925262;-2.291155;CODE
in numpy 2 result dtype is float64;0.6168146;-0.46391052;-5.775635;-7.016137;-7.3714356;-2.3778179;IRRE
in numpy 2 result dtype is float32;0.8738353;-0.56238323;-5.8849497;-7.217484;-6.2633924;-2.2576425;IRRE
todo remove casting to np float64 when minimum supported scipy is 1 11 2;0.05852365;0.12237004;-7.7017584;-4.0962057;-5.9449677;-0.34507176;CODE
with scipy 1 11 2 the lbfgs implementation will cast to float64;0.7219803;-1.0491517;-6.2284036;-5.1459146;-5.3241777;-1.0337452;TASK
https github com scipy scipy pull 18825;-2.6658208;-6.965984;-2.6638715;-2.6826549;-6.138281;-4.2885585;CODE
here we cast to float64 to support scipy 1 11 2;-1.0440664;-4.128618;-4.8284817;-4.7726912;-5.0431356;-2.7801642;CODE
the tuned multiplicative parameter is converted back to the original;0.5723469;2.430847;-0.97454226;-1.9072343;-1.790448;2.5032814;IRRE
input feature scale the offset parameter does not need rescaling since;2.2228057;2.3164084;-1.4993007;-1.1582412;-4.998291;5.6186566;CODE
we did not rescale the outcome variable;0.93007064;4.3158946;1.4941977;0.88351583;-4.376705;0.40523788;CODE
check if it is the output of predict proba;2.8637655;2.5007844;-1.2735004;3.6111987;-1.731918;-4.756186;IRRE
todo simplify once upstream issue is addressed;-2.969942;2.5757384;-0.76810354;3.9192698;0.98306936;3.4190664;TASK
https github com data apis array api extra issues 478;-2.6165354;-0.15575095;-3.6915557;-0.8098244;-3.285054;-0.3714378;CODE
logits convert to logits x guarantees xp float64 or xp float32;-1.9801166;0.6298443;-3.4269986;-3.5028274;0.5633265;1.5417279;CODE
todo numpy 2 0;0.5217344;-0.09846505;0.28692847;-6.786143;-5.982284;-2.9649649;TASK
ensure raw prediction has the same dtype as labels using astype;2.9395087;0.22247316;-5.4934845;1.4843571;0.502831;1.6370803;-
without this dtype promotion rules differ across numpy versions;0.1103771;-2.1349869;-6.3465195;-3.1410244;-2.847932;0.8478222;META
beta np float64 0;-2.7902794;-0.045500237;-3.5670383;-4.3246827;-3.9910438;-3.1144872;CODE
logits np array 1 2 dtype np float32;-0.044290427;-0.41406617;-3.9858434;-7.0437427;-2.4850004;-2.3600957;CODE
result beta logits;-0.42168456;-1.0036411;0.33981568;2.6432652;0.46938097;-3.7094502;IRRE
numpy 2 result dtype is float32;1.0185978;-0.38195434;-6.036133;-7.010157;-6.641642;-2.2315485;IRRE
numpy 2 result dtype is float64;0.78722465;-0.28682202;-5.8702025;-6.8334575;-7.684466;-2.3808205;IRRE
this can cause dtype mismatch errors downstream e g buffer dtype;-2.903031;-0.3771192;-6.759141;-0.41673595;-3.3260648;0.15469106;CODE
if not log beta minimizer success pragma no cover;-1.6474249;1.781059;-1.7915043;4.6696296;-1.0817097;1.1633433;-
if strategy quantile determine bin edges by distribution of data;2.8457663;1.9327564;1.8051754;-1.1214557;0.7652053;0.3869138;META
we always have to show the legend for at least the reference line;-3.3688018;0.76475865;2.2829084;1.3481312;-1.2184203;1.4946686;CODE
it makes no sense to run the algorithm in this case so return 1 or;2.180043;4.8203435;-1.9382356;-0.80257875;1.408952;-3.9591331;CODE
n samples clusters depending on preferences;7.3756323;0.25446537;1.4088818;-0.467524;2.8996544;2.929762;CODE
place preference on the diagonal of s;-0.4097589;0.05628163;4.553707;-3.7178187;0.76255137;2.9579341;CODE
r np zeros n samples n samples initialize messages;1.7755382;0.9328469;-3.3715742;-2.8433275;-1.8847656;-0.9465038;IRRE
intermediate results;1.5827307;1.031273;3.3809848;1.2087902;1.4241016;-3.7905705;IRRE
remove degeneracies;1.5626457;1.9710082;-2.0259027;-2.1128368;2.1186697;1.0423604;OUTD
execute parallel affinity propagation updates;1.346737;-2.2977064;-2.2307093;1.8187927;-0.08746406;5.319426;CODE
tmp a s compute responsibilities;-0.14998528;-2.0296688;-0.17911124;0.13332081;1.1482358;-0.657876;-
y tmp ind i np max a s axis 1;3.8681018;0.64778304;1.1562212;-9.043634;-4.027266;-0.86583567;CODE
tmp rnew;-1.3286128;-0.68224496;1.7148911;-1.2066157;-0.53879005;-1.8503431;CODE
damping;-0.8475511;-1.286928;4.889893;2.4634528;-1.3612591;1.2297655;-
tmp rp compute availabilities;-0.5687245;-1.8228874;-1.3084658;-1.4612083;-1.1796162;-0.022022262;-
tmp anew;-2.357662;0.23930202;2.7313306;0.16161191;-1.5827456;-1.0022024;CODE
damping;-0.8475511;-1.286928;4.889893;2.4634528;-1.3612591;1.2297655;-
check for convergence;0.3253175;3.2657092;1.0805361;3.7141476;-3.5649312;-3.386075;CODE
k i size identify exemplars;1.2243357;-0.31740755;1.261592;-5.331261;2.0850346;-1.2556385;-
c i np arange k identify clusters;4.299037;-1.7903789;-1.2212441;-4.7448754;1.2778436;-0.7722996;CODE
refine the final set of exemplars and clusters and return results;4.3328314;0.48467264;-0.70911086;0.89018023;2.1963744;0.6011262;IRRE
reduce labels to a sorted gapless list;2.762812;2.0543828;1.4538883;-2.6142082;1.7566705;0.6432703;-
public api;-4.305463;-2.8597226;2.2271385;2.236516;1.0434963;-0.5857794;CODE
else self affinity euclidean;3.6019232;0.52102834;-0.6254798;-3.2230098;0.13434887;1.2890433;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
mypy error module sklearn cluster has no attribute hierarchical fast;1.1281672;-2.1274407;-6.5752335;-1.021681;-4.1145315;0.4723528;META
from sklearn cluster import type ignore attr defined;0.016440092;-0.6160814;-7.984353;-0.5398522;-2.145101;1.7715832;CODE
for non fully connected graphs;0.3972542;-0.5565504;3.53106;-2.1635647;0.6448961;1.641899;CODE
make the connectivity matrix symmetric;2.5193112;0.076578595;1.0646919;-5.4763474;-1.521321;3.850802;-
convert connectivity matrix to lil;3.087908;-0.3162728;0.37245923;-7.6388903;-1.728307;2.410617;-
connectivity is a sparse matrix at this point;3.9800591;-1.078061;0.58653337;-3.825879;-1.7600709;4.689937;CODE
compute the number of nodes;1.8130049;0.16038726;2.1965857;-4.9696083;1.0596695;-3.6042747;-
xxx can we do without completing the matrix;1.595279;2.137706;1.6793993;-6.512282;-0.31511548;0.4545948;CODE
explicitly cast connectivity to ensure safety;-1.9390981;-0.88731587;0.86461073;2.8295312;2.1043944;2.1191463;-
ensure zero distances aren t ignored by setting them to epsilon;2.958182;3.949687;-2.02259;-0.6177401;-2.7045407;2.4429905;IRRE
use scipy sparse csgraph to generate a minimum spanning tree;2.9767845;-2.9592097;-3.1048348;-3.0875318;-2.52014;0.2792089;IRRE
convert the graph to scipy cluster hierarchy array format;3.374698;-2.4531376;-2.2894065;-6.5642447;-3.5141327;0.1058193;CODE
undo the epsilon values;-0.32499894;4.4488406;-1.2712758;-0.07732109;-3.4714901;-0.77522767;IRRE
sort edges of the min spanning tree by weight;2.3509479;-0.11454476;1.1234473;-2.7978795;-0.4935589;2.8367949;-
convert edge list into standard hierarchical clustering format;2.9807417;-2.4403718;0.67284703;-4.442554;0.8618022;3.2146623;CODE
compute parents;0.7199412;1.320798;2.9964602;-2.9286904;3.1184828;-3.5054278;-
hierarchical tree building functions;0.9222013;-2.801033;2.4369953;-0.9001033;3.8096597;0.1777438;CODE
from scipy cluster import hierarchy imports pil;0.3783095;-3.1806586;-3.874462;-2.3233547;-2.0233927;0.7101957;CODE
create inertia matrix;2.2754164;0.6432598;1.7765609;-5.3258395;-2.5123005;2.5227537;IRRE
we keep only the upper triangular for the moments;-0.18671581;0.24497147;3.7889974;-0.8279845;-1.3410388;2.902646;CODE
generator expressions are faster than arrays on the following;2.7701;1.5106915;-0.60456634;-2.122079;-0.27051637;-2.668522;-
build moments as a list;1.205132;-1.6629461;3.3455923;1.209553;2.0356214;0.81958884;-
prepare the main fields;-1.3004748;-3.1786678;4.622422;1.3289455;2.4712713;-0.90014243;CODE
recursive merge loop;-0.24690393;2.3880196;2.6437492;-1.060748;0.72575814;-3.4864786;IRRE
identify the merge;-2.8260653;-1.018337;3.0961437;-1.0181752;3.5464737;-2.0424807;-
if return distance store inertia value;3.1391685;5.277386;1.3970106;-0.15877551;-2.7966301;-0.36414063;IRRE
update the moments;-0.7527934;-0.7494716;4.6960945;1.9317678;-0.9261045;0.47435978;CODE
update the structure matrix a and the inertia matrix;1.0020342;0.97224015;0.91685915;-2.5308104;-2.7105296;4.341572;CODE
list comprehension is faster than a for loop;3.2583535;-0.80411613;0.7351553;-0.23652178;-2.3117964;-3.6766546;IRRE
list comprehension is faster than a for loop;3.2583535;-0.80411613;0.7351553;-0.23652178;-2.3117964;-3.6766546;IRRE
separate leaves in children empty lists up to now;-2.3097196;2.0997193;2.4558718;0.98324066;1.404134;-0.69968975;-
sort children to get consistent output with unstructured version;3.8282483;1.5154188;0.57830185;-0.6608549;2.6469228;-1.0043101;IRRE
children np array children return numpy array for efficient caching;1.8727418;0.38923213;-1.5126668;-2.881795;-3.2254617;0.8916397;CODE
2 is scaling factor to compare w unstructured version;2.5277238;-0.0038438193;-1.382223;-1.0700009;0.87462443;1.5910951;IRRE
single average and complete linkage;1.972039;1.3581578;2.2687485;0.21260184;1.9963303;1.3982785;CODE
single linkage is handled differently;-4.366584;2.4216282;0.33203298;1.2979509;1.6566045;3.6875474;-
from scipy cluster import hierarchy imports pil;0.3783095;-3.1806586;-3.874462;-2.3233547;-2.0233927;0.7101957;CODE
for the linkage function of hierarchy to work on precomputed;-1.4566324;0.09908299;0.4523582;0.73851186;3.5138793;3.578677;CODE
data provide as first argument an ndarray of the shape returned;5.053254;1.3190669;-1.1925905;-5.39166;-2.190373;1.2475766;IRRE
by sklearn metrics pairwise distances;5.453045;-4.926224;-0.9782023;-3.1953413;-1.7727088;-0.038795188;-
translate to something understood by scipy;1.8151786;-5.185062;-0.37003398;-2.759726;-3.4175966;-3.7062597;-
we need the fast cythonized metric from neighbors;5.223323;-2.2596033;1.2241465;-2.7517006;-0.76855457;1.8691239;CODE
the cython routines used require contiguous arrays;1.5226605;0.9047885;-0.38161093;-3.4929852;0.034955416;-0.036018062;CODE
sort edges of the min spanning tree by weight;2.3509479;-0.11454476;1.1234473;-2.7978795;-0.4935589;2.8367949;-
convert edge list into standard hierarchical clustering format;2.9807417;-2.4403718;0.67284703;-4.442554;0.8618022;3.2146623;CODE
put the diagonal to zero;-1.4059163;2.692744;3.5670502;-6.246219;-3.4292197;-0.5452633;-
fixme we compute all the distances while we could have only computed;3.1730678;1.2274593;0.22431383;-1.7870556;-2.602125;-0.740987;CODE
the interesting distances;3.3656662;-3.8394454;6.6436453;-1.162552;0.29670808;-1.2200301;CODE
create inertia heap and connection matrix;1.1360264;0.6454664;0.28576154;-4.0215554;-0.4421966;3.9882975;IRRE
lil seems to the best format to access the rows quickly;2.0890136;-1.2673566;3.1657863;-4.268519;2.0762553;-0.75431895;CODE
without the numpy overhead of slicing csr indices and data;5.4058905;-2.3027503;-3.1357214;-5.151656;-1.9575216;0.8672848;CODE
we are storing the graph in a list of intfloatdict;2.4809153;-0.5081703;2.322727;-3.9529634;-1.8370665;1.0074556;CODE
we keep only the upper triangular for the heap;-1.2648876;0.7713745;3.8045466;-0.70349115;0.8163142;0.93062705;CODE
generator expressions are faster than arrays on the following;2.7701;1.5106915;-0.60456634;-2.122079;-0.27051637;-2.668522;-
prepare the main fields;-1.3004748;-3.1786678;4.622422;1.3289455;2.4712713;-0.90014243;CODE
recursive merge loop;-0.24690393;2.3880196;2.6437492;-1.060748;0.72575814;-3.4864786;IRRE
identify the merge;-2.8260653;-1.018337;3.0961437;-1.0181752;3.5464737;-2.0424807;-
store distances;4.1592455;0.4760969;4.5329475;-3.1217182;1.3435488;1.530052;-
keep track of the number of elements per cluster;4.6722727;0.65147316;2.1975844;-3.0060773;1.5232209;0.4277972;-
update the structure matrix a and the inertia matrix;1.0020342;0.97224015;0.91685915;-2.5308104;-2.7105296;4.341572;CODE
a clever min or max operation between a i and a j;3.1422908;2.7574446;2.9814827;-3.3038466;2.1405456;-1.1668423;-
here we use the information from coord col containing the;1.2081358;-1.9082419;3.4350755;-5.6057262;1.1670678;-2.134721;CODE
distances to update the heap;2.1302588;1.3212355;2.6678236;-0.69302577;0.14798513;0.36128724;CODE
clear a i and a j to save memory;-2.2013268;2.1204991;2.435057;-0.07905984;-1.3500271;0.30150616;CODE
separate leaves in children empty lists up to now;-2.3097196;2.0997193;2.4558718;0.98324066;1.404134;-0.69968975;-
return numpy array for efficient caching;3.396349;0.4728264;-1.0649589;-2.808838;-4.7884283;1.0148889;CODE
matching names to tree building strategies;0.30232155;-2.808481;2.0492334;1.5177256;5.882306;-0.4516617;-
functions for cutting hierarchical clustering tree;2.8760984;-2.6763985;1.1935731;-1.2682157;2.180565;2.2425027;CODE
in this function we store nodes as a heap to avoid recomputing;0.80550456;0.9041853;-0.47661656;-1.1836894;1.4665177;1.5336052;CODE
the max of the nodes the first element is always the smallest;0.5597619;1.4942089;1.8097597;-3.6117086;0.14256564;0.22106318;-
we use negated indices as heaps work on smallest elements and we;1.3909869;0.5834758;-0.54685396;-2.9904695;2.362508;-0.50672567;-
are interested in largest elements;-0.63762915;-1.8498044;3.285695;-2.62358;1.2363093;-0.8331877;CODE
children 1 is the root of the tree;-3.7804272;-0.42206594;3.0860064;-0.2886356;2.0367653;-2.5356135;-
as we have a heap nodes 0 is the smallest element;-0.8993143;1.8233656;0.06553266;-3.0071466;0.863786;-0.46962136;-
insert the 2 children and remove the largest node;-1.1401615;3.63311;4.5315876;-3.8413298;1.3919473;-0.094762266;CODE
early stopping is likely to give a speed up only for;-0.4385432;0.53464675;1.2848738;5.3319526;-1.7005765;2.5735955;CODE
a large number of clusters the actual threshold;5.432377;-1.9639235;1.5610999;0.18076164;0.18208209;0.08145781;-
implemented here is heuristic;1.1956925;-2.1853569;4.2107124;1.9292818;4.655855;-0.41074026;TASK
construct the tree;-2.257053;-1.4175587;3.7492254;-0.45947278;4.215432;-2.3350215;CODE
if self distance threshold is not none distance threshold is used;2.438869;3.4762275;-1.568413;0.8110055;-0.8666607;1.0781941;CODE
else n clusters is used;1.759083;-0.026898881;1.7050442;-2.6278505;2.289812;-0.16166265;-
cut the tree;-3.0527942;-0.5651205;3.6863296;1.8334502;0.512573;-1.9654063;-
copy to avoid holding a reference on the original array;-0.20308653;3.7005284;0.5613974;0.2751601;-0.7373131;0.714267;CODE
reassign cluster numbers;1.3954723;1.2167368;-0.7532884;-4.5765886;1.8588593;1.0787313;IRRE
some eigenvalues of a a t are negative causing;-0.91397256;2.179272;-0.41006088;0.08678955;-4.832057;1.162317;IRRE
sqrt to be np nan this causes some vectors in vt;2.075987;0.3907832;-3.7168272;-5.082281;-5.417782;0.018471971;CODE
to be np nan;0.0457319;-1.384164;-0.07176224;-2.3886428;-1.4190911;-3.9902914;-
initialize with 1 1 as in arpack;-2.8784542;2.4605052;-1.5902865;-2.0643358;-0.35999507;0.3809247;IRRE
initialize with 1 1 as in arpack;-2.8784542;2.4605052;-1.5902865;-2.0643358;-0.35999507;0.3809247;IRRE
else tuple;-0.725811;0.97277766;3.2051313;-0.8770317;1.3831259;-3.8902578;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
make sure node1 is closest to itself even if all distances are equal;2.637781;3.5849502;-0.2952063;-1.152021;-0.72540945;0.89904916;CODE
this can only happen when all node centroids are duplicates leading to all;-0.20035273;3.2471883;-1.238228;-1.7579408;-2.1893175;2.9452858;CODE
distances between centroids being zero;2.2924151;3.886514;0.7506719;-4.9192376;-4.2467747;2.042528;-
the list of subclusters centroids and squared norms;3.84185;-2.72898;1.157347;-3.8638341;-0.33970723;2.6873045;-
to manipulate throughout;-3.6211975;-2.657378;9.108756;2.7785091;1.3419001;0.6725475;-
keep centroids and squared norm as views in this way;3.0913205;0.25746605;2.80037;-3.9626372;-1.6575402;6.8006306;CODE
if we change init centroids and init sq norm it is;1.2938732;2.2583683;-0.031533293;-3.6881912;-2.4489152;4.9118614;IRRE
sufficient;-2.4085505;0.85264844;5.6902184;1.7755886;1.064354;-1.8734425;-
because of numerical issues this could become negative;1.8686085;3.7950118;-0.607657;-1.9402281;-3.9627452;-1.3317912;CODE
if partial fit is called for the first time or fit is called we;1.3043263;2.2435968;1.8762182;3.0663154;2.562196;1.62544;IRRE
start a new tree;-3.319361;-0.87646097;3.5008404;1.6639047;1.8210738;-0.5096767;CODE
the first root is the leaf manipulate this object throughout;-4.5813966;-0.71586716;4.6279745;-0.397844;0.24662104;0.8130949;CODE
to enable getting back subclusters;-1.512821;-0.5305955;0.7595983;2.0414748;0.07849055;4.113005;-
cannot vectorize enough to convince to use cython;1.0019548;0.5741979;-2.9002326;-3.5979164;-3.6066165;1.0342714;-
perform just the final global clustering step;2.778959;-0.43857005;0.47780395;-0.37794322;0.6766625;3.7348835;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dbscan metric is not validated yet;0.45750862;0.7729096;-5.2835298;-0.40909463;-1.1243086;0.32950422;TASK
calculate neighborhood for all samples this leaves the original;6.6102877;2.183417;1.3354312;-2.581986;-0.9678459;-0.40977025;CODE
point in which needs to be considered later i e point i is in the;-1.9642076;-0.02769806;4.578488;2.5082452;3.2888486;0.41720322;CODE
neighborhood of point i while true its useless information;1.7899146;-0.3581799;2.2149994;-0.79082185;-0.41437447;0.05501719;CODE
set the diagonal to explicit values as a point is its own;1.3122429;2.7265365;1.4989349;-5.6604013;-1.6141548;2.756073;IRRE
neighbor;-0.08918441;-1.817538;4.305168;-0.024984386;0.72817355;-1.8324218;-
x x copy copy to avoid in place modification;-1.8431178;1.9288728;0.27617246;-1.5291504;0.098352954;2.2893035;CODE
this has worst case o n 2 memory complexity;0.80955654;0.78749245;-0.27358866;-1.5781122;2.4203627;-0.25468862;CODE
initially all samples are noise;3.4275854;1.3190836;-1.835775;2.2708492;-1.4044698;-0.58110905;IRRE
a list of all core samples found;3.4135273;-4.5466;-0.6480895;2.7013524;1.4006984;-2.3892713;-
fix for scipy sparse indexing issue;3.52935;-2.0856278;-6.768738;-4.093612;-5.26283;-0.06347805;IRRE
no core samples;0.19286317;-1.280964;-1.3019279;1.524973;-2.0548759;-2.272689;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
mixin class for feature agglomeration;2.6930995;-2.6735365;-2.4498007;-0.61974835;2.5062041;2.5626845;CODE
a fast way to compute the mean of grouped features;6.709637;-4.2182703;2.1292248;-0.9815478;1.6203433;1.9538363;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
redistribution and use in source and binary forms with or without;-2.6647937;-0.80558884;-2.205019;-1.0890408;5.278493;0.70217997;META
modification are permitted provided that the following conditions are met;-4.690063;1.632162;0.3372175;0.6699614;5.0898843;0.90391576;-
1 redistributions of source code must retain the above copyright notice;-5.293503;-2.4247677;-2.320428;0.47694176;1.5892305;-0.0031911582;META
this list of conditions and the following disclaimer;-3.1694458;1.9964614;-0.5951325;3.3097413;2.882659;-0.20676394;CODE
2 redistributions in binary form must reproduce the above copyright notice;-5.20111;-0.40945235;-2.979924;-2.6919394;3.098093;-1.1282672;META
this list of conditions and the following disclaimer in the documentation;-3.2955759;1.1498109;-1.7145323;3.4319687;3.6396382;1.4458841;CODE
and or other materials provided with the distribution;-0.9054127;-2.189002;4.0040417;-0.5560939;2.9407804;0.77652544;META
3 neither the name of the copyright holder nor the names of its contributors;-5.144567;-2.853571;-0.78296584;-2.1939976;1.8177469;-1.8638018;OUTD
may be used to endorse or promote products derived from this software without;-2.8413913;-5.071817;-0.6385582;1.6680455;1.810987;1.5254751;CODE
specific prior written permission;-4.32979;1.5171331;1.3658721;1.289174;2.6968436;0.6070074;-
this software is provided by the copyright holders and contributors as is;-3.6635652;-7.4281287;0.53392154;-1.0568374;1.8243268;-1.2357236;OUTD
and any express or implied warranties including but not limited to the;-3.0146248;0.8406256;-1.4500848;2.3040402;2.7623491;0.81115806;META
implied warranties of merchantability and fitness for a particular purpose;-1.8241695;1.8619481;-1.6574898;3.4015808;4.5321674;1.687379;CODE
are disclaimed in no event shall the copyright holder or contributors be;-4.7628994;-0.56930774;-1.8261784;1.5877062;0.39846954;1.2170122;OUTD
liable for any direct indirect incidental special exemplary or;-3.8432167;0.9334935;0.44271442;2.6947932;3.2232935;1.5634968;CODE
consequential damages including but not limited to procurement of;-2.8009334;1.2709025;-0.008399195;1.516769;2.6225798;1.0372971;META
substitute goods or services loss of use data or profits or business;-0.2822178;0.4136028;1.7751776;2.4774518;1.6341795;1.3103424;-
interruption however caused and on any theory of liability whether in;-5.435356;0.31344354;1.2262663;5.483502;0.88460225;0.004875019;CODE
contract strict liability or tort including negligence or otherwise;-4.9688253;1.0722415;-1.2435235;2.4410918;1.0292645;0.893746;-
arising in any way out of the use of this software even if advised of the;-3.942578;-3.8305385;-0.54743505;3.5004218;-0.19944671;-0.31945586;CODE
possibility of such damage;-2.4285438;0.2632133;2.680555;1.6385487;-0.5368986;-0.967404;-
encodings are arbitrary but must be strictly negative;-0.6058617;1.4260426;-4.4404087;-2.777567;1.1210726;0.6162058;TASK
the current encodings are chosen as extensions to the 1 noise label;0.9899122;-3.0849693;-3.0408716;-1.9777815;3.4171407;2.2972364;CODE
avoided enums so that the end user only deals with simple labels;-0.516169;2.1640434;0.28259075;-0.60606855;3.6522968;1.9772552;CODE
the probability could also be 1 since infinite points are certainly;-0.5818722;2.3796477;2.1517832;-0.16192576;-0.6056026;-1.8545338;IRRE
infinite outliers however 0 is convention from the hdbscan library;2.089422;0.31300816;-5.0838547;-2.485497;-2.0694067;-0.3117671;CODE
implementation;0.4730036;-0.9659206;4.6237373;0.7937431;3.9138992;-2.9248455;TASK
a nan probability is chosen to emphasize the fact that the;1.9128598;0.18924992;1.272689;0.7664526;-0.36012253;-1.3887175;-
corresponding data was not considered in the clustering problem;3.0373585;1.2871861;-3.0693293;-2.2038488;-0.17650053;1.0855452;CODE
check if the mutual reachability matrix has any rows which have;2.0238526;4.4948277;-0.9933179;-1.4998983;0.41127443;-0.34450293;IRRE
less than min samples non zero elements;5.340605;4.4667816;-1.4064709;-3.4749427;0.7631564;-0.8507778;-
check connected component on mutual reachability;-0.4282351;3.0230095;1.5567981;1.0213553;0.68322146;2.379874;-
if more than one connected component is present;-0.03896049;3.8290083;3.8726547;-0.5184164;3.4285023;0.72199017;-
it means that the graph is disconnected;-2.223727;-1.1588111;4.445382;-1.8545473;-1.728225;0.97798824;-
compute the minimum spanning tree for the sparse graph;1.6635739;-1.1695998;-0.38941613;-3.2365258;-0.5864096;1.3224925;IRRE
sort edges of the min spanning tree by weight;2.3509479;-0.11454476;1.1234473;-2.7978795;-0.4935589;2.8367949;-
convert edge list into standard hierarchical clustering format;2.9807417;-2.4403718;0.67284703;-4.442554;0.8618022;3.2146623;CODE
we need csr format to avoid a conversion in brute mst when calling;-0.5781764;1.357203;-3.0940812;0.8052279;-0.35100213;-3.108684;CODE
csgraph connected components;0.36851054;-1.8503418;2.3955283;-2.8908522;1.8391798;3.2731113;-
note that distance matrix is manipulated in place however we do not;3.9652388;0.24264145;0.45499945;-4.8155417;-4.5092835;4.0744157;TASK
need it for anything else past this point hence the operation is safe;-6.3427315;-0.8218621;2.0844543;0.79232883;0.6260722;0.47346166;CODE
warn if the mst couldn t be constructed around the missing distances;1.8216863;2.886749;-1.3269844;1.7184321;-0.7277457;1.1850497;CODE
the cython routines used require contiguous arrays;1.5226605;0.9047885;-0.38161093;-3.4929852;0.034955416;-0.036018062;CODE
get distance to kth nearest neighbour;3.6465383;-0.36714378;2.297476;-4.657409;-1.646519;-0.40160936;-
mutual reachability distance is implicit in mst from data matrix;3.569949;0.4426754;-2.065119;-1.7844874;-2.1076622;3.418372;CODE
hdbscan metric is not validated yet;0.50104344;-1.1411936;-6.356848;-0.7063427;-2.1586597;-0.6041173;TASK
todo 1 10 remove warn option;-5.094639;3.3143673;-0.18570718;2.9570127;-2.0067236;1.1402043;TASK
and leave copy to its default value where applicable in examples and doctests;-2.46571;2.1005685;-3.5641596;4.513583;1.6141757;0.3949354;IRRE
non precomputed matrices may contain non finite values;1.5255537;3.4725354;-3.2601306;-3.1853142;-0.9330363;1.7394806;IRRE
pass only the purely finite indices into hdbscan;2.3412483;0.7147535;-4.22907;-5.2981443;1.7282457;2.0441241;IRRE
we will later assign all non finite points their;0.87416077;0.9586891;1.8138629;-2.4422536;2.151692;1.5365025;IRRE
corresponding labels as specified in outlier encoding;3.979388;1.1480519;-1.7795237;-3.3056557;2.868313;1.6436093;-
reduce x to make the checks for missing outlier samples more;4.441989;4.9578767;-1.8230661;-0.10357863;-1.8817735;0.049980044;CODE
convenient;-2.3717875;-3.0443556;6.017468;2.5802886;1.3873496;1.2482594;-
samples with missing data are denoted by the presence of;2.8188727;2.1208084;-0.6286417;-1.1297393;2.714127;-2.1691508;TASK
np nan;-1.5824972;-0.50477827;1.5554569;-4.5749903;-2.6200979;-3.7662601;-
outlier samples are denoted by the presence of np inf;3.6044376;0.25830862;-3.5687387;-2.1337485;-1.3035238;0.1948749;TASK
continue with only finite samples;3.5945737;4.6487527;2.2195601;0.80435437;0.85978055;0.2529006;IRRE
handle sparse precomputed distance matrices separately;6.229268;0.13064201;-1.4960805;-2.6318517;-0.21676248;6.253362;IRRE
only non sparse precomputed distance matrices are handled here;6.300388;0.3573441;-2.903689;-2.8578453;-1.5387795;5.3090463;IRRE
and thereby allowed to contain numpy inf for missing distances;3.849499;0.53524375;-1.7268009;-3.3674078;-3.2026312;1.9595495;CODE
perform data validation after removing infinite values numpy inf;3.8732316;4.7921367;-3.2070696;-1.7946291;-5.065982;-1.2482435;IRRE
from the given distance matrix;3.1791313;-0.3228102;3.3770611;-5.755793;-2.3771043;0.6182383;CODE
todo support np nan in cython implementation for precomputed;0.07698089;1.3136582;-3.826083;-2.0103133;-2.422922;0.08337666;TASK
dense hdbscan;1.9185317;-3.8632038;-0.59357476;-3.2538533;-0.0529239;-0.31702733;-
we can t do much with sparse matrices;5.1633263;-3.1901312;-0.71829176;-3.095821;-0.44709155;3.3438754;IRRE
todo benchmark kd vs ball tree efficiency;3.2868185;-2.2027817;0.6853959;2.7384408;1.7983983;0.72736377;TASK
metric is a valid balltree metric;0.72809887;0.084779695;-1.2763553;0.122308195;1.424402;0.38082564;-
remap indices to align with original data in the case of;3.9144142;2.1362684;0.41242415;-5.32667;-0.07044377;2.0192924;CODE
non finite entries samples with np inf are mapped to 1 and;3.8234992;2.6884465;-4.3316846;-2.6122818;0.16639343;0.9261875;IRRE
those with np nan are mapped to 2;1.2658069;0.050384324;-2.7950077;-4.5004735;-0.24175307;-0.81514317;-
there may be overlap for points w both np inf and np nan;2.2653763;1.3356892;-3.4675882;-3.3088756;-2.5744817;0.048649713;CODE
infinite outliers have probability 0 by convention though this;1.4787729;2.9311588;-1.312746;0.0126185445;-1.6976547;-0.24115136;IRRE
is arbitrary;-0.7556839;0.27031872;0.14505804;0.3458721;4.6121492;-0.6850565;-
number of non noise clusters;3.3373954;-1.0097;-0.023550933;-0.9776914;0.8475999;0.1556956;-
need to handle iteratively seen each cluster may have a different;5.339164;0.5714834;0.6594347;0.81348914;3.4664228;3.040155;TASK
number of samples hence we can t create a homogeneous 3d array;3.9477184;2.929024;-0.92363054;-5.582828;0.7662025;0.63618326;IRRE
todo implement weighted argmin pwd backend;-0.89735734;-0.52580094;-0.8257192;0.28928655;1.1441761;3.5121999;TASK
infer indices from labels generated during fit;7.3828735;0.9251731;-1.2713789;-0.71411616;2.1437848;0.686401;CODE
overwrite infinite missing outlier samples otherwise simple noise;4.37621;3.000848;-2.327277;0.6412208;-2.8571079;1.9835773;TASK
buffers to avoid new allocations at each iteration;2.215215;1.1626363;2.1532845;1.2258323;0.4244446;2.0439777;CODE
compute new pairwise distances between centers and closest other;3.325925;0.16063099;2.7772086;-4.0310435;-1.3143535;1.2475188;CODE
center of each center for next iterations;1.8185153;1.6173123;6.6565304;-2.450369;-1.3589524;0.32440794;CODE
first check the labels for strict convergence;0.5360156;2.874132;-3.0765846;1.8782997;-2.9538896;0.88854045;CODE
no strict convergence check for tol based convergence;-0.5378289;4.111735;-4.176796;3.4381852;-2.1189115;1.2498896;CODE
rerun e step so that predicted labels match cluster centers;3.5907643;-0.552258;0.290385;0.7377478;-0.99638593;2.501467;CODE
threadpoolctl context to limit the number of threads in second level of;-1.8002219;0.24912022;0.69108284;1.7079817;0.87839526;3.6407835;CODE
nested parallelism i e blas to avoid oversubscription;-0.2106112;0.2484075;-0.32241026;-1.026493;2.480283;1.2845603;CODE
buffers to avoid new allocations at each iteration;2.215215;1.1626363;2.1532845;1.2258323;0.4244446;2.0439777;CODE
first check the labels for strict convergence;0.5360156;2.874132;-3.0765846;1.8782997;-2.9538896;0.88854045;CODE
no strict convergence check for tol based convergence;-0.5378289;4.111735;-4.176796;3.4381852;-2.1189115;1.2498896;CODE
rerun e step so that predicted labels match cluster centers;3.5907643;-0.552258;0.290385;0.7377478;-0.99638593;2.501467;CODE
same as labels inertia but in a threadpool limits context;0.16866857;-0.11168017;1.2700752;1.1786516;0.7649327;3.7119837;META
the blas call inside a prange in lloyd iter chunked dense is known to;-3.769376;0.6887726;-1.3310695;-1.8761805;1.6912171;1.859301;IRRE
cause a small memory leak when there are less chunks than the number;0.21441415;2.6409404;-0.58418643;0.2873419;-0.30125183;-0.74962723;-
of available threads it only happens when the openmp library is;-2.6908743;-0.71308845;-1.8553332;0.5606504;-3.486509;2.659205;CODE
vcomp microsoft openmp and the blas library is mkl see 18653;-4.259949;-4.575049;-1.736006;-4.2811136;-0.5620404;1.0357846;CODE
manually fit on batches;2.2161133;0.949833;-0.010044015;1.1779939;-0.26526782;2.40643;-
fit on the whole data;7.9932227;0.5416883;4.261341;-2.729921;0.78371567;0.19036414;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
if n neighbors 1 cannot fit nearestneighbors with n neighbors 0;3.6027822;2.047867;-0.8944773;-4.203199;-0.071902715;-0.7276274;-
separate function for each seed s iterative loop;4.904566;0.851744;2.5585349;-1.774336;1.0206105;-1.5688573;CODE
for each seed climb gradient until convergence or max iter;3.6198037;-1.2813982;2.0656085;0.07980591;-0.17326084;1.5018656;CODE
top thresh 1e 3 bandwidth when mean has converged;2.107597;2.838415;1.0346605;0.54974765;-2.7742739;2.787187;-
find mean of points within bandwidth;4.1152616;1.6513319;4.2092977;-2.6759295;-2.1512804;1.3786441;CODE
break depending on seeding strategy this condition may occur;1.2441123;3.2003934;1.461127;2.9178123;2.4536664;-1.0301636;CODE
my old mean my mean save the old mean;-1.3661861;2.0168521;3.02093;0.18903387;-1.9110205;0.4166613;CODE
if converged or at max iter adds the cluster;1.8188876;2.5314543;-0.4248206;0.8111585;-0.9207823;1.4145311;TASK
bin points;1.6070207;-0.49326035;3.5587335;-4.681721;1.1154833;-4.5439224;CODE
select only those bins as seeds which have enough members;1.3651297;1.4166294;0.70735896;-1.3259614;3.243778;-1.2373652;CODE
we use n jobs 1 because this will be used in nested calls under;-2.597654;-0.717042;1.8964838;1.4879425;3.6437366;0.12389667;IRRE
parallel calls to mean shift single seed so there is no need for;1.4756527;0.89623326;0.89578044;0.05167759;1.3157295;2.0097404;IRRE
for further parallelism;-0.5442377;-3.090671;4.604029;0.91430783;0.84864175;-0.29827237;CODE
execute iterations on all seeds in parallel;1.8198017;0.973186;2.0871027;2.4016898;0.73356277;0.96299523;CODE
copy results in a dictionary;0.6093735;-0.5967101;1.0592504;0.8624969;0.25244007;-2.458325;IRRE
if all res i 1 i e len points within 0;3.6515718;4.146708;2.4865835;-6.3810697;-0.4348321;-3.6605914;CODE
nothing near seeds;-1.6734487;-0.71267635;2.4214854;0.71724766;-1.731183;-2.3869627;-
post processing remove near duplicate points;1.9106189;3.9260569;2.0273173;-0.079114154;0.85874736;1.1146799;CODE
if the distance between two kernels is less than the bandwidth;3.2436516;-0.14881687;0.6062087;-0.4972737;-0.5849157;3.8098109;-
then we have to remove one because it is a duplicate remove the;-4.8282914;0.21168007;1.4297215;1.4295336;2.4037225;2.626624;-
one with fewer points;1.8349481;0.2852571;5.269907;-0.64887464;2.2297823;-3.360815;CODE
unique i 1 leave the current point as unique;0.90588135;3.7764878;2.2446787;-2.4276276;1.6963878;1.6677588;CODE
assign labels a point belongs to the cluster that it is closest to;4.403793;0.5110618;1.9087566;-3.212288;2.0282128;3.1060157;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
optics metric is not validated yet;-0.1829251;0.09574299;-4.3273497;0.76331633;-3.7195158;1.6254033;TASK
x x copy copy to avoid in place modification;-1.8431178;1.9288728;0.27617246;-1.5291504;0.098352954;2.2893035;CODE
set each diagonal to an explicit value so each point is its;2.6915073;2.3948364;3.2115219;-6.6557145;-0.96583086;1.5499791;IRRE
own neighbor;-0.8675077;-0.7474467;3.501845;0.31425244;0.1485798;-0.6030343;-
extract clusters from the calculated orders and reachability;4.5047503;0.19412439;1.8740705;-0.48843652;3.0251672;0.4323454;CODE
optics helper functions;-0.91259646;-2.2721946;2.128748;-0.3577397;-1.6287682;2.059661;CODE
prefer skip nested validation false metric is not validated yet;1.1553506;4.5664725;-5.399117;4.0061145;-0.17553315;1.3955313;TASK
start all points as unprocessed;-0.17779064;1.700888;2.064512;-0.1212365;-1.631896;1.6060508;CODE
here we first do a knn query for each point this differs from;3.9932396;-0.9847799;1.5700177;-4.7788568;1.3391898;-1.2438488;CODE
the original optics that only used epsilon range queries;1.1602451;-0.10128413;-0.9320019;-0.03493936;-2.3846867;1.6691815;-
todo handle working memory somehow;-3.3265164;0.47931427;1.8722337;4.178869;-0.61453617;0.9794487;TASK
optics puts an upper limit on these use inf for undefined;-2.1920304;1.9738941;-2.1974766;-0.9856618;-2.766134;0.78234327;CODE
main optics loop not parallelizable the order that entries are;-0.5310861;2.1228635;-0.026176756;-2.1194503;-1.3230404;2.2370102;CODE
written to the ordering list is important;-1.8778944;-0.6229015;2.8513792;0.48285842;3.7559116;-1.9265324;CODE
note that this implementation is o n 2 theoretically but;0.8743905;-0.40438035;-1.2107478;-2.5560153;2.513611;0.60310066;TASK
supposedly with very low constant factors;0.06680864;-0.26281628;0.5754035;-0.5251789;-3.2986739;0.47007594;CODE
choose next based on smallest reachability distance;2.0380032;2.012831;4.2435236;-0.376252;2.208451;0.23682834;CODE
and prefer smaller ids on ties possibly np inf;-0.18832165;-1.1456814;0.023808287;-1.9738141;4.1962585;0.7078754;-
assume that radius neighbors is faster without distances;3.1618161;0.5635863;2.1535487;-1.5477839;-1.3455272;0.6819956;-
and we don t need all distances nevertheless this means;0.759153;0.5654803;3.3520732;-0.071912386;-0.6366275;2.0778003;CODE
we may be doing some work twice;-2.223523;-0.50978357;2.5080907;3.5262961;-1.9284041;-1.3196074;CODE
getting indices of neighbors that have not been processed;4.491518;2.2082162;-0.7880525;-1.8415793;-0.20800132;-0.5952054;-
neighbors of current point are already processed;2.6388721;1.1436733;0.28435826;-1.3977734;-2.062604;3.928361;CODE
only compute distances to unprocessed neighbors;4.725399;-0.47875854;-1.2482382;-2.4336014;-1.6339183;1.3259568;-
the same logic as neighbors p is ignored if explicitly set;-0.017383771;3.7903612;-1.5007129;0.20264912;0.8035804;1.4456575;IRRE
in the dict params;-2.779164;-0.34158805;1.347593;-1.6994503;1.3761659;-2.7253504;CODE
find a maximal area;-0.16563588;2.573807;5.4350204;-3.7803445;-0.49229753;0.3480085;-
it s not a steep point but still goes up;-0.38796806;1.0866416;2.5994298;0.031852506;-3.5634234;0.5071666;TASK
region should include no more than min samples consecutive;3.2808785;4.8350654;-0.41306156;-0.63766193;2.1452878;0.5381361;CODE
non steep xward points;0.9835222;0.5333844;0.49985516;-3.8943696;-0.83025557;1.3812333;CODE
our implementation adds an inf to the end of reachability plot;0.44357938;-1.5858746;1.1946906;1.8195726;-1.9346495;1.994131;TASK
this helps to find potential clusters at the end of the;3.272386;-1.6413106;4.1710253;-1.8863392;-1.4579339;-0.11287324;CODE
reachability plot even if there s no upward region at the end of it;0.018448535;2.554158;4.1369743;-0.87006354;-4.8612213;1.5631378;CODE
das steep down areas introduced in section 4 3 2 of the paper;-1.6449593;-1.9195867;1.1651213;-1.0859865;1.2834432;3.1563628;CODE
mib 0 0 maximum in between section 4 3 2;-1.1134162;3.0350428;-2.6944196;-2.7668505;0.8149737;-0.04557185;-
our implementation corrects a mistake in the original;-0.7472748;1.8318491;-2.1816416;1.4991723;-0.3444156;-0.95776933;TASK
paper i e in definition 9 steep downward point;-1.5374339;-0.04103547;2.3233585;-1.6469029;1.3155407;-0.28840658;CODE
r p 1 x1 r p 1 should be;-0.5616664;3.4412782;-0.5960872;-5.354077;1.5399694;-2.04656;-
r p 1 x1 r p 1;-0.34597957;2.80991;1.4938663;-5.6624045;2.1828973;-1.9005319;-
the following loop is almost exactly as figure 19 of the paper;0.2593807;1.4424913;2.2140162;-3.0121107;-3.0701668;-1.8451462;IRRE
it jumps over the areas which are not either steep down or up areas;-2.0815315;-0.6283274;3.815836;0.43363506;-1.202746;1.5194863;CODE
just continue if steep index has been a part of a discovered xward;1.2782161;1.8856802;0.3583486;-0.14168084;0.74091524;0.77877307;CODE
area;-1.8504066;-1.238373;7.5493617;-1.6846358;0.43167025;-1.4184417;-
steep downward areas;0.34622;-0.1541066;4.9743657;-1.5383326;-0.17993978;1.8023068;CODE
steep upward areas;0.092090845;-0.20614119;4.4974585;-1.2097067;-0.05423216;1.9219968;-
line sc2;-3.2089841;-1.3514761;2.7648618;-2.3279505;-0.3538091;-1.747703;-
definition 11 criterion 4;-0.05794916;1.514976;-1.1845313;4.059437;4.7595863;-0.8829814;IRRE
find the first index from the left side which is almost;1.3751155;3.3289447;3.4704006;-6.056705;-2.093756;-2.274326;CODE
at the same level as the end of the detected cluster;3.6051934;-0.61523044;1.7134048;1.1240042;1.9276857;1.088283;CODE
find the first index from the right side which is almost;1.6690935;3.4148886;3.437091;-6.022428;-2.0283358;-2.381843;CODE
at the same level as the beginning of the detected;1.1296259;0.32058743;2.6437278;2.588592;2.295912;-1.1067998;-
cluster;3.968887;-3.0908215;5.276844;-0.80083305;2.730179;-0.8607726;-
our implementation corrects a mistake in the original;-0.7472748;1.8318491;-2.1816416;1.4991723;-0.3444156;-0.95776933;TASK
paper i e in definition 11 4c r x r sd should be;-2.3109155;-0.65642834;-1.2927052;-2.150891;4.487606;-0.15383936;IRRE
r x r sd;-0.23282239;-0.07151427;3.2131183;-3.5910382;1.7875743;-2.5775857;-
predecessor correction;-2.102695;2.2064438;0.61198026;0.2732226;1.7991123;-1.9747695;-
definition 11 criterion 3 a;-0.115044326;1.6841956;-1.2958733;3.761236;5.149593;-1.1559042;IRRE
definition 11 criterion 1;0.039395373;1.2163225;-1.0770186;4.0732327;5.091546;-0.7757599;IRRE
definition 11 criterion 2;0.11387289;1.3623695;-1.208824;4.205806;4.961279;-0.77639747;IRRE
add smaller clusters first;1.9909186;0.67825323;2.9323094;-2.534566;-0.0407128;3.5030339;TASK
generate sample data;5.170891;0.29904035;3.201082;-1.1294352;2.7187808;-3.5542893;-
the data is voluntary shifted away from zero to check clustering;2.9660804;2.4207523;-2.5823283;-0.67004186;-2.792586;1.4048225;CODE
algorithm robustness with regards to non centered data;6.988946;1.3866218;-1.2077109;-0.6575099;-0.36235425;2.3537998;-
todo affinitypropagation must preserve dtype for its fitted attributes;1.1122133;-1.6557208;-5.7596397;0.9756046;-1.2243253;5.79759;CODE
and test must be created accordingly to this new behavior;-3.9033775;5.3494253;-2.165414;6.855919;0.41599828;-1.6361089;IRRE
for more details see https github com scikit learn scikit learn issues 11000;-1.6383427;-10.444963;-6.256707;-0.7503379;-4.9537582;-3.847731;CODE
with copy true s should not be modified;-3.2477396;3.1407936;-3.2138047;2.321075;-0.36083248;0.69393885;-
with copy false s will be modified inplace;-2.5998964;4.491937;-1.9100094;0.3775854;0.32586572;1.3854938;-
test that copy true and copy false lead to the same result;0.8121911;6.657083;-1.0707563;4.0714593;-0.97075176;-6.385779;IRRE
sanity check for the number of samples in leaves and roots;2.3309143;2.9818757;0.67132086;1.5483509;0.6541522;-3.9925103;CODE
test that fit is equivalent to calling partial fit multiple times;4.575113;5.8779125;-0.73310286;4.766286;1.7072308;-0.90471053;IRRE
test that same global labels are obtained after calling partial fit;3.960642;5.348603;-2.1114683;3.2700768;0.891171;1.3715941;IRRE
with none;-2.013116;1.8474765;4.6586127;0.77394676;-0.27118787;-3.4376907;-
test the predict method predicts the nearest centroid;4.841613;2.1427038;0.58842367;1.9577225;-2.1296575;-1.0455278;IRRE
n samples n samples per cluster;4.0211263;-1.062011;1.2017304;-2.2251034;1.8526088;0.36745676;-
birch must preserve inputs dtype;-0.8042306;-1.2695012;-4.503381;-0.27213374;0.35714242;1.4328073;CODE
test that n clusters param works properly;3.7345173;3.8875716;-1.8449575;1.3556308;-0.08656397;-1.7927908;IRRE
test that n clusters agglomerative clustering gives;4.273118;-1.1528991;-1.0766982;1.6822622;0.8473341;-1.4501977;IRRE
the same results;-0.21697932;-0.9842096;3.6070697;3.3215566;-0.18607113;-2.7026422;IRRE
test that a small number of clusters raises a warning;3.3557198;3.3375976;-2.1116602;4.093418;-1.0205363;-3.1094775;IRRE
test that sparse and dense data give same results;5.812231;2.4741783;-3.0337975;1.6741463;-0.98347795;-1.8844997;IRRE
birch must preserve inputs dtype;-0.8042306;-1.2695012;-4.503381;-0.27213374;0.35714242;1.4328073;CODE
second partial fit calls will error when n features is not consistent;3.4508893;3.5444543;-5.40422;2.9171276;-0.40183;3.5671873;TASK
with the first call;-2.8270836;1.0646117;7.268219;2.907579;0.8628383;-1.5984145;IRRE
test that nodes have at max branching factor number of subclusters;2.0682268;1.7263799;-2.3424807;1.4591044;1.7156336;-0.9471407;IRRE
purposefully set a low threshold to maximize the subclusters;4.7165594;0.23220883;0.49299496;1.9254366;1.6947719;3.6012766;IRRE
no error;-5.884342;2.4395564;-0.39530978;0.04724649;-3.420438;-3.2771664;-
check if results is the same for dense and sparse data;7.701946;2.6357677;-2.3675554;0.5685907;0.50074774;-0.7709177;IRRE
all labels from fit or predict should be equal 0;3.905697;3.0831;-2.7532258;-1.4206628;-0.77827203;-0.9405331;CODE
tests the dbscan algorithm with a similarity array;4.914506;0.6241223;-1.7797114;-1.1517246;2.5137897;-1.6436958;IRRE
parameters chosen specifically for this task;3.4974391;2.1079051;4.6801233;-1.5763961;3.2334697;0.56952935;IRRE
compute similarities;4.6560388;-0.66888034;4.4890213;-3.3662333;2.5861204;-3.2047348;-
compute dbscan;3.0540898;-0.3217431;0.040310137;-4.4363427;1.5708112;-1.6159292;-
number of clusters ignoring noise if present;4.341838;1.4382159;-0.75553477;1.4727777;0.30890134;0.40066797;-
tests the dbscan algorithm with a feature vector array;5.2921057;-1.001523;-3.3621879;-1.138912;2.2058334;-0.6116482;TASK
parameters chosen specifically for this task;3.4974391;2.1079051;4.6801233;-1.5763961;3.2334697;0.56952935;IRRE
different eps to other test because distance is not normalised;4.0056796;5.295792;-1.9707896;-0.8389708;-1.9260432;0.40128055;IRRE
compute dbscan;3.0540886;-0.3217442;0.040309064;-4.4363427;1.5708103;-1.61593;-
parameters chosen for task;0.71761227;0.6453373;3.073248;2.4153974;1.9431218;1.4035536;TASK
number of clusters ignoring noise if present;4.341838;1.4382159;-0.75553477;1.4727777;0.30890134;0.40066797;-
ensure it is sparse not merely on diagonals;4.2395825;1.0673556;-0.72801846;-3.2504592;-1.4909129;4.30532;IRRE
test that precomputed neighbors graph is filtered if computed with;3.8223665;4.0070853;-1.3740833;1.2958683;-1.0771033;-0.8418516;IRRE
a radius larger than dbscan s eps;2.6674178;1.239969;-0.14542124;-3.4700127;-1.3064489;2.329202;-
test that the input is not modified by dbscan;1.3902012;3.9543827;-2.729382;2.3282585;0.38293567;-2.3067102;IRRE
add zeros on the diagonal that will be implicit when creating;-0.6033233;2.9880672;0.7707428;-6.758166;-2.676927;0.8254944;TASK
the sparse matrix if x is modified in place the zeros from;3.4710906;1.3689072;-1.7438973;-4.6132116;-1.7293731;3.5746703;IRRE
the diagonal will be made explicit;-1.0790681;-0.059456754;3.351569;-3.9908333;0.2821148;-0.033458948;-
make sure that we did not modify x in place even by creating;-5.4349523;3.1745992;0.2963419;0.4812601;-1.0796968;0.97504485;-
explicit 0s values;-0.63982564;4.002932;-1.8285799;-5.652472;-0.5872648;-3.2583628;IRRE
tests the dbscan algorithm with a callable metric;3.7533376;-0.65059835;-1.4044614;0.8103963;2.4679792;-0.21844207;IRRE
parameters chosen specifically for this task;3.4974391;2.1079051;4.6801233;-1.5763961;3.2334697;0.56952935;IRRE
different eps to other test because distance is not normalised;4.0056796;5.295792;-1.9707896;-0.8389708;-1.9260432;0.40128055;IRRE
metric is the function reference not the string key;-1.0336468;0.12065313;-2.4710913;-1.3577075;-1.3194044;-1.0038071;CODE
compute dbscan;3.0540898;-0.3217431;0.040310137;-4.4363427;1.5708112;-1.6159292;-
parameters chosen for task;0.71761227;0.6453373;3.073248;2.4153974;1.9431218;1.4035536;TASK
number of clusters ignoring noise if present;4.341838;1.4382159;-0.75553477;1.4727777;0.30890134;0.40066797;-
tests that dbscan works with the metrics params argument;2.7774305;1.1706482;-4.299172;1.4510754;0.14786774;0.14453018;IRRE
compute dbscan with metric params arg;2.7898026;0.7324665;-2.173816;-3.4458733;0.3898565;1.0675758;-
test that sample labels are the same as passing minkowski p directly;4.2632275;2.547098;-3.0088391;-0.23496056;0.50037664;-0.1925249;IRRE
minkowski with p 1 should be equivalent to manhattan distance;1.2949862;0.7484859;-0.19903192;-3.0192046;-2.2760794;2.7938108;-
test that checks p is ignored in favor of metric params p val;2.0558832;6.4178357;-4.2431774;3.5884914;-2.196291;-2.1122627;IRRE
tests the dbscan algorithm with balltree for neighbor calculation;4.778081;-0.58525234;-1.26188;-1.5874029;1.4137858;-1.6718948;IRRE
number of clusters ignoring noise if present;4.341838;1.4382159;-0.75553477;1.4727777;0.30890134;0.40066797;-
dbscan fit should accept a list of lists;3.5877178;1.1300219;-2.0247717;-1.2201613;1.5981977;1.3021666;CODE
dbscan fit x must not raise exception;0.1440841;3.498467;-5.3083696;-0.009135348;-0.7346597;1.935678;CODE
ensure min samples is inclusive of core point;6.525978;3.0478764;-1.7775098;0.742368;1.304387;4.3301024;CODE
ensure eps is inclusive of circumference;0.83061945;4.132469;0.21044378;-2.2108123;-1.329946;2.708812;-
ensure sample weight is validated;4.3202605;4.9840865;-3.1283352;4.4767013;1.7682538;-0.20594051;-
ensure sample weight has an effect;4.185658;4.1518292;0.07360863;4.388826;0.87489283;0.879872;-
points within eps of each other;3.6235492;2.5640152;2.985419;-6.3124547;-0.70997345;0.44386512;CODE
and effect of non positive and non integer sample weight;3.3208017;2.616917;-1.2897421;0.4702718;0.87236565;-0.38831982;CODE
for non negative sample weight cores should be identical to repetition;4.858488;1.7359276;-2.983314;1.6684116;0.48883346;1.9930035;CODE
sample weight should work with precomputed distance matrix;6.7383633;1.4950435;-1.6491795;-2.2300136;-0.89049494;3.8277504;-
sample weight should work with estimator;2.9702637;3.115287;-0.21879658;2.0486836;-0.88726383;2.129246;-
degenerate case every sample is a core sample either with its own;2.9594038;0.6624141;-1.7509762;2.7075157;4.494533;2.4383192;CODE
cluster or including other close core samples;5.9160137;-2.1860301;0.39271352;1.7562591;3.4965196;2.6521292;CODE
with eps 1 and min samples 2 only the 3 samples from the denser area;4.1403446;2.9511766;0.38975322;-4.376328;1.3845462;1.847752;CODE
are core samples all other points are isolated and considered noise;4.127182;-0.8918089;-1.4968148;1.1330928;0.81854135;2.6521235;CODE
only the sample in the middle of the dense area is core its two;2.1549993;1.3049613;1.8898576;-0.48283398;-0.41887754;1.4406483;CODE
neighbors are edge samples remaining samples are noise;4.2684393;-0.2973538;-1.0869037;-1.1919392;-1.3642416;0.7086676;CODE
it s no longer possible to extract core samples with eps 1;0.22554159;-1.5991912;-3.6113908;-0.5487472;-2.1909616;1.9812392;OUTD
everything is noise;-0.7441102;-1.5606642;2.589122;2.2022753;-1.9608424;-0.22681402;-
see https github com scikit learn scikit learn issues 4641 for;-2.316297;-10.636768;-7.1706123;-0.7744231;-4.8310037;-4.3055367;CODE
more details;-2.4105227;-2.2402644;4.5944734;0.51398784;0.5794692;-1.3544549;-
sample matrix with initial two row all zero;3.6359932;4.6490765;0.21858802;-4.909215;-0.652583;-0.5977652;IRRE
x np array 0 0 1 reshape 1 3 n samples n features;5.820654;-0.5533579;-2.0820432;-8.324794;-1.6162364;1.7393304;TASK
test transform;2.3050737;4.4743905;0.39611572;0.66798264;-2.042992;-5.261664;IRRE
test inverse transform;0.86360836;5.1730027;0.17711306;0.60630846;-3.5931127;-3.7686207;IRRE
ensure the matrix is not symmetric;0.99547017;3.3176389;-2.0221808;-3.3048613;-2.2070599;-0.027263314;-
check that clustering is arbitrarily good;5.0065613;1.059876;-0.55324775;1.6022002;0.88492626;-1.4293467;-
this is a heuristic to guard against regression;6.0401816;-1.417592;1.4042484;5.445621;0.81271845;-0.88901055;CODE
validation for brute is handled by pairwise distances;4.848266;3.1124735;-1.5890156;1.5673434;1.2874992;-3.149016;CODE
we use a looser threshold due to dbscan producing a more constrained;3.8751173;-0.080024146;-1.7193297;1.1222824;1.6501603;2.605171;CODE
clustering representation;5.9014206;-3.646406;2.888201;-3.6683288;4.092319;1.8381425;-
compare that the sparse and dense non precomputed routines return the same labels;6.318709;-0.8181054;-3.6889634;0.04421616;0.3654251;1.4966241;IRRE
where the 0th observation contains the outlier;2.558597;2.5571227;-0.29158357;-1.4724783;-2.360943;-0.2305762;-
ensure that nothing is done for noise;-0.26539525;2.1129746;-0.1038662;4.8950725;-0.6768537;0.54606813;CODE
without epsilon we should see many noise points as children of root;1.3529422;0.4814924;-2.5330224;0.9099903;-0.105903946;1.6962221;CODE
arbitrary heuristic would prefer something more precise;3.348807;-1.6836303;1.6427858;2.742826;3.8240979;-0.5771101;-
for this random seed an epsilon of 0 18 will produce exactly 2 noise;1.1837361;1.3673295;-2.4789994;-0.058965113;-1.0369921;-2.702066;CODE
points at that cut in single linkage;-0.4788068;0.080415346;3.1285536;-0.5808098;2.2746782;1.8888711;CODE
create symmetric sparse matrix with 2 connected components;3.6077893;-0.6686883;0.15590864;-6.4624686;0.78235644;4.7279687;IRRE
callables are not supported for either;-6.546109;-0.11995997;-2.8713949;1.5723827;-2.1816375;2.5517812;IRRE
the set of valid metrics for kdtree at the time of writing this test is a;3.7302473;-0.23982997;-3.0191233;1.6494031;0.22647387;-3.8084135;IRRE
strict subset of those supported in balltree;-0.6028601;1.1201315;-1.8011438;1.17895;2.6047528;1.3330991;IRRE
ensure the clusters are distinct with no overlap;4.235274;3.4705408;0.58026254;-1.8814036;2.3960989;1.0304242;-
the threshold should be calculated per sample based on the largest;4.290764;2.2630572;0.77079374;0.6418518;1.7664399;-0.90416324;CODE
lambda of any simbling node in this case all points are siblings;1.0040174;1.8857319;0.2968998;-3.4664311;1.0001506;0.9277242;CODE
and the largest value is exactly max lambda;1.356399;1.4547215;0.1654222;-1.294368;0.13291027;0.38993904;IRRE
todo 1 10 remove this test;-3.0449722;5.832788;-0.8860404;3.1743498;-1.4538953;-6.3706603;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
misc tests on linkage;-1.0536593;3.241945;-2.3860734;3.5660357;0.07603995;-1.5354028;IRRE
smoke test featureagglomeration;4.1426044;1.1099421;-2.072041;3.046606;0.15761504;0.37098488;TASK
test hierarchical clustering on a precomputed distances matrix;6.45638;-0.17320566;-0.605023;-0.7058951;-0.085890435;1.5723121;IRRE
test hierarchical clustering on a precomputed distances matrix;6.45638;-0.17320566;-0.605023;-0.7058951;-0.085890435;1.5723121;IRRE
check that we obtain the correct solution for structured linkage trees;-0.51989067;0.302884;-1.8077993;-0.59372145;5.2134743;-0.25918984;CODE
avoiding a mask with only true entries;1.9866481;5.119365;0.5729043;-0.3525387;1.815357;1.0914351;CODE
check that ward tree raises a valueerror with a connectivity matrix;1.9101403;2.206589;-3.856661;-1.1576383;-2.549148;-0.20437329;IRRE
of the wrong shape;-0.45296007;0.08263752;5.5054116;-1.590098;-2.3664744;-1.2346524;META
check that fitting with no samples raises an error;3.4077287;6.6150336;-5.90804;1.7892154;-4.7430325;-1.4685715;CODE
check that we obtain the correct solution for unstructured linkage trees;-0.22878915;-0.35337815;-1.8098955;-1.5338589;4.0621796;-0.40508604;CODE
with specified a number of clusters just for the sake of;4.028753;-0.85919124;3.3851998;-0.8462097;3.1235886;1.1373926;CODE
raising a warning and testing the warning code;-2.8020084;4.036818;-2.2912188;6.744827;0.012831216;-4.3626866;IRRE
check that the height of the results of linkage tree is sorted;0.38213256;3.1646574;1.0002139;-0.22207507;0.5022332;-0.78852963;IRRE
check that zero vectors in x produce an error when;2.3281622;4.951378;-4.9493876;-4.6469007;-3.3310246;-2.581769;-
cosine affinity is used;0.34163338;-0.5093538;0.75321716;-0.9640309;-1.2962414;2.2952266;IRRE
check that when compute distances is true or distance threshold is;4.585869;3.8000844;-0.2845087;0.80806655;-0.49699733;-2.4295287;-
given the fitted model has an attribute distances;4.993865;1.0747906;1.8155375;-1.7186762;0.6758787;2.4673548;META
check that we obtain the correct number of clusters with;2.4573233;3.5033333;-0.36824802;-1.8449186;0.7591085;-3.6474721;CODE
agglomerative clustering;5.160406;-3.8560686;1.4338936;-0.3796308;2.0723076;1.4391288;-
test caching;0.6970314;3.359196;0.71737874;6.482964;-0.77276444;-2.858193;IRRE
turn caching off now;-4.4408617;1.3036089;2.223959;2.5204763;-3.4511316;2.5818505;-
check that we obtain the same solution with early stopping of the;-0.5993479;4.367478;0.57134086;5.464231;-2.8086572;0.6735437;CODE
tree building;-1.4054143;-3.5440738;4.72303;0.056784425;2.5931795;-1.9292309;-
check that we raise a typeerror on dense matrices;2.4340186;2.8898752;-6.211114;-1.1844465;-3.3931336;1.0807649;CODE
test that using ward with another metric than euclidean raises an;3.4372375;3.731885;-1.7856226;0.8236584;-1.9098909;-0.7826218;CODE
exception;-4.882411;3.3908012;1.429237;3.3264651;0.4799478;-4.333034;CODE
test using another metric than euclidean works with linkage complete;2.3481495;3.8638775;-2.0479088;1.425299;-1.6212298;-1.1785141;CODE
compare our structured implementation to scipy;4.2429914;-5.284927;-3.9209936;-0.92138904;-2.3062932;-3.1575985;TASK
test that using a distance matrix affinity precomputed has same;5.32106;2.4793923;-3.612484;-0.050578948;-1.6687195;2.3245459;IRRE
results with connectivity constraints;5.191313;-0.0270574;0.8090232;-1.4935188;1.3559948;2.0776715;CODE
check that we obtain the correct solution in a simplistic case;-1.3203259;5.5608854;0.22660393;0.8632755;-1.5860877;-4.232484;CODE
check that fitting with no samples raises a valueerror;3.8632467;5.405617;-6.8625584;1.6479555;-5.851061;-1.1180553;IRRE
check that we get the correct result in two emblematic cases;-1.3860533;6.7464223;0.3572601;0.8377897;4.223486;-5.517451;CODE
non regression test for issue 19875;-0.047610644;3.8148367;-4.350605;3.439239;-2.480081;-5.507084;IRRE
greater than 1 non regression test for 16151;0.45509648;4.8246007;-3.9533517;2.8677928;-3.298631;-5.94474;IRRE
non regression test for 26657;0.024233816;3.4986286;-4.0426846;3.0544448;-3.1683605;-6.1624937;IRRE
non regression test for 21964;-0.79038334;2.7354136;-5.341817;2.7543805;-4.03618;-5.849425;IRRE
make cluster centers readonly;0.47295734;-0.8815964;1.1020943;0.11230433;-1.2657803;5.2615557;CODE
no center should be one of the 0 sample weight point;1.6075685;3.993095;-0.51707333;-2.0978076;-3.0117443;2.1158326;CODE
i e be at a distance 0 from it;-0.7185835;1.5957558;4.194583;-1.2314109;-4.101283;-1.817136;CODE
test convergence using 1d constant data;5.334078;4.6735563;-1.647888;1.1546392;-3.6070268;-0.7354847;IRRE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 28926;-3.2803771;-9.868725;-5.9945927;-0.20819363;-5.595216;-5.4110436;CODE
test estimate bandwidth;2.8855393;2.6171632;0.65370536;3.687983;-1.4337497;-0.9123895;IRRE
test estimate bandwidth when n samples 1 and quantile 1 so that;1.9752558;3.3962991;0.6900192;0.7490402;-1.3665172;0.16430147;IRRE
n neighbors is set to 1;1.340552;1.2697128;2.1053426;-3.8026698;-0.19721931;-1.7938241;IRRE
test meanshift algorithm;4.809717;3.6925743;-1.0446023;3.30721;-2.3666859;-2.433098;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
test meanshift predict;4.2743616;3.0789497;-1.1924306;5.552796;-3.9217546;-2.84413;IRRE
init away from the data crash with a sensible warning;-2.0861502;1.3230187;-1.6677817;4.608975;-1.3815501;0.33817187;IRRE
non regression before fit there should be not fitted attributes;1.6120579;2.8067067;-2.9176104;2.0462542;-2.437778;3.1059008;META
test the bin seeding technique which can be used in the mean shift;4.1205215;1.7971524;0.74837136;0.056896303;-1.3820045;-1.2780954;IRRE
algorithm;4.409945;-0.2822192;4.6803837;-2.8470244;3.30263;-4.743204;-
data is just 6 points in the plane;5.0034657;1.049329;3.053916;-4.6419835;-1.7893417;-1.7913142;CODE
with a bin coarseness of 1 0 and min bin freq of 1 3 bins should be;1.6299615;1.703215;-2.905008;-3.6214056;0.57675076;0.18640418;-
found;-3.7550693;-1.4731429;2.7264392;0.15267682;-0.2930322;-2.2349648;-
with a bin coarseness of 1 0 and min bin freq of 2 2 bins should be;1.967344;1.7457876;-2.6684408;-3.2492008;-0.06549951;0.46868783;-
found;-3.7550693;-1.4731429;2.7264392;0.15267682;-0.2930322;-2.2349648;-
with a bin size of 0 01 and min bin freq of 1 6 bins should be found;0.36999628;2.0325642;-1.2453314;-5.00116;0.33420017;-4.1137514;-
we bail and use the whole data here;2.9754221;-2.1514175;3.734496;1.5071577;0.31072715;-1.7505944;IRRE
tight clusters around 0 0 and 1 1 only get two bins;1.6748092;2.088445;-2.27047;-4.4793086;-2.5063698;-0.7485468;CODE
check that mean shift works when the estimated bandwidth is 0;1.3442063;4.351562;-1.8167392;0.49146482;-4.976472;3.2112112;CODE
estimate bandwidth with default args returns 0 on this dataset;3.4272048;1.6588627;-2.9658237;0.3446745;-4.1192694;2.8533726;IRRE
get bin seeds with a 0 bin size should return the dataset itself;2.7321188;2.2626061;-2.5517237;-2.4271414;-1.454923;-1.5836099;IRRE
meanshift with binning and a 0 estimated bandwidth should be equivalent;1.5907061;1.3840146;-1.2936631;0.46461827;-3.0628054;4.892914;-
to no binning;-1.8556283;0.41551355;3.002989;-0.22556788;-0.51036894;-0.30031335;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
small and easy test no clusters around other clusters;3.3223467;2.2282438;-0.862171;2.4719374;-1.5356979;-1.965038;IRRE
but with a clear noise data;4.2671814;-1.4833642;1.1319492;1.4475943;1.4847239;0.7174351;META
global random seed is not used here since the expected labels;0.11073359;-0.8559445;-1.2667952;-0.12568969;0.24149674;0.94323075;IRRE
are hardcoded for these specific data;5.3953395;-0.9955686;0.13841818;-2.9347382;4.72772;-2.7696972;CODE
check float min samples and min cluster size;5.959073;3.3929694;-2.2780802;-2.3142664;-1.0044234;-0.5114322;CODE
this may fail if the predecessor correction is not at work;-2.0544245;4.552295;-2.1324775;3.6556644;1.347697;-0.19353479;CODE
the first cluster should contain all point from c1 but due to how the data is;5.0123577;2.3418732;-0.78940994;-4.8896174;-1.419367;1.4681174;CODE
generated some points from c2 may end up in it;1.9199126;1.186338;-0.32877195;-2.0318182;0.012387578;0.21571;CODE
the second cluster should contain all points from c1 and c2;3.2496107;1.3012769;0.7590665;-4.467433;0.32709053;1.1730734;CODE
in auto mode;-5.528558;-1.6988196;4.717146;0.9736813;-0.78430676;1.2255602;-
parameters chosen specifically for this task;3.4974391;2.1079051;4.6801233;-1.5763961;3.2334697;0.56952935;IRRE
compute optics;1.6782357;-1.0527594;1.4179987;-4.2197604;-1.8594321;-0.47237962;-
number of clusters ignoring noise if present;4.34184;1.4382163;-0.7555354;1.4727778;0.30890164;0.40066847;-
check attribute types and sizes;1.6022878;3.2733462;-0.8826341;-0.41837507;2.770325;-2.7211986;META
test that we check a minimum number of samples;3.898735;5.252539;1.1589512;2.771669;1.7852383;-5.79042;IRRE
compute optics;1.6782357;-1.0527594;1.4179987;-4.2197604;-1.8594321;-0.47237962;-
run the fit;0.7230935;1.4304996;2.185687;1.140989;-1.2081004;-0.2503435;CODE
test an extraction of eps too close to original eps;3.929815;3.939329;-2.064716;0.09658873;-2.4061143;-0.66588956;IRRE
compute optics;1.6782357;-1.0527594;1.4179987;-4.2197604;-1.8594321;-0.47237962;-
make sure no warning is raised if metric and data are both boolean;2.055915;4.161839;-3.5288017;3.2548375;0.09330759;-0.29226202;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 18996;-3.05485;-9.819994;-5.430888;-0.7924646;-4.407504;-5.050627;CODE
make sure a single conversion warning is raised if metric is boolean;1.6689364;4.4762025;-5.499283;1.0297529;-0.70779294;-0.38311276;CODE
but data isn t;1.3450377;0.5155513;1.378668;0.60393476;0.194446;-1.6183898;META
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 18996;-3.05485;-9.819994;-5.430888;-0.7924646;-4.407504;-5.050627;CODE
silence a deprecationwarning from joblib 1 5 1 in python 3 14;-3.983666;-1.056211;-4.6925855;4.054293;-4.670766;-0.8495913;CODE
make sure no conversion warning is raised if;-2.9604452;5.7551064;-4.6589766;2.482092;-2.4469938;-2.098902;META
metric isn t boolean no matter what the data type is;2.4917028;2.02889;-4.1970735;-0.933735;0.5123753;-1.1116053;CODE
fit boolean data;6.1607704;2.9417489;-0.3534369;-2.7237701;1.4845345;-1.9372615;CODE
fit numeric data;6.9592338;2.2800734;1.1669948;-5.28289;-1.795784;-0.84703493;-
test extract where extraction eps is close to scaled max eps;5.6152773;3.0467544;-2.0376647;-1.2099593;-1.3704638;-0.29687256;IRRE
compute optics;1.6782357;-1.0527594;1.4179987;-4.2197604;-1.8594321;-0.47237962;-
cluster ordering starts at 0 max cluster label 2 is 3 clusters;0.7283117;2.900089;-1.2561909;-4.1349597;0.8992881;0.42389598;-
test that optics clustering labels are 5 difference of dbscan;3.193586;1.2448233;-1.5668163;-1.9191793;2.0252714;0.2674966;IRRE
calculate optics with dbscan extract at 0 3 epsilon;1.6761223;1.8682336;-3.861873;-4.002473;-1.3236625;0.7614473;-
calculate dbscan labels;3.7755954;0.11920316;-0.6182751;-4.8560834;2.8135605;-1.1864948;-
verify label mismatch is 5 labels;1.1787921;4.2596965;-1.9340109;-1.2397494;2.0402932;-4.229979;-
try arbitrary minimum sizes;4.222708;3.4620938;1.4244107;-2.5038252;0.96450835;1.3649776;CODE
redx x 2 astype global dtype copy false reduce for speed;-0.13937318;1.6811473;-5.606658;-1.181862;-0.83056825;3.0055513;CODE
check behaviour is the same when min cluster size is a fraction;4.3376913;5.16848;-2.7048378;-0.57474375;-1.2602113;1.3207355;-
ensure that we consider all unprocessed points;1.648598;0.22634201;-0.97375375;2.4728708;0.12943408;0.81307983;CODE
not only direct neighbors when picking the next point;0.43508935;-0.82437295;3.2879384;1.6182734;-0.84265786;1.4706981;CODE
expected values computed with future elki 0 7 5 using;1.5532471;1.5205321;-2.4060764;1.5400605;-0.7901297;-1.0417958;IRRE
java jar elki jar cli dbc in csv dbc filter fixeddbidsfilter;-0.60766435;-0.6862423;-5.1804523;-0.041506495;1.5784248;0.51154304;CODE
algorithm clustering optics opticsheap optics minpts 5;2.7892241;-2.7015464;-0.22303402;-2.9383445;-0.00657137;1.8235408;-
where the fixeddbidsfilter gives 0 indexed ids;-1.7622895;2.5295656;-4.1019;-0.39531836;1.3699465;1.2071403;-
tests against known extraction array;4.00023;3.8514824;-3.1231844;2.851922;1.5266314;-4.231914;IRRE
does not work with metric euclidean because sklearn euclidean has;1.8873007;0.2178915;-2.9383802;-3.1878781;-4.585635;-1.8737406;CODE
worse numeric precision minkowski is slower but more accurate;4.682779;-0.5789084;-2.530351;-2.0689723;-4.282213;0.77578336;META
elki currently does not print the core distances which are not used much;-0.76047134;-1.8900815;-1.8273805;-1.0379622;-2.1416073;2.0111423;CODE
in literature but we can at least ensure to have this consistency;-0.2933664;-0.1527725;0.5884521;6.949877;1.675215;2.9581003;META
expected values computed with future elki 0 7 5 using;1.5532471;1.5205321;-2.4060764;1.5400605;-0.7901297;-1.0417958;IRRE
testing an easy dbscan case not including clusters with different;2.7693553;2.1513634;-2.4082665;1.4294152;2.4029896;-0.5461176;IRRE
densities;1.3714458;-1.3131249;3.654805;-2.3292968;-0.62722695;0.3208503;-
add zeros on the diagonal that will be implicit when creating;-0.6033233;2.9880672;0.7707428;-6.758166;-2.676927;0.8254944;TASK
the sparse matrix if x is modified in place the zeros from;3.4710906;1.3689072;-1.7438973;-4.6132116;-1.7293731;3.5746703;IRRE
the diagonal will be made explicit;-1.0790681;-0.059456754;3.351569;-3.9908333;0.2821148;-0.033458948;-
make sure that we did not modify x in place even by creating;-5.4349523;3.1745992;0.2963419;0.4812601;-1.0796968;0.97504485;-
explicit 0s values;-0.63982564;4.002932;-1.8285799;-5.652472;-0.5872648;-3.2583628;IRRE
non regression test for 21380;0.6259955;3.5936959;-4.065888;3.535347;-2.3176992;-4.9467254;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
interleave the validated column specifiers;5.6397967;-0.46080938;-3.9878619;0.016726736;4.9012065;-2.6575997;CODE
add transformer tuple for remainder;-0.3104519;2.6098654;1.4019734;-3.6129029;0.581548;0.6765578;CODE
convert all columns to using their string labels;3.096535;-0.51838744;0.9115849;-4.30216;1.0516309;-1.2113229;CODE
selection is done with one dimension;3.7833035;0.010347287;2.3943632;-1.5766166;4.1833878;2.4447844;CODE
validate names;-0.5629785;2.136956;-1.2822537;1.726322;5.071116;-4.1330914;-
validate estimators;3.354892;2.8730853;-2.112185;5.2836685;0.30367175;-0.5489608;-
used to validate the transformers in the transformers list;-1.2122879;-1.2767074;-0.68014175;-0.06256682;2.8084168;-1.8747836;CODE
determine key type raises a valueerror if some transformer;0.16887094;3.6371381;-6.415664;-0.37303966;-2.1345918;-1.5303131;CODE
columns are callables;-1.0327573;1.0999352;0.6239889;-1.9214469;1.9399202;1.8387613;IRRE
use bunch object to improve autocomplete;0.76491886;-0.37311956;1.5429542;3.722642;1.5093787;0.6386184;CODE
an actual transformer;-1.5601285;-1.3748364;4.8172207;-0.5389679;-0.1489248;-0.09022601;CODE
list of tuples name feature names out;0.69434094;-2.8849194;0.06925591;-2.1976686;2.5973513;-3.5101614;TASK
no feature names;-4.420731;-5.010444;-0.59367275;0.6250256;0.022866141;-0.73411405;TASK
prefix the feature names out with the transformers name;-2.6578324;-1.710355;-0.026645875;0.6837391;3.0163438;2.319714;TASK
verbose feature names out is false;-2.772465;-0.29260886;-4.5445347;2.878542;0.55418855;-0.18259469;TASK
check that names are all unique without a prefix;0.22973321;2.5151463;-0.68276674;-0.29657245;4.8044434;-3.7234;-
there are more than 5 overlapping names we only show the 5;-2.5896184;-0.8622939;1.8679756;-1.6051503;3.853668;-1.7555791;-
of the feature names;-0.20832393;-7.6016455;2.9636557;1.0764197;4.4294586;-0.6762725;TASK
transformers are fitted excludes drop cases;-0.13428614;3.6981273;-1.054762;0.2521444;0.28868368;3.8558125;CODE
sanity check that transformers is exhausted;-2.8543882;2.2960193;1.1632302;2.9429862;-2.9365041;-1.5745631;CODE
iter only generates transformers that have a non empty;-2.7831814;2.6365726;-1.3506354;-0.3881203;-0.7797918;0.0326093;IRRE
selection here we set empty slices for transformers that;-0.34280342;2.0743856;0.9679602;-1.9754225;0.8339585;3.7412271;CODE
generate no output which are safe for indexing;0.82765067;4.035609;-1.3498652;-0.023095801;0.60455006;-1.912301;CODE
else func is transform one;-1.9416324;0.78454906;2.3476322;-0.62727386;0.94383436;-0.47498193;CODE
else func is transform one;-1.9416324;0.78454906;2.3476322;-0.62727386;0.94383436;-0.47498193;CODE
we use fit transform to make sure to set sparse output for which we;8.191682;-0.26198128;-0.9833866;-2.8392904;-2.3319156;5.6403565;IRRE
need the transformed data to have consistent output type in predict;4.7136335;1.2977197;-0.18566756;-1.3574693;-1.8184699;2.9543402;IRRE
estimators in columntransformer transformers are not validated yet;1.2021669;1.9317108;-6.206155;0.54384774;-3.0184524;3.499547;CODE
set n features in attribute;1.3750681;0.25233427;0.909383;-2.0746565;4.7554784;0.08482109;TASK
all transformers are none;-3.5435138;0.30099002;1.1844393;-0.69685453;-1.5148534;-1.6475946;CODE
determine if concatenated output will be sparse or not;5.115677;3.6869292;-1.5288047;-0.7443894;0.37256524;-1.0562465;IRRE
if columntransformer is fit using a dataframe and now a dataframe is;2.577768;3.0543466;-2.229758;-0.98758036;-3.4698474;0.67041445;CODE
passed to be transformed we select columns by name instead this;0.18652424;1.1915481;-0.091880985;-2.8830564;0.9775397;1.4818271;CODE
enables the user to pass x at transform time with extra columns which;-0.0769932;1.7039115;1.9236863;-3.7045438;0.438537;2.3656487;CODE
were not present in fit time and the order of the columns doesn t;2.802445;2.6572528;-0.16769099;-3.2603605;-1.9083415;0.65385103;CODE
matter;-1.7301903;-2.4582338;5.698846;0.33866847;0.26685596;-2.5354633;-
check that all names seen in fit are in transform unless;2.1248643;2.6713502;-2.5606148;-0.21780694;-0.046815004;0.512022;CODE
they were dropped;-1.2990063;0.81169575;2.8308809;1.5587668;-1.1306412;-2.2411454;-
ndarray was used for fitting or transforming thus we only;2.6083882;-2.8478503;-2.7713253;-4.1136003;-3.9723518;3.6968267;CODE
check that n features in is consistent;3.8515446;3.5143435;-3.0404103;0.81850535;2.902304;-2.392281;TASK
all transformers are none;-3.5435138;0.30099002;1.1844393;-0.69685453;-1.5148534;-1.6475946;CODE
since all columns should be numeric before stacking them;2.8983014;2.4575036;-1.340906;-5.905853;-0.5213072;-0.7783525;CODE
in a sparse matrix check array is used for the;3.709712;1.248259;-2.2443104;-3.2093294;0.23026496;-1.0010977;IRRE
dtype conversion if necessary;1.1908348;-0.00822406;-4.5630264;-2.764724;0.119924404;-2.488545;META
rename before stacking as it avoids to error on temporary duplicated;-3.2542028;3.2705362;-0.86275977;2.8648171;1.8275313;1.7850528;CODE
columns;2.9453604;-0.8405486;5.620917;-6.0069814;2.320245;-2.1489592;-
add prefix for feature names out takes care about raising;-2.9412656;-1.1241941;-1.8995442;3.080766;3.465202;2.9550242;TASK
an error if there are duplicated columns;0.8365293;4.212155;-2.03412;-1.8540627;0.795611;-3.5870776;-
check for duplicated columns and raise if any;3.1633418;4.3178697;1.1589828;-1.5692645;2.0885973;-3.778705;CODE
here we don t care about which columns are used for which;1.0376334;-0.48286837;0.42103863;-3.78861;2.491791;0.48359266;CODE
transformers and whether or not a transformer is used at all which;-1.6257257;0.49418783;2.0911307;0.6619206;0.8320115;-0.20457219;CODE
might happen if no columns are selected for that transformer we;-0.9386805;3.3127043;-2.4033592;-1.4622685;-2.846131;1.7124264;CODE
request all metadata requested by all transformers;-3.1202977;0.35288337;-1.0816102;1.9425377;0.9792538;4.377052;CODE
if transformers does not comply with our api list of tuples;-1.1103452;1.0233744;-3.1065266;1.2143396;2.6162362;0.74966526;CODE
then it will fail in this case we assume that sparse is false;3.2165058;3.6125858;-3.2850988;2.9888098;0.19965845;1.5133582;CODE
but the parameter validation will raise an error during fit;1.26532;5.9551625;-3.318567;5.057757;-0.5775645;2.3973155;IRRE
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
import pandas as pd doctest skip;-0.6039864;-0.18996616;-4.0655565;1.9794157;-4.383896;-1.8340653;CODE
rating 5 3 4 5 doctest skip;-1.1747214;0.47561783;0.16295838;3.453125;0.8364101;-5.115374;IRRE
make column selector dtype include np number rating;2.1033747;-0.05619863;-5.403611;-4.392036;0.9369031;-1.6164988;CODE
make column selector dtype include object string city;0.28598824;-0.52441937;-1.9401631;-1.7492251;1.8996468;0.2051824;CODE
ct fit transform x doctest skip;1.6618495;2.8228588;-2.2166548;0.37527496;-3.1131284;1.6743103;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we are transforming the target here and not the features so we set the;-1.3048918;-1.9617338;1.5084424;1.2050974;-1.3569329;3.779098;TASK
output of functiontransformer to be a numpy array default and to not;1.139934;1.8316426;-2.4710178;-4.435685;-5.533568;1.4024562;CODE
depend on the global configuration;-2.1017828;-0.124938734;3.1261456;2.4588957;1.4955068;5.1781335;CODE
xxx sample weight is not currently passed to the;0.251613;4.8236756;-3.4736483;0.37478197;-2.0774527;1.0816562;-
transformer however if transformer starts using sample weight the;1.7003832;3.8211694;-0.14817816;1.7083589;-0.4480531;2.7473722;CODE
code should be modified accordingly at the time to consider the;-4.1429234;1.5381178;0.5550686;4.3516507;2.8907926;0.5599396;-
sample prop feature it is also a good use case to be considered;0.3607965;-3.6523044;2.6053042;5.5126786;4.1730223;1.8113672;TASK
transformedtargetregressor regressor transformer are not validated yet;-1.4756761;1.7939191;-5.9413424;-0.07845457;-4.1214294;2.7870793;CODE
store the number of dimension of the target to predict an array of;6.8590846;0.11849604;1.0727688;-2.1631348;1.2897389;0.9428515;-
similar shape at predict;6.808121;-2.3362055;3.3228438;-1.0898144;-0.48814306;2.0641005;-
transformers are designed to modify x which is 2d dimensional we;0.98356104;-0.8140908;1.9102992;-5.390344;0.44720393;3.6661282;CODE
need to modify y accordingly;-0.9637579;2.2855666;5.0187488;-3.9064312;-1.8466861;-1.5111157;TASK
transform y and convert back to 1d array if needed;3.101395;2.7723267;2.168378;-7.329078;-3.9362633;0.536023;CODE
fixme a functiontransformer can return a 1d array even when validate;-0.04643095;6.66872;-4.3464646;-0.80956215;-2.2526023;-0.031812392;CODE
is set to true therefore we need to check the number of dimension;1.9082985;3.5400877;-0.32747823;-2.0454717;1.5313945;-0.648505;TASK
first;-3.0988061;-0.6879942;4.054453;1.0179563;0.9497118;-1.2876939;-
1d series 2d dataframe;3.1812906;-0.32515648;2.709185;-6.334168;-5.133142;-0.4660482;-
1d array 2d array;2.4083912;1.7065653;2.6814518;-8.15882;-2.066889;-1.0468199;-
single column 1d 2d;3.947017;1.4192152;3.05211;-9.760429;-1.119465;0.38663822;-
list like;0.2411717;-2.003275;6.182176;0.39560568;3.1810849;-4.422774;-
slice;-1.4802499;-0.8139195;6.010453;-1.1233138;-0.3378325;-2.9337795;-
boolean mask;0.85433203;1.3635021;1.3122602;-2.9801154;1.5913398;-1.0216067;CODE
callable that returns any of the allowed specifiers;-0.9460849;0.38279796;-1.7067496;3.2179275;4.5314837;-1.7602507;IRRE
test with transformer weights;3.5190442;4.570201;-1.2419524;2.580345;-1.3144172;-1.0539459;IRRE
string keys label based;0.24548894;-0.8145954;1.3417741;-3.2278142;5.1929502;-1.9119178;CODE
list;-0.24403423;-2.7110164;5.9260902;0.9299988;2.8310878;-4.6821876;-
slice;-1.4802499;-0.8139195;6.010453;-1.1233138;-0.3378325;-2.9337795;-
int keys positional;-2.5252278;1.4591321;1.7019769;-5.390083;1.4208577;-1.8143457;CODE
list;-0.24403423;-2.7110164;5.9260902;0.9299988;2.8310878;-4.6821876;-
slice;-1.4802499;-0.8139195;6.010453;-1.1233138;-0.3378325;-2.9337795;-
boolean mask;0.8543316;1.363502;1.3122599;-2.980116;1.5913405;-1.0216078;CODE
scalars are only supported for pandas dataframes;0.66913986;-2.6527007;-5.591816;-2.5761461;-6.219836;1.1719052;CODE
scalar;0.6947476;-1.6647757;2.0065823;-1.1214494;-1.2738489;-1.8990954;-
callable that returns any of the allowed specifiers;-0.9460849;0.38279796;-1.7067496;3.2179275;4.5314837;-1.7602507;IRRE
test with transformer weights;3.5190442;4.570201;-1.2419524;2.580345;-1.3144172;-1.0539459;IRRE
test multiple columns;4.5483675;5.048874;0.887035;-0.17820336;2.0069752;-6.030249;IRRE
ensure pandas object is passed through;0.21284738;1.9175155;-3.1134512;1.5197611;-2.2814155;-0.97276163;IRRE
dataframe protocol does not have 1d columns so we only test on pandas;1.1699783;1.267067;-4.483204;-1.7571375;-3.280526;-2.2002301;IRRE
dataframes;3.624378;-3.1048534;4.469008;-3.5065384;-2.1974485;-4.1047473;-
only test on pandas because the dataframe protocol requires string column;0.26670447;1.3746452;-4.6663003;0.21577635;-3.1009347;-3.0000482;IRRE
names;-0.9103291;-3.5028324;5.6223774;0.7044326;2.7243469;-4.658295;-
integer column spec integer column names still use positional;-0.54634225;2.2687333;-3.8367922;-4.8720503;1.7360451;0.91130924;CODE
test case that ensures that the column transformer does also work when;0.80429137;4.942788;-2.8783948;1.9315803;-1.0760218;0.46788186;CODE
a given transformer doesn t have any columns to work on;-0.6111975;3.1134632;-1.6571091;-3.884827;-2.0518064;-0.28004938;CODE
assert len ct transformers 2 including remainder;0.9384884;6.2038293;-2.465303;-0.07573828;0.4796256;-3.3614755;CODE
assert len ct transformers 2 including remainder;0.9384884;6.2038293;-2.465303;-0.07573828;0.4796256;-3.3614755;CODE
checks for the output indices attribute;2.8262134;4.5644927;-3.0395362;-0.8169352;1.2977061;-2.4258258;IRRE
test with transformer weights and multiple columns;5.4044886;4.184317;-1.536759;-0.013022897;-0.053282823;-0.6971787;IRRE
test case that ensures that the attribute does also work when;-1.1786613;6.3128676;-1.768036;6.5766063;3.1609998;-1.6360706;IRRE
a given transformer doesn t have any columns to work on;-0.6111975;3.1134632;-1.6571091;-3.884827;-2.0518064;-0.28004938;CODE
checks for the output indices attribute with data frames;3.761678;2.8277297;-3.0080135;-2.3014865;-0.6352878;-0.6033194;IRRE
no distinction between 1d and 2d;0.21165237;-0.04939947;1.3712155;-5.000509;0.41691902;1.5237414;CODE
this shouldn t fail since boolean can be coerced into a numeric;0.6756933;5.801191;-4.229606;-0.41304085;1.1568885;-4.2466426;CODE
see https github com scikit learn scikit learn issues 11912;-2.3734572;-10.782356;-6.131625;-1.1968135;-4.625626;-4.0868697;CODE
this fails since strings a and b cannot be;-3.3804812;5.2054486;-1.5432594;-1.1732556;0.9063073;-4.3311048;CODE
coerced into a numeric;1.8004632;3.346839;-0.22128034;-3.3940716;0.48687902;-3.5295076;CODE
above data has sparsity of 4 8 0 5;4.1311975;1.7102478;-2.247401;-4.5224786;-1.5490727;0.3311482;-
apply threshold even if all sparse;5.3366637;2.6823738;-1.9440984;-0.54587394;0.25982746;2.6295311;IRRE
mixed sparsity of 4 2 8 0 75;1.6724607;2.4886847;-0.5754291;-4.230557;-1.7942665;-0.07045345;-
if nothing is sparse no sparse;2.831431;0.92647153;-1.0622118;-1.2679747;-0.29278558;1.6292008;IRRE
if one transformer is dropped test that name is still correct;-0.9819795;5.0058646;-2.5324645;3.7461896;1.6230873;-1.6932286;TASK
because fit is also doing transform this raises already on fit;0.102364175;1.176157;-0.39091414;0.41391024;-2.1542659;3.526146;CODE
if one transformer is dropped test that name is still correct;-0.9819795;5.0058646;-2.5324645;3.7461896;1.6230873;-1.6932286;TASK
because fit is also doing transform this raises already on fit;0.102364175;1.176157;-0.39091414;0.41391024;-2.1542659;3.526146;CODE
general invalid;-3.2814138;2.0641701;-1.546874;1.2300996;0.9918178;-3.5646477;OUTD
invalid for arrays;-0.40355337;4.3538613;-2.1641831;-3.0297718;-2.5333831;-5.0692434;OUTD
transformed n features does not match fitted n features;2.3145282;0.4375467;-3.7765234;-3.8003051;-1.7071192;2.965829;TASK
invalid keyword parameters should raise an error message;-4.3816237;4.1044126;-4.98542;1.8847736;-0.022240814;-0.26358485;IRRE
check it are fitted transformers;-2.4465778;2.8987753;-0.47567013;-0.29962453;-2.7214327;-0.3129087;CODE
raise correct error when not fitted;1.9343616;6.8971553;-4.249363;2.9882884;-3.2918344;1.2051115;CODE
raise correct error when no feature names are available;-3.4710236;1.2396551;-5.093153;5.2797813;0.83541036;-0.060336545;TASK
one drop ignore;-0.13092372;5.0858636;2.1225305;2.9277883;0.07278315;-0.3745839;-
all drop return shape 0 array;1.4951124;4.888949;0.4904793;-2.1684074;-2.4057257;-0.64243484;IRRE
passthrough;-2.904109;-0.2935284;2.5707638;1.8239417;1.2250637;-2.3539448;-
default drop;-2.8122628;2.0837562;2.393403;1.4863125;-0.31487837;2.022466;CODE
specify passthrough;-4.1163783;2.4725983;-0.17094305;2.3951623;2.1068163;1.5132371;-
column order is not preserved passed through added to end;-1.3906416;5.18732;-0.721141;-1.8213811;-0.89135814;0.6548296;TASK
passthrough when all actual transformers are skipped;-2.3084822;3.2500808;-0.5025055;3.5820127;0.6187439;2.2198977;CODE
check default for make column transformer;-1.057554;1.5445538;-3.296264;-1.5136858;-1.3147898;2.9617488;CODE
0 false true false 2 mix types;-0.42650616;7.0619335;-4.28033;0.09147035;1.4059113;-2.71917;IRRE
0 1 2 ints;-2.1270466;1.6052601;2.1453104;-4.7307525;-0.33740035;-3.935474;CODE
lambda x 0 lambda x 1 2 callables;-3.1891112;2.4516838;-0.15325797;-1.9330531;2.1934872;1.2780198;CODE
a b c all strings;-1.2593346;1.4646962;3.4442556;-2.3293533;2.049541;-5.048511;IRRE
true false false false true false false false true all bools;-1.5090053;3.0252075;-0.77373165;0.49402633;1.3671393;-3.651597;IRRE
if inputs are column names store remainder columns as column names;2.9276485;2.8481796;-0.45783383;-2.5403347;2.3834927;-2.8230395;CODE
todo 1 9 remove this test;-2.5246928;5.7930527;-1.2224977;2.654717;-0.6708477;-7.163978;CODE
test different ways that columns are specified with passthrough;2.9168208;5.5367675;-2.176013;2.0400376;1.9346962;-3.1963363;IRRE
test different ways that columns are specified with passthrough;2.9168208;5.5367675;-2.176013;2.0400376;1.9346962;-3.1963363;IRRE
second and third columns are doubled when remainder doubletrans;0.8482845;2.7503998;-1.0206532;-5.1655307;-2.3598447;-1.3389106;CODE
columns are doubled when remainder doubletrans;1.1207681;2.865415;-1.2253721;-4.71573;-3.1084116;-1.088467;CODE
sparsematrixtrans creates 3 features for each column there is;3.3115573;-0.75666803;-3.57066;-5.554255;-1.7920942;1.8821038;IRRE
one column in transformers thus;0.7197483;2.1970904;2.3118026;-4.9530234;2.035535;1.3317767;CODE
sparsematrixtrans creates 3 features for each column thus;3.7536085;-1.161243;-3.6416073;-5.4462194;-1.3821535;2.5804214;IRRE
assert that function gets the full array;1.0352063;7.875274;-1.1610861;2.1443274;-1.1627331;-4.833382;CODE
assert that function gets the full dataframe;2.3803058;4.903053;-2.286551;1.5138767;-3.5835402;-3.8345833;CODE
regression test for 14510;0.6843085;2.4461758;-0.5161045;3.097308;-3.8122776;-6.8567643;IRRE
boolean array like does not behave as boolean array with sparse matrices;2.4392903;2.8110368;-4.3350086;-3.5945814;-0.90384537;0.08995013;CODE
make sure n features in is what is passed as input to the column;2.4919126;2.8602931;-2.2953448;-2.8959465;3.0177085;-3.410816;TASK
transformer;-1.4245996;-1.5366583;5.2588625;-2.0365984;-0.047867265;-0.22808374;CODE
functional test for column transformer column selector;2.1496148;2.6937337;-3.1025379;0.71233934;1.0062132;-1.018588;CODE
remainder passthrough or an estimator will be shown in repr html;-1.1719575;1.203279;-0.32062274;1.5961896;-1.9007162;2.4337773;CODE
remainder drop is not shown in repr html;-3.9896843;1.4117674;0.76086146;0.008453432;-3.0313275;0.33639425;CODE
remainder shows the columns after fitting;2.9434514;2.8899179;0.4431162;-5.291425;-3.6048644;0.1501133;CODE
remainder shows the indices after fitting;3.6696281;3.4370692;-1.5971255;-5.2288327;-3.716054;-0.027211472;CODE
non regression test for 26306;0.77374405;3.2667458;-4.717762;2.166162;-2.0292175;-6.4660354;IRRE
fit on pandas and transform on polars;2.1883733;-1.4146785;-0.85088354;-4.867518;-4.403629;0.8225096;CODE
fit on polars and transform on pandas;1.8839922;-1.5626341;-1.223238;-5.054652;-4.5100074;0.6131988;CODE
non regression test for issue 28781;-1.0003382;4.4426827;-5.597126;2.5491047;-3.2694268;-6.1840706;IRRE
non regression test for issue 31546;-1.1276782;4.617803;-5.8752074;1.9824733;-3.068177;-6.0859494;IRRE
provide a transformer and functions at the same time;-1.3486738;-0.080708556;3.2933724;-0.21937883;1.5454494;3.9504733;CODE
fit with sample weight with a regressor which does not support it;3.3942873;3.8280857;-2.2621796;-0.32202196;-1.2484949;3.2882295;CODE
one of func inverse func is given but the other one is not;-2.7228193;4.131928;-0.36773238;-1.5437391;-2.4630144;-1.5936327;META
check the transformer output;-1.4797031;3.4563315;0.8065161;-0.07340515;-2.1646276;-3.3066645;IRRE
check the regressor output;0.15270168;4.7199144;-0.044523366;-1.8676045;-3.6835268;-2.9444623;IRRE
check the transformer output;-1.4797031;3.4563315;0.8065161;-0.07340515;-2.1646276;-3.3066645;IRRE
check the regressor output;0.15270168;4.7199144;-0.044523366;-1.8676045;-3.6835268;-2.9444623;IRRE
all transformer in scikit learn expect 2d data functiontransformer with;1.5477592;-3.1688774;-5.256732;-2.6758027;-4.2676964;0.7777086;CODE
validate false lift this constraint without checking that the input is a;0.6464564;5.5886464;-3.058287;1.533171;1.6244624;-0.7885628;CODE
2d vector we check the consistency of the data shape using a 1d and 2d y;6.6525884;1.3339565;-0.19678164;-4.1791234;-2.0981867;0.8668494;-
array;0.32504454;2.3025823;5.5294733;-3.8580654;0.6459899;-5.286;-
consistency forward transform;1.5461599;2.1521795;-0.2582042;0.47388065;0.21147643;4.5798607;CODE
consistency inverse transform;2.823129;2.882901;-0.2930388;-0.7654622;-0.9240879;4.3277264;IRRE
consistency of the regressor;0.63566554;3.0532885;0.19185638;0.61429626;-1.8877331;3.127419;-
check consistency with transformer accepting only 2d array and a 1d 2d y;3.7614887;5.308956;-1.5650052;-3.1201286;-2.7020984;2.0428646;TASK
array;0.32504454;2.3025823;5.5294733;-3.8580654;0.6459899;-5.286;-
consistency forward transform;1.5461599;2.1521795;-0.2582042;0.47388065;0.21147643;4.5798607;CODE
if y ndim 1 create a 2d array and squeeze results;5.137541;3.1530178;1.1090068;-6.814019;-2.5837166;-1.5400507;IRRE
consistency inverse transform;2.823129;2.882901;-0.2930388;-0.7654622;-0.9240879;4.3277264;IRRE
consistency of the regressor;0.63566554;3.0532885;0.19185638;0.61429626;-1.8877331;3.127419;-
if y ndim 1 create a 2d array and squeeze results;5.137541;3.1530178;1.1090068;-6.814019;-2.5837166;-1.5400507;IRRE
check consistency with transformer accepting only 2d array and a 2d y;3.3229976;5.6211457;-1.3126132;-2.3551533;-2.61734;1.622669;CODE
array;0.32504454;2.3025823;5.5294733;-3.8580654;0.6459899;-5.286;-
consistency forward transform;1.5461599;2.1521795;-0.2582042;0.47388065;0.21147643;4.5798607;CODE
consistency inverse transform;2.823129;2.882901;-0.2930388;-0.7654622;-0.9240879;4.3277264;IRRE
consistency of the regressor;0.63566554;3.0532885;0.19185638;0.61429626;-1.8877331;3.127419;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 18866;-3.6656373;-10.197049;-4.4783306;-0.19170213;-5.1422377;-4.9336486;CODE
check with a 3d target with a transformer that reshapes the target;0.880501;2.7226794;0.11043324;-0.28957516;-2.1334279;2.5141716;CODE
force that the function only return a 1d array;1.7505511;7.352921;0.10681569;-2.3490357;-2.0702884;-0.1636257;CODE
check that the target y passed to the transformer will always be a;-1.6584325;4.6732945;-0.6505368;1.1707312;-3.2420402;0.10440324;CODE
numpy array similarly if x is passed as a list we check that the;3.4641669;3.1574173;-0.38772357;-2.747902;-3.2846344;-3.738791;-
predictor receive as it is;0.9214593;-0.5005176;0.1755106;3.1855636;1.0438892;1.5648799;-
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import pytest run parallel noqa f401;-2.140419;-0.7038916;-2.8372087;-1.3991776;-3.4523633;1.1602929;CODE
scipy requires network access to get data;0.42209437;-3.2426894;-3.6845443;-1.8914927;-6.3312116;-1.8813533;CODE
import pooch noqa f401;-3.9926288;-1.7453433;-1.8030971;-2.4338279;-0.5445494;-0.9123379;CODE
global fixtures;-1.2982411;-0.4433806;3.5328915;2.1172392;1.3077507;1.1458156;-
https scikit learn org dev computing parallelism html sklearn tests global random seed;0.3733515;-7.324756;-4.9941726;2.158669;-3.5218832;-2.8892553;IRRE
strict mode to differentiate between 3 14 and np float64 3 14;-1.6138755;3.4892972;-3.622367;-3.639119;-0.69592506;-0.402164;CODE
dt config rtol 0 01;-4.5689187;0.14448233;-2.7095459;-1.3290869;-0.9638989;-0.34311748;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
avoid division truncation;0.310493;4.522657;0.2954652;-1.9179713;-0.37453204;-1.8460859;CODE
x test should have been called x;-3.1301224;4.63823;-0.6601898;4.2960944;-1.0642363;-4.2448206;IRRE
set covariance;1.5046184;0.6719168;1.5697982;-0.7415673;-0.6038909;2.9925447;IRRE
set precision;2.3437026;2.705845;1.2554218;-1.2377106;-1.7807264;-1.6215603;IRRE
compute empirical covariance of the test set;3.9495256;1.1741697;-2.6902328;0.8931561;-0.9377503;-1.7466989;IRRE
compute log likelihood;0.992841;0.5333469;0.5917033;-1.0423876;-0.25161025;-0.93219477;-
compute the error;0.49288896;4.5831666;-0.03648963;-1.8185316;-2.0817602;-6.4626174;-
compute the error norm;2.6948998;1.6150305;-1.4820645;-1.8314568;-3.1902514;0.34769148;-
optionally scale the error norm;4.7258544;2.6640642;-2.4205635;-0.05932879;-3.1358936;5.0218835;CODE
finally get either the squared norm or the norm;1.3045115;0.5135913;1.2220932;-3.2601805;-3.0160215;1.3006116;CODE
compute mahalanobis distances;3.9597888;0.30899158;-0.15703136;-5.0566564;-0.9076064;0.49827558;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
mypy error module sklearn linear model has no attribute cd fast;1.5466566;-1.528317;-7.1063523;-1.5322107;-4.5704393;-0.5776169;META
from sklearn linear model import cd fast as cd fast type ignore attr defined;1.7824723;-1.162579;-6.1405144;-1.6782421;-1.9584231;1.298829;CODE
helper functions to compute the objective and dual objective functions;2.0241177;-2.9847496;0.35449517;0.08366001;2.269526;2.4677293;CODE
of the l1 penalized estimator;2.1514654;0.32137698;-2.149492;2.8536005;-1.0276197;4.7569833;-
the g lasso algorithm;6.5955596;-4.0509095;0.070648514;0.1824831;-0.26229563;3.0335188;-
early return without regularization;3.0801036;1.8923752;-0.024538284;3.7122774;0.20775536;4.294913;IRRE
as a trivial regularization tikhonov like we scale down the;4.629328;-2.3939052;-0.8796899;-0.6551184;0.2878979;6.0127273;IRRE
off diagonal coefficients of our starting point this is needed as;1.38014;1.6034784;1.5517986;-5.452134;-1.4881506;2.8507323;CODE
in the cross validation the cov init can easily be;0.5469652;-0.025665997;-2.0715773;2.8880541;1.5152047;1.3423203;IRRE
ill conditioned and the cv loop blows beside this takes;0.36338097;2.448188;1.2199929;2.979465;-1.8328918;0.21545674;IRRE
conservative stand point on the initial conditions and it tends to;-1.4842921;0.8283099;2.4106154;1.951125;-2.565171;2.0447712;CODE
make the convergence go faster;1.7464721;0.92657137;0.8726464;3.6830254;-3.7593966;1.0147694;-
i 0 initialize the counter to be robust to max iter 0;-1.594222;4.270575;-0.3247837;-0.7100871;-2.1572464;-1.3772897;IRRE
the different l1 regression solver have different numerical errors;1.2983851;1.585819;-4.6477365;0.354844;-5.0823565;1.9570199;-
be robust to the max iter 0 edge case see;-0.878721;1.6326522;0.001157665;-1.5053653;-0.27024946;2.78036;CODE
https github com scikit learn scikit learn issues 4134;-3.2475274;-9.637236;-5.8883047;-0.4770064;-5.185564;-5.2781806;CODE
set a sub covariance buffer;1.4457856;0.9652879;-0.77012235;-0.12278999;-1.5707256;5.5472527;IRRE
to keep the contiguous matrix sub covariance equal to;3.345486;1.8880861;-0.85571665;-2.9934754;-2.0177739;6.054671;CODE
covariance indices idx t indices idx;1.672888;1.185916;-3.5931804;-4.1618648;0.85948175;1.9697164;CODE
we only need to update 1 column and 1 line when idx changes;-0.92783356;3.3066728;-0.25696993;-3.305582;1.6888797;0.9787977;CODE
use coordinate descent;4.0665436;-0.76608795;0.5797185;-1.8058718;-1.6647422;3.7071307;-
todo it is not ideal that the max iter of the outer;-1.5285182;2.1286285;1.528901;-1.4537542;-0.45738813;2.096244;TASK
solver graphical lasso is coupled with the max iter of;2.3132536;-1.2491684;-2.0916195;-0.96550024;-3.6548455;4.052543;IRRE
the inner solver cd ideally cd has its own parameter;-1.2233014;0.0061234334;-2.9480445;-1.4203447;0.9190647;2.3408906;IRRE
enet max iter like enet tol a minimum of 20 is rather;-0.4996521;1.2249974;1.7681307;-0.64285636;0.17650765;-0.66778886;-
arbitrary but not unreasonable;0.22971961;1.6406882;0.80219346;3.2301316;2.4390728;-1.3359152;META
else mode lars;-1.8906031;0.24891566;1.7053672;-0.45091355;0.14588383;0.3458276;-
update the precision matrix;3.3675325;1.4499586;-1.7525944;-3.884717;-3.0138147;0.22433627;CODE
covariance does not make sense for a single feature;0.71869564;-0.39261073;-2.2642066;0.7902002;-1.9834552;2.7747276;CODE
cross validation with graphicallasso;1.566169;-0.21744868;-0.94392943;1.5333047;2.4767563;-0.36987922;IRRE
capture the errors and move on;-1.4440933;3.959988;0.88777256;5.1849923;-2.2222633;-2.8030457;-
covariance does not make sense for a single feature;0.71869564;-0.39261073;-2.2642066;0.7902002;-1.9834552;2.7747276;CODE
list of alpha scores covs;2.2046936;-1.5253891;0.7908552;-1.636175;0.5321465;-3.426458;-
no need to see the convergence warnings on this grid;1.5419674;1.5782257;-1.5443184;1.5933005;-3.0961044;1.1773976;TASK
they will always be points that will not converge;1.4544655;3.151786;1.4564441;0.49105877;-2.270377;0.9058387;CODE
during the cross validation;1.1456065;1.2871807;3.0728;3.467082;2.439552;-1.7013654;-
compute the cross validated loss on the current grid;4.26894;1.5808834;-1.8126109;0.016021673;-0.26512754;0.80361986;-
note warm restarting graphical lasso path has been tried;1.4856365;-2.836057;-1.9160937;0.6407183;-4.52203;3.9807663;TASK
and this did not allow to gain anything;-5.0704575;0.08796135;1.0823883;1.2203311;-1.7629355;0.34810054;CODE
same execution time with or without;-0.7492732;2.4229586;2.4899075;4.3684273;1.3605527;-0.54096633;-
little danse to transform the list in what we need;0.31557143;-0.65835315;3.4805524;-1.0611187;2.557068;0.53349924;IRRE
find the maximum avoid using built in max function to;1.9354684;3.3681266;2.4479675;-1.0100145;-0.8522108;-1.6714487;CODE
have a fully reproducible selection of the smallest alpha;2.240774;-0.6700211;0.15173796;2.2980807;2.4960344;-0.38333634;CODE
in case of equality;-2.222278;3.1479847;3.4422145;0.7982408;3.5265713;-2.9887757;CODE
refine the grid;2.4576437;0.24151997;5.219823;-2.3309689;0.2326251;1.8572651;-
we do not need to go back we have chosen;-2.7394323;2.1089022;3.0704317;1.4569759;-0.83445984;2.4636688;CODE
the highest value of alpha for which there are;-0.18425497;1.7189801;1.5897272;-2.020488;-0.34924826;-3.125303;IRRE
non zero coefficients;-0.71492684;3.3010848;-0.80902785;-4.8816085;-1.30247;-1.5432434;-
we have non converged models on the upper bound of the;1.8727976;-0.70929974;0.59574264;4.286857;0.3124002;2.4232693;CODE
grid we need to refine the grid there;0.51493;0.8911069;4.804775;-3.1623647;0.21286944;1.553203;TASK
finally compute the score with alpha 0;1.4036361;2.28247;0.4156157;-1.4928102;-0.57013065;-5.542747;CODE
finally fit the model with the selected alpha;0.95888513;-0.6754891;1.6066017;1.4506823;-0.594285;3.2564015;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
minimum covariance determinant;1.9128754;-0.5725114;-2.3948898;-2.3227289;-1.5601166;4.1592345;CODE
implementing of an algorithm by rousseeuw van driessen described in;5.084661;-2.2066414;0.20835932;-2.0171282;2.387688;-0.25069076;TASK
a fast algorithm for the minimum covariance determinant estimator;5.948929;-3.0536754;-1.4574971;-0.7956851;-0.27632666;4.3945594;CODE
1999 american statistical association and the american society;3.2133765;-2.304611;1.0729169;1.3706003;0.8091276;-2.5625253;-
for quality technometrics;3.9120333;-3.278636;0.49691927;1.5837325;1.4474832;-2.0120373;CODE
xxx is this really a public function it s not listed in the docs or;-5.904762;-1.5882297;0.253161;-2.042897;1.7581177;-0.50816584;CODE
exported by sklearn covariance deprecate;0.808053;-2.6770737;-7.3759127;0.80710465;-5.1764765;2.2323916;CODE
initialisation;-4.835132;1.5811408;2.9075983;-0.113820374;1.698463;-1.5759581;IRRE
compute initial robust estimates from a random subset;4.6280446;1.1341488;-1.1431662;1.608374;-0.25115588;4.6748857;IRRE
get initial robust estimates from the function parameters;3.2030356;1.730211;-1.4125329;1.1009945;-2.8694518;4.478814;IRRE
run a special iteration for that case to get an initial support indices;2.2125516;2.8083675;-3.721121;-0.16245444;1.0385761;2.09211;CODE
compute new estimates;3.7454345;0.6111122;1.4063542;1.1585399;-0.81004953;1.1565003;CODE
iterative procedure for minimum covariance determinant computation;4.4257336;-1.9618198;-2.8815503;-1.4313283;-0.24894178;4.7292123;CODE
if the data already has singular covariance calculate the precision;5.1182723;2.2636642;-3.906119;-2.0226257;-3.3438532;1.3653679;CODE
as the loop below will not be entered;-3.0678923;4.503141;2.397526;-1.4815748;-1.676674;-6.103076;IRRE
save old estimates values;3.505153;2.6222055;0.77473897;1.3540419;-2.208546;3.3388696;IRRE
compute a new support indices from the full data set mahalanobis distances;6.5466394;-1.7118276;-2.1387005;-3.6376996;1.3471596;2.1397376;CODE
compute new estimates;3.7454345;0.6111122;1.4063542;1.1585399;-0.81004953;1.1565003;CODE
update remaining iterations for early stopping;1.3207828;2.5421097;2.206959;5.221705;-1.5339661;0.6224934;CODE
check if best fit already found det 0 logdet inf;3.0417416;4.9999347;-4.0564547;0.51121086;-0.5550299;-0.5488658;IRRE
check convergence;0.21066397;3.0294006;1.1896883;4.1585145;-3.4774327;-3.2561412;-
c step procedure converged;0.29533815;2.3184965;-1.1397191;1.5118;-3.1813736;0.09620835;-
determinant has increased should not happen;0.093761444;3.165607;-0.39109504;-1.1920209;-3.2485583;0.17193994;-
check early stopping;0.21328253;3.5477583;2.3725705;6.759599;-1.4315368;-1.9597167;-
convert from list of indices to boolean mask;3.3129354;3.1662037;-1.2890149;-4.8867;0.7299631;-1.4737104;CODE
formulas as in sec 3 of pison 2002 derived from eq 4 2 in croux 1999;-1.2704269;-0.7878099;-1.9586052;-3.7417917;0.03299043;0.31899285;CODE
compute n trials location and shape estimates candidates in the subset;6.7196007;-0.021036288;1.508555;-0.6247442;2.6664455;0.51654595;IRRE
perform n trials computations from random initial supports;2.8371694;-1.3886971;-0.5171539;2.4617774;1.3585925;0.39072788;IRRE
perform computations from every given initial estimates;5.8017735;1.0536329;1.2783406;0.378854;-0.12310832;2.8351183;CODE
find the n best best results among the n trials ones;5.389801;-0.6213084;2.7293093;3.067021;2.3163865;-4.365455;IRRE
minimum breakdown value;3.5424678;4.388292;-0.12508953;-1.4611871;1.5067883;-1.5440904;CODE
1 dimensional case quick computation;3.9209003;0.975365;3.0041955;-7.315162;2.110295;-2.0564556;CODE
rousseeuw p j and leroy a m 2005 references in robust;2.8251493;-3.1361558;-3.0676413;0.52232754;0.83391523;4.166584;CODE
regression and outlier detection john wiley sons chapter 4;4.835972;-1.3531502;-2.0593324;1.6825736;-1.2468024;-0.61518437;CODE
find the sample shortest halves;3.4486737;3.3293107;4.0954843;-3.1797802;0.6031997;-3.3924;IRRE
take the middle points mean to get the robust location estimate;4.9031014;1.5986419;3.2316475;-1.1192602;-2.4246955;4.360224;CODE
get precision matrix in an optimized way;6.140815;1.3706763;-1.8628732;-3.3045287;-1.9949862;1.3353267;-
get precision matrix in an optimized way;6.140815;1.3706763;-1.8628732;-3.3045287;-1.9949862;1.3353267;-
starting fastmcd algorithm for p dimensional case;3.2815256;-0.6861572;-1.4424206;-3.2499976;2.0291913;3.2710476;CODE
1 find candidate supports on subsets;3.167093;0.065750875;-0.65961486;0.19283111;6.125725;-2.466898;IRRE
a split the set in subsets of size 300;2.7398293;0.38681993;3.321898;-1.4237517;3.801072;-2.732858;IRRE
b perform a total of 500 trials;1.762894;1.3721545;2.980812;3.1348965;2.6315143;-3.8863816;CODE
c select 10 best location covariance for each subset;6.070389;0.68492925;1.0804163;-2.5489113;1.2181946;1.5078949;CODE
the above is too big let s try with something much small;-2.458448;0.5746586;2.4670274;-2.3106353;-1.2442627;0.3551873;CODE
and less optimal;2.4673352;-0.6226125;4.42082;2.2978268;2.3058302;2.4972243;-
2 pool the candidate supports into a merged set;0.96284837;1.1244915;1.1196047;1.4154581;6.165682;0.3701744;IRRE
possibly the full dataset;3.9431875;-6.5752378;2.8930027;0.5872084;1.1296107;-1.4680737;IRRE
find the best couples location covariance on the merged set;4.008188;1.8983393;2.4022985;-1.0639659;1.3068763;2.0766826;IRRE
3 finally get the overall best locations covariance couple;1.1382129;-1.2363055;2.2480388;-0.12965633;0.72794485;1.7847365;CODE
directly get the best couple location covariance;4.340107;0.42372075;1.6922376;0.035355274;0.44237992;3.5117855;CODE
select the best couple on the full dataset;6.4663687;0.20145606;1.7285632;-1.4572004;2.9170976;-1.4996797;IRRE
1 find the 10 best couples location covariance;3.7003734;0.13414867;3.6295702;-0.365472;1.1365339;0.10368645;CODE
considering two iterations;2.5507798;3.4772913;4.972568;1.788293;0.75908715;-3.0562599;-
2 select the best couple on the full dataset amongst the 10;5.889493;-0.5514441;2.6403003;-1.0153345;3.351217;-2.1721215;IRRE
check that the empirical covariance is full rank;2.927283;0.9548067;-3.952278;-0.65757316;-1.8505203;1.3857068;CODE
compute and store raw estimates;5.268794;0.093405105;0.021352882;0.01174033;0.37655383;3.0816488;-
get precision matrix in an optimized way;6.140815;1.3706756;-1.8628737;-3.3045287;-1.9949863;1.3353273;-
obtain consistency at normal models;2.1542716;2.2324858;-0.8322317;2.5988266;0.6901266;3.0745223;-
re weight estimator;3.5334058;1.1257488;-0.0032267335;1.2192158;-2.1778514;3.9646726;IRRE
check that the covariance of the support data is not equal to 0;2.2614653;3.4140122;-4.7319717;1.1440678;-3.3047357;1.4301201;TASK
otherwise self dist 0 and thus correction 0;-2.0669062;5.9133134;-3.3854978;-3.2274725;-0.91297686;-4.4158196;CODE
parameter alpha as in croux1999 eq 4 2;-2.274746;0.64461386;-3.0038521;-3.1482594;-0.5656752;1.5925108;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
avoid division truncation;0.31049362;4.522657;0.29546553;-1.9179714;-0.37453112;-1.8460855;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
tests covariance module on a simple dataset;4.8447447;0.29565307;-3.5717413;2.4447215;-1.5501587;-2.2341034;IRRE
test covariance fit from data;4.8772845;2.5391567;-1.1477143;1.3983508;-2.615387;-0.7229296;CODE
mahalanobis distances computation test;4.8070745;1.9060503;-1.7645612;-1.5280012;-1.1468422;-2.078486;IRRE
test with n features 1;3.2868183;3.289073;-1.1883309;1.2867911;2.5278175;-7.0424047;TASK
test with one sample;2.7535405;5.7027006;2.874718;3.312733;3.1367722;-6.947655;IRRE
create x with 1 sample and 5 features;3.587825;0.650592;1.2887291;-3.2562215;4.8214254;-1.3459243;TASK
test integer type;0.60253215;6.6485515;-1.940261;0.6396936;0.9913718;-7.659863;IRRE
test centered case;1.3035662;6.037426;1.9658827;1.7102275;0.080936246;-5.1977983;IRRE
tests shrunkcovariance module on a simple dataset;5.6633167;0.57410866;-5.238489;1.9949571;-2.6098192;-1.5243844;CODE
compare shrunk covariance obtained from data and from mle estimate;5.2571144;0.6519224;-1.7793638;2.1058526;-2.669682;2.6136727;CODE
same test with shrinkage not provided;1.4063771;5.455047;-3.404408;3.269866;-2.9096453;-2.5807326;IRRE
same test with shrinkage 0 empirical covariance;2.7448955;2.0592067;-4.2909265;1.6625739;-3.8463805;1.4022645;IRRE
test with n features 1;3.2868183;3.289073;-1.1883309;1.2867911;2.5278175;-7.0424047;TASK
test shrinkage coeff on a simple data set without saving precision;7.8446865;3.51568;-4.658025;2.359994;-1.979747;-0.15577285;IRRE
tests ledoitwolf module on a simple dataset;2.352632;-0.94911426;-3.670193;1.7961618;-0.42954865;-3.785367;IRRE
test shrinkage coeff on a simple data set;8.013141;3.1245456;-3.6562412;1.555923;-0.8715393;-0.28606743;IRRE
compare shrunk covariance obtained from data and from mle estimate;5.2571144;0.6519224;-1.7793638;2.1058526;-2.669682;2.6136727;CODE
compare estimates given by lw and shrunkcovariance;4.042097;0.38862517;-2.4860985;2.8541114;-2.2407775;3.6140728;CODE
test with n features 1;3.2868183;3.289073;-1.1883309;1.2867911;2.5278175;-7.0424047;TASK
test shrinkage coeff on a simple data set without saving precision;7.8446865;3.51568;-4.658025;2.359994;-1.979747;-0.15577285;IRRE
same tests without assuming centered data;5.3387365;6.0585647;1.0881431;1.8088433;-1.1722548;-2.2179883;IRRE
test shrinkage coeff on a simple data set;8.013142;3.1245463;-3.6562421;1.5559212;-0.87153894;-0.28606743;IRRE
compare shrunk covariance obtained from data and from mle estimate;5.2571144;0.6519224;-1.7793638;2.1058526;-2.669682;2.6136727;CODE
compare estimates given by lw and shrunkcovariance;4.042097;0.38862517;-2.4860985;2.8541114;-2.2407775;3.6140728;CODE
test with n features 1;3.2868183;3.289073;-1.1883309;1.2867911;2.5278175;-7.0424047;TASK
test with one sample;2.7535405;5.7027006;2.874718;3.312733;3.1367722;-6.947655;IRRE
warning should be raised when using only 1 sample;1.3014035;5.8069186;-2.893048;4.2266803;1.5971099;-1.4925588;CODE
test shrinkage coeff on a simple data set without saving precision;7.8446865;3.51568;-4.658025;2.359994;-1.979747;-0.15577285;IRRE
a simple implementation of the formulas from ledoit wolf;1.6104932;-2.8715503;-0.08966594;-4.4442;1.3130472;-2.1272578;CODE
the computation below achieves the following computations of the;1.1309918;1.2823966;0.5766193;-5.3705525;0.5918396;1.9890527;-
o ledoit and m wolf a well conditioned estimator for;2.6405978;-0.29116535;-0.6039408;3.3213348;0.6389083;2.9563496;CODE
large dimensional covariance matrices;4.7888865;-3.0126445;-0.486041;-3.303975;-0.7868322;4.405312;CODE
beta and delta are given in the beginning of section 3 2;-3.257006;-0.7989019;0.0008063552;-0.76426786;1.6264737;0.5063445;CODE
compare our blocked implementation to the naive implementation;-0.6765706;-1.2159724;-1.3047669;3.9955587;1.652311;0.31707293;TASK
test that ledoit wolf doesn t error on data that is wider than block size;0.76196206;3.7524564;-3.63673;0.14935482;-3.0262258;-3.025953;CODE
use a number of features that is larger than the block size;2.6441894;1.2423334;1.2009565;-2.0729473;3.0911963;1.772694;TASK
check that covariance is about diagonal random normal noise;-0.090096086;0.42550638;-3.1572065;-0.9480226;-2.364687;2.338038;IRRE
check that the result is consistent with not splitting data into blocks;4.666522;6.7780337;-1.1322134;0.20301296;0.038835917;-3.5956888;IRRE
sample data from a sparse multivariate normal;5.3122225;-0.8578454;-0.71898603;-3.8395977;-0.41178808;3.9044979;CODE
check that the costs always decrease doesn t hold if alpha 0;0.4449838;4.763222;-1.6104057;1.2964786;-2.5977376;-0.058838382;CODE
use 1e 10 since the cost can be exactly 0;-0.71306443;2.556462;0.41029057;-1.1544436;0.43560496;-0.71035534;-
check that the 2 approaches give similar results;2.604176;4.57577;1.1075794;1.8863281;0.81415266;-1.3469044;IRRE
smoke test the estimator;1.5630026;3.930415;-0.0042923153;4.4155297;-2.4107544;-0.12071369;IRRE
for a centered matrix assume centered could be chosen true or false;2.775944;3.1053064;-0.24453962;-1.1222863;-2.0510502;0.91281253;CODE
check that this returns indeed the same result for centered data;4.2903805;6.107305;-0.17340821;-3.3168979;-4.981926;-1.6732429;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
tests the fastmcd algorithm implementation;1.6870892;-0.019103369;-2.003266;1.2815069;0.91612786;-0.766506;TASK
small data set;7.1651106;-0.84576446;3.3268387;-2.4019651;2.459135;-1.5901812;IRRE
test without outliers random independent normal data;3.4426525;4.6679053;-1.2573704;1.4748329;-0.86508644;-1.4401189;IRRE
test with a contaminated data set medium contamination;3.9041407;3.531706;-1.6800522;3.121213;-0.16091236;-4.312509;IRRE
test with a contaminated data set strong contamination;3.9960907;4.472943;-1.9908752;3.7705002;0.5256057;-4.743138;IRRE
medium data set;6.8470736;-1.7817938;2.9159887;-2.796554;1.6065722;0.227417;IRRE
large data set;6.777114;-1.9136738;3.5972536;-1.375758;2.091558;-1.6180222;IRRE
1d data set;6.5471096;0.5664225;1.945763;-6.859251;1.9434326;0.13224025;IRRE
n samples n features;5.852936;-2.6180372;0.8141393;-3.781754;3.215305;-2.277004;TASK
add some outliers;4.5602713;-0.09494259;2.9461763;0.4609042;-0.23813012;-1.1692656;TASK
compute mcd by fitting an object;4.88768;0.36236006;-0.70513314;-1.9819173;0.225378;1.6765109;IRRE
compare with the estimates learnt from the inliers;6.0404825;-0.6210608;0.9037254;4.0330205;-2.0308974;-0.37086958;IRRE
check that the code does not break with x shape 3 1;-2.123596;4.039827;-1.7869074;-3.2240574;-0.88421834;-3.3688862;CODE
i e n support n samples;3.1933339;-2.9914114;0.3606304;-0.3962363;2.7440577;-2.0919445;-
check that mcd completes when the covariance matrix is singular;1.5011663;2.6827874;-4.8817816;-0.3081728;-2.2704933;3.0445561;CODE
i e one of the rows and columns are all zeros;1.7568785;3.7212415;0.6329491;-7.595819;-2.2474487;-3.5885408;-
think of these as the values for x and y 10 values between 5 and 5;2.149114;0.605007;5.3175054;-6.02206;-0.7359401;-4.1054544;IRRE
get the cartesian product of all possible coordinate pairs from above set;1.2673829;0.63003075;2.3839083;-5.4912057;0.08264626;-0.22524862;IRRE
add a third column that s all zeros to make our data a set of point;4.523179;2.8390725;2.6214502;-8.279059;-1.3691064;-1.0797257;TASK
within a plane which means that the covariance matrix will be singular;1.5471811;1.8165905;-1.4719495;-3.430933;-2.863036;5.5974097;CODE
the below line of code should raise an exception if the covariance matrix;1.3657855;3.824612;-5.9923725;-0.8404588;-2.5109932;0.8747759;CODE
is singular as a further test since we have points in xyz the;1.2916154;4.7236786;-1.3054366;-2.2285476;-1.5394156;-2.8777823;IRRE
principle components eigenvectors of these directly relate to the;-0.5205754;-3.5888577;-0.16964251;-2.1940165;2.2300885;5.223656;-
geometry of the points since it s a plane we should be able to test;1.2522471;3.1952746;2.7326255;-0.63483286;-2.1692736;-1.7982702;CODE
that the eigenvector that corresponds to the smallest eigenvalue is the;0.3665597;-1.0109458;-1.6499051;-1.5151082;0.17963363;3.7763147;IRRE
plane normal specifically 0 0 1 since everything is in the xy plane;-1.4921155;2.2615297;-0.97736156;-6.453192;-3.98952;1.6729558;IRRE
as i ve set it up above to do this one would start by;-2.8762987;-1.0124035;5.2215996;-2.1977804;1.0780417;1.9267966;CODE
evals evecs np linalg eigh mcd fit covariance;2.6023579;-1.6056572;-6.486377;-0.48874247;-2.3486378;3.507347;CODE
normal evecs np argmin evals;0.034003373;0.109632306;-4.407523;-1.1220303;0.027624939;-0.59301066;-
after which we need to assert that our normal is equal to 0 0 1;0.51089215;4.9316244;-2.0139792;-0.012451646;-0.73659694;-1.3028715;TASK
do note that there is floating point error associated with this so it s;-0.23095375;3.9249713;-2.5170536;-2.4628277;-3.9339454;-3.5048585;CODE
best to subtract the two and then compare some small tolerance e g;1.4883766;4.6285043;0.6095929;1.6330434;-0.9652641;-2.012823;IRRE
1e 12;-2.2189655;-0.5869433;2.0186088;-2.5343523;-0.014529253;-3.1396909;-
check that mcd returns a valueerror with informative message when the;0.32355073;3.6475146;-5.6374044;3.5803595;-2.1827192;-2.981995;IRRE
covariance of the support data is equal to 0;0.88632804;0.89112645;-2.9062827;-0.1611779;-3.044418;3.5194657;CODE
check that a warning is raised if we observe increasing determinants;1.8506316;2.6196861;-1.6259811;1.7032146;-2.135742;0.16887309;CODE
during the c step in theory the sequence of determinants should be;-0.07045424;-0.22002293;-0.6545164;-0.92509025;-0.7119407;1.6256889;CODE
decreasing increasing determinants are likely due to ill conditioned;2.1445434;2.4223258;-1.0894698;1.428458;-1.7654902;2.748053;-
covariance matrices that result in poor precision matrices;5.060152;-0.27687925;-4.0430355;-1.3968052;-3.315698;2.433886;IRRE
threshold 0 985 threshold for variance underesitmation;1.817102;1.7163746;-3.0650342;0.75156283;-1.9389629;0.5167836;CODE
assume centered data to reduce test complexity;6.7558823;5.297502;-0.43510583;1.8452793;-0.992487;-0.953033;IRRE
compute mean ratio of variances;1.2168641;1.5330408;2.2220461;-1.3365287;-3.047298;-0.123115584;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
used previous scipy pinv2 that was updated in;-2.3452194;-5.98504;-3.7230027;-1.7163678;-4.9893436;-1.7406375;CODE
https github com scipy scipy pull 10067;-1.6391695;-6.615933;-4.011647;-3.019147;-6.344948;-4.1983204;CODE
we can not set cond or rcond for pinv2 in scipy 1 3 to keep the;-2.7613974;-1.9388266;-5.6985626;-2.6279845;-4.217209;-0.18928353;CODE
same behavior of pinv2 for scipy 1 3 because the condition used to;-0.6270218;-0.12734109;-6.697254;-2.0616567;-5.10938;-1.0598153;IRRE
determine the rank is dependent on the output of svd;3.8785355;0.33150542;-1.151388;-2.7639885;0.39151463;1.0235652;IRRE
x weights old 100 init to big value for first convergence check;3.3525002;3.256869;-1.8391284;1.3333572;-3.0969338;1.6405834;IRRE
precompute pseudo inverse matrices;2.7068903;-1.4445449;-0.9027783;-4.684939;-1.2219268;1.8817984;CODE
basically x pinv x t x 1 x t;0.07130456;-1.6572633;1.8893319;-5.2191014;1.6120145;-0.73661023;IRRE
which requires inverting a n features n features matrix;3.3232248;-1.6712971;-0.5357898;-3.7209156;0.7687507;2.519814;TASK
as a result and as detailed in the wegelin s review cca i e mode;-2.5598147;-1.7486435;-0.14868763;0.52348876;1.9013942;2.3938644;IRRE
b will be unstable if n features n samples or n targets;3.7020154;0.0961288;-2.8111904;1.4051567;0.18443102;0.74056274;TASK
n samples;4.707609;0.067905225;3.3776014;-2.4757779;2.6855786;-5.2138243;-
center;-1.4909133;-0.15169014;8.293048;-1.6786757;-1.5458238;-0.391684;-
scale;2.7350285;-0.18313088;6.790365;-1.8021256;-2.4313195;-1.2581645;-
basic checks for plscanonical;1.1755853;1.6575918;-1.3558242;-1.1040287;-0.35394707;-2.2582822;CODE
check x tp and y uq;-0.62166536;4.3447223;0.04492762;-2.690616;-1.1954684;-4.1222215;-
need to scale first;1.7933327;1.557801;7.10111;-2.4857905;-2.2085738;0.939405;TASK
check that rotations on training data lead to scores;4.4869447;1.4116243;-1.0464941;1.2375578;-0.50755197;-2.3156774;-
check that inverse transform works;-1.2032391;4.1619763;0.9741513;-1.5503871;-4.1419687;-2.5256338;IRRE
sanity check for plsregression;-2.9739978;3.4037316;-0.263578;2.583982;-0.42737848;0.27082038;CODE
the results were checked against the r packages plspm misomics and pls;1.4244311;-1.5925176;-5.2565355;-0.1755268;-1.5863986;-0.78740007;IRRE
fixme one would expect y trans pls y scores but this is not;-1.3172287;1.2892543;-0.64532524;0.6779616;-1.9187939;-2.775099;CODE
the case;-2.6398394;-1.4212574;5.9303617;1.2890185;0.6542482;-1.6974206;CODE
xref https github com scikit learn scikit learn issues 22420;-3.1465015;-7.609325;-5.638905;-0.9045666;-5.8326426;-4.4804463;CODE
the r python difference in the signs should be consistent across;0.18542808;1.2358562;-3.229785;-2.6440015;-4.3592186;-3.2497401;CODE
loadings weights etc;0.1786637;-3.1092522;4.1198606;2.6627932;0.044048686;1.6520159;IRRE
check behavior when the first column of y is constant;2.5884922;5.389112;1.1919327;-2.0908453;-4.8881803;-1.7173011;CODE
the results are checked against a modified version of plsreg2;0.03500293;-1.23262;-4.613976;1.1831137;-1.9160591;-0.87991416;IRRE
from the r package plsdepot;-0.92493635;-2.063842;-0.9593708;-3.5829127;0.18254778;-2.665785;CODE
for the plsregression with default parameters y loadings y weights;1.6254637;0.8959225;-1.3056602;-1.5360824;-1.9834247;4.8664956;CODE
we ignore the first full zeros row for y;2.0076585;4.5838084;-1.3784661;-6.2658186;-4.1951923;-1.9740951;CODE
sanity check for plscanonical;1.0353074;0.44672847;-0.5662315;-1.8374487;-2.0616286;-1.0281394;CODE
the results were checked against the r package plspm;1.1388083;-1.5518211;-4.723966;2.1216686;-1.6167763;-1.1146771;IRRE
sanity check for plscanonical on random data;5.500205;1.1807778;-1.6915514;-0.72343016;-0.6186135;-0.4854995;IRRE
the results were checked against the r package plspm;1.1388083;-1.5518211;-4.723966;2.1216686;-1.6167763;-1.1146771;IRRE
2 latents vars;-1.680974;2.1398017;0.45711455;-1.1222467;1.341239;-1.8868285;CODE
make sure convergencewarning is raised if max iter is too small;0.86083865;1.9154712;-3.0889852;2.850396;-4.1054373;3.6884649;CODE
make sure attributes are of the correct shape depending on n components;3.8546207;2.063924;0.12109446;-2.8825355;3.9944274;2.6529727;TASK
ensure 2d y with 1 column is equivalent to 1d y;4.5715876;3.6347492;0.058835678;-6.626013;-3.203946;1.3634845;-
check that the copy keyword works;-4.8188734;1.8277973;-3.504454;2.1909044;-0.7827461;-0.61152387;-
copy true won t modify inplace;-4.104723;4.165149;-1.4298241;0.83854324;-2.5664616;1.7114962;-
copy false will modify inplace;-3.647961;5.472563;-1.8988029;1.1295232;-2.3218832;1.3217351;-
return plssvd does not support copy param in predict or transform;0.23806995;0.63241655;-4.582012;-0.7672189;-3.5794027;2.5248725;CODE
make sure copy true gives same transform and predictions as predict false;1.5702385;1.7870898;-3.8020742;2.37907;-3.5912926;1.0484153;CODE
loadings converges to reasonable values;2.6478674;1.9033184;-0.29122844;3.5487905;-3.7740157;1.1227118;IRRE
check that it works in votingregressor;-3.042049;3.4170353;-1.8140448;1.855234;0.5137281;-1.4376568;-
handcrafted data where we can predict y from x with an additional scaling factor;6.0326934;-2.5070007;3.4479167;-2.7365732;-2.1291;4.043618;TASK
x rng normal scale 10 size 30 5 add a std of 10;0.99797356;1.9077415;0.9620339;-5.4765024;-0.11497999;-0.07641208;CODE
we need to make sure that the dimension of the latent space is large enough to;1.8700757;-0.59304863;-1.255547;0.31669003;-0.4457793;3.7145658;TASK
perfectly predict y from x no information loss;4.439493;1.5381134;-1.0033509;1.8191999;-2.41041;0.7297712;CODE
we therefore should be able to predict y from x;4.070872;-2.0708413;2.5203302;2.20054;-1.7095094;0.034059793;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
convert to array for fancy indexing;1.8786771;1.2148117;3.7765021;-5.37328;1.0877174;-0.9975748;CODE
read header and data;-2.0687904;0.315837;2.8193507;-1.1221547;0.6894936;-1.5343246;CODE
f seek 0 reset file obj;-3.3351715;1.3591671;-1.7004431;-1.4615296;-2.9184644;-0.26638317;IRRE
f seek 0 reset file obj;-3.3351724;1.3591671;-1.7004446;-1.4615283;-2.918464;-0.266383;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
https www dcc fc up pt ltorgo regression cal housing tgz;-0.84613615;-1.957732;-0.86662894;-0.055274185;-1.0537925;-0.6385023;CODE
columns are not in the same order compared to the previous;1.6195457;3.3975322;1.3647488;-4.3659863;-1.6973761;-0.4974282;IRRE
url resource on lib stat cmu edu;-4.1460233;-4.479873;-0.48168984;0.6222636;1.2094914;0.4426373;-
avg rooms total rooms households;0.20771822;0.9864084;2.1967797;-0.13213733;0.44682822;0.3756602;-
avg bed rooms total bed rooms households;0.23427284;0.61758345;1.5609857;-0.67440534;0.47337323;0.21427448;-
avg occupancy population households;0.76563776;-1.045914;0.15559201;0.44915462;0.26736477;1.2902002;-
target in units of 100 000;2.0332172;0.94009274;2.3200796;-0.63971853;0.28309062;-1.0936214;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found in;2.1239507;-2.555784;1.9467325;-1.0367235;0.890359;-0.9491109;-
https archive ics uci edu ml machine learning databases covtype covtype data gz;2.3777244;-5.6678753;-4.8768067;-1.0496563;1.92222;0.2346947;CODE
column names reference;0.26156422;-2.1049776;0.1330943;-3.4585598;2.7109935;-0.4718415;CODE
https archive ics uci edu ml machine learning databases covtype covtype info;1.9385065;-5.787754;-5.414007;-1.0102767;2.0794654;-0.02062922;CODE
creating temp dir as a direct subdirectory of the target directory;-1.5798663;-0.39554563;-0.04437775;-0.601325;-0.45478502;1.2559102;-
guarantees that both reside on the same filesystem so that we can use;-2.4186876;-0.5765099;0.46803123;2.1847558;1.4733769;4.562781;CODE
os rename to atomically move the data files to their target location;-1.5118989;-1.0204664;0.6425291;-0.17002904;-0.4108762;3.6015165;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
https archive ics uci edu ml machine learning databases kddcup99 mld kddcup data gz;2.3980272;-5.7060447;-3.0386279;-0.27141926;3.291417;-0.478194;CODE
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
https archive ics uci edu ml machine learning databases kddcup99 mld kddcup data 10 percent gz;3.0442002;-5.4476304;-2.9958704;0.10328449;3.2747664;-0.9148973;CODE
selected abnormal samples;4.83049;2.3194263;1.3804121;1.0436873;2.3744738;-2.9005394;CODE
select all samples with positive logged in attribute;2.932059;3.0528743;-0.5027248;1.6109992;2.654191;-0.88955957;META
xxx bug when compress 0;-3.5872545;3.7573986;-3.6391332;-3.162121;-3.376191;0.22358449;-
error incorrect data length while decompressing the file;-0.69335634;2.2726161;-4.222437;-3.6597843;-3.5015256;-1.2397752;CODE
could be corrupted;-5.34457;0.61828697;-0.2860699;0.37092918;-3.5800369;-2.4305663;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found in;2.1239507;-2.555784;1.9467325;-1.0367235;0.890359;-0.9491109;-
http vis www cs umass edu lfw lfw tgz;-3.1255493;-3.0619357;-0.16276923;-0.6144426;1.0901617;-2.3435886;CODE
the original funneled data can be found in;2.5525706;-2.0013626;2.2992551;0.59484816;0.94528526;1.2657701;-
http vis www cs umass edu lfw lfw funneled tgz;-2.9868734;-2.001918;-0.36618024;0.7467297;0.31906334;-0.36580554;CODE
the original target data can be found in;2.473933;-2.4641187;1.3884535;1.0625854;1.3410213;0.7296348;-
http vis www cs umass edu lfw pairsdevtrain txt;-1.1425054;-3.990198;-1.7647915;-1.3086338;1.9991218;-2.3735356;CODE
http vis www cs umass edu lfw pairsdevtest txt;-1.0489669;-1.3695893;-2.4779391;-0.21795787;1.2167385;-5.3346314;IRRE
http vis www cs umass edu lfw pairs txt;-2.1251235;-2.3036828;-0.3521145;-2.0326624;2.3073308;-3.2600303;CODE
common private utilities for data fetching from the original lfw website;-2.1478665;-2.6029036;-0.13559902;1.6103703;2.1997063;2.2030745;CODE
local disk caching and image decoding;1.0927411;-0.96724254;0.79584664;0.2788389;-0.29292482;4.513902;-
compute the portion of the images to load to respect the slice parameter;3.0318341;1.0545206;3.6002152;-3.1050231;-1.4717319;3.5998695;IRRE
given by the caller;-2.012098;0.40288857;5.5383854;2.1183662;3.073694;-3.4743361;IRRE
allocate some contiguous memory to host the decoded image slices;0.036554422;0.9368425;0.5220075;-2.4261568;0.89501077;5.404548;-
iterate over the collected file path to load the jpeg files as numpy;1.448257;-1.2495736;0.54120034;-1.2264667;-4.852994;1.6633729;CODE
arrays;2.3240907;1.5815082;4.629078;-4.281872;0.95440394;-5.127513;-
logger debug loading face 05d 05d i 1 n faces;-3.0738146;-0.21767302;-1.4647529;-1.7012409;-1.7465565;1.1173679;CODE
checks if jpeg reading worked refer to issue 3594 for more;-2.368081;3.366802;-1.9946343;1.6290944;-2.7562768;-2.1320505;CODE
details;-1.9197476;-2.4566455;5.9425316;0.8847738;1.0150981;-1.1708876;-
face 255 0 scale uint8 coded colors to the 0 0 1 0 floats;0.082676865;0.91957766;-2.0872834;-7.897232;-2.8181126;1.5782442;CODE
average the color channels to compute a gray levels;4.1863055;-0.25423187;2.3947442;-3.4883432;-1.6668026;0.51427364;-
representation;-0.7608903;-2.367999;4.962392;-1.9334484;2.9168937;-1.2665551;-
task 1 face identification on picture with names;0.3662504;-0.82474923;2.5319512;-2.4571505;2.1212332;-0.15560506;TASK
scan the data folder content to retain people with more that;1.9483185;-0.70485944;2.4485207;0.115928605;1.9344378;0.81535053;OUTD
min faces per person face pictures;2.0446184;-0.9520245;2.712663;-2.429256;1.8044999;1.6327986;-
shuffle the faces with a deterministic rng scheme to avoid having;2.8916676;-0.011528605;1.0020221;-1.4505008;2.8165205;1.510847;CODE
all faces of the same person in a row as it would break some;-0.39358678;0.36132923;5.214655;-0.5300942;2.400228;-0.82924736;CODE
cross validation and learning algorithms such as sgd and online;4.849173;-4.9426007;-0.43239573;3.1010737;2.1046634;0.4291696;CODE
k means that make an iid assumption;-0.6068357;0.20474689;-0.85032;0.6915812;3.1302183;0.30025214;-
wrap the loader in a memoizing function that will return memmaped data;2.533299;1.1144341;1.3389173;2.438983;0.61032087;2.7328057;CODE
arrays for optimal memory usage;3.5968468;-0.12867068;3.1152432;-2.058552;1.9735966;0.5756098;CODE
load and memoize the pairs as np arrays;4.596232;-1.5961131;-0.020257032;-3.4964914;-0.13509166;-0.31986094;CODE
pack the results as a bunch instance;3.898031;0.91364795;3.008929;3.8270068;2.5283344;-0.7172693;IRRE
task 2 face verification on pairs of face pictures;2.3713138;-0.13552955;0.77847725;-0.5002967;2.3285234;0.13454838;TASK
parse the index file to find the number of pairs to be able to allocate;2.0735862;1.684911;0.50906396;-5.3570256;2.2501097;-2.5980341;IRRE
the right amount of memory before starting to decode the jpeg files;-0.5561149;-0.0035249195;0.8605357;0.96453696;-0.8947485;2.099894;CODE
iterating over the metadata lines for each pair to find the filename to;1.1072607;-0.8547305;-0.012264467;-0.9603523;2.3719656;-0.10836385;CODE
decode and load in memory;-0.8527574;-0.3609812;1.1029723;-1.0803198;1.2676523;0.8468392;CODE
wrap the loader in a memoizing function that will return memmaped data;2.533299;1.1144341;1.3389173;2.438983;0.61032087;2.7328057;CODE
arrays for optimal memory usage;3.5968468;-0.12867068;3.1152432;-2.058552;1.9735966;0.5756098;CODE
select the right metadata file according to the requested subset;1.0511886;0.6289845;-0.57426095;1.4975109;4.8650723;2.9674122;CODE
load and memoize the pairs as np arrays;4.596232;-1.5961131;-0.020257032;-3.4964914;-0.13509166;-0.31986094;CODE
pack the results as a bunch instance;3.898031;0.91364795;3.008929;3.8270068;2.5283344;-0.7172693;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
https cs nyu edu roweis data olivettifaces mat;1.4098147;-0.95502657;0.8632887;-5.1970468;-0.6205918;0.40270495;CODE
delete raw mat data;2.0836809;2.8759391;-0.85215586;-5.0717397;-2.3513222;1.8836222;CODE
we want floating point data but float32 is enough there is only;0.97632354;1.1288041;-1.8567461;-4.623487;-0.46033764;-0.7573518;CODE
one byte of precision in the original uint8s anyway;-0.59629196;1.4024584;-2.536338;-2.3890996;-1.6300489;-0.23056625;CODE
10 images per class 400 images total each class is contiguous;2.4156556;0.76216716;2.339166;-0.64646906;2.198618;0.0744365;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
412 is a specific openml error code;-6.254651;1.8688257;-3.113899;-0.70246387;1.1002961;-1.8339015;CODE
avoid a resourcewarning on python 3 14 and later;-2.637901;-2.160737;-1.0425329;3.8162727;-2.7562025;1.3575426;CODE
create a tmpdir as a subfolder of dir name where the final file will;-1.3397022;0.4640462;2.0767045;-0.8225899;-0.34775636;1.2592776;IRRE
be moved to if the download is successful this guarantees that the;-4.0858517;0.7306734;0.14470905;4.016063;-2.8224204;3.2299972;CODE
renaming operation to the final location is atomic to ensure the;-5.1092978;2.5418324;-0.010573125;2.8963447;2.1376336;2.3501306;CODE
concurrence safety of the dataset caching mechanism;2.1473432;-1.8470271;-0.7592042;3.7789676;1.5939643;2.1694283;IRRE
xxx first time decompression will not be necessary by using fsrc but;-3.1800597;1.8789277;-3.4650853;0.6564587;-0.39936113;3.3293397;META
it will happen nonetheless;-0.6134705;1.2287252;1.9368274;2.8948061;0.5724608;1.9668237;-
https www openml org api docs data get data list data name data name;-2.910824;-1.9788787;-0.16830656;-1.0245956;0.67672163;-0.10031156;CODE
adult fetch openml adult version 2 doctest skip;-5.187637;1.5207082;-2.6043293;4.416987;-0.81834906;-0.88995016;CODE
adult frame info doctest skip;-3.4516447;0.43631497;-1.914286;2.7760286;-1.6743326;-0.3667172;IRRE
column non null count dtype;1.9631977;3.2964828;-4.1702266;-3.6997278;-0.26820916;-3.4232564;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original vectorized data can be found at;7.0533676;-5.001128;-0.7647053;-4.3178296;0.060262088;2.1942313;-
http www ai mit edu projects jmlr papers volume5 lewis04a a13 vector files lyrl2004 vectors test pt0 dat gz;0.73651445;-3.684234;-4.594383;-3.3912401;0.16142622;-0.79871863;IRRE
http www ai mit edu projects jmlr papers volume5 lewis04a a13 vector files lyrl2004 vectors test pt1 dat gz;0.7080272;-3.5425131;-4.763892;-3.377862;0.09292773;-0.7476306;IRRE
http www ai mit edu projects jmlr papers volume5 lewis04a a13 vector files lyrl2004 vectors test pt2 dat gz;0.63945633;-3.6368985;-4.621936;-3.290721;0.00029290165;-0.827783;IRRE
http www ai mit edu projects jmlr papers volume5 lewis04a a13 vector files lyrl2004 vectors test pt3 dat gz;0.31821537;-3.7089717;-4.649857;-3.6348076;0.33180204;-0.75309104;IRRE
http www ai mit edu projects jmlr papers volume5 lewis04a a13 vector files lyrl2004 vectors train dat gz;1.4553132;-6.3112574;-3.0994656;-3.2671418;0.9614049;0.6675625;CODE
while the original stemmed token files can be found;-5.0629215;-3.803548;-1.2488422;-1.1548709;1.8707161;1.5670687;CODE
in the readme section b 12 i;-4.1543436;-3.054599;0.52518916;0.0020069513;2.8787887;0.13856412;CODE
http www ai mit edu projects jmlr papers volume5 lewis04a lyrl2004 rcv1v2 readme htm;-2.2141297;-6.046777;-0.8406017;-0.4317186;1.8532797;0.4730619;CODE
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
http jmlr csail mit edu papers volume5 lewis04a a08 topic qrels rcv1 v2 topics qrels gz;-4.2290626;-4.909563;-2.4663951;0.9006;2.3962576;0.5493417;CODE
load data x and sample id;2.1396887;3.0416667;1.2818261;-1.1208966;3.302533;0.006175887;TASK
training data is before testing data;3.121602;2.01094;-1.3113964;5.7942204;0.8389589;-2.844075;IRRE
delete archives;-2.894054;0.16735666;1.7037398;-0.6372967;0.73259795;-0.07636608;CODE
load target y categories and sample id bis;1.5551821;0.44475988;-1.388673;0.51066977;2.9825244;-0.09435095;CODE
parse the target file;-0.47530973;0.110928215;1.1619722;0.43708742;-0.022135641;-0.23250689;IRRE
delete archive;-3.6202824;1.0810139;1.4632882;-0.8209113;-0.055126633;-0.17743582;CODE
samples in x are ordered with sample id;2.8033311;3.66407;0.1263519;-2.6376286;3.2530591;-1.106942;-
whereas in y they are ordered with sample id bis;1.4368005;2.1586876;-1.3190496;-2.18015;4.8723335;-1.6834899;-
save category names in a list with same order than y;1.5126755;-0.025449207;2.5120358;-0.4177836;2.243418;-0.92828;CODE
reorder categories in lexicographic order;-0.68727213;-1.5270827;1.6938598;-1.5608822;2.6919003;2.0395496;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found at;2.32536;-2.5450666;2.2903926;-1.3836601;0.17923182;-0.7435019;-
https biodiversityinformatics amnh org open source maxent samples zip;0.8389673;-4.303657;-2.4006753;-1.272303;2.3031058;-1.6840557;CODE
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
https biodiversityinformatics amnh org open source maxent coverages zip;-0.8274827;-4.0753636;-2.059624;-0.087091565;1.9739039;-0.6695112;CODE
x y coordinates for corner cells;0.42943436;-0.15855147;3.4682386;-8.578858;-3.992921;1.0000855;CODE
x coordinates of the grid cells;1.1938763;0.97250885;3.1347892;-7.352223;-2.9789383;1.3927096;-
y coordinates of the grid cells;0.9027665;0.42357472;3.3228528;-6.7840323;-4.5404034;1.127217;-
define parameters for the data files these should not be changed;-0.42205185;1.633642;-2.5373828;-1.3009131;1.3304567;4.0331993;CODE
unless the data model changes they will be saved in the npz file;-0.33364278;-1.0030792;-1.3798062;1.5445036;-0.48987514;3.636388;CODE
with the downloaded data;-0.8671477;-3.953518;4.43289;-0.103271335;1.062848;0.53953594;CODE
with np load samples path as x samples zip is a valid npz;0.4510973;0.64912164;-5.146675;-1.9979333;-1.0876653;0.8849277;CODE
with np load coverages path as x coverages zip is a valid npz;-2.0096707;1.2696843;-4.7664266;-0.68930894;-0.77531457;0.3116058;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dtype no validation delegate validation to numpy;0.47286406;-0.6859078;-7.311464;-1.0779586;-5.0228963;-0.3853194;OUTD
if isinstance f int file descriptor;-2.059255;3.5997713;-1.8624073;0.91115975;1.1398448;-0.6257173;CODE
convert from array array give data the right dtype;3.2718017;1.9961455;-2.0090146;-5.3510776;-3.226546;-3.1886206;CODE
indptr np frombuffer indptr dtype np longlong never empty;-1.4896793;0.07328541;-5.7505455;-3.0690784;-3.92086;-0.29727125;CODE
data np asarray data dtype dtype no op for float 32 64;0.14910267;-0.5543775;-5.97595;-6.2087884;-4.0773826;-2.1755471;CODE
dtype no validation delegate validation to numpy;0.47286406;-0.6859078;-7.311464;-1.0779586;-5.0228963;-0.3853194;OUTD
disable heuristic search to avoid getting inconsistent results on;0.24848434;2.9158711;-1.4396766;5.214544;0.34839627;-0.20698251;IRRE
different segments of the file;-1.0379337;1.2724946;3.7674234;-4.198057;1.387783;0.37709194;-
generated by dump svmlight file from scikit learn s n version;-1.5270747;-7.1787252;-6.3784833;-1.784892;-3.0981143;-2.1836247;META
column indices are s based n zero one one based encode;4.156511;0.401519;-3.488576;-7.6072745;1.9412968;-1.1540551;-
f write b n;-1.7288096;0.05533461;3.3026378;-3.198862;0.37261143;-5.0510125;TASK
f writelines b s n line for line in comment splitlines;-0.92137384;-0.11135172;0.58815134;-3.4273634;0.6389506;-2.3236725;CODE
convert comment string to list of lines in utf 8;-1.6815162;0.16056024;1.0776402;-1.3149554;-1.2639849;-1.5890752;CODE
if a byte string is passed then check whether it s ascii;-2.695341;4.792357;-1.3005686;-0.15554881;-0.7444988;-3.491304;IRRE
if a user wants to get fancy they ll have to decode themselves;-3.607701;-2.5670788;0.8823526;0.7691021;1.7409594;0.5415997;-
comment decode ascii just for the exception;-5.079345;2.599641;-2.7347147;0.25822997;-0.5531778;-2.4480467;CODE
we had some issues with csr matrices with unsorted indices e g 1501;2.8491993;1.4319879;-4.736717;-4.923994;-2.1364365;-0.058248416;-
so sort them here but first make sure we don t modify the user s x;-1.3900831;-0.43519428;0.5590989;-1.726421;1.0842116;0.88727987;META
todo we can do this cheaper sorted indices copies the whole matrix;5.0541115;0.6991239;-0.65092504;-5.4758277;-0.4314981;2.7427845;CODE
note query id is passed to cython functions using a fused type on query id;-4.345133;2.1382701;-4.590416;-1.4304048;0.95015985;0.98292947;CODE
yet as of cython 3 0 memory views can t be none otherwise the runtime;-3.164261;0.6591877;-3.023235;-0.9494755;-0.546912;3.1342793;TASK
would not known which concrete implementation to dispatch the python call to;-4.280901;-3.781052;-2.7662926;1.5837675;-1.862883;-0.7886114;TASK
todo simplify interfaces and implementations in svmlight format fast pyx;-2.42786;-3.2441897;-2.6994975;-1.3919126;1.4516097;3.6647232;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the original data can be found at;2.325361;-2.5450664;2.2903922;-1.383659;0.17923129;-0.7435028;-
https people csail mit edu jrennie 20newsgroups 20news bydate tar gz;-3.5251973;-2.886583;0.62643564;0.03366309;-0.8644529;-1.8053548;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
extract a reduced dataset;7.8448524;-0.29343036;0.043680273;-1.194604;1.951712;0.10272153;IRRE
check that the ordering of the target names is the same;-0.31276283;3.3355355;-1.1721408;1.4054612;2.8481371;-1.3471845;-
as the ordering in the full dataset;6.054907;-3.0325274;2.029624;-1.8796729;3.874766;0.5320974;IRRE
assert that we have only 0 and 1 as labels;1.4960885;5.7402697;-0.91250044;-1.7135571;3.801193;-4.9310374;CODE
check that the number of filenames is consistent with data target;2.5281034;4.359047;-2.1540334;2.0171287;1.2496669;-1.7701774;-
check that the first entry of the reduced dataset corresponds to;6.7943897;3.9775078;-2.2167218;0.1181303;2.1182368;-1.3141394;IRRE
the first entry of the corresponding category in the full dataset;2.9569488;-3.429034;0.7271158;-0.33978158;3.899875;-0.45682833;CODE
check that return x y option;-2.136967;6.323392;2.0141904;0.32525316;-1.4658917;-5.0703073;IRRE
extract the full dataset;5.560562;-2.1544118;1.7348894;-2.2666168;1.7122443;-2.1577451;IRRE
test subset train;5.8871584;1.7856659;0.45134664;3.7247708;3.8714263;-3.7493062;IRRE
test subset test;2.9193769;4.8997874;1.1044084;3.114143;2.3754737;-6.9554677;IRRE
test return x y option;-0.2907888;6.884537;1.1328739;2.0968096;-2.058989;-6.7149377;IRRE
test subset all;3.7248924;4.6710744;1.2380245;4.100736;2.7604163;-6.802605;IRRE
check a small subset of features;5.0976653;1.7088165;0.22744945;0.36906445;2.3316512;-2.1213708;TASK
mock that the dataset was cached;2.5139673;2.2673533;-1.3649263;5.2957044;-1.6626476;-1.2015921;IRRE
mock that we have an outdated pickle with only x and y returned;-1.1499319;3.153971;-0.40161988;3.8992026;-1.72788;-3.3671792;IRRE
none of the input parameters are required to be accurate since the check;-0.10139476;5.9743457;-4.3993816;1.7234808;-1.8785477;-2.6786008;CODE
of the parser will be carried out first;-2.6085017;0.2872413;1.5192957;1.690122;3.823293;-1.946642;IRRE
internal quotes are not considered to follow the arff spec in liac arff;-4.5629907;1.4817369;-5.384219;0.72405916;-0.5785305;1.8001156;CODE
assert is china image;-0.80595165;2.007785;1.9050132;2.513716;-0.33395165;0.057788774;CODE
assert is flower image;-1.0097734;3.1463811;0.4330005;3.7169678;0.15227237;-1.3783199;CODE
this reproduces a problem when bunch pickles have been created;-2.5632257;1.9004836;-0.28595406;0.3104463;-2.9073684;-0.5369332;IRRE
with scikit learn 0 16 and are read with 0 17 basically there;0.76044846;-6.348336;-3.3179486;-2.4838443;-4.552662;-4.4361577;IRRE
is a surprising behaviour because reading bunch key uses;-1.6380388;1.1739649;0.49127638;1.702067;-0.69238853;-1.1298493;CODE
bunch dict which is non empty for 0 16 bunch objects;0.0018478016;3.258122;0.361747;-2.851148;-0.27503282;-3.3197973;CODE
whereas assigning into bunch key uses bunch setattr see;-1.8121355;1.8093601;-1.0843009;-1.1929971;1.4420644;-0.09215599;IRRE
https github com scikit learn scikit learn issues 6196 for;-3.3295703;-10.064104;-5.9560647;-0.2922356;-4.850987;-5.0437617;CODE
more details;-2.4105227;-2.2402644;4.5944734;0.51398784;0.5794692;-1.3544549;-
after loading from pickle the dict should have been ignored;-4.1854963;-0.34232682;-3.1586866;1.4222925;-3.222077;-0.15689604;CODE
making sure that changing the attr does change the value;-2.8371332;3.8792522;1.6383188;0.50236255;-0.6650381;1.2865816;IRRE
associated with getitem as well;-5.5956287;-4.0312405;2.6139362;2.0062034;1.442086;2.9013443;-
check that dir important for autocomplete shows attributes;-3.2765157;-0.8321394;-1.7970088;3.0098257;-0.33057535;1.3072573;CODE
https example com path to data json anchor;-3.0885565;0.25903395;1.9501826;-0.35228306;-3.1798646;2.49786;CODE
the first call should trigger a download;-5.661228;0.52407527;2.1793687;4.6700363;-0.30832943;1.971322;CODE
fetching again the same file to the same folder should do nothing;-4.0176835;2.3188374;2.0402794;3.541988;-2.3071797;1.7132031;CODE
deleting and calling again should re download;-5.302474;1.5344688;0.7381345;2.2119942;-1.7826716;1.636671;CODE
the first call should trigger a download;-5.661228;0.52407527;2.1793687;4.6700363;-0.30832943;1.971322;CODE
fetching again the same file to the same folder should do nothing when;-4.0713143;2.5925725;1.8549119;3.6547298;-2.503494;1.6535728;CODE
the sha256 match;-2.217212;-0.64247125;1.9421433;-0.029104594;0.6503222;-2.5276752;-
corrupting the local data should yield a warning and trigger a new download;-2.3730938;0.83903635;-0.88335985;4.419824;-1.1952673;1.1117365;CODE
calling again should do nothing;-3.4042804;4.0728416;1.3075802;1.9687748;-2.596044;-0.948166;IRRE
deleting the local file and calling again should redownload without warning;-5.6882887;1.5393054;-0.80712384;3.3726535;-2.8303473;2.654529;CODE
calling without a sha256 should also work without redownloading;-6.1129866;0.46016;-2.2923076;2.26527;-1.3035967;2.6606321;CODE
calling with a wrong sha256 should raise an informative exception;-4.253724;2.5089705;-4.2680655;2.8820443;-0.856785;-1.036024;CODE
test return x y option;-0.2907888;6.884537;1.1328739;2.0968096;-2.058989;-6.7149377;IRRE
check that pandas is imported lazily and that an informative error;0.8236412;1.128439;-5.394478;2.036033;-4.5210257;-2.6783164;CODE
message is raised when pandas is missing;-1.5468471;0.83269197;-2.6154897;-0.28792793;-5.1169653;-1.0911223;CODE
test return x y option;-0.2907888;6.884537;1.1328739;2.0968096;-2.058989;-6.7149377;IRRE
enumerated names are added correctly;-3.7898982;1.6039186;-0.47637132;-0.47812298;2.1142056;-1.8695985;TASK
test the return x y option;0.04960468;6.632179;1.4972438;2.563325;-2.220452;-5.7600293;IRRE
the data frames for the input features should match up to some numerical;7.396844;-1.5623941;-1.1704828;-4.1588187;-0.2615048;-0.44224426;CODE
dtype conversions e g float64 int64 due to limitations of the;-0.2566773;-1.4489855;-4.2381716;-4.7825856;-2.250869;-2.0721834;CODE
liac arff parser;-1.8370607;-0.83138734;-2.3057072;-0.2889306;3.2440274;0.1696435;IRRE
let s also check that the frame attributes also match;-3.0642207;1.6638448;-0.3138079;-1.0677012;-2.1367412;1.9512898;META
note that the frame attribute is a superset of the data attribute;0.31915027;-1.4282347;-0.077951;-2.1626348;-1.1326306;3.8652272;META
however the remaining columns typically the target s are not necessarily;3.4066765;1.4423494;0.9590318;-2.339398;1.1942427;0.683374;IRRE
dtyped similarly by both parsers due to limitations of the liac arff parser;-0.014000105;-2.1884716;-5.948978;0.3032346;2.9365227;-0.2600392;IRRE
therefore extra dtype conversions are required for those columns;1.8128624;0.28079942;-6.8567533;-4.1965632;-0.17746738;-0.7517719;CODE
compare categorical features by converting categorical liac uses;2.6280727;-0.34642032;-2.5267613;-0.4386589;3.3472679;-2.7234106;IRRE
strings to denote the categories we rename the categories to make;-1.0828371;-3.3424463;1.7407414;-1.2322521;4.2648096;-1.5383157;TASK
them comparable to the pandas parser fixing this behavior in;2.3213348;-1.7814786;-4.882812;-0.28932267;-1.774999;-1.0388219;CODE
liac arff would allow to check the consistency in the future but;-0.8121382;1.1209536;-1.2462959;5.81226;1.7130387;2.0330544;TASK
we do not plan to maintain the liac arff on the long term;-3.741614;1.009477;-1.2243577;3.0643845;-1.2967659;2.6628404;CODE
iris dataset;3.7608812;-4.3275394;0.8641831;-2.9046853;0.92744845;-1.958766;IRRE
anneal dataset;5.8606052;-2.9907134;0.31154352;-2.6185498;4.0014725;-0.60959494;IRRE
cpu dataset;5.5276437;-5.531258;1.4997016;-1.4544288;0.93699247;-1.2211839;IRRE
emotions dataset;2.5932827;-5.194282;2.7695518;-1.6278373;-0.4232938;-1.0241216;IRRE
adult census dataset;2.7498224;-2.3311994;2.6880267;-1.2881815;1.5121539;-0.85289407;IRRE
miceprotein;-3.278268;-1.8639016;3.929377;-0.12534463;-0.49936017;-0.55448353;-
titanic;-1.3705014;-1.7801048;3.8769917;0.922929;-0.8678593;-1.2814496;-
test some more specific behaviour;0.9717059;6.605243;2.1758296;6.8374405;-0.015102441;-7.273022;IRRE
single column test;4.1783414;5.018232;1.0139375;0.7804288;1.1759229;-7.0664344;IRRE
multi column test;4.393502;5.0225787;1.1599962;-0.29597923;2.27697;-6.5099645;IRRE
create a temporary modified arff file;-2.7665374;0.59539086;0.70740277;1.4213979;-1.4370809;2.6021268;IRRE
requests are already mocked by monkey patch webbased functions;-4.921441;-0.89404744;-1.6109313;5.849256;-2.0815032;-1.1548997;CODE
we want to reuse that mock for all requests except file download;-3.6255877;2.3824332;0.100120656;6.5592456;-0.8517253;1.2150637;CODE
hence creating a thin mock over the original mock;-0.226188;3.8119237;-0.3621412;5.0020604;-0.6328575;-0.23913318;-
validate failed checksum;-1.5226958;6.017916;-1.4303132;2.561848;1.7069623;-3.1220315;-
exception message should have file path;-5.6855307;2.1217303;-0.9058792;2.0936198;-1.7587657;0.38898033;CODE
avoid a resourcewarning on python 3 14 and later;-2.637901;-2.160737;-1.0425329;3.8162727;-2.7562025;1.3575426;CODE
non regressiont tests;2.392999;2.8812537;-2.163717;5.86848;-1.813338;-5.172887;IRRE
the dataset has 17 features including 1 ignored animal;2.212996;-1.2762687;-1.2220391;0.58800465;0.6988781;-1.3914598;TASK
so we assert that we don t have the ignored feature in the final bunch;-2.0827804;1.3681788;-0.2025336;6.1314;0.3937673;2.6321106;CODE
similar behaviour should be observed when the column is not the target;4.320058;5.5481505;-0.9755497;1.4810666;-1.281851;0.59586656;-
test sparsity;3.4974778;2.9403865;-1.5378989;1.5744205;-1.7872334;-2.4404397;IRRE
test shapes;3.7701466;1.3486441;3.8785493;0.6616207;-0.47576937;-4.4999294;IRRE
test descr;0.7166809;2.2427728;-0.20948876;1.5831637;1.516817;-7.559095;IRRE
test ordering of categories;1.8101013;2.582085;-0.053733118;3.1380067;2.8046253;-4.187871;IRRE
test number of sample for some categories;3.065732;1.6810423;0.1651884;2.3534768;3.1989577;-5.0239844;IRRE
test shuffling and subset;3.2122033;4.5045967;0.76321346;2.6623964;3.581288;-4.6717305;IRRE
test return x y option;-0.2907888;6.884537;1.1328739;2.0968096;-2.058989;-6.7149377;IRRE
the first 23149 samples are the training samples;3.3231714;-3.2942703;-0.6640795;0.50976396;3.0787606;-4.21013;-
test some precise values;5.1323385;7.1458054;0.25100031;2.0107615;-1.3074982;-8.513599;IRRE
assert sum y 0 10 unexpected number of samples in class 0;3.371312;4.4175525;-4.40885;0.6571384;-1.5092376;-6.292977;CODE
assert sum y 1 25 unexpected number of samples in class 1;3.1670058;4.0053697;-3.4448283;1.6495413;-1.3201069;-6.883058;CODE
assert sum y 2 65 unexpected number of samples in class 2;2.7353127;3.666824;-3.7870133;1.8693448;-1.1763887;-6.222036;CODE
test for n features 30;3.1275408;1.5500715;-1.6621491;0.7804649;1.9128413;-6.894957;TASK
create very separate clusters check that vertices are unique and;3.5271754;1.8192248;-0.12655967;-1.6196173;3.1581776;-0.14285313;IRRE
correspond to classes;1.3501058;-3.2320921;1.7197415;0.08903274;6.979184;-2.5781586;IRRE
cluster by sign viewed as strings to allow uniquing;2.79729;2.7250555;-1.1372818;-2.4916368;4.0951514;0.14720334;CODE
ensure on vertices of hypercube;-0.2515212;2.723775;-1.0219775;-0.97536516;0.8080346;0.51436967;-
also test return distributions and return indicator with true;1.3323001;4.5789104;0.24685535;4.6954594;0.17899357;-4.102719;IRRE
test that y np dot x c bias n 0 1 0;2.8253326;1.1132832;-4.252025;-1.5479097;-4.0211525;-1.61873;IRRE
test with small number of features;5.3062267;2.406708;-0.8470734;3.068749;1.9190283;-5.2086697;TASK
x y make regression n samples 100 n features 1 n informative 3;4.1078615;-2.7015035;0.6594178;-3.2915297;0.7606348;-1.592688;TASK
test that y np dot x c bias n 0 1 0;2.8253326;1.1132832;-4.252025;-1.5479097;-4.0211525;-1.61873;IRRE
do not use scipy sparse linalg eigs because it cannot find all eigenvalues;3.0709577;-1.1862044;-7.1355247;-3.969397;-4.957012;3.0372586;IRRE
check that leading diagonal elements are 1;-1.159975;3.761491;-0.044675626;-4.562412;-0.18346757;-4.41122;-
testing odd and even case because in the past make circles always;-0.044870052;4.52658;1.4524702;1.7951682;-0.634496;-4.934736;CODE
created an even number of samples;3.195012;1.9555044;2.106744;-0.5695532;1.7322509;-4.9264107;IRRE
test x s shape;3.189024;3.2188966;2.480684;-2.6869316;-1.2500726;-3.5298858;IRRE
test x s non zero values;1.9443676;7.792849;-1.7776608;-2.2724786;-1.357552;-6.887733;IRRE
tests x s zero values;1.8078253;7.051476;-2.3348632;-1.9049754;-1.9081339;-6.381553;IRRE
test can change x s values;1.2320687;6.6609063;-1.568854;1.0749804;-1.2079657;-5.493282;IRRE
test y;-0.6176926;2.9145403;3.6294668;2.7659435;-2.123843;-7.7249246;IRRE
test loading from file descriptor;-1.5010157;3.5601103;-1.7391832;4.4209723;-0.42456964;-0.2390549;CODE
gh20081 testing equality between path based and;-0.65648746;3.803601;-4.226838;4.397315;-0.3594633;-0.28190345;IRRE
fd based load svmlight file;-0.4709682;-1.9916916;-2.1107256;-1.0635604;0.13045205;4.292273;CODE
test loading from file descriptor;-1.5010157;3.5601103;-1.7391832;4.4209723;-0.42456964;-0.2390549;CODE
test x shape;3.5933967;3.7708476;2.9536345;-2.640018;-1.200266;-3.9786444;IRRE
test x s non zero values;1.9443676;7.792849;-1.7776608;-2.2724786;-1.357552;-6.887733;IRRE
21 features in file;-0.9786993;-2.317014;0.36507398;-2.036809;4.066947;-2.7773504;TASK
tmp close necessary under windows;-3.5412042;-0.70248824;0.71067005;0.96027535;-2.510846;2.829248;CODE
because we close it manually and write to it;-6.0502787;-2.3899674;3.301637;2.5565832;-2.3027728;0.62234235;CODE
we need to remove it manually;-5.836087;-1.1107934;2.5470178;0.49091142;-2.2868495;1.922418;TASK
tmp close necessary under windows;-3.5412042;-0.70248824;0.71067005;0.96027535;-2.510846;2.829248;CODE
because we close it manually and write to it;-6.0502787;-2.3899674;3.301637;2.5565832;-2.3027728;0.62234235;CODE
we need to remove it manually;-5.836087;-1.1107934;2.5470178;0.49091142;-2.2868495;1.922418;TASK
load svmfile with qid attribute;0.21517465;-1.5795631;-3.5795057;-0.79098773;-0.5733401;4.3022738;META
in python 3 integers are valid file opening arguments taken as unix;-3.5618527;0.8669633;-3.6382723;-4.361789;-2.041487;-4.1370134;CODE
file descriptors;-0.14886665;-3.7030303;0.50230235;-1.403987;3.6416335;0.6244597;CODE
slicing a csr matrix can unsort its indices so test that we sort;3.8290656;1.9846528;-2.934922;-2.5283027;-0.3923947;0.042509466;IRRE
those correctly;-2.3234303;-1.9066992;2.756128;-0.9702749;1.1939473;-1.7210946;-
we need to pass a comment to get the version info in;-5.776777;-1.9283086;1.0969517;1.9293822;-0.4861758;-1.208053;TASK
libsvm doesn t grok comments so they re not put in by;-3.6617053;-2.427088;-2.984546;1.2081492;-1.0286806;1.7026658;CODE
default anymore;-5.997035;-1.2757546;3.2109463;1.0641296;-1.9989996;1.5063022;OUTD
make sure y s shape is n samples n labels;4.3868694;0.64539677;0.13636374;-5.054727;-0.6143853;-1.3530443;-
when it is sparse;2.8934922;-0.97762483;3.0798657;1.453942;-0.94702303;1.9339163;IRRE
note with dtype np int32 we are performing unsafe casts;-2.2151644;0.16388075;-6.7898874;-1.229915;-2.2543938;-0.8895864;CODE
where x astype dtype overflows the result is;-0.44416696;1.2834125;-5.493352;-3.3381035;-2.6638415;-1.2538315;IRRE
then platform dependent and x dense astype dtype may be;-0.79168075;-2.1497962;-5.273349;-1.0556316;1.0404195;1.8977903;CODE
different from x sparse astype dtype asarray;1.0025271;-1.3666759;-5.9510393;-3.7540724;-0.54156435;1.6751813;IRRE
allow a rounding error at the last decimal place;0.56553733;4.8670974;-0.0069889077;-0.44181865;-3.9275165;-1.8444434;CODE
allow a rounding error at the last decimal place;0.56553733;4.8670974;-0.0069889077;-0.44181865;-3.9275165;-1.8444434;CODE
make sure it dumps multilabel correctly;-2.405455;0.09805704;-2.8770773;-0.8405479;0.28322142;-0.4872687;-
loses the last decimal place;-0.833182;3.141193;1.4276934;-2.5982044;-5.0018363;-3.565064;CODE
make sure it s using the most concise format possible;-3.6038148;0.88600284;-2.513961;-1.9118723;-1.1817048;-1.9959;CODE
make sure it s correct too;-3.5589983;1.4086392;0.18823807;-0.32211745;-0.941861;-4.2930145;-
xxx we have to update this to support python 3 x;-6.643273;-3.9408572;-3.418479;-2.924236;-2.707277;-0.8601232;CODE
test dumping a file with query id;-1.1456747;4.999429;-1.9831525;2.8619552;0.7757707;-3.4694629;CODE
load svmfile with longint qid attribute;0.51895607;-0.8784307;-3.3230393;-2.0628567;-0.834784;4.01471;CODE
put some marks that are likely to happen anywhere in a row;1.8163455;0.9889431;5.855304;0.5168736;2.736519;-3.055101;-
load the original sparse matrix into 3 independent csr matrices;3.7759383;-0.0548201;-2.899122;-4.6054854;0.41939598;4.620888;CODE
load the same data in 2 parts with all the possible byte offsets to;2.6982586;3.0758622;1.3956972;-2.7103775;2.283765;1.4414674;IRRE
locate the split so has to test for particular boundary cases;1.6086287;3.8578818;0.7982968;0.22440177;2.266048;-4.0481577;CODE
the first and last element are explicit zeros;-2.1754508;3.5470417;-1.1007767;-5.179307;-0.6143263;-1.8944219;-
y as a dense array would look like;3.2813094;0.8657328;3.293165;-5.9302163;-1.8370605;-1.2515709;-
0 0 1;-1.775403;2.0044188;2.302608;-3.9080539;-0.59256446;-4.375464;-
0 0 1;-1.775403;2.0044188;2.302608;-3.9080539;-0.59256446;-4.375464;-
1 1 0;-1.1952986;2.3423338;3.0766947;-3.2021532;-0.73135173;-4.48801;-
convert to memmap backed which are read only;-0.74082017;0.74617594;-2.1501276;0.031244475;0.40803513;2.2020051;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
enter parallel code block;-2.8019836;1.1837537;1.5633253;-0.76041466;1.5398502;-1.4183129;-
1e 6 is arbitrary but consistent with the spams implementation;-0.920143;0.015300493;-4.495581;1.779356;1.7539153;0.36281088;TASK
kth atom is almost never used sample a new one from the data;0.8757954;-0.24758501;-2.866319;1.3145701;-1.981534;-0.65890825;CODE
add small noise to avoid making the sparse coding ill conditioned;5.5394835;-0.8813818;-2.2028944;0.10984635;1.119036;4.3027196;IRRE
noise level 0 01 newd std or 1 avoid 0 std;0.92541075;2.6173537;-4.4157095;-2.0784116;1.1804861;0.17317058;CODE
projection on the constraint set v k 1;1.5661215;0.3007358;-1.036545;-2.5056539;0.6295127;4.7634125;CODE
feature vector is split into a positive and negative side;1.4902496;-1.0677;-0.6530431;-4.579017;-1.4897137;1.6299256;TASK
compute number of expected features in code;3.0256991;-1.4193563;-0.0588243;0.7772767;2.9841902;-4.4811673;TASK
n components;0.24123365;-1.3953292;2.6840322;-5.3998485;4.5323806;-0.93594706;-
fit algorithm;7.0816135;0.90797967;2.028543;-2.6623905;0.026316497;-0.51498365;-
batch size;2.0691597;-0.008335878;2.0205753;-0.3358195;0.40846446;0.45131153;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
some constant terms;-0.3261317;0.9542263;2.8027866;-1.285734;-0.27786687;-0.70492554;CODE
we ll modify svd outputs to return unexplained variance;4.2880898;-1.0941057;-3.989568;-0.08052737;-0.5140181;0.90289336;CODE
to allow for unified computation of loglikelihood;1.5817192;-2.554516;-1.6285716;0.48446923;2.9869387;1.9083523;CODE
else svd method randomized;5.102807;0.021469394;-2.6037529;0.8928575;2.313192;1.923436;IRRE
small helps numerics;2.8731875;0.098322056;1.8523878;-2.8236384;-1.0506207;-3.2464843;-
use maximum here to avoid sqrt problems;0.041805085;3.1496422;2.318422;-1.8430507;-2.2150412;-1.1054729;CODE
loglikelihood;-1.6086254;-1.6769775;2.5099525;1.2328598;1.4560803;-1.845608;-
cov flat len cov 1 self noise variance modify diag inplace;1.4686898;1.0429087;-5.196073;-2.6736295;-3.6007102;4.131081;CODE
handle corner cases first;-2.62307;2.326535;4.0770683;-1.7762327;1.6669362;1.9139174;CODE
get precision using matrix inversion lemma;3.5731943;2.6122673;-3.2437537;-3.602621;-3.0264833;1.3315176;META
note that tol is not exposed;-6.1999626;0.18233575;-0.21491915;2.2007296;0.02416328;1.2064466;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
avoid sqrt of negative values because of rounding errors note that;1.6011558;4.203574;-1.6427369;-1.727912;-5.7091827;-1.8463112;IRRE
np sqrt tiny is larger than tiny and therefore this clipping also;-1.5073947;0.36175063;-1.8863436;-2.4051852;-5.1635456;1.6546634;CODE
prevents division by zero in the next step;-2.3886364;4.5224104;0.27192616;-2.2003071;-1.9014614;-3.0881827;CODE
u resp s contains the eigenvectors resp square roots of;-1.2173445;-2.0486503;-1.9153489;-3.1229157;-0.65625066;3.0140202;-
the eigenvalues of w w t;-1.1937865;-0.79986775;0.34015495;-1.3931361;-1.7047307;1.6463608;IRRE
j is the index of the extracted component;-0.38803384;0.43196383;1.2904463;-3.124822;2.255401;0.35268834;-
builtin max abs are faster than numpy counter parts;2.8867009;-0.11326089;-2.2273533;-2.9570606;-3.2470856;0.4051999;-
np einsum allows having the lowest memory footprint;0.92660826;-2.1064389;-2.8005402;-2.5920887;0.17993817;0.50809014;IRRE
it is faster than np diag np dot w1 w t;1.1027944;-2.9553213;-2.649432;-1.1594316;-0.4607676;0.48987502;CODE
some standard non linear functions;-0.29585677;-0.17151745;2.2915957;-3.134514;-1.4715903;0.74256253;CODE
xxx these should be optimized as they can be a bottleneck;1.8672147;-0.83426964;1.7499715;-3.2936058;1.6035309;2.470576;-
alpha fun args get alpha 1 0 comment it out;-4.55282;1.4339356;0.5783455;-0.83922195;-2.123502;-3.123891;IRRE
gx np tanh x x apply the tanh inplace;-1.5248903;2.157549;-0.36510947;-4.789516;-2.3811924;1.4206142;-
xxx compute in chunks to avoid extra allocation;2.4057453;2.1028614;-0.18991044;-3.5235715;2.1157956;1.3507398;CODE
for i gx i in enumerate gx please don t vectorize;0.77603817;1.8567555;-0.91564673;-7.35308;-0.5890009;0.9721979;CODE
centering the features of x;1.7324018;-0.35979822;4.3212366;-3.892728;-1.3171178;3.4173772;TASK
whitening and preprocessing by pca;3.1220658;-1.8710873;-1.1252689;-0.17241937;2.0697076;3.8658056;-
faster when num samples n features;6.5910535;-2.393612;-0.6746807;-1.4312106;2.0066934;0.07302262;TASK
d degenerate idx eps for numerical issues;2.716488;2.140907;-4.452951;-4.63001;-0.4536225;3.1666565;CODE
give consistent eigenvectors for both svd solvers;2.1702213;-1.048004;-4.986118;-1.2366202;-0.6062127;5.6117845;CODE
k u d t n components see 6 33 p 140;-2.6948907;-1.2234347;0.28149813;-3.6686938;2.3261116;-1.6820291;-
see 13 6 p 267 here x1 is white and data;-2.0862596;0.18406561;-1.0899897;-5.5018764;0.4355551;-1.743555;-
in x has been projected onto a subspace by pca;1.1394916;0.012952308;-1.5073999;-3.060735;-0.15129137;5.752501;CODE
x must be casted to floats to avoid typing issues with numpy;0.8070407;0.46819136;-2.6332457;-7.1438336;-6.576045;-0.45907238;CODE
2 0 and the line below;-3.472109;2.0900228;4.497506;-5.309629;-1.7965271;-5.0343547;-
x1 as float array xt copy false copy has been taken care of;0.069319785;5.04315;-3.1120298;-3.839075;-4.353018;0.57819825;CODE
either partially fit on smaller batches of data;7.183584;1.1437029;0.30244872;0.029972244;0.22594175;2.4057517;-
or let the fit function itself divide the data into batches;7.470322;1.395581;0.409084;-0.6983011;-0.38095924;2.8072658;CODE
ipca transform x doctest skip;-0.5775759;1.1654016;-4.4895086;1.6284404;-1.9969821;0.7402806;CODE
center kernel in place;0.063201986;-1.7303356;3.13319;-2.3419309;-2.5534427;4.8737097;-
adjust n components according to user inputs;2.2701395;1.7871656;3.7816424;-3.6499782;3.1556497;1.343202;CODE
n components k shape 0 use all dimensions;1.9724948;-0.29114977;-0.26423204;-7.7663875;0.46741807;2.8611777;-
compute eigenvectors;0.5176852;-2.0064228;-0.83134127;-4.828138;-0.7948776;0.21991652;-
note subset by index specifies the indices of smallest largest to return;1.8673527;2.579815;-0.6642154;-3.4833393;1.7443334;-1.3086959;IRRE
make sure that the eigenvalues are ok and fix numerical issues;2.6663897;1.5608735;-4.449425;-2.477212;-5.336605;0.89566505;IRRE
flip eigenvectors sign to enforce deterministic output;0.64326704;0.5519347;-4.2541;-0.6714114;-0.15641952;3.8967779;CODE
sort eigenvectors in descending order;2.0196216;0.18774985;-0.7611395;-3.6138573;0.10716169;3.418407;CODE
remove eigenvectors with a zero eigenvalue null space if required;0.24230118;2.9533427;-4.1552954;-1.9756731;-0.7623926;4.4492636;IRRE
maintenance note on eigenvectors normalization;2.093628;-3.8387125;-3.7511337;-1.9239053;-0.55673146;6.5127664;CODE
there is a link between;-3.851625;-5.2574353;5.700877;0.75328165;1.0679867;-1.1893785;-
the eigenvectors of k phi x phi x and the ones of phi x phi x;-1.4653537;-2.0347762;-2.0286603;-1.6771227;-0.033264603;3.928956;-
if v is an eigenvector of k;-1.00476;-1.2263001;-0.5082438;-1.2423531;-0.6404223;0.9485903;-
then phi x v is an eigenvector of phi x phi x;-2.1352637;-0.54518944;-2.1965115;-0.3924258;0.72612154;3.7615008;-
if u is an eigenvector of phi x phi x;-2.7420776;0.044219237;-1.3045613;-0.9577841;1.4159809;1.8247583;-
then phi x u is an eigenvector of phi x phi x;-2.5416067;-0.40545732;-1.7769514;-0.7210827;1.5878638;2.7916253;-
at this stage our self eigenvectors the v have norm 1 we need to scale;2.06239;-0.6765385;-1.2813573;-2.7209969;-3.0513003;5.7851315;CODE
them so that eigenvectors in kernel feature space the u have norm 1;1.7487669;-3.5746658;-2.2014854;-3.3092356;0.022047047;4.5341115;TASK
instead;-3.4498208;-1.8747259;4.7573843;1.0487124;-1.2410853;-0.27382374;-
we could scale them here;3.0819623;-0.9879082;5.1261454;0.56550026;-0.6594442;1.6002585;CODE
self eigenvectors self eigenvectors np sqrt self eigenvalues;-1.169651;-2.463825;-4.2527394;-3.251237;-2.3716683;2.7994773;CODE
but choose to perform that later when needed in fit and in;-0.250894;1.5616844;2.4432561;4.768165;2.1968684;1.9091038;IRRE
transform;0.119849384;-0.7246064;5.7246265;-4.0461097;-0.9593361;-1.0896541;CODE
when kernel precomputed k is x but it s safe to perform in place operations;0.75444263;-0.4263681;-1.1012418;-0.09135127;0.50146794;2.2377481;META
on k because a copy was made before if requested by copy x;-3.6868713;0.45696798;-0.8927389;0.120960966;1.1491666;0.108619735;CODE
no need to use the kernel to transform x use shortcut expression;-2.8447118;-1.0008266;-1.1595392;-2.8908577;-0.8895241;3.1324415;TASK
no need to use the kernel to transform x use shortcut expression;-2.8447118;-1.0008266;-1.1595392;-2.8908577;-0.8895241;3.1324415;TASK
compute centered gram matrix between x and training data x fit;5.7213173;-1.2603203;-1.8253177;-4.297468;-2.0247202;3.0463142;-
scale eigenvectors properly account for null space for dot product;1.6670886;-0.23755555;-4.7660666;-3.3408632;-3.1685145;7.2053146;CODE
project with a scalar product between k and the scaled eigenvectors;2.8088553;-3.7908037;-1.9386622;-3.1774187;-2.0803895;6.282817;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
in the literature this is exp e log theta;-1.9184191;-1.0234966;2.7042158;-0.57592165;-0.07984865;-2.3216562;CODE
diff on component only calculate it when cal diff is true;0.46446413;4.415562;-0.24016738;-0.50972337;-2.5058;-0.014377043;-
these cython functions are called in a nested loop on usually very small arrays;0.5352684;1.1261357;1.22795;-4.726134;-2.4761112;-2.8041744;IRRE
length n topics in that case finding the appropriate signature of the;1.207658;-0.6465624;1.251679;-0.655488;6.3388724;-2.3285618;CODE
fused typed function can be more costly than its execution hence the dispatch;-2.6413472;0.57509226;-2.3963373;2.5666285;1.9140635;1.5194036;CODE
is done outside of the loop;-1.1922213;2.635411;5.5436783;1.6290342;0.029820535;-1.4418136;IRRE
the next one is a copy since the inner loop overwrites it;-2.3113782;2.2672853;1.4241035;-1.0908726;-0.6394625;-2.6496637;TASK
iterate between doc topic d and norm phi until convergence;1.2159243;-1.3900363;-1.3991858;1.3883568;0.3747197;2.5031762;CODE
the optimal phi dwk is proportional to;2.1019976;-1.1724801;-0.57921433;0.7509597;0.08714781;1.6272002;-
exp e log theta dk exp e log beta dw;-2.1640897;-1.2924117;-0.86972135;-1.526815;0.28998405;-2.9275765;-
note adds doc topic prior to doc topic d in place;-4.403425;-1.7250032;0.7796186;1.5610735;0.5830534;2.4218822;TASK
contribution of document d to the expected sufficient;-1.175775;-0.09083446;-0.3850698;0.8551501;3.598469;0.9116107;META
statistics for the m step;2.872526;0.25132582;3.1251624;2.01261;-0.36753502;-0.96115196;CODE
numerator;-2.4541533;0.9068769;3.8487408;-2.9318218;-0.41309983;-4.975707;-
avoid a copy of xht which will be re computed update h true;-2.6878474;3.3452618;-0.86054194;2.4438913;-1.1087849;2.0533118;CODE
preserve the xht which is not re computed update h false;-2.5672553;3.965681;0.12799552;1.7290606;-1.4351165;2.55062;CODE
denominator;-2.487176;0.56637615;4.150676;-1.8238399;-1.3004361;-3.438902;-
numerator;-2.4541533;0.9068769;3.8487408;-2.9318218;-0.41309983;-4.975707;-
if x is sparse compute wh only where x is non zero;3.4998658;3.2142584;-3.2921972;-3.5070536;-0.33385283;1.2168986;IRRE
copy used in the denominator;-3.0994422;0.613941;1.0512758;-2.067312;-1.653436;-1.1590432;CODE
to avoid taking a negative power of zero;-2.439231;3.7023144;0.7278436;-1.2247511;-2.3445363;-1.2572542;CODE
speeds up computation time;1.7794703;-2.6789782;1.0381379;-0.5511486;-1.6864636;-0.10716109;-
refer to numpy numpy issues 9363;1.882671;-1.1376226;-4.8673587;-6.939302;-6.957596;-1.6757971;-
element wise multiplication;1.2113323;0.54274094;2.3873065;-4.8300924;1.0091531;-2.459034;-
element wise multiplication;1.2113323;0.54274094;2.3873065;-4.8300924;1.0091531;-2.459034;-
here numerator dot x dot w h beta loss 2 h t;0.22917943;-0.27228665;0.104233794;-3.4337432;-2.1298132;-0.84643996;CODE
denominator;-2.487176;0.56637615;4.150676;-1.8238399;-1.3004361;-3.438902;-
h sum np sum h axis 1 shape n components;2.8006828;-0.71474475;1.4867476;-9.455232;-1.436649;0.7318421;-
computation of whht dot dot w h beta loss 1 h t;1.8558571;-1.3366582;-3.4939797;-2.1084175;-1.556948;1.1299052;CODE
memory efficient computation;2.426254;-2.1978757;2.9655805;-0.6648286;1.6558751;-0.3746935;-
compute row by row avoiding the dense matrix wh;4.2296762;2.97814;-1.5611633;-4.7699122;-1.0431441;0.7579371;CODE
add l1 and l2 regularization;2.7926133;0.87221867;-0.821064;-2.0291924;1.6291531;4.6012187;TASK
gamma is in 0 1;-2.5930772;1.8219516;0.97733426;-2.8112507;-1.8951356;-1.7656183;-
n components;0.24123365;-1.3953292;2.6840322;-5.3998485;4.5323806;-0.93594706;-
beta loss;-0.16032368;-0.6449066;0.76650566;1.881379;-1.8943299;-0.9704067;-
param validation is done in fit transform;2.2266793;3.625953;-2.131067;1.0050619;-1.5852207;2.5697443;CODE
get scaled regularization terms done for each minibatch to take into account;4.6315165;-0.43085864;-1.1638168;0.04358041;-0.14668374;6.3474445;CODE
variable sizes of minibatches;2.2793534;-0.12433093;0.98766595;-1.4895098;0.06953723;2.2778034;IRRE
update w;-5.08947;-1.2387377;2.4316401;0.13600011;-0.02741265;-1.6497058;CODE
necessary for stability with beta loss 1;-0.2035763;-0.73308116;-1.4922286;1.8802947;-1.0264846;2.9303007;CODE
update h only at fit or fit transform;0.79423994;1.3761612;-0.3286118;-2.0640926;-1.306493;2.8986974;CODE
necessary for stability with beta loss 1;-0.2035763;-0.73308116;-1.4922286;1.8802947;-1.0264846;2.9303007;CODE
raise an error for sparse input and unsupported svd solver;4.3169003;-0.44620228;-7.047845;-0.47326723;-1.8682396;3.3973248;CODE
validate the data without ever forcing a copy as any solver that;2.8054283;4.1704965;-3.7456236;2.8200536;0.6682262;-1.4611701;CODE
supports sparse input data and the covariance eigh solver are;6.9316864;-3.8849666;-2.8499815;-0.95114225;0.25271934;4.1921287;CODE
written in a way to avoid the need for any inplace modification of;-4.164521;1.4985107;1.0757145;1.148219;4.2035956;2.1298566;CODE
the input data contrary to the other solvers;4.3643274;0.7117813;-0.7854608;-1.8555628;-1.6399314;-2.0903594;CODE
the copy will happen;-4.253341;-1.6217626;2.952604;2.9266975;0.14477986;-0.72744584;-
later only if needed once the solver negotiation below is done;-3.3377235;1.1053586;1.512146;2.0617723;1.1448895;2.3418438;CODE
tall and skinny problems are best handled by precomputing the;2.3042965;-2.762365;1.9068041;0.7360187;-0.5661923;0.066927746;-
covariance matrix;1.3398074;-0.9966985;0.8697111;-3.807948;-2.3954928;1.6127397;CODE
small problem or n components mle just call full pca;2.7401288;-0.06972315;-3.5378833;-0.28124762;2.6246192;4.149926;IRRE
this is also the case of n components in 0 1;-0.32936984;0.9294266;-0.21430153;-5.6207857;2.6542096;-0.1043729;CODE
call different fits for either full or truncated svd;2.56577;1.4068358;-2.5162776;-2.040713;1.8720481;4.2007623;CODE
most values in the components are zero sparsity;3.4316394;2.109306;-2.9388437;-4.4271846;-1.5969793;3.1760035;IRRE
flip eigenvectors sign to enforce deterministic output;0.64326704;0.5519347;-4.2541;-0.6714114;-0.15641952;3.8967779;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.944593;-3.3966897;-3.4007463;-0.13234925;-4.2971573;-1.9892544;CODE
ubsampling 3 subsampling factor;2.8289735;1.5914285;-1.4069155;-3.233687;0.5302134;1.4919189;-
compute a wavelet dictionary;3.4286284;-1.68976;-0.027231282;-4.3347907;-0.9031088;1.2365087;CODE
check that the underlying model fails to converge;2.296259;4.820186;-2.0518444;6.597133;-2.8522666;-0.9789914;-
check that the underlying model converges w o warnings;1.6560134;3.1127856;-3.9337726;6.179261;-2.1326406;-0.6962092;-
test error raised for wrong code size;0.5596353;5.3560324;-5.5931935;2.449822;-3.1476955;-4.4248543;CODE
used to test lars here too but there s no guarantee the number of;0.6753815;-0.8496199;-1.7715515;2.0916152;-1.1679809;-2.7414021;IRRE
nonzero atoms is right;-1.6755853;2.0938745;1.5580806;-1.7090985;0.5825045;-2.8362598;-
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.944593;-3.3966897;-3.4007463;-0.13234925;-4.2971573;-1.9892544;CODE
regression test that parallel reconstruction works with n jobs 1;4.235983;1.9019737;-1.7387245;3.6507745;-2.036689;-0.34165204;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.944593;-3.3966897;-3.4007463;-0.13234925;-4.2971573;-1.9892544;CODE
test verbosity for better coverage;2.043778;2.011967;-1.4777852;7.182021;2.2116868;-4.830135;IRRE
convergence monitoring verbosity;1.9858196;-1.8432695;-0.29534528;7.3393064;0.24194552;-0.5583139;-
higher verbosity level;-0.9327519;-2.8283746;0.6658918;2.787094;2.2560072;-1.9247859;-
function api verbosity;-3.1231737;-1.6307995;-0.75189644;3.71244;1.2523968;-1.8246824;CODE
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
partial fit should ignore max iter 17433;1.6141679;4.144294;-3.6807292;-1.0970043;-1.0108399;2.8919213;-
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
v rng randn n components n features random init;2.288187;-2.074562;-2.4796166;-1.0261146;2.788317;0.9131856;IRRE
v rng normal size n components n features random init;2.8660848;-0.89480835;-2.5937212;-2.2640162;1.2728066;1.8299942;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.944593;-3.3966897;-3.4007463;-0.13234925;-4.2971573;-1.9892544;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 5956;-3.3558016;-9.782207;-6.078247;-0.08294195;-5.3149376;-5.1856084;CODE
test that sparsecoder does not error by passing reading only;3.2351992;3.0778522;-5.861495;3.297088;-1.0320066;-1.2452761;IRRE
arrays to child processes;0.64876926;1.3177983;2.5278301;-0.040763613;1.21683;0.3793255;-
ensure that data is 2m joblib memory maps arrays;1.7625104;0.7963521;-3.0912395;-1.6545435;-1.6121752;0.99370974;-
if they are larger than 1mb the 4 accounts for float32;0.12084274;0.24058948;-1.0612975;-4.5193553;2.2936306;-0.18693458;CODE
data type;2.7149274;-1.2770822;1.5360144;-2.6744668;4.4573135;-3.107877;-
check the dict update in batch mode vs online mode;-1.917012;0.5749358;-1.4751359;2.978064;-0.81830686;-0.17368703;CODE
non regression test for 4866;0.2987172;3.8285646;-3.2820456;3.0739617;-2.0539362;-5.4812036;IRRE
full batch update;-1.3057531;-0.48550835;2.2184932;1.6601251;0.24512343;0.23670946;CODE
online update;-3.3535473;-3.1075885;3.048568;1.2956493;0.015912063;-0.2446687;CODE
note do not check integer input because lasso lars and lars fail with;3.1746542;1.0579587;-4.88502;-2.604843;-2.633416;-0.77885765;CODE
valueerror in lars path solver;-0.17105842;-0.49355033;-5.751684;-1.1333643;-5.187045;1.0535152;IRRE
verify numerical consistency among np float32 and np float64;2.0929685;2.7404416;-6.330892;-2.5587137;-3.6086843;-1.5528214;CODE
note do not check integer input because lasso lars and lars fail with;3.1746542;1.0579587;-4.88502;-2.604843;-2.633416;-0.77885765;CODE
valueerror in lars path solver;-0.17105842;-0.49355033;-5.751684;-1.1333643;-5.187045;1.0535152;IRRE
verify preserving dtype for transform in sparse coder;1.7662218;0.041866403;-7.4543133;-2.2274919;-0.083847724;1.7937638;CODE
verify preserving dtype for fit and transform in dictionary learning class;3.7738564;-1.2617747;-5.9996133;0.18458846;-0.2661927;1.0454336;CODE
verify preserving dtype for fit and transform in minibatch dictionary learning;4.5764894;-2.5542693;-5.2590933;1.16937;-0.38745654;2.251543;CODE
verify output matrix dtype;3.1928108;1.5827572;-5.6710334;-4.4639525;-2.1224058;-2.62021;IRRE
verify numerically consistent among np float32 and np float64;2.152084;3.0090725;-6.517001;-2.7323334;-4.2416406;-1.9022623;CODE
optimal solution u v is not unique;1.2952734;2.014594;-1.088944;-1.8462105;-0.32630774;2.8348327;-
if u v is optimal solution u v is also optimal;0.18729919;-0.1373786;1.2280253;0.27778828;0.9615456;2.9770126;-
and column permutated u row permutated v are also optional;-0.053584162;2.0170462;-1.927106;-3.693647;3.1109364;0.41551483;CODE
as long as holding uv;-2.8123014;0.29150438;3.101444;1.5550824;0.47796777;0.5201311;-
so here uv u 1 1 and sum v k 2 2 are verified;-0.6265249;0.34409726;-0.36390358;-3.8524985;1.7173274;-5.48966;-
instead of comparing directly u and v;0.3636544;2.928669;-0.37920645;-0.57048124;-0.5527721;-3.5385644;CODE
verify an obtained solution is not degenerate;-0.5445865;4.6954417;-4.028877;-0.41419867;-0.5235606;-0.68742335;-
verify output matrix dtype;3.1928108;1.5827572;-5.6710334;-4.4639525;-2.1224058;-2.62021;IRRE
verify numerically consistent among np float32 and np float64;2.152084;3.0090725;-6.517001;-2.7323334;-4.2416406;-1.9022623;CODE
optimal solution u v is not unique;1.2952738;2.0145938;-1.0889431;-1.8462096;-0.32630727;2.8348334;-
if u v is optimal solution u v is also optimal;0.18729919;-0.1373786;1.2280253;0.27778828;0.9615456;2.9770126;-
and column permutated u row permutated v are also optional;-0.053584162;2.0170462;-1.927106;-3.693647;3.1109364;0.41551483;CODE
as long as holding uv;-2.8123014;0.29150438;3.101444;1.5550824;0.47796777;0.5201311;-
so here uv u 1 1 and sum v k 2 are verified;-0.39730242;0.33220732;-0.56934625;-3.8636017;1.42096;-5.30381;-
instead of comparing directly u and v;0.3636544;2.928669;-0.37920645;-0.57048124;-0.5527721;-3.5385644;CODE
verify an obtained solution is not degenerate;-0.5445865;4.6954417;-4.028877;-0.41419867;-0.5235606;-0.68742335;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
test factoranalysis ability to recover the data covariance structure;4.691776;-0.6004648;-2.0393596;1.389965;-1.0532892;0.63391674;CODE
some random settings for the generative model;2.3479078;-2.4045172;1.2982016;3.1154554;2.6163342;3.0264459;IRRE
latent variable of dim 3 20 of it;-1.0664854;2.0891924;-0.49770337;-3.957272;-0.48554713;-0.8642503;IRRE
using gamma to model different noise variance;2.12541;-0.8775194;0.2021659;1.5106853;-0.47952437;3.852891;CODE
per component;-0.023050727;-0.7583154;5.011281;-2.4842668;5.1280856;1.0577241;-
generate observations;5.7906485;-0.31182972;3.5562012;0.7081018;0.57000864;-1.1536002;-
wlog mean is 0;-0.9863248;3.828254;-0.23925501;-1.0411029;-5.1082735;-2.795683;-
sample covariance;1.0774662;0.24033542;1.3236791;-0.40482298;-1.282176;0.28680986;CODE
model covariance;0.75660986;-0.9396388;1.3559862;1.2772255;-1.2285728;2.217474;CODE
return np abs getattr x y sign will not be equal;0.5884621;4.8732214;-4.1625495;-3.8085709;-4.175028;-2.4957008;IRRE
test get covariance and get precision with n components n features;4.7463627;1.2457044;-3.9987786;-0.29421273;-0.26714787;-1.4416837;TASK
with n components n features and with n components 0;1.3237122;-1.3095988;-1.0974269;-4.1885085;4.8086176;1.5113117;TASK
test rotation;1.8658519;4.5398183;1.1712185;1.7091229;-1.7200719;-4.7345095;IRRE
test against r s psych principal with rotate varimax;1.2122108;1.5374938;-2.694748;0.30901337;-1.7637123;-0.2956447;IRRE
i e the values below stem from rotating the components in r;2.2000256;0.3005906;3.0669837;-7.346085;-2.3306656;-1.4558259;IRRE
r s factor analysis returns quite different values therefore we only;3.1498892;3.539312;-2.0564697;-1.9056721;-4.3736577;-0.4738914;IRRE
test the rotation itself;0.72651535;3.7259548;1.9800359;1.8724662;-2.1002953;-3.8149543;IRRE
test gram schmidt orthonormalization;2.5184784;1.4191539;-2.3354247;-0.23365408;-2.3039114;-0.19574656;IRRE
generate a random orthogonal matrix;2.7718582;-0.7479599;0.68604976;-4.0739694;0.4658356;3.1884103;IRRE
https github com scikit learn scikit learn issues 24131 issuecomment 1208091119;-2.9399097;-8.575569;-7.387677;-0.04622249;-5.5135803;-4.267626;CODE
test the fastica algorithm on very simple data;6.536557;0.3805208;-1.7367319;0.21801926;0.7568218;-3.274098;IRRE
generate two sources;-0.41110227;-1.0465326;1.1002985;-1.0610528;2.7648299;0.17065133;-
mixing angle;-0.85677147;1.6941488;3.3935745;-2.6339922;-0.5543242;0.94271964;-
function as fun arg;-2.1356926;1.7005935;3.5742047;0.96494424;-0.15543455;-1.4572631;CODE
check that the mixing model described in the docstring holds;-1.7483392;2.1142979;-5.4264174;2.0160964;-0.51027656;2.0594893;CODE
xxx exact reconstruction to standard relative tolerance is not;1.292088;3.1337266;-4.0596666;-1.6378177;-1.4782987;4.387704;CODE
possible this is probably expected when add noise is true but we;-0.82134145;1.8501922;-2.2139056;3.3250213;-2.4506645;1.8932549;CODE
also need a non trivial atol in float32 when add noise is false;-1.0889871;2.024353;-4.803001;-2.3636777;-2.6124003;0.75598824;TASK
note that the 2 sources are non gaussian in this test;3.1608508;2.321176;-4.392185;0.60467565;-2.4723952;-2.456069;CODE
check to see if the sources have been estimated;0.7392616;-2.1223516;-0.45406508;3.7445676;-3.6423714;-0.9065411;-
in the wrong order;-3.1409698;0.6618765;4.4532514;-0.37702608;1.3311756;-2.4842699;META
check that we have estimated the original sources;0.7275793;-1.6885312;-0.3045035;2.6259842;-3.1223614;-1.1279336;-
test fastica class;1.1640406;2.1735756;-2.5490353;3.1259215;1.6223309;-4.96753;IRRE
set atol to account for the different magnitudes of the elements in sources;3.312124;1.5080845;0.26669568;-3.0048819;0.44014853;0.9034555;IRRE
from 1e 4 to 1e1;-0.6041208;0.07855462;2.0860786;-2.2979982;2.0140073;-1.0367998;CODE
test for issue 697;-1.9204463;4.1590505;-2.6882153;2.6723375;-0.6577529;-7.7344728;IRRE
test the fastica algorithm on very simple data;6.536557;0.3805208;-1.7367319;0.21801926;0.7568218;-3.274098;IRRE
see test non square fastica;2.5721228;2.182968;-2.1068563;0.1864367;-1.426166;-4.132443;IRRE
ensure a convergencewarning raised if the tolerance is sufficiently low;2.3739674;2.4086373;-2.5372226;5.57969;-2.6554282;4.1725574;CODE
generate two sources;-0.41110227;-1.0465326;1.1002985;-1.0610528;2.7648299;0.17065133;-
mixing matrix;3.958185;1.4130405;0.7902764;-5.109324;-0.051252928;2.2040353;-
do fastica with tolerance 0 to ensure failing convergence;1.509851;1.6260219;-3.6961546;2.938623;-2.2738264;1.7882265;CODE
test the fastica algorithm on very simple data;6.536557;0.3805208;-1.7367319;0.21801926;0.7568218;-3.274098;IRRE
generate two sources;-0.41110227;-1.0465326;1.1002985;-1.0610528;2.7648299;0.17065133;-
mixing matrix;3.958185;1.4130405;0.7902764;-5.109324;-0.051252928;2.2040353;-
check that the mixing model described in the docstring holds;-1.7483392;2.1142979;-5.4264174;2.0160964;-0.51027656;2.0594893;CODE
check to see if the sources have been estimated;0.7392616;-2.1223516;-0.45406508;3.7445676;-3.6423714;-0.9065411;-
in the wrong order;-3.1409698;0.6618765;4.4532514;-0.37702608;1.3311756;-2.4842699;META
check that we have estimated the original sources;0.7275799;-1.6885316;-0.30450535;2.6259847;-3.1223607;-1.1279334;-
multivariate uniform data in 0 1;4.754283;1.7092022;-0.24323255;-5.7090282;-1.0508461;0.5861532;CODE
make sure that numerical errors do not cause sqrt of negative;0.74796;4.516685;-3.5654948;-0.51882046;-5.164626;-2.4213538;CODE
values;2.3852327;2.8150017;4.596041;-3.805712;2.3660839;-6.126723;IRRE
xxx for some seeds the model does not converge;1.3798251;2.7492764;-1.902954;0.41690862;-3.4996173;-0.52837634;CODE
however this is not what we test here;-0.45877695;2.691006;1.0480392;3.3740337;-0.73422366;-5.3994393;IRRE
make sure that numerical errors do not cause sqrt of negative;0.74796;4.516685;-3.5654948;-0.51882046;-5.164626;-2.4213538;CODE
values;2.3852327;2.8150017;4.596041;-3.805712;2.3660839;-6.126723;IRRE
xxx we have to set atol for this test to pass for all seeds when;-1.8679397;2.8007846;-1.48109;2.6703753;0.40296724;-3.5309749;CODE
fitting with float32 data is this revealing a bug;2.4142268;1.5262825;-5.464867;-3.1438854;-4.0403557;2.235234;CODE
atol 0 0 the default rtol is enough for float64 data;-2.123703;2.5272596;-4.8460016;-4.7629733;-3.5699198;0.44470742;CODE
test fastica inverse transform;2.047929;3.3493054;-2.4671233;-0.6282128;-3.1431267;-1.0814507;IRRE
for some dataset depending on the value of global dtype the model;5.044384;-1.0816777;-2.1177485;0.43948978;1.0037241;1.0607353;IRRE
can fail to converge but this should not impact the definition of;-0.6277634;2.8938463;-0.7780752;5.253006;-0.09507283;1.1340207;IRRE
a valid inverse transform;0.25204948;1.6891844;0.8699415;-2.997109;-1.8826017;1.2269245;IRRE
reversibility test in non reduction case;-0.37852418;6.86582;-3.2526677;3.537198;0.11762787;-2.6874094;IRRE
xxx we have to set atol for this test to pass for all seeds when;-1.8679382;2.800786;-1.4810894;2.670377;0.40296766;-3.5309749;CODE
fitting with float32 data is this revealing a bug;2.4142268;1.5262825;-5.464867;-3.1438854;-4.0403557;2.235234;CODE
xxx dividing by a smaller number makes;-0.56721747;3.0625083;2.3726022;-4.669085;0.6344651;-3.603776;-
tests fail for some seeds;0.22331452;4.061136;-3.247534;4.887386;-3.22035;-5.5549526;IRRE
atol 0 0 the default rtol is enough for float64 data;-2.123703;2.5272596;-4.8460016;-4.7629733;-3.5699198;0.44470742;CODE
the fastica solver may not converge for some data with specific;3.8376586;1.2150089;-6.175514;-0.36507487;-4.001792;0.86964935;CODE
random seeds but this happens after the whiten step so this is;-2.0878828;1.091167;1.0662705;-0.052200135;-1.3210409;-1.3818544;CODE
not want we want to test here;-1.2216928;2.5956473;2.0264711;4.063776;-2.1203878;-6.111973;IRRE
histogram kernel implemented as a callable;1.3492031;-4.1009855;0.2500639;-1.7269384;0.16601714;2.5857587;TASK
assert kwargs no kernel params that we didn t ask for;0.15561534;2.5011473;-5.1844344;4.6718554;-1.1174297;0.61341906;CODE
histogram kernel produces singular matrix inside linalg solve;2.9999866;0.06484818;-5.5681567;-4.8368707;-5.148675;3.1143503;-
xxx use a least squares approximation;5.0877976;0.8345931;-0.14067534;-2.8961298;-3.0605233;3.4270997;-
transform fit data;6.9288898;0.44044852;1.5020206;-4.627656;-2.125056;2.615012;CODE
non regression test previously gamma would be 0 by default;-1.7945006;4.391896;-3.6070306;2.4744973;-5.438163;0.15848793;IRRE
forcing all eigenvalues to 0 under the poly kernel;1.0395427;2.0948381;-4.6743937;-1.1005701;-1.1470528;6.2100596;IRRE
transform new data;4.0455885;0.07485334;3.4459226;-3.4980206;1.5404117;0.67738014;CODE
inverse transform;-0.7656195;0.53304803;4.459853;-4.4682918;-3.12857;-0.3419941;IRRE
x fit needs to retain the old unmodified copy of x;-0.45577514;1.2483075;-1.9846952;-0.8054182;-0.8421224;4.5397162;TASK
transform fit data;6.9288898;0.44044852;1.5020206;-4.627656;-2.125056;2.615012;CODE
transform new data;4.0455885;0.07485334;3.4459226;-3.4980206;1.5404117;0.67738014;CODE
inverse transform not available for sparse matrices;2.6937082;-0.62717086;-3.0756083;-4.7069917;-3.730797;5.702417;IRRE
xxx should we raise another exception type here for instance;-4.06228;5.035401;-2.631347;3.4972372;2.5165606;-0.22819032;CODE
notimplementederror;-3.610181;0.9498064;2.4345467;2.9016747;0.97210264;-0.9755129;TASK
for a linear kernel kernel pca should find the same projection as pca;1.9413389;-1.7727478;-1.6931903;-2.5892007;-1.8316664;4.612427;CODE
modulo the sign direction;-4.355676;1.3208792;3.511446;-3.82655;0.3467795;-1.3182358;-
fit only the first four components fifth is near zero eigenvalue so;3.682227;3.0567567;-3.0452745;-4.3150826;-1.2957586;3.3708944;IRRE
can be trimmed due to roundoff error;-0.32308808;3.6693513;-2.0096385;-0.11184156;-1.7574499;0.635984;CODE
n components none default remove zero eig is true;-2.0069275;4.851441;-3.7956464;-3.5200493;-1.0858026;0.9936905;CODE
assert that even with all np warnings on there is no div by zero warning;-1.3316981;5.461446;-4.4975686;1.6109278;-2.4417756;-1.3310566;CODE
there might be warnings about the kernel being badly conditioned;0.5128914;-0.4092727;-3.1780684;5.215142;-2.206136;1.2071767;-
but there should not be warnings about division by zero;-1.3226323;3.8023274;-2.6719627;-0.0685052;-0.3790851;-3.1229792;META
numpy division by zero warning can have many message variants but;1.1105616;1.9055839;-5.203991;-3.8530195;-3.9695504;-2.210155;META
at least we know that it is a runtimewarning so let s check only this;-1.6476922;-0.8652194;-2.2909188;5.457501;-2.3160083;0.19906406;CODE
fit then transform;3.07218;1.6669062;3.4895754;-2.9560468;-1.2777214;1.9730312;CODE
do both at once;-3.1979887;0.121290006;4.832735;1.0671403;0.5587509;-0.41616195;CODE
compare;-0.48553318;2.0645502;4.928796;2.6526678;-0.5637102;-4.75837;IRRE
non regression test for issue 12140 pr 12145;-1.3885046;4.6146417;-5.3661046;2.340757;-2.496351;-5.26008;IRRE
generate random data;4.188049;-0.66981894;3.3131325;-0.03655153;2.2443533;-2.3176146;IRRE
reference full;-2.4827085;-1.7131219;2.8474152;1.9435076;0.15454164;-2.5481148;CODE
arpack;-2.1664052;-3.2019367;1.797028;-0.6745507;-0.8189395;-1.5579554;-
check that the result is still correct despite the approx;2.648411;5.515821;-0.98109174;1.4446987;-4.390354;-2.924831;TASK
randomized;4.2589526;-2.7529867;4.334999;1.6568846;3.380293;-1.7553806;IRRE
check that the result is still correct despite the approximation;3.203267;5.9423213;-1.1981426;1.9859394;-5.206712;-1.7011513;TASK
compare the shapes corresponds to the number of non zero eigenvalues;4.0499735;1.8931134;-0.041565813;-5.678378;-0.8620538;0.983426;IRRE
non regression test for 26280;0.8326212;3.5709417;-3.7044663;3.346456;-2.9343421;-5.764562;IRRE
from sklearn decomposition import nmf as nmf for testing internals;3.0101488;-2.674146;-6.908616;1.5612315;-2.4057155;-0.8018898;CODE
test that initialization does not return negative values;-0.7611472;8.055846;-3.0319538;3.011454;-3.0464494;-4.5932856;IRRE
here we only check for invalid parameter values that are not already;-1.255369;7.1919627;-3.52639;2.6219878;0.11571709;-1.8965143;IRRE
automatically tested in the common tests;1.8689402;0.3852712;-0.8101794;7.977787;0.81651366;-4.0789514;IRRE
test nndsvd error;-1.7385707;2.5345023;-5.3976984;-1.5872773;-3.8056457;-4.2701235;IRRE
test that initialize nmf error is less than the standard deviation of;2.8016207;4.5090322;-5.253427;2.506549;-3.1229117;-2.5874493;IRRE
the entries in the matrix;2.5687578;0.4368792;3.3506973;-6.2780147;-0.29712623;-2.4180431;CODE
test nndsvd variants correctness;1.4675095;1.8430127;-5.1126556;0.45082355;1.0578909;-2.3047168;IRRE
test that the variants nndsvda and nndsvdar differ from basic;0.6069709;-0.3481477;-3.8322332;-2.301318;-0.24750459;-1.160929;CODE
nndsvd only where the basic version has zeros;-3.5351722;-1.053359;-3.0531597;-4.0213084;-1.9008038;-0.30907315;META
ignore userwarning raised when both solver mu and init nndsvd;-1.5295501;2.3324137;-4.5786576;1.7893077;-3.6803093;3.6300845;IRRE
test that the decomposition does not contain negative values;2.5786414;6.704353;-3.35215;0.09548572;-1.125515;-3.6808853;IRRE
test that the fit is not too far away;2.6466792;3.7922995;0.12923534;3.1894555;-2.8565848;-2.3682551;IRRE
test that the fit is not too far away from an exact solution;3.4590287;5.348416;-1.9145085;2.5559611;-3.386081;-1.7660127;IRRE
by construction;-2.8183734;-2.8505905;5.3112683;1.1885477;1.1020125;-1.7982292;CODE
test that fit transform is equivalent to fit transform for nmf;4.0845733;2.6702297;-2.7810156;1.2936109;-2.6735303;1.3297193;CODE
test that nmf transform returns close values;3.6906903;4.4759755;-2.9562886;1.3993951;-3.8396785;-1.7007838;IRRE
test that fit transform is equivalent to fit transform for minibatchnmf;3.6657665;2.2295184;-3.1907578;1.9998673;-1.9035206;2.3885264;CODE
only guaranteed with fresh restarts;-2.679471;0.78111655;2.3820102;5.032327;-0.3463035;0.19868393;-
smoke test that checks if nmf transform works with custom initialization;0.97799283;4.168273;-4.021852;3.7131252;-0.9927796;2.2981458;IRRE
test that nmf inverse transform returns close values;3.3819206;4.3756986;-2.3944;0.96095484;-4.2657127;-0.63746756;IRRE
test that minibatchnmf transform followed by minibatchnmf inverse transform;1.8766611;1.7528241;-2.5360157;0.6963064;-2.011526;2.0356765;IRRE
is close to the identity;-2.3565958;-0.3100836;2.1341102;-0.34521148;2.0738075;-2.4424155;IRRE
smoke test for the case of more components than features;2.8859546;0.891987;-0.86353475;4.203476;3.367953;-0.527995;CODE
test that sparse matrices are accepted as input;6.030915;2.3661;-4.254861;0.5888434;-0.6528067;-0.35653058;IRRE
test that transform works on sparse data issue 2124;5.3803306;3.7888076;-5.8799343;-0.2105617;-3.037873;-0.5690733;IRRE
test that the function is called in the same way either directly;-1.5822549;6.3001328;-0.17221898;4.547023;-1.1477964;-4.2522197;IRRE
or through the nmf class;0.996509;-4.3023667;-0.8322203;1.8305439;2.8599172;0.0070595145;IRRE
note that the validity of parameter types and range of possible values;2.6906989;3.6403039;-2.5562022;-0.120696254;3.2622306;-1.6432359;IRRE
for scalar numerical or str parameters is already checked in the common;0.7682102;3.3900902;-6.7084236;-0.061489943;-0.62329024;0.49216828;CODE
tests here we only check for problems that cannot be captured by simple;0.5441953;2.898199;-1.0634615;6.092689;-1.1646516;-6.498604;IRRE
declarative constraints on the valid parameter values;2.5949454;3.4624827;-2.759619;-0.52993625;4.060786;1.5154041;IRRE
test parameters checking in public function;-1.2206898;6.9111376;-2.0694778;5.147096;0.046423588;-4.105487;IRRE
compare beta divergence with the reference beta divergence dense;0.75839436;0.26393017;-3.164794;1.0754398;0.1002209;1.164293;IRRE
initialization;-4.863746;1.2167654;2.7104175;0.31914788;2.0933006;-1.2629358;IRRE
test the function that computes np dot w h only where x is non zero;1.2352326;3.8482845;-4.3243737;-2.5046587;-3.13895;-2.338209;CODE
test that both results have same values in x csr nonzero elements;3.7600043;7.3228526;-1.6789848;-0.6601116;1.1532087;-4.8963704;IRRE
test that wh safe and x csr have the same sparse structure;2.6874163;2.060315;-5.0381274;0.28445932;0.40222836;0.35234785;IRRE
compare sparse and dense input in multiplicative update nmf;6.4947524;0.530088;-2.7545958;-0.15958646;0.2622126;1.3594278;IRRE
also test continuity of the results with respect to beta loss parameter;1.8743837;2.483247;-2.4635768;4.29806;-2.4849517;0.39124817;IRRE
initialization;-4.863746;1.2167654;2.7104175;0.31914788;2.0933006;-1.2629358;IRRE
reference with dense array x;1.5907756;1.6354262;-0.3896942;-3.6733513;0.46919695;-0.8216375;CODE
compare with sparse x;5.427555;-0.2833252;-0.4099691;-1.974358;0.4867564;0.5598748;IRRE
compare with almost same beta loss since some values have a specific;3.5344021;3.8785837;-0.8977471;2.5811834;-0.4914565;-2.0970387;IRRE
behavior but the results should be continuous w r t beta loss;1.7707343;2.2168975;-1.2249843;3.7034178;-3.8873558;0.7029089;IRRE
test that an error is raised if beta loss 0 and x contains zeros;0.6571899;5.298042;-3.9372222;2.48391;-2.006315;-3.4024787;IRRE
test that the output has not nan values when the input contains zeros;2.7898011;6.1545844;-3.013937;-1.7954811;-4.173301;-6.291077;IRRE
check verbose mode of minibatchnmf for better coverage;0.17264962;2.3914182;-3.7373593;4.628326;-0.9752483;1.2632192;IRRE
check that n components is correctly inferred;2.7766504;4.549881;-2.2131288;-0.97692925;2.718384;-2.8419213;-
from the provided custom initialization;-5.9646225;0.31185064;0.7036615;1.0447025;3.596082;3.9713378;IRRE
check that n components is correctly inferred from the provided;1.4577441;4.602729;-2.3788767;-1.8560783;2.1601985;-2.5576224;CODE
custom initialization;-4.669802;1.7299932;1.1918998;1.0826914;3.9280236;3.552445;IRRE
tests that non negative factorization does not fail when setting;1.7180591;5.6386886;-5.5410876;3.8205338;-2.6140966;-1.6465439;IRRE
n components auto also tests that the inferred n component;0.92174685;1.3530352;-2.9677296;3.4283237;2.6443832;-1.131382;IRRE
value is the right one;-0.73126733;4.015061;4.0812097;-2.0906794;1.3210666;-5.8714414;IRRE
should not fail;-2.4378164;3.6113756;0.42122597;6.005756;-1.2461045;-3.7874975;-
check that warnings are raised if user provided w and h are not used;-4.650211;3.6709836;-4.1110864;3.4599946;-0.47150826;-2.1128125;OUTD
and initialization overrides value of w or h;-4.5620165;1.5821242;-1.2431617;0.09165349;1.6044698;2.7298248;IRRE
when update h is false w is ignored regardless of init;-5.2351933;4.3766165;-2.1355171;2.7597334;-1.480682;1.4603748;IRRE
todo use the provided w when init custom;-6.6556416;1.8026137;0.0005921063;2.849875;1.734148;4.0559134;IRRE
check that an informative error is raised when custom initialization does not;-2.9846513;6.0068164;-4.3128967;6.253766;0.9286519;0.99358296;CODE
have the right shape;0.08745651;-0.2340715;6.4171553;-0.3549636;-1.1014409;-0.03567414;-
create 3 topics and each topic has 3 distinct words;0.2648471;-1.78959;3.7461703;-2.4552956;4.4106197;-0.52921623;IRRE
each word only belongs to a single topic;0.09831911;-2.080504;1.9025226;0.8483966;3.1743333;0.38409656;CODE
default prior parameter should be 1 topics;-1.3823338;1.099813;-0.14944494;1.7848103;2.442874;4.5761075;IRRE
and verbose params should not affect result;-0.56908715;5.682199;-0.25351053;3.2433133;-0.07311346;-0.20525931;IRRE
test lda batch learning offset fit method with batch learning;4.9368377;0.656122;-3.7954457;1.986976;0.58615106;1.087852;IRRE
find top 3 words in each lda component;1.3166443;-0.18710275;0.41991988;-3.4712172;4.396256;-0.25124526;-
test lda online learning fit method with online learning;3.247703;-1.8488566;-3.1058733;2.6398244;0.9749801;0.24677266;IRRE
find top 3 words in each lda component;1.3166443;-0.18710275;0.41991988;-3.4712172;4.396256;-0.25124526;-
test lda online learning partial fit method;4.7333503;-1.3220515;-3.1916173;2.787698;1.7883837;0.8192183;IRRE
same as test lda batch;1.33217;0.076019086;-1.3972679;2.6507914;3.2744348;-1.2099826;IRRE
test lda with dense input;3.1757722;2.54624;-3.747824;0.6980789;0.8837475;-1.2833827;IRRE
find top 3 words in each lda component;1.3166443;-0.18710275;0.41991988;-3.4712172;4.396256;-0.25124526;-
test lda transform;1.517963;2.2293785;-3.1599724;-0.042867657;0.10769556;-1.3777671;IRRE
transform result cannot be negative and should be normalized by default;0.13629109;3.9486496;-2.7364416;-3.9171233;-4.358458;2.3315806;CODE
test lda fit transform transform;3.0905745;2.2177992;-3.5434816;-1.5969136;-1.7588042;1.1455193;CODE
fit transform and transform result should be the same;3.3315525;2.6107292;-0.041075803;-3.0014608;-3.5004318;3.123479;CODE
test pass dense matrix with sparse negative input;5.5301456;2.9451718;-4.6243925;-1.2839472;-1.7631259;0.003556028;IRRE
test perplexity before fit;4.0182567;5.6048503;-2.6400387;4.2745695;-0.6241234;-2.5633283;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
test lda batch training with multi cpu;3.6002176;-0.059838433;-2.8781474;2.8682973;1.5194075;-0.030129358;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445925;-3.3966901;-3.4007475;-0.13234863;-4.2971582;-1.9892539;CODE
test lda online training with multi cpu;2.9613159;-1.2252166;-2.78232;2.8029542;1.6496205;-0.069418415;IRRE
test dimension mismatch in perplexity method;2.1013546;4.3648357;-5.84907;-0.43187308;-0.99344105;-1.646072;IRRE
invalid samples;1.8520699;3.823848;-3.2670937;-0.23082238;-1.2514386;-5.313463;OUTD
invalid topic number;-3.676893;-0.9042221;-2.6569357;-0.98529464;-1.0674483;-1.8393059;OUTD
test lda perplexity for batch training;3.765074;-0.47547978;-3.950071;3.329122;3.2548244;-1.1026757;IRRE
perplexity should be lower after each iteration;1.704847;3.8796804;-1.1046882;-0.9941256;-2.2014425;-0.91652244;-
test lda score for batch training;3.4948108;-0.117345296;-2.9250295;2.127165;2.4215064;-2.1213636;IRRE
score should be higher after each iteration;4.33716;3.130656;1.5694817;1.8359487;-0.37239257;-3.291696;-
test lda perplexity for sparse and dense input;4.0356793;0.28964424;-4.9639473;-1.0051056;0.66335875;0.9615051;IRRE
score should be the same for both dense and sparse input;5.711117;1.03919;-2.8532295;-0.2581639;-0.4462091;0.7126292;CODE
test the relationship between lda score and perplexity;2.0470743;1.573319;-2.2475152;1.7903455;2.9082332;-2.9431229;IRRE
test that the perplexity computed during fit is consistent with what is;3.5823615;4.5634027;-3.497592;3.709457;-0.7977944;-1.0662954;IRRE
returned by the perplexity method;0.88037026;3.005052;-0.9932802;-1.1652366;0.80297667;-2.31606;IRRE
perplexity computed at end of fit method;3.109778;3.1292703;-2.987387;0.4351704;-1.7799838;1.4673461;CODE
result of perplexity method on the train set;4.139284;1.9529356;-1.170921;-1.1127701;0.4727745;0.29683408;IRRE
pytest mark thread unsafe manually captured stdout;-3.4542491;1.6311595;-2.386387;2.2372425;-4.13873;0.8035803;CODE
sparse m and sparse n could be larger but be aware;4.0653086;-0.9792846;-2.3220413;-2.53108;0.33355913;2.1518364;IRRE
scipy s generation of random sparse matrix can be costly;5.6476007;-4.9982266;-3.4873025;-1.790785;-2.3894515;1.7450529;IRRE
a sparse m sparse n dense array is allocated to compare against;4.499764;-0.053227503;-2.2265415;-1.1314836;0.32747796;1.7957984;IRRE
sparse m sparse n 1000 300 arbitrary;4.482577;-2.1728106;-1.8330907;-3.081297;0.7435752;2.1283557;IRRE
check the shape of fit transform;4.4561133;2.5739832;1.0683432;-3.0087638;-2.965888;1.2495459;CODE
check the equivalence of fit transform and fit transform;3.0925906;3.6514647;-0.42653742;-0.9150897;-2.0550308;1.2303199;CODE
test get covariance and get precision;3.6478605;3.9647782;-2.9056952;1.6774074;-3.543116;-3.863992;IRRE
test if we avoid numpy warnings for computing over empty arrays;3.1168616;4.55827;-5.1569967;0.19727038;-4.4351273;-3.3194387;CODE
n features n components 2 anything n comps triggered it in 0 16;-1.3363703;-0.63698417;-1.5373622;-2.3998199;0.8731374;-0.6554668;TASK
check that pca output has unit variance;3.0940545;2.8430502;-2.8706405;-1.265519;-1.6710553;0.7313437;IRRE
some low rank data with correlated features;5.9802184;-2.764197;0.3912193;-2.503278;1.040379;2.0710974;TASK
the component wise variance of the first 50 features is 3 times the;2.0857766;-2.1264248;-1.0921609;-2.3575158;1.1841859;0.9401375;TASK
mean component wise variance of the remaining 30 features;4.068073;-1.7347753;-0.080541275;-1.8721944;0.72302413;2.45167;CODE
the component wise variance is thus highly varying;3.3423755;-0.25501806;-2.0889914;-0.13947263;-1.7757034;5.6948185;CODE
whiten the data while projecting to the lower dim subspace;4.392269;1.3183322;-1.2666575;-2.6987338;-1.8229086;5.800656;CODE
x x copy make sure we keep an original across iterations;0.6354852;2.219394;0.80066365;-0.11981991;0.19533473;0.13980432;-
test fit transform;5.2509274;3.4688818;-0.89479244;-0.14223525;-2.9574573;-1.7965223;IRRE
in that case the output components still have varying variances;3.4700086;1.6710608;-2.3609674;0.31193078;-1.1860342;5.904151;CODE
we always center so no test for non centering;-0.021599056;3.8090503;1.7805468;3.2090318;-3.1049774;-0.60720056;TASK
with a non zero tail strength the data is actually full rank;3.8832958;0.8571852;-2.4757197;-1.400632;-1.2475518;1.79363;META
only check for a truncated result with a large number of iterations;4.424964;5.3609595;-0.10755683;3.3167305;-1.6987267;-4.017513;CODE
to make sure that we can recover precise results;3.3364432;-1.0419184;0.94575006;5.698438;-1.2242035;-2.4754164;IRRE
test all components except the last one which cannot be estimated by;4.330218;6.560516;-1.1272902;3.8606381;1.5616481;-1.5246488;CODE
arpack;-2.1664052;-3.2019367;1.797028;-0.6745507;-0.8189395;-1.5579554;-
test all components to high precision;5.1543117;3.9423487;-2.7972116;2.274352;-0.3690032;-2.8735433;IRRE
for some choice of n components and data distribution some components;4.499814;-2.1481402;1.9780371;-3.7341826;6.3747272;2.1240563;CODE
might be pure noise let s ignore them in the comparison;2.101093;0.8537593;-1.2361351;2.68624;-1.8738296;-1.8639224;CODE
as a result the output of fit transform should be the same;3.3174093;3.186813;-1.5973723;-2.669719;-3.748513;3.2791286;IRRE
and similarly for the output of transform on new data except for the;4.7783747;0.37070134;1.2202883;-2.6282573;1.3987509;1.4780885;CODE
last component that can be underdetermined;1.5827124;2.134824;2.5269992;-2.331793;4.6696653;2.7852578;-
check that inverse transform reconstructions for both solvers are;1.5220506;2.689654;-3.602847;-1.0913767;-3.1014743;2.7505934;CODE
compatible;-3.4564965;-2.5597074;2.2612953;-0.8807609;0.5636557;-0.9411292;-
in this case the models should have learned the same invertible;2.6784418;-1.0231917;-0.38506633;3.9671254;-0.3819423;2.7394009;CODE
transform they should therefore both be able to reconstruct the test;0.5226595;4.964174;-1.942787;2.1640093;-0.4696047;-2.436437;CODE
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
in the absence of noisy components both models should be able to;4.3161163;-0.36763385;-0.95668554;4.3596377;3.3064554;5.0537586;CODE
reconstruct the same low rank approximation of the original data;8.083612;0.5215886;-1.3885795;-2.227544;-0.8495652;4.796702;CODE
when n features n samples and n components is larger than the rank;5.6483436;-1.215508;-2.0703986;-1.9752054;2.4385612;2.1088605;TASK
of the training set the output of the inverse transform function;3.056764;-2.3357966;1.1687851;-0.85007894;-0.075561546;3.1038833;IRRE
is ill defined we can only check that we reach the same fixed point;-0.98545426;4.2340274;0.4285046;3.2889028;-0.63600653;0.31938356;CODE
after another round of transform;-1.1106949;2.7880273;4.088864;-1.9318513;-2.2913222;0.6127338;CODE
compare to the frobenius norm;2.4837372;0.35552844;-0.3483263;-0.8004686;-1.3953241;2.744286;IRRE
compare to the 2 norms of the score vectors;5.349189;1.0175344;0.22340952;-1.6132743;0.08162842;-0.66231406;IRRE
set the singular values and see what er get back;2.6785896;4.1571736;-1.1598438;-3.2251687;-1.9374285;-2.3294508;IRRE
test that the projection of data is correct;5.238021;5.256847;-0.88539857;1.9140689;-2.3422034;-1.9750794;IRRE
test that the projection of data is correct;5.23802;5.256846;-0.8853989;1.914069;-2.3422024;-1.9750775;IRRE
test that the projection of data can be inverted;5.3325243;4.2478824;-0.41346827;-0.058768805;-1.9111407;0.8208555;IRRE
x rng randn n p spherical data;3.400057;-1.746438;-0.22486024;-4.7203703;-0.68058676;0.8349088;IRRE
x 1 0 00001 make middle component relatively small;1.4921099;3.5336907;-0.5952761;-8.004315;-2.4049277;1.4527067;-
x 5 4 3 make a large mean;2.5744748;2.3829143;4.047805;-2.5952325;-1.2750064;-1.721037;-
same check that we can find the original data from the transformed;2.5936158;1.9164476;0.631706;-0.9321675;-0.88008976;0.5728521;CODE
signal since the data is almost of rank n components;6.687774;0.77405214;-0.028096465;-3.6803985;1.2903339;4.4849987;-
ensures that solver specific extreme inputs for the n components;2.0454206;0.6911062;-2.297213;-1.0012835;1.5738186;3.8799672;CODE
parameter raise errors;-2.375644;6.1392684;-3.0789979;2.8723168;-1.3147426;-1.1564672;IRRE
mallest d 2 the smallest dimension;1.3979913;0.37103063;0.21957843;-4.8441954;0.047176484;1.2012985;CODE
additional case for arpack;-3.0255945;-1.789128;-0.047788642;-0.28489393;2.1805427;2.2706065;CODE
ensure that n components mle doesn t raise error for auto full;1.9818172;3.1867988;-5.272275;4.1513133;0.78484064;3.675056;CODE
ensure that n components mle will raise an error for unsupported;2.2449281;2.3839955;-6.946043;3.5147038;1.3771684;2.2686958;CODE
solvers;0.6119101;-2.543535;2.8168771;-0.057267364;0.42410028;-3.9833293;-
check automated dimensionality setting;5.1359043;-0.03452381;-1.0614498;-2.1162426;0.7391588;1.116608;IRRE
todo explain what this is testing;-1.2204686;1.8090154;0.1278249;5.6461897;-0.145883;-6.3104434;IRRE
or at least use explicit variable names;-1.4953877;0.8341581;-2.6624925;0.50722957;2.792598;0.32683003;IRRE
todo explain what this is testing;-1.2204686;1.8090154;0.1278249;5.6461897;-0.145883;-6.3104434;IRRE
or at least use explicit variable names;-1.4953877;0.8341581;-2.6624925;0.50722957;2.792598;0.32683003;IRRE
iris data 0 95 2 row col;3.063625;1.686864;-0.4783873;-6.922926;-1.1906208;-2.5868425;-
iris data 0 01 1 row col;3.2555969;1.584113;-0.3747357;-8.444249;-0.85584915;-3.0381212;-
row col;2.0558603;-0.34537265;5.1807284;-5.6420245;0.8841206;-3.005963;-
test that probabilistic pca scoring yields a reasonable score;4.632473;-0.16204832;-2.3048928;2.687902;1.1663567;-1.4525212;IRRE
check that probabilistic pca selects the right model;3.0464718;0.86258334;-1.2165931;3.200026;1.780784;1.1374403;CODE
sanity check for the noise variance for more details see;2.934839;1.9108574;-1.8144593;1.8184615;-2.3541708;0.882568;CODE
https github com scikit learn scikit learn issues 7568;-3.1100152;-9.442547;-6.3004913;-0.25660557;-5.369318;-5.299212;CODE
https github com scikit learn scikit learn issues 8541;-3.3660724;-9.165369;-5.974803;-0.39994702;-5.3484936;-5.0601015;CODE
https github com scikit learn scikit learn issues 8544;-3.3029563;-9.791342;-5.947871;-0.38824835;-5.1233454;-5.245307;CODE
check the consistency of score between solvers;3.254485;4.146087;-2.460677;3.6147037;-0.039546218;-2.5795865;-
arpack raises valueerror for n components min n samples n features;3.323808;-0.17137982;-7.2766924;-1.3360559;-2.056368;0.9012168;CODE
ensure that noise variance is 0 in edge cases;2.6672964;3.2910182;-3.1467266;0.13673487;-1.027809;3.5375867;CODE
when n components min n samples n features;5.7342777;-1.542421;-1.2041928;-1.8008941;4.2058287;1.8541147;TASK
non regression test for gh 12489;0.86464685;3.5111277;-4.8051295;3.1178284;-3.6740763;-4.3828683;IRRE
ensure no divide by zero error for n components n features n samples;5.0647917;3.2571247;-4.2675724;-1.1362486;1.1078516;0.35081095;TASK
non regression test for gh 12489;0.86464685;3.5111277;-4.8051295;3.1178284;-3.6740763;-4.3828683;IRRE
ensure no divide by zero error for n components n samples n features;4.9926043;3.2808573;-4.3369665;-1.0376596;1.0058086;0.51384646;TASK
case n samples 10 n features and max x shape 500 full;4.3847246;0.33183935;-1.0079834;-3.1778417;3.1083949;-0.39771414;TASK
case n samples 10 n features and n features 500 covariance eigh;4.2876825;-1.668907;-1.6742679;-2.290165;2.1178865;-0.1519623;TASK
case n components 8 min x shape full;1.149388;1.8161329;2.470804;-5.4047084;3.2119582;1.7669803;CODE
n components 1 and n components 8 min x shape randomized;4.972848;-1.0982854;0.7275989;-4.3618913;1.9272134;2.6252344;IRRE
case n components in 0 1 full;0.2821628;2.8237612;0.4335927;-5.24098;4.9576564;-1.0171816;CODE
ensure that pca does not upscale the dtype when input is float32;2.2140863;0.86905515;-6.247055;-4.412343;-3.530462;3.5035508;CODE
the atol and rtol are set such that the test passes for all random seeds;0.74413186;1.1433346;-0.89487225;4.941605;1.3031528;-2.789789;IRRE
on all supported platforms on our ci and conda forge with the default;-4.051271;-6.090693;-2.5715759;-0.16271937;-2.6482809;2.7531004;CODE
random seed;0.9575821;-2.271988;3.8742115;1.1954926;1.3722162;-4.3936505;IRRE
ensure that all int types will be upcast to float64;-1.2562183;3.1368196;-3.687275;-3.157752;-1.7626317;0.33169085;CODE
when n components is the second highest cumulative sum of the;2.2934852;0.6001275;1.4021277;-3.3423622;1.6672649;-0.23173444;-
explained variance ratio then n components should equal the;2.4180307;1.100307;-0.13930665;-2.8306172;-0.63317627;2.015072;CODE
number of features in the dataset 15669;2.2589602;-4.280407;-0.7181146;-2.6701958;1.386817;-4.169942;TASK
test error when tested rank not in 1 n features 1;1.804735;4.4269967;-4.892782;1.0541694;-0.26657096;-4.7001667;IRRE
test rank associated with tiny eigenvalues are given a log likelihood of;2.6437027;2.01745;-3.2988608;0.34426606;-1.6618781;1.1951433;IRRE
inf the inferred rank will be 1;1.9049139;1.3169451;-1.065821;0.7818398;1.957025;-0.40933356;-
test mle with pathological x only one relevant feature should give a;2.0930467;2.47218;-1.5350634;3.166171;2.1188293;-1.2541014;TASK
rank of 1;0.1483076;0.16602461;2.5384781;-2.6597319;2.0287607;-4.01526;-
tests that an error is raised when the number of samples is smaller;3.8560014;6.2122855;-1.6299663;4.807235;-1.4443036;-4.299058;IRRE
than the number of features during an mle fit;6.6832194;-0.3506002;-0.9779542;1.2764803;2.0340726;1.1887808;TASK
non regression test for issue;0.79106295;4.78909;-2.3927195;4.884089;-2.2617483;-5.790237;IRRE
https github com scikit learn scikit learn issues 16730;-3.6471484;-9.193699;-5.6324844;-1.4455022;-5.355277;-5.4362035;CODE
x 1 np mean x 1 axis 1 true x dim is ndim 1;4.596755;2.048328;-2.2156858;-9.076255;-3.3574903;0.60000545;CODE
make sure assess dimension works properly on a matrix of rank 1;3.945556;3.0190856;-3.760025;-2.1835356;-1.6276706;-0.67303705;-
x np ones n samples n features rank 1 matrix;5.314246;-1.9558959;-2.286425;-5.482099;0.29984805;1.5192019;TASK
except for rank 1 all eigenvalues are 0 resp close to 0 fp;2.7758482;2.593944;-3.6473262;-3.076363;-1.9051619;3.734776;IRRE
the default value of n oversamples will lead to inaccurate results;4.2243156;3.3098817;-2.8799763;0.8727498;-2.4722638;0.030726437;IRRE
we force it to the number of features;1.8349395;-4.091435;1.4381615;2.459001;3.5778713;1.0339195;TASK
random state 0 how to use global random seed here;-0.1634;0.68915516;0.11737078;0.1491642;0.688204;0.98298234;IRRE
pca with mle cannot use check array api input and values because of;1.8468666;3.0898316;-4.6761475;-1.1797194;-1.9842684;0.38604182;IRRE
rounding errors in the noisy low variance components even checking;4.656311;2.1726494;-5.0766625;1.0462865;-4.2012606;1.1034807;CODE
the shape of the components is problematic because the number of;1.7988136;0.7622333;1.8931998;-4.9587;0.31447366;0.8853958;IRRE
components depends on trimming threshold of the mle algorithm which;4.349545;-0.102937296;-2.594845;0.7886996;2.1705441;4.0962505;CODE
can depend on device specific rounding errors;2.7945292;2.8490374;-2.8525097;0.6597896;-3.375035;-0.7942388;CODE
simpler variant of the generic check array api input checker tailored for;0.104020596;3.940817;-1.4409616;2.0127954;1.8293266;-0.9908202;CODE
the specific case of pca with mle trimmed components;3.8416069;-1.2315736;-2.5622578;-1.5401784;2.7283895;4.5535293;CODE
check that the explained variance values match for the;3.73632;4.5969415;-1.0446812;0.45906466;-1.6557808;-2.675999;IRRE
common components;-0.18764624;-2.8548872;3.0532348;-2.0883036;4.531127;1.5419122;-
if the number of components differ check that the explained variance of;3.6847718;2.4759576;-0.15770319;-0.8197476;1.6660316;0.6227838;CODE
the trimmed components is very small;-1.3058834;-0.8445866;1.4235481;-2.1954167;0.13922739;3.6572628;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
y is defined by y uv noise;0.051116195;-0.49611482;0.40241635;-2.5144637;-3.185012;0.49888468;CODE
y 0 1 rng randn y shape 0 y shape 1 add noise;4.3582745;-1.1204592;0.4268486;-4.995877;-2.6222079;-0.40747464;TASK
sparsepca can be a bit slow to avoid having test times go up we;2.8529086;-1.5457103;-3.2861736;4.478634;-1.7207932;0.38693264;IRRE
test different aspects of the code in the same test;0.34464055;5.242743;-0.4895473;4.711996;2.6498382;-5.20156;IRRE
test overcomplete decomposition;5.4927692;4.361595;-4.572395;4.579617;0.7589929;-3.6174831;TASK
y generate toy data 3 10 8 8 random state rng wide array;2.8289003;0.15303706;1.4748691;-4.4636035;-0.37910455;-2.0720468;IRRE
test that cd gives similar results;3.0642674;3.139125;-0.9399434;2.4668517;1.738571;-5.1080155;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445925;-3.3966901;-3.4007475;-0.13234863;-4.2971582;-1.9892539;CODE
y generate toy data 3 10 8 8 random state rng wide array;2.8289003;0.15303706;1.4748691;-4.4636035;-0.37910455;-2.0720468;IRRE
test multiple cpus;2.6793942;2.5767932;-0.51055086;3.1194448;0.06820939;-2.9743102;IRRE
test that sparsepca won t return nan when there is 0 feature in all;3.028217;3.7572412;-5.890749;0.7392828;-2.7932484;-2.1753802;IRRE
samples;3.4987426;-1.3804811;5.2160425;1.2945335;2.538919;-4.9781947;-
y generate toy data 3 10 8 8 random state rng wide array;2.8289003;0.15303706;1.4748691;-4.4636035;-0.37910455;-2.0720468;IRRE
y generate toy data 3 65 8 8 random state rng tall array;2.7981427;0.59067154;0.9359159;-4.573956;-0.646669;-2.4149976;IRRE
test overcomplete decomposition;5.4927692;4.361595;-4.572395;4.579617;0.7589929;-3.6174831;TASK
verify output matrix dtype;3.1928108;1.5827572;-5.6710334;-4.4639525;-2.1224058;-2.62021;IRRE
verify numericall consistentency among np float32 and np float64;2.250918;3.114432;-7.227105;-2.276204;-3.2112763;-1.3735536;CODE
vary the tolerance to force the early stopping of one of the model;2.2292783;3.2875473;0.78563845;6.171555;-2.4272406;3.0488324;CODE
force the max number of no improvement to a large value to check that;3.986016;5.085922;0.37558848;3.5232916;-0.7587344;-3.3622718;TASK
it does help to early stop;-2.4685104;0.3706182;3.3345592;4.739127;-1.1951904;1.7093226;CODE
elf store covariance store covariance used only in svd solver;0.64306927;-2.0320241;-6.6497936;-0.9740513;-1.1602073;5.0761;CODE
elf tol tol used only in svd solver;-1.9985399;-1.0888621;-4.848299;-1.4138076;-0.8433575;1.6959254;CODE
sw self covariance within scatter;2.8228915;-1.0900648;-1.353144;-0.6566321;-3.7664244;5.150533;CODE
st cov x shrinkage covariance estimator total scatter;3.4507444;-1.1593459;-2.7528398;-2.1041732;-3.5675921;5.816404;CODE
sb st sw between scatter;-0.391146;-0.3365079;3.1654365;-3.8426266;-1.9738808;0.6456952;-
evecs evecs np argsort evals 1 sort eigenvectors;1.3254701;0.18830939;-5.9922366;-2.3435678;-1.7470131;2.912498;IRRE
1 within univariate scaling by with classes std dev;5.0111866;-1.1458822;-3.8931944;-3.6546984;0.45577133;4.162876;CODE
avoid division by zero in normalization;2.4887164;4.119955;-1.6911926;-4.511645;-0.71148497;1.8059107;CODE
2 within variance scaling;3.0949075;1.6386822;1.2996341;-1.8444412;-1.5923016;3.462023;CODE
svd of centered within scaled data;5.643383;-0.45540872;-0.4212621;-5.072121;-2.1622121;5.7060876;CODE
scaling of within covariance is v 1 s;1.9925568;-0.12135681;-1.6463631;-0.24023324;-3.4867465;6.5331182;CODE
3 between variance scaling;3.6205537;0.691407;2.3364139;-2.7223396;-1.6121743;3.2862873;CODE
scale weighted centers;5.5283184;0.4510331;4.000315;-2.8668668;-2.2310092;4.1273627;-
centers are living in a space with n classes 1 dim maximum;2.2112699;0.2588281;-0.32359946;-3.761318;0.7363911;1.6413167;IRRE
use svd to find projection in the space spanned by the;2.400716;-0.8463322;-0.53257406;-4.000252;-1.4237666;2.7401085;CODE
n classes centers;0.71613336;-3.8864377;1.6269228;-0.83275324;2.6689637;-0.9358788;IRRE
lineardiscriminantanalysis covariance estimator is not validated yet;1.7772793;1.197372;-7.121914;0.5586082;-4.2307963;3.712689;TASK
if self priors is none estimate priors from sample;1.0375798;3.5940793;-1.7264684;2.0533528;0.29534185;1.752165;CODE
cnts xp unique counts y non negative ints;1.7777759;3.2385535;-2.1981096;-3.9507604;3.0298193;-2.902286;CODE
maximum number of components no matter what n components is;0.7329945;0.4576663;0.8387835;-4.604608;4.2454443;0.36306158;-
specified;-3.1292474;-1.5410633;5.141917;-0.63692564;2.7343311;-2.3118706;-
if size self classes 2 treat binary case as a special case;-0.3132482;3.4803326;-3.7147782;-1.6186463;5.3159122;-0.8589236;CODE
only overrides for the docstring;-5.9848557;0.3058633;-2.0105166;4.62122;2.26963;2.4952638;CODE
caling rotation linalg eigh cov scalings are eigenvalues;2.0517669;-1.5642865;-3.1149256;-3.1324658;-4.7596774;6.0775847;IRRE
rotation rotation np argsort scaling 1 sort eigenvectors;2.156776;-1.2842433;-3.7307227;-4.599747;-3.5977242;5.271702;IRRE
caling scaling np argsort scaling 1 sort eigenvalues;4.581976;0.048151713;-3.6334345;-2.990244;-4.5231266;5.335346;IRRE
xc u s v t;-2.3060563;-1.6632237;1.8038193;-0.5464184;0.22047502;-1.1285055;-
caling s 2 n samples 1 scalings are squared singular values;5.1328096;0.32159153;-3.4004376;-3.7496357;-4.9277754;2.7932556;IRRE
cov v s 2 n 1 v t;-0.7420506;-0.83459634;1.5976663;-1.4472289;-0.44159824;-2.8978026;-
support for shrinkage could be implemented as in;2.2949412;-2.37009;-0.43784058;0.7410638;1.8330377;6.051606;TASK
https github com scikit learn scikit learn issues 32590;-3.275769;-9.878767;-6.404463;-0.32481474;-4.9095078;-5.0553355;CODE
return log posterior see eq 4 12 p 110 of the esl;-2.0352275;2.1990948;0.3353168;1.5928845;0.9979735;0.12713613;IRRE
norm2 np array norm2 t shape len x n classes;3.7739546;-0.7414297;-2.175515;-7.927006;-0.8305592;0.46542248;IRRE
only overrides for the docstring;-5.9848557;0.3058633;-2.0105166;4.62122;2.26963;2.4952638;CODE
draw sample indices;4.6880198;0.73589486;4.5579762;-5.7306275;-0.2661826;-1.5628049;-
retrieve settings;-2.5975583;-0.82880193;3.7336223;0.7872607;0.36996648;2.6220639;IRRE
build estimators;3.0019476;-2.14972;0.46917203;4.221644;-0.05760568;2.468624;-
draw random feature sample indices using normalized sample weight;5.1313243;-1.6162473;-0.3308338;-3.3540325;-0.5292375;2.8993592;IRRE
as probabilities if provided;0.79408586;-0.07754233;4.721244;2.0048833;3.1915824;-3.8670592;-
note row sampling can be achieved either through setting sample weight or;4.7301455;0.8212487;0.2968334;-1.069087;1.9275851;1.9859358;TASK
by indexing the former is more memory efficient therefore use this method;1.2943038;2.8676426;1.3353556;-1.2892545;2.9707534;0.31981176;CODE
if possible otherwise use indexing;3.6304393;1.3456862;4.2270365;-2.168797;4.702155;-1.8203444;-
row sampling by setting sample weight;5.736349;1.9665562;0.49199077;-1.2257334;1.548129;1.8119856;IRRE
row sampling by indexing;6.9285755;1.2390755;2.3103871;-3.2756643;3.3458948;-0.07189365;-
basebagging estimator is not validated yet;0.61230373;2.305857;-5.5289335;3.710872;-1.6825213;2.1105466;TASK
convert data x is required to be 2d and indexable;3.7360895;3.443189;-0.5346121;-8.533693;0.21696585;1.4605628;CODE
remap output;-1.6077955;1.6962209;2.382157;-3.1994834;0.001439844;-0.4419781;IRRE
check parameters;-0.36041477;6.456168;1.3902186;1.6032363;0.99924314;-3.843164;IRRE
validate max samples;6.094226;3.9922178;-1.3482273;2.4409769;2.3259516;-3.2941942;-
store validated integer row sampling value;4.193608;5.497906;-1.0408355;-1.7542329;3.3033497;-1.9505568;IRRE
validate max features;2.8540385;1.9744412;-2.1236012;3.0308626;3.2441518;-1.853064;TASK
store validated integer feature sampling value;3.9585707;2.992345;-3.0048313;0.12493843;3.3979268;-1.1014782;TASK
store sample weight needed in get estimators indices note that;3.7187414;0.8211097;-2.1649852;0.85355633;0.89593387;4.5114546;TASK
we intentionally do not materialize sample weight none as an array;3.407542;3.2834024;-2.6057982;0.009637686;-0.27723294;2.0376835;CODE
of ones to avoid unnecessarily cluttering trained estimator pickles;5.271166;-3.9018996;-1.2617539;3.6056852;1.0963796;2.6656861;CODE
other checks;-2.2398605;1.3873355;2.5455756;2.0821176;1.9732473;-3.3074098;-
free allocated memory if any;-1.5531619;2.0395393;0.75011;-0.023162346;2.097257;-0.3464558;-
parallel loop;1.9479783;1.2367799;5.214352;-2.3168125;-0.3092049;-2.674209;IRRE
advance random state to state after training;2.2250788;-0.7769593;1.1827756;5.054937;2.821607;1.3226762;IRRE
the first n estimators;2.212423;-1.8931335;1.2544689;1.5546297;-0.9348961;1.2339222;-
reduce;0.3180044;1.979058;4.9018087;-0.10519549;-0.18671434;-1.753967;-
todo slep6 remove if condition for unrouted sample weight when metadata;1.607318;4.600422;-3.953241;2.3136053;1.7783551;1.684191;CODE
routing can t be disabled;-4.436514;2.0703022;0.95970947;0.3525929;-3.3181427;2.7271163;-
set parameters;0.10336056;3.1397374;3.7041438;-0.6311514;2.8253968;1.1828105;IRRE
don t instantiate estimators now parameters of estimator might;0.3185138;2.5544522;-1.6236522;4.4200788;-2.3590624;4.7576623;IRRE
still change eg when grid searching with the nested object syntax;-0.7060363;1.8130293;0.23144174;0.99409837;2.1056201;2.9041834;CODE
self estimators needs to be filled by the derived classes in fit;3.6892653;-1.0211719;-3.8305964;3.341502;1.4036498;4.517878;CODE
compute the number of jobs;1.4408116;-0.41661292;4.2722917;-2.3250165;1.0765722;-4.350536;-
partition estimators between jobs;3.8695405;-1.8359842;0.6664287;1.7926004;1.3156102;3.782732;-
defined by metaestimatormixin;-5.14832;-2.6291275;-0.8068276;0.8705988;2.1398435;1.6632832;CODE
if estimators does not comply with our api list of tuples then it will;2.8208673;-0.028929075;-3.4778953;2.9569373;0.2421869;1.5955642;CODE
fail in this case we assume that allow nan and sparse are false but;3.6818182;3.951325;-4.761447;-0.80604225;-1.8003385;-1.297475;CODE
the parameter validation will raise an error during fit;0.8599789;5.550035;-4.326458;4.2127924;-1.6900628;2.0585363;IRRE
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
validate or convert input data;3.0361273;3.8265345;-0.0014879467;-0.45534238;2.0202339;-5.29073;CODE
compute missing values in feature mask checks if x has missing values and;3.568131;4.2178817;-2.749952;-0.918961;0.019591812;-2.2856557;IRRE
will raise an error if the underlying tree base estimator can t handle missing;0.86213493;2.7557437;-4.678217;4.559685;0.053452585;2.0256605;CODE
values only the criterion is required to determine if the tree supports;1.3049524;2.8024554;-3.3073559;2.0145745;3.7855933;-1.9195542;IRRE
missing values;0.6812976;4.817846;0.061043583;-2.770763;-0.9457375;-5.3258653;IRRE
pre sort indices to avoid that each individual tree of the;2.9389389;1.1056033;0.5628171;-1.8558699;1.9494351;0.4480901;CODE
ensemble sorts the indices;4.5267267;0.24590711;-0.23804873;-1.4408528;2.8413308;0.8130688;-
reshape is necessary to preserve the data contiguity against vs;1.4835404;-0.5861336;-0.6574447;-1.0544254;0.69500864;5.6920056;-
np newaxis that does not;-2.9079926;-0.11009479;-0.009352005;-2.4536517;-0.8250196;-0.07860009;CODE
free allocated memory if any;-1.5531619;2.0395393;0.75011;-0.023162346;2.097257;-0.3464558;-
we draw from the random state to get the random state we;0.25199813;-0.4747933;4.973862;0.61340344;0.6209697;-0.40240785;IRRE
would have got if we hadn t used a warm start;-2.007451;2.9497845;2.2859213;2.7478883;-2.3545363;-0.18520837;-
parallel loop we prefer the threading backend as the cython code;-1.0801119;-1.4597377;1.8148181;-0.33871958;-0.55481523;0.6282605;CODE
for fitting the trees is internally releasing the python gil;0.28242397;-3.9717486;-1.3473792;0.9869754;-3.9819043;-0.025862116;CODE
making threading more efficient than multiprocessing in;1.1006752;-1.9721037;1.3383578;1.9191829;-0.62056667;2.5635037;CODE
that case however for joblib 0 12 we respect any;-3.60442;-3.244124;-3.2642915;1.4467776;-0.7864093;-0.30591372;CODE
parallel backend contexts set at a higher level;-3.2988632;-1.1798131;1.4683992;2.0921042;2.7883523;5.7680554;IRRE
since correctness does not rely on using threads;-0.80063444;1.2794234;-0.7451654;4.486593;-0.37172392;0.05041358;CODE
collect newly grown trees;-1.1007692;-2.3856595;1.9969114;1.0944693;1.866889;0.52052855;CODE
fixme we could consider to support multiclass multioutput if;0.77852386;-2.3693929;-2.510607;2.0872984;3.4780679;1.9689273;IRRE
we introduce or reuse a constructor parameter e g;-2.589268;-1.382042;0.61634713;3.4503226;5.531973;3.7035818;CODE
oob score allowing our user to pass a callable defining the;-1.3320701;1.5547719;-0.6742274;2.6664815;3.798825;-0.56297946;IRRE
scoring strategy on oob sample;5.952752;0.028534481;0.52139914;2.3515174;3.7721784;-2.560249;-
decapsulate classes attributes;-1.5647949;-1.4386488;-1.4843601;0.060360942;5.662435;2.3673637;IRRE
prediction requires x to be in csr format;1.7026784;0.14108099;-3.5693636;0.27743196;-0.30243155;-0.7891022;CODE
n classes is a ndarray at this stage;1.4451339;-3.57085;-1.0973192;-2.6955614;2.8633869;-1.1468054;CODE
all the supported type of target will have the same number of;-0.79545385;0.6355707;-1.82173;1.2814187;3.3303902;1.636116;-
classes in all outputs;0.3522942;-2.0991158;-0.299497;0.17047384;3.9034586;-1.6649002;IRRE
for regression n classes does not exist and we create an empty;1.2788334;1.2207778;-4.036768;-0.4019725;0.77078545;-2.528572;CODE
axis to be consistent with the classification case and make;5.231795;-0.9051433;1.730621;-3.2539663;1.3002121;2.2535481;CODE
the array operations compatible with the 2 settings;-0.89729285;0.31965145;1.8245785;-2.2481205;2.2434635;2.7597852;IRRE
default implementation;-3.3599937;-1.7541647;-0.6336157;1.2707511;1.8313285;2.4934714;TASK
get drawn indices along both sample and feature axes;5.2640452;-0.077309094;2.0105727;-5.985943;-1.4335146;2.1460733;TASK
tree random state is actually an immutable integer seed rather;-1.3511267;-0.41029015;-1.364009;1.2680868;2.5967555;-0.039126143;IRRE
than a mutable randomstate instance so it s safe to use it;-0.9687779;-0.14286919;0.82768506;4.9816766;2.5625763;2.2989006;IRRE
repeatedly when calling this property;-3.6815996;3.9513762;2.744047;4.0026965;2.6343296;0.77415574;IRRE
operations accessing random state must be performed identically;-0.7753467;2.3761563;0.060209148;3.088947;3.5035071;1.1885487;IRRE
to those in parallel build trees;-1.2996107;-4.558225;2.7508867;1.9610959;3.1065867;0.40359664;-
only the criterion is required to determine if the tree supports;-0.58698285;1.1036718;-2.8808067;3.7107015;4.0968146;-0.015092388;CODE
missing values;0.6812976;4.817846;0.061043583;-2.770763;-0.9457375;-5.3258653;IRRE
binary and multiclass;-0.5953562;-1.8598273;-1.9197661;-2.2386131;6.661099;-2.695849;IRRE
roll the first n outputs axis to the last axis we will reshape;2.9855692;0.4765143;4.3025904;-7.608889;-3.542938;3.1332161;IRRE
from a shape of n outputs n samples n classes to a shape of;6.5506964;-2.08213;1.2906047;-4.065653;3.2311068;-0.2549266;IRRE
n samples n classes n outputs;5.0552344;-1.399009;-0.13472824;-2.287651;4.837865;-4.033263;IRRE
drop the n outputs axis if there is a single output;3.3792005;4.537063;3.089082;-4.2758517;-1.3492861;0.99749327;IRRE
all dtypes should be the same so just take the first;0.75716114;-0.47477028;-1.5111398;-1.6211646;2.5682685;-1.4684019;-
check data;2.5182383;3.6637943;3.9254577;0.88440025;1.17757;-7.1813874;-
assign chunk of trees to jobs;0.50150985;-2.1187081;1.0478493;0.6009203;3.6680412;0.7457304;IRRE
avoid storing the output of every estimator by summing them here;4.6215205;2.1495025;0.2000809;2.6297648;-1.4395297;2.8732705;IRRE
check data;2.5182383;3.6637943;3.9254577;0.88440025;1.17757;-7.1813874;-
assign chunk of trees to jobs;0.50150985;-2.1187081;1.0478493;0.6009203;3.6680412;0.7457304;IRRE
avoid storing the output of every estimator by summing them here;4.6215205;2.1495025;0.2000809;2.6297648;-1.4395297;2.8732705;IRRE
parallel loop;1.9479783;1.2367799;5.214352;-2.3168125;-0.3092049;-2.674209;IRRE
single output regression;4.640169;-0.04942608;3.4917934;0.5364569;-1.1118509;0.34655166;IRRE
multioutput regression;6.5291495;-2.535631;1.998308;0.46457344;-1.1522126;0.4789173;IRRE
drop the n outputs axis if there is a single output;3.3792005;4.537063;3.089082;-4.2758517;-1.3492861;0.99749327;IRRE
note we don t sum in parallel because the gil isn t released in;0.09654951;0.6941268;1.6554465;1.0999794;-2.1080391;0.04459773;TASK
the fast method;3.4393342;-3.0350597;3.9668217;3.9638948;1.334229;-0.68316406;-
average over the forest;2.0832589;-1.0338845;2.0923607;1.3461974;-1.2190161;-1.0467287;CODE
parameters are validated in fit transform;3.1295664;3.0960286;-3.6574876;-0.27432612;-1.7637203;2.7274244;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
sample weight is always a ndarray never none;3.5457695;1.3497742;-4.300262;-1.3505557;-3.1069915;0.84295344;-
header fields and line format str;-3.720691;0.021685194;0.10835307;-3.4608924;1.7134079;-1.2686876;CODE
do oob;-1.8041439;-3.0583446;2.4137492;-0.3918872;0.6840619;-2.1834328;CODE
print the header line;-4.9550915;0.4436413;2.858319;-3.0835128;-0.35537586;-2.5860877;CODE
plot verbose info each time i verbose mod 0;-0.7226133;2.634236;2.6666434;-3.320641;-4.750438;-0.43139333;IRRE
we need to take into account if we fit additional estimators;3.2806985;1.2615712;0.0545718;4.3876257;-1.4142356;5.0268254;TASK
i j self begin at stage iteration relative to the start iter;-2.3732154;3.5106099;2.7660494;2.1495132;0.027763937;2.1439188;CODE
adjust verbose frequency powers of 10;1.2984997;2.507506;1.3283213;-1.176545;-0.52425325;-0.33333346;IRRE
todo without oob i e with self subsample 1 0 we could call;-1.0326031;0.99539334;0.6891972;0.6385972;2.6150258;-1.2393593;CODE
self loss loss gradient and use it to set train score;2.6343672;-1.0331646;-0.5010608;0.71626776;0.19289336;2.3683758;IRRE
but note that train score i is the score after fitting the i th tree;1.9676313;-0.4142247;-0.13846558;2.5675986;2.370917;-1.22496;TASK
note we need the negative gradient;0.70128596;-1.4291878;1.6059985;-2.0122385;-2.9166207;3.1592216;TASK
ample weight none we pass sample weights to the tree directly;1.6600513;0.8002079;-0.29072338;1.8103946;1.7848065;2.2590492;CODE
2 d views of shape n samples n trees per iteration or n samples 1;5.710828;-2.5033422;1.7563823;-2.8091795;1.3883548;2.2017508;-
on neg gradient to simplify the loop over n trees per iteration;3.6772568;-0.92457443;-1.3305955;-1.2603849;0.8001011;0.8065196;IRRE
induce regression tree on the negative gradient;1.8591628;-1.5779598;-0.69871587;1.1872588;-0.4692426;3.7725353;-
no inplace multiplication;-0.74094963;2.6013143;1.0815512;-5.790335;-0.009973492;-1.1514822;-
update tree leaves;-3.0510023;-1.4008968;1.4578837;2.024283;1.0983906;0.3667966;CODE
add tree to ensemble;0.50672275;-3.1416638;0.40819663;2.8903618;4.395487;1.3651931;TASK
do oob;-1.8041439;-3.0583446;2.4137492;-0.3918872;0.6840619;-2.1834328;CODE
self n estimators is the number of additional est to fit;1.7206649;0.71465296;-0.57162684;1.0405502;-0.44212034;3.2991846;TASK
if do oob resize arrays or create new if not available;0.79424006;2.9006536;-0.6323525;-0.10722172;0.6524868;0.82025236;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
ignore missing values when computing bin thresholds;3.8711674;4.6632104;-2.8263893;-1.785885;-0.86431766;-1.8397192;IRRE
the data will be sorted anyway in np unique and again in percentile so we do it;4.437105;0.67792284;0.04845979;-3.0415802;0.7689812;1.5017189;CODE
here sorting also returns a contiguous array;1.1091738;3.6595657;2.7919786;-3.753296;-0.8001931;-2.0566828;IRRE
we could compute approximate midpoint percentiles using the output of;5.8392735;0.39246565;2.2886355;-2.3503237;-1.2210872;0.70753944;IRRE
np unique col data return counts instead but this is more;5.056084;1.7311914;-1.8428457;-2.8402038;-1.1528413;-2.258515;CODE
work and the performance benefit will be limited because we;-0.16754325;-1.8650911;3.9405015;4.9179683;1.1164968;0.97682154;CODE
work on a fixed size subsample of the full data;7.285013;1.4491336;0.84240556;-2.4891014;2.1739564;1.911996;-
we avoid having inf thresholds inf thresholds are only allowed in;1.3758276;1.3718419;-3.2589538;2.0840762;0.28258857;2.6891367;CODE
a split on nan situation;1.5239899;3.1511033;1.2357843;-0.17512923;-1.0317378;-2.3731585;-
min is 3 at least 2 distinct bins and a missing values bin;1.6083122;3.1720622;-0.6735169;-4.909179;1.2762512;-3.8792388;IRRE
validate is categorical and known categories parameters;1.1611812;1.6691594;-3.5329225;2.0814664;4.031461;-2.5253692;IRRE
since categories are assumed to be encoded in;-1.140899;-2.087042;-1.7040197;0.6047043;3.032811;1.1945168;-
0 n cats and since n cats max bins;-0.3474801;0.23902951;1.7767165;-3.49611;1.5419114;-4.859507;-
the thresholds are the unique categorical values this will;3.8630958;0.8202069;-0.31107503;-1.2992784;3.9426904;-2.2069626;IRRE
lead to the correct mapping in transform;-0.4297536;1.6944577;1.0813804;-2.9796288;-1.6620141;2.5442743;CODE
todo complexity is o n categorical features 255 maybe this is;1.6352308;-2.671488;-0.99163127;-0.98762375;3.128309;-2.6602993;TASK
worth cythonizing;-0.7564093;1.360151;2.6998346;0.38863784;-1.7369013;-0.29621625;-
if there is a preprocessor we let the preprocessor handle the validation;-2.0038385;3.4428852;-4.0611134;5.696016;2.8618345;0.49666524;CODE
otherwise we validate the data ourselves;3.845053;0.46590012;-0.5789601;4.400314;1.7079096;-1.8205229;-
at this point reset is false which runs during fit;-1.4962504;3.9801254;-1.2847735;2.446268;-2.1640894;2.1661718;CODE
check categories found by the ordinalencoder and get their encoded values;0.60667396;1.1957445;-1.4918858;-2.1209302;2.7823853;-2.7202573;IRRE
the columntransformer s output places the categorical features at the;0.8047483;-1.548831;-1.9285434;-3.4239979;0.6412218;0.2503267;TASK
beginning;-3.4532704;-1.9971553;6.236535;0.69577056;0.5025393;-2.5771558;-
ordinalencoder always puts np nan as the last category if the;-0.5662395;1.2464228;-4.0412073;-3.197073;0.41426066;-1.2930481;-
training data has missing values here we remove it because it is;1.9539207;1.4635073;-2.5217717;0.122178346;-0.9642571;-1.9338623;IRRE
already added by the binmapper;-3.780371;-4.839448;0.9446526;0.273451;2.459879;0.32070005;TASK
special code for pandas because of a bug in recent pandas which is;-0.47421443;-2.0313447;-3.8342319;-2.0766933;-4.324765;-2.4258647;CODE
fixed in main and maybe included in 2 2 1 see;-6.475605;-0.51355857;-2.0294645;-0.6445399;0.07157583;1.7016991;CODE
https github com pandas dev pandas pull 57173;-2.5951846;-6.027988;-3.3525298;-2.4003866;-5.857855;-3.0902925;CODE
also pandas versions 1 5 1 do not support the dataframe interchange;-1.3791795;-2.2938278;-5.0124288;-2.8499212;-5.1109614;0.33415508;CODE
at this point validate data was not called yet because we use the original;-1.3711417;2.605551;-3.397407;5.4808636;0.8029031;-0.9076076;IRRE
dtypes to discover the categorical features thus feature names in;1.4421266;-6.0738435;-2.344114;-1.0300725;2.2434285;-2.3786507;TASK
is not defined yet;-6.987583;-1.8310225;0.14110932;1.5245668;0.443999;-1.6567812;CODE
check for feature names;-1.0748018;-1.3242146;-0.752423;3.1614423;2.3441522;-3.0883367;TASK
check for categorical features as indices;3.0870092;1.1998928;-2.1559343;-2.024866;2.7219799;-3.2087352;TASK
todo incorporate sample weights here in resample;6.4144125;0.4681594;-0.43345645;0.4687728;-0.03606018;3.1849906;TASK
a higher score is always better higher tol means that it will be;0.3225178;1.3297396;-0.17182541;2.647511;1.61074;-1.3391246;-
harder for subsequent iteration to be considered an improvement upon;2.2698467;0.99601334;3.1184711;5.569124;1.2847784;-0.30870652;TASK
the reference score and therefore it is more likely to early stop;0.65933216;1.795065;1.4847169;5.421135;0.8587889;-1.1551888;CODE
because of the lack of significant improvement;-1.3025426;-0.5466245;1.0739925;3.7515874;-1.8274426;0.9899317;TASK
x binned self bin mapper fit transform x f aligned array;3.394793;1.6016779;-2.890846;-6.0049596;-2.1196117;2.0326848;CODE
x binned self bin mapper transform x f aligned array;1.9408935;1.337319;-2.5744703;-6.610992;-1.4623904;1.2091829;CODE
we convert the array to c contiguous since predicting is faster;6.421097;0.5571326;1.182872;-2.295371;-1.1440036;-1.1073711;-
with this layout training is faster on f arrays though;4.4045286;-2.2857404;1.2781144;-1.3758318;0.58095276;3.1809354;CODE
we intentionally decouple the number of threads used at prediction;3.98351;-3.9827673;0.4420767;5.387936;0.3836008;1.0660568;CODE
time from the number of threads used at fit time because the model;2.8124828;-0.23659818;0.57747394;1.6594743;-1.4973675;1.6985334;CODE
can be deployed on a different machine for prediction purposes;1.152241;-3.6725485;-0.33305913;3.7762566;1.0631258;3.0446796;CODE
note that the learning rate is already accounted for in the leaves;2.3191745;-3.3126965;0.9867559;3.3970385;0.34410164;-0.012807675;CODE
values;2.3852327;2.8150017;4.596041;-3.805712;2.3660839;-6.126723;IRRE
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
todo this could be done in parallel;0.8242713;0.39249304;6.721159;-0.6700201;3.2262557;0.1766124;CODE
np argmax 0 5 0 5 is 0 not 1 therefore 0 not 0 to be;1.3437433;2.9880302;-4.1773777;-6.7230353;-3.7606049;-0.76666135;CODE
consistent with the multiclass case;0.30658552;-0.84650105;-2.3757923;3.1891885;6.329295;1.9328136;CODE
np argmax 0 0 is 0 not 1 therefore 0 not 0;0.84617203;2.9804647;-4.8503656;-6.454908;-4.356577;-0.27992415;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
start and stop indices of the node in the splitter partition;1.7348609;1.5240953;0.560674;-3.4695;1.3753362;2.1793904;CODE
array concretely;0.5766051;0.9816258;3.7023952;-2.3171906;2.5149336;-4.23017;-
self sample indices view self splitter partition start stop;1.0220888;1.3295636;-2.061099;-1.0366154;0.100315355;3.073318;CODE
please see the comments about splitter partition and;-0.09144351;-2.011224;1.7523285;-2.1101925;3.4604962;2.7524157;-
splitter split indices for more info about this design;3.4096758;-0.9053553;0.6221042;-4.623778;4.0454154;1.6264654;CODE
these 2 attributes are only used in update raw prediction because we;1.0119679;-2.0052145;-2.0276172;2.64075;1.2694181;0.94128597;META
need to iterate over the leaves and i don t know how to efficiently;3.1124551;0.092953645;5.5042205;-1.9560815;-0.003768611;-1.7116342;TASK
store the sample indices views because they re all of different sizes;5.4731274;1.0200691;0.8769488;-3.1681986;2.7950275;5.1792855;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
the dtype of feature idx is np intp which is platform dependent here we;-1.5872551;-3.873112;-6.497649;-2.2726932;1.4026642;0.38637114;CODE
make sure that saving and loading on different bitness systems works without;-3.1076143;1.3528938;-3.3654516;0.48212364;-0.846107;2.8941832;CODE
errors for instance on a 64 bit python runtime np intp np int64;-2.6053092;0.12229995;-6.4533634;-2.4770143;-4.878237;-2.9248307;CODE
while on 32 bit np intp np int32;-4.044425;-0.18746383;-3.766423;-3.8675451;-2.3962083;-1.5623298;CODE
todo consider always using platform agnostic dtypes for fitted;1.8907981;-2.8616288;-5.529865;0.50963086;-0.5334218;2.71989;CODE
estimator attributes for this particular estimator this would;2.2756746;0.49761114;2.1598728;1.1356153;1.5783812;2.7141004;CODE
mean replacing the intp field of predictor record dtype by an int32;2.3719156;0.005555103;-4.5655932;-1.9405657;-1.1315222;1.5432016;CODE
field ideally this should be done consistently throughout;0.90852916;1.4311421;3.8336673;3.2461586;4.33429;1.7254239;CODE
scikit learn along with a common test;3.360351;-8.601389;-4.6145096;3.9377048;-2.7256653;-6.5076685;IRRE
assert bin thresholds i shape 254 255 1;2.5579064;4.310963;-3.818457;-1.4935168;0.6781178;-5.077853;CODE
assert bin thresholds i shape 127 128 1;2.431482;4.4047036;-3.4592984;-1.149456;-0.703525;-4.9676156;CODE
max bins is the number of bins for non missing values;0.9730692;2.5871987;-1.1518143;-3.710005;-0.018624123;-3.1702676;IRRE
check that the binned data is approximately balanced across bins;5.839041;4.6940823;-1.9034748;-2.9418516;-0.81559473;-2.7672238;-
max bins is the number of bins for non missing values;0.9730692;2.5871987;-1.1518143;-3.710005;-0.018624123;-3.1702676;IRRE
max bins is the number of bins for non missing values;0.9730692;2.5871987;-1.1518143;-3.710005;-0.018624123;-3.1702676;IRRE
adding more bins to the mapper yields the same results same thresholds;3.6260216;1.6787121;-2.9351327;-0.33604363;-0.4137746;0.90573996;TASK
max bins is the number of bins for non missing values;0.9730692;2.5871987;-1.1518143;-3.710005;-0.018624123;-3.1702676;IRRE
check that n bins non missing is n unique values when;2.0327466;4.14349;-2.1174724;-3.0382762;0.65512085;-4.761194;IRRE
there are not a lot of unique values else n bins 1;2.4688437;1.9630264;-0.3926332;-5.0899363;1.9815786;-5.049077;IRRE
make sure bin thresholds are different when applying subsampling;4.540197;3.253699;-3.3595803;-0.6559452;-1.2069743;1.2546142;CODE
0 0 0 255 missing value;-0.45511177;4.9772997;-4.5335546;-6.276265;-2.717826;-4.390328;IRRE
0 0 0 2 missing value;-0.023520024;5.174233;-1.9243275;-5.6468596;-2.0563345;-5.3746696;IRRE
check for missing values make sure nans are mapped to the last bin;1.797252;4.4996834;-3.4581852;-2.784789;-4.5497084;-4.655862;IRRE
and that the binmapper attributes are correct;-1.1964123;-1.6645182;-4.07317;1.3700825;3.6867082;1.7352984;META
make sure infinite values are properly handled;0.5166683;7.3631244;0.096175954;0.6957859;-1.7729764;-3.4476614;IRRE
basic test for categorical features;2.5234878;0.3500872;-0.30429906;0.7376563;1.956221;-6.708751;TASK
we make sure that categories are mapped into 0 n categories 1 and;0.028962089;-0.86348593;-1.5421809;-0.11790067;3.5629628;-0.3401559;CODE
that nans are mapped to the last bin;0.5251483;0.90350574;-0.13987018;-4.7765813;-1.9859233;-2.7912524;-
negative categories are mapped to the missing values bin;-0.10136101;1.9698533;-2.7930431;-2.397295;-0.49919036;-0.9224924;IRRE
i e the bin of index missing values bin idx n bins 1;-0.18710342;1.9107516;-2.0222025;-6.1173263;0.10759766;-4.75912;IRRE
unknown positive categories does not happen in practice and tested;0.215571;0.6484631;-4.2573605;4.227849;2.1233122;-4.405434;IRRE
for illustration purpose;-1.5736758;-3.029909;8.345542;-0.6534882;-0.41548717;-0.27870983;CODE
make sure sklearn has the same predictions as lightgbm for easy targets;1.7775563;-4.7924585;-4.2689934;2.4553025;-3.3549786;-0.51607984;CODE
in particular when the size of the trees are bound and the number of;1.4733871;-0.5858975;3.7764347;0.65114695;2.5845025;-0.76303524;-
samples is large enough the structure of the prediction trees found by;6.460411;-4.648483;-0.998213;4.049929;1.9099586;-0.674101;CODE
lightgbm and sklearn should be exactly identical;-0.16436645;-5.247083;-5.3353467;-0.45877117;-2.1484973;0.36669648;-
notes;-2.3740342;-3.2439115;6.1178803;0.32522762;-0.195891;-3.8100605;TASK
several candidate splits may have equal gains when the number of;3.0780947;1.2018533;1.3598648;0.67304164;5.263794;-0.9209586;-
samples in a node is low and because of float errors therefore the;3.9148288;3.2250872;-3.1046598;-1.6649302;-3.0856366;-1.4444293;CODE
predictions on the test set might differ if the structure of the tree;3.492407;1.8614334;-1.3345884;5.4402585;1.8927627;-3.3997421;IRRE
is not exactly the same to avoid this issue we only compare the;-0.19145033;1.745122;-1.7797703;6.3454986;-0.04239292;2.9526603;CODE
predictions on the test set when the number of samples is large enough;6.62564;1.5662847;0.7431699;7.006801;0.3775495;-2.8918927;IRRE
and max leaf nodes is low enough;-0.019040914;0.4586794;1.5917385;0.32611552;0.11442689;1.9741135;-
to ignore discrepancies caused by small differences in the binning;4.2585564;2.482884;-1.6367601;0.37713832;-0.7003603;-1.0067362;CODE
strategy data is pre binned if n samples 255;3.316806;3.2586298;-0.9117879;0.6211305;3.1263359;-1.7475454;-
we don t check the absolute error loss here this is because;0.6492448;3.5156538;-3.049054;2.687231;-4.302366;-0.6075398;CODE
lightgbm s computation of the median used for the initial value of;1.3672808;-0.19059165;-1.0883445;-3.2086253;-2.1182528;1.4263915;IRRE
raw prediction is a bit off they ll e g return midpoints when there;2.8970087;-0.75448984;0.36152452;4.015698;-3.49451;0.59132653;CODE
is no need to since these tests only run 1 iteration the;2.1920276;4.4985967;-1.7361747;5.815636;-0.30024186;-4.046906;IRRE
discrepancy between the initial values leads to biggish differences in;2.5726078;3.7946227;-2.9553697;-2.055603;-4.4812307;-0.54300606;IRRE
the predictions these differences are much smaller with more;4.6260023;-1.8877217;1.1388102;3.5335557;-1.1915306;0.17540039;-
iterations;1.8315903;-0.21061742;6.7108765;1.8012995;1.6812211;-4.3973346;-
make the target positive;-0.32586524;2.3487396;2.8978035;2.225035;-0.20079377;-1.8699747;-
bin data and convert it to float32 so that the estimator doesn t;1.5111278;2.2633243;-3.2559755;-3.6516542;-3.5309815;-0.47937435;CODE
treat it as pre binned;-3.2009299;1.5430053;0.6394282;1.4526876;2.56599;1.2181569;-
we need x to be treated an numerical data not pre binned data;4.118491;3.2473109;-2.3575175;-3.5331893;0.50446886;-0.6152398;-
more than 65 of the predictions must be close up to the 2nd decimal;2.6265237;-0.8412508;1.2304908;1.979081;-2.5289824;-3.2670372;CODE
todo we are not entirely satisfied with this lax comparison but the root;-1.1707985;1.6663692;0.35944656;2.6930287;-1.2375543;0.3726;TASK
cause is not clear maybe algorithmic differences one such example is the;1.1520817;0.02498723;-2.317033;1.5413358;0.9646763;-2.1517463;META
poisson max delta step parameter of lightgbm which does not exist in hgbt;-1.4238236;1.8552811;-3.442694;-1.1063806;-1.20543;3.7006721;TASK
less than 1 of the predictions may deviate more than 1e 3 in relative terms;2.7070014;-0.0462101;-1.9909763;1.8565154;-1.779055;-0.745837;-
less than 1 of the predictions may deviate more than 1e 4 in relative terms;3.1471565;0.30872843;-1.6325907;2.256878;-2.3913887;-0.65457225;-
same as test same predictions regression but for classification;3.4715273;-1.2225177;-0.019211387;5.7707915;2.185183;-2.0494115;IRRE
bin data and convert it to float32 so that the estimator doesn t;1.5111278;2.2633243;-3.2559755;-3.6516542;-3.5309815;-0.47937435;CODE
treat it as pre binned;-3.2009299;1.5430053;0.6394282;1.4526876;2.56599;1.2181569;-
we need x to be treated an numerical data not pre binned data;4.118491;3.2473109;-2.3575175;-3.5331893;0.50446886;-0.6152398;-
same as test same predictions regression but for classification;3.4715273;-1.2225177;-0.019211387;5.7707915;2.185183;-2.0494115;IRRE
bin data and convert it to float32 so that the estimator doesn t;1.5111278;2.2633243;-3.2559755;-3.6516542;-3.5309815;-0.47937435;CODE
treat it as pre binned;-3.2009299;1.5430053;0.6394282;1.4526876;2.56599;1.2181569;-
we need x to be treated an numerical data not pre binned data;4.118491;3.2473109;-2.3575175;-3.5331893;0.50446886;-0.6152398;-
assert more than 75 of the predicted probabilities are the same up to;4.2319694;3.3779204;-1.4818846;6.1131816;-0.03496745;-3.5560455;CODE
the second decimal;-1.0707105;0.6068532;3.409137;-3.20858;-1.8749491;-5.117636;-
assert more than 75 of the predicted probabilities are the same up;4.2671347;3.4595668;-1.7195584;5.8629594;-0.5222776;-3.4788113;CODE
to the second decimal;-1.0949664;0.9570014;3.982116;-2.948923;-2.3135204;-4.5954576;-
take care that x coef intercept 0;-0.61342406;2.8626635;-2.2619784;-3.336545;-4.9575896;0.542198;CODE
for an exponential distribution with rate lambda e g exp lambda x;-2.021724;-0.031369526;2.1021128;0.33561772;-0.12697342;2.1906657;CODE
the quantile at level q is;-0.38922074;1.1207137;2.4605682;-0.74506813;0.68346095;-0.42607278;-
quantile q log 1 q lambda;-1.342534;1.6532023;0.5665241;-1.2606572;-0.5737132;-0.5198849;CODE
scale 1 lambda quantile q log 1 q;0.97698724;1.6793118;0.68453354;-2.081803;-1.9603008;1.7950937;CODE
we are overfitting;1.3312268;-0.604685;1.8668399;4.0107245;-1.5737841;-0.14785083;-
test that valueerror is raised if either one y i 0 or sum y i 0;2.6623356;6.212869;-3.9413426;-0.041539397;-3.5523856;-6.6708183;IRRE
for poisson distributed target poisson loss should give better results;3.6906526;0.6789012;-0.3177962;3.5003405;-1.8019016;1.6828121;IRRE
than least squares measured in poisson deviance as metric;2.4590583;0.28470054;-0.8939156;0.0047735902;-3.2552516;3.7126052;-
we create a log linear poisson model and downscale coef as it will get;4.0487595;0.3353442;2.8559458;0.57119083;-0.9021011;3.9947448;IRRE
exponentiated;-4.041523;-0.73016334;2.3329694;-1.4224738;0.75904506;-2.290021;-
squared error might produce non positive predictions clip;1.7760448;0.96997863;-4.224978;2.7371223;-5.7971563;-0.15086433;CODE
make sure training and validation data are binned separately;2.9626586;1.1069555;-2.8393672;2.0064394;2.4373071;-0.5231309;-
see issue 13926;-7.02036;-3.1888795;-1.9587926;0.8627483;-1.0196307;-3.2447028;-
note that since the data is small there is no subsampling and the;7.8858757;1.5324838;-0.007199107;-1.4347836;-0.69342655;2.7222085;TASK
random state doesn t matter;0.18040013;1.3418344;2.5847924;2.6859064;1.0673456;-1.5631906;IRRE
sanity check for missing values support with only one feature and;0.66433895;3.857383;-4.02024;1.7057096;1.777215;-1.3661114;IRRE
y isnan x the gbdt is supposed to reach perfect accuracy on the;1.5181373;-0.60168445;-2.6403472;0.033598516;-2.4338434;-0.90125847;-
training set;2.5613565;-3.9551353;3.8796027;0.98318845;2.6271846;-1.2734559;IRRE
make sure the estimators can deal with missing values and still yield;3.0193975;4.4823575;-2.1015215;3.1584883;-3.7292268;0.32769555;IRRE
decent predictions;2.460754;-1.5641787;3.4836032;4.467055;-2.142535;-2.805264;-
non regression test for issue 14018;-0.6171884;4.894773;-4.430771;3.9523246;-4.0886517;-5.712586;IRRE
make sure we avoid zero division errors when computing the leaves values;3.2994518;3.528384;-2.9746752;-3.7922497;-2.576;-2.982386;IRRE
if the learning rate is too high the raw predictions are bad and will;4.2198706;-3.5724854;-0.95527834;6.2773566;-0.936527;0.123150066;-
saturate the softmax or sigmoid in binary classif this leads to;4.2288895;-0.50499886;-3.9249716;-2.2372804;2.4782348;0.4478035;CODE
probabilities being exactly 0 or 1 gradients being constant and;2.192404;0.21152185;-0.8800516;-0.6862561;-0.32550237;1.9662387;CODE
hessians being zero;-0.12337673;0.15955262;-2.9881566;-2.3231351;-4.791414;1.8950144;-
make sure that the small trainset is stratified and has the expected;-0.7975597;2.9741123;1.3441058;1.4608706;-1.7639164;1.4129883;IRRE
length 10k samples;4.530447;0.28014007;0.54694086;-1.1128446;0.9329379;-3.5359926;-
compute the small training set;7.768333;-2.4385219;1.0468931;-0.62475455;3.2384284;-0.8754731;IRRE
compute the class distribution in the small training set;5.941491;-3.4012506;-0.52930635;1.2560121;3.512437;0.33103004;IRRE
test that the small training set has the expected length;5.0489855;1.8008863;0.87785083;4.101047;0.97309715;-3.333867;IRRE
test that the class distributions in the whole dataset and in the small;6.0553446;-0.108391814;-1.8621613;3.8862982;2.5409186;-2.0676775;IRRE
training set are identical;2.9611552;-1.0729368;-0.06341634;1.4598486;2.5860918;0.14386918;IRRE
compare the buit in missing value handling of histogram gbc with an;3.529819;3.1966891;-3.1112726;-2.5004742;0.42071977;-2.5562975;IRRE
a priori missing value imputation strategy that should yield the same;2.502907;3.957032;-0.52575636;3.2706718;2.9213028;0.2914624;IRRE
results in terms of decision function;3.2512214;0.9194858;2.1233025;2.2364874;3.259468;-2.0035293;CODE
each feature containing nans is replaced by 2 features;2.4123657;1.2740446;-2.0683825;-2.7835488;0.2159169;-1.1133231;TASK
one where the nans are replaced by min feature 1;2.902214;-1.3400849;0.6288148;-2.6066043;1.4032086;-0.62835395;TASK
one where the nans are replaced by max feature 1;1.9793524;-2.0327218;0.8231878;-2.1475573;1.1891208;-0.7630482;TASK
a split where nans go to the left has an equivalent split in the;0.8744801;1.1552436;1.6289788;-4.347774;0.47356465;-2.525808;CODE
first min feature and a split where nans go to the right has an;1.3959469;0.48749185;2.4106667;-3.0203886;-0.2633897;-0.9837761;TASK
equivalent split in the second max feature;3.4096498;1.0741457;0.965547;-1.053642;4.517632;2.2518504;TASK
assuming the data is such that there is never a tie to select the best;6.3696566;1.6646271;2.7474687;1.4855545;3.4372914;-0.115209684;CODE
feature to split on during training the learned decision trees should be;3.4954743;-4.7994;1.0590101;3.412353;5.188173;0.4728786;TASK
strictly equivalent learn a sequence of splits that encode the same;3.4262488;-1.9222634;-0.55990726;-0.47477156;4.8113184;0.65858614;-
decision function;1.6420257;0.41849428;4.162715;1.1952342;3.07233;-2.7374961;CODE
the minmaximputer transformer is meant to be a toy implementation of the;0.0986041;-2.5941012;0.83155406;-0.7696861;0.3724226;3.838695;TASK
missing in attributes mia missing value handling for decision trees;1.0662036;-0.44788352;-3.9590266;1.5166019;2.9357998;0.15794249;IRRE
https www sciencedirect com science article abs pii s0167865508000305;-1.7900165;-4.312098;0.46654105;0.48279482;-0.39217773;-1.061442;CODE
the implementation of mia as an imputation transformer was suggested by;-0.86193824;0.7816532;-0.41592404;1.1879853;0.3834286;1.47733;TASK
remark 3 in arxiv 1902 06931;-4.68353;0.6464244;-3.0221856;-0.94145185;1.5252466;1.5951502;-
pre bin the data to ensure a deterministic handling by the 2;3.000604;2.364991;-0.861224;0.41960457;3.2369847;-2.3467474;CODE
strategies and also make it easier to insert np nan in a structured;3.4534297;-0.1808544;-0.62912095;-0.99947864;0.71155614;-0.5446444;CODE
way;-1.5039655;-2.677613;5.043886;1.0283071;0.34958398;-1.7420157;-
first feature has missing values completely at random;1.6350374;3.4970856;-3.0660272;1.7167389;-1.0873666;-1.1866057;IRRE
second and third features have missing values for extreme values;2.3277748;2.9016192;-3.5272472;-2.3793821;-1.7149279;-0.799286;IRRE
censoring missingness;-0.7639109;0.7392635;-1.2649652;3.2901263;-0.09918644;1.3128123;-
make the last feature nan pattern very informative;3.1351922;0.7978773;0.410824;-1.719201;0.038024846;-0.23528628;TASK
check that there is at least one missing value in each feature;1.4340954;4.462609;-1.7524086;1.5885456;2.0808673;-3.4847064;TASK
let s use a test set to check that the learned decision function is;3.5100772;2.0948384;0.02267837;6.1509614;2.4513228;-4.8411264;IRRE
the same as evaluated on unseen data otherwise it could just be the;4.103983;0.7934155;-0.6214362;1.237242;2.3178055;-1.4980869;CODE
case that we find two independent ways to overfit the training set;3.9735076;-1.309699;0.6757977;4.594885;4.636963;2.8472557;IRRE
n samples need to be large enough to minimize the likelihood of having;5.4506974;1.8858284;-0.15771526;2.1641245;2.0451982;-0.4376927;TASK
several candidate splits with the same gain value in a given tree;2.9910085;0.3358108;-0.16380532;-0.2652175;5.5912886;-0.6388492;IRRE
use a small number of leaf nodes and iterations so as to keep;2.7504742;0.7515242;4.5345397;-0.06613034;1.3880711;1.3057108;-
under fitting models to minimize the likelihood of ties when training the;6.1700773;-2.6889968;2.0340989;4.6620975;2.8099139;1.6949697;CODE
model;1.6850569;-3.146167;5.856185;2.3733578;2.0956028;-1.8042274;-
check that the model reach the same score;4.048771;4.419824;1.1152908;5.5511355;1.768625;-3.2370496;-
check the individual prediction match as a finer grained;7.1554127;0.6848352;-0.9595271;4.588824;1.2899125;-1.3915151;-
decision function check;1.6869284;4.0318103;1.4505095;2.6365538;2.633849;-5.5559964;CODE
basic test for infinite values;0.41892406;6.9746184;2.1637242;1.7164382;-2.0427425;-8.018556;IRRE
high level test making sure that inf and nan values are properly handled;3.4444387;5.8512435;-3.8908803;2.2708187;-3.1886177;-4.248223;IRRE
when both are present this is similar to;-3.0741155;0.087209724;5.349042;2.25076;2.4115758;-0.5527868;CODE
test split on nan with infinite values in test grower py though we;3.0101645;4.491465;-4.110592;-0.2525467;-4.8741527;-2.9820263;IRRE
cannot check the predictions for binned values here;2.9916897;1.4556918;-2.9094512;-0.044309404;-3.3909621;-5.0312567;IRRE
regression tests for 14709 where the targets need to be encoded before;2.46748;1.8619851;-3.8330986;3.1967778;-1.6923959;-4.3230085;CODE
to compute the score;3.3816357;1.3565829;3.6660786;-0.63273823;1.7917006;-6.750425;-
make sure setting a sw to zero amounts to ignoring the corresponding;-0.22174469;4.4245677;-2.5596662;-0.041796114;-2.919974;1.268523;IRRE
sample;1.7340889;-0.29218516;6.123778;1.5984565;2.6697383;-5.329025;-
ignore the first 2 training samples by setting their weight to 0;5.2963414;3.8202195;-1.6114546;1.3060756;0.457311;1.5679027;IRRE
make sure setting a sw to zero amounts to ignoring the corresponding;-0.22174469;4.4245677;-2.5596662;-0.041796114;-2.919974;1.268523;IRRE
sample;1.7340889;-0.29218516;6.123778;1.5984565;2.6697383;-5.329025;-
ignore the first 2 training samples by setting their weight to 0;5.2963414;3.8202195;-1.6114546;1.3060756;0.457311;1.5679027;IRRE
ignore the first 2 training samples by setting their weight to 0;5.2963414;3.8202195;-1.6114546;1.3060756;0.457311;1.5679027;IRRE
high level test to make sure that duplicating a sample is equivalent to;3.2155986;4.380452;-0.6074691;4.3722568;2.611065;-2.8555713;IRRE
giving it weight of 2;-1.2641499;1.5791436;4.293622;-0.9288533;0.52965605;-2.3224616;-
fails for n samples 255 because binning does not take sample weights;2.6394837;1.902116;-5.4303117;-1.6237323;-1.9040638;-0.8902303;CODE
into account keeping n samples 255 makes;4.6070127;0.56270355;-1.0079277;-0.7575906;3.5831006;-2.3425994;CODE
sure only unique values are used so sw have no effect on binning;1.8963048;2.726206;-1.6831185;-1.2650684;2.6784003;0.82623494;IRRE
this test can t pass if min samples leaf 1 because that would force 2;1.4351958;6.186041;-2.160689;2.7224197;0.56622297;-5.142403;IRRE
samples to be in the same node in est sw while these samples would be;3.9355845;0.6470231;-0.43775523;1.2839624;3.0936415;0.74566483;CODE
free to be separate in est dup est dup would just group together the;-1.0061604;0.9725403;3.6952174;-0.1550206;5.3242445;1.2368281;CODE
duplicated samples;2.7193446;1.6726913;-0.0057551623;1.643195;2.2693832;-1.8678716;-
create dataset with duplicate and corresponding sample weights;6.238715;-0.36082065;0.6190011;-1.1438929;3.1017258;1.2698375;IRRE
checking raw predict is stricter than just predict for classification;3.0496914;0.93427616;-6.0038424;4.998848;-1.1511236;-0.9184238;CODE
for losses with constant hessians the sum hessians field of the;0.6044997;-3.0171084;-1.1654242;-0.47490332;-2.0559113;3.255747;CODE
histograms must be equal to the sum of the sample weight of samples at;4.1257925;1.948136;0.7971142;-2.3324754;-0.21899053;-1.2722301;TASK
the corresponding bin;-0.5724767;0.11683009;2.9618707;-4.604247;2.6210077;-4.023969;-
while sample weights are supposed to be positive this still works;2.7664495;4.068361;-3.5103366;3.157061;-2.4511054;-0.90449846;CODE
build sum sample weight which contains the sum of the sample weights at;4.3422093;0.6713102;0.94142383;-0.84228534;1.0938039;1.0627135;-
each bin for each feature this must be equal to the sum hessians;4.989586;-1.4087679;-2.0122044;-5.0879793;-0.03921091;1.6507615;CODE
field of the corresponding histogram;2.9688957;-1.0174408;2.400519;-6.0222344;0.52610856;0.46058786;CODE
build histogram;3.992935;-2.8492148;4.645487;-4.972378;-0.3208201;-1.8937498;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 16179;-3.2582889;-9.947592;-6.1367683;0.06960991;-5.028062;-5.5172973;CODE
there was a bug when the max depth and the max leaf nodes criteria were;-1.0246856;0.8525226;-1.8857297;0.65226233;-0.76167226;3.1213405;-
met at the same time which would lead to max leaf nodes not being;0.24295981;2.044256;0.63746446;0.21643025;-0.7870756;0.9846512;-
respected;-2.876229;-1.9269257;3.796081;-0.70726657;0.14933915;-1.750796;-
assert tree get n leaf nodes 3 would be 4 prior to bug fix;-1.0956482;3.5228374;-3.7451808;3.8104515;2.790613;-3.191262;CODE
non regression test for 16661 where second fit fails with;0.59309363;5.0914483;-3.731283;2.0653806;-3.304179;-3.308026;IRRE
warm start true early stopping is on and no validation set;-0.18093698;2.9928863;-1.5461303;4.470848;-2.5009518;0.69293946;IRRE
does not raise on second call;-3.919758;4.879912;2.4083745;2.6302426;-1.8598319;-0.6078213;CODE
raw predict should never be called with scoring as a string;1.5381081;0.82;-3.121233;3.59121;-0.8913223;-0.79095054;IRRE
for scorer is called twice train and val for the baseline score and twice;0.36802095;0.7596588;2.420451;0.9177094;2.8879745;-0.7611908;CODE
per iteration train and val after that so 6 times in total for max iter 2;2.0987453;0.7326102;1.8624823;0.20102252;1.3538677;-1.5440205;CODE
non regression test for 22907;0.6835053;3.5953555;-3.923794;2.954893;-3.2587097;-6.666762;IRRE
class weight is the same as sample weights with the corresponding class;3.283644;-0.6299473;-1.400851;0.75138366;2.3865821;1.8255981;IRRE
check that sample weight and class weight are multiplicative;5.038449;3.0770671;-2.7447648;0.95371515;2.55848;-1.9821092;IRRE
make imbalanced dataset;6.135995;0.1424007;0.78004205;0.21998143;1.81627;-0.865856;IRRE
class weight balanced is the same as sample weights to be;3.6768734;0.44443482;-0.8940426;1.3533162;2.6616976;0.7728951;IRRE
inversely proportional to n samples n classes np bincount y;4.7015557;-0.09028029;-1.9687188;-3.4718237;0.67170167;-0.19830297;IRRE
check that negative values from the second column are treated like a;2.652031;5.8774343;0.37964097;-3.4870822;0.031298686;-5.1400356;IRRE
missing category;-3.6349897;-2.1727078;0.52477735;0.07927358;0.17925495;-2.094936;-
make f cat an informative feature;1.1349369;-4.271108;1.6727691;0.5927372;2.2415972;-0.022426233;TASK
check categories are correct and sorted;1.0720319;1.8008597;0.9036781;1.5307349;1.9248774;-4.8682775;-
construct a target with some noise;1.9983208;0.5130803;1.0973921;2.659326;0.7872544;1.6575339;CODE
construct categorical where 0 a and 1 b and 1 a and 0 b;-0.12388855;0.4279892;0.90296924;-4.2566247;5.334718;-3.4643545;CODE
field names in node struct with np intp types see;-2.4694722;0.25769383;-4.234322;-3.646712;0.6479242;0.30045584;CODE
sklearn ensemble hist gradient boosting common pyx;3.6703818;-5.085481;-4.106061;-0.62521106;-0.29258713;1.2323655;-
simulate loading a pickle of the same model trained on a platform with different;0.90483826;-2.1048923;0.32149768;3.6558092;0.05597681;2.0374966;CODE
bitness that than the platform it will be used to make predictions on;1.1994312;-4.6719484;0.67072016;1.8925538;-0.8045415;-0.6267912;OUTD
make sure that a platform specific pickle generated on a 64 bit;-5.116989;-2.5610712;-3.5545247;-1.1447443;-2.0030859;-0.25947928;CODE
platform can be converted at pickle load time into an estimator;3.1160755;-2.6968398;-0.30256808;2.8813443;-1.0312814;3.5608666;CODE
with cython code that works with the host s native integer precision;-0.3906814;1.659527;-4.157029;-3.5050247;-1.5260494;-2.0552988;CODE
to index nodes in the tree data structure when the host is a 32 bit;-0.3555867;0.10749645;-2.3169036;-4.040836;2.9294832;0.3547889;CODE
platform and vice versa;-3.5270379;-5.1905866;3.0057995;-0.21178219;0.5173916;0.30090877;CODE
this is in particular useful to be able to train a model on a 64 bit linux;-0.5344071;-6.2556663;-0.8446235;0.2992546;1.8723333;0.3528869;CODE
server and deploy the model as part of a 32 bit wasm in browser;-4.559076;-0.37237492;0.46083504;-0.41154975;0.44310018;3.5025246;IRRE
application using pyodide;-2.685424;-4.0188336;-1.4761343;-1.8709557;-1.4076736;-0.12679102;-
non regression test for https github com scikit learn scikit learn issues 28317;-0.012204887;-4.891789;-8.717135;3.3323126;-6.7061396;-6.336292;CODE
generate some test data directly binned so as to test the grower code;2.502601;2.8368065;-2.5062268;1.5405431;0.90040356;-4.0448895;IRRE
independently of the binning logic;0.0051724;1.0775211;1.2838843;0.098989286;3.7348082;-0.5267368;CODE
assume a square loss applied to an initial model that always predicts 0;1.9983939;2.7292044;-1.297995;3.3321483;-3.145788;2.4991624;IRRE
hardcoded for this test;1.1717312;2.995601;-0.20899278;0.54124135;2.2072372;-8.958433;CODE
make sure the samples are correctly dispatched from a parent to its;0.8615481;3.224016;-2.463024;3.3926558;-0.7109508;0.0623264;CODE
children;-2.2731419;-1.1649911;6.467863;0.32024592;0.9331717;-2.8621197;-
each sample from the parent is propagated to one of the two children;2.2034924;0.953172;3.4217584;-0.109595746;3.1366913;0.37066686;CODE
samples are sent either to the left or the right node never to both;0.17799965;2.8885427;0.7403429;0.5330151;-0.5047814;0.05687858;-
the root node is not yet split but the best possible split has;-2.1957176;-0.88597006;0.60934204;-1.5470024;1.0657773;0.8090174;TASK
already been evaluated;-2.2992978;1.6820164;0.4984504;5.4774184;1.0092868;-4.479537;CODE
calling split next applies the next split and computes the best split;2.5039785;2.4523911;1.3123677;0.03562815;1.824415;-2.2937317;IRRE
for each of the two newly introduced children nodes;-0.06121016;-1.0836385;3.5903008;-2.4271228;3.9598944;1.4785601;CODE
all training samples have ben split in the two nodes approximately;4.5499663;-0.6443753;-2.335939;-2.003747;1.6954145;0.09678252;CODE
50 50;-1.4601614;0.07149754;4.8884296;-1.7919494;-0.31229374;-4.524162;-
the left node is too pure there is no gain to split it further;-0.5520996;1.8542249;0.549267;-3.7623782;-1.0881934;1.2971543;CODE
the right node can still be split further this time on feature 1;-1.8859732;-0.21352972;1.0100843;0.96947664;0.65889174;4.393068;TASK
the right split has not been applied yet let s do it now;-3.1993334;1.083437;0.97258776;-0.6086212;0.8635843;-0.18465073;CODE
all the leafs are pure it is not possible to split any further;0.03522664;1.4724061;2.7331212;0.24294676;1.2545477;1.0099337;CODE
check the values of the leaves;0.92798114;4.369229;2.9633708;-1.2662991;-0.77138716;-5.4081116;IRRE
build a tree on the toy 3 leaf dataset to extract the predictor;2.1489275;-3.605035;0.815339;0.39423025;2.9392602;-0.14712791;IRRE
assert grower n nodes 5 2 decision nodes 3 leaves;1.9457698;2.364014;-1.9711624;1.2904059;3.29341;-2.3998795;CODE
check that the node structure can be converted into a predictor;2.267112;2.5332246;-2.78841;0.5630382;0.88018423;0.040000334;CODE
object to perform predictions at scale;5.982339;-2.4655273;4.6582875;2.279031;-0.72902256;1.8657931;CODE
we pass undefined binning thresholds because we won t use predict anyway;2.9420526;0.31784937;-3.7459307;2.1278706;-0.84627503;-0.7332386;CODE
probe some predictions for each leaf of the tree;3.531092;-1.6093695;3.1115558;3.955861;0.9456791;-3.1114461;CODE
each group of 3 samples corresponds to a condition in make training data;4.9389353;0.6475648;0.26752344;-1.6308544;4.7815237;-1.810099;-
check that training set can be recovered exactly;2.792845;1.0882971;-2.1313472;3.9331279;1.8037345;-1.7418438;IRRE
data linear target 3 features 1 irrelevant;3.4478378;-0.2151028;-1.5730101;-1.7437648;0.44381967;1.2890803;TASK
make sure root node isn t split if n samples is not at least twice;3.4695756;3.4408755;-3.5305734;-0.31926483;0.5072805;-0.37259835;-
min samples leaf;3.2837808;1.6063659;1.1091368;-0.915384;1.4094578;-1.142113;-
data linear target 3 features 1 irrelevant;3.4478378;-0.2151028;-1.5730101;-1.7437648;0.44381967;1.2890803;TASK
to assert that stumps are created when max depth 1;0.65138507;2.7608356;0.32016823;2.0645785;1.191052;-1.1968111;IRRE
make sure max depth parameter works as expected;0.10559094;4.3629036;-0.9689083;-2.6408875;-2.9114985;2.3462608;IRRE
data linear target 3 features 1 irrelevant;3.4478378;-0.2151028;-1.5730101;-1.7437648;0.44381967;1.2890803;TASK
make sure that missing values are supported at predict time even if they;3.3147404;2.7786014;-4.6037507;3.6383796;-2.226337;0.56871045;IRRE
were not encountered in the training data the missing values are;2.8014228;1.3860755;-3.4286637;0.43958962;-0.72776234;-2.9213886;IRRE
assigned to whichever child has the most samples;3.95496;1.4538978;3.1901133;0.43509433;5.217321;-1.9397464;IRRE
we pass undefined binning thresholds because we won t use predict anyway;2.9420526;0.31784937;-3.7459307;2.1278706;-0.84627503;-0.7332386;CODE
go from root to a leaf always following node with the most samples;2.3892128;1.9702327;2.6228206;0.97502893;0.39786938;2.1177056;CODE
that s the path nans are supposed to take;-1.0985578;-0.4397596;1.7334887;-0.35019004;-3.0250373;-0.30761343;-
now build x test with only nans and make sure all predictions are equal;5.0216227;3.6707883;-2.7989724;1.9477398;-2.4233975;-4.1554484;IRRE
to prediction main path;2.9188695;-3.8721688;3.9506533;4.203222;0.8872251;0.60475224;CODE
make sure the split on nan situations are respected even when there are;1.2750329;2.7767413;-1.7252392;0.9465923;-1.2462903;-1.0207092;-
samples with inf values we set the threshold to inf when we have a;4.611814;3.1077554;-1.3189641;0.711304;0.31445006;-0.42127538;IRRE
split on nan so this test makes sure this does not introduce edge case;2.579214;5.7528133;-2.7242572;-1.1227171;-1.3811176;-4.288753;CODE
bugs we need to use the private api so that we can also test;-4.46846;-0.31861427;-1.8807064;6.4325657;-2.0738013;-0.97721654;IRRE
predict binned;3.898708;-1.637793;0.6286461;0.56619394;0.4988668;-3.8490148;-
the gradient values will force a split on nan situation;3.6654165;1.5500274;-1.6671942;-2.9068098;-3.3728;1.647399;IRRE
sanity check this was a split on nan;0.37717023;3.041807;-0.5404488;-1.5546564;-3.1028445;-3.6833136;CODE
make sure in particular that the inf sample is mapped to the left child;0.71659344;4.342851;-0.7407705;0.7887431;-0.022199359;2.4588215;-
note that lightgbm fails here and will assign the inf sample to the;-1.769419;-0.90684885;-3.8188558;0.08448358;-0.2728592;2.5531425;TASK
right child even though it s a split on nan situation;-0.8639772;1.8637286;1.8578806;0.27639595;-1.4353096;-1.1089346;-
check that the grower produces the right predictor tree when a split is;0.739703;1.4440036;-2.3231895;1.792039;-0.046677705;-0.8245388;-
categorical;0.37158218;-3.1642597;4.289835;-0.055465456;3.7574751;-4.7597713;-
arbitrary validation but this means ones go to the left;0.7209567;3.8356502;2.0950189;1.2170341;3.2903268;-1.7146257;META
check binned category value 1;0.69712025;2.9431746;-1.1555802;-1.2863436;2.166896;-5.1875744;IRRE
check raw category value 9;0.70862263;2.2885349;-1.4830074;-1.1563712;1.1968701;-4.8591256;IRRE
note that since there was no missing values during training the missing;2.6416228;0.61571544;-2.9205334;2.3226304;0.31803206;-1.183046;IRRE
values aren t part of the bitsets however we expect the missing values;-0.5868561;2.9077547;-3.8327768;-5.0780706;-0.41183272;-1.5109159;IRRE
to go to the biggest child i e the left one;-2.096741;1.2377197;6.274851;-0.17236996;0.13336171;0.0410942;-
the left child has a value of 1 negative gradient;-0.34170204;1.3898518;1.4887649;-3.7409275;-1.6199198;0.93227166;IRRE
make sure binned missing values are mapped to the left child during;-0.6932616;5.3521075;-1.6076175;-2.2418454;-0.04295143;-0.47085905;IRRE
prediction;5.3878164;-2.566415;6.164522;4.8268876;0.24309775;-2.5988433;-
assert allclose prediction binned 1 negative gradient;3.189184;2.6722858;-5.299634;1.5079063;-2.1534967;1.0860358;CODE
make sure raw missing values are mapped to the left child during;-0.12189783;5.6951504;-1.075648;-0.80323803;-0.96667093;0.44449624;IRRE
prediction;5.387814;-2.5664148;6.164522;4.8268886;0.24309698;-2.5988457;-
known cat bitsets np zeros 1 8 dtype np uint32 ignored anyway;-2.5997267;-0.12265857;-8.3296175;-5.0096335;-2.752051;-1.585986;IRRE
make sure that native categorical splits are equivalent to using a ohe;1.1191295;0.14521034;-2.7495735;-0.05036443;2.8487868;0.4245984;-
when given enough depth;-0.2568667;0.113882385;5.2678275;0.81035477;0.31524464;-1.0925816;-
we pass undefined bin thresholds because we won t use predict;2.622564;0.7527001;-3.8025498;1.2297708;-1.3591084;-1.9925584;CODE
ohe needs more splits to achieve the same predictions;2.082494;-0.58681196;1.5439483;3.5664172;1.6992948;1.6874498;TASK
small sample indices below unrolling threshold;4.634739;2.938752;-2.834955;-0.5202898;-1.3226523;0.9511888;-
larger sample indices above unrolling threshold;4.563959;2.5223458;-2.3114197;-0.54129374;-1.0327563;1.7394847;-
make sure the order of the samples has no impact on the histogram;3.7337883;3.7332375;-0.77012885;-1.1337678;-1.2891555;-1.0696933;-
computations;2.8940887;-1.2405083;4.837158;-2.5118415;1.3791417;-4.919025;-
make sure the different unrolled histogram computations give the same;2.8857374;1.8221245;-1.888269;-2.6791217;-2.671254;0.9747938;-
results as the naive one;3.4306374;-3.0005682;2.4137127;4.3764257;2.0232515;-4.186925;IRRE
make sure the histogram subtraction trick gives the same result as the;3.192991;2.5839484;0.5850031;-4.3050437;-3.1394365;-2.2215786;IRRE
classical method;0.7793039;-0.3940011;2.936641;1.0515647;-0.20897841;0.47807476;IRRE
make sure leaves values from left to right are either all increasing;1.7903862;5.110008;1.7527624;-4.0851116;-2.1662738;-1.4900864;IRRE
or all decreasing or neither depending on the monotonic constraint;0.59488964;3.879383;0.9714442;-0.4404642;1.437851;0.9067646;CODE
init gradients and hessians to that of least squares loss;1.9300988;-3.6616313;-1.4011471;0.94245607;-2.1310277;5.2597136;IRRE
make sure infinite values and infinite thresholds are handled properly;3.3584197;4.750777;-0.18746625;1.1266407;-0.99563694;-1.0905643;IRRE
in particular if a value is inf and the threshold is almost inf the;3.688961;3.5412536;0.40525424;0.7431435;-0.16184619;-0.93454444;IRRE
sample should go to the right child if the threshold is inf split on;3.2901547;4.7778897;0.37922716;1.8601598;1.3526453;-0.48302707;-
nan the inf sample will go to the left child;0.45612746;3.9531653;1.794447;-0.57549685;-1.1963708;-1.9904602;-
we just construct a simple tree with 1 root and 2 children;-2.6274397;-1.5600991;2.841869;-0.62944585;4.013292;-1.3647411;CODE
parent node;-3.1033468;-0.09236014;4.690896;-1.4426912;2.252254;0.59133244;-
left child;-3.5163095;0.73506767;4.8712926;-0.54290396;-0.71621865;-1.3448517;-
right child;-3.0740426;-0.34283707;4.1229296;0.15327385;-0.68173724;-1.7879488;-
test predictor outputs are correct with categorical features;2.2287471;1.3310764;-4.678956;1.3812015;-1.1709268;-4.23813;IRRE
we just construct a simple tree with 1 root and 2 children;-2.6274397;-1.5600991;2.841869;-0.62944585;4.013292;-1.3647411;CODE
parent node;-3.1033478;-0.09236122;4.690898;-1.4426897;2.2522533;0.59133244;-
left child;-3.5163095;0.73506767;4.8712926;-0.54290396;-0.71621865;-1.3448517;-
right child;-3.0740426;-0.34283707;4.1229296;0.15327385;-0.68173724;-1.7879488;-
check binned data gives correct predictions;4.3379555;2.7555099;-3.5183756;1.9377085;-2.439366;-5.2111707;-
manually construct bitset;-3.4455225;-0.7618229;-1.19967;-3.8288655;1.4912041;-0.93559045;CODE
check with un binned data;2.2285712;5.6031747;-2.1755884;-1.2954718;1.8774981;-5.6615252;-
check missing goes left because missing values bin idx 6;-1.8823663;6.2289205;-3.2429767;-3.36116;0.045933638;-5.0803065;IRRE
missing and unknown go left;-4.869517;2.4679334;1.860563;-0.72350323;-1.3593314;-3.1911268;-
constant hessian 1 per sample;3.347872;-0.08845144;-1.6982942;-0.9544812;-1.9272416;3.8739686;CODE
this test checks that the values of gradients and hessians are;1.195421;1.65821;-2.9292204;1.707657;-2.956372;-3.49328;IRRE
consistent in different places;1.1895583;2.052674;2.9118762;4.071671;0.9195795;0.9793714;-
in split info si sum gradient left si sum gradient right must be;1.4565744;-0.39964405;-2.816699;-4.3391695;0.21919164;1.4769906;TASK
equal to the gradient at the node same for hessians;0.090284795;-1.4621385;-0.33486855;-1.467148;-1.4126122;3.4848838;CODE
in the histograms summing sum gradients over the bins must be;4.0265083;-0.7565013;-1.8540319;-4.2739396;-1.5390468;0.88006717;TASK
constant across all features and those sums must be equal to the;3.4989016;0.5299707;-1.0848315;-2.7903438;1.2132603;0.51275563;TASK
node s gradient same for hessians;0.5936779;-2.0936837;-1.5649627;-1.7312018;-1.6148443;4.110556;CODE
make sure that si sum gradient left si sum gradient right have their;1.0340242;0.7189686;-3.4936192;-3.1522956;-2.8764307;2.4219062;-
expected value same for hessians;0.18611622;-0.23283266;-0.42318746;-0.49960357;-3.4315655;2.1132312;IRRE
make sure sum of gradients in histograms are the same for all features;5.3468227;-0.18412994;-2.2522707;-2.1864557;-1.0444081;2.0299203;TASK
and make sure they re equal to their expected value;3.5707014;3.6650527;2.2393267;1.3066403;1.7249794;-2.8659306;IRRE
note gradients and hessians have shape n features;2.837052;-5.302998;-1.3183343;-2.3925729;-0.80996245;3.3108017;TASK
we re comparing them to scalars this has the benefit of also;1.545578;-2.1203508;-0.59969264;1.8293258;-0.7707383;1.4478695;CODE
making sure that all the entries are equal across features;4.4212804;2.6782556;0.34706965;0.68298036;4.983593;-1.2231079;TASK
gradients hists sum gradients sum axis 1 shape n features;4.032251;-2.2522361;0.33956245;-5.1326213;-0.8337043;2.0381737;TASK
expected gradient all gradients indices sum scalar;1.8254873;-1.0276675;-0.21899518;-0.48446798;-0.75410944;3.1473408;-
0 is not the actual hessian but it s not computed in this case;-1.1336229;-0.18433449;-4.670335;-2.5504467;-4.6338024;1.3802222;CODE
check that split indices returns the correct splits and that;3.1103523;4.218475;-2.535032;-4.175491;0.23235054;-3.1664593;IRRE
splitter partition is consistent with what is returned;1.6789854;2.3418024;-1.6575373;0.037425224;0.11130922;0.5163002;IRRE
split will happen on feature 1 and on bin 3;-2.6279767;-0.9412128;-1.0046481;0.9055944;2.4391608;1.0073773;TASK
sanity checks for best split;1.5640342;2.1790247;1.5551757;3.3445191;2.9264033;-1.5483292;CODE
check that the resulting split indices sizes are consistent with the;4.6920824;4.0626864;-5.038764;-3.8640895;-1.3358814;-0.4159979;IRRE
count statistics anticipated when looking for the best split;3.90858;0.45473346;3.0092633;2.372562;1.4383776;-2.124601;CODE
try to split a pure node all gradients are equal same for hessians;2.341334;-0.12032112;-3.4996889;-2.5112154;-2.0141003;4.0587077;CODE
with min gain to split 0 and make sure that the node is not split best;3.0301993;3.0602088;-1.0822618;-2.8594153;0.82941276;1.5874764;CODE
possible gain 1 note before the strict inequality comparison this;-0.118025914;4.2533154;-0.57221526;0.9317178;-1.5542557;-0.17233156;CODE
test would fail because the node would be split with a gain of 0;1.9299192;5.316564;-1.6673406;1.4319233;-0.6431888;-3.5327096;IRRE
basic sanity check with no missing values given the gradient;2.9147267;3.585109;-0.90019745;-1.7531327;-1.5967654;-1.0745946;IRRE
values the split must occur on bin idx 3;-0.089242786;3.9320881;-2.9140978;-6.2133527;1.8691276;-3.2361572;IRRE
0 1 2 3 4 5 6 7 8 9 x binned;1.1476845;1.5023991;1.5451621;-8.61341;0.9454796;-5.949837;-
1 1 1 1 5 5 5 5 5 5 gradients;4.031331;-1.4020516;2.9134848;-7.148997;1.3875426;0.018428162;-
false no missing values;0.41519022;8.139167;-2.446203;-0.16002987;-1.3420786;-5.476111;IRRE
10 n bins non missing;-0.27674317;1.9904454;-0.25199175;-3.3448458;-0.22904384;-4.714275;-
false don t split on nans;2.6318605;5.048272;-2.013014;-0.93122435;-1.5264852;-3.7951233;CODE
3 expected bin idx;-3.606136;3.0883286;-1.7703027;-5.0000205;1.5883522;-3.8937044;-
we replace 2 samples by nans bin idx 8;3.436104;1.9883487;-2.9428465;-5.2534986;0.38968813;-2.7614548;-
these 2 samples were mapped to the left node before so they should;1.6426585;1.4018372;-2.2026453;-1.5501223;-0.2713684;0.9169862;CODE
be mapped to left node again;-2.9420197;2.5536926;4.26476;-1.4820677;-0.043628875;3.5321918;-
notice how the bin idx threshold changes from 3 to 1;-0.2721111;1.6255568;-2.5518835;-3.9808245;0.72568876;-1.7276582;CODE
8 0 1 8 2 3 4 5 6 7 8 missing;0.77485424;2.304491;0.80411464;-5.749084;-0.2818479;-5.16954;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
8 n bins non missing;-1.0886252;1.679455;-0.5618531;-3.7748594;-0.5242459;-4.2941313;-
false don t split on nans;2.63186;5.048271;-2.0130148;-0.93122476;-1.5264862;-3.7951221;CODE
1 cut on bin idx 1;-2.6592438;1.4643397;-0.4670485;-5.5926914;1.5545994;-0.9290774;-
missing values go to left;-1.1115152;5.399093;1.2562201;-3.6178136;-2.452173;-3.2320356;IRRE
same as above but with non consecutive missing values bin;0.7263925;4.665954;0.21373558;-3.96511;1.2686467;-4.377421;IRRE
9 0 1 9 2 3 4 5 6 7 9 missing;1.6087728;2.6108654;0.5934573;-4.7309017;0.1450778;-5.2519507;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
8 n bins non missing;-1.0886252;1.679455;-0.5618531;-3.7748594;-0.5242459;-4.2941313;-
false don t split on nans;2.6318605;5.048272;-2.013014;-0.93122435;-1.5264852;-3.7951233;CODE
1 cut on bin idx 1;-2.6592438;1.4643397;-0.4670485;-5.5926914;1.5545994;-0.9290774;-
missing values go to left;-1.1115153;5.3990936;1.2562197;-3.617813;-2.4521723;-3.2320368;IRRE
this time replacing 2 samples that were on the right;1.9217854;2.505983;1.7584511;1.325008;0.5888706;-2.8683007;CODE
0 1 2 3 8 4 8 5 6 7 8 missing;0.69648397;2.8534534;0.13275972;-6.299048;-0.74077576;-5.507646;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
8 n bins non missing;-1.0886252;1.679455;-0.5618531;-3.7748594;-0.5242459;-4.2941313;-
false don t split on nans;2.63186;5.048271;-2.0130148;-0.93122476;-1.5264862;-3.7951221;CODE
3 cut on bin idx 3 like in first case;-2.3595786;1.3644211;1.5308765;-6.25139;4.061507;-0.9838863;CODE
missing values go to right;-0.32143897;5.446546;0.1546405;-3.3848534;-3.4448624;-3.9459205;IRRE
same as above but with non consecutive missing values bin;0.7263925;4.665954;0.21373558;-3.96511;1.2686467;-4.377421;IRRE
0 1 2 3 9 4 9 5 6 7 9 missing;1.4784675;2.8777301;0.38656795;-5.2680287;-0.164628;-5.383249;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
8 n bins non missing;-1.0886252;1.679455;-0.5618531;-3.7748594;-0.5242459;-4.2941313;-
false don t split on nans;2.6318605;5.048272;-2.013014;-0.93122435;-1.5264852;-3.7951233;CODE
3 cut on bin idx 3 like in first case;-2.3595786;1.3644211;1.5308765;-6.25139;4.061507;-0.9838863;CODE
missing values go to right;-0.32143897;5.446546;0.1546405;-3.3848534;-3.4448624;-3.9459205;IRRE
for the following cases split on nans is true we replace all of;1.1166425;3.1090734;-0.071174525;-2.2663014;0.4147553;-3.7520626;CODE
the samples with nans instead of just 2;4.17645;1.8503318;-2.2064025;-3.8150344;-3.4707465;-4.0152164;CODE
0 1 2 3 4 4 4 4 4 4 4 missing;1.196781;3.0580509;0.82019496;-5.975596;0.106946476;-5.5964146;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
4 n bins non missing;-0.7643974;2.4278564;-0.38138944;-4.4733295;0.41399458;-4.566939;-
true split on nans;2.497235;2.4857469;-0.49369094;-1.6662813;-0.59040886;-2.5550215;-
3 cut on bin idx 3;-3.6095686;1.0742282;0.4044603;-6.0016723;2.264348;-1.0412103;-
missing values go to right;-0.32143897;5.446546;0.1546405;-3.3848534;-3.4448624;-3.9459205;IRRE
same as above but with non consecutive missing values bin;0.7263925;4.665954;0.21373558;-3.96511;1.2686467;-4.377421;IRRE
0 1 2 3 9 9 9 9 9 9 9 missing;1.5242852;2.8957841;0.51165354;-5.227775;0.05086634;-5.2798657;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
4 n bins non missing;-0.7643974;2.4278564;-0.38138944;-4.4733295;0.41399458;-4.566939;-
true split on nans;2.4972346;2.4857461;-0.4936912;-1.6662811;-0.5904091;-2.5550203;-
3 cut on bin idx 3;-3.6095686;1.0742282;0.4044603;-6.0016723;2.264348;-1.0412103;-
missing values go to right;-0.32143897;5.446546;0.1546405;-3.3848534;-3.4448624;-3.9459205;IRRE
6 6 6 6 0 1 2 3 4 5 6 missing;0.36287928;1.8055968;1.2411364;-3.949879;0.8983666;-4.999992;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
6 n bins non missing;-0.7849426;1.5870562;-0.45313853;-3.8740816;0.15598479;-4.982555;-
true split on nans;2.4972346;2.4857461;-0.4936912;-1.6662811;-0.5904091;-2.5550203;-
5 cut on bin idx 5;-2.8085349;0.5342151;0.55384886;-4.813272;1.468867;-0.98483735;-
missing values go to right;-0.32143897;5.446546;0.1546405;-3.3848534;-3.4448624;-3.9459205;IRRE
same as above but with non consecutive missing values bin;0.7263925;4.665954;0.21373558;-3.96511;1.2686467;-4.377421;IRRE
9 9 9 9 0 1 2 3 4 5 9 missing;1.5314763;2.5790422;0.69069046;-4.159226;0.6411938;-4.7227273;-
true missing values;1.6279974;5.414272;-0.70879835;-0.8175468;-0.388632;-5.3929973;IRRE
6 n bins non missing;-0.7849426;1.5870562;-0.45313853;-3.8740816;0.15598479;-4.982555;-
true split on nans;2.4972346;2.4857461;-0.4936912;-1.6662811;-0.5904091;-2.5550203;-
5 cut on bin idx 5;-2.8085344;0.53421557;0.55384874;-4.813271;1.4688683;-0.98483795;-
missing values go to right;-0.32143897;5.446546;0.1546405;-3.3848534;-3.4448624;-3.9459205;IRRE
make sure missing values are properly supported;0.2833093;5.0610313;-4.7221932;-0.3763712;-1.583674;-1.8713244;IRRE
we build an artificial example with gradients such that the best split;6.146365;-2.6202261;2.2823744;-0.56618273;3.2490265;3.6559126;-
is on bin idx 3 when there are no missing values;-2.6574023;3.843282;-4.263054;-3.6811504;0.46012187;-2.85554;IRRE
then we introduce missing values and;1.858982;2.183779;1.3775485;0.49188954;2.4742696;-1.6606338;IRRE
make sure the chosen bin is correct find best bin it s;-1.2497046;1.5722026;-0.29973537;-1.4450914;-0.71758705;-2.856287;IRRE
still the same split even though the index of the bin may change;-0.62404144;1.4251974;-0.21202925;-1.0664911;0.7735152;0.11281408;TASK
make sure the missing values are mapped to the correct child;0.3147199;5.168302;-0.81570154;-0.70001996;0.37149188;-0.32588655;IRRE
split indices;3.78872;1.6050844;0.86791867;-5.6721454;2.3806808;-1.2037429;-
make sure the split is properly computed;1.8570529;3.5387738;-2.2767305;-1.7878646;-1.0229061;-0.9377643;-
this also make sure missing values are properly assigned to the correct;-1.0332916;4.2079983;-2.8996549;-0.5692969;-0.806344;-1.5809901;IRRE
child in split indices;1.8269985;2.063968;0.52462214;-4.9520936;2.82733;-0.77424705;-
when we don t split on nans the split should always be the same;1.369575;2.042411;-0.17333362;-1.1761259;-0.07406708;-0.07999273;CODE
when we split on nans samples with missing values are always mapped;4.2452397;3.3524525;-2.968579;-1.9050559;-2.1744912;0.36974204;IRRE
to the right child;-3.5366828;0.0060324525;5.9570007;0.22370715;-0.5122613;-1.0653299;-
one category;-0.43589765;-4.2222614;5.1823444;1.8449465;4.6422377;-2.9188035;-
all categories appear less than min cat support hardcoded to 10;0.030667318;-0.39206988;-3.2199583;-1.1101155;0.20258763;-0.41213176;-
only one category appears more than min cat support;-1.6494396;-1.2690241;-1.0056752;-0.38400233;0.9223884;0.5634116;-
missing values category appear less than min cat support;0.038763043;1.2293515;-3.493353;-1.1913022;-1.1987884;-0.36642915;IRRE
9 is missing;-2.636924;1.7586219;2.1963928;-1.9942018;0.26664534;-3.5889282;-
no non missing category;-3.1958988;-1.4207727;-0.7790644;0.839606;0.9339215;-1.3753806;-
checks categorical splits are correct when the min cat support constraint;1.2770035;1.9908428;-3.783521;0.36789533;3.2054105;-0.6931046;CODE
isn t respected there are no splits;-1.2700891;1.4055722;1.2477587;-0.046122935;2.1733184;0.5389167;-
no split found;-3.9827664;0.14880681;0.67864406;-1.7781059;-0.4831946;-2.4207294;-
assert that the bitset exactly corresponds to the categories;-0.26729468;0.8180424;-3.2972977;-1.6183197;3.3388345;-1.5678837;IRRE
bitset is assumed to be an array of 8 uint32 elements;-2.327008;1.3164294;-2.6934881;-5.5229735;-0.30186662;-0.84561175;IRRE
form bitset from threshold;1.3706224;1.6060085;-0.7343102;-4.4797215;1.3834339;0.22096856;CODE
check for equality;-1.2181323;6.241277;1.3619733;0.20619452;0.9672886;-6.263466;CODE
4 categories;0.56528735;-2.8808682;5.2183475;-1.1572818;5.194604;-3.256946;-
0 1 2 3 11 x binned;-0.38063726;1.4421687;0.96636605;-8.036575;1.2781953;-5.6138954;-
10 1 10 10 11 all gradients;3.0517538;-1.309978;2.1902573;-5.7547836;0.050102655;-0.73178566;-
1 expected categories left;0.16603169;0.47580737;3.0906823;0.8540666;1.9251909;-2.9851785;-
4 n bins non missing;-0.7643974;2.4278564;-0.38138944;-4.4733295;0.41399458;-4.566939;-
4 missing values bin idx;-2.0442965;3.6862066;-3.4930341;-5.723539;0.52811795;-3.8065853;IRRE
false has missing values;-0.28348285;7.8192964;-2.5711596;-0.52852017;-1.690428;-5.501989;IRRE
expected missing go to left unchecked;-3.068488;5.3003354;0.10304766;2.6185336;-2.1872697;-0.37530696;-
make sure that the categories that are on the right second half of;-1.8691087;-0.32713944;2.4749897;1.0991962;1.0525725;-1.5911855;-
the sorted categories array can still go in the left child in this;-1.192158;1.4686508;1.7440405;-0.7843426;-0.85666955;0.124131486;CODE
case the best split was found when scanning from right to left;-0.25132108;1.6137704;1.186431;-1.769154;0.92904633;-0.32272035;CODE
0 1 2 3 11 x binned;-0.38063726;1.4421687;0.96636605;-8.036575;1.2781953;-5.6138954;-
10 10 10 1 11 all gradients;2.983021;-1.2931455;2.228319;-5.6575146;0.05143482;-0.67564464;-
3 expected categories left;-0.27918118;-0.052934576;3.8422604;-0.03455698;2.8450902;-3.145847;-
4 n bins non missing;-0.7643974;2.4278564;-0.38138944;-4.4733295;0.41399458;-4.566939;-
4 missing values bin idx;-2.0442963;3.6862056;-3.493033;-5.72354;0.52811855;-3.8065834;IRRE
false has missing values;-0.28348285;7.8192964;-2.5711596;-0.52852017;-1.690428;-5.501989;IRRE
expected missing go to left unchecked;-3.068488;5.3003354;0.10304766;2.6185336;-2.1872697;-0.37530696;-
categories that don t respect min cat support cat 4 are always;-1.1421008;-2.279856;-1.1675184;0.6923185;2.0942252;1.0549257;CODE
mapped to the right child;-2.0154254;1.05013;5.083798;-1.7936832;2.8450265;2.8378766;-
0 1 2 3 11 4 5 x binned;0.47148725;1.4423758;1.5136814;-7.925901;1.2366621;-5.7407804;-
10 10 10 1 11 10 5 all gradients;3.8168218;-1.4994059;2.768521;-6.147135;0.53576756;-0.65190554;-
3 expected categories left;-0.27918118;-0.052934576;3.8422604;-0.03455698;2.8450902;-3.145847;-
4 n bins non missing;-0.7643974;2.4278564;-0.38138944;-4.4733295;0.41399458;-4.566939;-
4 missing values bin idx;-2.0442965;3.6862066;-3.4930341;-5.723539;0.52811795;-3.8065853;IRRE
false has missing values;-0.28348285;7.8192964;-2.5711596;-0.52852017;-1.690428;-5.501989;IRRE
expected missing go to left unchecked;-3.068488;5.3003354;0.10304766;2.6185336;-2.1872697;-0.37530696;-
categories that don t respect min cat support are always mapped to;-0.7540474;-1.6917382;-2.2616603;1.1830046;1.7765036;3.4668245;CODE
the right child in this case a more sensible split could have been;-1.8126286;1.8028344;1.2881569;1.8795524;1.6978146;0.13697739;CODE
3 4 0 1 2;-2.0042589;2.0975883;3.232456;-4.2277303;0.45373294;-4.1127343;-
but the split is still 3 0 1 2 4 this is because we only scan;-0.6078484;1.7663527;0.16835758;-3.4907334;1.3230773;-1.5579795;TASK
up to the middle of the sorted category array 0 1 2 3 and;1.0814307;0.16138603;2.9293315;-4.1736665;1.0429776;-1.8654139;-
because we exclude cat 4 in this array;-1.1228185;2.3653915;-0.7241415;-2.706713;0.2715713;-3.3896704;CODE
0 1 2 3 11 4 5 x binned;0.47148725;1.4423758;1.5136814;-7.925901;1.2366621;-5.7407804;-
10 10 10 1 11 1 5 all gradients;3.6887238;-1.3337775;2.9161253;-6.4606037;0.61379915;-0.8047756;-
3 expected categories left;-0.27918118;-0.052934576;3.8422604;-0.03455698;2.8450902;-3.145847;-
4 n bins non missing;-0.7643974;2.4278564;-0.38138944;-4.4733295;0.41399458;-4.566939;-
4 missing values bin idx;-2.0442965;3.6862066;-3.4930341;-5.723539;0.52811795;-3.8065853;IRRE
false has missing values;-0.28348285;7.8192964;-2.5711596;-0.52852017;-1.690428;-5.501989;IRRE
expected missing go to left unchecked;-3.068488;5.3003354;0.10304766;2.6185336;-2.1872697;-0.37530696;-
4 categories with missing values that go to the right;1.9147618;1.3243511;2.820614;-2.1970916;2.19748;-2.6207976;IRRE
0 1 2 11 9 11 x binned;0.22066458;1.0169914;0.99951166;-6.465034;0.81868577;-6.335752;-
10 1 10 11 10 11 all gradients;3.387221;-1.1706088;2.2764218;-6.37655;0.29812968;-0.9448307;-
1 expected categories left;0.16603169;0.47580737;3.0906823;0.8540666;1.9251909;-2.9851785;-
3 n bins non missing;-1.1982459;2.207006;-0.46826172;-4.7861056;0.61536777;-4.6624665;-
9 missing values bin idx;-1.5849345;3.0328422;-3.4369595;-5.2120376;0.27524528;-4.3234873;IRRE
true has missing values;-0.6900064;5.78101;-0.9201444;-0.056283455;-1.1819763;-5.142615;IRRE
expected missing go to left;-2.0579836;4.7550197;1.7236098;0.2659204;-1.7859437;-2.4608102;-
4 categories with missing values that go to the left;1.4728396;1.2509594;3.0645013;-2.6584728;2.3111181;-2.5163069;IRRE
0 1 2 11 9 11 x binned;0.22066458;1.0169914;0.99951166;-6.465034;0.81868577;-6.335752;-
10 1 10 11 1 11 all gradients;3.323006;-1.1039175;2.3657389;-6.6968827;0.5008088;-1.0241324;-
1 9 expected categories left;0.61719364;-0.01999857;2.749729;0.65050304;1.7937431;-3.5057178;-
3 n bins non missing;-1.1982448;2.2070074;-0.46826142;-4.7861066;0.615368;-4.662468;-
9 missing values bin idx;-1.5849372;3.0328429;-3.43696;-5.2120376;0.27524534;-4.3234873;IRRE
true has missing values;-0.6900064;5.78101;-0.9201444;-0.056283455;-1.1819763;-5.142615;IRRE
expected missing go to left;-2.0579836;4.7550197;1.7236098;0.2659204;-1.7859437;-2.4608102;-
split is on the missing value;0.21847332;4.810306;-0.0044053555;-2.882397;0.5203336;-4.0995126;IRRE
0 1 2 3 4 11 255 12 x binned;0.83357143;1.2344558;0.8228461;-9.439325;0.8867777;-5.5193563;-
10 10 10 10 10 11 1 12 all gradients;3.7583168;-1.8517418;2.5267513;-6.294437;0.3856069;-0.45042044;-
255 expected categories left;0.20422879;-0.18007673;1.0953281;-0.15015146;1.4494388;-4.1052513;-
5 n bins non missing;-0.4524436;1.8032904;-0.34211463;-3.8087182;-0.03488406;-4.746617;-
255 missing values bin idx;-2.0621653;2.8169577;-5.1259737;-5.893808;0.055783246;-3.3038216;IRRE
true has missing values;-0.6900064;5.78101;-0.9201444;-0.056283455;-1.1819763;-5.142615;IRRE
expected missing go to left;-2.0579836;4.7550197;1.7236098;0.2659204;-1.7859437;-2.4608102;-
split on even categories;1.3599188;-0.7013189;2.5905163;-0.5648969;3.9994607;-1.5969641;-
list range 60 12 x binned;1.9541523;0.97356766;1.8920393;-4.931668;1.8233001;-4.584478;-
10 1 360 all gradients;2.519809;-0.88041306;2.7493114;-5.0490727;-0.85699826;-0.17399402;-
list range 1 60 2 expected categories left;1.2996941;1.004215;2.262079;-0.9172783;1.3949646;-4.4011607;-
59 n bins non missing;-1.0717037;1.6106795;-0.29999942;-3.02821;-0.2122415;-4.9824758;-
59 missing values bin idx;-1.9093082;3.1874144;-3.2417994;-4.6138;0.103396945;-4.044732;IRRE
true has missing values;-0.6900064;5.78101;-0.9201444;-0.056283455;-1.1819763;-5.142615;IRRE
expected missing go to left;-2.0579836;4.7550197;1.7236098;0.2659204;-1.7859437;-2.4608102;-
split on every 8 categories;2.468272;-1.6185799;3.9975533;-0.87961614;3.5457435;-0.76754224;-
list range 256 12 x binned;0.6729128;0.34816182;-0.946541;-5.548081;0.6608284;-4.9294176;-
10 10 10 10 10 10 10 1 384 all gradients;3.3937647;-1.8469838;1.9290761;-6.0617747;0.32051662;-0.7318606;-
list range 7 256 8 expected categories left;1.0317678;0.23718794;0.26305154;-0.973937;0.5276134;-4.4654193;-
255 n bins non missing;-0.541921;1.4412569;-2.7889168;-4.6837463;-0.8519574;-3.8813887;-
255 missing values bin idx;-2.0621653;2.8169577;-5.1259737;-5.893808;0.055783246;-3.3038216;IRRE
true has missing values;-0.6900064;5.78101;-0.9201444;-0.056283455;-1.1819763;-5.142615;IRRE
expected missing go to left;-2.0579836;4.7550197;1.7236098;0.2659204;-1.7859437;-2.4608102;-
tests various combinations of categorical splits;3.220225;1.0802149;0.21164626;2.2700033;4.6993585;-4.8402815;IRRE
if there is no missing value during training the flag missing go to left;-1.1628993;4.5643325;-0.30607072;1.504018;0.93356234;-2.5235887;IRRE
is set later in the grower;-3.598718;-2.070842;4.941281;1.6524322;-0.3347269;1.8869756;IRRE
make sure samples are split correctly;4.937521;2.9579046;-1.1269916;0.5734499;-0.26807573;-1.8462199;-
unmapped xgb parameters;-1.4344481;2.025666;-3.67185;-3.0712938;0.5543176;3.4337406;IRRE
min samples leaf;3.2837808;1.6063659;1.1091368;-0.915384;1.4094578;-1.142113;-
min data in bin;3.8884418;2.428322;-0.5010759;-4.843122;-0.29416752;-2.4453435;-
min split gain there is min split loss though;2.2148983;1.0277061;-0.2532755;-1.2876887;1.4785913;2.2894368;CODE
unmapped catboost parameters;0.8791691;1.2449243;-3.368985;-1.8254919;0.70233035;2.9418375;IRRE
max leaves;-1.4218733;-0.022703951;3.4370964;-0.567982;0.26345533;-1.3609383;-
min;-0.9937482;-0.0023651621;5.0186086;-2.107777;0.599395;-2.1714149;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
note we use threading here as the predict method is not cpu bound;5.2136374;-1.3167213;-1.8647132;4.148818;-1.932237;1.1424297;TASK
note we use threading here as the decision function method is;2.7746508;-0.21881022;2.489249;4.104201;3.3941228;0.3185786;CODE
not cpu bound;1.0484464;0.34068003;0.252369;0.50499326;-1.6902866;0.218519;-
note we use threading here as the score samples method is not cpu bound;5.585179;0.39640585;-2.097872;2.813256;0.105264135;-0.54624355;TASK
preds is here a list of n targets 2d ndarrays of;0.7352068;-3.1491327;-0.12907955;-4.9762053;-0.94484323;0.02369596;-
n classes columns the k th column contains the;2.5583682;-1.2794952;-0.17560741;-5.2209296;4.3750606;-2.7484174;IRRE
probabilities of the samples belonging the k th class;4.2782736;-1.6151195;-0.53859276;-0.34247738;3.5342996;-1.9682974;IRRE
since those probabilities must sum to one for each sample;3.4023495;0.6795828;0.46403408;0.3920128;2.8655748;-1.0697048;CODE
we can work with probabilities of n classes 1 classes;2.6003265;-2.851617;0.6789596;1.3498769;5.892541;-1.5556414;IRRE
hence we drop the first column;0.27200347;2.865678;2.2991445;-2.5558262;-0.5726904;-0.38629618;-
some estimator return a 1d array for predictions;6.2508807;1.1879839;-0.7107977;0.26566404;-3.3283625;1.114122;CODE
which must be 2 dimensional arrays;3.9540975;2.22834;0.97844106;-7.027147;1.4064138;-1.8629005;TASK
remove the first column when using probabilities in;0.72397345;2.8088262;1.0650524;-1.621193;0.30573907;-1.3748344;-
binary classification because both features preds are perfectly;2.9618864;-0.8561658;-2.9707997;-0.4856636;5.358738;-1.1775976;TASK
collinear;-0.0023351628;0.17082725;5.7452097;-2.516514;-1.158274;-2.2138171;-
estimators in stacking estimators are not validated yet;1.6231947;1.6005921;-3.658258;2.982327;-2.1348176;3.4595785;TASK
all estimators contains all estimators the one to be fitted and the;0.7712075;0.008961479;0.9401524;1.6262969;-1.3417525;3.355464;-
drop string;-2.442941;3.399932;3.2660387;0.88082355;0.068721734;-2.5773904;CODE
fit the base estimators on the whole training data those;6.576604;-1.6904602;-0.06709284;2.0413334;1.11016;3.581068;CODE
base estimators will be used in transform predict and;3.080944;-2.5631552;0.24261607;0.79703355;-0.74642843;2.953567;CODE
predict proba they are exposed publicly;2.0039551;-1.9641064;0.44875586;4.742902;0.43215212;-1.860998;CODE
generate predictions from prefit models;4.209339;-2.6663516;0.08357864;5.4385557;1.1665089;1.4096296;CODE
to train the meta classifier using the most data as possible we use;5.7006483;-5.0921283;2.0669858;3.3157372;5.1552796;0.4918727;CODE
a cross validation to obtain the output of the stacked estimators;5.579201;-0.65587085;0.08804446;3.2684155;1.416222;1.3714532;IRRE
to ensure that the data provided to each estimator are the same;4.891555;3.1288865;0.431857;3.2672691;0.47201106;4.2039742;-
we need to set the random state of the cv if there is one and we;1.8093065;1.7485976;-1.0028481;3.141323;3.6395776;0.5814954;IRRE
need to take a copy;-3.5764263;-3.3474743;2.4983885;-0.9283089;-0.52792853;-1.7556901;TASK
only not none or not drop estimators will be used in transform;1.5895262;2.5106606;-1.6762632;0.59648544;-1.1532986;4.002705;CODE
remove the none from the method as well;-2.5078704;5.4940004;-2.3780138;1.2122184;-0.5761962;-1.9270965;CODE
final estimator is wrapped in a parallel block to show the label;0.5427457;1.5488021;0.38951194;0.72070086;-2.058634;4.412744;CODE
final estimator in the html repr;-0.36093295;0.17642461;0.2827163;3.0734375;-1.9220018;3.1626425;CODE
self estimators is a list of name est tuples;2.7927594;-1.4624332;-0.47601038;2.0106862;1.4990463;1.2152847;CODE
todo slep6 remove when metadata routing cannot be disabled;-5.61098;1.6930459;-3.205838;2.6438422;-0.20211492;5.64911;TASK
handle the multilabel indicator case;0.5015552;1.4331338;1.5081604;-1.2717849;5.60651;1.6786507;CODE
handle the multilabel indicator cases;1.6200284;1.115476;1.6164896;-1.2737095;6.059959;1.0097857;CODE
if final estimator s default changes then this should be;-0.5626738;2.8448298;-1.7037557;4.308337;-2.8724787;5.933212;CODE
updated;-4.5566597;-3.119256;1.7938508;1.906648;0.32191268;-0.90469325;CODE
todo slep6 remove when metadata routing cannot be disabled;-5.61098;1.6930459;-3.205838;2.6438422;-0.20211492;5.64911;TASK
if final estimator s default changes then this should be;-0.5626738;2.8448298;-1.7037557;4.308337;-2.8724787;5.933212;CODE
updated;-4.5566597;-3.119256;1.7938508;1.906648;0.32191268;-0.90469325;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
for consistency with other estimators we raise an attributeerror so;2.134999;2.243553;-5.521451;5.057569;-2.8062525;4.0423646;CODE
that hasattr fails if the estimator isn t fitted;0.32427052;5.162015;-4.261321;3.3785415;-3.616793;2.9842381;-
self estimators is a list of name est tuples;2.7927601;-1.4624323;-0.47600907;2.0106852;1.4990468;1.2152842;CODE
estimators in votingclassifier estimators are not validated yet;2.2898126;-0.31352243;-6.634907;3.4521465;0.15504786;0.2997762;TASK
raise a specific valueerror for non classification tasks;3.2805126;0.7024707;-4.836673;4.368093;-0.18334147;-0.44882107;CODE
raise a notimplementederror for backward compatibility for non supported;-4.2219944;1.1439091;-6.320814;3.0340457;1.2891116;4.0612493;CODE
classification tasks;4.930731;-5.592987;4.156635;2.6608336;5.1637955;-1.7009202;TASK
else hard voting;0.33702838;-0.4392605;2.522143;1.2639543;1.7395405;-2.1212215;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
only called to validate x in non fit methods therefore reset false;0.18687803;6.7656655;-5.7492986;4.399278;-2.3091896;0.111524835;IRRE
adaboost estimator is not validated yet;-0.53548276;0.41542727;-6.261532;2.543274;-1.9874089;1.7985307;TASK
check parameters;-0.36041427;6.4561687;1.3902198;1.6032356;0.99924463;-3.843164;IRRE
clear any previous fit results;3.586363;3.1063046;-0.6204169;2.921705;-0.5220214;1.6357572;IRRE
initialization of the random number instance that will be used to;-1.4100795;0.96502674;1.2809058;1.7295512;2.8104913;0.35474467;IRRE
generate a seed at each iteration;3.508607;-0.391019;3.2002094;-0.39987218;1.0991521;-1.6820067;-
avoid extremely small sample weight for details see issue 20320;4.0256286;2.3174725;-3.5183158;2.6907601;-0.030541893;0.5398399;CODE
do not clip sample weights that were exactly zero originally;2.9614441;3.5600867;-2.739887;0.06274094;-2.1405358;1.2420596;CODE
boosting step;3.559446;-2.1122973;1.4858757;-0.20055053;2.5023885;1.0088915;-
early termination;-3.816999;-0.39485464;2.610028;3.6027606;0.14622793;0.008590293;-
stop if error is zero;-0.49552372;9.415504;-1.6081765;3.6471906;-3.8503516;-4.477244;-
stop if the sum of sample weights has become non positive;3.0947983;5.048878;-1.5132691;2.3907385;-1.52889;0.062077124;-
normalize;3.2357895;-0.4351677;3.841472;-2.7884026;1.0498034;1.0225147;-
weighted sampling of the training set with replacement;6.263003;-0.9143217;0.8443597;2.2092032;3.5328584;1.8480513;IRRE
fit on the bootstrapped sample and obtain a prediction;6.119791;-0.2294795;0.7406789;3.1650271;0.7752365;-0.035248026;CODE
for all samples in the training set;6.064346;-2.4155815;1.5361415;1.1666173;4.904547;-2.1537986;CODE
calculate the average loss;2.607783;0.8720037;3.4802349;-0.3665194;-1.948943;-0.7325995;-
stop if fit is perfect;2.458866;5.0286655;2.296801;2.8108997;-2.3996544;-0.46721923;-
discard current estimator only if it isn t the only one;1.7332432;5.1359754;-0.7882497;4.3073735;-1.1591158;5.097099;IRRE
boost weight using adaboost r2 alg;0.7443949;-1.4822979;-2.4603772;-0.11101624;1.54118;2.34695;-
evaluate predictions of all estimators;5.0653114;0.047603484;0.5872489;6.1065755;-1.3085941;-0.13398306;-
sort the predictions;4.48802;-1.9150242;4.214168;2.9127872;0.18271175;-0.9392485;-
find index of median prediction for each sample;5.001047;0.11299781;2.0994425;-0.7961905;-0.57071286;-0.47554368;CODE
return median predictions;6.05058;-0.04640611;2.458452;3.289167;-1.7257425;0.058045432;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
also load the iris dataset;1.5464042;-4.3465104;-0.13598996;-1.1130621;-0.53984874;0.6428218;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
also load the diabetes dataset;3.756223;-3.7747552;1.0352626;0.72781825;0.2249242;0.34326255;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
check classification for various parameter settings;3.2985556;-0.02190016;-1.4320148;2.51045;3.6795504;-0.4528095;IRRE
try different parameter settings with different base classifiers without;2.4782145;1.2593434;-4.6004915;2.7403576;3.3433254;3.9657888;IRRE
doing the full cartesian product to keep the test durations low;3.078304;3.91656;0.626496;0.6925662;0.47082195;-2.531493;CODE
check classification for various parameter settings on sparse input;6.184624;-0.6555308;-3.270663;0.9838455;1.8883065;1.4607477;IRRE
trained on sparse format;6.8429346;-4.56035;-1.8299532;-0.9784787;2.5721352;0.9050573;CODE
trained on dense format;5.2517204;-5.14741;-1.1186123;0.3762311;2.1888788;-1.1586736;CODE
test that bootstrapping samples generate non perfect base estimators;3.14267;3.146676;-4.7695255;3.976318;-1.3276485;-0.93260384;IRRE
without bootstrap all trees are perfect on the training set;2.172807;-3.5866864;-0.89503866;3.140489;2.3434982;0.9889951;IRRE
with bootstrap trees are no longer perfect on the training set;0.7172077;-2.4095902;-2.8983443;2.5844474;0.33612642;1.3787633;IRRE
check that each sampling correspond to a complete bootstrap resample;4.8494854;2.4064786;-0.8964957;2.0327525;1.0664603;0.43055362;CODE
the size of each bootstrap should be the same as the input data but;3.479431;0.9158941;-0.041677564;-2.8656979;-0.5412456;1.4428407;META
the data should be different checked using the hash of the data;1.9679428;5.98949;0.5420875;0.024403278;1.9510071;-1.4316226;-
test that bootstrapping features may generate duplicate features;2.482249;1.1594125;-3.185747;5.356951;2.6347587;-1.2122012;TASK
predict probabilities;4.265847;-2.253928;2.852144;2.9215846;1.3508704;-2.3749144;-
normal case;-2.4815557;1.7821296;4.156418;-0.81035787;2.6566513;-1.9000647;CODE
degenerate case where some classes are missing;-0.68340415;0.82270074;-3.0029235;2.147396;5.4037924;-0.38784257;CODE
check that oob prediction is a good estimation of the generalization;6.4055066;-3.0092244;-2.7016318;4.3984957;2.4515789;0.8161517;-
error;-5.63395;2.4462695;1.2432225;-0.761733;-1.536994;-4.77406;-
test with few estimators;3.0023744;5.259747;-0.4065507;5.8839793;-1.0458021;-2.0261602;IRRE
check that oob prediction is a good estimation of the generalization;6.4055066;-3.0092244;-2.7016318;4.3984957;2.4515789;0.8161517;-
error;-5.63395;2.4462695;1.2432225;-0.761733;-1.536994;-4.77406;-
test with few estimators;3.0023744;5.259747;-0.4065507;5.8839793;-1.0458021;-2.0261602;IRRE
check singleton ensembles;3.4177592;0.7219802;-2.152056;4.4867034;2.6858723;-0.6550826;CODE
test support of decision function;2.2334864;1.3205224;-1.1751744;6.7480416;2.3843765;-3.1577303;IRRE
check parallel classification;5.260604;-1.1351377;-0.8796726;1.6784793;4.564807;-2.0462995;IRRE
predict proba;3.5203054;-0.95955616;3.3026886;3.8423004;0.7238421;-4.227098;-
decision function;1.6420257;0.41849428;4.162715;1.1952342;3.07233;-2.7374961;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
check parallel regression;3.3861687;2.412039;0.2935857;2.0164912;-2.6354158;-1.8418809;-
check that bagging ensembles can be grid searched;6.3975534;-0.96626055;-0.8825912;2.1069846;3.181527;-0.6380119;-
transform iris into a binary classification task;3.0227954;-2.5936272;0.2794565;-1.931398;2.9907668;-1.729409;CODE
grid search with scoring based on decision function;5.86784;0.39238313;1.0054685;-0.11473733;2.7901094;-0.8372321;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
check estimator and its default values;0.8243631;5.043945;-1.3086244;3.0959187;-3.137068;0.7302188;IRRE
classification;5.668271;-5.822057;4.2595434;1.7214539;6.9095426;-2.1959188;IRRE
regression;4.8113813;-1.4023851;5.968424;1.4558641;-1.5940726;-2.9783654;-
test if fitting incrementally with warm start gives a forest of the;4.4775877;2.9035718;-2.1967285;4.5640826;-2.1717863;-1.0029116;IRRE
right size and the same results as a normal fit;0.39418226;0.79129595;2.5722518;-0.063466504;-1.667736;0.9687265;IRRE
test if warm start ed second fit with smaller n estimators raises error;4.1269603;4.8559604;-5.166111;3.1533132;-3.210532;1.6076967;IRRE
test that nothing happens when fitting without increasing n estimators;2.9415896;6.361339;-4.041692;4.9033003;-4.6334066;-0.32036433;IRRE
modify x to nonsense values this should not change anything;-0.82095456;5.402596;0.15178716;-3.3521233;-1.7591219;-2.7772274;IRRE
warm started classifier with 5 5 estimators should be equivalent to;3.8025131;-1.417077;-2.3158886;3.4497008;1.2755406;1.7336863;IRRE
one classifier with 10 estimators;5.304783;-1.6273594;0.109394364;1.9927369;3.6070304;0.7739206;IRRE
check using oob score and warm start simultaneously fails;-0.46335185;3.6129901;-3.4688597;3.9074821;-0.7709166;-2.8574452;-
case 1 small weights and fractional max samples would lead to sampling;5.2063646;2.8071973;-0.26391327;0.8722604;0.7948604;2.2956567;CODE
less than 1 sample which is not allowed;1.8498591;3.9817207;-0.3800946;-0.059822064;2.7884653;-4.288184;-
case 2 large weights and bootstrap false would lead to sampling without;3.7567048;3.5678794;-2.4522378;3.3252397;0.06836047;2.0511494;CODE
replacement more than the number of samples which is not allowed;2.5805;3.3455713;0.124690555;0.7339868;2.7699034;-2.8388453;-
all indices except 4 and 5 have zero weight;1.5174356;4.2528615;-2.7091267;-4.7004905;-1.0813774;-0.8253522;CODE
max samples passed as a fraction of the input data since;6.229909;3.5371048;0.4105881;-0.43120864;-0.70479554;-1.851939;CODE
sample weight are provided the effective number of samples is the;4.340292;1.8005128;0.81993794;0.91921145;2.4698505;-1.3685025;-
sum of the sample weights;3.631418;0.59137374;1.8227514;-0.3650818;0.27275267;-0.030693054;-
todo slep006 remove block when default routing is implemented;-4.94549;3.020871;-1.6413981;1.4874734;-1.0562121;5.391793;CODE
only indices 4 and 5 should appear;-1.8752509;2.6950898;-1.4015025;-5.2373867;-1.347738;-1.6393777;-
sampled indices represented through weighting;8.040408;0.049629968;-0.86637837;-3.653461;2.465985;2.3030443;-
sampled indices represented through indexing;6.2810907;0.8412959;0.25298572;-4.7593055;3.090119;1.197669;-
make sure oob scores are identical when random state estimator and;2.959836;2.015169;-4.103401;3.0651486;0.73088056;1.1000988;IRRE
training data are fixed and fitting is done twice;4.2738047;0.87734085;-1.036418;1.6596364;-1.4260713;1.8356296;CODE
check that format of estimators samples is correct and that results;2.0048754;3.286857;-3.765946;0.06971741;-3.488244;-1.2738659;IRRE
generated at fit time can be identically reproduced at a later time;3.019191;-0.24717502;-1.8441026;3.9728942;0.44996145;4.1295524;IRRE
using data saved in object attributes;0.3017519;-0.38352865;1.6941051;1.0823573;2.1618378;1.6408707;CODE
get relevant attributes;2.9779837;-0.64285314;2.3933296;1.3698303;5.410854;0.83112526;META
test for correct formatting;-0.51683927;3.7096567;0.17561191;1.5933583;1.0001359;-7.101275;CODE
re fit single estimator to test for consistent sampling;4.2389045;3.8788009;-1.2346882;4.6677685;-1.300863;2.9186862;IRRE
this test is a regression test to check that with a random step;0.92634666;3.1003726;-0.6430568;4.9132338;-0.8208027;-6.2070136;IRRE
e g sparserandomprojection and a given random state the results;4.2027116;-1.9625834;-0.296951;2.8444684;2.0906613;2.399472;IRRE
generated at fit time can be identically reproduced at a later time using;3.601498;-0.34243777;-1.7874755;3.700113;0.95444083;3.8920326;IRRE
data saved in object attributes check issue 9524 for full discussion;-1.9809968;2.778718;-4.2202682;2.5621104;0.56315225;-1.0625974;CODE
make sure validated max samples and original max samples are identical;4.9323792;5.0984397;-3.7281713;2.3450913;0.99314445;-1.6276187;CODE
when valid integer max samples supplied by user;4.068397;4.323609;-1.3928336;1.290211;2.931518;-3.1054473;CODE
make sure the oob score doesn t change when the labels change;0.22393692;0.38011608;-1.2569532;1.3372946;2.5370085;0.7073572;CODE
see https github com scikit learn scikit learn issues 8933;-2.2544327;-11.033504;-6.604232;-0.76145697;-4.968243;-4.269388;CODE
check that baggingregressor can accept x with missing infinite data;1.6340172;4.310831;-3.6104038;1.1752067;-1.230557;-0.317424;IRRE
verify that exceptions can be raised by wrapper regressor;0.41213602;5.080183;-5.1821127;4.253898;0.61595684;1.3583392;CODE
check that baggingclassifier can accept x with missing infinite data;2.9739747;1.5754358;-3.6836126;2.2343218;2.4412296;-0.8182891;IRRE
verify that exceptions can be raised by wrapper classifier;1.7100918;1.1080055;-4.4251633;5.6110597;2.9188879;-0.392336;CODE
check that bagging estimator can accept low fractional max features;4.7567263;0.14451857;-4.483432;1.0201494;0.09275947;3.1014147;TASK
check that bagging estimator can generate sample indices properly;5.022514;1.8979726;-4.320837;1.7533461;-0.40108833;0.8947269;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 16436;-2.8924875;-9.737782;-4.8780403;-0.8399517;-5.638322;-5.2283845;CODE
metadata routing tests;-0.843307;-0.22733422;-1.494115;5.5445786;1.6963054;-0.69893;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
check baseensemble methods;-0.8305923;3.3620033;-2.4086506;3.7347367;2.202594;-2.7093918;-
ensemble estimators empty the list and create estimators manually;2.270335;-0.44819734;-3.233279;3.4709897;-1.1798952;2.3531694;IRRE
linear discriminant analysis doesn t have random state smoke test;3.8684773;1.700411;-5.840435;0.8539809;-1.0579383;0.56983876;IRRE
check random state is none still sets;0.004327357;5.2392883;-0.06814406;3.248909;0.22873268;-3.2980263;IRRE
check random state fixes results in consistent initialisation;0.094383895;4.4980645;-2.9195445;4.432141;-1.1978273;0.14456965;IRRE
nested random state;0.6691009;1.953752;3.0957773;0.7537984;3.5132117;0.04342635;IRRE
ensure multiple random state parameters are invariant to get params;1.2830837;3.6655166;-1.0441487;2.5403519;2.854002;4.548757;IRRE
iteration order;2.004224;2.5443034;3.9806752;1.0496734;1.5259593;-1.9159669;-
check that the behavior of estimators estimators;1.3391058;3.9584112;-0.25173026;3.5013745;-3.5704;0.41644886;-
named estimators named estimators is consistent across all;1.1107703;-0.4164213;-2.5733879;3.269401;0.13317068;4.381042;-
ensemble classes and when using set params;3.63186;-1.4614891;-0.4906511;3.6552625;5.3454056;1.5892761;IRRE
estimator clone estimator avoid side effects from shared instances;1.1206807;0.7873871;-2.0372317;5.011927;-1.3823977;5.6544023;CODE
before fit;0.24353704;1.1049862;3.0077193;3.021409;-0.04904409;1.0888522;CODE
check fitted attributes;3.2522113;3.8949406;-0.45859113;1.1510062;0.67527443;-0.24163501;META
check that set params does not add a new attribute;-2.6963394;5.9709487;-1.3846174;3.7349966;1.0189672;-0.0766096;CODE
check the behavior when setting and dropping an estimator;0.89062583;5.4703465;-1.348209;7.137074;-3.9859998;3.2267709;IRRE
check that the correspondence is correct;-1.2850296;3.9138782;-0.15242001;-1.7364143;1.4339361;-2.7821507;-
check that we can set the parameters of the underlying classifier;3.2219093;0.38028988;-2.7717311;4.417539;3.85373;0.8996051;IRRE
check that ensemble will fail during validation if the underlying;3.3992124;3.439013;-4.466925;7.174596;1.756659;-1.1901871;-
estimators are not of the same type i e classifier or regressor;2.011497;0.36568177;-3.305286;-0.11801648;-1.6219296;1.4947882;IRRE
stackingclassifier can have an underlying regresor so it s not checked;-1.2936976;1.0921608;-4.3486094;3.4696972;0.7755584;2.71067;IRRE
raise an error when the name contains dunder;-2.4177597;3.8133233;-3.020059;2.3063717;1.4079258;-2.2689593;CODE
raise an error when the name is not unique;-0.6649959;5.082772;-2.3619506;2.981177;3.4478476;-1.9682468;CODE
raise an error when the name conflicts with the parameters;-2.910704;5.4052453;-2.8120944;3.3310843;1.1160381;0.19056399;IRRE
check that we raise a consistent error when all estimators are;2.8767867;5.70448;-3.121771;6.197796;-3.493067;2.1486378;CODE
dropped;-1.6039472;1.3710659;4.3890543;1.4298252;-0.7007899;-2.52439;-
fixme we should move this test in estimator checks once we are able;0.8696925;4.9389224;-4.515658;6.2542768;-4.459895;-0.49102986;IRRE
to construct meta estimator instances;2.4575126;0.07199714;-0.49830437;4.6748548;2.4948182;3.538597;CODE
check that voting and stacking predictor delegate the missing values;2.3027651;2.8430583;-2.2400665;2.3804276;0.6152047;-0.8994853;IRRE
validation to the underlying estimator;3.209039;2.9940221;-1.398177;6.1635556;0.25057593;1.3958222;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
toy sample;0.09531039;-1.1268612;5.4498596;1.2328323;2.0021768;-3.605327;-
larger classification sample used for testing feature importances;5.323455;-3.0548441;-0.81735474;3.8222697;3.1239893;-1.198405;CODE
also load the iris dataset;1.5464042;-4.3465104;-0.13598996;-1.1130621;-0.53984874;0.6428218;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
make regression dataset;5.4628153;-3.0902746;1.7543378;-0.8543766;-0.5427107;-0.8046613;IRRE
also make a hastie 10 2 dataset;5.3976398;-2.5890253;1.4875705;-2.8598824;3.4398954;-1.8018256;IRRE
get the default backend in joblib to test parallelism and interaction with;-3.250344;-0.39628765;-2.0737665;4.182105;-3.144628;0.012410834;CODE
different backends;-5.140824;-4.0187497;4.3874207;1.323094;0.7234259;0.95268023;CODE
regression models should not have a classes attribute;0.7808199;-1.0062997;-3.6122098;2.1866913;1.0165858;1.2649599;IRRE
predict probabilities;4.265847;-2.253928;2.852144;2.9215846;1.3508704;-2.3749144;-
cast as dtype;-1.2694733;-3.320049;-2.0742517;-0.4425676;-0.4698836;-0.35667783;-
the forest estimator can detect that only the first 3 features of the;2.2543507;-1.5020423;0.28924823;1.734568;3.5836403;0.6834491;TASK
dataset are informative;5.1714654;-6.0324893;2.0110412;1.5883054;3.422519;-1.4219681;IRRE
check with parallel;1.0801039;4.1755824;2.0271785;1.0691923;0.53613055;-4.4813266;-
check with sample weights;6.395095;4.1662784;-0.029028868;2.435105;1.3333906;-3.4375296;-
check whether variable importances of totally randomized trees;3.1158063;-0.8595353;-1.743009;3.0100498;3.860401;0.42898795;CODE
converge towards their theoretical values see louppe et al;1.8819497;-1.8162947;0.668018;4.3787904;-1.2568803;0.83078533;IRRE
understanding variable importances in forests of randomized trees 2013;1.5856869;-5.1886277;0.17494589;2.7620049;2.5044417;0.1537048;CODE
weight of each b of size k;2.8694842;0.17399625;2.8237665;-2.7037098;1.2417729;-1.0383098;-
for all b of size k;0.4430645;-0.49861822;3.5752647;-2.1476192;1.8119372;-2.1392055;CODE
for all values b b;2.955454;3.6851332;3.4519756;-5.1056023;3.0807846;-5.796849;IRRE
1 0 n samples b n samples p b b;3.0642612;2.6690845;0.8888693;-4.047352;2.766372;-3.251595;-
compute true importances;4.3713627;-0.14431737;1.9627057;0.28799778;2.4727116;-1.0117285;CODE
estimate importances with totally randomized trees;4.904335;-3.1637366;0.19993538;2.1846328;3.7161317;2.2599602;CODE
check correctness;-1.168317;5.309277;0.4789862;4.027742;0.80270606;-8.452853;-
check pickability;0.60845333;1.0233235;0.96168417;4.8015275;2.4390488;-3.8639965;-
check estimators on multi output problems;5.094029;3.5321546;-1.8351992;2.9980967;-1.6540823;0.40711415;IRRE
check estimators on multi output problems with string outputs;4.282986;3.7298133;-2.749571;2.2293549;-0.40330026;-1.9784747;IRRE
test that n classes and classes have proper shape;4.2933025;1.668933;-0.7645385;1.061153;3.2756472;-3.3880591;IRRE
classification single output;6.1762466;-2.9361827;1.4179972;0.3883535;4.957419;-1.6149068;IRRE
classification multi output;6.271925;-3.1803617;1.9575181;-0.90821844;5.6696854;-1.1859078;IRRE
test that the sparse output parameter of randomtreesembedding;4.034608;-0.44601375;-3.4972694;3.0871618;1.3531749;0.62065434;IRRE
works by returning a dense array;1.788164;4.0072346;-0.88483506;-1.0945276;-1.4066229;-2.0898325;IRRE
create the rte with sparse false;2.131109;2.7477384;-2.841489;-2.0247486;-0.16083322;0.9963963;IRRE
assert that type is ndarray not scipy sparse csr matrix;2.2768486;1.3509362;-8.484836;-2.8617644;-3.400944;-0.98702496;IRRE
test that the sparse output parameter of randomtreesembedding;4.034608;-0.44601375;-3.4972694;3.0871618;1.3531749;0.62065434;IRRE
works by returning the same array for both argument values;-0.4692036;6.985799;0.07742723;-0.85161424;-0.6820818;-2.519874;IRRE
create the rtes;-2.7006412;-2.576561;1.7725991;-2.865634;0.7206519;-0.92331225;IRRE
assert that dense and sparse hashers have same array;2.6281488;3.5812817;-3.4297903;-0.4550991;1.724817;0.13093139;IRRE
test random forest hashing on circles dataset;3.9147835;-1.3105376;-1.6386495;1.4508421;1.3570538;-2.7759104;IRRE
make sure that it is linearly separable;1.4985828;2.8566396;-2.6461244;-3.1252732;-0.7547279;2.1310227;-
even after projected to two svd dimensions;2.4726636;-0.4625741;-2.2850559;-2.9992251;-1.5763777;5.8692985;-
note not all random states produce perfect results;1.9009985;2.7425382;-1.5040969;2.109733;-1.2876834;-1.3529599;IRRE
test fit and transform;5.4256516;3.5474832;-0.15894172;0.9748278;-1.3938851;-2.7862759;IRRE
one leaf active per data point per forest;3.1225188;-0.7519496;2.2357392;-1.0826253;2.7402523;3.4347978;CODE
single variable with 4 values;1.1650378;3.8570318;4.119284;-4.8190722;2.3391964;-3.9273024;IRRE
on a single variable problem where x 0 has 4 equiprobable values there;0.9387086;3.5915236;1.911117;-2.165338;1.2949735;-1.9047794;IRRE
are 5 ways to build a random tree the more compact 0 1 0 0 0 2 of;0.8127153;-1.8764675;1.4386623;-0.99312645;3.8913453;-1.4737359;IRRE
them has probability 1 3 while the 4 others have probability 1 6;-0.74299085;0.7374242;2.4506552;-0.9061378;2.9552839;-3.3703399;CODE
assert 0 20 uniques 0 0 rough approximation of 1 6;4.282382;4.7348547;-1.9459021;-1.2867664;0.2253575;-5.5664973;CODE
two variables one with 2 values one with 3 values;-0.71792114;2.6513608;2.9648755;-5.8584924;1.2079809;-3.1894956;IRRE
test precedence of max leaf nodes over max depth;1.8660803;4.485045;0.053680383;1.8083799;2.0946486;-0.4783919;IRRE
test if leaves contain more than leaf count training examples;2.5714824;2.5110703;0.22354606;2.8602724;3.2457516;-4.9761806;IRRE
drop inner nodes;1.2498952;1.7023883;2.3922381;-1.9994121;0.32444257;3.1301131;-
drop inner nodes;1.2498952;1.7023883;2.3922381;-1.9994121;0.32444257;3.1301131;-
test if leaves contain at least min weight fraction leaf of the;2.4135008;4.2899013;0.28360903;0.45446932;1.1910084;-2.7063508;IRRE
training set;2.5613565;-3.9551353;3.8796027;0.98318845;2.6271846;-1.2734559;IRRE
test both depthfirsttreebuilder and bestfirsttreebuilder;-0.12324812;2.0533638;-2.774997;4.7300735;2.367405;-1.3352383;IRRE
by setting max leaf nodes;0.40057382;-0.13837983;3.2822185;-1.2170144;0.5237301;1.880574;IRRE
drop inner nodes;1.2498952;1.7023883;2.3922381;-1.9994121;0.32444257;3.1301131;-
test that it works no matter the memory layout;-3.4256155;3.3477445;-1.1345142;1.4172679;-0.8019604;0.4869851;IRRE
dense;-0.45144767;-1.2325659;4.2241225;0.4093085;-0.055715483;-2.2632747;-
np asarray nothing;-3.7372396;-0.3398448;1.2759074;-4.042155;-2.1817157;-2.7306666;-
np asarray order c c order;-2.7998803;0.8776249;0.37355864;-4.5553317;1.0467892;-2.5269513;-
np asarray order f f order;-2.1172354;1.0949519;1.239755;-4.332544;0.7585056;-2.140995;CODE
np ascontiguousarray contiguous;2.9153616;2.0073621;-1.841467;-7.1529574;-0.7439369;0.7006998;-
sparse if applicable;4.868164;1.0997446;0.2536463;-0.24937904;2.292845;-0.13568044;IRRE
strided;-2.3499353;-1.07886;2.6548412;0.6789499;0.7450382;-0.85803777;-
check class weights resemble sample weights behavior;5.6607275;1.8375273;-3.3491814;3.6000395;0.7570992;-0.20231852;IRRE
iris is balanced so no effect expected for using balanced weights;0.88794667;3.4332461;-2.1008587;0.110785276;-2.4686332;1.8834249;CODE
make a multi output problem with three copies of iris;1.1664597;2.882182;0.71608;-3.740641;2.201678;-1.4765903;IRRE
create user defined weights that should balance over the outputs;4.502186;1.9039869;1.4588318;-1.7463223;0.75755054;2.6221657;IRRE
check against multi output balanced which should also have no effect;2.0182598;7.1419015;-0.91113317;0.51873827;-0.31529427;-3.2108397;IRRE
inflate importance of class 1 check against user defined weights;3.549155;2.7990115;-2.0915527;4.164784;1.9934494;2.2217896;CODE
check that sample weight and class weight are multiplicative;5.038449;3.0770671;-2.7447648;0.95371515;2.55848;-1.9821092;IRRE
note nodes with indices 0 1 and 4 are internal split nodes and;-0.36839938;1.1333249;-1.770898;-6.5026164;1.465122;-0.7455884;TASK
therefore do not appear in the expected output feature names;-3.3520916;-0.44889548;-4.237091;0.3444215;-0.355784;-1.429345;CODE
test repeated calls result in same set of indices;4.144272;6.8060164;-1.6255348;2.2902532;1.0107961;-3.9759417;IRRE
the bootstrap should be a resampling with replacement;1.6309121;-0.3723031;0.12440199;-0.1066125;-0.8215549;3.000584;-
toy sample;0.09531039;-1.1268612;5.4498596;1.2328323;2.0021768;-3.605327;-
also make regression dataset;5.934229;-5.825475;2.6990654;1.0456173;-0.26128972;-1.2136929;IRRE
also load the iris dataset;1.5464042;-4.3465104;-0.13598996;-1.1130621;-0.53984874;0.6428218;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
check classification on a toy dataset;5.1126094;-2.951145;-0.18973042;2.355515;4.227479;-4.308819;IRRE
test gradientboostingclassifier on synthetic dataset used by;5.5282784;-3.3600516;-4.350104;2.3163095;1.962804;-0.35314482;IRRE
hastie et al in eslii figure 10 9;-2.6982477;0.36008337;1.4986793;-2.186029;-0.78197914;-1.3793648;-
note that figure 10 9 reuses the dataset generated for figure 10 2;3.1807973;-2.6868842;-0.101084374;-2.5601585;-1.7417152;0.45393485;TASK
and should have 2 000 train data points and 10 000 test data points;4.5200114;0.39431474;0.03787612;1.2647973;2.2959404;-1.2883644;CODE
here we intentionally use a smaller variant to make the test run faster;3.0454628;2.961298;-1.7083766;6.4901843;0.061632846;-2.2595484;CODE
but the conclusions are still the same despite the smaller datasets;5.407935;-0.6328522;-0.40052873;3.743022;-0.75550044;0.092366636;TASK
increasing the number of trees should decrease the test error;1.2058947;3.5532033;-3.6951344;4.851821;0.5944015;-4.1844068;IRRE
decision stumps are better suited for this dataset with a large number of;7.500473;-2.9750335;1.7784832;2.1471598;3.717697;-2.0784774;CODE
estimators;2.3262725;-0.61843187;3.9596899;3.1279066;-1.2442536;0.7653516;-
check consistency on regression dataset with least squares;4.676813;2.046026;-2.4521463;2.9935772;-3.5507581;0.92656577;IRRE
and least absolute deviation;4.331336;0.18346058;1.0879139;-1.1494236;0.16385289;0.5995263;-
learning rate max depth and n estimators were adjusted to get a mode;3.0163915;-2.7177346;-0.1704427;0.17678279;-1.5087488;4.4364066;CODE
that is accurate enough to reach a low mse on the training set while;3.5737903;-1.1509275;-0.7421759;4.2532153;-1.5077876;0.35213485;IRRE
keeping the resource used to execute this test low enough;-0.6182703;5.9948473;0.065288834;7.4572973;-0.32425392;-0.52038646;CODE
fixme we temporarily bypass this test this is due to the fact;-3.5353286;2.5606482;-4.294363;6.171477;-3.0727403;-3.6501884;CODE
that gbrt with and without sample weight do not use the same;1.2248229;1.1415093;-3.0614314;-0.2150563;-0.02626839;2.041244;IRRE
implementation of the median during the initialization with the;0.8264476;1.4787124;1.5614599;-0.64845604;-1.1084279;2.1946094;TASK
dummyregressor in the future we should make sure that both;-2.1566958;1.2982674;-0.78819805;4.579997;0.51639193;0.1541916;TASK
implementations should be the same see pr 17377 for more;-3.391569;-3.3828156;-4.169843;1.8614529;3.8474603;2.2864134;TASK
assert allclose last y pred y pred;0.22122532;6.506615;-0.6485527;3.0499692;0.71188515;-3.096079;CODE
check consistency on dataset iris;4.410563;1.6984775;-3.7309673;1.764228;0.5863222;-1.2973349;IRRE
test on synthetic regression datasets used in leo breiman;3.1993473;-1.397337;-3.4924586;3.781209;-1.1726145;-3.6778321;IRRE
bagging predictors machine learning 24 2 123 140 1996;5.7774353;-5.2256513;-1.2471267;1.2774848;2.1374543;-1.2123536;-
friedman1;-1.5613166;-3.089134;2.1991231;-1.5160375;-0.99819237;-3.738219;-
friedman2;-0.48549098;-4.533483;2.601412;-0.8939264;-0.6407551;-3.099379;-
friedman3;-1.3622682;-4.266625;2.2516859;-2.0069795;-0.46258178;-3.2172084;-
smoke test to check that the gradient boosting expose an attribute;3.1658723;1.3422608;-1.5730592;4.1499553;1.224583;0.71769655;IRRE
feature importances;1.9864721;-6.039988;3.8674636;2.4415276;2.7463691;1.3241955;CODE
predict probabilities;4.265847;-2.253928;2.852144;2.9215846;1.3508704;-2.3749144;-
check if probabilities are in 0 1;0.82182086;3.6258862;-0.22726624;-0.2711091;0.18756875;-4.7901654;IRRE
derive predictions from probabilities;4.6441584;-3.2759144;2.659147;4.1629157;1.4723809;-1.2736806;CODE
check that predict stages through an error if the type of x is not;3.0418715;4.6121373;-2.328368;2.9861624;0.57119596;-2.0374022;-
supported;-4.929468;-3.8329413;2.6012824;1.1891209;0.33778575;-0.031595215;-
test to make sure random state is set properly;2.2690446;5.3004136;-0.23072255;6.036633;0.6715917;-4.580979;IRRE
the most important feature is the median income by far;1.6934853;-2.9436533;2.145034;1.1171919;-0.39032078;1.8798974;CODE
the three subsequent features are the following their relative ordering;0.17691915;-2.1058404;2.501427;-3.4987836;5.405439;0.86455375;TASK
might change a bit depending on the randomness of the trees and the;0.80954534;-1.9071032;2.4218352;3.7953775;1.4773903;-0.47854406;IRRE
train test split;4.160898;2.1980376;1.0679042;2.8806887;2.763753;-3.8187416;IRRE
test if max features is set properly for floats and str;3.6720884;4.1445055;-2.8574474;-0.20835271;-1.1104507;-2.7866921;IRRE
test whether staged decision function eventually gives;1.3918256;4.4802713;-1.0904591;6.7646117;1.8313296;-1.4303408;IRRE
the same prediction;2.3423567;-1.7224598;3.4350698;4.989226;-1.1747773;-0.7163538;-
test raise valueerror if not fitted;2.4593813;7.164411;-5.168643;3.551302;-4.698004;-3.7424576;IRRE
test if prediction for last stage equals predict;3.465542;4.716759;0.26097155;6.2111797;0.83947724;-2.476001;IRRE
test whether staged predict proba eventually gives;3.2177274;2.9064593;-2.2142894;7.5746984;-0.1837511;-1.522822;IRRE
the same prediction;2.3423567;-1.7224598;3.4350698;4.989226;-1.1747773;-0.7163538;-
test raise notfittederror if not;0.22968902;6.738481;-5.3411436;5.761312;-4.7017727;-4.6146035;IRRE
test if prediction for last stage equals predict;3.465542;4.716759;0.26097155;6.2111797;0.83947724;-2.476001;IRRE
test if prediction for last stage equals predict proba;3.0617015;3.8483365;-0.04053787;6.0075326;0.9653896;-2.0445673;IRRE
test that staged functions make defensive copies;-1.4596786;4.2675176;-2.451123;6.0696683;-0.047788274;-2.6131966;CODE
y 4 x 0 astype int 1 don t predict zeros;1.7590555;3.0269492;-3.0269349;-3.7910106;-4.394158;-2.4848452;CODE
regressor has no staged predict proba;0.4205752;1.1339774;-3.6497653;2.8621325;-3.4124289;0.54156023;-
check model serialization;0.96540964;2.3551712;-2.6138623;3.5066524;2.7927923;-0.24142848;-
check if we can fit even though all targets are equal;4.2829514;4.8471923;0.42047614;2.2305422;0.65099764;-0.6451973;IRRE
classifier should raise exception;1.2998174;-0.056683544;-4.4438295;5.096902;2.7263484;-0.8271696;CODE
check if quantile loss with alpha 0 5 equals absolute error;1.7965534;5.209496;-2.471576;0.16243918;-3.724551;-1.4443593;IRRE
test with non integer class labels;3.0537245;4.116738;-2.7291632;-0.31787866;4.0362835;-6.127547;IRRE
test with float class labels;3.5469773;3.7303765;-2.194451;-0.7539387;1.0773422;-5.054754;IRRE
test with float class labels;3.5469773;3.7303765;-2.194451;-0.7539387;1.0773422;-5.054754;IRRE
this will raise a dataconversionwarning that we want to;0.0469948;-3.5821016;-1.2852489;4.7102046;1.6553321;3.97401;CODE
always raise elsewhere the warnings gets ignored in the;-2.5813;1.7462986;-1.93774;5.26411;-1.8264141;1.4357969;CODE
later tests and the tests that check for this warning fail;-1.9329355;4.141964;-4.357976;8.032054;-1.45859;-4.2729344;IRRE
test with different memory layouts of x and y;0.8676151;4.0193663;0.12606812;-1.5692221;-0.12480279;-1.8212458;IRRE
test if oob improvement has correct shape and regression test;3.348335;2.1372302;-2.2979772;3.9897285;-0.3034221;-1.9718524;IRRE
hard coded regression test change if modification in oob computation;2.5018523;2.8321786;-4.3115025;3.5576558;-1.0424707;-1.8664898;IRRE
test if oob scores has correct shape and regression test;3.573097;2.6747549;-2.7814848;2.0398662;-0.32389006;-3.3685708;IRRE
check oob improvement on multi class dataset;5.082184;-1.4824835;-4.1340837;2.193568;4.152718;-1.5772928;IRRE
hard coded regression test change if modification in oob computation;2.5018523;2.8321786;-4.3115025;3.5576558;-1.0424707;-1.8664898;IRRE
fixme the following snippet does not yield the same results on 32 bits;-3.2557583;3.0505345;-5.1885953;-4.0568485;-1.4914234;-2.824881;IRRE
assert array almost equal estimator oob improvement 5;5.5401163;5.5269322;-4.977088;3.2545967;-0.55572134;-2.3694143;TASK
np array 12 68 10 45 8 18 6 43 5 13;0.82466084;0.36272082;1.118604;-8.041287;-1.1149209;-5.1256285;-
decimal 2;-1.175765;1.1147727;2.89794;-3.7084649;-1.9065342;-5.5038123;-
pytest mark thread unsafe manually captured stdout;-3.4542491;1.6311595;-2.386387;2.2372425;-4.13873;0.8035803;CODE
check verbose 1 does not cause error;-4.2005515;7.3645043;-3.4174187;3.9954572;-1.7709651;-4.74703;IRRE
check output;-0.98659337;5.095306;2.0797615;0.57101035;-0.89581877;-8.508085;IRRE
with oob;-2.1133912;-3.2008274;4.1737676;0.22925144;0.57292205;-1.7590533;-
one for 1 10 and then 9 for 20 100;-0.2884225;1.5836402;3.6335018;-2.2539213;1.2199599;-3.5307581;CODE
pytest mark thread unsafe manually captured stdout;-3.4542491;1.6311595;-2.386387;2.2372425;-4.13873;0.8035803;CODE
check verbose 2 does not cause error;-4.618623;6.940581;-3.525172;3.9348488;-1.874983;-4.2595677;IRRE
check output;-0.98659337;5.095306;2.0797615;0.57101035;-0.89581877;-8.508085;IRRE
no oob;-3.5891883;-1.8881673;2.8697245;-1.3012899;0.462561;-1.4940835;-
100 lines for n estimators 100;3.5330894;1.3492472;1.2000731;-0.915916;-1.6647071;0.36236432;CODE
test if warm start equals fit;2.6784182;4.5872855;-0.37364516;3.2641697;-0.46640325;-2.4206805;IRRE
random state is preserved and hence predict proba must also be;1.4778342;0.23767416;-0.33884782;3.9420152;1.4894549;1.0589819;IRRE
same;-2.970426;-1.5172942;2.8265855;1.9994456;-2.1783886;-0.47579575;-
test if warm start equals fit set n estimators;4.767929;4.220314;-1.484081;3.1730232;-1.7434843;0.07515596;IRRE
test if possible to fit trees of different depth in ensemble;4.6841507;0.88513;-1.2881294;2.8603828;3.8811123;-0.78462577;IRRE
last 10 trees have different depth;0.20853114;-0.9426855;2.724279;-0.61184305;1.9711173;-0.3111472;-
test if fit clears state;3.0497127;6.998608;-1.4530278;4.483311;-1.2644426;-0.5542827;IRRE
est 2 fit x y inits state;1.3471799;2.4312923;1.3441752;-1.2041463;-0.3090549;1.1662503;IRRE
est 2 fit x y clears old state and equals est;0.35945347;4.183703;-0.7775249;-1.8158493;-0.86498344;1.572101;-
test if warm start with smaller n estimators raises error;3.451629;5.4128194;-4.990792;4.235681;-4.3681135;-0.5343555;IRRE
test if warm start with equal n estimators does nothing;2.7572489;5.7876797;-2.9076145;4.2804556;-3.843232;-1.8507582;IRRE
test if oob can be turned on during warm start;-1.555179;1.9083241;0.061318867;4.0983367;-0.27010718;-2.0052605;IRRE
the last 10 are not zeros;-0.28126538;2.8998265;1.1078632;-3.1428034;-1.5274978;-4.6880865;-
test if warm start oob equals fit;1.7170007;3.3018882;-2.4646556;2.523556;0.35055688;-2.0299911;IRRE
test that all sparse matrix types are supported;3.5917156;1.4027383;-6.546048;0.44293535;0.22655371;0.8905419;IRRE
test that feeding a x in fortran ordered is giving the same results as;1.4190769;5.099852;-3.5899036;-1.6255809;-2.39794;-4.257445;IRRE
in c ordered;-1.7507943;1.3581358;3.09211;-4.4280367;2.1927304;-3.7675962;-
we want an asymmetric distribution;0.74355817;-0.08885046;5.300043;0.21195619;0.81417984;-0.13773088;META
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load iris diabetes dataset;3.8043153;-3.1406214;-0.39922684;-1.6552521;-0.006879206;0.22196926;IRRE
trained on sparse format;6.8429346;-4.56035;-1.8299532;-0.9784787;2.5721352;0.9050573;CODE
trained on dense format;5.2517204;-5.14741;-1.1186123;0.3762311;2.1888788;-1.1586736;CODE
generate train test data;5.4570518;1.0310016;1.0194211;0.9852596;1.6887379;-4.5770183;CODE
generate some abnormal novel observations;5.389696;-1.1086786;1.1809517;1.1423573;-0.67577666;-1.1810746;-
fit the model;1.4823507;-1.8818413;3.3056061;0.78029215;0.8633571;-0.14115278;-
predict scores the lower the more normal;5.2460327;0.7391276;1.653883;1.6293408;-0.15331581;-2.2397187;-
check that there is at most 6 errors false positive or false negative;1.2500474;5.903291;-2.9072;2.707349;0.70895284;-6.897056;-
toy sample the last two samples are outliers;3.9382617;2.7343247;0.1671023;0.44581926;-1.2977628;-2.6877103;CODE
test isolationforest;0.28312522;1.8126594;-2.3545196;5.436669;1.3005086;-2.9227662;IRRE
assert detect outliers;4.935828;4.5684857;-3.7353523;4.4424253;-0.51222575;-3.6744318;CODE
make sure validated max samples in iforest and basebagging are identical;3.2672007;4.504809;-4.3520875;3.6051612;0.9776866;-0.61654866;CODE
it tests non regression for 5732 which failed at predict;-0.9570692;1.7941136;-5.1143;4.051318;-4.3854513;-5.2342987;IRRE
it tests non regression for 8549 which used the wrong formula;-0.027706088;2.1145105;-4.688406;1.7258228;-4.073212;-3.8069797;CODE
for average path length strictly for the integer case;2.6296017;2.3081455;1.112521;-1.5031708;0.39839137;0.15333746;CODE
updated to check average path length when input is 2 issue 11839;0.74795854;3.29488;-1.2273222;-0.2275173;-1.9865118;-2.822407;CODE
average path length is increasing;1.3723444;1.2851844;1.6890638;-0.086601496;-4.021072;1.3601052;CODE
2 d array of all 1s;4.393151;2.8691437;3.153775;-7.8928037;-0.15458915;-2.5752358;-
2 d array where columns contain the same value across rows;5.2298794;2.761019;2.0113575;-6.4861135;0.17860508;-1.9356846;IRRE
single row;2.1388562;1.5876497;6.3041153;-4.032291;3.314376;-3.0877357;-
mock out fit and stack method to be asserted later;2.2120264;4.895084;-1.3377409;5.9537797;-0.061302807;1.071316;CODE
mocking a method will not provide a name while python methods;-1.8041401;2.2732804;-3.7534997;4.2300715;-3.5789087;-3.5237179;CODE
do and we are using it in get response method;-3.8103092;1.7068197;3.5237525;3.4397066;-0.27860373;-1.1503173;CODE
fit was not called again;-1.6353328;3.5450299;0.50804913;2.5871534;-1.9562979;1.0053524;IRRE
stack method is called with the proper inputs;-2.3695252;1.0532265;1.7651943;1.0764732;0.40207645;-0.0870304;IRRE
check that notfittederror is raised;0.25356597;6.377418;-5.411134;5.6283374;-4.6417985;-3.776398;CODE
if base estimators are not fitted when cv prefit;2.6975195;3.1685994;-4.504428;3.62886;-2.3795166;4.4813313;-
stacking supports estimators without n features in regression test;3.4156044;0.078960896;-2.8719199;3.0903327;0.56610334;1.8145053;TASK
for 17353;-3.4997551;-0.028690524;2.6781495;-1.850373;0.42444694;-3.308608;CODE
access sub estimator in name est with estimator 1;0.8785293;2.0050802;-1.183583;1.5253295;0.97807187;2.8953054;-
access final estimator;-0.03411672;1.3564982;0.69949186;3.1892252;-1.6522108;2.8012252;CODE
check that an estimator can be set to drop and passing some weight;3.162153;4.4720225;-0.6483397;4.605822;-2.6551678;2.45887;IRRE
regression test for;2.4998717;3.807307;1.2143148;4.486459;-2.3460186;-7.2211394;IRRE
https github com scikit learn scikit learn issues 13777;-2.9660506;-10.133523;-5.7643833;0.17168595;-5.3558745;-5.2825165;CODE
scaled to solve convergencewarning throw by logistic regression;3.745692;0.26889342;-2.2212687;3.1435313;-3.9052994;2.9928098;CODE
access sub estimator in name est with estimator 1;0.8785293;2.0050802;-1.183583;1.5253295;0.97807187;2.8953054;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
use settattr to avoid mypy errors when monkeypatching;-2.088837;2.9631286;-2.2318294;0.7998593;-4.0707846;0.21762118;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
don t remove this file we don t want to break users code just because the;-6.7022543;0.3233746;-0.51280296;0.46657372;-1.0417166;-0.2704191;CODE
feature isn t experimental anymore;-1.9843119;-2.6368086;-1.6473521;4.654839;-3.9727182;-0.6835032;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
use settattr to avoid mypy errors when monkeypatching;-2.088837;2.9631286;-2.2318294;0.7998593;-4.0707846;0.21762118;IRRE
from sklearn experimental import enable hist gradient boosting noqa;1.3746471;-3.7984788;-5.8208504;-0.7609419;-3.5772917;0.4304685;CODE
federal university of rio grande do sul ufrgs;-1.8715283;-4.140185;-0.6367133;0.8429923;0.6429909;-0.5882691;IRRE
connectionist artificial intelligence laboratory liac;0.17644311;-5.5260735;0.39238223;1.474873;0.24064893;-2.6661763;CODE
renato de pontes pereira rppereira inf ufrgs br;-2.5107553;-0.46498495;1.6342849;1.2004555;0.8263374;-0.2580173;-
copyright c 2011 renato de pontes pereira renato ppontes at gmail dot com;-4.884933;-2.8510015;1.4881995;-0.11184502;1.571015;-0.361559;CODE
permission is hereby granted free of charge to any person obtaining a copy;-5.26728;-2.8850343;0.44421828;-1.2080314;0.2010172;-0.106646284;CODE
of this software and associated documentation files the software to deal;-4.259975;-8.697942;1.2858801;1.5226647;2.9138794;0.12587412;CODE
in the software without restriction including without limitation the rights;-4.9826736;-3.6631806;0.95395833;0.100634694;3.260945;0.37792516;CODE
to use copy modify merge publish distribute sublicense and or sell;-4.3756475;-0.27743837;-0.5955661;-0.10053646;2.5948322;3.1916473;META
copies of the software and to permit persons to whom the software is;-3.8927224;-4.8896074;0.59407276;1.3463122;3.5372615;-0.1307833;-
furnished to do so subject to the following conditions;-3.9156249;0.71704715;4.2957363;-0.14874268;5.815407;0.43755567;TASK
the above copyright notice and this permission notice shall be included in;-7.384657;-3.9839363;0.91111827;-0.6444856;1.1845264;0.48691267;CODE
all copies or substantial portions of the software;-2.5470006;-5.0271635;1.2746357;1.6229631;3.2310207;-0.7400069;-
the software is provided as is without warranty of any kind express or;-4.1047316;-3.4038374;-0.8592677;1.31469;-0.03405283;0.41296607;-
implied including but not limited to the warranties of merchantability;-2.8900888;1.3910481;-1.0895584;2.4876125;4.79405;2.2625303;META
fitness for a particular purpose and noninfringement in no event shall the;-1.9547422;0.16688769;0.7099427;5.207557;2.767584;0.700331;CODE
authors or copyright holders be liable for any claim damages or other;-3.4910662;-2.384658;-1.9625244;1.024116;0.09695671;-0.36048895;OUTD
liability whether in an action of contract tort or otherwise arising from;-4.6000195;1.9135303;-0.15376925;2.2389545;1.2191103;1.0837619;CODE
out of or in connection with the software or the use or other dealings in the;-3.4355323;-5.8508697;3.052755;2.5512204;2.0134645;-0.7160237;CODE
software;-1.6231102;-7.44677;5.0367627;1.8323617;1.6376363;-4.1100783;-
org doc scipy reference generated scipy sparse coo matrix html scipy sparse coo matrix;1.150504;-4.311039;-4.712291;-4.8383827;-3.3236341;1.4268467;IRRE
constants;-0.8768149;1.1299901;3.420978;-2.576763;-0.78344524;-2.9715178;CODE
typing extensions is available when mypy is installed;-5.2130756;-2.1871676;-2.218126;-0.17318037;-2.613102;1.2581247;-
open quote followed by zero or more of;-4.7043686;2.3255289;0.022620471;-1.421184;0.17453836;-2.8823404;CODE
no additional backslash;-7.759082;0.25873175;-0.11100138;-0.788558;1.0593426;-0.7183132;TASK
maybe escaped backslashes;-6.636192;-0.17799027;-1.4193163;0.06119937;-1.7078588;-1.2040266;-
escaped quote;-5.0189342;0.3329344;0.7924427;-0.3348919;-0.95959914;-1.8549052;-
escaping a non quote;-4.596079;0.9479616;-0.01220449;-0.27396962;-0.5933843;-0.8059581;CODE
non quote char;-3.7391713;-0.47189084;0.58503556;-2.3731554;-0.22021675;-2.8665576;CODE
close quote;-3.5136251;0.021196762;3.1292744;2.3486013;-0.4922711;-1.7984163;CODE
a value is surrounded by or by or contains no quotables;-0.36748734;4.339324;-0.4347806;-2.0390086;3.7271333;-4.3587093;IRRE
a value may be surrounded by;1.8770157;4.682863;4.7192802;-2.430377;1.9149379;-2.7303128;IRRE
or by;-1.416237;-0.48365054;3.5499856;1.8230267;1.4455912;-1.9054122;-
s or may contain no characters requiring quoting;-4.598806;0.4173999;-3.2668126;-0.5684506;1.1130016;-2.5825086;CODE
this captures value error groups because empty values are allowed;-0.2943231;7.1970973;-3.5508232;1.0362401;0.85989827;-2.8635619;IRRE
we cannot just look for empty values to handle syntax errors;-2.0574007;5.685224;-4.3294992;1.2677861;1.091807;-4.3846536;IRRE
we presume the line has had prepended;-5.491849;1.5754187;1.6247641;0.7604224;-1.1837643;-0.49733543;CODE
may follow;-1.1878756;-1.0250068;4.4114738;3.5716138;0.18870652;-0.53765386;-
value re empty or value;-1.3170404;7.0986247;1.1000249;-1.149142;0.7006703;-3.9183416;IRRE
s error;-3.579156;1.7524858;0.44877243;-0.48469958;-0.9824081;-4.538228;-
this captures key value groups and will have an empty key value;-2.101937;3.1977696;0.14527595;-1.8826407;2.6431491;-0.71815157;IRRE
in case of syntax errors;-4.023366;0.82503444;-1.0749766;1.9209473;1.5756571;-4.6685405;CODE
it does not ensure that the line starts with or ends with;-4.3230114;3.937328;-0.09840045;0.07808283;-0.16740587;-0.018896922;CODE
s may follow or at line start;-3.2494533;-0.300418;4.5453873;2.5261266;0.6685265;-0.0941243;-
d attribute key;-2.2387881;-0.36861393;-0.78503615;-4.0452266;3.630988;-0.2172546;META
value re s value;-0.86424863;4.3083;2.155271;-3.4268026;-0.24841368;-4.206786;IRRE
s not an error if it s;-3.811608;2.9497926;-1.37543;1.9381269;-0.78790134;-3.623736;-
s s s not an error if it s;-2.6744435;2.1482408;-0.93128175;1.5680054;-0.4060898;-4.1456423;-
s error;-3.579156;1.7524858;0.44877243;-0.48469958;-0.9824081;-4.538228;-
fast path for trivial cases unfortunately we have to handle missing;0.2002598;-0.6234494;-0.1172945;2.3916175;1.7642081;1.2793156;CODE
values because of the empty string case;-0.6306295;6.3609304;-0.090001054;-1.853345;2.2515748;-5.465496;IRRE
re dense values tokenizes despite quoting whitespace etc;-0.18994027;1.6794847;-4.4349866;-2.463804;-1.3387165;-0.1230232;IRRE
an arff syntax error in sparse data;4.349101;0.3699442;-4.8352785;-3.0192761;-1.3935635;0.6593511;IRRE
an arff syntax error;-2.1998181;2.9295933;-1.8026503;-2.0425408;-1.5010347;-2.07959;-
dense 0 constant value representing a dense matrix;2.3557801;2.4514558;-2.845722;-5.654536;-2.2432826;2.5501773;IRRE
coo 1 constant value representing a sparse matrix in coordinate format;4.3455663;0.41615245;-2.8495414;-7.966211;-2.8754675;4.02512;IRRE
lod 2 constant value representing a sparse matrix in list of;5.107271;1.6446174;-3.2124946;-5.991965;-0.11661164;2.1361065;IRRE
dictionaries format;-0.50431174;-3.8667848;0.14060828;-4.3851867;2.1620233;-2.5833936;CODE
dense gen 3 generator of dictionaries;-0.7220788;-2.106009;-2.9881573;-3.1973147;2.0653706;0.1933086;-
lod gen 4 generator of dictionaries;-0.88173425;-2.498117;-2.7576132;-2.8940525;2.6770017;-0.4595886;-
exceptions;-3.007008;1.9451993;2.0586464;5.458023;0.88136214;-2.9776647;CODE
internal;-4.3479714;-2.1410604;5.6249447;1.7275206;1.4071658;-1.545764;CODE
sparse decode;4.4022655;-1.8603041;-2.0263014;-2.7938247;1.9803423;2.0805922;IRRE
see issue 52 nominals should take their first value when;-1.2564025;2.0995202;-0.80168205;0.37293702;3.303524;-2.58702;IRRE
unspecified in a sparse matrix naturally this is consistent;3.9804695;0.7566447;-4.38702;-3.3926558;0.68894094;2.5423484;IRRE
with encodednominalconversor;-0.10380006;-1.3497412;-2.6595614;-3.5023773;2.6213233;1.5403782;-
xxx int 0 is used for implicit values not 0;-1.9123468;4.9363484;-3.5902648;-5.999252;-3.0294178;-1.8854283;IRRE
do not rename this file;-5.4368134;0.8714239;-0.27704483;-0.6223225;-1.553672;-0.115703955;CODE
this is a hook for array api extra lib compat py;-3.343485;-0.03165526;-1.0093943;-1.501346;-2.6400433;0.0660034;CODE
to co vendor array api compat and potentially override its functions;-2.5771124;0.6163825;-2.640836;0.5660132;1.0028923;3.468951;CODE
from array api compat import noqa f403;-2.4827273;0.9073927;-3.970144;-3.7836623;-1.5280814;-0.91441727;CODE
elf str data split n store string as list of lines;1.0793837;0.3488813;-0.007447189;-3.7504737;1.6944104;-2.0841308;CODE
elf l 0 current line nr;-4.4187975;0.9681058;0.7809318;-3.2753563;-0.60582364;-2.3347898;-
l1 self doc peek strip e g parameters;-2.7618785;1.226545;-1.1278913;-0.17910153;1.0087729;2.3359914;CODE
l2 self doc peek 1 strip or;-3.2394874;-1.2357321;2.611788;-0.49258;0.4498689;0.6896875;CODE
if not self doc peek 1 strip previous line was empty;-6.928014;3.3666806;-0.6338677;1.4412158;-2.512593;-0.7218321;CODE
if name startswith index section;-2.5315075;3.4648635;2.168433;1.5805846;2.4969146;-0.74881774;-
note param line with single element should never have a;-4.379527;5.090389;0.20547472;-1.8930653;-0.2271696;-1.0787181;TASK
a before the description line so this should probably;-3.6617396;-0.34999505;2.2347877;0.62202126;2.305775;1.1774797;CODE
warn;-2.3767388;0.5380358;3.0784876;3.4188523;-1.1569048;-2.2426286;-
see also supports the following formats;-2.8057706;-4.2889857;0.747425;-3.4565816;2.5607617;1.4296006;CODE
funcname;-2.991276;-2.3528926;3.3285854;0.36885148;0.64208966;-3.2517664;-
funcname space colon space desc space;-3.1062367;-1.4246707;-0.6889133;-1.8233281;2.1492925;1.1331409;-
funcname comma space funcname comma period space;-3.010568;1.168539;0.29730156;-3.282482;1.1183906;-1.2373917;-
funcname comma space funcname space colon space desc space;-3.0941243;-0.24179587;-1.2591468;-2.25802;1.7233404;0.020862322;-
funcname is one of;-3.2841618;-2.8276627;1.3330845;0.6635266;2.2881458;-1.9754583;-
plain funcname;-3.8588417;-1.2910126;2.7380145;-0.45911208;1.2117472;-3.2200534;-
colon role colon backtick plain funcname backtick;-5.679825;-0.14625786;-0.93173707;-2.4538822;1.2510514;-0.95120305;-
where;-3.526096;-1.9471323;4.6898365;0.9650585;-0.80402994;-0.515195;-
plain funcname is a legal function name and;-6.3466353;-0.19118716;-1.2350266;-0.22896707;2.747777;-1.9730402;CODE
role is any nonempty sequence of word characters;-4.175995;-0.31648135;1.0710145;-0.7234802;2.8906267;-2.3601804;CODE
examples func f1 meth func h1 obj baz obj r class class j;-1.3367462;-1.9171793;-1.3353974;-1.1542279;2.976481;-3.0140624;IRRE
desc is a string describing the function;-2.4105325;0.6024241;1.0301975;-2.1412642;0.7884453;-3.205863;CODE
funcname group for all function names;-1.2869004;0.23665746;0.56214225;-0.38121963;2.4661896;-0.6046263;CODE
r p trailing end of allfuncs;-1.8727481;3.779384;0.09119738;-2.1968777;-3.1213815;-0.80197287;CODE
description some function lists have a trailing comma or period s;-2.3398473;1.2282982;-0.07655869;-1.9636818;0.5871212;-2.3299775;CODE
empty desc elements are replaced with;-3.8783767;4.0706725;-0.9355364;-2.5037723;-0.34259173;-1.0364103;-
if several signatures present take the last one;-1.6634026;3.363713;2.5325274;-0.2719723;5.0097857;-2.6716738;-
we could do more tests but we are not arbitrarily;1.4807246;0.85239214;0.757668;7.1272244;-0.5647686;-4.8517427;IRRE
we know where the docs came from;-1.9852245;-5.172753;0.8996217;2.568503;0.22526404;-0.46601328;CODE
make userwarning more descriptive via object introspection;-1.0428083;-1.9360697;1.2780653;4.8522477;1.9685612;1.4029297;CODE
skip if introspection fails;-2.1930478;4.8946443;-0.5894743;7.127896;1.0140836;-0.5584154;CODE
string conversion routines;0.953541;0.08074538;1.1884422;-1.5937842;-0.0072486056;-4.4012456;META
copyright c donald stufft and individual contributors;-3.3633761;-5.161555;0.15008801;-0.50794786;0.034547072;-2.1542103;META
all rights reserved;-6.1172695;-1.7122531;2.8031313;-1.001879;1.5156415;-0.6406165;-
redistribution and use in source and binary forms with or without;-2.6647937;-0.80558884;-2.205019;-1.0890408;5.278493;0.70217997;META
modification are permitted provided that the following conditions are met;-4.690063;1.632162;0.3372175;0.6699614;5.0898843;0.90391576;-
1 redistributions of source code must retain the above copyright notice;-5.293503;-2.4247677;-2.320428;0.47694176;1.5892305;-0.0031911582;META
this list of conditions and the following disclaimer;-3.1694458;1.9964614;-0.5951325;3.3097413;2.882659;-0.20676394;CODE
2 redistributions in binary form must reproduce the above copyright;-4.4733324;-0.49365726;-1.5629307;-2.6088657;3.1455169;-0.86478573;META
notice this list of conditions and the following disclaimer in the;-2.8765543;1.7101343;-1.1523315;3.3939996;2.5451956;1.0992507;CODE
documentation and or other materials provided with the distribution;-1.6212902;-6.150332;3.119261;0.3345237;3.852782;-0.056162048;CODE
this software is provided by the copyright holders and contributors as is and;-3.8302457;-7.2718143;0.6127078;-1.0228776;1.8997488;-1.1657168;OUTD
any express or implied warranties including but not limited to the implied;-2.3334541;2.328684;-1.331554;1.8353908;3.027354;0.43669343;META
warranties of merchantability and fitness for a particular purpose are;-1.6844977;0.62495637;-1.3823153;3.3848844;3.55545;0.70462275;CODE
disclaimed in no event shall the copyright holder or contributors be liable;-4.7723284;-0.5456694;-1.7100189;1.397545;0.58978075;0.78323656;OUTD
for any direct indirect incidental special exemplary or consequential;-3.2022939;0.4536465;3.0833898;3.4438407;3.706679;0.9345772;CODE
damages including but not limited to procurement of substitute goods or;-2.500769;1.1852741;-0.21752752;1.701609;2.4789255;0.9001056;META
services loss of use data or profits or business interruption however;-1.2989793;0.9621962;1.922926;2.2986257;-1.5823233;1.8186654;CODE
caused and on any theory of liability whether in contract strict liability;-4.705749;0.8723207;-1.0671368;3.498545;1.3559921;0.42416263;CODE
or tort including negligence or otherwise arising in any way out of the use;-5.125674;0.27472958;-0.9696112;4.9947133;1.5329208;2.292163;-
of this software even if advised of the possibility of such damage;-3.2526746;-3.8878937;0.90317816;2.5803292;-0.078712;-0.32149732;CODE
copyright c donald stufft and individual contributors;-3.3633761;-5.161555;0.15008801;-0.50794786;0.034547072;-2.1542103;META
all rights reserved;-6.1172695;-1.7122531;2.8031313;-1.001879;1.5156415;-0.6406165;-
redistribution and use in source and binary forms with or without;-2.6647937;-0.80558884;-2.205019;-1.0890408;5.278493;0.70217997;META
modification are permitted provided that the following conditions are met;-4.690063;1.632162;0.3372175;0.6699614;5.0898843;0.90391576;-
1 redistributions of source code must retain the above copyright notice;-5.293503;-2.4247677;-2.320428;0.47694176;1.5892305;-0.0031911582;META
this list of conditions and the following disclaimer;-3.1694458;1.9964614;-0.5951325;3.3097413;2.882659;-0.20676394;CODE
2 redistributions in binary form must reproduce the above copyright;-4.4733324;-0.49365726;-1.5629307;-2.6088657;3.1455169;-0.86478573;META
notice this list of conditions and the following disclaimer in the;-2.8765543;1.7101343;-1.1523315;3.3939996;2.5451956;1.0992507;CODE
documentation and or other materials provided with the distribution;-1.6212902;-6.150332;3.119261;0.3345237;3.852782;-0.056162048;CODE
this software is provided by the copyright holders and contributors as is and;-3.8302457;-7.2718143;0.6127078;-1.0228776;1.8997488;-1.1657168;OUTD
any express or implied warranties including but not limited to the implied;-2.3334541;2.328684;-1.331554;1.8353908;3.027354;0.43669343;META
warranties of merchantability and fitness for a particular purpose are;-1.6844977;0.62495637;-1.3823153;3.3848844;3.55545;0.70462275;CODE
disclaimed in no event shall the copyright holder or contributors be liable;-4.7723284;-0.5456694;-1.7100189;1.397545;0.58978075;0.78323656;OUTD
for any direct indirect incidental special exemplary or consequential;-3.2022939;0.4536465;3.0833898;3.4438407;3.706679;0.9345772;CODE
damages including but not limited to procurement of substitute goods or;-2.500769;1.1852741;-0.21752752;1.701609;2.4789255;0.9001056;META
services loss of use data or profits or business interruption however;-1.2989793;0.9621962;1.922926;2.2986257;-1.5823233;1.8186654;CODE
caused and on any theory of liability whether in contract strict liability;-4.705749;0.8723207;-1.0671368;3.498545;1.3559921;0.42416263;CODE
or tort including negligence or otherwise arising in any way out of the use;-5.125674;0.27472958;-0.9696112;4.9947133;1.5329208;2.292163;-
of this software even if advised of the possibility of such damage;-3.2526746;-3.8878937;0.90317816;2.5803292;-0.078712;-0.32149732;CODE
please keep the duplicated isinstance check;-3.41687;4.001307;-1.3771628;4.302103;2.2248278;-1.5134751;-
in the six comparisons hereunder;1.0786107;0.12256021;2.8003213;3.3376403;0.25945252;-4.278593;CODE
unless you find a way to avoid adding overhead function calls;1.0442836;2.1253006;1.1371276;2.8158813;1.0813906;3.3103402;CODE
pad for numeric comparison;4.305645;2.7915795;0.6326347;-4.229962;-0.6934847;-4.2345777;CODE
ensure that alpha beta candidate are before final;0.25925162;2.2044091;-0.7959906;5.8701606;2.6816475;-0.5061095;CODE
we hardcode an epoch of 1 here a pep 440 version can only have a epoch;-1.0736107;-0.9068367;-3.7437468;-0.6245508;-1.765219;-1.533554;META
greater than or equal to 0 this will effectively put the legacyversion;-3.6016538;1.6099231;-3.3256176;1.3029395;0.8879351;1.0574554;META
which uses the defacto standard originally implemented by setuptools;-5.0569863;-1.848086;-3.0242894;2.746442;1.8721448;2.346155;CODE
as before all pep 440 versions;-4.1652384;-2.992552;-0.13415653;0.68301845;-0.08394911;0.06295988;META
this scheme is taken from pkg resources parse version setuptools prior to;-4.5634823;-2.8650787;-4.382428;1.481718;1.9469092;3.0512016;IRRE
it s adoption of the packaging library;-4.802514;-6.2284007;1.6043473;2.2991443;0.4317409;-0.19662839;CODE
remove before a prerelease tag;-5.171077;2.0513902;-0.24224336;3.7080586;1.1782322;3.326596;IRRE
remove trailing zeros from each series of numeric parts;3.062174;3.2829535;0.03972145;-5.5962005;-2.3770356;-2.5975542;CODE
deliberately not anchored to the start and end of the string to make it;-4.220602;3.2271812;3.786801;1.1644225;-1.2536489;0.6519004;CODE
easier for 3rd party code to reuse;-3.9600983;-1.9840896;0.6420647;1.3804389;4.2716365;2.0282416;CODE
validate the version and parse it into pieces;-1.8246856;2.756083;-2.09853;2.2161674;3.1396034;-3.4723003;IRRE
store the parsed out pieces of the version;-1.4208062;0.6505506;1.1614166;0.38615796;3.280687;0.14111991;IRRE
generate a key which will be used for sorting;-0.5648564;0.39092168;2.1957395;-3.2135649;3.4357474;-1.6479114;CODE
epoch;0.15382367;-2.1456802;2.6801026;-0.019702803;-1.2254441;-2.5075603;-
release segment;-2.8912091;-2.5346386;3.6367238;1.1082114;1.344076;1.3957497;-
pre release;-2.81224;-3.2037306;3.4486701;3.0409214;-0.84005976;-0.9330751;-
post release;-3.874955;-2.8092387;4.430415;2.4764993;0.018280182;-2.0730398;-
development release;-4.8555794;-6.4774327;3.1732926;2.3115685;-1.3564122;-3.6649983;-
local version segment;-2.4321275;-2.7471673;0.1699341;0.64175457;1.506916;2.2546546;META
epoch;0.15382367;-2.1456802;2.6801026;-0.019702803;-1.2254441;-2.5075603;-
release segment;-2.8912091;-2.5346386;3.6367238;1.1082114;1.344076;1.3957497;-
we consider there to be an implicit 0 in a pre release if there is;-3.0060687;1.2560872;-3.4014473;1.9901724;-0.66286564;-0.48431146;-
not a numeral associated with it;-4.14854;0.72312015;1.0316504;-3.9016068;2.7721136;-3.9303856;-
we normalize any letters to their lower case form;-0.42426074;0.29430458;0.44834533;-2.9916615;3.174266;1.2729373;CODE
we consider some words to be alternate spellings of other words and;-2.6382058;-1.1442076;-0.063208975;2.1589825;2.01382;1.9685798;-
in those cases we want to normalize the spellings to our preferred;-1.1702042;-1.5752913;0.4129168;2.1269112;2.4610746;2.7354124;CODE
spelling;-2.310045;-1.899013;4.7262383;2.4153252;0.5296419;-3.3592587;-
we assume if we are given a number but we are not given a letter;-1.3447337;4.6636004;1.1321487;0.50546503;1.8821728;-5.9159827;META
then this is using the implicit post release syntax e g 1 0 1;-5.8830004;0.45257682;-3.0175276;0.15602633;1.5933877;0.35792744;CODE
when we compare a release version we want to compare it with all of the;-0.17175348;-0.6200698;1.3601763;4.5428286;-0.0413036;-1.2118793;IRRE
trailing zeros removed so we ll use a reverse the list drop all the now;-1.1824703;4.205174;0.029450739;-3.0501723;-1.5149188;-3.5072253;IRRE
leading zeros until we come to something non zero then take the rest;-0.4981789;3.7574978;1.8569139;-2.904616;-2.045815;-3.4172816;-
re reverse it back into the correct order and make it a tuple and use;-3.6605575;3.687249;1.0758837;-3.1295702;0.9563939;-2.2765453;IRRE
that for our sorting key;-2.0779822;-1.4906131;4.2414446;-1.1488456;2.8708234;-1.4159781;CODE
we need to trick the sorting algorithm to put 1 0 dev0 before 1 0a0;1.6453393;2.2977552;-2.3161151;-3.9508247;-0.59609544;-1.0215828;TASK
we ll do this by abusing the pre segment but we only want to do this;-1.7031462;0.039130773;3.0985756;3.6374192;1.3970025;3.323437;CODE
if there is not a pre or a post segment if we have one of those then;-1.8238168;1.0457299;3.278092;2.667953;3.644412;0.67350304;IRRE
the normal sorting rules will handle this case correctly;1.9089597;3.2913506;1.0313795;-0.5963081;5.0599403;0.71364474;CODE
versions without a pre release except as noted above should sort after;-1.9075173;-0.73443115;-0.033458706;1.8211325;0.0015008792;1.6356951;TASK
those with one;-2.0626848;-2.889052;3.5791118;1.6653271;1.2801836;-0.42192888;-
versions without a post segment should sort before those with one;-0.93231755;1.7460196;-0.28775683;1.1866788;1.6609397;2.6222115;META
versions without a development segment should sort after those with one;-1.2792978;-0.3983735;-0.44919336;1.9115485;1.2734284;1.9303919;META
versions without a local segment should sort before those with one;0.101519555;0.918694;-1.3120632;0.41261032;1.3368984;3.3747253;META
versions with a local segment need that segment parsed to implement;-1.5216627;-0.16304429;-2.0331297;-0.8453143;2.004248;2.7139277;TASK
the sorting rules in pep440;-0.26433277;-0.035069916;-0.20470741;-1.3646339;3.462381;-1.5231754;-
alpha numeric segments sort before numeric segments;2.256319;2.1763375;0.80806375;-4.8260207;-0.28200004;0.7114829;CODE
alpha numeric segments sort lexicographically;2.928826;0.102272935;1.2528734;-5.704579;1.6194923;-0.5879406;IRRE
numeric segments sort numerically;3.9380238;2.1735873;1.7457453;-5.770571;-0.18512057;-0.41254658;IRRE
shorter versions sort before longer versions when the prefixes;0.05747002;1.4990811;-0.82844824;0.69288933;2.3859227;1.8684033;META
match exactly;0.17965448;1.2438134;4.6399856;1.7778031;1.808763;-1.5115472;-
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
graph laplacian;1.8490108;-1.9179866;4.0220494;-4.2832294;-1.0453612;2.4806397;-
the keyword argument copy is unused and has no effect here;-4.944929;2.1601546;-4.5596747;2.1699948;-1.167228;0.8913469;OUTD
the keyword argument form is unused and has no effect here;-5.0656967;3.372917;-3.7197187;1.6671529;0.2512295;0.76098776;OUTD
from common import noqa f401 f403;-3.872782;-1.2751228;-2.1288457;-3.0883262;0.9211679;-0.022310391;CODE
wrapped f signature new sig pyright ignore reportattributeaccessissue;-3.6707895;2.2998273;-6.8711214;1.9223763;-0.44664797;3.5736265;META
return wrapped f pyright ignore reportreturntype;-2.5681794;3.330485;-5.3071337;2.4030612;-2.3531532;2.9392972;IRRE
from helpers import noqa f403;-4.5283484;-1.4175124;-2.15742;-3.270185;0.13177532;-1.8299117;CODE
todo import from typing requires python 3 13;-6.389327;-1.8089799;-3.626702;0.17074259;-3.643431;-1.9101311;CODE
these functions are modified from the numpy versions;1.4680715;-3.6787689;-2.752176;-6.286302;-5.932991;0.16580112;CODE
creation functions add the device keyword which does nothing for numpy and dask;-2.2982042;-3.4514012;-5.366555;-3.2510076;-2.506032;0.10784903;CODE
np unique is split into four functions in the array api;0.37059677;1.9371852;-2.6689494;-3.0265522;-0.39319685;-0.4129896;CODE
unique all unique counts unique inverse and unique values this is done;3.189226;2.5371861;2.3721814;-3.728041;2.6843045;-2.3519459;IRRE
to remove polymorphic return types;-1.1331027;2.6320524;-2.6716177;2.0965366;1.8175211;-0.36412388;IRRE
the functions here return namedtuples np unique returns a normal;1.094912;1.2300558;-4.3855824;-3.729692;-0.16178423;-1.522617;CODE
tuple;-0.27094585;-1.56985;4.491048;-1.6730574;1.3296063;-4.2235546;-
note that these named tuples aren t actually part of the standard namespace;-2.87772;-2.5645258;-2.2058852;-1.9525639;3.3040006;-0.23235594;TASK
but i don t see any issue with exporting the names here regardless;-3.753001;-2.5645468;-1.313952;0.9340926;2.5089383;2.236649;META
older versions of numpy and cupy do not have equal nan rather than;1.151645;0.07506303;-4.6534567;-5.729676;-6.1718125;-1.916088;OUTD
trying to parse version numbers just check if equal nan is in the;0.3525425;3.8583667;-4.0678473;-2.1693897;-1.7472302;-5.595533;IRRE
signature;-3.8445275;-0.5146877;2.3869717;-0.8287165;3.7186055;-2.08427;-
np unique flattens inverse indices but they need to share x s shape;3.7952678;1.1262481;-3.0882773;-7.4755545;0.046639863;3.5676618;TASK
see https github com numpy numpy issues 20638;-1.7057781;-3.4944751;-6.360401;-5.841061;-8.991825;-0.94066894;CODE
xp unique flattens inverse indices but they need to share x s shape;3.2387707;1.8791028;-2.949741;-7.2441163;2.7540796;4.3286657;TASK
see https github com numpy numpy issues 20638;-1.7057781;-3.4944751;-6.360401;-5.841061;-8.991825;-0.94066894;CODE
these functions have different keyword argument names;-3.731109;1.1728963;-2.2806358;-2.0968747;0.39979166;-1.5879722;CODE
correction float 0 0 correction instead of ddof;-0.013791056;2.9234;-4.5016994;-3.1706338;-3.375046;-0.88644207;CODE
correction float 0 0 correction instead of ddof;-0.013791056;2.9234;-4.5016994;-3.1706338;-3.375046;-0.88644207;CODE
cumulative sum is renamed from cumsum and adds the include initial keyword;-2.5440001;1.6720791;-1.0641521;-1.4423888;-0.6843146;-0.691046;CODE
argument;-2.922641;0.6521082;4.6576743;2.8854768;0.15559238;-4.0643554;-
todo the standard is not clear about what should happen when x ndim 0;-0.17898113;2.5192177;-2.7779064;-5.101029;-0.23975898;1.6237588;TASK
np cumsum does not support include initial;-2.5280194;2.1470473;-3.701012;-1.7234024;-1.6379673;0.40869808;CODE
np cumprod does not support include initial;-3.9913213;0.5986771;-4.833743;-0.51305306;-1.4859152;1.0295256;CODE
the min and max argument names in clip are different and not optional in numpy and type;0.9521073;0.19035266;-4.4924483;-4.4564195;-4.7260103;0.14183816;CODE
promotion behavior is different;-1.1841786;-0.08337035;2.2919111;0.8615863;0.87310976;0.6842871;-
todo np clip has other ufunc kwargs;-4.1921844;-2.025101;0.9250579;0.27745008;-1.8276821;-0.45152152;CODE
np clip does type promotion but the array api clip requires that the;-2.592768;-0.36935642;-2.5983465;-1.4665415;-1.4496988;1.1485733;CODE
output have the same dtype as x we do this instead of just downcasting;0.77690923;0.3470826;-3.2940304;-2.9531407;-1.4317393;1.1455386;CODE
the result of xp clip to handle some corner cases better e g;-2.1045926;-1.0966992;2.0857952;-1.1957399;1.2848663;3.0060034;CODE
avoiding uint64 float64 promotion;-2.984257;1.830451;-1.5886372;-3.9193423;-1.3891582;2.2030435;CODE
note cases where min or max overflow integer or round float in the;0.9602817;2.9039152;0.67221695;-3.8602939;0.38453844;-3.2481632;CODE
wrong direction when downcasting to x dtype are unspecified this code;-2.7049077;0.5125831;-4.635172;-3.4165196;-2.4165232;0.5089786;CODE
just does whatever numpy does when it downcasts in the assignment but;2.4597948;-2.2182198;-2.6490023;-3.4165003;-4.3784475;0.21231021;CODE
other behavior could be preferred especially for integers for example;0.021109102;2.6200097;-0.13768321;-0.89083743;1.1421554;-1.9519372;CODE
this code produces;-3.033983;-0.1779721;2.0245514;-1.446466;1.7985812;-4.754355;CODE
clip asarray 0 dtype int8 asarray 128 dtype int16 none;-2.3805788;1.894912;-3.352152;-4.9235587;-2.073535;-1.698641;CODE
128;-2.5532534;-0.85408604;3.9361026;-2.116773;-0.06162184;-4.2441583;-
but an answer of 0 might be preferred see;-2.0832877;3.8828213;1.5866293;-1.4645259;0.5942375;-3.7748544;META
https github com numpy numpy issues 24976 for more discussion on this issue;-1.3764467;-3.51173;-6.917865;-4.0579524;-9.059849;0.5370187;CODE
at least handle the case of python integers correctly see;0.17046207;1.921781;-2.2930372;-3.9961014;-2.5857413;-5.645221;CODE
https github com numpy numpy pull 26892;-1.2565697;-4.874157;-4.8152194;-5.5642715;-7.316057;-2.9340475;CODE
assert out is not none workaround for a type narrowing issue in pyright;-0.54172933;4.524155;-7.060105;4.3139596;-1.9149497;1.1157544;CODE
return a scalar for 0 d;1.9041053;3.9732668;-1.7174718;-4.688724;-1.9197485;-1.5167989;CODE
unlike transpose the axes argument to permute dims is required;1.4072328;1.3328503;-1.9385718;-8.059138;-2.8018746;3.1918945;IRRE
np reshape calls the keyword argument newshape instead of shape;-0.17581916;-0.41322178;-2.8288558;-3.3031344;-3.4544618;2.9496777;CODE
the descending keyword is new in sort and argsort and kind replaced with;-1.9817398;0.48421058;-2.31326;-0.27511236;0.29039887;-1.2164936;CODE
stable;-1.8943725;-1.6073065;4.9279366;1.8391316;-1.4195144;-1.6829987;-
note this keyword argument is different and the default is different;-5.613453;0.8300991;-2.7390394;0.82630557;1.383534;2.566134;CODE
we set it in kwargs like this because numpy sort uses kind quicksort;1.9844935;-2.1104639;-2.1357224;-4.517224;-3.698529;1.5432926;IRRE
as the default whereas cupy sort uses kind none;-1.6086414;-0.6762413;-2.2006903;-0.8591621;0.23757347;0.9204122;CODE
as numpy has no native descending sort we imitate it here note that;2.493207;-1.2145491;-0.41887614;-5.9744573;-5.410038;-0.388474;TASK
simply flipping the results of xp argsort x would not;-2.1152763;3.4638498;-1.2065995;-0.035486933;0.44615796;0.99885845;IRRE
respect the relative order like it would in native descending sorts;0.36267862;0.9552805;0.70419705;-1.1053246;2.6159954;1.087937;CODE
rely on flip argsort to validate axis;1.309916;4.074838;-1.3986683;-1.3166072;-1.7812705;1.7877536;IRRE
note this keyword argument is different and the default is different;-5.613453;0.8300991;-2.7390394;0.82630557;1.383534;2.566134;CODE
we set it in kwargs like this because numpy sort uses kind quicksort;1.9844937;-2.1104643;-2.1357212;-4.517225;-3.698528;1.5432934;IRRE
as the default whereas cupy sort uses kind none;-1.6086414;-0.6762413;-2.2006903;-0.8591621;0.23757347;0.9204122;CODE
nonzero should error for zero dimensional arrays;3.5230992;4.377191;-5.8972254;-5.2977386;-2.819245;-0.20901363;CODE
ceil floor and trunc return integers for integer inputs;0.5358026;3.401068;-0.0907342;-3.1489816;-0.5769502;-4.4311013;CODE
linear algebra functions;1.1044786;-0.28545755;2.9868913;-5.0653825;-1.1098373;-0.30590886;CODE
unlike transpose matrix transpose only transposes the last two axes;1.3996031;-0.16546352;0.13053772;-6.174073;-3.5944645;2.9747512;-
isdtype is a new function in the 2022 12 array api specification;-2.0670424;-0.26124462;-4.624805;-1.4029688;-0.006128694;-2.1163268;CODE
tuple bool true disallow nested tuples;-1.5243104;3.073798;-1.3123853;0.032372776;2.734197;-1.2702334;CODE
this will allow things that aren t required by the spec like;-3.6576545;-0.71817714;-0.88773733;3.0885239;3.3546236;3.9779172;CODE
isdtype np float64 float or isdtype np int64 l should we be;-0.58224815;1.2614846;-4.26764;-5.483976;-2.4023192;-2.8177106;CODE
more strict here to match the type annotation note that the;-2.6997683;-1.4457275;-4.22841;2.3138328;2.9116278;0.25446486;TASK
array api strict implementation will be very strict;-1.7301078;4.5024033;-3.1271713;0.9556307;-2.018395;0.08775683;TASK
unstack is a new function in the 2023 12 array api standard;-1.7717552;0.45333782;-1.8219744;-0.64060444;-1.0487262;-0.031107053;CODE
numpy 1 26 does not use the standard definition for sign on complex numbers;-1.2733532;1.0765809;-4.0718718;-5.5398245;-4.825644;-0.98625743;IRRE
sign 0 0 but the above formula would give nan;-0.56635845;4.4024167;-0.8575267;-5.864136;-3.88159;-4.9462523;META
cupy sign does not propagate nans see;-2.4891295;0.5200354;-2.7061765;-3.1915565;-4.866502;-1.1295354;CODE
https github com data apis array api compat issues 136;-2.7293274;-0.1964149;-3.9440682;-1.4783248;-3.697962;-0.47157314;CODE
it is surprisingly difficult to recognize a dtype apart from an array;2.4021752;-1.570296;-4.760031;-3.0670547;-1.1693819;-3.2548895;CODE
np int64 is not the same as np asarray 1 dtype;-2.2629275;-0.009340976;-6.6965747;-5.4104285;-3.8407805;-1.969503;CODE
note numpy fft functions improperly upcast float32 and complex64 to;0.16191682;-0.16323873;-5.0121565;-4.822677;-8.306217;0.06502766;CODE
complex128 which is why we require wrapping them all here;-3.8088162;-2.140586;1.8089525;-1.4818554;2.9127257;-0.016077891;META
import sparse pyright ignore reportmissingtypestubs;0.5001257;-0.88551646;-7.978759;0.80808735;-2.0386994;3.5877326;CODE
todo import from typing requires python 3 13;-6.3893275;-1.8089805;-3.6267028;0.1707426;-3.6434321;-1.9101312;CODE
cupyarray typealias any cupy has no py typed;-2.919257;-0.5238449;-5.3768597;-1.7456453;-2.7305672;-0.38421378;-
fast exit;-1.6766483;0.2598644;5.060119;2.3052192;-0.6310504;-2.5945413;-
dtype x dtype type ignore attr defined;-1.518917;2.159511;-6.354145;-1.583157;-1.0071323;1.4106205;CODE
jax float0 is a np dtype float0 v;-2.2652512;-0.14136252;-4.303529;-3.264771;-0.5815929;-0.028045401;CODE
todo should we reject ndarray subclasses;0.8844692;-1.2055434;-5.1973205;0.5599049;0.7249085;1.6107615;CODE
todo account for other backends;-4.9258027;-1.4518915;2.9317477;1.8852127;-0.42754987;2.107988;CODE
def is array api obj x object typeis arrayapiobj pyright ignore reportunknownparametertype;-0.16841877;2.4900162;-6.5545416;-0.10426673;-2.2410705;-0.25876027;CODE
todo drop support for numpy 2 which didn t have array namespace;-1.4268804;0.06262777;-3.6833923;-1.1701971;-4.218432;1.9018309;CODE
todo drop support for jax 0 4 32 which didn t have array namespace;-4.2858176;1.9348469;-1.2973844;1.5736817;0.14143804;3.2100604;CODE
numpy 2 0 have array namespace however they are not yet fully array api;-1.5597711;-0.4110667;-4.568236;-4.072388;-5.172376;0.87473077;TASK
compatible;-3.4564965;-2.5597074;2.2612953;-0.8807609;0.5636557;-0.9411292;-
import cupy as cp pyright ignore reportmissingtypestubs;-2.572632;-0.32473657;-7.1228313;0.8391374;-2.6129658;1.2160226;CODE
jax v0 4 32 and newer implements the array api directly in jax numpy;-2.5485864;0.65571517;-3.7359526;-1.123851;-2.4520013;2.1960618;CODE
for older jax versions it is available via jax experimental array api;-2.4807146;-0.5815038;0.27339733;1.3916305;1.3683008;2.2662187;CODE
import jax experimental array api as jnp pyright ignore reportmissingimports;-1.4190583;0.9048182;-4.841213;2.0837603;-2.5923064;2.5721264;CODE
import sparse pyright ignore reportmissingtypestubs;0.5001257;-0.88551646;-7.978759;0.80808735;-2.0386994;3.5877326;CODE
sparse is already an array namespace we do not have a wrapper;-0.9566369;-1.0512191;-2.979638;-0.43073243;-0.16907573;3.2684083;CODE
submodule for it;-3.314282;-2.0541606;3.77994;-0.61895865;1.2899835;0.9958546;CODE
todo support python scalars;-0.99793684;-2.9056232;-2.4477413;0.4636169;-2.2680027;0.2834936;CODE
backwards compatibility alias;-5.259241;-0.5967924;-2.0447984;-0.28810963;2.6711798;1.7007443;-
def check device bare xp namespace device device none pyright ignore reportunusedfunction;-5.0049677;1.9259704;-5.312699;2.29088;-1.0861439;0.62120306;CODE
placeholder object to represent the dask device;-3.3472955;-3.9610896;0.32551998;-2.2949488;1.5241604;2.442074;IRRE
when the array backend is not the cpu;-1.9460871;3.1914573;-0.1945164;0.5424525;-2.5095966;0.6482713;CODE
since it is not easy to tell which device a dask array is on;0.005067913;-1.8014435;-0.6451216;-1.795314;-0.042064857;0.10518849;TASK
device is not on numpy ndarray or dask array and to device is not on numpy ndarray;-0.015179278;-2.0546644;-5.4656897;-5.6129985;-6.2162585;0.2229671;-
or cupy ndarray they are not included in array objects of this library;-1.1346526;-3.063224;-3.997496;-3.1373925;-0.74713737;-0.30689013;CODE
because this library just reuses the respective ndarray classes without;-1.4680324;-4.1260147;-5.013095;-2.2607803;-1.6567459;2.2248735;CODE
wrapping or subclassing them these helper functions can be used instead of;-2.016372;-0.9657839;-0.104743145;0.725545;2.9419372;2.2003891;CODE
the wrapper functions for libraries that need to support both numpy cupy and;0.19457039;-5.773998;-4.042914;-4.1422415;-3.7936108;0.42878613;CODE
other libraries that use devices;-3.1138577;-8.086088;1.330277;0.3672207;-0.55142564;1.2663716;-
peek at the metadata of the dask array to determine type;-0.23021367;-2.47732;-4.364001;-1.4180743;0.45177212;-0.30693302;-
if is numpy array x meta pyright ignore;1.8356316;4.8039575;-3.9085286;-3.0646;-5.7681007;-0.79540074;-
must be on cpu since backed by numpy;-0.55292225;-2.2862818;-3.9958363;-3.6420958;-9.129494;-1.0635334;TASK
fixme jitted jax arrays do not have a device attribute;-3.3695428;1.8406694;-2.2240837;1.1155161;-0.7591668;3.8789115;META
https github com jax ml jax issues 26000;-4.826145;-1.9456668;-1.2968386;0.1721124;-2.2353532;-0.47999322;CODE
return none in this case note that this workaround breaks;-4.633337;8.173644;-2.6023514;3.0727684;-1.4222766;0.9590375;CODE
the standard and will result in new arrays being created on the;-0.30929354;1.5224104;0.25146377;-2.5931764;2.6492307;-0.2921234;IRRE
default device instead of the same device as the input array s;-0.30043763;1.3915386;1.1359688;-2.146741;0.32356718;2.9128587;CODE
older jax releases had device as a method which has been replaced;-5.7973566;-1.3248862;0.7976561;3.48558;0.33700436;4.184686;TASK
with a property in accordance with the standard;-1.8843877;2.77362;1.515975;0.6449904;5.012025;1.2832634;-
sparse will gain device so check for this first;0.79040134;0.7619425;-3.07172;-0.064905584;-1.0905119;3.0077958;CODE
everything but dok has this attr;-4.7223444;-3.2366145;-0.339002;0.37737632;-1.4251769;-0.07265314;CODE
inner x data pyright ignore;2.544329;4.054795;-2.8113444;-3.512929;-2.0756738;3.3112261;-
return the device of the constituent array;0.04193377;2.7032917;0.9889391;-2.5646405;1.5381286;-1.6400013;CODE
return device inner pyright ignore;-2.246485;3.6978242;-1.486402;1.666931;-2.3677106;3.9240866;IRRE
return x device pyright ignore;-3.0511644;3.6684544;-2.2488387;1.0289071;-2.7418783;3.4230692;IRRE
prevent shadowing used below;-2.937711;2.2289498;3.1089432;0.33308893;-0.9036992;2.9938726;CODE
based on cupy array api array to device;0.7907945;0.21126963;-0.4220676;-1.4309992;0.5155751;0.77893597;CODE
allowing us to use to device x cpu;-3.5858157;-3.2707517;0.18128723;-0.51288015;0.051753912;3.2443097;IRRE
is useful for portable test swapping between;-0.23839834;1.2324407;-0.10601974;4.703579;1.5569415;-1.2364341;CODE
host and device backends;-4.183982;-3.513283;3.3823302;0.27629083;0.012674426;1.5817648;CODE
stream can be an int as specified in dlpack or a cupy stream;-4.5713573;-1.1834795;-3.6821082;-2.663288;1.2570374;0.47554982;CODE
cupy does not yet have to device;-4.0795226;-4.215272;0.7539866;0.83438486;-1.4525405;0.93837076;TASK
return torch to device x device stream stream pyright ignore reportargumenttype;-3.8631835;0.86831766;-3.504913;1.9546936;-2.1424847;4.116032;IRRE
todo what if our array is on the gpu already;-0.03730235;1.9868202;2.427449;-1.1869932;0.026296739;1.0671471;CODE
in jax v0 4 31 and older this import adds to device method to x;-6.158265;-0.9899868;-2.6614304;1.253179;0.8171534;3.727788;CODE
import jax experimental array api noqa f401 pyright ignore;-1.870235;2.1973212;-5.260211;1.1327379;-2.4209983;1.2992791;CODE
but only on eager jax it won t work inside jax jit;-4.52739;1.7813232;-0.010893411;3.46379;0.8969286;4.168469;META
perform trivial check to return the same array if;1.6351211;8.2396755;0.9056558;1.4843911;0.3498147;-4.4389563;IRRE
device is same instead of err ing;-4.3405285;1.0501128;-0.45100516;2.192811;-0.8718042;2.3757718;CODE
return x to device device stream stream pyright ignore;-3.015692;1.4318008;-0.7396125;1.1499391;-2.3287425;4.8508053;IRRE
lazy api compliant arrays such as ndonnx can contain none in their shape;-0.36305708;1.8713751;-3.3076298;-0.74830985;0.87563545;2.2600987;CODE
dask array array shape can contain nan;2.297046;0.9761619;-3.3544042;-6.056548;-2.3437054;-1.5803624;-
jax note while it is possible to determine if you re inside or outside;-3.164449;1.9901946;4.100463;2.3536372;1.6367389;0.7702416;CODE
jax jit by testing the subclass of a jax array object as well as testing bool;-0.37356108;4.974573;-1.1128289;4.6785245;2.615312;0.24192007;IRRE
as we do below for unknown arrays this is not recommended by jax best practices;0.2731198;2.6745226;0.17089269;1.6738514;3.5011165;3.3072152;CODE
dask note dask eagerly computes the graph on bool float and so on;0.015273927;-1.500715;-1.3982879;-3.5597868;-3.1339881;-1.5110005;CODE
this behaviour while impossible to change without breaking backwards;-3.5108087;2.87451;2.4658213;0.84851664;-2.250504;1.1330733;CODE
compatibility is highly detrimental to performance as the whole graph will end;0.59261495;-1.8108364;-0.42028382;0.26085004;0.26771298;2.500342;CODE
up being computed multiple times;0.95470166;2.4447188;1.8825649;1.8335304;0.8784394;-1.8931249;CODE
note skipping reclassification of jax zero gradient arrays as one will;1.8926718;1.2465492;-4.589839;0.03698081;2.1301734;3.4745355;CODE
exclusively get them once they leave a jax grad jit context;-3.0717797;-1.9763945;0.95608085;3.4257998;2.3802676;4.0985785;-
unknown array api compatible object note that this test may have dire consequences;-0.8906273;2.9899266;-4.352686;2.4166975;-1.2764703;-3.7151735;CODE
in terms of performance e g for a lazy object that eagerly computes the graph;3.1971385;-2.817842;2.991067;2.5354009;1.4617332;2.3704562;CODE
on bool dask is one such example which however is special cased above;-2.1089742;-0.2772709;-0.5486117;0.13695025;2.7814763;-0.21252508;CODE
select a single point of the array;2.1363437;4.0606585;3.8588398;-3.9950018;0.20304917;-1.6906525;CODE
cast to dtype bool and deal with size 0 arrays;1.4794203;4.741071;-4.8214016;-2.6893992;-0.41176215;-1.1068224;CODE
the array api standard dictactes that bool should raise typeerror if the;-1.2257428;4.631659;-4.8421183;1.1659936;-0.90247667;-2.281604;CODE
output cannot be defined;-3.4051864;1.9089644;-1.7135881;-1.5077239;-2.3414507;-2.6178403;IRRE
here we allow for it to raise arbitrary exceptions e g like dask does;-3.2858956;-2.9332135;-2.5768306;5.3481727;2.3579051;1.0584042;CODE
these are in the main numpy namespace but not in numpy linalg;-2.1317465;-3.1194844;-6.2012095;-5.219253;-4.98137;1.7399312;CODE
these functions are the same as their numpy counterparts except they return;2.909979;-0.59565216;-2.4058416;-6.682906;-6.43535;-0.7877692;CODE
a namedtuple;-2.1532042;-2.8255255;2.380311;1.0135518;4.0142727;-2.576816;-
these functions have additional keyword arguments;-3.390002;0.27658343;-0.6089112;-2.1650596;1.7781878;-1.0491747;TASK
the upper keyword argument is new from numpy;-0.60128206;-1.2758782;-4.956384;-5.1628146;-5.6463847;-1.0421014;CODE
u xp conj u pyright ignore reportconstantredefinition;-3.9780233;1.1295416;-2.5290666;2.1633577;0.030797195;0.99516416;IRRE
the rtol keyword argument of matrix rank and pinv is new from numpy;0.53079474;-1.9644558;-5.450858;-4.7592463;-3.390507;1.0701293;CODE
note that it has a different semantic meaning from tol and rcond;-4.0518885;-2.395325;0.22399566;0.5866049;2.8358476;0.4365442;TASK
this is different from xp linalg matrix rank which supports 1;1.1887941;-0.33480388;-3.7399766;-4.456897;0.98744994;3.3101864;CODE
dimensional arrays;4.9331827;0.4218614;2.2830691;-7.231029;1.012972;-1.9601939;-
this is different from xp linalg matrix rank which does not;1.2359431;-0.74476326;-3.3361554;-3.821229;0.069749005;3.7842774;CODE
multiply the tolerance by the largest singular value;2.961326;3.0622084;-2.2446783;-2.1632125;-2.688684;2.31292;IRRE
this is different from xp linalg pinv which does not multiply the;-1.5933444;-1.1964786;-2.5094419;-3.8035185;0.3539296;3.0274107;CODE
default tolerance by max m n;1.2332016;2.8502924;-0.95576847;0.43548226;-0.18259755;0.9460171;CODE
these functions are new in the array api spec;-2.7864723;-0.5507555;-0.9162022;-1.660195;0.13058707;-1.0475764;CODE
svdvals is not in numpy but it is in scipy it is equivalent to;2.4156702;-3.4014351;-6.500223;-5.285505;-5.3319435;-0.021791741;META
xp linalg svd compute uv false;-0.23711015;0.6741233;-5.33823;-2.6285033;-3.206648;2.3947659;-
xp linalg norm tries to do a matrix norm whenever axis is a 2 tuple or;2.1631563;1.3682823;-4.55889;-5.8657117;-4.275839;5.2212353;TASK
when axis none and the input is 2 d so to force a vector norm we make;2.5379612;1.4456205;-0.0052218796;-6.162603;-3.891236;2.722718;CODE
it so the input is 1 d for axis none or reshape so that norm is done;2.5494907;0.3104523;1.471724;-7.880815;-4.603347;4.1937947;CODE
on a single dimension;1.6922917;-0.49963686;4.5020313;-4.7582073;1.1617744;1.8821585;-
note xp linalg norm doesn t handle 0 d arrays;1.9816202;2.2808468;-5.8196535;-6.202889;-3.280693;3.1050744;TASK
note the axis argument supports any number of axes whereas;0.086287364;1.655489;-1.0454955;-6.4026;-4.5879354;2.640995;TASK
xp linalg norm only supports a single axis for vector norm;0.8961352;0.39516282;-4.7202597;-5.8504224;-3.5839589;6.1643577;CODE
normalize axis tuple axis x ndim pyright ignore reportcallissue;3.8564155;3.22424;-1.6525186;-6.8381314;-4.195636;5.0340576;IRRE
we can t reuse xp linalg norm keepdims because of the reshape hacks;0.590691;-0.98766994;-3.3701398;-2.8826256;0.5582367;7.250668;-
above to avoid matrix norm logic;3.7719448;1.6334116;-0.4606603;-2.852541;0.31200802;1.8002517;CODE
normalize axis tuple pyright ignore reportcallissue;3.7559972;3.4679708;-1.7259294;-4.837661;-3.9959908;5.17168;IRRE
xp diagonal and xp trace operate on the first two axes whereas these;-0.18775082;-0.7168521;-0.76746243;-4.902786;-1.0839815;3.152104;-
operates on the last two;-4.1208477;-0.7059774;5.2125187;1.6227683;2.5496228;-1.4601725;-
these just types are equivalent to the just type from the optype library;-1.7899482;-3.2979822;-2.987554;-1.679283;2.0278099;-0.83059585;CODE
apart from them not being runtime checkable;-3.836637;0.7398467;-3.3578272;5.0246973;0.70683646;-0.83979505;CODE
docs https github com jorenham optype blob master readme md just;-4.190971;-6.138492;-1.5877138;-0.9211341;0.6540044;-0.025916856;CODE
code https github com jorenham optype blob master optype core just py;-4.4383473;-4.529249;-4.7240124;-2.540013;-2.6701925;-1.4597789;CODE
def class self value type int none pyright ignore reportincompatiblemethodoverride;-3.0320385;1.8550386;-6.8899255;2.20968;0.20427468;0.78705245;CODE
def class self value type float none pyright ignore reportincompatiblemethodoverride;-1.9712175;2.232312;-6.7124157;0.85511327;-1.2459896;1.0777268;CODE
def class self value type complex none pyright ignore reportincompatiblemethodoverride;-2.6731374;1.6156261;-7.023813;1.9713875;0.32602695;1.4722085;CODE
return type of array namespace info default dtypes;-1.256447;0.7347674;-4.7992826;-1.8025092;-0.13465264;0.44770354;CODE
return type of array namespace info default dtypes;-1.256447;0.7347674;-4.7992826;-1.8025092;-0.13465264;0.44770354;CODE
type of the kind parameter in array namespace info dtypes;-0.9339195;0.013084005;-4.338033;-2.7490833;1.1403039;0.10084225;IRRE
array namespace info dtypes kind bool;-2.2771277;2.1887171;-5.3557844;-1.7374442;0.83458114;-1.8795617;CODE
array namespace info dtypes kind signed integer;-2.171931;1.0979469;-5.701641;-4.874891;1.9668851;-2.0877345;CODE
array namespace info dtypes kind unsigned integer;-1.9403467;0.6244913;-5.2675667;-5.4425774;1.027475;-2.0658998;CODE
array namespace info dtypes kind integral;-0.9917922;-0.8135113;-4.1142845;-4.125808;0.15491672;-0.31524253;CODE
array namespace info dtypes kind real floating;-1.7415546;-0.08164222;-4.348955;-3.5520372;-1.7966986;-0.51363915;CODE
array namespace info dtypes kind complex floating;-1.28353;-0.43936917;-3.9615424;-4.132647;-0.47291088;-0.39432052;META
array namespace info dtypes kind numeric;0.019351063;-0.08347873;-4.400896;-4.8128834;0.80286944;-1.849559;-
array namespace info dtypes kind none default;-3.3665216;-0.06650893;-5.037833;-2.0772235;-0.72270054;0.6149829;CODE
array namespace info dtypes kind fallback;-2.0782008;-0.23726065;-5.1394596;-1.0443479;0.30539045;0.44999576;-
from cupy import noqa f403;-3.7125928;-2.5611036;-1.4855425;-3.36088;-0.32482654;-1.999601;CODE
from cupy import doesn t overwrite these builtin names;-4.460164;-2.544999;-5.3322873;-0.22342628;-1.432966;-0.3366203;CODE
from cupy import abs max min round noqa f401;-1.0850976;0.17570475;-1.6664139;-3.817523;-1.0748751;-1.9780129;CODE
these imports may overwrite names from the import above;-4.9508343;-1.9331101;-4.2742944;-0.019066628;0.17102978;0.3901678;CODE
from aliases import noqa f403;-4.7234273;-0.35512882;-3.7228816;-3.144054;0.3897066;0.3214068;CODE
see the comment in the numpy init py;1.3808368;-2.2829816;-2.0842755;-6.4052205;-7.167349;-0.17887078;IRRE
basic renames;-3.6690965;-1.5946751;2.8831835;-2.2032123;3.8480067;-1.932582;-
asarray also adds the copy keyword which is not present in numpy 1 0;-2.0092194;0.1988389;-6.0975904;-3.653773;-5.627844;0.04557842;TASK
cupy count nonzero does not have keepdims;-1.258871;2.5572703;-1.282677;-1.0553488;0.40656796;-2.036816;CODE
take along axis axis defaults to 1 but in cupy and numpy axis is a required arg;1.091191;1.9511776;-1.953858;-6.640534;-7.326412;1.9904796;CODE
these functions are completely new here if the library already has them;-2.916004;-4.310924;-0.44229147;-2.8630195;-1.6530813;-0.1566826;CODE
i e numpy 2 0 use the library version instead of our wrapper;-0.576265;-4.186592;-4.44209;-5.4680686;-7.449914;0.4487319;CODE
todo does this depend on device;-1.6945143;-2.090022;3.2674108;3.2131236;0.8520687;2.490261;CODE
todo does this depend on device;-1.6945143;-2.090022;3.2674108;3.2131236;0.8520687;2.490261;CODE
numpy 1 x on python 3 10 fails to parse np dtype;-0.5466071;-1.0793796;-7.4812818;-5.75864;-6.325857;-1.5301859;IRRE
from cupy fft import noqa f403;-3.1461182;-2.019442;-2.3209841;-2.7764988;-1.0322393;-1.474871;CODE
cupy fft doesn t have all if it is added replace this with;-3.9348567;0.16857593;-1.6848845;1.0150826;-1.6179485;0.4633884;CODE
from cupy fft import all as linalg all;-0.73699546;-1.8102623;-3.2281346;-1.7012409;-1.7849207;0.9200742;CODE
from cupy linalg import noqa f403;-3.315643;-2.3358386;-3.8674014;-4.479304;-1.525124;-0.6405957;CODE
cupy linalg doesn t have all if it is added replace this with;-4.5845203;-0.36107087;-3.1784992;-0.38753313;-1.5434351;1.4469687;CODE
from cupy linalg import all as linalg all;-1.1745398;-2.0942023;-3.7639093;-2.5635521;-1.275626;1.6272715;CODE
these functions are in both the main and linalg namespaces;-3.7309353;-2.8490663;-2.2643137;-2.6104274;-0.32402918;3.0671532;CODE
from aliases import matmul matrix transpose tensordot vecdot noqa f401;1.3713588;-1.0597429;-5.734624;-7.3123517;-3.4228127;2.4363542;CODE
these functions are completely new here if the library already has them;-2.916004;-4.310924;-0.44229147;-2.8630195;-1.6530813;-0.1566826;CODE
i e numpy 2 0 use the library version instead of our wrapper;-0.576265;-4.186592;-4.44209;-5.4680686;-7.449914;0.4487319;CODE
from dask array import noqa f403;0.43134013;-0.7527947;-3.698128;-6.3259172;-1.8843415;-2.2020648;CODE
these imports may overwrite names from the import above;-4.9508343;-1.9331101;-4.2742944;-0.019066628;0.17102978;0.3901678;CODE
from aliases import noqa f403;-4.7234273;-0.35512882;-3.7228816;-3.144054;0.3897066;0.3214068;CODE
see the comment in the numpy init py;1.380837;-2.2829804;-2.0842776;-6.405223;-7.167348;-0.17887054;IRRE
pyright reportprivateusage false;-4.5365667;4.083859;-4.6738234;3.014329;-2.6350849;1.6372625;CODE
pyright reportunknownargumenttype false;-4.3886456;2.2837312;-6.360018;2.7384458;-1.6102468;0.6950912;-
pyright reportunknownmembertype false;-2.6337564;1.1784106;-6.3515368;1.422316;-1.2723653;1.8892411;-
pyright reportunknownvariabletype false;-2.6273112;2.2936583;-7.1858053;0.453998;-2.205565;1.5677725;CODE
da astype doesn t respect copy true;-3.0844138;1.6305611;-4.1420226;1.2533964;0.70148736;0.8117839;CODE
todo respect device keyword;-5.0137534;-1.640664;0.3613304;1.644156;2.5705163;2.1834583;TASK
common aliases;-1.6055446;-1.064711;1.4254613;-0.99897736;4.1479807;0.23446307;-
this arange func is modified from the common one to;-3.9871798;-1.6160332;0.8201489;0.83238345;1.867654;2.5488343;CODE
not pass stop step as keyword arguments which will cause;-4.5586214;4.718659;-0.43343532;2.8331234;-0.10792532;0.06968303;-
an error with dask;-2.5791934;-1.9165497;-3.924167;-1.6733816;-2.366412;-2.8718252;-
todo respect device keyword;-5.0137534;-1.640664;0.3613304;1.644156;2.5705163;2.1834583;TASK
stop is none so start is actually stop;-3.9384649;2.4364092;4.106362;1.7909533;-1.0186759;-1.8702196;META
prepend the default value for start which is 0;-3.418383;5.824732;2.0442376;-1.6154977;-0.68686384;0.606378;CODE
asarray also adds the copy keyword which is not present in numpy 1 0;-2.00922;0.19883941;-6.0975895;-3.6537728;-5.627843;0.04557878;TASK
todo respect device keyword;-5.0137534;-1.640664;0.3613304;1.644156;2.5705163;2.1834583;TASK
return obj copy if copy else obj pyright ignore reportattributeaccessissue;-1.922047;3.8667564;-4.146382;3.2187223;-0.69460267;1.6630265;IRRE
copy none to be uniform across dask 2024 12 and 2024 12;-0.31999758;0.2504803;-2.810828;-2.1310716;1.7488271;-1.8963753;CODE
see https github com dask dask pull 11524;-3.4566104;-6.263122;-2.3608572;-1.3432566;-0.9604572;-1.1205766;CODE
element wise aliases;-1.0678962;1.0951085;1.0682287;-2.400686;3.1719015;1.865641;-
other;-2.9724238;-3.8820531;4.947025;1.1824225;1.3158734;-1.3568438;-
dask array clip does not work unless all three arguments are provided;-1.2979096;0.52085775;-3.3585026;-2.5058105;-1.9371147;-0.77570593;CODE
furthermore the masking workaround in common aliases clip cannot work with;-3.7047713;1.0403305;-3.7278297;0.18002763;-1.7954279;5.3183155;CODE
dask meaning uint64 promoting to float64 is going to just be unfixed for;-3.3356693;-2.1364548;-3.7167442;-3.0200398;-2.6933467;0.30059165;CODE
now;-4.632184;-2.1807024;5.5390363;1.0222448;-0.07846583;-1.4567467;-
todo this won t handle dask unknown shapes;0.5947428;-2.668599;0.3645919;-1.6945568;-0.013080231;0.7823268;CODE
break chunks on other axes in an attempt to keep chunk size low;2.2620018;1.9101908;1.6169983;-4.282027;-2.904755;3.1630054;CODE
rather than reconstructing the original chunks which can be a;1.430887;-0.12332819;0.4767063;-0.77417076;1.6190875;1.1663669;CODE
very expensive affair just break down oversized chunks without;-0.4541975;0.48662823;2.2220309;0.4406263;-0.19185123;2.0398898;CODE
incurring in any transfers over the network;0.39513233;0.78658587;2.5156002;-0.0012111334;-1.9217526;1.4788307;-
this has the downside of a risk of overchunking if the array is;1.1327871;2.66176;1.7171196;1.3794233;1.3072889;1.46955;CODE
then used in operations against other arrays that match the;1.1300623;3.364199;-0.20783961;-1.5648297;1.4912761;-3.6862707;-
original chunking pattern;1.8820405;-0.22473824;2.904085;-2.1478484;3.8809516;-0.059745833;-
dask array count nonzero does not have keepdims;1.6911812;1.7450529;-4.1634874;-2.9785805;-2.0282447;-0.8488912;CODE
fmt skip;-2.0130608;1.3041993;0.39130172;2.2470703;-0.48560718;-0.8339246;-
pyright reportprivateusage false;-4.5365677;4.08386;-4.6738234;3.0143294;-2.6350844;1.6372628;CODE
if isinstance kind tuple type ignore reportunnecessaryisinstancecall;0.15185982;5.475244;-4.845547;3.038292;1.7933897;-1.688043;IRRE
from dask array fft import noqa f403;0.9300802;-0.8302682;-3.9637587;-5.815579;-2.9897583;-1.311565;CODE
dask array fft doesn t have all if it is added replace this with;0.31616583;0.8142268;-3.4105093;-2.4119205;-3.134822;-0.7318704;CODE
from dask array fft import all as linalg all;1.7676682;-1.79598;-3.9027522;-3.9231868;-3.0111637;0.8769643;CODE
the matmul and tensordot functions are in both the main and linalg namespaces;-1.1922314;-4.9820046;-3.801987;-2.9824266;-1.8497537;4.4550147;CODE
exports;-3.1779315;-2.1530194;4.1441817;-0.341504;-0.38885185;-0.91114205;-
from dask array linalg import noqa f403;0.40278763;-0.89395577;-5.0047684;-6.137076;-2.8435676;-0.35148907;CODE
dask array linalg doesn t have all if it is added replace this with;-0.359737;0.5934892;-4.387179;-2.800175;-2.647033;0.429798;CODE
from dask array linalg import all as linalg all;0.73367316;-2.2297533;-4.3174467;-3.618136;-1.9005401;1.3281509;CODE
todo use the qr wrapper once dask;-3.8505273;-2.124422;-0.77615994;0.8037477;-0.7064492;1.9295453;TASK
supports the mode keyword on qr;-3.093315;-0.88824135;-1.1149964;-1.2048324;1.5039237;4.01572;CODE
https github com dask dask issues 10388;-4.4961824;-5.2298355;-4.337777;-1.4070733;-2.9577672;-1.4424946;CODE
qr get xp da linalg qr;-2.6975436;-0.5806696;-0.09869877;-1.9949834;2.1007693;-0.27166438;-
wrap the svd functions to not pass full matrices to dask;2.0206764;-1.8644418;-5.1270733;-3.1540818;-1.3922993;4.811958;CODE
when full matrices false as that is the default behavior for dask;1.280588;0.34617957;-4.7889895;-1.3858434;-1.7543184;1.944858;CODE
and dask doesn t have the full matrices keyword;-0.06953239;-4.012092;-4.082281;-3.0112486;-0.2003958;0.92064065;CODE
todo can t avoid computing u or v for dask;-2.8159444;-2.7050302;-2.6173723;-0.18484455;-1.4113004;-0.9659908;CODE
ruff noqa plc0414;-4.6985607;0.6089384;-0.22984996;-4.5491357;1.5873973;-2.045625;-
from numpy import noqa f403 pyright ignore reportwildcardimportfromlibrary;-2.4530017;-0.68735975;-6.216816;-1.7922736;-5.3378882;-0.26517114;CODE
from numpy import doesn t overwrite these builtin names;-1.6039414;-1.8257617;-5.099513;-3.2111049;-4.5784564;-0.5577463;CODE
these imports may overwrite names from the import above;-4.9508343;-1.9331101;-4.2742944;-0.019066628;0.17102978;0.3901678;CODE
from aliases import noqa f403;-4.723426;-0.3551279;-3.7228825;-3.1440558;0.38970762;0.321406;CODE
don t know why but we have to do an absolute import to import linalg if we;-2.8530164;-2.337373;-5.196505;-1.1674666;-3.198702;2.9843626;CODE
instead do;-3.5259383;-1.2150431;3.8848317;1.3688508;-1.3269016;-0.76871413;TASK
from import linalg;-1.6573482;-3.207485;-2.693018;-3.4993858;-2.3920121;1.4164839;CODE
it doesn t overwrite np linalg from above the import is generated;-2.8159282;-1.2336845;-5.2733793;-0.7643894;-3.2204041;3.3690035;CODE
dynamically so that the library can be vendored;-3.3884883;-1.9416821;-1.2360291;2.0787053;5.789757;5.3678803;CODE
from linalg import matrix transpose vecdot type ignore no redef noqa f401;0.40493298;1.2438232;-6.1082964;-7.126464;-4.112818;2.537314;CODE
pyright reportprivateusage false;-4.5365677;4.08386;-4.6738234;3.0143294;-2.6350844;1.6372628;CODE
the values of the copymode enum can be either false true or 2;-3.200203;5.173687;-2.2240984;-1.5117711;-0.00033802097;-0.8107704;IRRE
https github com numpy numpy blob 5a8a6a79d9c2fff8f07dcab5d41e14f8508d673f numpy globals pyi l7 l10;-0.31485218;-2.955288;-4.3302956;-7.874659;-5.831049;-0.12394829;CODE
basic renames;-3.6690965;-1.5946751;2.8831835;-2.2032123;3.8480067;-1.932582;-
def supports buffer protocol obj object typeis buffer pyright ignore reportunusedfunction;-3.5630677;0.58434314;-5.5173883;2.91898;-2.2416809;1.2547923;CODE
memoryview obj pyright ignore reportargumenttype;-2.3282423;1.7468835;-4.9111557;2.1394405;-0.5744562;4.1171713;-
asarray also adds the copy keyword which is not present in numpy 1 0;-2.00922;0.19883941;-6.0975895;-3.6537728;-5.627843;0.04557878;TASK
asarray is different enough between numpy cupy and dask the logic;1.9025267;-1.9860452;-3.4212735;-3.7189727;-3.040258;-1.4152292;-
complicated enough that it s easier to define it separately for each module;-1.2825587;-2.6569457;1.3144873;-0.9377844;5.3649383;3.056221;CODE
rather than trying to combine everything into one function in common;0.8537835;0.6511876;3.4275465;-0.9304851;2.5467007;-0.06709342;CODE
return np array obj copy copy dtype dtype kwargs pyright ignore;1.0564331;0.62434787;-5.8355;-2.9908862;-4.9613085;-0.48266602;IRRE
count nonzero returns a python int for axis none and keepdims false;2.5205293;4.7549367;-2.938606;-6.1159263;-5.4450336;-2.0407455;CODE
https github com numpy numpy issues 17562;-2.8698637;-3.5894606;-4.8023386;-4.684583;-9.36681;-2.478089;CODE
note this is currently incorrectly typed in numpy but will be fixed in;3.1411908;-0.09877809;-3.3450024;-7.88351;-7.7324324;-0.09793197;TASK
numpy 2 2 5 and 2 3 0 https github com numpy numpy pull 28750;0.22141494;-2.2773921;-3.494822;-8.443633;-5.7879715;-2.5116613;CODE
result cast any np count nonzero x axis axis keepdims keepdims pyright ignore reportargumenttype reportcallissue;4.412474;4.1912975;-3.9852898;-4.8122225;-3.4541721;2.348771;IRRE
take along axis axis defaults to 1 but in numpy axis is a required arg;0.77173626;2.3679514;-1.552268;-6.2081213;-7.757036;2.3958771;CODE
these functions are completely new here if the library already has them;-2.916004;-4.310924;-0.44229147;-2.8630195;-1.6530813;-0.1566826;CODE
i e numpy 2 0 use the library version instead of our wrapper;-0.576265;-4.186592;-4.44209;-5.4680686;-7.449914;0.4487319;CODE
numpy 1 x on python 3 10 fails to parse np dtype;-0.5466071;-1.0793796;-7.4812818;-5.75864;-6.325857;-1.5301859;IRRE
pyright reportattributeaccessissue false;-3.9518752;2.9350262;-5.513294;2.8339386;-2.02281;1.7268531;META
pyright reportunknownargumenttype false;-4.3886456;2.2837312;-6.360018;2.7384458;-1.6102468;0.6950912;-
pyright reportunknownmembertype false;-2.6337552;1.1784111;-6.351537;1.4223155;-1.2723649;1.8892413;-
pyright reportunknownvariabletype false;-2.6273112;2.2936583;-7.1858053;0.453998;-2.205565;1.5677725;CODE
intersection of np linalg all on numpy 1 22 and 2 2 minus linalg all;0.68619055;-0.0050574443;-4.3818483;-5.258984;-3.753868;1.5039601;CODE
these functions are in both the main and linalg namespaces;-3.7309353;-2.8490663;-2.2643137;-2.6104274;-0.32402918;3.0671532;CODE
from aliases import matmul matrix transpose tensordot vecdot noqa f401;1.371358;-1.0597433;-5.734623;-7.3123507;-3.4228122;2.4363542;CODE
note unlike np linalg solve the array api solve only accepts x2 as a;0.6896903;0.275635;-4.3490086;-4.8792577;-3.9006817;0.6343112;TASK
vector when it is exactly 1 dimensional all other cases treat x2 as a stack;1.5637238;0.6696697;-0.5364111;-6.3482723;0.8214676;1.8566945;CODE
of matrices the np linalg solve behavior of allowing stacks of both;1.2459459;-0.46699706;-2.29401;-2.106082;-1.7872155;4.1795497;-
matrices and vectors is ambiguous c f;1.2133564;1.0723423;-2.4111135;-4.763838;-2.956278;1.009405;META
https github com numpy numpy issues 15349 and;-2.6839294;-3.4484484;-5.033531;-4.2820487;-9.039174;-2.115646;CODE
https github com data apis array api issues 285;-2.9042933;-0.427838;-3.760626;-1.4405289;-3.2808118;-1.0438974;CODE
to workaround this the below is the code from np linalg solve except;0.6558064;1.184264;-6.0684443;-3.6109862;-5.326886;3.2886345;CODE
only calling solve1 in the exactly 1d case;-0.18060133;6.0940285;-1.413438;-2.3294601;-0.8063391;-0.21035098;CODE
this code is here instead of in common because it is numpy specific also;1.0201604;-0.5151137;-3.037991;-7.8186455;-6.2760434;-1.8546716;CODE
note that cupy s solve does not currently support broadcasting see;-1.9847007;-3.5650976;-2.1265368;0.060504798;-2.0027084;0.66004574;TASK
https github com cupy cupy blob main cupy cublas py l43;-4.6050744;-4.67014;-0.19601703;-3.7291102;-0.03766943;-1.9897779;CODE
this part is different from np linalg solve;-0.017513098;-1.0174925;-3.823107;-3.802125;-2.3410742;1.6622567;CODE
this does nothing currently but is left in because it will be relevant;-4.0153427;-3.0212865;2.918454;3.2169113;1.7160002;3.1592815;CODE
when complex dtype support is added to the spec in 2022;-2.3069065;-4.38367;-3.836569;1.2243693;0.2286557;0.85916495;TASK
these functions are completely new here if the library already has them;-2.916004;-4.310924;-0.44229147;-2.8630195;-1.6530813;-0.1566826;CODE
i e numpy 2 0 use the library version instead of our wrapper;-0.576265;-4.186592;-4.44209;-5.4680686;-7.449914;0.4487319;CODE
from torch import noqa f403;-5.5313826;-2.2407131;-0.4883883;-3.5890465;-1.0152663;-0.63696736;CODE
several names are not included in the above import;-3.580264;-2.3942342;-4.0363693;-0.5971783;0.9163371;-1.5065991;CODE
these imports may overwrite names from the import above;-4.9508343;-1.9331101;-4.2742944;-0.019066628;0.17102978;0.3901678;CODE
from aliases import noqa f403;-4.7234273;-0.35512882;-3.7228816;-3.144054;0.3897066;0.3214068;CODE
see the comment in the numpy init py;1.380837;-2.2829804;-2.0842776;-6.405223;-7.167348;-0.17887054;IRRE
torch 2 3;-3.991833;-2.179272;3.510772;-1.9535058;0.14267313;-1.5156088;-
ints;-2.8110883;-0.23808043;3.9940445;-1.516955;0.061265133;-4.7454286;CODE
ints and uints mixed sign;-3.5095475;2.0591052;-0.65188885;-4.016874;0.06779491;-1.6559736;CODE
floats;-0.27345288;0.5280914;5.3944473;-3.384547;-1.7550778;-3.3400388;CODE
complexes;-2.529195;-1.8194445;4.0101743;-1.5776647;2.2835329;-0.97091293;META
mixed float and complex;0.24915904;3.4121196;1.4838065;-4.369716;-0.7804626;-0.20710056;META
if an argument is 0 d pytorch downcasts the other argument;-0.19602637;1.8952835;-3.418615;-1.2261434;-3.2279818;0.25233433;CODE
sort scalars so that they are treated last;3.5384433;2.194166;-1.4966984e-05;-1.1259419;0.6555477;1.2429656;-
combine left to right;-1.2834482;1.0925153;6.417489;-4.59554;1.9195435;-1.6616697;-
this doesn t result type dtype dtype for non array api dtypes;-1.4740722;1.1390544;-5.9931183;-2.4902582;-2.2691395;-1.3299892;CODE
because torch result type only accepts tensors this does however allow;-2.0087397;-0.56733793;-4.8162575;-1.5337979;-1.1832229;1.7324015;IRRE
cross kind promotion;-1.484247;-1.374842;1.5465336;0.3214418;3.7362926;-1.1037861;-
basic renames;-3.6690965;-1.5946751;2.8831835;-2.2032123;3.8480067;-1.932582;-
torch conj sets the conjugation bit which breaks conversion to other;-3.737129;0.95107436;-1.5435778;-2.7026882;-0.6737241;2.0187733;IRRE
libraries see https github com data apis array api compat issues 173;-3.370564;-1.805023;-5.208537;-1.5031117;-3.7979221;0.15815486;CODE
two arg elementwise functions;-1.2901063;3.4574397;2.186612;-3.1124456;-0.82963794;-0.68192023;CODE
these require a wrapper to do the correct type promotion on 0 d tensors;-0.041199867;-1.5790428;-4.6699204;-2.7682717;1.1778768;2.995641;CODE
also a rename torch equal does not broadcast;-4.6970696;1.2999207;-1.5002602;-0.033294614;-0.52217144;1.5773281;CODE
logical functions are not included here because they only accept bool in the;-3.9205449;3.7213233;-2.995395;-0.8688754;0.530775;-3.5049262;CODE
spec so type promotion is irrelevant;-2.3069057;-1.3735799;-1.4637575;2.0601716;2.982817;1.268948;-
torch asarray does not respect input output device propagation;-1.2988206;0.40333617;-2.5444052;-0.8023463;-4.0353956;3.3114321;CODE
https github com pytorch pytorch issues 150199;-3.5484302;-4.044086;-5.491541;-1.5913268;-7.4364204;-1.3842313;CODE
these wrappers are mostly based on the fact that pytorch uses dim instead;-1.0330578;-3.7168367;-1.8017747;-1.2778538;-3.210082;0.8472965;CODE
of axis;0.76577246;-0.34432623;6.474134;-6.3706913;-3.0683045;-0.02508913;-
torch min and torch max return a tuple and don t support multiple axes https github com pytorch pytorch issues 58745;-0.36871573;-0.4330587;-3.6606889;-5.2096667;-4.8662143;2.5217018;CODE
https github com pytorch pytorch issues 29137;-3.6642754;-4.2289877;-5.421173;-1.9372782;-7.0426774;-1.2450111;CODE
https github com pytorch pytorch issues 29137;-3.6642754;-4.2289877;-5.421173;-1.9372782;-7.0426774;-1.2450111;CODE
torch sort also returns a tuple;-0.21380052;0.4463195;0.09662955;-1.6139473;-1.4598379;-0.609531;IRRE
https github com pytorch pytorch issues 70921;-3.373683;-3.9411023;-5.8267345;-1.5425946;-6.9433403;-1.0039772;CODE
better error message in this case;-4.8023896;4.4050407;-1.3619162;0.7700571;0.03333984;-3.1217122;CODE
match torch error message e g from sum;-1.5567327;3.5532897;-1.7665828;-0.79815453;-1.554197;-3.2701142;CODE
use indexerror instead of runtimeerror and axis instead of dim;4.1862426;2.779318;-3.2512338;-2.9488304;-5.606924;1.6527768;CODE
apply keepdims when axis none;3.4606793;4.5544167;1.1257837;-6.477692;-3.7615602;5.3026423;-
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
note that this is only valid for the axis none case;1.0474167;3.5505006;-0.40403098;-6.8205075;-2.9184492;3.5404384;CODE
some reductions don t support multiple axes;1.6086445;2.3676572;-1.4801058;-4.159305;-1.266236;4.5281973;CODE
https github com pytorch pytorch issues 56586;-3.654845;-4.183025;-5.5077534;-1.625647;-7.0145416;-1.3165901;CODE
we can t upcast uint8 according to the spec because there is no;-3.635747;-1.4782555;0.73439765;-0.5027829;-0.11321276;1.7056497;IRRE
torch uint64 so at least upcast to int64 which is what prod does;-4.6120815;-2.1702;-0.45573568;-1.3921386;-0.04575854;1.6996489;CODE
when axis none;-1.1375091;4.499411;1.5660859;-4.45274;-5.8880806;0.2262863;-
torch prod doesn t support multiple axes;-3.0184715;0.33016935;-0.95635915;-4.6927013;-2.4030652;4.0986147;CODE
https github com pytorch pytorch issues 56586;-3.654845;-4.183025;-5.5077534;-1.625647;-7.0145416;-1.3165901;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
torch any doesn t support multiple axes;-3.494819;0.04245172;-0.09853793;-5.141596;-2.9469821;3.2731957;CODE
https github com pytorch pytorch issues 56586;-3.654845;-4.183025;-5.5077534;-1.625647;-7.0145416;-1.3165901;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
torch any doesn t return bool for uint8;-5.9311876;2.7577293;-2.8361762;-0.5191682;-2.7383416;-0.58905625;CODE
torch all doesn t support multiple axes;-2.619643;0.31487277;0.10861879;-4.53214;-3.0870657;4.0385265;CODE
https github com pytorch pytorch issues 56586;-3.654845;-4.183025;-5.5077534;-1.625647;-7.0145416;-1.3165901;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
torch all doesn t return bool for uint8;-5.311949;2.5501244;-2.2157402;0.12311391;-3.0766778;0.038991734;CODE
https github com pytorch pytorch issues 29137;-3.6642754;-4.2289877;-5.421173;-1.9372782;-7.0426774;-1.2450111;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
note float correction is not supported;-1.6592999;2.3370237;-3.9307964;-2.4716568;-5.658837;-1.0469737;TASK
https github com pytorch pytorch issues 61492 we don t try to;-3.7931492;-4.058906;-5.708608;-2.012547;-6.7448683;-1.1576802;CODE
implement it here for now;-4.2040815;-2.9677997;4.5947275;0.65363735;2.6261487;1.6771455;TASK
https github com pytorch pytorch issues 29137;-3.6642754;-4.2289877;-5.421173;-1.9372782;-7.0426774;-1.2450111;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105094;-3.9235542;-5.7090216;-1.464071;-7.0644417;-1.1482449;CODE
note float correction is not supported;-1.6592999;2.3370237;-3.9307964;-2.4716568;-5.658837;-1.0469737;TASK
https github com pytorch pytorch issues 61492 we don t try to;-3.7931492;-4.058906;-5.708608;-2.012547;-6.7448683;-1.1576802;CODE
implement it here for now;-4.204082;-2.9678004;4.59473;0.6536375;2.6261477;1.677144;TASK
if isinstance correction float;2.2597263;5.4998927;-2.8697987;-0.98144335;-2.9698215;-1.8168972;CODE
correction int correction;-1.1542633;2.0874143;-0.1711811;-1.2237904;-1.8871348;-3.9729767;CODE
https github com pytorch pytorch issues 29137;-3.6642754;-4.2289877;-5.421173;-1.9372782;-7.0426774;-1.2450111;CODE
torch doesn t support keepdims with axis none;-1.2106252;1.4118334;-0.35831374;-4.7454987;-4.5476027;4.6220813;CODE
https github com pytorch pytorch issues 71209;-3.8105104;-3.9235551;-5.7090216;-1.4640701;-7.064441;-1.1482443;CODE
torch concat doesn t support dim none;-4.146991;1.9857835;-1.7663385;-3.432245;-1.8218396;1.0682683;CODE
https github com pytorch pytorch issues 70925;-3.203855;-3.8754942;-5.7831845;-1.5631918;-7.087988;-1.2175789;CODE
torch squeeze only accepts int dim and doesn t require it;-3.0454686;2.125076;-2.0073307;-2.6307054;-2.0737278;0.049778596;CODE
https github com pytorch pytorch issues 70924 support for tuple dim was;-2.1696308;-3.535519;-7.0550213;-3.271341;-5.5188026;-0.12467526;CODE
added at https github com pytorch pytorch pull 89017;-3.1143103;-5.481116;-3.9310699;-3.253062;-5.1717553;-0.70949185;TASK
remove this once pytorch 1 14 is released with the above pr 89017;-4.2545867;-0.7880069;-3.2067902;-1.142907;-3.603164;-1.0889615;OUTD
torch broadcast to uses size instead of shape;-1.1561651;-0.10553851;1.5242488;-2.0067468;-1.7843323;4.8644195;CODE
torch permute uses dims instead of axes;-1.2884257;0.17920086;-0.625482;-5.1666293;-3.2249238;3.3229117;CODE
the axis parameter doesn t work for flip and roll;-1.4445839;2.8225071;0.158356;-5.3162093;-4.50111;1.0509745;CODE
https github com pytorch pytorch issues 71210 also torch flip doesn t;-4.2022724;-2.6176033;-4.1633444;-1.5960248;-6.189803;-0.2935712;CODE
accept axis none;-1.313577;4.231294;1.0619284;-6.21645;-5.261346;1.7117535;-
torch flip doesn t accept dim as an int but the method does;-3.4699872;1.3432363;-1.9982153;-3.0490928;-2.2230637;-0.45210028;CODE
https github com pytorch pytorch issues 18095;-4.116581;-4.240829;-5.098028;-1.7360268;-7.25881;-1.2587131;CODE
torch uses dim instead of axis;-1.6905107;0.12581281;0.27399278;-4.819619;-5.2207894;1.7913519;CODE
torch uses dim instead of axis does not have keepdims;-0.78786284;0.9743158;-0.19862911;-5.0277066;-4.7321196;3.2704034;CODE
repeat is torch repeat interleave also the dim argument;-1.1819005;0.8419625;0.2561763;-2.115108;-0.24162391;0.3236096;CODE
torch reshape doesn t have the copy keyword;-3.60271;-0.8307652;-1.6675633;-1.5405596;-2.4789336;4.516911;CODE
torch arange doesn t support returning empty arrays;-2.8380983;2.9312866;-2.055463;-0.03602275;-2.4215372;1.0273612;CODE
https github com pytorch pytorch issues 70915 and doesn t support some;-3.4531412;-4.013652;-5.931364;-1.1285716;-6.7647996;-0.18590085;CODE
keyword argument combinations;-0.7789778;0.047820877;1.1868092;0.31887612;5.300394;-2.686079;-
https github com pytorch pytorch issues 70914;-3.3795116;-3.9667273;-5.5859184;-1.4287151;-7.038349;-1.0530162;CODE
torch eye does not accept none as a default for the second argument and;-6.145714;3.321462;-2.2350461;-0.10137519;-1.7409651;1.3420947;CODE
doesn t support off diagonals https github com pytorch pytorch issues 70910;-2.1414053;-2.6965363;-5.623893;-4.293943;-5.6884584;1.8562022;CODE
torch linspace doesn t have the endpoint parameter;-5.34552;0.34761444;-1.3265268;-1.7351197;-3.0473735;3.9982598;CODE
torch full does not accept an int size;-3.869263;2.0583937;-1.60735;-2.6580305;-2.2400057;0.4236506;CODE
https github com pytorch pytorch issues 70906;-3.231694;-4.0087137;-5.319091;-1.1694027;-7.194474;-0.82342994;CODE
ones zeros and empty do not accept shape as a keyword argument;-0.6490708;3.4930084;-3.1552942;-4.131621;-0.012293692;-1.5182072;CODE
tril and triu do not call the keyword argument k;-4.14755;1.4256028;-2.5286968;-1.6943184;-0.53479975;-1.491674;IRRE
functions that aren t in torch https github com pytorch pytorch issues 58742;-3.929043;-2.8355203;-4.952485;-1.6051668;-5.631786;-0.5069038;CODE
note that these named tuples aren t actually part of the standard namespace;-2.8777192;-2.5645273;-2.2058837;-1.9525641;3.3040016;-0.2323566;TASK
but i don t see any issue with exporting the names here regardless;-3.753001;-2.5645468;-1.313952;0.9340926;2.5089383;2.236649;META
https github com pytorch pytorch issues 70920;-3.4133637;-3.9949036;-5.6297874;-1.3256773;-7.0105934;-0.8551685;CODE
torch unique doesn t support returning indices;-0.081346974;1.9807106;-3.2821505;-1.4729863;-0.1683698;1.2617041;CODE
https github com pytorch pytorch issues 36748 the workaround;-3.2484481;-3.361429;-6.646383;-1.3059224;-7.27763;0.61819565;CODE
suggested in that issue doesn t actually function correctly it relies;-3.6425521;4.1060233;-4.512285;3.0238347;-3.533559;2.0963295;CODE
on non deterministic behavior of scatter;3.522817;-0.94949836;-0.7330851;-1.1843841;-2.8017828;3.4325736;-
values inverse indices counts torch unique x return counts true return inverse true;2.2892072;3.4592066;-1.4022535;-3.289853;-0.9059997;-1.4851624;IRRE
torch unique incorrectly gives a 0 count for nan values;1.0965022;2.7198524;-3.2560794;-3.784144;-3.4150422;-1.7773253;IRRE
https github com pytorch pytorch issues 94106;-3.5459743;-4.116824;-5.709056;-1.565908;-6.877733;-1.0652165;CODE
counts torch isnan values 1;0.055978294;4.2126956;-1.2651842;-3.0861466;-1.2206179;-3.221171;IRRE
return uniqueallresult values indices inverse indices counts;4.250735;3.703033;-1.3679451;-1.9077268;1.6532143;-0.68277043;IRRE
torch unique incorrectly gives a 0 count for nan values;1.0965022;2.7198524;-3.2560794;-3.784144;-3.4150422;-1.7773253;IRRE
https github com pytorch pytorch issues 94106;-3.5459743;-4.116824;-5.709056;-1.565908;-6.877733;-1.0652165;CODE
torch matmul doesn t type promote but differently from fix promotion;-4.1232476;0.23543277;-1.8536446;-1.2238752;-2.0517569;2.9726682;CODE
torch tensordot uses dims instead of axes;-1.0277132;-1.3929985;-2.4041998;-5.1501164;-5.8542013;2.6464684;CODE
note torch tensordot fails with integer dtypes when there is only 1;-1.5243709;-0.77405113;-5.8272533;-4.085404;-3.443917;-0.44528255;CODE
element in the axis https github com pytorch pytorch issues 84530;-1.0467031;-1.226889;-4.6404834;-6.3476205;-7.745157;1.0639641;CODE
tuple true disallow nested tuples;-1.0110426;2.5708983;-1.1163011;0.19705302;3.0023537;-0.71907276;CODE
torch sign does not support complex numbers and does not propagate;-4.457605;0.15301637;-1.4990771;-2.5021458;-3.3545284;0.4412479;CODE
nans see https github com data apis array api compat issues 136;-1.7512231;0.84362954;-5.391274;-2.633326;-5.671843;-1.1306669;CODE
sign 0 0 but the above formula would give nan;-0.56635845;4.4024167;-0.8575267;-5.864136;-3.88159;-4.9462523;META
enforce the default of xy;-4.6306105;2.567673;-0.8590556;0.13950673;-1.7629659;2.2099571;CODE
todo is the return type a list or a tuple;-2.3019865;0.20443706;1.2790154;1.5902537;1.7709706;-3.2384086;CODE
note if the default is set to float64 the devices like mps that;-3.3008454;0.3260036;-2.4810567;-3.972826;-2.6757298;4.213279;CODE
don t support float64 will error we still return the default dtype;-2.5725334;0.77892095;-5.836064;-3.0528765;-3.8833163;0.17793356;CODE
value here because this error doesn t represent a different default;-3.5664537;6.103942;-3.299329;-1.0047868;-1.054378;-1.7811536;CODE
per device;-0.22200094;-2.7103732;4.794234;-0.40833312;3.2709126;-0.3100416;-
uint16 uint32 and uint64 are present in newer versions of pytorch;-3.3396254;-3.1308258;-4.8147807;-3.3066583;-4.97429;0.62953794;CODE
but they aren t generally supported by the array api functions so;-1.7367526;0.29862535;-2.527972;-1.7646745;-0.16877034;0.7388511;CODE
we omit them from this function;-1.6270432;3.021258;1.3941168;-0.9275944;0.9493148;-1.5749156;CODE
torch doesn t have a straightforward way to get the list of all;-2.7129362;-1.134706;1.1994971;0.5825937;-1.047783;0.28372929;CODE
currently supported devices to do this we first parse the error;-4.4966607;-0.6855774;-3.6994417;0.54844487;-1.1538347;0.9758652;IRRE
message of torch device to get the list of all possible types of;-2.7616844;-2.0645006;0.40463048;0.34831387;2.1091695;-1.3809357;CODE
device;-2.3601575;-4.2326217;5.9504232;0.6123467;0.79183805;-1.7006005;-
raise assertionerror unreachable pragma nocover;-2.055518;4.2424474;-7.2714887;3.4628174;-3.5255234;-2.2276542;CODE
the error message is something like;-6.6822567;0.9506753;-2.3709939;-0.39834064;-1.8021135;-0.67870617;-
expected one of cpu cuda ipu xpu mkldnn opengl opencl ideep hip ve fpga ort xla lazy vulkan mps meta hpu mtia privateuseone device type at start of device string notadevice;-3.6755726;0.08287303;-4.6440477;-3.3352923;0.24326923;0.38062972;CODE
next we need to check for different indices for different devices;0.85508543;1.4332153;-0.94072646;-1.5351351;0.73983693;0.4444125;CODE
device device name index index doesn t actually check if the;-1.2752606;1.4204767;-2.3961904;-0.24449748;1.0377812;1.1892333;IRRE
device name or index is valid we have to try to create a tensor;-1.1911706;-1.3861169;-3.537328;-3.6317315;0.3045311;1.9126757;IRRE
with it which is why this function is cached;-4.138133;1.8508834;1.9182693;2.0713582;-1.4936152;1.7824802;CODE
from torch fft import noqa f403;-4.220445;-1.634038;-1.8924161;-3.3955579;-2.0183418;0.055633053;CODE
several torch fft functions do not map axes to dim;0.4202547;0.7459991;-1.5967654;-4.6899333;-5.260459;3.5283632;CODE
from torch linalg import noqa f403;-4.2967243;-1.592443;-2.8089569;-4.114968;-2.40695;0.70969445;CODE
torch linalg doesn t define all;-3.946045;-0.74663013;-3.6089573;-1.2091844;-1.7102978;3.1815362;CODE
from torch linalg import all as linalg all;-2.264258;-2.3263135;-2.5360188;-2.6247919;-1.7484801;2.7981973;CODE
outer is implemented in torch but aren t in the linalg namespace;-5.283417;-1.9387403;-3.3388903;-1.225875;-1.4227529;4.6120462;CODE
these functions are in both the main and linalg namespaces;-3.7309353;-2.8490663;-2.2643137;-2.6104274;-0.32402918;3.0671532;CODE
note torch linalg cross does not default to axis 1 it defaults to the;-3.0933564;-0.45582464;-1.3087829;-4.1256065;-5.3867483;3.4679475;CODE
first axis with size 3 see https github com pytorch pytorch issues 58743;0.7232291;-0.79741234;-2.5130942;-8.092231;-7.390197;2.0634167;CODE
torch cross also does not support broadcasting when it would add new;-5.540145;-1.7409658;-0.96016395;0.9176608;-1.4378673;3.7173154;CODE
dimensions https github com pytorch pytorch issues 39656;-1.3890207;-2.7838433;-4.749107;-4.1876664;-6.2798357;0.5824271;CODE
torch linalg vecdot incorrectly allows broadcasting along the contracted dimension;-1.9113009;-0.12489424;-3.4438403;-3.8033013;-3.536244;4.2920446;CODE
torch linalg vecdot doesn t support integer dtypes;-2.5211089;-1.4301165;-5.61471;-5.091483;-3.2468355;0.6597907;CODE
torch tries to emulate numpy 1 solve behavior by using batched 1 d solve;1.7288735;-0.5258116;-4.1276517;-2.5408134;-5.649849;0.5652435;-
whenever;-3.6445653;-2.803879;4.822568;1.8096064;-0.21975511;-0.729642;-
1 x1 ndim 1 x2 ndim;3.2454662;2.3238328;0.113806054;-10.858359;2.0016463;-0.18330793;-
2 x1 shape 1 x2 shape;1.8206513;0.68001455;3.5125017;-7.4144216;-0.25387105;1.5309649;-
see linalg solve is vector rhs in;-0.53169703;-1.1453998;-3.0438101;-5.1083293;-2.6776574;1.4279689;-
aten src aten native linearalgebrautils h and;-1.7733967;-2.2350876;-1.8378237;-4.004412;1.7884092;2.8290105;-
torch meta func linalg solve ex in;-3.038005;0.090017155;-1.6502125;-2.17759;-2.8884804;1.2890943;CODE
aten src aten native batchlinearalgebra cpp in the pytorch source code;-2.4176996;-4.4293017;-4.9065247;-2.228324;-1.3572636;1.1334774;CODE
the easiest way to work around this is to prepend a size 1 dimension to;1.2220063;3.0024424;-0.39059266;-4.9973073;-1.7946811;5.8105283;CODE
x2 since x2 is already one dimension less than x1;1.5404904;2.424392;0.15750858;-6.075604;0.93725175;2.0345354;CODE
see https github com pytorch pytorch issues 52915;-2.3629897;-4.44097;-5.851597;-2.6419108;-6.2963533;-0.43389478;CODE
torch trace doesn t support the offset argument and doesn t support stacking;-2.551201;1.114119;-1.1698644;-1.2992717;-4.189035;3.3596625;CODE
use our wrapped sum to make sure it does upcasting correctly;-0.5107981;2.2761657;1.6176649;0.8550408;-1.3493235;0.08354835;CODE
justfloat stands for inf inf which are not valid for literal;-2.800659;1.7713212;-2.2112863;-0.65724707;-2.344111;0.21855767;CODE
torch vector norm incorrectly treats axis the same as axis none;1.236041;0.35533148;-2.5224009;-5.6354527;-5.7842245;3.6952124;-
the norm of a single scalar works out to abs x in every case except;0.91174436;1.3715068;-1.4189413;-1.631133;-2.8902063;3.3808932;CODE
for ord 0 which is x 0;-1.5993446;3.3666418;-2.3806143;-6.6273046;2.0576665;-2.75096;CODE
array 1 79769313e 308 1 79769313e 308 0 00000000e 000 may vary;0.068819195;2.044997;-1.7264984;-7.186279;-0.04768924;-4.3159504;CODE
array 1 79769313e 308 1 79769313e 308 0 00000000e 000 may vary;0.068819195;2.044997;-1.7264984;-7.186279;-0.04768924;-4.3159504;CODE
array 1 79769313e 308 0 00000000e 000j may vary;-0.6827579;1.8808672;-1.7980057;-6.592026;-0.24325077;-3.7881866;CODE
override from python 3 12;-4.613495;-1.4857007;-2.9801967;-0.101347476;-1.5849407;-0.17496143;CODE
def str self str pyright ignore reportimplicitoverride;-3.2112134;2.2956936;-4.937691;2.4608645;-1.4118075;1.3940353;CODE
xpx at x idx set value or add value etc;-3.1870975;2.185837;1.4467655;-3.4830842;4.308011;1.7476805;IRRE
y xpx at x 0 set 2 copy true never updates x;-3.5909612;3.6724734;-1.7372395;-3.2866073;-1.8848959;0.4621172;IRRE
z xpx at x 1 set 3 may or may not update x in place;-3.4593937;3.0714376;-0.6593464;-2.8274174;2.3187807;1.3914137;IRRE
del x avoid accidental reuse of x as we don t know its state anymore;-4.3719964;1.6874216;-0.39815748;2.39799;2.6425025;1.5952637;CODE
x xpx at x mask set f x mask crash on dask and jax jit;-3.3139205;0.29369596;-2.824024;-1.6451923;-1.0016441;3.0521812;IRRE
array numpydoc ignore pr01 rt01;0.7987899;2.7623885;-5.161216;-5.0541315;-3.9520981;-1.7538381;CODE
array numpydoc ignore pr01 rt01;0.7987899;2.7623885;-5.161216;-5.0541315;-3.9520981;-1.7538381;CODE
array numpydoc ignore pr01 rt01;0.7987899;2.7623885;-5.161216;-5.0541315;-3.9520981;-1.7538381;CODE
on dask this function runs on the chunks so we need to determine the;1.9375074;0.05797605;-0.9194584;-2.791778;-0.8935409;-3.3175387;CODE
namespace that dask is wrapping;-5.5075083;-4.1571345;-2.637103;-0.35885984;-1.1351846;2.3241384;-
note that da minimum incidentally works on numpy cupy and sparse;6.033882;-1.4541714;-4.1977754;-4.3639283;-3.0218241;2.265376;TASK
thanks to all these meta namespaces implementing the array ufunc;-3.1625648;-0.5648615;-0.67509806;-1.5217463;0.02066249;1.3187903;TASK
interface but there s no guarantee that it will work for other;-4.165292;-3.961933;2.6836197;0.37047583;0.5206573;2.3727486;CODE
wrapped libraries in the future;-4.678148;-7.0853677;0.9441598;3.3178627;1.0734196;0.8182424;TASK
array numpydoc ignore pr01 rt01;0.7987899;2.7623885;-5.161216;-5.0541315;-3.9520981;-1.7538381;CODE
def like self others backend bool numpydoc ignore pr01 rt01;-2.8138592;0.5527235;-3.9625118;-1.9010359;-0.3537332;-1.9328868;CODE
jax jit does not support assignment by boolean mask;-2.5140631;2.7778478;-2.7724583;1.0103811;1.7204419;1.7163011;CODE
float in signature to accept math nan for dask;0.07811536;1.1835245;-4.3747654;-5.072217;-2.7331393;-1.6086105;CODE
int s are still accepted as float is a superclass of int in typing;-1.7603691;0.714918;-2.2186215;-2.341189;-0.29064146;-2.038027;CODE
return match numpy output;4.2359104;2.4169471;-0.48249424;-4.9095597;-5.736143;-3.7075808;IRRE
dask uses nan for unknown shape which predates the array api spec for none;0.24140501;-0.9263986;-6.302783;-3.6865664;-3.9176986;-0.23588093;CODE
none size none in sizes or math nan in sizes noqa plw0177;1.0979056;3.282544;-2.373049;-6.5746717;-1.8628658;-2.5464368;-
array numpydoc ignore pr01 rt01;0.7987899;2.7623885;-5.161216;-5.0541315;-3.9520981;-1.7538381;CODE
prevent warnings on numpy and dask on inf inf;0.02588868;-0.23170437;-6.4420023;0.59954935;-5.35246;0.13566111;-
lambda a b mxp isinf a mxp isinf b mxp sign a mxp sign b pyright ignore reportunknownargumenttype;-3.5190346;3.0952008;-5.6903944;1.7840041;1.5304704;1.3571746;CODE
note inf inf is true;-2.4494781;2.6598167;-0.78056836;1.9135817;-0.7125483;-1.3935052;TASK
lambda a b mxp abs a b atol rtol mxp abs b pyright ignore reportunknownargumenttype;-2.6380167;2.2312813;-5.9256053;2.7548122;2.0593474;1.089828;CODE
integer types;-0.56468207;0.97276396;0.44814363;-3.74251;2.954427;-3.4589405;CODE
don t rely on overflowerror as it is not guaranteed by the array api;1.0245571;4.317001;-2.2322514;2.8315625;-2.8218012;-2.4834433;CODE
rtol max int 1 so it s inconsequential;-2.8149445;3.3726418;0.35773033;-1.2506591;-0.32684526;-2.9489884;CODE
equalise the shapes by prepending smaller one with 1s;3.110471;2.3443046;3.8486602;-4.8651304;0.45294714;-0.8546823;CODE
insert empty dimensions;-0.480619;4.671494;0.9018424;-5.33365;0.6096227;-0.13012545;CODE
compute the product;-0.7069682;1.026676;3.0077856;-3.8499904;0.6438162;-3.6255224;-
reshape back and return;-0.59284395;1.4903326;4.5261273;-3.0828943;-1.5857801;4.2274404;IRRE
def nan to num numpydoc ignore pr01 rt01;1.2668242;2.1717594;-5.0983768;-4.512269;-3.9233775;-2.0132189;CODE
convert infinities to finite values;1.0725453;4.4528403;2.3655062;-2.8877125;-1.089372;-0.73552954;IRRE
size is jax specific;-1.9185891;1.5377597;1.7285075;-1.3937771;2.6177247;1.8514513;-
https github com data apis array api issues 883;-3.067918;-0.5570132;-3.1730635;-1.116094;-3.3417485;-0.7442834;CODE
there are 3 general use cases;-3.2854183;-1.7144849;2.627496;2.4880464;5.3078556;-0.2583427;CODE
1 backend has unique counts and it returns an array with known shape;2.611417;3.9629936;1.5210558;-2.1108313;1.6097702;-1.8357246;CODE
2 backend has unique counts and it returns a none sized array;0.14739016;6.161221;-0.2228514;-0.9139926;0.4768957;-1.9085008;CODE
e g dask ndonnx;-1.6671491;-3.9300172;1.628249;-1.9429355;-0.2993127;-0.19725744;CODE
3 backend does not have unique counts e g wrapped jax;-3.8613892;2.5882957;0.16839868;0.73719686;3.5592477;1.0341257;CODE
xp has unique counts o n complexity;1.217276;0.025056997;-0.61340827;-2.247901;5.602105;-1.8433126;META
xp does not have unique counts o n logn complexity;0.19879472;1.5064402;-3.1388729;-2.3366344;4.011718;-0.8609967;META
special cases;-2.6506574;0.6511672;4.3065166;1.506766;5.0094795;-2.2773423;CODE
array is size 0;-1.5457505;4.6841493;-0.11666841;-4.516462;-4.1836514;-2.9184465;-
array has all elements equal to each other;0.13027292;3.6339562;3.2176955;-3.2132754;0.22215581;-4.770062;-
array numpydoc ignore pr01 rt01;0.7987899;2.7623885;-5.161216;-5.0541315;-3.9520981;-1.7538381;CODE
weisstein eric w sinc function from mathworld a wolfram web;-1.4614499;-2.1952207;0.85513055;-3.2440066;-2.2895906;-0.891811;CODE
wikipedia sinc function;-1.8149619;-2.1740348;2.1111286;-3.1140745;-2.9007168;-1.1259831;CODE
https sparse pydata org en stable operations html package configuration;-4.4049497;-1.7633959;-2.5546987;-1.699507;-1.5013493;2.4575791;IRRE
import jax pylint disable import outside toplevel;-5.33805;1.1879535;-2.7238195;2.1768813;-1.1275368;4.849471;CODE
def lazy apply wrapper numpydoc ignore pr01 rt01;-0.4047139;0.5572419;-6.2826633;-1.4856635;-2.4022696;0.25996295;CODE
on dask wraps causes the graph key to contain the wrapped function s name;-3.6650853;-1.6687753;-1.8671867;-2.4651768;-2.1999426;0.70850146;CODE
tuple array numpydoc ignore gl08;1.7174271;2.2274408;-5.0041494;-5.9554443;-4.215778;-0.9840587;CODE
arg cast array np asarray arg pyright ignore reportinvalidcast noqa plw2901;-0.0859102;3.848398;-5.674118;-1.7757751;-2.9205987;0.6511598;OUTD
moduletype numpydoc ignore rt03;-3.4273846;0.8005243;-7.014235;-3.580314;-1.9265628;0.9098051;CODE
actual xp array namespace actual raises on scalars and lists;-0.3158078;-0.80978423;-3.683691;-2.1182556;1.6700841;1.7566643;CODE
dask uses nan instead of none for unknown shapes;1.8312135;-1.0801203;-4.655693;-4.1339426;-3.417222;-0.20197782;CODE
assert none not in actual shape requires explicit support;0.5825061;6.1689205;-5.557235;1.6540967;0.15870242;-0.50790066;CODE
actual shape actual compute shape type ignore attr defined pyright ignore reportattributeaccessissue;-0.32061872;2.4368265;-5.2796316;-0.927591;-2.139159;3.5084567;CODE
desired shape desired compute shape type ignore attr defined pyright ignore reportattributeaccessissue;1.0906135;3.2386758;-4.0956306;-0.86767155;-0.77848643;3.9061928;CODE
ignore shape but check flattened size this is normally done by;1.9546237;5.3007884;0.28673536;-1.538957;-2.5208204;0.451585;CODE
np testing assert array equal etc even when strict false but not for;2.5336623;7.257425;-5.9952006;2.1568255;-1.4617865;-5.06864;CODE
non materializable arrays;1.2945774;1.1018934;-0.5230462;-2.934612;0.7192275;2.1080098;-
actual size math prod actual shape pyright ignore reportunknownargumenttype;0.09454507;1.6888409;-2.671172;-2.0678344;-2.2127473;1.0695306;-
desired size math prod desired shape pyright ignore reportunknownargumenttype;1.4651253;2.8946679;-2.1899116;-2.377841;-0.47129378;2.2076738;-
only numpy distinguishes between scalars and arrays we do if check scalar;3.289029;1.7814854;-4.2533183;-2.6208136;-6.3457017;-2.390791;CODE
important here we assume that we re not tracing;-2.1291971;-1.7096449;3.272103;3.714682;-3.1670516;0.7832253;CODE
e g we re not inside jax jit nor cupy cuda stream begin capture;-2.8268504;-1.7356045;0.8011226;2.661918;-0.6048797;2.236782;-
return not is torch array x or x device type meta type ignore attr defined pyright ignore reportattributeaccessissue;-2.61278;4.4930177;-5.2572556;1.1014191;-1.4213955;2.0834095;CODE
return array todense type ignore attr defined pyright ignore reportattributeaccessissue;-1.7334068;4.937617;-4.938507;2.4931383;-1.253457;2.7452502;IRRE
note only needed if the transfer guard is enabled;-5.324213;-0.5020627;0.4604528;1.4333968;-0.76949805;3.3071322;TASK
multiplier of 4 is used as for np float64 this puts the default rtol;-3.0302453;1.415623;-2.9422824;-6.317985;-2.271124;-0.80654895;CODE
roughly half way between sqrt eps and the default for;-0.46912324;-0.5649586;1.4776438;-3.3017993;-3.1651266;1.8722141;CODE
numpy testing assert allclose 1e 7;2.7236254;4.2284813;-6.051032;-0.08741486;-6.71404;-4.609039;CODE
np testing assert allclose pyright ignore reportcallissue;0.14876625;5.1417546;-6.5488157;4.8376656;-4.5143995;-0.6711129;IRRE
rtol rtol pyright ignore reportargumenttype;-4.1610546;2.6725442;-5.9876623;2.9829113;-0.0834923;1.9754046;-
https github com numpy numpy blob v1 26 0 numpy lib arraysetops py l524 l758;0.35797334;-2.0659392;-5.6887555;-7.129676;-6.1344404;-0.80044675;IRRE
isinstance x float returns true for np float64;-0.5773161;2.5446265;-5.2203603;-3.2469006;-4.9694138;-1.0068347;CODE
isinstance x complex returns true for np complex128;-0.80532306;2.1231048;-4.747899;-1.4162054;-2.6486027;-0.100810975;META
bool is a subclass of int;-3.0436304;2.541823;-1.9488323;-0.8426277;3.1740463;-3.2825925;CODE
this includes misc malformed input e g str;-3.6916153;0.62455004;-2.7356548;-1.6013848;-0.5343998;-4.328889;CODE
return a b type ignore return value;-0.1433691;7.178806;-1.7527617;0.68794495;0.83417135;-1.7216593;IRRE
a is an array api object;-2.036232;1.4825199;0.9730954;0.33267358;1.7921383;-1.4041489;CODE
b is a int float complex bool;-2.003451;4.51619;-0.22701398;-4.564346;0.1545569;-2.929348;CODE
https data apis org array api draft api specification type promotion html mixing arrays with python scalars;-1.1806839;-1.5725613;-4.3548126;-0.9716984;-1.2516482;1.0173299;CODE
undefined behaviour let the function deal with it if it can;-4.8329463;5.4284596;1.1387943;1.3177698;-3.4444535;-3.1416526;CODE
neither a nor b are array api objects;-2.6234403;2.695534;-1.0244783;-0.62066716;0.871308;-2.3794231;IRRE
note we can only reach this point when one explicitly passes;-2.3875334;2.7060406;2.394371;2.3525758;0.21387967;0.48693705;CODE
xp xp to the calling function otherwise we fail earlier on;-5.8184543;2.0757704;0.056844287;1.3736432;0.15641214;-0.08654748;IRRE
array namespace a b;-1.2268006;2.1437204;-0.09083665;-3.1479225;1.9920881;-0.17629378;-
dask arrays uses non standard nan instead of none;1.2240825;0.8037208;-6.1750717;-4.4291687;-4.2204494;-1.7141111;CODE
quietly skip scalars and none s;2.295857;0.47250044;-2.550225;1.5826764;-0.9488156;0.816762;-
fixme https github com pydata sparse issues 876;-2.9992595;-1.0832827;-5.5557213;-2.288758;-5.376624;0.94797504;IRRE
boolean indexing is supported but not when the index is a sparse array;1.7408092;3.227075;-5.341095;-1.1923752;-0.558877;0.60880953;IRRE
boolean indexing by list or numpy array is not part of the array api;0.24953012;2.8224156;-4.873889;-2.5325828;-4.130821;-2.358702;CODE
if out boolean indexing pragma no cover;0.22910511;5.121247;-1.4911021;1.1478857;1.9422215;-1.7084904;CODE
backwards compatibility with jax 0 6 0;-4.8643107;0.19418599;-1.9850457;0.6333589;1.110827;2.2630172;-
https github com jax ml jax issues 27418;-5.8515844;-1.8513038;-1.3773328;0.20093289;-2.2259593;-0.23446356;CODE
fixme https github com data apis array api issues 945;-3.4844902;-0.11583962;-3.911268;-0.54284704;-3.6199849;-0.64636;CODE
if device type meta type ignore union attr pyright ignore reportattributeaccessissue reportoptionalmemberaccess;-1.2118049;2.8135614;-5.346492;2.9856968;1.8831491;3.2356505;META
fmt skip;-2.0130606;1.3041986;0.391302;2.2470698;-0.48560628;-0.83392584;-
fmt skip;-2.0130606;1.3041986;0.391302;2.2470698;-0.48560628;-0.83392584;-
class pickler pickle pickler numpydoc ignore gl08;-0.78657866;0.0726519;-6.083402;-2.3488998;-2.3797438;-0.85573334;CODE
literal 0 1 none numpydoc ignore gl08;-0.63755447;3.39667;-6.4662437;-6.381058;-3.6356509;-2.079128;CODE
instances append obj type ignore arg type;-3.2264807;3.2424233;-2.93908;1.682673;0.8114297;2.2652469;CODE
if typ in basic pickled types no subclasses;-2.0478559;1.5043229;-3.726105;0.5357647;2.967046;-1.7702152;IRRE
if obj is a collection recursively descend inside it;-0.7315706;2.3636868;0.22532251;2.1562924;2.7078369;-0.6294594;CODE
note a class that defines slots without defining getstate;-3.442075;2.1335862;1.445875;0.1256113;4.1867633;0.31693143;CODE
cannot be pickled with reduce but can with reduce ex 5;-1.8123304;2.3692992;-1.32667;-0.3208597;-0.10285979;-0.09032168;META
except exception pylint disable broad exception caught;-4.186844;4.02331;-3.6634226;4.0566654;-1.0940884;1.3843639;CODE
object can be pickled let the pickler recursively descend inside it;-2.366754;1.73808;1.7050517;0.7914308;1.4872997;0.3593177;CODE
class unpickler pickle unpickler numpydoc ignore gl08;-1.4889865;0.21215664;-5.220377;-2.5433068;-2.1898363;0.37130806;CODE
numpydoc ignore gl08;-0.8114932;1.220731;-5.4870253;-4.254023;-4.6395526;0.2273729;CODE
pylint disable missing module docstring duplicate code;-7.4967203;1.1279525;-5.0403233;1.8575933;-1.0905943;1.6765736;CODE
if type checking pragma no cover;-2.1129162;5.373351;-2.0357947;2.9607048;1.392845;-3.6419868;-
todo import override from typing requires python 3 12;-6.3439207;-0.8787549;-4.484789;1.4838785;-2.6680894;-0.11172567;CODE
sphinx hacks;-3.5419514;-4.221396;0.95114875;1.2213229;0.7012746;-1.3836627;-
when xp jax numpy this is similar to b jax jit myfunc a;-1.5222726;-2.0234082;0.095237486;-2.4935925;-1.1566362;0.38523102;CODE
when xp dask array crash on compute or persist;-1.3068141;-1.350298;-3.794122;-0.8861747;-1.3036674;0.8254466;-
b myfunc a this is wrapped when xp jax numpy or xp dask array;-3.5373728;-0.5960398;-3.0321977;-3.3206153;-1.7937837;0.4415445;CODE
c mymodule myfunc a this is not;-4.6691704;1.0877714;1.3846954;-0.486973;-1.1261218;-2.049342;CODE
b mymodule myfunc a this is wrapped when xp jax numpy or xp dask array;-4.7657876;0.09489296;-2.4218724;-2.552482;-1.2849112;1.3665994;CODE
c naked myfunc a this is not;-2.7591932;0.54188246;2.8631008;-0.72350687;-1.2428958;-2.0082512;CODE
do not collect any tests in externals this is more robust than using;-1.3146815;0.93489486;-2.8793824;6.8311887;-0.27183858;-0.96805227;CODE
ignore because ignore needs a path and it is not convenient to pass in;-3.3465812;4.1883893;-0.71681935;4.362547;-1.4945974;2.1523411;TASK
the externals path very long install dependent path in site packages when;-3.5531247;-1.3637706;-2.5332634;0.991834;-0.9625128;2.8888483;CODE
using pyargs;-2.3281353;-3.2908742;-0.3412118;-0.23955375;-2.9692655;-0.22293495;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this isn t something that people should be routing using in a pipeline;-1.7875891;-1.1300211;0.8992233;2.4514446;1.2984146;3.7795653;CODE
dtype no validation validation delegated to numpy;0.3651389;-0.52531075;-7.3894324;-0.9778225;-5.252304;-0.2655408;OUTD
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this list of english stop words is taken from the glasgow information;-1.3850112;-2.2102253;1.5473814;0.9264603;-0.04467949;-0.26455224;CODE
retrieval group the original list can be found at;0.52116954;-1.4148145;2.0549326;-0.80415434;3.877609;-1.2873899;-
http ir dcs gla ac uk resources linguistic utils stop words;-3.9805262;-2.1107218;-0.50662243;1.6696213;1.1336807;0.09826727;CODE
use the array data from the first image in this dataset;4.6942663;0.6584814;4.0611324;-4.47374;-0.9653539;0.19919844;CODE
here are just two of these patches;-2.9711723;-0.917072;1.5619345;-1.0700121;0.7058436;-0.31826884;-
use the array data from the second image in this dataset;4.6100855;0.34716657;4.460624;-4.5501122;-0.38257864;0.35431188;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
csr matrices can t be compared for equality;2.7161038;3.9066432;-3.9842222;-2.9820416;-2.164515;0.08027305;IRRE
make two feature dicts with two useful features and a bunch of useless;-0.36746788;-1.3032622;0.10604953;0.24843164;3.2080133;1.7235678;TASK
ones in terms of chi2;-0.85034144;-1.891223;2.0461931;-2.210144;2.507576;-3.8500872;CODE
generate equal dictionaries with different memory layouts;2.2517927;-1.1658773;-1.2960676;-3.3355803;3.337909;0.7862203;-
check that the memory layout does not impact the resulting vocabulary;-1.9789436;1.2229916;-2.3811867;2.2902975;0.27771586;1.1245302;IRRE
for vectorizers n features in does not make sense and does not exist;1.5127487;-1.4968977;-5.342347;-2.8554933;0.17099102;0.4208309;CODE
mix byte and unicode strings note that foo is a duplicate in row 0;-1.3890873;3.8588955;-1.9731615;-3.805283;1.3086514;-2.617136;TASK
it x for x in raw x iterable;-0.28788614;0.5140103;0.9213261;-1.8120981;1.954548;-2.0916607;CODE
check the influence of the seed when computing the hashes;3.3098586;1.7291821;0.28442505;0.731989;0.4830066;-3.320547;-
assert that no zeros are materialized in the output;1.371347;6.870991;-2.7687428;-0.38709575;-2.4952183;-4.1773033;CODE
check that some of the hashed tokens are added;-0.9938054;2.6009922;-0.37881663;1.960689;1.7530371;-2.0030985;TASK
with an opposite sign and cancel out;-4.696232;1.9502344;4.697324;-0.88058436;0.90948385;-2.1547146;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
negative elements are the diagonal the elements of the original;-2.0965204;0.982783;2.8756273;-4.597477;1.4205245;-0.77434146;-
image positive elements are the values of the gradient they;1.5653287;-0.6669287;1.9975065;-3.2840438;-0.613172;2.4586718;IRRE
should all be equal on grad x and grad y;0.748382;-0.10303324;-0.35606632;-0.26853207;1.5751624;-0.2651251;-
check that the edges are in the right position;-1.0377309;3.8638895;2.88076;-1.5409169;-2.6362894;-0.9681034;CODE
when using a sparse image with a singleton component;1.1080363;0.76363677;0.9670719;0.29020536;0.09707626;7.5769997;IRRE
checking that the function works with graphs containing no edges;-0.4537239;4.8732095;-0.44608307;-0.048165407;-1.3125741;-1.956909;CODE
generating two convex parts with one vertex;1.1003371;-0.21608724;2.1739755;-4.1069365;2.1555827;2.6603227;-
thus edges will be empty in to graph;-1.5284805;2.8233473;1.5879539;-3.08682;-1.6148131;0.5152567;CODE
check ordering;-0.20650859;4.2120385;3.3418844;0.75167733;3.2870395;-5.527637;-
checking that the function works whatever the type of mask is;-0.51704127;4.281771;-1.5350157;-0.116802305;-1.3375806;-0.89557445;CODE
checking dtype of the graph;2.4304583;0.7822146;-1.812655;-3.8159554;-2.0608616;-2.6637661;-
subsample by 4 to reduce run time;4.5164347;2.3173068;0.96717286;-0.14489199;3.5558808;0.25931346;CODE
subsample by 4 to reduce run time;4.5164347;2.3173068;0.96717286;-0.14489199;3.5558808;0.25931346;CODE
make a collection of faces;-0.24121824;-2.4722867;5.188005;-2.6822243;3.0007079;0.8327225;-
request patches of the same size as image;0.037137803;1.7451982;2.5781968;-0.9970111;-0.563793;4.037591;CODE
should return just the single patch a k a the image;-0.46598426;1.0756679;1.0044454;0.4467402;-1.2399576;2.3151803;IRRE
this is 3185;-3.6368508;-1.0560766;0.6100954;-2.5537357;3.0937932;-2.076746;CODE
test same patch size for all dimensions;3.2757285;3.8115091;-0.8993538;-0.87197673;-0.49146727;0.23531626;IRRE
width and height of the patch should be less than the image;-1.7698965;0.64336896;2.1321504;-3.3673935;-3.1157825;3.1305223;-
check some classical latin accentuated symbols;-2.1453428;-1.1498342;0.33375585;-2.0790274;2.3537667;-0.9435561;IRRE
check some arabic;-2.783528;-0.36561635;2.352793;0.41932142;0.6425747;-3.2231688;-
a u0625 alef with a hamza below;-1.6124502;0.6268012;0.024379725;-3.280051;-0.45682698;-1.7594277;-
expected u0627 simple alef;-2.7228014;1.3810657;-2.3757184;-1.2368459;-0.93122905;-3.8969278;-
mix letters accentuated and not;-1.1322174;0.5923247;0.27125427;-1.9202358;2.2564502;0.23591997;CODE
strings that are already decomposed;-0.41882908;1.2883612;-0.5572098;-0.40294033;2.9612463;-0.42836255;CODE
a o u0308 o with diaeresis;-2.402521;-0.60860837;1.9125308;-3.1897457;2.0281732;-1.7927734;-
combining marks by themselves;1.0900354;0.6062889;3.910008;-2.1164181;3.913041;-0.53929913;-
multiple combining marks on one character;0.2549044;1.1352127;3.2147038;-3.0917168;3.6888576;-2.1963549;CODE
check some classical latin accentuated symbols;-2.1453428;-1.1498342;0.33375585;-2.0790274;2.3537667;-0.9435561;IRRE
check some arabic;-2.783528;-0.36561635;2.352793;0.41932142;0.6425747;-3.2231688;-
a u0625 halef with a hamza below;-1.5650182;0.34680125;0.46480146;-2.9780262;-0.95523554;-1.6507009;-
expected halef has no direct ascii match;-2.7084658;0.72203285;-2.1699812;0.5922174;-2.1267264;-2.2882342;-
mix letters accentuated and not;-1.1322174;0.5923247;0.27125427;-1.9202358;2.2564502;0.23591997;CODE
with custom preprocessor;-2.6190937;0.71667755;0.20393792;0.29499736;4.115555;2.0423653;-
with custom tokenizer;-2.8696818;-0.9029059;1.4440947;1.7712641;3.6843636;3.4247534;-
decode error default to strict so this should fail;-3.5826828;5.464297;-6.4279966;0.78073186;-2.0163348;-0.6985657;CODE
first encode as bytes a unicode string;-2.7898755;1.4769877;-0.6308064;-4.0940022;0.3783063;0.9076054;CODE
then let the analyzer try to decode it as ascii it should fail;-1.6865726;3.0093539;-3.6112192;0.34498146;-2.2254064;-2.5493333;CODE
because we have given it an incorrect encoding;-3.4886894;-0.7008958;-2.5455375;-2.1514602;-2.7195466;-1.0238672;-
try a few of the supported types;-3.710119;-4.605267;-0.8830384;-0.05677351;1.1750388;3.6011934;CODE
fit on stopwords only;0.59944636;1.419373;0.79330176;1.5532223;1.1290975;1.1059614;-
check that the check for uppercase in the provided vocabulary is only done at fit;-2.2776084;2.016554;-4.8925705;2.11721;-0.8495268;-0.5493682;CODE
time and not at transform time 21251;-2.3313954;0.45677444;0.59761107;-1.6505342;-0.69557476;-0.7915114;CODE
normalize white spaces;2.4140737;-0.27048072;0.84742904;-5.437357;1.1233636;3.6361623;-
no need to do any slicing for unigrams;-0.110568576;0.7121926;0.03263306;-3.8331668;0.68055314;1.5640755;CODE
iterate through the string;-1.1718245;2.1324394;4.788121;-0.055358198;0.1439052;-5.788321;CODE
bind method outside of loop to reduce overhead;0.44436413;3.4972887;2.2243867;3.1225061;1.4682951;2.9992888;IRRE
normalize white spaces;2.4140737;-0.27048072;0.84742904;-5.437357;1.1233636;3.6361623;-
bind method outside of loop to reduce overhead;0.44436413;3.4972887;2.2243867;3.1225061;1.4682951;2.9992888;IRRE
if offset 0 count a short word w len n only once;-0.061236326;4.2457633;1.5841273;-1.7055326;1.100835;-4.050027;IRRE
accent stripping;-1.5728562;-1.0423272;2.205461;-0.74371403;-1.2668605;0.5184771;-
stop words are were previously validated;-4.1252956;3.5576808;-2.1861694;4.4645925;0.71697974;-1.498084;-
nb stop words is validated unlike self stop words;-3.298836;2.0305307;-3.4860885;1.9647477;0.8181739;-0.79316247;CODE
failed to check stop words consistency e g because a custom;-4.2469835;4.323175;-3.3433545;4.9670186;0.074778296;-1.372998;-
preprocessor or tokenizer was used;-5.054289;-2.1231487;-1.6020607;1.69514;2.2427049;1.699436;-
dtype no validation delegate to numpy;0.39686117;-0.85284895;-7.185549;-1.346478;-4.8403244;-0.36455625;OUTD
triggers a parameter validation;-1.8293629;5.026878;-1.2850168;5.378939;0.79448575;0.88423663;IRRE
add a new value when a new vocabulary item is seen;-1.7964158;-0.1735843;3.3055625;2.77268;2.6130574;0.7892794;CODE
ignore out of vocabulary items for fixed vocab true;-0.77924293;1.4736539;-2.0076773;4.041537;1.3063551;1.8523872;CODE
disable defaultdict behaviour;-3.2934444;0.96426266;-3.0000525;2.6160507;-2.280981;2.3661296;CODE
if indptr 1 np iinfo np int32 max 2 31 1;-1.1541784;2.870465;-3.3955536;-4.65595;1.0846139;-4.0872383;CODE
we intentionally don t call the transform method to make;-2.2479432;0.84847975;-1.142058;1.296679;-3.3795288;2.3630917;CODE
fit transform overridable without unwanted side effects in;1.0599041;1.0041322;-0.7571359;0.18869284;-1.8556874;6.388763;CODE
tfidfvectorizer;0.307643;-3.3551643;-2.1422322;-0.26497284;-0.7217467;5.0509853;-
use the same matrix building strategy as fit transform;6.1577435;-0.4430546;-0.48363096;-2.3421316;-1.172653;5.887923;IRRE
we need csr format for fast row manipulations;2.0028126;-1.383442;0.8422984;-3.6195345;2.0610049;-1.1410801;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
mask 2 true select the first two features;0.5395912;1.821;1.3759032;-1.6074554;3.121928;0.7075501;TASK
input features in which an element is true iff its;0.88734746;3.453066;1.3112342;0.5710909;2.8282833;-4.640016;TASK
true this is an integer array of shape output features whose;3.5590866;0.12689261;0.33669052;-6.1254334;1.331049;-1.365374;CODE
upport boolean array of shape input features;1.1363063;0.9783352;-0.6183311;-2.2953577;1.051202;-0.1595764;CODE
insert additional entries in indptr;-1.853871;1.3054327;0.993519;-1.7806665;3.0060768;-0.40628183;TASK
e g if transform changed indptr from 0 2 6 7 to 0 2 3;-0.18204954;1.7113122;0.7870691;-3.049527;-0.5118821;-2.2293797;CODE
col nonzeros here will be 2 0 1 so indptr becomes 0 2 2 3;0.21370506;3.054497;-1.015011;-7.089458;-0.99721134;-3.9142165;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
selectfrommodel estimator is not validated yet;0.44537333;2.8365228;-5.060154;4.481877;-2.437278;1.7357999;CODE
todo slep6 remove when metadata routing cannot be disabled;-5.61098;1.6930459;-3.205838;2.6438422;-0.20211492;5.64911;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
here we rely on nearestneighbors to select the fastest algorithm;4.780151;-2.3941903;1.2079064;-1.667566;1.8268483;-0.41199446;IRRE
kdtree is explicitly fit to allow for the querying of number of;0.28915626;-0.92363507;-3.763882;-0.011007962;1.4031478;0.9859283;CODE
neighbors within a specified radius;2.6108766;0.99084765;3.8377512;-3.5117924;-0.8688666;0.38776535;-
ignore points with unique labels;4.653578;3.2471955;1.6985269;-2.1240308;3.1067157;0.5396738;CODE
add small noise to continuous features as advised in kraskov et al;3.99462;-3.783583;-1.326376;1.8766686;-0.055233832;5.2067323;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
features in the friedman 1 dataset;4.842763;-6.5698285;0.7051247;0.31417918;1.1527829;0.003859654;TASK
informative features in the friedman 1 dataset;4.530655;-6.594929;1.2166077;0.43248758;1.587148;-0.21947332;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
sequentialfeatureselector estimator is not validated yet;0.23215693;2.5408409;-4.6136966;4.4678807;-0.90399474;2.5109851;TASK
with auto feature selection n features to select will be updated;-0.6151861;-2.9031286;1.2756834;2.7785792;1.8748679;1.4371656;CODE
to support sum after features are selected;3.134424;0.121568896;1.3711694;1.1198369;2.4744527;0.3187942;TASK
the current mask corresponds to the set of features;1.2795168;-2.753684;1.0306137;-1.1645901;1.9065433;3.092175;TASK
that we have already selected if we do forward selection;-2.575114;0.17583488;3.1042025;3.7018032;4.4077086;1.3077079;CODE
that we have already excluded if we do backward selection;0.23478472;-0.1960469;0.10549726;4.7225647;2.8723319;1.9994371;CODE
we only need to verify the routing here and not use the routed params;-2.5549374;3.4480653;0.06119769;2.2538543;-1.1442584;2.652622;TASK
because internally the actual routing will also take place inside the;-3.7504723;0.73757255;1.8276544;0.9202416;-0.5698932;5.2987504;CODE
cross val score function;2.735811;2.687102;0.6046736;-2.5362601;-0.5819407;-3.033009;CODE
return the best new feature and its score to add to the current mask;1.8750352;0.655053;1.211841;2.8541203;1.93699;1.4350284;TASK
i e return the best new feature and its score to add resp remove;-1.2012749;0.28382668;0.64357;3.8270328;0.87503034;1.6086718;TASK
when doing forward selection resp backward selection;1.1193539;0.6466099;-0.39176217;1.910261;1.8960168;3.4531562;CODE
feature will be added if the current score and past score are greater;0.423315;-0.4168;1.4990655;4.511226;2.2878683;-0.44143397;TASK
than tol when n feature is auto;-1.1293242;1.3329915;-1.3279479;2.4304328;3.1058273;0.29250118;TASK
fixes issue 1240 nans can t be properly compared so change them to the;0.9352007;2.1793494;-3.9741488;-2.650282;-5.4402046;-2.813222;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
if hasattr x toarray sparse matrix;3.6216047;2.6822443;-3.5440047;-3.5314512;-0.71154267;1.7930266;IRRE
use peak to peak to avoid numeric precision issues;5.4061027;2.9365554;-0.014484233;-1.8796953;-2.577924;0.42387938;CODE
for constant features;4.32854;-2.6160803;0.7650417;-0.87367743;2.9167097;1.2080945;CODE
check dtype matches;0.62296337;1.1991061;-2.8210986;0.4694687;1.1210275;-5.006546;-
check 1d list and other dtype;1.6581813;2.2692523;-2.7374556;-2.3663733;1.5788625;-4.8668485;CODE
check wrong shape raises error;0.010794437;5.1037965;-2.2134953;-0.13085467;-2.9119058;-2.800285;META
check dtype matches;0.62296337;1.1991061;-2.8210986;0.4694687;1.1210275;-5.006546;-
check wrong shape raises error;0.010794437;5.1037965;-2.2134953;-0.13085467;-2.9119058;-2.800285;META
check dtype matches;0.62296337;1.1991061;-2.8210986;0.4694687;1.1210275;-5.006546;-
check 1d list and other dtype;1.6581813;2.2692523;-2.7374556;-2.3663733;1.5788625;-4.8668485;CODE
check wrong shape raises error;0.010794437;5.1037965;-2.2134953;-0.13085467;-2.9119058;-2.800285;META
check dtype matches;0.62296337;1.1991061;-2.8210986;0.4694687;1.1210275;-5.006546;-
check wrong shape raises error;0.010794437;5.1037965;-2.2134953;-0.13085467;-2.9119058;-2.800285;META
feature 0 is highly informative for class 1;0.2645749;-3.799754;-3.073201;2.7958298;2.5684469;-0.075044855;CODE
feature 1 is the same everywhere;-1.4480617;-2.0211554;-0.29760095;2.824859;3.1559117;2.3556008;TASK
feature 2 is a bit informative for class 2;-0.41910234;-5.874477;0.62345713;3.8899736;3.4302197;0.1202635;CODE
test the score functions;3.7776997;3.8316348;1.0150938;2.861825;0.3552387;-7.422746;IRRE
test that our f oneway gives the same result as scipy stats;4.4452844;0.08503426;-3.3029954;1.9702045;-4.0932646;-5.814291;IRRE
smoke test f oneway on integers that it does raise casting errors;1.18774;6.302918;-3.9040406;2.2889142;-0.6331393;-4.3373966;CODE
with recent numpys;2.2067797;-4.5964684;1.3710251;-4.386386;-4.707284;-1.9423033;-
test that is gives the same result as with float;2.2108345;7.5019717;-0.2751227;0.17494315;-3.2241657;-7.1403213;IRRE
test whether the f test yields meaningful results;3.2100866;3.6162398;-1.04684;5.005221;-2.2858918;-5.888436;IRRE
on a simple simulated classification problem;6.479335;-1.4192291;1.5157478;0.6178525;4.356852;-0.90310067;IRRE
testing against numpy for reference;3.1940136;1.9787809;-3.8123872;-0.015798684;-5.8931594;-4.8516846;CODE
test whether the f test yields meaningful results;3.2100866;3.6162398;-1.04684;5.005221;-2.2858918;-5.888436;IRRE
on a simple simulated regression problem;4.339884;2.2871995;1.820108;0.4911024;-3.543132;-0.31088236;-
with centering compare with sparse;7.343432;-0.1739413;1.2768271;-2.851948;-0.8179805;2.7526808;IRRE
again without centering compare with sparse;7.00675;1.0885317;0.9691497;-2.7332082;-1.429563;2.2903285;IRRE
test whether f regression returns the same value;2.2378476;5.7480397;-0.5452798;2.9490395;-3.1884348;-4.2112513;IRRE
for any numeric data type;4.5749793;-0.2513798;0.6954406;-5.184641;2.8433688;-3.5164332;CODE
test whether f regression preserves dof according to center argument;2.1330805;4.2159867;-2.2543025;2.266778;-4.5088553;-0.19805922;IRRE
we use two centered variates so we have a simple relationship between;1.7256529;2.2709963;3.9183166;-2.0839517;-1.2641377;1.9948102;IRRE
f score with variates centering and f score without variates centering;3.1650946;2.8406143;1.7622949;-0.3871076;-0.86848456;2.0515773;CODE
create toy example;-2.8154805;-2.2626746;5.4739285;0.06963022;2.568034;-1.7136978;IRRE
x np arange 5 6 reshape 1 1 x has zero mean;2.089058;3.6613622;-2.91979;-6.696361;-4.180814;0.6684407;-
y 0 0 0 have y mean being null;0.04303619;4.565334;-1.6618081;-3.0941753;-4.6233935;-1.646336;-
assert almost equal f2 0 0 232558139 value from statsmodels ols;3.0093606;4.5869;-5.9764137;1.0566654;-3.806598;-3.1899555;CODE
a feature in x is constant forcing finite;-1.3107094;1.7006242;-0.4161181;1.5026623;-0.07956251;4.3726287;CODE
the target y is constant forcing finite;-1.2124832;2.4597456;0.3179797;1.6789168;-3.0252995;3.793604;CODE
a feature in x is constant not forcing finite;-1.1325529;2.8498747;-1.6083343;0.20574194;-1.8089218;3.2002811;CODE
the target y is constant not forcing finite;-0.70665264;3.480223;-0.33172727;0.44648173;-5.5153627;2.7182226;CODE
a feature in x is constant forcing finite;-1.3107094;1.7006242;-0.4161181;1.5026623;-0.07956251;4.3726287;CODE
the target y is constant forcing finite;-1.2124832;2.4597456;0.3179797;1.6789168;-3.0252995;3.793604;CODE
feature in x correlated with y forcing finite;0.5862989;1.8741777;-1.1854283;0.28701425;-1.1079834;4.1603665;CODE
feature in x anti correlated with y forcing finite;0.16646464;2.4718578;-1.8172125;0.4342826;-1.6061513;3.9555628;CODE
a feature in x is constant not forcing finite;-1.1325529;2.8498747;-1.6083343;0.20574194;-1.8089218;3.2002811;CODE
the target y is constant not forcing finite;-0.70665264;3.480223;-0.33172727;0.44648173;-5.5153627;2.7182226;CODE
feature in x correlated with y not forcing finite;1.047656;2.6948984;-1.6903046;-0.52008456;-1.9918714;3.2112856;CODE
feature in x anti correlated with y not forcing finite;0.69236773;3.2410853;-2.310841;-0.5082508;-2.554785;3.0664601;CODE
test whether the f test yields meaningful results;3.2100866;3.6162398;-1.04684;5.005221;-2.2858918;-5.888436;IRRE
on a simple simulated classification problem;6.479335;-1.4192291;1.5157478;0.6178525;4.356852;-0.90310067;IRRE
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple classification problem;5.0752964;-0.16643606;2.8275592;0.69287086;5.891095;-3.6679633;IRRE
with the percentile heuristic;5.25504;-2.9499557;4.138652;1.108967;2.320461;-1.3798757;-
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple classification problem;5.0752964;-0.16643606;2.8275592;0.69287086;5.891095;-3.6679633;IRRE
with the percentile heuristic;5.25504;-2.9499557;4.138652;1.108967;2.320461;-1.3798757;-
check other columns are empty;1.1074623;6.115883;-0.2332047;-2.334051;0.35858276;-4.8298607;-
test univariate selection in classification settings;5.339574;-0.13940322;-1.6955752;3.5167322;3.6153233;-2.6421185;IRRE
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple classification problem;5.0752964;-0.16643606;2.8275592;0.69287086;5.891095;-3.6679633;IRRE
with the k best heuristic;2.729817;-2.9587379;3.6545613;1.5313162;1.6049745;-1.3489096;-
test whether k all correctly returns all features;2.9587839;2.706942;-2.2333286;2.3997657;0.13056938;-5.7826276;IRRE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 24949;-3.11715;-9.948442;-5.8975725;-0.6047584;-5.082187;-5.127274;CODE
test whether k 0 correctly returns no features;1.8567197;4.016752;-3.9005477;1.4297148;-1.0031905;-5.7052813;IRRE
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple classification problem;5.0752964;-0.16643606;2.8275592;0.69287086;5.891095;-3.6679633;IRRE
with the fdr fwe and fpr heuristics;0.9082296;-2.37627;1.7823974;1.7813658;1.460678;-1.0711296;-
test univariate selection in regression settings;3.7835596;2.8689733;-1.1885511;4.0906153;-0.20505267;-1.8472298;IRRE
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple regression problem;4.303654;3.2967875;3.6281562;0.1670692;-0.17703259;-2.745008;-
with the percentile heuristic;5.25504;-2.9499557;4.138652;1.108967;2.320461;-1.3798757;-
check inverse transform respects dtype;-0.35298717;2.6126745;-5.250887;-0.89709234;-3.0908163;0.33084428;IRRE
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
selects all features when 100 is asked;1.393934;1.1184874;1.9226741;2.5247183;3.02031;-2.0586824;TASK
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple regression problem;4.303654;3.2967875;3.6281562;0.1670692;-0.17703259;-2.745008;-
with the k best heuristic;2.729816;-2.9587371;3.6545606;1.5313162;1.6049739;-1.3489106;-
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple regression problem;4.303654;3.2967875;3.6281562;0.1670692;-0.17703259;-2.745008;-
with the fpr fdr or fwe heuristics;1.5351816;-2.144584;1.9279157;1.8460063;2.6107078;-1.2787858;-
test boundary case and always aim to select 1 feature;1.1488817;5.1143928;-0.32519746;4.618386;3.8268535;-1.6326877;CODE
test that fdr heuristic actually has low fdr;1.8586383;1.5766453;-2.5618546;2.6282423;-0.29827437;-3.9880705;IRRE
warnings can be raised when no features are selected;-2.5747762;1.7755234;-3.9683263;5.26323;0.07413901;0.6563604;CODE
low alpha or very noisy data;3.7622335;0.28024653;-0.10696553;0.6303602;-2.6680553;-0.38918376;-
as per benjamini hochberg the expected false discovery rate;3.4458091;-0.6225538;-1.9061176;3.9497466;-0.30806628;-1.5055004;-
should be lower than alpha;-1.6714096;2.170913;0.0024673876;-1.1957402;-3.3950691;-1.1814622;-
fdr e fp tp fp alpha;-2.054401;-1.1936011;-0.7510089;-2.4759588;0.32485065;-1.8215386;-
make sure that the empirical false discovery rate increases;4.6646376;-1.9536266;-2.6415422;5.6346717;0.5300879;-1.9529684;-
with alpha;-1.7635357;-1.3814158;5.5087337;-0.16559383;-1.4002876;-3.3131382;-
test whether the relative univariate feature selection;3.8238904;0.49202952;-1.4969858;2.058154;1.3304685;-2.1820593;CODE
gets the correct items in a simple regression problem;4.303654;3.2967875;3.6281562;0.1670692;-0.17703259;-2.745008;-
with the fwe heuristic;1.2257067;-3.322745;3.6508996;3.2285209;1.7637756;-0.49762598;-
test whether selectkbest actually selects k features in case of ties;1.7543714;0.34850997;-1.6410115;2.5201583;2.8223095;-2.692245;CODE
prior to 0 11 selectkbest would return more features than requested;0.47673458;0.1261904;-3.6585453;1.979041;1.7308064;-0.98327905;CODE
test if selectpercentile selects the right n features in case of ties;3.379682;2.808108;0.35410255;1.268346;1.6744242;-2.545755;CODE
test whether k best and percentiles work with tied pvalues from chi2;3.1716554;2.065185;-1.7353259;-0.53710127;0.55586904;-1.5349685;IRRE
chi2 will return the same p values for the following features but it;1.1400236;2.920295;-2.4367604;-1.5361964;0.60150343;-2.6699061;IRRE
will return different scores;1.7548574;3.1915362;2.1793334;2.9215963;2.0325592;-3.959125;IRRE
test whether k best and percentiles works with multilabels with chi2;4.0233226;1.1185001;-0.9153045;-0.9626823;1.5168103;-1.801052;IRRE
test for stable sorting in k best with tied scores;4.164133;1.9590962;0.8601899;1.8016945;0.52425444;-2.9848728;IRRE
assert that selectkbest and selectpercentile can handle nans;2.4904;4.6689887;-4.2698765;1.3532624;-1.2946055;-1.0653114;CODE
first feature has zero variance to confuse f classif anova and;0.6677046;0.6644699;-2.364785;0.18840647;-0.88574415;-0.25239202;CODE
make it return a nan;-0.3803671;3.628846;1.2905692;-0.6943789;-3.5534124;-3.3142684;IRRE
test that f classif warns if a feature is constant throughout;1.359278;3.6801083;-3.9671137;5.6671343;0.019575808;-1.5734345;IRRE
generate random uncorrelated data a strict univariate test should;4.26101;3.6868834;-2.5325453;2.1103601;0.099548616;-1.4697806;IRRE
rejects all the features;-1.9609281;-0.60782653;-0.73314786;3.6541853;0.37647465;-0.08334078;TASK
test in kbest mode;-0.48527655;2.5031688;-2.5374248;3.2751207;0.48906004;-3.0784826;IRRE
test in percentile mode;2.6206806;4.592707;0.6084035;1.420271;-0.9363854;-3.5213757;IRRE
test in kbest mode;-0.48527655;2.5031688;-2.5374248;3.2751207;0.48906004;-3.0784826;IRRE
test in percentile mode;2.6206806;4.592707;0.6084035;1.420271;-0.9363854;-3.5213757;IRRE
test that selectfrommodel fits on a clone of the estimator;2.7561376;4.0780053;-2.490779;5.429801;-0.9226907;1.2895741;CODE
case 1 an error should be raised at transform if fit was not called to;1.7698587;5.825782;-4.676206;1.1294171;-2.8432527;1.6212826;CODE
validate the attributes;1.1095514;2.65775;-1.1592138;2.2352948;5.2768817;-2.7556324;META
case 2 max features is not validated and different from an integer;0.8591286;3.744013;-4.450355;-0.22066906;2.50831;-2.516613;CODE
fixme we cannot validate the upper bound of the attribute at transform;0.30739543;3.7311308;-4.537595;0.2750358;-0.8023767;2.5771084;CODE
and we should force calling fit if we intend to force the attribute;1.5665619;2.2715003;-2.0543284;4.9629683;2.0437725;3.511653;CODE
to have such an upper bound;-0.7431415;1.5779722;3.4531994;1.4709103;1.0544684;-1.3131524;-
non regression test for 21949;-0.7782352;2.6121614;-4.918101;3.0475416;-3.3719954;-5.7823224;IRRE
linearregression does not implement partial fit and should raise an;2.654057;3.4058192;-3.4725282;0.35490245;-3.121826;3.0304437;CODE
attributeerror;-2.6384718;1.6531335;-2.5732567;-0.2505034;-3.9445484;-3.6376987;META
in discrete case computations are straightforward and can be done;3.065241;-0.36086226;2.3171055;-2.0495963;5.6391544;-2.3408475;CODE
by hand on given vectors;2.929323;-2.6877983;2.9796696;-5.8582726;0.33505246;-1.2680349;CODE
for two continuous variables a good approach is to test on bivariate;1.9163051;2.3574123;2.0740945;2.1107097;-1.473212;-2.4796607;CODE
normal distribution where mutual information is known;1.227937;-0.8792113;1.6156951;-1.8852476;2.4725025;3.3643346;META
mean of the distribution irrelevant for mutual information;0.62576294;-0.07011958;1.3459388;0.549475;0.52043897;4.338261;CODE
setup covariance matrix with correlation coeff equal 0 5;3.1762507;1.6887671;-1.9301606;-3.8898146;-3.0188406;2.801834;IRRE
true theoretical mutual information;2.09254;-1.7074738;1.8477951;1.3232759;2.1681507;3.16328;CODE
theory and computed values won t be very close;3.4982514;1.8338819;-1.4600711;1.4367199;-2.5755439;-2.1625695;IRRE
we here check with a large relative tolerance;0.25477508;1.8838357;-0.25949803;5.6826506;-2.0802321;-1.052354;-
to test define a joint distribution as follows;-0.7701494;3.831086;0.76162726;2.4017653;2.248819;-2.8530698;CODE
p x y p x p y x;-2.7461708;0.9965401;1.986468;-2.792439;1.7473297;-1.7549182;-
x bernoulli p;-2.5255725;1.2417812;2.1264954;-2.6544776;0.108997926;-3.3171194;-
y x 0 uniform 1 1;-1.0112733;2.1479752;1.8315368;-4.8620667;-2.5419676;-1.7623671;CODE
y x 1 uniform 0 2;-0.69997287;2.0033078;2.4026384;-5.5677905;-2.460642;-2.218034;CODE
use the following formula for mutual information;1.050653;1.5760627;2.3151062;-3.9475024;2.753493;0.87368864;CODE
i x y h y h y x;-2.036802;-0.76218885;1.8799137;-3.2148361;0.56237596;-0.38454983;-
two entropies can be computed by hand;1.6855205;-0.12985964;1.5118731;-2.318375;2.083789;1.0967438;-
h y 1 p 2 ln 1 p 2 p 2 log p 2 1 2 log 1 2;-1.6613691;0.75838166;1.9655422;-3.8309455;0.28049174;-1.3793174;-
h y x ln 2;-3.3391933;-0.9182443;2.0899475;-3.95042;-1.084147;-2.4630592;-
now we need to implement sampling from out distribution which is;2.5126379;0.4335619;2.852256;2.1106417;3.92885;1.4695996;TASK
done easily using conditional distribution logic;1.840769;3.0658925;4.236577;0.5377927;5.2612734;-3.0485802;META
assert the same tolerance;0.5039055;4.67716;-0.29419887;5.122537;-0.4664224;-1.684708;CODE
test that adding unique label doesn t change mi;1.7847936;5.927501;-2.1290424;3.2870035;2.2064183;-3.8138485;TASK
we are going test that feature ordering by mi matches our expectations;1.6546273;-1.6711342;-0.8144489;6.069715;1.753571;-0.075307414;TASK
here x 0 is the most informative feature and x 1 is weakly;1.0185173;-2.8323169;0.43921906;-0.2768829;1.6201681;0.71960235;TASK
informative;-0.45043162;-4.899712;5.491829;3.618143;3.1063402;-1.790567;CODE
we generate sample from multivariate normal distribution using;2.7416961;-0.7272126;0.41365087;-2.9353929;1.5158749;1.3259379;CODE
transformation from initially uncorrelated variables the zero;0.53172255;1.9277067;-0.8550937;-3.347663;-4.108708;3.546422;CODE
variables after transformation is selected as the target vector;1.0269046;1.0908165;0.7502354;-1.9844128;-0.40289026;3.200891;CODE
it has the strongest correlation with the variable 2 and;2.283604;0.21469496;1.5861344;-0.66762936;0.26121792;-1.7439426;IRRE
the weakest correlation with the variable 1;1.934351;1.8363633;-0.5740607;0.19980347;-1.3117727;1.0059752;IRRE
xxx should mutual info regression be fixed to avoid;1.691478;1.4273878;-1.5636063;-0.5624034;1.1558936;2.44219;CODE
up casting float32 inputs to float64;-1.5610623;1.5090867;-1.9978299;-4.0318303;-2.9726264;0.3214569;CODE
here the target is discrete and there are two continuous and one;-0.5108226;2.2174435;5.652124;-0.803429;0.7676757;-1.6595542;CODE
discrete feature the idea of this test is clear from the code;1.8821424;3.584512;-2.5308747;0.78320295;2.6647034;-5.752873;CODE
check that the continuous values have a higher mi with greater;1.8319583;4.643109;0.10319405;-0.3917053;-2.821128;-1.8696028;IRRE
n neighbors;1.0182556;-1.8383988;4.511547;-2.3875818;0.4827486;-2.36377;-
the n neighbors should not have any effect on the discrete value;3.0271354;3.464441;-0.050936557;-3.9649677;0.082250424;-1.1698686;IRRE
the mi should be the same;-1.0992914;0.12138549;2.1976159;1.5053105;0.6255738;2.0323598;-
add some irrelevant features random seed is set to make sure that;0.98020685;-1.0760955;-1.8469601;3.4973192;1.113418;1.0326792;IRRE
irrelevant features are always irrelevant;-0.15930516;-1.049175;0.22039092;3.4573088;1.6340966;2.5399024;TASK
check if the supports are equal;0.9284546;4.90333;-0.049021848;0.10064475;0.96892154;-2.0571146;IRRE
add some irrelevant features random seed is set to make sure that;0.98020685;-1.0760955;-1.8469601;3.4973192;1.113418;1.0326792;IRRE
irrelevant features are always irrelevant;-0.15930516;-1.049175;0.22039092;3.4573088;1.6340966;2.5399024;TASK
dense model;2.9500043;-1.5403422;1.5155225;0.73658377;0.3001043;1.9623486;-
sparse model;6.1372337;-2.44112;1.0080827;-0.7535178;0.4661643;2.9876153;IRRE
make sure rfe passes the metadata down to fit and score methods of the;0.01954919;-0.5694253;-4.4356885;4.407127;0.9753759;1.857647;CODE
underlying estimator;2.5909646;-0.3965227;0.07814013;3.6094217;-0.5172316;5.3967233;-
test that the results are the same;3.6131709;5.7891583;2.3641207;3.865284;2.344066;-8.119293;IRRE
add some irrelevant features random seed is set to make sure that;0.98020685;-1.0760955;-1.8469601;3.4973192;1.113418;1.0326792;IRRE
irrelevant features are always irrelevant;-0.15930516;-1.049175;0.22039092;3.4573088;1.6340966;2.5399024;TASK
there are 10 features in the data we select 40;3.0439014;-1.9399793;2.495019;-1.0792522;4.0841517;-1.9369887;CODE
add some irrelevant features random seed is set to make sure that;0.98020685;-1.0760955;-1.8469601;3.4973192;1.113418;1.0326792;IRRE
irrelevant features are always irrelevant;-0.15930516;-1.049175;0.22039092;3.4573088;1.6340966;2.5399024;TASK
dense model;2.9500043;-1.5403422;1.5155225;0.73658377;0.3001043;1.9623486;-
add some irrelevant features random seed is set to make sure that;0.98020685;-1.0760955;-1.8469601;3.4973192;1.113418;1.0326792;IRRE
irrelevant features are always irrelevant;-0.15930516;-1.049175;0.22039092;3.4573088;1.6340966;2.5399024;TASK
y list iris target regression test list should be supported;1.3914914;0.24423842;-3.9129968;0.98635507;-1.7036023;-1.3255905;IRRE
test using the score function;2.2999218;4.939982;0.9148416;2.3296795;0.15424445;-7.9563565;IRRE
non regression test for missing worst feature;2.8748374;2.8388426;-3.7415993;3.9248085;-2.1516025;-2.4616072;TASK
all the noisy variable were filtered out;0.834918;2.768252;-1.4106064;1.9249419;-2.9552808;-0.82666886;CODE
same in sparse;3.2661502;-2.827551;-0.3322769;-0.8431225;0.21254992;2.982376;IRRE
test using a customized loss function;3.8100102;5.376825;-2.4205046;4.5317254;-1.0115001;-2.3890588;IRRE
test using a scorer;2.3290591;4.2003064;1.9249499;4.182051;0.81606;-6.900187;IRRE
test fix on cv results;2.3199885;4.0008245;-4.1356726;3.7981274;-2.1537237;-4.526906;IRRE
in the event of cross validation score ties the expected behavior of;3.2266526;1.9672792;0.11756795;5.139972;1.9612284;-1.0208983;CODE
rfecv is to return the fewest features that maximize the cv score;3.3424513;-2.687225;-2.2054935;2.5443943;3.5334022;0.26420638;TASK
because test scorer always returns 1 0 in this example rfecv should;0.20905352;3.8979619;-3.912474;3.0020301;-0.86828554;-3.5554771;IRRE
reduce the dimensionality to a single feature i e n features 1;4.879214;-0.8582966;1.0726978;-4.482243;2.819795;2.5929823;TASK
same as the first two tests but with step 2;-0.0963517;3.205282;0.71916324;3.765698;0.24566847;-4.5334306;IRRE
verifying that steps 1 don t blow up;-2.3691485;2.9160042;0.71084374;2.2076125;-2.051854;-3.9326534;CODE
y list iris target regression test list should be supported;1.3914914;0.24423842;-3.9129968;0.98635507;-1.7036023;-1.3255905;IRRE
test using the score function;2.2999218;4.939982;0.9148416;2.3296795;0.15424445;-7.9563565;IRRE
non regression test for missing worst feature;2.8748374;2.8388426;-3.7415993;3.9248085;-2.1516025;-2.4616072;TASK
check verbose 1 is producing an output;-2.051833;6.954307;-1.533801;3.0932841;-1.3795866;-6.598559;IRRE
y list iris target regression test list should be supported;1.3914914;0.24423842;-3.9129968;0.98635507;-1.7036023;-1.3255905;IRRE
non regression test for varying combinations of step and;2.6277237;4.5323253;-0.86305636;4.841061;0.081217624;-3.01559;CODE
min features to select;3.7787883;-0.5719431;2.383997;-0.64798254;4.4353347;1.346234;TASK
make sure that cross validation is stratified;1.1706785;3.7523668;-2.6722329;4.4308424;2.051471;-1.0628287;-
test when floor step n features 0;1.962796;4.908424;-1.5372902;0.39706704;0.666949;-5.1051784;TASK
test when step is between 0 1 and floor step n features 0;2.1507115;4.3787656;-0.72464174;-0.5784022;0.65650004;-4.1693997;TASK
test when step is an integer;-0.30449557;6.6339335;0.7104328;1.8226993;-0.29001686;-6.468822;IRRE
in rfe number of subsets of features;3.43667;-1.3148421;-1.0461755;-0.46973485;5.157156;0.35092205;TASK
the number of iterations in fit;5.908396;0.46759936;2.3130639;1.4774071;0.38786557;-0.87109476;-
max ranking;3.3028831;-1.3190794;4.0063972;-0.6415866;3.3234324;-0.8416053;-
1 n features step n features to select 1 step;1.5240777;-0.7527487;1.3967232;-2.3446875;3.510392;0.16177309;TASK
after optimization 4534 this number;0.5875355;1.4858693;-0.8131525;-2.9478538;1.9857922;-2.677187;CODE
1 np ceil n features n features to select float step;2.899719;-0.46339837;-1.0138676;-4.987806;0.66120416;-0.5245318;TASK
this test case is to test their equivalence refer to 4534 and 3824;-1.2802222;4.7147765;-1.2269515;0.59630626;3.4486809;-6.0561275;IRRE
rfe;-2.5618095;-1.6198665;2.8506444;2.764743;2.0746977;-1.6276454;-
case 1 n features n features to select is divisible by step;0.76868796;1.3699547;-0.50415677;-1.9224329;3.4126844;-1.0116476;TASK
case 2 n features n features to select is not divisible by step;-0.10144512;2.0764472;-1.7819175;-1.5860959;2.3685126;-0.9696145;TASK
this number also equals to the maximum of ranking;1.1681966;1.0607663;1.8810438;-1.9136513;3.7355218;-2.8178387;CODE
in rfecv fit calls rfe fit;-1.3452371;0.21913223;-3.2252195;0.036804523;1.9111357;3.1477969;IRRE
number of subsets of features of rfe;2.5402582;-1.4368155;-0.85030735;0.2930844;5.5312653;0.4139266;TASK
the size of each score in cv results of rfecv;4.231884;-0.89691573;-1.9859647;0.8724226;2.1156685;-1.3092668;IRRE
the number of iterations of the for loop before optimization 4534;3.2445056;-0.28849545;-0.017261451;-0.5430541;-0.26541042;-1.607934;CODE
rfecv n features to select 1;1.5920278;-0.6794633;-1.5016627;-0.8475259;5.8147335;1.2331266;TASK
case 1 n features 1 is divisible by step;0.25065735;0.80553156;-0.90388393;-2.2885847;3.141115;-1.4234488;TASK
case 2 n features 1 is not divisible by step;-0.77117586;2.038833;-2.5547183;-2.1945362;1.8468747;-1.6491333;TASK
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 15312;-3.3258157;-9.918299;-5.636911;-0.55869037;-5.330411;-5.720181;CODE
add nan and inf value to x;0.97555494;4.3166995;-0.4247138;-4.6966224;-3.2310154;-2.3907719;TASK
linearregression does not implement decision function and should raise an;1.3564143;2.4602575;-2.8080184;1.1575531;-1.570496;1.012767;CODE
attributeerror;-2.6384718;1.6531335;-2.5732567;-0.2505034;-3.9445484;-3.6376987;META
create rfe rfecv with n features to select min features to select;2.3910284;-0.3412363;-1.4774815;-1.1346341;4.718251;1.5039634;TASK
larger than the number of features present in the x variable;3.2735798;-0.2556087;0.4098606;-2.6208746;0.43530566;-0.5357296;CODE
make sure n features to select is respected;0.72834116;-0.30846292;-1.2317317;1.6915765;3.524083;0.37861463;TASK
test passing a float as n features to select;3.750323;4.64074;-2.0352812;0.04887617;1.1672654;-4.507838;CODE
2 0 2 f1 is dropped since it has no predictive power;-0.0015496631;1.0082767;-0.81463087;1.89544;-1.1499454;-2.638619;-
1 2 f2 is more predictive than f0 so it s kept;1.1598496;0.72410053;0.37587035;2.6922193;-1.6015866;-0.7969199;-
basic sanity check 3 features only f0 and f2 are correlated with the;2.2347171;1.6198298;-0.7332266;-0.64529985;1.7534544;-1.6639079;TASK
target f2 having a stronger correlation than f0 we expect f1 to be;2.565002;0.370477;-0.786544;2.7848964;-1.8481286;0.562513;-
dropped and f2 to always be selected;-2.138161;2.333019;2.1840153;3.3141918;1.0049597;1.6356839;CODE
make sure sparse data is supported;4.4957867;-0.9387513;-4.199572;0.20460908;-1.7059968;2.0856652;IRRE
make sure nans are ok if the underlying estimator supports nans;2.5332406;3.003149;-4.570131;0.5975029;-4.857335;1.3175651;-
linearregression does not support nans;2.8062618;2.579759;-5.78947;-2.299851;-4.8473587;1.679284;CODE
make sure that pipelines can be passed into sfs and that sfs can be;-3.5118368;-3.8835695;-1.9091853;2.8562117;0.31020764;0.8311548;CODE
passed into a pipeline;-2.2923353;0.14324541;0.8915909;3.2118907;2.1914098;-0.23566784;CODE
pipeline in sfs;-1.3130288;-4.4860206;1.9088683;1.4343785;1.1975864;0.5674753;CODE
sfs in pipeline;-1.6329049;-4.3397613;0.73231786;0.77403253;0.45192403;-0.2854633;CODE
make sure that models without classification labels are not being;1.200555;-0.6516407;-3.013912;3.8565545;1.6959682;1.0541009;IRRE
validated;-1.5191796;0.52636254;1.6320295;4.5162673;2.6669848;-4.1220565;-
make sure that other non conventional y labels are not accepted;-0.30481404;1.0892334;-2.7396262;-0.08911812;2.4071696;0.11075057;-
non regression test for 25525;1.8807737;4.1110435;-4.2662554;1.5417165;-3.1677854;-5.515579;IRRE
non regression test for 25957;0.907876;3.139604;-3.7663915;3.0446706;-2.790551;-5.9270825;IRRE
test variancethreshold with default setting zero variance;1.0800166;5.375116;-4.053615;3.320784;-2.8861723;1.2172412;CODE
test variancethreshold with default setting zero variance error cases;1.2527704;5.8152204;-5.1468854;4.3128147;-2.4662197;0.8719878;CODE
test variancethreshold with custom variance;1.7777984;4.6015186;-2.706371;3.6056232;-0.77392346;0.8540808;CODE
test that variancethreshold 0 0 fit eliminates features that have;3.5462375;3.4423745;-5.4516783;2.7631595;-1.3761729;1.1328923;TASK
the same value in every sample even when floating point errors;4.380351;5.867582;-3.2084577;-0.2673091;-3.4387343;-3.397444;CODE
cause np var not to be 0 for the feature;-0.9168861;2.4325309;-5.239829;-0.31844378;-3.2701888;-1.1007996;CODE
see 13691;-3.6094463;-0.14697196;1.728903;-1.8962814;-2.1460116;-2.7682705;-
add single nan and feature should still be included;-0.5301907;1.9959161;-2.272446;0.4548211;-0.8173004;0.73421293;TASK
make all values in feature nan and feature should be rejected;2.9689808;4.2080026;-2.602843;0.52952725;-0.8250795;-1.2765594;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
raise original attributeerror if attr does not exist;-1.5790222;5.0729322;-4.4143844;3.3871288;-1.9384577;-0.4258514;CODE
estimator s attributes are now accessible except fit predict and;1.9448905;-3.6281657;-2.485599;3.8280919;-1.0749912;4.656567;META
fit transform;3.9978116;0.28379557;2.7620976;-4.3803077;-2.7573245;2.5813391;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this should be no op;-3.6005857;0.31836158;2.3953114;-0.55959713;-0.37508157;-0.34756353;CODE
only here to test that it doesn t get called;-5.556288;0.78346485;1.5201079;5.8391757;-2.49039;-2.841549;IRRE
pragma no cover;-3.7499998;0.42159036;2.464259;1.0908369;-0.12944427;-0.99521214;-
only here to test that it doesn t get called;-5.556288;0.78346485;1.5201079;5.8391757;-2.49039;-2.841549;IRRE
pragma no cover;-3.7499998;0.42159036;2.464259;1.0908369;-0.12944427;-0.99521214;-
obj func is the objective function to be maximized which;1.6433069;-2.6654494;1.0303026;-0.02170014;1.5162799;2.3125873;CODE
takes the hyperparameters theta as parameter and an;0.038770083;1.8527312;1.1956056;0.04343829;0.72330767;1.0437853;IRRE
optional flag eval gradient which determines if the;0.8902968;3.2008224;-2.04731;0.20674327;2.2138283;2.3125036;-
gradient is returned additionally to the function value;0.17098269;1.879261;-0.10749186;-0.9850173;-2.9118767;1.528329;IRRE
initial theta the initial value for theta which can be;-2.9934916;2.3367646;3.0328739;-0.69040823;-1.0762627;-1.2887676;IRRE
used by local optimizers;0.7555621;-4.41754;1.0562726;0.06981546;0.6114045;3.6803775;-
bounds the bounds on the values of theta;-1.1938035;1.7624516;3.0309296;-0.48745826;-2.248632;-2.0998063;IRRE
returned are the best found hyperparameters theta and;2.422764;1.9431417;0.7465811;2.3333666;0.09602276;-2.382361;IRRE
the corresponding value of the target function;0.4961778;2.2379344;2.923382;-0.67686576;-0.8450292;-0.3574232;IRRE
obj func is the objective function to be maximized which;1.6433069;-2.6654494;1.0303026;-0.02170014;1.5162799;2.3125873;CODE
takes the hyperparameters theta as parameter and an;0.038770083;1.8527312;1.1956056;0.04343829;0.72330767;1.0437853;IRRE
optional flag eval gradient which determines if the;0.8902968;3.2008224;-2.04731;0.20674327;2.2138283;2.3125036;-
gradient is returned additionally to the function value;0.17098269;1.879261;-0.10749186;-0.9850173;-2.9118767;1.528329;IRRE
initial theta the initial value for theta which can be;-2.9934916;2.3367646;3.0328739;-0.69040823;-1.0762627;-1.2887676;IRRE
used by local optimizers;0.7555621;-4.41754;1.0562726;0.06981546;0.6114045;3.6803775;-
bounds the bounds on the values of theta;-1.1938035;1.7624516;3.0309296;-0.48745826;-2.248632;-2.0998063;IRRE
returned are the best found hyperparameters theta and;2.422764;1.9431417;0.7465811;2.3333666;0.09602276;-2.382361;IRRE
the corresponding value of the target function;0.4961778;2.2379344;2.923382;-0.67686576;-0.8450292;-0.3574232;IRRE
if theta shape 0 n dims use same theta for all sub kernels;3.0598176;1.5124495;-2.3377385;-3.0193403;0.42502055;3.3107367;CODE
theta for compound kernel;0.7557271;-0.049987543;-0.8423155;-3.2013688;-1.0248921;1.0339185;CODE
obj func the objective function to be minimized which;2.366755;-1.0673316;-0.024001246;-0.6199342;0.83791834;3.1711707;CODE
takes the hyperparameters theta as a parameter and an;0.108236074;1.6895978;1.2947944;0.2565261;0.7522292;1.1004025;IRRE
optional flag eval gradient which determines if the;0.8902968;3.2008224;-2.04731;0.20674327;2.2138283;2.3125036;-
gradient is returned additionally to the function value;0.17098269;1.879261;-0.10749186;-0.9850173;-2.9118767;1.528329;IRRE
initial theta the initial value for theta which can be;-2.9934916;2.3367646;3.0328739;-0.69040823;-1.0762627;-1.2887676;IRRE
used by local optimizers;0.75556123;-4.4175377;1.0562731;0.069814384;0.61140364;3.680377;-
bounds the bounds on the values of theta;-1.1938035;1.7624516;3.0309296;-0.48745826;-2.248632;-2.0998063;IRRE
returned are the best found hyperparameters theta and;2.422764;1.9431417;0.7465811;2.3333666;0.09602276;-2.382361;IRRE
the corresponding value of the target function;0.4961778;2.2379344;2.923382;-0.67686576;-0.8450292;-0.3574232;IRRE
convert from upper triangular matrix to square matrix;1.5325998;0.11975203;1.3968539;-5.5385513;-2.443107;1.1858233;CODE
hyperparameter l kept fixed;0.33908445;3.7639856;-0.3468415;2.6611753;-0.4662492;1.5721405;IRRE
we need to recompute the pairwise dimension wise distances;5.0335026;-1.369303;-0.7190066;-4.0766373;0.6083106;3.6527696;TASK
else isotropic;-0.26863652;-0.82842;2.4877608;-2.7633867;0.323275;0.48971492;-
else general case expensive to evaluate;0.9005277;2.6362529;0.7549456;4.159234;2.4766731;-2.7234724;CODE
k k 0 0 np finfo float eps strict zeros result in nan;1.0916721;1.6139354;-5.2790165;-5.996776;-4.617876;-0.6566483;IRRE
convert from upper triangular matrix to square matrix;1.5325998;0.11975203;1.3968539;-5.5385513;-2.443107;1.1858233;CODE
hyperparameter l kept fixed;0.33908445;3.7639856;-0.3468415;2.6611753;-0.4662492;1.5721405;IRRE
we need to recompute the pairwise dimension wise distances;5.0335026;-1.369303;-0.7190066;-4.0766373;0.6083106;3.6527696;TASK
approximate gradient numerically;4.820593;-1.2991754;0.10673275;-1.7307235;-1.5287747;3.6418366;IRRE
def f theta helper function;-1.8714397;0.8935072;2.1775806;-0.83634216;-1.6993976;-2.5617833;CODE
gradient with respect to length scale;2.1023526;-0.7244871;1.8918355;-3.2243218;-1.3770891;3.1409545;-
else l is kept fixed;-3.4522388;4.051617;2.6617134;1.1853479;0.8727277;0.009379014;-
gradient with respect to alpha;0.04473948;-0.95383203;1.3091571;-2.2478518;-1.1313789;2.5307133;-
else alpha is kept fixed;-3.4438365;2.0869992;1.3471242;1.637683;-2.4148324;0.50382036;-
adapted from scipy optimize optimize py for functions with 2d output;4.887435;-3.8022296;-2.0128238;-4.1089354;-5.2306557;0.9118284;CODE
approximate gradient numerically;4.820593;-1.2991754;0.10673275;-1.7307235;-1.5287747;3.6418366;IRRE
def f gamma helper function;-1.8536327;-0.036283743;2.3655002;-1.4291112;-1.7564908;-1.4071711;CODE
we have to fall back to slow way of computing diagonal;3.0061843;-2.0393167;0.1715259;-1.9089354;-1.2241628;1.3878711;-
check that the latent mean and variance have the right shape;3.296438;3.1187491;0.9262684;-0.5632618;-2.720722;-0.1874531;CODE
larger than unity this test was made in response to issue 15612;-0.7100795;3.930501;-3.0031621;2.1008186;-1.785274;-2.5012646;IRRE
by convention single output data is squeezed upon prediction;6.352197;-0.6354123;-1.8733367;1.6684276;-0.54056233;3.5503309;IRRE
number of spatial locations to predict at;5.1236587;-1.71644;3.342005;0.0748404;0.62371874;0.2745444;-
number of sample predictions per test point;5.355096;-0.33036473;0.50082844;4.295705;1.0213063;-2.3042536;IRRE
by convention single output data is squeezed upon prediction;6.352197;-0.6354123;-1.8733367;1.6684276;-0.54056233;3.5503309;IRRE
fixme before fitting the estimator does not have information regarding;-0.2929562;1.3537316;-3.5094488;3.2532043;-5.379195;3.754306;CODE
the number of targets and default to 1 this is inconsistent with the shape;0.99362516;1.9420183;0.5924999;-1.5889163;-2.0804381;1.0875736;CODE
provided after fit this assert should be made once the following issue;1.1919771;7.195952;-5.6942;5.43035;0.0950609;-0.23322584;CODE
is fixed;-4.786336;0.1804971;3.8871152;1.5097651;-0.6066745;-0.78296524;-
https github com scikit learn scikit learn issues 22430;-3.4941037;-9.645538;-5.730262;-1.1194936;-5.0650706;-5.2743907;CODE
y samples model sample y x test n samples n samples y test;1.927473;1.1119612;0.101594396;0.23372325;0.11491295;-2.2167387;IRRE
assert y samples shape y test shape;4.091702;3.3739707;-0.84903324;0.5090659;-2.0615962;-3.2457948;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
allow using pd na as missing values to impute numerical arrays;4.2575817;4.3151784;-3.6351674;-2.631708;-1.9040321;0.7727498;IRRE
raise pragma no cover;-3.5503745;1.5173928;1.7737461;1.9276663;-0.44656143;1.0840081;CODE
compute the most frequent value in array only;4.313517;2.7260296;2.9965398;-2.8416176;-0.032820974;-2.697126;IRRE
scipy stats mode is slow with object dtype array;4.775422;-2.2792337;-5.251671;-2.6686506;-5.6295037;-1.6479155;IRRE
python counter is more efficient;1.789569;-0.40602002;2.0357385;-0.99778706;-1.4148855;-5.4302497;CODE
tie breaking similarly to scipy stats mode;2.356304;-2.6152377;-0.80742615;-1.4369103;-3.1540515;-1.9725146;CODE
compare to array extra value n repeat;2.7806075;6.3498883;1.8981298;-2.0200024;0.35584024;-6.083134;IRRE
tie breaking similarly to scipy stats mode;2.356304;-2.6152377;-0.80742615;-1.4369103;-3.1540515;-1.9725146;CODE
sp hstack may result in different formats between sparse arrays and;3.2466338;-0.5390353;-4.7224813;-2.0575893;-1.7677344;0.76431924;IRRE
matrices specify the format to keep consistent behavior;3.6229804;1.7237798;-1.8290312;-5.5156655;-0.73017645;2.2226937;CODE
fill value no validation any object is valid;-1.9798597;6.260286;-0.7779387;1.4991769;0.4274744;-3.0250115;IRRE
if input is a list of strings dtype object;1.7021062;1.6028178;-1.2754422;0.003010701;1.2276514;-5.98249;CODE
otherwise valueerror is raised in simpleimputer;-0.91638774;3.9606686;-4.5323997;1.6660533;-4.952379;-1.6338485;IRRE
with strategy most frequent or constant;2.716329;0.11706627;6.264456;3.8949256;2.7932093;0.5796983;CODE
because the list is converted to unicode numpy array;0.026953546;0.40605286;-3.4029586;-5.915444;-5.5169277;-1.9139851;IRRE
use object dtype if fitted on object dtypes;1.3641095;1.7960606;-3.954252;0.77765006;0.21738093;1.0929912;CODE
use the dtype seen in fit for non fit conversion;2.7739177;0.15188502;-5.6242375;-1.8140801;-1.625678;1.4325805;IRRE
missing values 0 not allowed with sparse data as it would;4.000638;3.626958;-5.2435284;-2.9994555;-2.5819266;-1.0181355;IRRE
force densification;-1.5277815;2.565762;1.1175005;0.86278015;-1.3624891;2.7719312;CODE
by default fill value none and the replacement is always;-2.8124044;5.83059;-0.9234962;-0.81422454;-0.44924015;-0.30013818;IRRE
compatible with the input data;3.1637895;-1.2044405;0.9871554;-3.178393;2.1537023;-2.5423012;CODE
make sure we can safely cast fill value dtype to the input data dtype;1.4725952;1.7764361;-4.5596538;-1.5777881;-0.8851497;-1.0358683;IRRE
default fill value is 0 for numerical input and missing value;-0.32497048;4.914639;-2.2167933;-3.7963097;-3.7509792;-1.8358281;CODE
otherwise;-1.9837351;-0.27491835;3.2116354;2.2846112;-0.45446774;-1.311218;-
mean;-0.8584131;0.4457244;6.374265;0.8543819;-1.3125975;-2.3286166;-
avoid the warning warning converting a masked element to nan;-0.24761857;4.808223;-3.5445611;-0.64765763;-3.234216;0.2025688;CODE
median;1.957881;0.935303;5.648348;-1.1242545;-0.94169176;-2.1763885;-
avoid the warning warning converting a masked element to nan;-0.24761857;4.808223;-3.5445611;-0.64765763;-3.234216;0.2025688;CODE
most frequent;0.1670411;-2.152988;4.976749;3.3662395;0.83449405;-1.773985;-
avoid use of scipy stats mstats mode due to the required;2.352944;0.046334874;-4.0962114;-0.060053345;-4.950756;-1.782327;CODE
additional overhead and slow benchmarking performance;3.1838305;-2.8395388;0.106235795;1.8660413;0.75059295;1.6052462;TASK
see issue 14325 and pr 14399 for full discussion;-6.8554683;-1.5447099;-4.086446;1.7594532;1.8929275;-0.7801322;CODE
to be able access the elements by columns;1.4467878;1.3261619;4.3758993;-5.786535;2.0082126;-2.2471185;-
constant;-1.5298865;1.5791034;4.3617334;-0.2552734;-1.1152405;-2.919341;CODE
for constant strategy self statistcs is used to store;1.2868801;-0.5927725;1.9711033;3.813263;1.7270765;1.5071803;CODE
fill value in each column or np nan for columns to drop;4.3682895;2.0418556;-0.052790023;-5.028483;-2.5052373;-1.844543;IRRE
custom;-2.5554588;-2.6092026;6.759293;0.4113912;4.8472605;0.25488627;-
compute mask before eliminating invalid features;3.1978116;3.543779;-2.9692962;-0.6857339;0.70381016;-0.018245146;TASK
decide whether to keep missing features;0.7337842;0.33143643;-0.31915554;3.568478;1.8181798;0.63972145;TASK
same as np isnan but also works for object dtypes;-1.9894826;-3.2672417;-4.93603;-2.022017;-0.177209;-0.3305421;CODE
use feature names warning if features are provided;-2.228725;-0.4942836;-3.0875049;4.8634944;2.161885;-0.6278606;TASK
do actual imputation;-0.9360969;2.714424;0.5294474;2.7945883;0.9682088;-2.0437126;CODE
if no invalid statistics are found use the mask computed;4.5134125;4.3890953;-2.821895;0.48253202;-1.0866721;-0.33794716;IRRE
before else recompute mask;-2.8200436;1.3807099;0.70980453;1.931563;0.117581524;2.41246;CODE
use mask computed before eliminating invalid mask;0.8691111;5.2654605;-2.837231;-0.18859825;-0.6383079;1.7097255;OUTD
count number of true values in each row;3.5153677;3.4424036;2.0160935;-2.9186487;1.0144558;-5.9758244;IRRE
missing values 0 not allowed with sparse data as it would;4.000638;3.626958;-5.2435284;-2.9994555;-2.5819266;-1.0181355;IRRE
force densification;-1.5277815;2.565762;1.1175005;0.86278015;-1.3624891;2.7719312;CODE
need not validate x again as it would have already been validated;-4.3599043;6.8218994;-2.5542681;1.6004788;0.37760735;-1.387419;CODE
in the imputer calling missingindicator;-5.769647;0.39920065;-1.0974808;0.68759686;0.684466;0.6577647;IRRE
only create n features in in the precomputed case;1.8015549;2.345873;-0.8143218;-0.8396836;5.2897577;0.12697582;CODE
need not validate x again as it would have already been validated;-4.3599043;6.8218994;-2.5542681;1.6004788;0.37760735;-1.387419;CODE
in the imputer calling missingindicator;-5.769647;0.39920065;-1.0974808;0.68759686;0.684466;0.6577647;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
if hasattr x1 mask pandas dataframes;1.5215213;2.4221494;-2.4389317;-3.2508926;-2.523103;-0.6872178;-
else ndarrays;-0.15717669;-1.1280732;0.8275803;-2.8428154;-1.3917925;-1.2344848;CODE
fill value no validation any object is valid;-1.9798597;6.260286;-0.7779387;1.4991769;0.4274744;-3.0250115;IRRE
if no missing values don t predict;5.148144;4.1062994;-1.0442575;2.9104128;-0.93367;-3.4516768;IRRE
get posterior samples if there is at least one missing value;1.997514;5.2930336;-0.5977141;0.6419814;2.36601;-0.42380053;IRRE
two types of problems 1 non positive sigmas;2.046179;2.9090085;-0.87513006;0.21815985;1.6677103;-1.0800028;-
2 mus outside legal range of min value and max value;0.9956482;5.114214;-0.7533282;-2.4396691;2.4633777;0.10120446;IRRE
results in inf sample;4.0325933;2.2089288;-2.3936837;0.96844476;-1.2003359;-2.643509;IRRE
the rest can be sampled without statistical issues;7.047808;1.4852494;1.6554207;2.6535726;2.593558;-1.8563207;-
update the feature;-4.1165037;-3.392585;2.096158;4.0465045;0.08666208;1.2362229;TASK
if a feature in the neighborhood has only a single value;3.0860264;3.8207085;0.31582913;0.62998146;2.574992;-1.0869254;TASK
e g categorical feature the std dev will be null and;-1.5386441;-1.0634329;-4.1463857;0.9640406;1.3116946;-0.6704106;TASK
np corrcoef will raise a warning due to a division by zero;-0.7176587;3.197192;-3.7850716;-1.0332893;-3.152912;-2.0266402;CODE
np corrcoef is not defined for features with zero std;-1.1743311;0.03255252;-7.366424;-3.6440437;-2.236881;1.5542625;CODE
ensures exploration i e at least some probability of sampling;2.0024464;-0.4655967;2.2979782;5.0755124;1.6188097;3.4423437;-
features are not their own neighbors;0.6220446;-3.9631255;-0.03249205;1.4499828;0.488164;2.3540788;TASK
needs to sum to 1 for np random choice sampling;2.2057514;0.8502076;-0.8196185;-1.3641034;0.5774093;-0.9817456;IRRE
drop empty features;-1.0501871;2.0599103;-0.5947401;1.6242148;1.3570867;0.98529845;TASK
mark empty features as not missing and keep the original;-1.1480103;3.480725;-0.8616378;1.0978174;2.6274154;0.99402076;TASK
imputation;-0.71801853;2.7241366;1.95022;2.4147592;2.0602167;-3.9298785;-
make sure to remove the empty feature elements from the bounds;-0.6954191;2.1017997;-2.301532;-0.9110399;-2.427315;1.8083643;TASK
iterativeimputer estimator is not validated yet;2.350174;1.7284415;-3.9575577;4.2434;-4.7842045;2.8086178;TASK
edge case a single feature we return the initial imputation;1.307792;2.3501754;0.26498216;0.52209586;2.5267377;0.6689651;IRRE
order in which to impute;-2.540107;3.020992;2.7590716;1.0776355;2.529518;-0.50295216;-
note this is probably too slow for large feature data d 100000;4.396096;-4.396314;-1.3805677;-0.024494555;1.3539582;1.420317;TASK
and a better way would be good;-1.5037296;-1.3146119;4.3687325;3.060377;1.0782454;3.1565459;-
see https goo gl kycnwj and subsequent comments;-4.6916223;-1.9137726;2.2842987;0.6971938;-1.6030346;0.55355686;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
get donors;-1.5934443;-0.19377412;1.8593541;0.28764123;0.6930536;-2.0190525;CODE
get weight matrix from distance matrix;4.789871;-0.13696323;0.042944036;-4.7201705;-2.665004;3.2071493;CODE
fill nans with zeros;2.0648348;3.4470274;0.072248444;-6.349617;-3.0316904;-3.443575;-
retrieve donor values and calculate knn average;4.093188;1.6982738;-0.5773519;-3.386734;-1.047939;-2.0650866;IRRE
check data integrity and calling arguments;-1.6741914;5.050701;-3.7098627;2.0892816;1.2125998;-2.954749;IRRE
removes columns where the training data is all nan;4.4470987;1.3083162;-2.0052865;-1.4570402;-1.3473815;-0.15295604;-
no missing values in x;-0.2356341;5.2545733;-0.65761405;-4.2256393;-2.2662818;-4.130753;IRRE
even if there are no missing values in x we still concatenate xc;0.017571894;5.0737853;-0.9120293;-3.3598304;0.36072806;-2.0743742;IRRE
with the missing value indicator matrix x indicator;2.8826778;2.7779028;-0.21783407;-5.208835;-0.35231343;1.3760624;IRRE
this is to ensure that the output maintains consistency in terms;-0.029487105;2.0407188;-0.6886252;1.5592173;0.69997925;0.7570865;CODE
of columns regardless of whether missing values exist in x or not;3.176213;5.3664985;-0.45577753;-3.1880767;0.7530606;-2.5012832;IRRE
maps from indices from x to indices in dist matrix;3.9750516;0.6176059;-0.20379883;-8.277894;0.34402254;3.179549;CODE
find and impute missing by column;2.0874991;4.4205337;-0.33581287;-2.5424092;-1.3328519;-3.5810106;-
column was all missing during training;0.06521083;0.21570842;-1.5192275;-0.22044091;-1.4925004;-1.6553494;-
column has no missing values;0.6421894;4.930919;-1.5819347;-3.6016207;-1.9986224;-3.9687214;IRRE
receivers idx are indices in x;-0.12126702;2.4454205;-3.3444889;-3.6004424;3.599487;0.7153471;-
distances for samples that needed imputation for column;5.4026933;2.4905555;0.2000654;-1.6877505;-0.68143237;-0.5536384;CODE
receivers with all nan distances impute with mean;5.01734;2.599608;-1.308884;-1.2687763;-1.505267;2.8658156;-
all receivers imputed with mean;1.4888952;3.4700768;-1.9875351;3.3105612;-0.81583065;1.0547962;-
receivers with at least one defined distance;2.2952082;2.2811735;1.0300752;-0.75538176;3.2009037;1.9626251;CODE
process in fixed memory chunks;-0.18301752;-0.0037028394;1.4385438;0.8005451;1.053518;1.4586372;-
process chunk modifies x in place no return value;-1.8204579;4.842089;-2.2262783;-0.01447877;-1.9256065;-0.46155897;IRRE
from sklearn experimental import enable iterative imputer noqa f401;2.1473963;-4.167484;-6.167386;0.1567887;-4.6431565;-0.38231748;CODE
convergencewarning will be raised by the iterativeimputer;4.1192575;-2.113455;-1.8165604;4.797178;-2.0860784;4.094682;CODE
non regression test for issue 13968 missing value in test set should;0.60863274;4.155923;-6.536071;2.907699;-2.9439414;-5.040769;IRRE
not throw an error and return a finite dataset;5.603176;4.2782636;-1.8318146;2.3633242;0.34928682;-1.8097985;IRRE
convergencewarning will be raised by the iterativeimputer;4.1192575;-2.113455;-1.8165604;4.797178;-2.0860784;4.094682;CODE
convergencewarning will be raised by the iterativeimputer;4.1192575;-2.113455;-1.8165604;4.797178;-2.0860784;4.094682;CODE
imputer clone imputer avoid side effects from shared instances;-2.6786983;0.015304844;-1.5773953;3.4860225;0.027570698;1.7203785;CODE
convergencewarning will be raised by the iterativeimputer;4.1192575;-2.113455;-1.8165604;4.797178;-2.0860784;4.094682;CODE
test pandas integerarray with pd na;2.5603259;3.1041157;-3.7292116;-3.8648133;-3.9545798;-3.2906983;IRRE
fit on numpy array;5.62358;0.67967;-0.8749546;-6.8395133;-6.39972;1.2263628;-
creates dataframe with integerarrays with pd na;2.9170067;0.36669078;-2.3734324;-5.40997;-2.7405002;0.046858087;IRRE
fit on pandas dataframe with integerarrays;4.4646378;0.46531084;-2.4118147;-4.6337028;-4.284176;1.1769519;CODE
test data where missing value test variable can be set to np nan or 1;2.8302119;5.366365;-3.88773;-0.8855014;-2.7004292;-4.2941165;IRRE
make iterativeimputer available;-1.0414873;-1.4176295;-0.14269418;2.9075837;-2.396465;2.3469725;-
from sklearn experimental import enable iterative imputer noqa f401;2.1473963;-4.167484;-6.167386;0.1567887;-4.6431565;-0.38231748;CODE
normal matrix;1.470216;0.7166405;2.3671334;-6.516563;-0.82165986;0.21096863;-
sparse matrix;5.675845;-1.4944562;0.692235;-5.229802;-0.19213772;2.3508759;IRRE
verify the shapes of the imputed matrix for different strategies;3.5369413;2.2684014;0.6681263;-1.0049473;-0.68566066;1.7462387;CODE
check simpleimputer returning feature name attribute correctly;-1.2277005;2.1290767;-3.443598;2.7199264;-1.3744372;-0.9000088;TASK
ensure that skipped feature warning includes feature name;-3.6575043;1.4181807;-4.9588118;5.36869;0.27093747;0.8970343;TASK
check that error are raised when missing values 0 and input is sparse;4.6029787;5.833754;-4.950808;0.36041778;-2.8016965;-2.8267703;IRRE
np median raises a typeerror for numpy 1 10 1;2.3028877;0.16907544;-5.0563993;-3.8236504;-7.457344;-0.19388328;CODE
np mean raises a runtimewarning for numpy 1 10 1;4.038962;-0.45655343;-4.583521;-2.740208;-7.482497;0.72634846;CODE
test imputation using the mean and median strategies when;2.5715983;3.5605564;0.5857812;5.1963544;-0.32241598;-2.6139307;IRRE
missing values 0;-0.27904147;5.988399;-1.8671317;-3.956099;-2.76396;-5.6578684;IRRE
create a matrix x with columns;3.104334;-0.0254307;1.9945627;-8.305287;-0.23369464;1.1919596;IRRE
with only zeros;-0.56396043;2.5362167;2.8152843;-4.728379;-1.0861363;-4.2921033;-
with only missing values;2.8679817;5.4090543;1.4217114;-2.0584824;1.83178;-4.3318834;IRRE
with zeros missing values and values;2.5747945;5.6990037;-0.18922544;-5.1335316;-0.7835578;-4.9951463;IRRE
and a matrix x true containing all true values;2.627456;3.4761899;0.05769089;-2.6043925;1.3319397;-1.3186334;IRRE
create the columns;1.8751245;-0.7740729;5.272229;-6.8948655;2.6728847;-1.8254926;IRRE
xxx unreached code as of v0 22;-7.1776857;2.1495879;-3.8963044;-0.051122006;-1.990353;-0.8256172;-
shuffle them the same way;1.0387683;0.8019204;3.9535189;-2.02712;2.8174698;0.87350214;CODE
mean doesn t support columns containing nans median does;2.5125878;2.0129855;-2.4488127;-3.3784606;-4.7032375;0.15402612;CODE
test median imputation with sparse boundary cases;4.1595173;2.8225548;-0.930505;2.2126632;-0.36561123;-0.81532156;IRRE
0 np nan np nan odd implicit zero;0.41838208;2.0627134;-4.765047;-7.1655374;-4.467525;-1.582868;-
5 np nan np nan odd explicit nonzero;0.17488898;2.0124094;-3.0233853;-6.2717953;-1.1813648;-3.249094;-
0 0 np nan even average two zeros;2.7812555;3.0453732;-2.6775987;-6.514174;-4.260792;-2.9116518;-
5 0 np nan even avg zero and neg;1.6286829;2.0168881;-2.2520864;-3.8316376;-2.6343143;-4.1817346;-
0 5 np nan even avg zero and pos;2.0355098;1.4332076;-2.6877425;-3.7286162;-2.6530962;-3.3956316;-
4 5 np nan even avg nonzeros;1.2389565;0.8367582;-2.2664092;-3.021454;-1.5951543;-3.1953523;-
4 5 np nan even avg negatives;1.3647468;1.1092193;-1.592472;-2.5791032;-2.0146124;-3.3926587;-
1 2 np nan even crossing neg and pos;-0.7932929;1.7713633;-0.11451069;-3.262296;-0.5344617;-3.5602188;-
test imputation on non numeric data using most frequent and constant;4.3278947;4.986711;-0.5914927;0.784575;-0.9619971;-3.1413462;IRRE
strategy;-0.92067444;-0.8776743;7.6960506;4.167958;0.8335491;-2.2432013;-
test imputation using the most frequent strategy;3.3810074;3.7143714;0.6745309;6.655383;1.6611476;-3.8762908;IRRE
scipy stats mode used in simpleimputer doesn t return the first most;3.1327984;-0.6912879;-3.122032;-1.1814035;-5.8447104;-2.4708977;CODE
frequent as promised in the doc but the lowest most frequent when this;-1.2515386;0.68836313;0.59719056;4.645148;-0.30948064;0.30755502;CODE
test will fail after an update of scipy simpleimputer will need to be;-0.6477562;0.04800527;-5.7908897;1.8891462;-7.2062244;-4.5587497;TASK
updated to be consistent with the new correct behaviour;-4.7888136;1.9536344;-0.29343796;4.9954824;-1.5716752;2.2667336;CODE
test imputation using the most frequent strategy;3.3810074;3.7143714;0.6745309;6.655383;1.6611476;-3.8762908;IRRE
test imputation using the most frequent strategy on pandas df;3.0129683;1.6048594;-1.1094618;3.100246;-2.9291818;-2.111331;IRRE
verify that exceptions are raised on invalid fill value type;-0.70638883;7.4421277;-4.83451;2.2465444;0.9837481;-2.7635655;CODE
test imputation using the constant strategy on integers;2.5964723;6.595241;-1.4825989;3.5363545;0.31142473;-5.892489;CODE
test imputation using the constant strategy on floats;4.0760098;6.2537227;-1.6654919;2.4290051;-1.6257157;-3.0782595;CODE
test imputation using the constant strategy on objects;3.013799;4.7708244;-1.1805204;6.7187276;1.8193166;-3.7175865;IRRE
test imputation using the constant strategy on pandas df;2.253769;3.125056;-2.163839;2.854045;-3.8452299;-2.442481;IRRE
check we exit early when there is a single feature;-1.4933653;2.3434927;1.5476452;6.494516;0.4240837;0.19530547;TASK
test imputation within a pipeline gridsearch;2.3665445;2.8870995;-2.724209;4.3823314;0.10023285;-0.9259759;CODE
test imputation with copy;0.37258682;5.1359735;-1.29049;3.7233753;0.09385104;-5.1981015;IRRE
copy true dense copy;-0.0076070447;0.61293614;-0.8753394;-0.61764604;-0.5259189;0.32066363;-
copy true sparse csr copy;1.2956123;0.18026735;-3.417586;-0.91933584;-0.44742242;2.702496;IRRE
copy false dense no copy;-1.1199143;2.7812803;-2.5206974;0.40926617;-1.7629156;-0.35335082;-
copy false sparse csc no copy;0.26106703;1.5181556;-4.184205;0.6186949;-1.603568;1.9720895;IRRE
copy false sparse csr copy;1.0751462;1.4600015;-3.9021273;-0.33247107;-1.0163562;2.1152606;IRRE
note if x is sparse and if missing values 0 then a dense copy of x is;3.787031;2.563406;-3.9947526;-2.784431;-1.1080317;0.6572597;IRRE
made even if copy false;-2.496705;3.4606876;-0.9096034;2.963567;-0.8562327;-3.107424;-
with max iter 0 only initial imputation is performed;-0.7862899;6.2999187;-2.137093;0.9896351;-0.4534242;-0.5751386;IRRE
repeat but force n iter to 0;-1.8930972;5.5150876;2.2760174;-1.4531004;-1.5090814;-2.042993;META
transformed should not be equal to initial imputation;-1.3013306;5.6965947;-1.7773368;0.18642908;-1.7662904;2.2509286;IRRE
now they should be equal as only initial imputation is done;-0.85400975;4.61592;-0.8722716;2.5641844;2.9166176;-0.64225626;IRRE
x 0 1 this column should not be discarded by iterativeimputer;2.983375;4.1966968;-2.4007604;-3.1091652;-3.495652;0.11104192;CODE
check that types are correct for estimators;2.214062;3.019324;-1.8669444;2.307408;-1.5336775;-0.32968497;CODE
check that each estimator is unique;4.5517616;4.1492453;-0.21497542;2.5516818;1.2354941;1.6335499;-
test that the values that are imputed using sample posterior true;1.2937678;6.160545;-1.0155983;3.0630236;1.2232952;-1.9573287;IRRE
with boundaries min value and max value are not none are drawn;-0.081444316;5.16474;1.6273574;-3.9918199;-2.4975731;-0.43411908;IRRE
from a distribution that looks gaussian via the kolmogorov smirnov test;2.133722;-0.3019447;-1.443283;0.7664884;-2.0806649;-0.19415756;IRRE
note that starting from the wrong random seed will make this test fail;1.7038951;3.8541071;-2.9492574;4.638778;-1.1251583;-5.931232;IRRE
because random sampling doesn t occur at all when the imputation;0.524288;2.9238355;-1.4198703;2.9159288;-0.55508536;-0.13163094;IRRE
is outside of the min value max value range;0.7895974;5.0760765;0.30687073;-2.5706668;-0.42352012;-1.5506498;IRRE
generate multiple imputations for the single missing value;2.8608572;3.7721598;-0.07966811;-0.6365498;2.0745003;-2.7502282;IRRE
we want to fail to reject null hypothesis;0.06839901;3.8541095;-1.3356006;5.6549606;-1.1758575;-2.2834373;-
null hypothesis distributions are the same;-0.43144077;2.7354476;-0.7757856;1.3160015;-1.9210811;0.22772329;META
x train 0 1 definitely no missing values in 0th column;2.099035;3.3931673;-3.3378634;-3.8476582;-1.8237112;-2.5430746;IRRE
x test 0 0 0 definitely missing value in 0th column;0.36098722;7.1950865;-4.493045;-4.105671;-3.429792;-5.6463914;IRRE
if there were no missing values at time of fit then imputer will;3.2510135;4.318504;-2.2928684;1.5322915;-0.57975966;-0.4757402;IRRE
only use the initial imputer for that feature at transform;-1.8861032;1.5016688;-1.1804247;0.27824336;-0.75613016;4.08661;IRRE
when sample posterior true two transforms shouldn t be equal;0.690174;4.6748734;-1.7039341;0.50861204;0.3192049;3.2086115;CODE
sufficient to assert that the means are not the same;1.8137791;4.8315578;1.1642207;3.1303887;-0.7155142;0.52467585;CODE
when sample posterior false and n nearest features none;2.7234404;3.113088;-3.0993006;0.17871308;1.0561031;-0.56785446;TASK
and imputation order is not random;0.116866216;2.533382;-0.6261262;2.470909;2.3098013;-1.6653256;IRRE
the two transforms should be identical even if rng are different;1.1556964;3.2578948;-2.0093315;-0.71244514;-0.9404809;2.4668422;CODE
should exclude the first column entirely;1.4223621;4.843718;1.2977585;-1.3459169;0.85384923;-0.0654013;-
fit and fit transform should both be identical;2.5627377;1.7871041;0.15646186;-2.2278411;-1.2137337;3.3178282;CODE
split up data in half;5.229373;1.6894186;4.223287;-4.752745;2.2813385;-1.0564059;-
a quarter is randomly missing;-0.9418931;4.04192;2.891755;-0.5323078;-3.0201826;-4.2838707;IRRE
split up data;5.6344695;0.33010805;5.001768;-3.9423995;3.9588492;-1.2681497;-
check that we catch a runtimewarning due to a division by zero when a;0.92213106;4.3826337;-2.247273;2.7621562;-1.1451801;-4.8678184;CODE
feature is constant in the dataset;3.0560787;-0.7914867;-1.3728002;0.26101398;-0.5009573;1.3410547;CODE
simulate that a feature only contain one category during fit;3.5253513;1.2787685;-0.014785281;3.4534333;2.86605;0.9227787;TASK
add some missing values;1.867204;4.614441;1.6399895;-2.9664867;1.112827;-3.744163;IRRE
check that passing scalar or array like;1.6293029;5.4521976;-0.7486257;-0.14901054;0.7247267;-4.2322474;-
for min value and max value in iterativeimputer works;3.512075;2.9173045;-1.0014592;-0.7172908;-2.1488862;-0.20917384;IRRE
check that passing scalar or array like;1.6293029;5.4521976;-0.7486257;-0.14901054;0.7247267;-4.2322474;-
for min value and max value in iterativeimputer works;3.512075;2.9173045;-1.0014592;-0.7172908;-2.1488862;-0.20917384;IRRE
test that none inf and scalar vector give the same imputation;2.7111614;5.252459;-4.6056414;0.4846183;-2.1289482;-2.165641;IRRE
check the imputing strategy when missing data are present in the;2.4313989;5.4276557;-0.48139924;3.7992387;1.007547;-1.7387855;CODE
testing set only;1.2542274;5.369611;0.5515517;5.6353106;1.296251;-4.721775;IRRE
taken from https github com scikit learn scikit learn issues 14383;-3.2480052;-9.394213;-8.057127;-0.29941815;-5.0271864;-4.383985;CODE
impute with the initial strategy mean;-0.74227667;3.0949073;3.368263;3.3249068;-1.0254629;0.83165;IRRE
convert the input to the right array format and right dtype;2.4887226;0.36610729;-0.95188254;-6.0817666;-2.1859496;-3.5990555;CODE
test for sparse input and missing value 0;5.1064396;5.011167;-3.47534;0.31301135;-2.1167562;-4.352169;IRRE
convert the input to the right array format;1.7768325;1.5697672;3.0645216;-5.8317437;-1.362626;-3.827176;CODE
check the format of the output with different sparse parameter;4.98371;3.3847892;-4.1647034;-1.999632;-1.2543433;-0.4154418;IRRE
regression test for issue 11390 comparison between incoherent dtype;2.0264056;2.4927256;-6.4169197;1.8694252;-3.5790756;-4.045637;IRRE
for x and missing values was not raising a proper error;1.2369995;5.318408;-2.7971203;-3.2158594;-3.1348815;-4.749523;IRRE
check that all features are dropped if there are no missing values when;0.5578201;4.548054;-2.3324773;3.333054;-0.17286322;-2.457035;IRRE
features missing only 13491;-2.966456;-2.1540332;-3.7666712;-0.23933034;0.07275478;-1.4791836;TASK
check that non missing values don t become explicit zeros in the mask;3.2282097;6.239161;-4.410598;-2.9227338;-1.880833;-1.1444175;IRRE
generated by missing indicator when x is sparse 13491;1.9026405;2.5925844;-3.4047835;-2.9372296;-0.772319;-0.059009954;IRRE
regression test for 15393;0.7749722;3.0860298;-2.030737;2.8199613;-4.0060253;-6.9768715;IRRE
test inverse transform feature for np nan;3.6047924;2.7200537;-4.613104;-2.1852963;-4.2361593;-1.5646034;IRRE
x 2 trans imputer transform x 2 test on new data;1.4887925;3.0322142;-3.1391337;-1.3477073;-1.8416083;-2.2481916;CODE
array of object dtype;1.5079095;-0.1711609;-0.8339161;-3.4526148;0.15892772;-1.8089054;IRRE
array of numeric dtype;3.3983452;0.79736453;-2.0850155;-6.5654893;-1.2130785;-3.331242;-
impute pandas array of string types;1.3198266;0.12068883;-2.795697;-3.2716808;-2.2708845;-2.3470948;CODE
impute pandas array of string types without any missing values;1.6046096;1.5978433;-3.5328567;-2.4709601;-2.7164445;-2.4217114;IRRE
impute pandas array of integer types;1.9652032;0.8797444;-3.146359;-5.2548895;-2.821006;-1.9312334;CODE
use np nan also works;0.92457885;1.4414726;-2.581682;-4.4848166;-2.925738;-2.2079842;-
impute pandas array of integer types with median strategy;3.9111984;0.98027116;-1.3499666;-3.5600243;-2.5499456;-0.73209083;CODE
impute pandas array of integer types with mean strategy;4.243733;1.3683347;-1.2655602;-3.2978306;-2.9048681;-0.7021648;CODE
impute pandas array of float types;2.8175957;0.26624355;-3.2333708;-5.6637444;-4.1515512;-1.2005173;CODE
impute pandas array of float types with median strategy;4.9240236;0.4568855;-1.4960172;-4.085658;-3.7642636;0.11145367;CODE
non regression test for 19572;-0.1551989;3.6996183;-3.8328116;3.8358314;-2.6002476;-5.2956543;IRRE
sparse matrix;5.675845;-1.4944562;0.692235;-5.229802;-0.19213772;2.3508759;IRRE
cannot cast fill value at fit;1.2829292;4.939365;-2.6176715;-2.0107737;-2.2167914;1.4625479;IRRE
cannot cast fill value at transform;-1.3979475;4.130862;-1.1493312;-3.5644984;-2.4204266;1.1556648;IRRE
check that no error is raised when having the same kind of dtype;-0.30272058;4.2561603;-7.6530294;2.0707636;-0.9611214;-3.324988;CODE
np array 1 2 3 4 5 6 7 8 without empty feature;1.7026864;2.7252471;-1.6370057;-5.715669;-0.4131315;-2.068131;TASK
np array np nan 2 3 4 np nan 6 7 8 empty feature at column 0;1.7375495;2.3359997;-4.2526217;-7.3779283;-2.9391236;-2.866729;TASK
np array 1 2 3 np nan 5 6 7 np nan empty feature at column 3;2.1534288;1.8882453;-3.154373;-7.3969407;-1.7443509;-2.856976;TASK
verify the shapes of the imputed matrix for different weights and;4.8908167;2.811468;-1.2296759;-3.5832899;-1.5261627;1.6338438;CODE
number of neighbors;1.6401688;-0.33371785;3.5057173;-2.530943;0.36789325;-1.7759807;-
test imputation with default values and invalid input;1.5391152;7.903582;-3.1175044;3.4434085;-0.6589919;-5.804095;IRRE
test with inf present;-0.41307467;6.251312;-1.0039642;4.13544;-0.073941074;-5.75925;IRRE
test with inf present in matrix passed in transform;2.476111;5.879235;-2.68726;-0.84513617;-2.5449827;-1.0096421;CODE
test with missing values 0 when nan present;2.2578952;7.624465;-3.0770113;-0.37771717;-3.4140937;-6.710963;IRRE
test with an imputable matrix and compare with different missing values;4.5073233;6.0432997;-2.1652536;-0.8591413;-0.96515936;-4.4354434;IRRE
test with an imputable matrix;4.2966304;4.856738;-2.4446416;-0.738267;-0.9726674;-4.9136586;IRRE
test when there is not enough neighbors;2.8735044;4.2206683;1.3387176;3.231987;-0.9446147;-5.4524446;TASK
not enough neighbors use column mean from training;6.6227865;0.4527004;-1.3129934;-0.62228185;-1.2924111;0.11061467;TASK
test when data in fit and transform are different;5.4589744;4.9454756;-1.0701983;1.0140387;-1.3722372;-1.4729944;CODE
test with uniform weight or unweighted;2.1943932;4.2647614;-0.21200311;2.3780653;0.19715673;-1.8272823;CODE
test with callable weight;2.7251954;4.9148574;0.031511478;4.1601424;-0.046504226;-2.5598245;IRRE
test with callable uniform weight;2.9215503;5.3610187;-1.0331129;2.593601;0.4412312;-1.71053;IRRE
test with distance weight;4.572051;4.0677075;1.9741405;1.4928178;-1.0066419;-3.350864;IRRE
manual calculation;1.4040349;0.7114029;3.5008094;-3.585877;-0.47502705;-3.3688865;-
nearestneighbor calculation;3.5361736;1.3959029;1.3656228;-4.476146;-1.3514551;-2.0722945;-
test with weights distance and n neighbors 2;6.260124;3.2431872;0.39306045;-0.7777952;-0.3354353;-3.6780229;IRRE
neighbors are rows 1 2 the nan euclidean distances are;3.9050274;0.6232257;0.7621967;-6.8537393;-2.4602497;-1.1120896;CODE
test with varying missingness patterns;3.679607;6.365892;-2.085069;3.854191;1.3280756;-4.5869336;IRRE
get weights of donor neighbors;5.1311255;0.5766623;1.1637003;-2.2754874;0.97035146;0.73248756;CODE
collect donor values;2.5004823;1.5190072;1.5653559;-1.5267423;3.2410557;-2.3538542;IRRE
final imputed values;1.4647255;5.926208;-0.08580289;-0.0012597932;0.4462822;-2.5936875;IRRE
calculate weights;4.0797353;1.0469044;2.9688683;-2.3234458;-0.534674;-0.8882854;-
calculate weighted averages;4.4493613;2.1019847;3.548029;-1.500632;-0.67806286;-0.48332238;-
define callable metric that returns the l1 norm;1.4190159;0.4829299;-0.17196739;-0.9291807;0.51788163;4.313002;IRRE
note that we use working memory 0 to ensure that chunking is tested even;-0.036807325;2.149308;-3.4102237;4.1889367;-0.50231296;-1.2296506;TASK
for a small dataset however it should raise a userwarning that we ignore;4.6871862;-2.6373928;-0.14605042;4.789361;0.12303072;1.4348774;CODE
samples with needed feature has nan distance;6.7520857;1.5912178;-2.2857356;-2.5769155;-2.239722;-0.6872336;TASK
samples with nan distance should be excluded from the mean computation;5.310426;2.9837513;-2.7836096;-0.41354007;-3.4081657;1.5991591;CODE
grid resolution 2 doctest skip;-0.7642294;3.7678447;-1.570083;1.6150299;-2.647302;1.143957;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
get the column names for a pandas dataframe;0.031112162;-2.5066686;-0.24128912;-2.89147;-3.6318815;-1.9032569;CODE
define a list of numbered indices for a numpy array;2.9182622;0.12361378;-1.2325232;-7.2956376;-2.7771614;-0.88796395;CODE
convert numpy array or pandas index to a list;3.427686;-1.1983136;-0.48486674;-5.642677;-5.1208835;-0.9054908;-
work on a copy of x to ensure thread safety in case of threading based;-2.0646312;0.29261392;-1.1139535;1.249488;0.6019916;1.7108608;CODE
parallelism furthermore making a copy is also useful when the joblib;-1.9691365;-4.477035;0.11523508;3.2212245;-0.14339359;1.1883215;-
backend is loky default or the old multiprocessing in those cases;-5.6079264;-2.3367188;-0.83887446;1.8511215;-1.0980229;3.2989092;CODE
if x is large it will be automatically be backed by a readonly memory map;0.22969873;0.6406794;-0.04770813;-0.50773776;0.37338743;3.0121932;CODE
memmap x copy on the other hand is always guaranteed to return a;-3.3664768;2.604874;-1.565561;3.0674052;0.48164752;2.8302732;IRRE
writable data structure whose columns can be shuffled inplace;2.4387047;0.21477394;1.1417876;-3.8151252;3.461071;1.4659662;CODE
precompute random seed from the random state to be used;1.9662287;-1.8703814;0.3120795;1.031711;1.0902064;0.29880482;IRRE
to get a fresh independent randomstate instance for each;1.7798942;0.7552249;0.893884;2.6937175;3.5068629;1.8615803;CODE
parallel call to calculate permutation scores irrespective of;3.5837786;0.96386045;0.655099;-0.38797462;2.476864;-2.6876504;IRRE
the fact that variables are shared or not depending on the active;-0.56470776;1.3959324;2.1051767;2.0036414;3.1033862;0.7427291;CODE
joblib backend sequential thread based or process based;-2.0170393;-2.077769;0.1290273;2.6387691;-0.80649966;0.9009218;CODE
unpack the permuted scores;3.7706382;-0.14630412;0.052985065;-2.2918534;3.478134;-2.805101;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
else self response ndim 3;-2.0519118;2.3921235;-0.05335433;-2.302761;0.1892797;-2.0135083;CODE
special case for the tab10 and tab20 colormaps that encode a;-2.4237077;-1.0505526;1.0690888;-3.5127182;3.4843032;1.2978345;CODE
discrete set of colors that are easily distinguishable;3.245442;-0.60013294;2.9043248;-2.4992332;5.042579;-1.4394823;IRRE
contrary to other colormaps that are continuous;-0.87111926;-0.27433884;2.174335;0.23205751;-0.57187426;4.1610703;-
for linearsegmentedcolormap;1.3384736;-2.3957465;1.221126;-5.8490186;-0.05884632;4.201118;CODE
plot only argmax map for contour;1.8380494;1.6436985;3.0636315;-3.7722306;-4.5030065;5.4604335;CODE
re raise a more informative error message since pos label is unknown;-2.996738;2.8794143;-4.1477757;1.3693225;0.5475493;-1.323239;CODE
to our user when interacting with;-5.333134;-4.5688233;6.411763;2.617331;0.31942537;-0.6686445;CODE
decisionboundarydisplay from estimator;3.1348283;-1.1514088;0.18767291;3.7054262;1.1505412;4.302554;CODE
convert classes predictions into integers;4.7671;-1.0086441;-0.60106677;-0.1080088;2.7842543;-4.4819174;CODE
for the multiclass case get response values returns the response;-0.46919203;2.1657193;-0.9813897;1.8297656;2.290767;-0.8627933;CODE
as is thus we have a column per class and we need to select the;2.318753;-0.19054481;0.62474364;-1.6425359;6.840265;-1.7272116;CODE
column corresponding to the positive class;2.445505;0.8018467;-0.35056034;-4.728347;3.426834;-1.8677456;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
set target idx for multi class estimators;2.2508266;0.55912125;-3.2404153;1.750071;3.2274182;5.0998044;IRRE
regression and binary classification;4.5073247;-3.6025221;0.768984;0.47424662;3.7226675;-2.4004796;IRRE
use check array only on lists and other non array likes sparse do not;3.5102606;5.0957313;-1.5787799;0.715903;-0.16926739;-2.5429296;CODE
convert dataframe into a numpy array;3.0222218;-1.3023822;-0.7479488;-6.2739115;-7.402001;-0.359519;CODE
expand kind to always be a list of str;0.19107042;1.2146038;-1.4865142;-0.32264382;4.456256;-1.5189835;-
convert features into a seq of int tuples;2.9075348;0.4849808;-0.67579955;-4.8508277;2.2985437;-2.0062466;CODE
store the information if 2 way pd was requested with ice to later;-1.1463523;2.2773721;2.245418;0.49565542;2.6629531;2.0478425;CODE
raise a valueerror with an exhaustive list of problematic;2.2011516;4.187239;-4.243149;3.5201955;-1.0838672;-4.534489;IRRE
settings;-4.2340403;-1.8681971;6.994803;0.2633829;-1.2244998;1.7592822;IRRE
raise an error and be specific regarding the parameter values;-0.08515638;7.104612;-1.951423;1.3751985;-0.8097524;-2.434142;IRRE
when 1 and 2 way pd were requested;-3.6705534;0.03664517;-0.62838984;-0.2608577;1.4811194;0.7403333;CODE
we need to create a boolean indicator of which features are;0.95308435;-1.0141342;2.1246603;0.06405338;5.152314;-1.3422929;TASK
categorical from the categorical features list;1.515799;-4.3745847;1.355362;-2.2028656;2.6419647;-2.1920536;TASK
categorical features provided as a list of boolean;1.1570414;-1.0571116;0.029611977;-0.5909669;4.6315613;-3.2071319;TASK
categorical features provided as a list of indices or feature names;1.6666613;-4.6793036;-0.34860432;-2.4348176;4.389665;-1.1834279;TASK
collect the indices of the categorical features targeted by the partial;3.2980573;-2.829941;0.6897519;-2.7283316;3.7072794;0.728214;TASK
dependence computation;3.4040627;0.95330626;1.1892196;-0.29897624;3.6635773;-0.17766939;CODE
early exit if the axes does not have the correct number of axes;0.72285295;4.7150216;2.5677516;-2.185907;-4.0387435;1.7824005;CODE
compute predictions and or averaged predictions;7.27274;-2.2915294;1.8164767;2.3346663;0.018624488;-0.7892947;CODE
for multioutput regression we can only check the validity of target;4.2239513;1.7999997;-2.6780746;4.101943;-0.39721537;-0.12686227;IRRE
now that we have the predictions;1.4282067;-2.7856324;4.1875734;5.0955586;-0.5322301;-0.07967223;-
also note as multiclass multioutput classifiers are not supported;1.0984466;-4.406612;-5.127542;0.4625551;2.200257;0.9849585;IRRE
multiclass and multioutput scenario are mutually exclusive so there is;0.54568934;-0.29662037;-2.120675;2.1191359;4.44958;0.9291355;IRRE
no risk of overwriting target idx here;-3.1248553;1.82291;-1.7280556;1.4451021;2.873026;3.5106087;-
pd result pd results 0 checking the first result is enough;1.0335348;6.0578656;-1.93863;-0.54198104;-2.9353952;-3.45774;IRRE
change plotting method for second plot;-0.6338637;1.9319909;4.4266396;-1.2656691;-5.441159;2.9289598;CODE
change plotting method for second plot;-0.6338637;1.9319909;4.4266396;-1.2656691;-5.441159;2.9289598;CODE
pandas column names are used by default;-1.2745963;-2.2300532;-3.6410596;-3.0399523;-2.8517025;0.4141658;CODE
second call to plot will have the names;-0.04587025;-0.14044513;5.6541257;-2.6993296;-2.7417133;-0.64948165;IRRE
axes with a label will not get overridden;-2.0380607;2.2222564;1.210207;-3.3501163;-3.0296142;3.9957128;-
labels get overridden only if provided to the plot method;-0.42892912;2.8235505;-0.010566152;0.143767;-3.6053808;2.860444;-
labels do not get inferred if provided to from estimator;2.3106623;2.877513;-2.6541617;1.891128;-0.6252735;2.0969558;CODE
in matplotlib v3 5 default value of pcolormesh shading is flat which;-0.3660621;-1.1222881;-3.5037453;-5.661039;-5.276505;2.997067;IRRE
results in the last row and column being dropped thus older versions produce;1.123763;3.637512;-2.0219984;-0.0465772;-2.2256405;-1.170983;IRRE
a 99x99 grid while newer versions produce a 100x100 grid;-0.0900622;-0.23440935;0.46304852;-4.5135283;0.3048366;2.7081723;CODE
get which class has highest response and check it is plotted;3.6137047;2.3988683;3.2889833;-0.022448976;-1.4061464;-2.6510515;CODE
note quadmesh mask is true i e masked when idx is not the highest class;-1.2183547;0.55367607;-2.3367474;-2.4464605;1.3873911;2.2596588;TASK
diabetes dataset subsampled for speed;7.3016596;-1.4462285;0.24167314;0.44171318;1.8567269;0.7063277;IRRE
test partial dependence plot function;2.1014874;3.4972951;1.4143326;0.7908207;-3.22901;-1.1476697;CODE
use columns 0 2 as 1 is not quantitative sex;2.541674;3.4649732;-0.5774414;-6.0253453;0.11954299;-3.1240141;-
deciles lines always show on xaxis only show on yaxis if 2 way pdp;-2.9828212;2.6208944;-1.7577609;-3.981213;-2.98121;1.823409;-
two feature position;0.41145778;-0.45227733;5.2591653;-2.0249052;1.3585382;2.3034692;TASK
check with str features and array feature names and single column;1.4302593;2.5460737;-2.1686404;-1.7911472;2.3330073;-4.847631;TASK
line;-2.925906;-0.43487287;6.9197173;-0.8761948;-0.56607336;-3.5288904;-
contour;-1.2071894;-0.7947585;6.468619;-2.7815275;-1.3658617;0.3442073;-
contour;-1.2071894;-0.7947585;6.468619;-2.7815275;-1.3658617;0.3442073;-
with axes object;0.8155802;-0.2138242;6.101165;-5.9417777;-2.556811;0.8671497;IRRE
the first call to plot partial dependence will create two new axes to;0.5184979;1.3549327;1.688104;-2.6889832;-3.9714181;4.692246;IRRE
place in the space of the passed in axes which results in a total of;0.57231665;3.223974;4.8747826;-5.2811675;-1.7154367;1.009512;IRRE
three axes in the figure;-2.1683104;0.11524417;6.322445;-6.4898944;-2.4895277;0.5356426;CODE
currently the api does not allow for the second call to;-5.6471133;2.342983;1.5180546;5.0318666;0.06757254;2.7782018;CODE
plot partial dependence to use the same axes again because it will;1.7214963;2.2883866;4.20031;-2.772429;-3.4595175;4.0160155;IRRE
create two new axes in the space resulting in five axes to get the;0.90637374;1.2032524;5.3589396;-7.187102;-1.9158373;2.2266216;IRRE
expected behavior one needs to pass the generated axes into the second;0.91894364;4.0653887;0.8360558;-3.0988736;-3.5448935;2.5324135;TASK
call;-4.239492;0.99547666;5.603635;1.9231473;-0.4027324;-2.277719;IRRE
disp1 plot partial dependence;1.7885708;0.88404995;1.4235286;-2.409757;-2.0466979;1.897007;CODE
disp2 plot partial dependence ax disp1 axes;1.8701729;0.4921532;0.9770285;-4.9938836;-3.1098096;3.3299572;CODE
second call to plot does not change the feature names from the first;-0.775666;0.40459904;0.91563255;-0.5332967;-4.3974414;2.3565283;CODE
call;-4.239492;0.99547666;5.603635;1.9231473;-0.4027324;-2.277719;IRRE
test partial dependence plot function on multi class input;4.3317585;2.6149557;-0.5479977;0.8966848;0.20315221;-1.101861;CODE
now with symbol labels;-3.6269686;-2.5033216;4.032975;-1.8575672;4.055317;-1.4802803;-
check that the pd plots are different for another target;1.4103177;2.875594;-0.27665335;-0.3691454;-5.615576;0.9717632;CODE
test partial dependence plot function on multi output input;4.5440307;3.8014514;1.1301073;0.14803022;-2.4821587;-0.7699876;CODE
non regression test to be sure to not override the ylabel if it has been;0.39354384;4.549435;-2.191528;4.304345;-2.3606112;-1.1598716;IRRE
see https github com scikit learn scikit learn issues 15772;-2.561984;-10.022421;-7.2350745;-0.35569462;-5.305846;-4.014224;CODE
single feature;1.1056373;-3.1542222;3.529167;1.8751584;4.029089;0.5814143;TASK
interaction between two features;0.4296739;-2.0091925;4.020237;-0.81483454;1.6776614;0.13635816;TASK
check that the subsampling is properly working;5.304188;5.2108355;-0.6493136;0.67579323;-2.234864;-0.56016827;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn pull 18359;-3.5520418;-8.850977;-3.0364246;-1.0068976;-3.5247972;-4.223614;CODE
check that we anchor to zero x axis when centering;0.11070029;4.3184443;2.5516918;-4.3063846;-5.5258484;2.2452683;-
kind average len kind len features;3.3372939;-3.7644603;-0.3473903;-1.080834;2.2354944;-2.5723596;TASK
alter kind to be a list with a length different from length of features;2.6716204;0.6713163;0.60250705;-1.0607413;3.2658556;-1.3355522;TASK
toy sample;0.09531039;-1.1268612;5.4498596;1.2328323;2.0021768;-3.605327;-
x y n targets as expected in the output of partial dep;2.123346;2.324742;-1.7019105;-2.6879592;-2.0739071;0.8736788;IRRE
iris;-1.8228364;-1.9651062;3.3862739;-0.52846915;-0.48364025;-2.0501149;-
check that partial dependence has consistent output shape for different;3.918586;4.1761684;-2.0549881;0.20625632;0.6477908;1.8087848;CODE
kinds of estimators;3.1205869;-1.348207;2.5766802;3.4119625;0.14746672;2.327744;-
classifiers with binary and multiclass settings;3.4768188;-4.3473167;-3.1051018;-0.5914504;6.127161;0.33572185;IRRE
regressors;1.7630031;-0.38902894;3.4197032;-2.4072652;-0.42792502;-0.29497892;-
multi task regressors;3.3747559;-1.3443012;2.1316297;0.522602;0.35595423;3.2163436;TASK
est set params n estimators 2 speed up computations;4.5622406;-0.13054402;-0.8712383;1.3004918;-0.41796243;3.451879;IRRE
n target corresponds to the number of classes 1 for binary classif or;0.87070155;-0.5073732;-2.2736924;-1.9682958;4.9089313;-2.7218099;CODE
the number of tasks outputs in multi task settings it s equal to 1 for;0.96294916;0.5634358;2.1408253;-0.21586472;0.08388563;-0.22362612;TASK
classical regression data;4.5384417;-2.2278855;2.6967313;-0.064336985;-2.3451936;0.65463;IRRE
else both;-2.9466221;-0.44385284;2.5011187;1.4650171;-1.1758652;-1.3735988;-
tests for grid from x sanity check for output and for shapes;4.34262;3.753351;-0.45958397;-1.3118019;-1.7634674;-2.0658526;CODE
make sure that the grid is a cartesian product of the input it will use;-0.38482416;3.073641;0.40480188;-4.657952;-3.6895874;0.5141033;CODE
the unique values instead of the percentiles;4.912854;1.0443295;1.1741456;-2.9107518;1.107529;1.0737205;IRRE
test shapes of returned objects depending on the number of unique values;6.3713675;4.4862823;2.5815032;0.50980943;3.1853;-3.968841;IRRE
for a feature;0.16462936;-4.9009166;5.157074;2.6248937;2.415737;-1.9252113;TASK
n unique values grid resolution;6.377921;2.2789156;0.6446972;-6.900253;1.0940257;1.1655704;IRRE
n unique values grid resolution will use actual values;5.6960535;3.8380573;-1.1237413;-5.5864873;0.08924011;1.4313387;IRRE
rng shuffle x just to make sure the order is irrelevant;0.47513083;1.2270515;2.0075529;-0.34268075;3.0359523;-0.7455035;-
axes is a list of arrays of different shapes;3.9040394;-0.62343246;4.3075247;-6.6200395;-1.1953297;0.5998633;-
check that uses custom range;0.5550466;7.1983724;-0.30626374;0.8919679;0.7325621;-3.0406225;-
axes is a list of arrays of different shapes;3.9040394;-0.62343246;4.3075247;-6.6200395;-1.1953297;0.5998633;-
check that grid resolution does not impact custom range;1.9991443;6.3003163;-2.1829405;-0.6792048;-3.1641827;3.131029;CODE
axes is a list of arrays of different shapes;3.9040396;-0.6234325;4.307527;-6.6200395;-1.19533;0.59986305;-
2 since n categories 2 we should not use quantiles resampling;3.4717238;-0.24600393;0.7448525;0.34426302;1.4261348;1.1595365;-
check that what is returned by partial dependence brute or;1.2490788;4.9715514;-1.6944731;3.9868493;1.1476703;-3.6994247;CODE
partial dependence recursion is equivalent to manually setting a target;-0.6163721;1.0124187;-1.4782866;3.8742785;2.8971775;3.6417918;IRRE
feature to a given value and computing the average prediction over all;7.1097503;-1.5989931;1.5365222;1.3605636;-0.11529084;0.04126425;TASK
samples;3.4987426;-1.3804811;5.2160425;1.2945335;2.538919;-4.9781947;-
this also checks that the brute and recursion methods give the same;-0.76588464;0.55105704;-0.29579952;3.2524614;1.1215365;-4.452127;CODE
output;-1.1213751;0.32023555;5.7646704;-2.4469266;0.68465555;-6.4614663;IRRE
note that even on the trainset the brute and the recursion methods;1.0100651;-0.72029215;2.0450113;1.5016311;1.6284277;-3.2093163;TASK
aren t always strictly equivalent in particular when the slow method;1.7639441;1.5847623;-1.9781178;5.2548184;-0.2369313;2.5565531;-
generates unrealistic samples that have low mass in the joint;3.4561076;2.0262718;-0.8708959;-0.12279678;-1.9445077;0.29909927;CODE
distribution of the input features and when some of the features are;5.3101764;-2.5896761;1.5773197;0.44658613;3.1041431;1.2008792;TASK
dependent hence the high tolerance on the checks;-0.326297;1.9922247;-0.62260455;5.073931;2.3411334;0.5105342;CODE
the init estimator for gbdt here the average prediction isn t taken;1.6572993;0.8657625;-3.6774404;1.4848746;-3.7791169;1.6247694;IRRE
into account with the recursion method for technical reasons we set;-0.20799679;0.27263072;1.8409884;4.348349;2.352658;-1.649443;CODE
the mean to 0 to that this bug doesn t have any effect;-0.53748906;3.5790024;-3.449609;2.5411215;-4.5940723;0.6822994;CODE
clone is necessary to make the test thread safe;-2.5226722;1.8757675;-1.3003863;5.7276945;-1.6935865;-0.7619959;IRRE
target feature will be set to 5 and then to 123;-2.3323052;0.13603044;1.7947017;1.3392901;1.244492;0.1888688;TASK
pdp pdp 0 shape is 1 2 so make it 2;-0.921009;1.6408181;0.9594913;-7.2734213;-0.28254107;0.32436496;-
allow for greater margin for error with recursion method;1.5105822;4.175072;-0.82267505;2.8594193;0.14160115;-1.6654423;CODE
make sure that the recursion method gives the same results on a;0.05765837;3.972801;-0.7368907;1.1667928;-1.0527787;-3.7850254;IRRE
decisiontreeregressor and a gradientboostingregressor or a;2.4484117;-3.5444005;-2.8297205;2.5218844;3.2346106;4.569874;IRRE
randomforestregressor with 1 tree and equivalent parameters;1.1495482;-0.2501;-1.9337021;3.0225058;3.2128248;1.3490242;IRRE
purely random dataset to avoid correlated features;6.4357634;-3.3093066;-0.29619968;1.5303788;2.4970825;2.623196;IRRE
the init estimator for gbdt here the average prediction isn t taken;1.6572993;0.8657625;-3.6774404;1.4848746;-3.7791169;1.6247694;IRRE
into account with the recursion method for technical reasons we set;-0.20799679;0.27263072;1.8409884;4.348349;2.352658;-1.649443;CODE
the mean to 0 to that this bug doesn t have any effect;-0.53748906;3.5790024;-3.449609;2.5411215;-4.5940723;0.6822994;CODE
set max depth not too high to avoid splits with same gain but different;2.5841408;2.7655516;1.6922002;-1.9556116;2.1446877;3.7091808;IRRE
features;1.4263527;-6.2441335;5.031171;1.4146436;3.9154737;-1.3022918;TASK
the forest will use ensemble base set random states to set the;2.794937;-3.1517024;0.30202517;3.4021614;4.9093046;1.5757285;IRRE
random state of the tree sub estimator we simulate this here to have;2.6325583;0.14701219;-0.11094297;3.2308397;0.76774275;1.4905735;IRRE
equivalent estimators;1.643503;0.8417198;1.2679998;3.2916322;-0.18175629;3.8858442;IRRE
sanity check if the trees aren t the same the pd values won t be equal;2.2683477;3.0541837;-1.9642892;-1.8973696;0.10903994;-2.2887356;IRRE
for some reason the trees aren t exactly equal on 32bits so the pds;-1.2325115;-0.793901;-3.369992;-3.2560656;-1.4448314;-0.1056716;CODE
cannot be equal either see;-3.6506917;4.4049773;1.2418649;-1.563194;-1.3614333;-4.467994;-
https github com scikit learn scikit learn issues 8853;-3.2130797;-9.716984;-5.688465;-0.38737148;-5.1279488;-5.292709;CODE
make sure the recursion method implicitly uses decision function has;-0.09677881;2.532061;-2.195909;3.271501;0.47693768;-1.0018709;CODE
the same result as using brute method with;0.29919595;1.5342228;1.6667471;2.2372735;1.3561387;-5.9081793;IRRE
response method decision function;1.0550517;1.6342176;2.072793;3.0829897;0.6055592;-0.30935442;CODE
assert np mean y 0 5 make sure the init estimator predicts 0 anyway;2.4895036;4.5746365;-6.406824;2.2238941;-5.482909;-1.977176;IRRE
if the target y only depends on one feature in an obvious way linear or;3.5797627;0.6631557;1.8233638;-0.0045204726;-0.14673537;1.1547087;TASK
quadratic then the partial dependence for that feature should reflect;2.7387908;-0.46668962;-0.371804;-1.6015266;0.08412608;5.4703603;CODE
we here fit a linear regression data model with polynomial features if;4.7685184;-0.8316398;-0.44726306;-1.013461;0.460829;1.5519344;TASK
needed and compute r squared to check that the partial dependence;1.7054417;2.5565336;-0.0452703;-0.849083;-1.3319163;0.6988557;CODE
correctly reflects the target;-0.29631045;0.6008043;3.1207478;2.547659;-1.1797769;1.1986384;-
add polynomial features if needed;1.4071941;-2.1525698;1.0387927;-2.3646712;3.0520074;-0.042576637;TASK
make sure error is raised for multiclass multioutput classifiers;2.500108;-0.7002104;-6.247676;2.9873438;1.5040466;0.024098948;CODE
make multiclass multioutput dataset;4.74817;-4.0938373;-1.4118356;-1.0341884;3.4627945;1.2385696;IRRE
simulate that we have some classes;1.6364181;-1.4234796;3.0632012;2.1389492;3.9033406;-0.9578168;IRRE
check that array like objects are accepted;0.44174355;5.238376;0.20014143;3.0171192;1.1664611;-3.9331875;IRRE
make sure that passing a non constant init parameter to a gbdt and using;-3.111784;2.6570685;-5.324177;-0.12648034;-1.3298734;2.5894783;IRRE
recursion method yields a warning;-3.0725849;3.5766551;-1.8434559;3.1042962;-0.92084175;-4.249067;-
test near perfect correlation between partial dependence and diagonal;2.575567;3.3418193;-2.0540025;1.1094135;-1.275249;0.56182855;IRRE
when sample weights emphasize y x predictions;5.3633456;-0.69480157;0.09135548;3.7349143;-0.8833938;2.3788996;-
non regression test for 13193;-0.32207423;3.6799808;-4.2714286;2.0349667;-3.3288555;-5.8380065;IRRE
todo extend to histgradientboosting once sample weight is supported;2.2107444;-0.5438017;-2.5009623;4.002628;1.6449678;5.6039233;CODE
set y x on mask and y x outside;-1.4341666;1.311275;3.9213948;-3.7879443;-1.8878239;3.387232;IRRE
sample weights to emphasize data points where y x;7.4374256;-0.6165742;2.471779;-1.632079;0.66751885;2.3434465;CODE
todo remove fix when pdp supports hgbt with sample weights;-0.44386655;0.54623103;-5.9822645;-0.096027486;-1.7004963;3.7472239;TASK
check that the partial dependence support pipeline;-1.2296904;0.15327267;-5.0541534;3.6706977;0.87598443;2.7067242;CODE
check that the partial dependence support dataframe and pipeline;1.110299;0.35899797;-4.464053;1.3048731;-2.4745905;0.85402375;CODE
including a column transformer;0.48824742;-0.9761502;0.79404;-3.625875;0.6914714;3.3666751;CODE
the column transformer will reorder the column when transforming;-0.28554356;1.7156112;0.091739744;-4.285238;-2.6495268;4.017755;CODE
we mixed the index to be sure that we are computing the partial;1.8267697;2.380603;-0.844933;-1.7729102;-0.5808806;0.8518188;-
dependence of the right columns;3.1341944;1.1812181;2.025564;-4.06364;0.3121189;1.4352796;CODE
check all possible features type supported in pdp;-0.7181413;0.035525154;-4.2177153;0.04699259;1.9773393;-0.78693575;TASK
with pytest raises valueerror match the column 0 contains mixed data types;1.541721;3.2596943;-7.1366496;-2.0121894;-3.5692775;-1.1535953;IRRE
the following should not raise as we do not compute numerical partial;0.7539104;3.744656;-2.471452;-2.4117136;-1.3506495;0.717379;CODE
dependence on integer columns;3.8935053;2.0867908;-0.7216181;-5.429069;2.316275;0.22385994;CODE
the following should not raise as we do not compute numerical partial;0.7539104;3.744656;-2.471452;-2.4117136;-1.3506495;0.717379;CODE
dependence on integer columns;3.8935053;2.0867908;-0.7216181;-5.429069;2.316275;0.22385994;CODE
make sure that feature highly correlated to the target have a higher;3.8795998;1.3707466;-1.163481;3.382341;0.3234038;3.1130557;TASK
importance;-1.3485912;-3.7403564;6.410065;1.5617807;2.2375164;0.3733092;CODE
the correlated feature with y was added as the last column and should;1.115744;1.7719944;0.3133076;-2.3999546;-2.5797594;0.7929485;TASK
have the highest importance;-1.47788;-2.909325;6.1403847;0.9644965;2.3528292;0.5556807;CODE
make sure that feature highly correlated to the target have a higher;3.8795998;1.3707466;-1.163481;3.382341;0.3234038;3.1130557;TASK
importance;-1.3485912;-3.7403564;6.410065;1.5617807;2.2375164;0.3733092;CODE
adds feature correlated with y as the last column;1.7846293;1.2726822;1.7449049;-3.7246113;-0.98669916;0.7667505;TASK
the correlated feature with y was added as the last column and should;1.115744;1.7719944;0.3133076;-2.3999546;-2.5797594;0.7929485;TASK
have the highest importance;-1.47788;-2.909325;6.1403847;0.9644965;2.3528292;0.5556807;CODE
permutation variable importance should not be affected by the high;2.7753103;2.226272;-0.32888097;0.17704326;2.0874107;2.332173;CODE
cardinality bias of traditional feature importances especially when;3.901569;-3.9417942;0.655291;1.4323947;3.1097543;2.6673105;CODE
computed on a held out test set;3.4083788;3.9602463;-1.8986429;4.5107284;0.9569789;-3.8648646;IRRE
generate a multiclass classification dataset and a set of informative;4.8939214;-6.3759074;0.05651485;0.4491435;5.8933287;-0.2661977;IRRE
binary features that can be used to predict some classes of y exactly;5.6450067;-4.196247;-0.45744148;-1.1275369;3.8090727;-2.0635424;TASK
while leaving some classes unexplained to make the problem harder;0.14504355;-1.0071942;0.9940303;4.194898;1.9294708;-2.2115402;CODE
not all target classes are explained by the binary class indicator;-0.12733126;-0.88951445;-4.380984;1.3653964;2.8090196;-0.3245737;IRRE
features;1.4263527;-6.2441335;5.031171;1.4146436;3.9154737;-1.3022918;TASK
add 10 other noisy features with high cardinality numerical values;6.10279;-0.99230796;-0.70133466;-1.4308417;2.9043984;0.6255061;TASK
that can be used to overfit the training data;3.6496348;-3.2641323;0.84431696;2.3978264;3.3198051;1.3546089;OUTD
split the dataset to be able to evaluate on a held out test set the;6.1945443;2.8188765;-0.10280795;3.60061;2.6700606;-3.5122123;IRRE
test size should be large enough for importance measurements to be;3.9275663;1.5464326;0.3825847;4.146148;0.69558066;-1.0817128;CODE
stable;-1.8943725;-1.6073065;4.9279366;1.8391316;-1.4195144;-1.6829987;-
variable importances computed by impurity decrease on the tree node;0.5415304;0.33864662;-1.6396943;1.0198436;0.56107205;2.4763772;CODE
splits often use the noisy features in splits this can give misleading;2.8625937;-2.259462;0.60297763;2.323853;2.7349489;1.9958878;TASK
impression that high cardinality noisy variables are the most important;5.3136287;-2.0493667;0.80738604;2.9073577;2.866235;1.4449852;CODE
let s check that permutation based feature importances do not have this;1.4103537;-0.2668142;-1.4920949;0.77196544;3.1266732;1.8588742;CODE
problem;-3.3429859;0.5084639;5.251237;0.44499403;-0.801874;-4.072769;-
split the importances between informative and noisy features;5.1727676;-5.4023895;1.8366596;1.7135919;3.7090168;2.9867024;CODE
because we do not have a binary variable explaining each target classes;-0.8716189;-2.1607738;-3.3846643;1.0875355;3.4322643;-1.3325062;CODE
the rf model will have to use the random variable to make some;1.0217073;-0.3522108;1.1315123;2.7158108;3.2980578;0.82847774;IRRE
overfitting splits as max depth is not set therefore the noisy;2.9803407;0.30655977;-1.4708072;0.6404429;-1.7336051;2.7237792;CODE
variables will be non zero but with small values oscillating around;0.7661408;4.714393;-1.586024;-3.6627944;-5.3290906;-1.6394528;IRRE
zero;-2.359473;1.2926373;2.9025295;-2.352723;-1.7710636;-5.686084;-
the binary features correlated with y should have a higher importance;3.6999016;-2.0956328;0.53840214;-2.1799216;1.1724081;1.510213;CODE
than the high cardinality noisy features;6.180009;-3.6080122;-0.087169;0.98560804;3.2920504;2.1345801;TASK
the maximum test accuracy is 2 5 0 4 each informative feature;4.7885284;-0.7128479;-3.5071394;2.9743557;2.0826023;-4.5154605;TASK
contributing approximately a bit more than 0 2 of accuracy;2.646158;-2.0215175;-0.70613873;2.903973;-1.8255281;-3.8568716;META
last column is correlated with y;1.5950067;2.9116504;2.0002825;-4.714767;-3.8025994;-1.0464095;-
the correlated feature with y is the last column and should;1.8940505;1.4669532;1.2481562;-3.4047;-2.5600991;0.4598817;TASK
have the highest importance;-1.47788;-2.909325;6.1403847;0.9644965;2.3528292;0.5556807;CODE
use another random state;-0.57879406;2.4280035;3.63878;2.9779744;3.6201842;-0.19561432;IRRE
the correlated feature with y is the last column and should;1.8940505;1.4669532;1.2481562;-3.4047;-2.5600991;0.4598817;TASK
have the highest importance;-1.47788;-2.909325;6.1403847;0.9644965;2.3528292;0.5556807;CODE
last column is correlated with y;1.5950067;2.9116504;2.0002825;-4.714767;-3.8025994;-1.0464095;-
the correlated feature with y is the last column and should;1.8940505;1.4669532;1.2481562;-3.4047;-2.5600991;0.4598817;TASK
have the highest importance;-1.47788;-2.909325;6.1403847;0.9644965;2.3528292;0.5556807;CODE
this relationship can be computed in closed form;0.024782179;1.2911568;1.4598398;-2.0710702;2.8429694;-0.38317293;CODE
regression test to make sure that sequential and parallel calls will;1.7578717;4.078983;1.1883249;6.1942677;-0.43482876;-3.1587853;IRRE
output the same results;2.076463;3.638137;4.0857096;-2.1100955;0.8198633;-6.3513513;IRRE
also tests that max samples equal to number of samples is equivalent to 1 0;4.1729307;4.146114;-2.252174;0.5438321;0.6164264;-4.0929728;IRRE
first check that the problem is structured enough and that the model is;2.56895;2.5163195;-1.3629938;4.704448;1.070787;-1.1628838;CODE
complex enough to not yield trivial constant importances;0.28646153;-0.46757033;0.7989299;1.0641695;1.2398372;3.6380565;CODE
the actually check that parallelism does not impact the results;2.3309455;1.934454;-1.9426559;5.1102023;-1.007252;-0.8829701;IRRE
either with shared memory threading or without isolated memory;-1.604616;-1.8063419;2.269264;1.9069171;1.9186909;3.578144;CODE
via process based parallelism using the default backend;-2.7731369;-1.8207128;0.88543075;2.6381085;0.7028386;3.423798;CODE
loky or multiprocessing depending on the joblib version;-1.30934;-3.0829813;-1.2587346;2.651343;-0.47136626;1.1959995;TASK
process based parallelism by default;-1.2337325;-2.1943955;1.1318445;3.0021276;0.58765143;3.2444158;CODE
thread based parallelism;0.6716231;-2.7558079;3.3884013;1.4680735;1.2607307;0.58963716;CODE
this test checks that the column shuffling logic has the same behavior;1.8129888;6.0524445;-2.6850262;1.0177804;1.1622624;-4.7265224;IRRE
both a dataframe and a simple numpy array;3.8461835;-1.6746327;0.03755527;-4.9859834;-6.1085596;-0.9498437;-
regression test to make sure that sequential and parallel calls will;1.7578717;4.078983;1.1883249;6.1942677;-0.43482876;-3.1587853;IRRE
output the same results;2.076463;3.638137;4.0857096;-2.1100955;0.8198633;-6.3513513;IRRE
add a categorical feature that is statistically linked to y;1.4568988;-1.5460165;1.7018645;-0.4288509;1.4434136;-0.5985247;TASK
concatenate the extra column to the numpy array integers will be;1.9507856;0.8466477;-1.1530144;-7.638719;-4.8209333;-1.7597572;CODE
cast to float values;2.0042677;3.9489188;0.327664;-3.611711;-1.4829521;-1.4256793;IRRE
insert extra column as a non numpy native dtype;1.3011382;-1.7901999;-4.874049;-5.8202825;-3.8532217;-0.23132744;CODE
stich an arbitrary index to the dataframe;3.1072137;0.41459614;-0.04211635;-4.7453175;-1.1675813;0.29499546;-
first check that the problem is structured enough and that the model is;2.56895;2.5163195;-1.3629938;4.704448;1.070787;-1.1628838;CODE
complex enough to not yield trivial constant importances;0.28646153;-0.46757033;0.7989299;1.0641695;1.2398372;3.6380565;CODE
now check that importances computed on dataframe matche the values;3.6713626;2.0584004;-0.71867055;-0.79587835;-2.2024841;-0.99604326;CODE
of those computed on the array with the same data;6.5670996;2.2324636;1.172586;-3.5576105;0.651187;-2.6788664;CODE
smoke non regression test for;1.8913888;4.346105;-2.0256965;4.889781;-1.6118182;-2.9905076;IRRE
https github com scikit learn scikit learn issues 15810;-3.4143593;-9.933292;-5.7103043;-0.34235325;-5.595566;-5.65303;CODE
assert x nbytes 1e6 trigger joblib memmaping;-0.82748884;1.9912102;-5.687903;1.6562206;-0.7408336;-2.259591;CODE
actual smoke test should not raise any error;-0.57237625;6.543066;-4.132047;5.895305;-3.239735;-2.1095974;IRRE
auxiliary check dummyclassifier is feature independent;-0.47708726;1.134333;-6.0867453;3.679294;3.0052068;-0.44156545;CODE
permutating feature should not change the predictions;2.9569886;-0.49687222;-0.40790382;3.528707;1.255015;1.4088814;TASK
creating data with 2 features and 1000 samples where the target;5.9220357;-0.31858155;1.7812258;-0.53037035;3.0888736;-1.5551722;TASK
variable is a linear combination of the two features such that;1.8498307;-1.3667848;1.2555004;-2.5747066;2.3681073;0.036025718;TASK
in half of the samples the impact of feature 1 is twice the impact of;3.9983137;-0.24878873;0.13437277;1.7408231;0.5397656;-0.31456697;TASK
feature 2 and vice versa on the other half of the samples;4.428398;-0.7153943;0.4647537;0.6866045;3.1437097;0.15333094;TASK
fitting linear regression with perfect prediction;4.9823313;1.1385263;0.44134867;1.007331;-3.8408263;1.3295153;-
when all samples are weighted with the same weights the ratio of;5.3146324;2.4793217;1.2090591;-0.112867236;0.97178763;1.4869508;-
the two features importance should equal to 1 on expectation when using;1.5938013;-0.5534963;-0.076809354;0.52041924;1.642949;1.809298;CODE
mean absolutes error as the loss function;2.1336858;1.7932546;-1.8090171;-0.6572955;-3.9142206;2.2456732;CODE
when passing a vector of ones as the sample weight results should be;5.894008;1.459437;-2.6928632;-1.3471735;0.25840843;1.685675;IRRE
the same as in the case that sample weight none;2.7789676;2.335831;-0.46595073;0.6428409;1.1608391;-0.11685413;CODE
when the ratio between the weights of the first half of the samples and;4.545787;2.524134;1.959634;-0.207566;-0.7750779;0.509117;-
the second half of the samples approaches to infinity the ratio of;2.6019928;2.999581;1.6683513;-0.19262943;-3.2117164;-1.1090537;IRRE
the two features importance should equal to 2 on expectation when using;1.3758411;-0.75843006;0.2741261;0.48467126;1.911011;1.8061408;CODE
mean absolutes error as the loss function;2.1336873;1.7932553;-1.8090168;-0.6572949;-3.9142206;2.2456746;CODE
creating a scorer function that does not takes sample weight;4.9345694;3.9466326;0.3674428;1.2843242;1.3931677;-0.21956503;CODE
creating some data and estimator for the permutation test;4.2479696;3.7293932;1.5254658;1.698456;2.0592387;-3.0488129;IRRE
test that permutation importance does not return error when;2.4327645;6.0507183;-2.9619286;2.5849514;1.3631759;-4.765957;CODE
sample weight is none;1.5080857;3.2532845;-1.4690014;0.27806082;-2.1582797;-2.336193;-
test that permutation importance raise exception when sample weight is;3.427889;5.2642827;-3.037127;3.6287751;1.8674235;-1.6481513;CODE
not none;-2.2953875;-1.2729574;1.8622242;1.3364519;-0.18807134;-3.747351;-
test permutation importance when scoring contains multiple scorers;4.222108;2.7850943;1.2999343;2.8422048;3.5329595;-3.233976;CODE
creating some data and estimator for the permutation test;4.2479696;3.7293932;1.5254658;1.698456;2.0592387;-3.0488129;IRRE
single y constant prediction;5.962457;-0.52389103;1.1800249;0.6134426;-2.5970232;0.77280253;CODE
remove interpolation method;1.4281441;3.3982503;-0.7333822;-0.6228287;-4.0765853;2.390553;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo bayesian ridge regression and bayesian regression ard;1.9088774;-2.898392;-1.9405977;0.6705435;-1.907171;3.963572;TASK
should be squashed into its respective objects;-1.2463057;1.826279;2.3717706;0.73832065;1.4305596;2.6210907;CODE
for sparse data intercept updates are scaled by this decay factor to avoid;4.026292;-0.5328503;-3.1087883;-0.8570444;-3.7229388;5.14247;CODE
intercept oscillation;-0.5274984;0.8827457;2.30757;-0.9785369;-5.4359546;0.7319996;CODE
seed should never be 0 in sequentialdataset64;-1.398507;2.9956014;-3.5803611;-0.49399823;-1.8208373;-0.59320915;IRRE
x scale is no longer needed it is a historic artifact from the;-3.1894095;-0.86943144;1.1144127;-1.8905163;-3.690427;3.0713644;OUTD
time where linear model exposed the normalize parameter;3.00013;0.08278767;-0.043296523;0.3270186;-2.525264;5.0822835;IRRE
sample weight can be implemented via a simple rescaling;7.3542557;-0.65449536;0.7724023;-0.61833197;0.8385999;4.403143;TASK
for sparse x and y it triggers copies anyway;1.0076116;0.7234586;-0.266308;-1.690335;0.02520137;2.8103852;IRRE
for dense x and y that already have been copied we safely do inplace;3.931957e-06;-0.3062116;-0.15417585;-1.243388;-0.4626507;1.6188527;CODE
rescaling;2.2124317;0.023155073;6.491121;-3.2258081;-2.291242;1.8253025;-
assume that validate data and check sample weight have been called by;5.058051;5.475924;-1.8744546;4.408751;2.5131457;-2.0733812;IRRE
the caller;-3.2422101;-0.61379254;5.182906;1.1414775;0.5796451;-1.8776841;IRRE
y 1 x 0 2 x 1 3;0.51312625;1.5146317;1.9235543;-9.489942;-1.4000783;-2.5908046;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
bayesianridge regression;2.3213155;-2.8474047;1.4389004;2.678792;-1.3536115;0.9600242;-
sample weight can be implemented via a simple rescaling;7.3542557;-0.65449536;0.7724023;-0.61833197;0.8385999;4.403143;TASK
initialization of the values of the parameters;-0.68827873;3.2381823;1.7369868;-1.2868584;0.22644415;1.3489372;IRRE
add eps in the denominator to omit division by zero;-0.14914179;3.2273333;-0.8399041;-5.065764;-2.2328858;-0.4426478;TASK
avoid unintended type promotion to float64 with numpy 2;-0.19367938;0.56451267;-4.898403;-4.999694;-5.7544575;0.8032035;CODE
let m n n samples n features and k min m n;6.3131504;-2.404617;0.18268646;-2.7159412;3.8851755;-0.92218095;TASK
the posterior covariance matrix needs vh full n n;0.46483374;1.2410357;-2.427405;-2.773309;0.039185558;4.2174144;TASK
the full svd is only required when n samples n features;2.5013638;-1.8011491;-5.1690555;-0.8314155;3.232961;2.239404;TASK
when n samples n features k m and full matrices true;5.8876953;-0.6534776;-1.9210987;-2.2529786;1.6735945;0.8440381;TASK
u m m s m vh full n n vh m n;-1.7217889;-0.26687035;0.6834261;-2.0246944;0.9633023;-1.9713211;-
when n samples n features k n and full matrices false;5.844011;0.4616816;-3.2389085;-2.1143727;0.8347239;-0.3909807;TASK
u m n s n vh full n n vh n n;-1.9428065;-0.2564664;0.63989294;-1.9350941;1.0913619;-2.4855175;-
convergence loop of the bayesian ridge regression;2.58445;-2.2733562;-1.0811445;1.602432;-3.953802;4.158976;IRRE
update posterior mean coef based on alpha and lambda and;0.7981934;1.9099425;-0.39195716;1.6650271;-0.37892956;3.5635092;CODE
compute corresponding sse sum of squared errors;2.6857762;0.6966867;-3.5956395;-0.71891034;-2.3321514;-0.32388455;-
compute the log marginal likelihood;-1.1253028;-0.55223876;1.1009083;-1.4128379;-0.16781524;0.15404215;-
update alpha and lambda according to mackay 1992;-2.061593;-2.2513506;-2.703935;1.6722583;-1.4643706;1.1480544;CODE
check for convergence;0.3253175;3.2657092;1.0805361;3.7141476;-3.5649312;-3.386075;CODE
return regularization parameters and corresponding posterior mean;3.0588696;1.2061162;-1.138599;1.4786714;0.12316838;6.856565;IRRE
log marginal likelihood and posterior covariance;-2.109719;-1.5665296;0.1581825;0.2746097;0.25615308;3.669116;CODE
compute the log marginal likelihood;-1.1253028;-0.55223876;1.1009083;-1.4128379;-0.16781524;0.15404215;-
posterior covariance;-0.9946155;-0.3958535;1.3100082;0.21826522;-0.099045046;4.156308;CODE
note we do not need to explicitly use the weights in this sum because;2.4246068;0.52135086;0.02088789;-1.1610625;-1.0777575;0.95027155;CODE
y and x were preprocessed by rescale data to handle the weights;5.2134323;0.18551062;0.66765827;-3.1945786;-4.777717;4.23718;CODE
http www utstat toronto edu rsalakhu sta4273 notes lecture2 pdf page 15;-1.4595158;-4.6365743;-0.41598722;-1.7093304;1.5009416;1.2066768;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
mypy error module sklearn linear model has no attribute cd fast;1.5466566;-1.528317;-7.1063523;-1.5322107;-4.5704393;-0.5776169;META
from sklearn linear model import cd fast as cd fast type ignore attr defined;1.7824723;-1.162579;-6.1405144;-1.6782421;-1.9584231;1.298829;CODE
paths functions;-2.6162934;-1.4332898;3.590458;-0.71661097;-0.3838663;-0.6821438;CODE
todo for y ndim 1 think about avoiding memory of y y y mean;3.0991757;0.2786847;0.69611055;-1.5997118;-0.47852677;0.37956387;CODE
avoid copy of x i e avoid explicitly computing x x mean;2.4034193;3.4081643;-0.26770958;-0.30484688;-1.3029749;0.94896024;CODE
compute np max np sqrt np sum xyw 2 axis 1 we switch sqrt and max to avoid;1.8054621;0.23576109;-1.310222;-6.418673;-4.5885153;1.2913115;CODE
many computations of sqrt this however needs an additional np abs;2.0636458;0.1250511;-2.1406376;-2.5023658;-2.201095;0.042695716;TASK
we expect x and y to be already fortran ordered when bypassing;-2.454334;0.9090692;-1.0523423;-1.1910337;-1.3367732;-0.2603051;CODE
checks;-1.7342966;1.2948469;3.663561;1.8668331;0.98105586;-5.659494;-
xy should be a 1d contiguous array or a 2d c ordered array;1.7008588;2.277074;0.36856776;-8.999551;-2.1389115;-0.3081075;-
multitaskelasticnet does not support sparse matrices;2.4164512;-3.1753948;-3.7480314;-0.43162614;-2.4663336;5.519646;TASK
as sparse matrices are not actually centered we need this to be passed to;4.7329073;0.56944656;-2.27252;-3.5342896;-2.7510946;6.490455;IRRE
the cd solver;2.8154287;-3.6819804;0.7134591;-1.4965593;1.8547075;-0.96465224;-
x should have been passed through pre fit already if function is called;0.27237892;5.30256;-1.2696745;2.315143;-1.87647;1.3460273;CODE
from elasticnet fit;2.6676834;-1.7356775;-0.44855577;-1.1604489;-1.2531558;3.498033;CODE
fit intercept and sample weight have already been dealt with in calling;2.5309696;2.9873555;-3.3246229;2.7547839;-2.988642;2.295399;CODE
methods like elasticnet fit;6.034193;-2.2807262;-0.1526254;0.021603648;0.10806779;4.740757;-
alphas np sort alphas 1 make sure alphas are properly ordered;0.18461812;1.2915953;-1.7367805;-2.0404491;-1.4861338;-1.0479423;-
account for n samples scaling in objectives between here and cd fast;6.443587;-0.6261454;-0.9633028;1.0453243;1.6904421;3.22593;CODE
we expect precompute to be already fortran ordered when bypassing;-2.9752452;-0.9740123;-2.3804548;1.709201;-1.4220594;1.0173119;CODE
checks;-1.7342966;1.2948469;3.663561;1.8668331;0.98105586;-5.659494;-
we correct the scale of the returned dual gap as the objective;3.9718633;0.9722673;-1.0045136;0.8073705;0.038013894;3.6012778;IRRE
in cd fast is n samples the objective in this docstring;2.8609648;-2.4306672;-1.1438112;0.44051135;4.35882;-0.63293386;CODE
elasticnet model;1.824605;-2.6242216;0.33910695;0.8828571;0.7526285;2.4093704;-
check input is used for optimisation and isn t something to be passed;0.3628075;4.907901;-2.0805662;3.2418733;-0.14226434;-3.3614538;CODE
around in a pipeline;-0.7061259;-1.7293218;4.836078;2.5719156;0.32400727;-0.5010201;CODE
remember if x is copied;-2.8896143;2.5675423;1.6682295;1.7888992;-0.08537843;-0.60292083;-
we expect x and y to be float64 or float32 fortran ordered arrays;0.8491932;1.0026865;-3.0778048;-7.3553076;-4.0058146;-2.7135577;CODE
when bypassing checks;-3.6986003;3.0356746;0.08662548;4.32606;0.32209966;-2.0699062;-
tldr rescale sw to sum up to n samples;6.7222857;0.12087289;-0.0794821;-2.486713;-0.37308332;2.0972958;-
long the objective function of enet;0.7217936;-1.395927;1.2395494;1.4779397;1.6886177;2.0416021;CODE
1 2 np average squared error weights sw;4.730757;-0.15434338;-3.289486;-2.0521514;-3.2129853;0.52489436;-
alpha penalty 1;-1.6126727;1.8739855;1.590816;0.67391425;-0.8936413;-1.6094857;-
is invariant under rescaling of sw;0.8307743;0.6770104;-0.7995642;0.12811399;-1.1516154;7.089704;CODE
but enet path coordinate descent minimizes;2.2440534;-1.5282269;-1.9432697;0.011753681;-1.3040228;6.765857;META
1 2 sum squared error alpha penalty 2;1.4933541;1.5624006;-2.180879;-0.15367739;-2.8585067;0.2365355;-
and therefore sets;-1.6060141;0.1926472;4.916112;1.1325395;3.7569673;-2.4076688;IRRE
alpha n samples alpha 3;0.42378578;0.43039572;0.41321066;-3.3356564;0.36755767;-3.541048;-
inside its function body which results in objective 2 being;-3.1914947;0.59552735;1.4916979;1.3129865;-0.13993685;1.2098035;IRRE
equivalent to 1 in case of no sw;-0.6143445;3.5764763;0.41728935;-1.5708497;3.7789671;-3.748066;CODE
with sw however enet path should set;-5.896431;0.8015041;0.66872615;0.4022742;-1.8444972;2.4132795;IRRE
alpha sum sw alpha 4;-2.0602417;0.32603025;2.0262136;-2.7961257;0.09384934;-3.1845627;-
therefore we use the freedom of eq 1 to rescale sw before;-1.0516517;1.6289881;0.35436141;0.21559645;0.56541127;5.312427;CODE
calling enet path i e;-5.7708316;-0.13967042;1.4583073;-0.21283972;-1.4080119;1.0574445;IRRE
sw n samples sum sw;4.072668;0.043052796;1.631791;-2.3172436;2.2273185;-3.6106129;-
such that sum sw n samples this way 3 and 4 are the same;4.608329;2.7787101;1.189567;-3.9258583;3.3908665;-2.9228783;CODE
note alternatively we could also have rescaled alpha instead;-1.4558867;0.15585886;0.114689074;-1.795761;-3.8519614;2.980713;TASK
of sample weight;4.05895;1.3209984;1.3409092;1.3460313;0.74016625;-1.4957371;-
alpha np sum sample weight n samples;3.592582;-0.14254887;-2.0906458;-1.8038789;-0.63606125;-0.5057809;-
ensure copying happens only once don t do it again if done above;-1.9774723;4.5857368;0.061329417;3.8675518;-0.19011006;1.2164177;CODE
x and y will be rescaled if sample weight is not none order f;4.821075;4.1137233;0.5265416;-2.5752573;-3.0322878;2.0163376;-
ensures that the returned x and y are still f contiguous;0.8929566;4.800202;2.7041764;-1.256857;-1.0153929;0.9303081;TASK
coordinate descent needs f ordered arrays and pre fit might have;5.391412;1.574906;-3.2208648;-2.3088763;-3.0851266;3.1200678;TASK
called rescale data;4.0488353;0.11709169;3.5015132;-3.8896694;-1.9709377;2.8422194;IRRE
from here on params;-1.901336;-2.5779254;5.750915;0.89721507;0.53509086;-0.9099704;CODE
check for finiteness of coefficients;0.9930361;4.6568465;-1.5714495;-0.30372146;-0.2834573;-1.0399364;IRRE
return self for chaining fit and predict calls;2.6179976;1.7389089;-0.55365485;4.2791452;0.3773296;2.3018355;CODE
todo 1 9 remove warn and none options;-5.2494845;2.8947337;-0.20384552;2.2699199;-1.3699666;0.025701836;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we allow for newtonsolver classes for the solver parameter but do not;0.15580279;-1.7082251;-4.882781;0.68137693;-1.8707745;2.4978247;CODE
make them public in the docstrings this facilitates testing and;-4.1943226;-2.7104614;-1.366164;4.771559;2.1137516;-1.3617841;CODE
benchmarking;6.1970744;-2.8507786;1.9310492;3.4308205;1.3603196;-1.9027531;-
required by losses;0.5040832;1.0778642;2.7540057;2.1740732;2.7710054;-0.014070332;CODE
lbfgs will force coef and therefore raw prediction to be float64 the;1.5106174;0.11048994;-5.1682124;0.49800426;-3.6581266;0.96011555;CODE
base loss needs y x coef and sample weight all of same dtype;3.9399319;0.5333498;-3.5506938;-0.99097914;-1.1033747;1.9408201;TASK
and contiguous;0.20659253;0.33575836;5.043412;-0.9608645;4.0277834;0.09990536;-
note that check sample weight calls check array order c required by;3.7441826;4.2122607;-3.614323;-0.46187884;0.49892294;-1.7067;TASK
losses;0.69978666;-0.73770744;5.3066673;1.9306068;-0.5837727;-2.540905;-
todo if alpha 0 check that x is not rank deficient;1.3872404;4.9246373;-3.8511684;-1.1936332;-0.7828552;-2.2003033;CODE
note rescaling of sample weight;5.065648;1.8094878;0.73271817;-1.106445;-1.9624164;2.0690336;TASK
we want to minimize;1.0519251;-0.98451203;5.5983706;2.3471098;0.10093398;2.0169108;-
obj 1 2 sum sample weight sum sample weight deviance;3.1086128;0.47364464;-2.9199405;-1.0410326;0.33562335;0.9114258;-
1 2 alpha l2;-2.0496314;1.2843556;3.2893398;-3.7454505;0.8756267;-3.0283318;-
with;-2.4284165;-1.2547264;5.601066;0.86658394;-1.1801157;-2.4086056;-
deviance 2 loss;-1.4131447;0.45836005;-0.06555703;0.87903965;-1.379545;-1.0948778;-
the objective is invariant to multiplying sample weight by a constant we;6.418781;0.238914;-1.0336733;1.7738887;1.3651955;4.477243;CODE
could choose this constant such that sum sample weight 1 in order to end;3.9771552;3.848633;1.2369367;-1.1286616;0.21606319;0.3160975;CODE
up with;-2.4444864;-2.1784608;3.9179826;1.4120957;-1.3219012;-1.6614758;-
obj sum sample weight loss 1 2 alpha l2;2.8845875;1.0041914;-1.1865054;-0.8128842;-1.1739902;0.6928767;-
but linearmodelloss loss already computes;3.6892045;-1.0291272;-2.1074722;1.3846967;-1.0059532;2.2377558;META
average loss weights sample weight;3.288036;0.49844852;0.7927336;1.390181;-1.6600883;2.0418086;-
thus without rescaling we have;0.24087167;0.639764;4.3105245;1.2776314;-1.2947085;3.550889;-
obj linearmodelloss loss;3.5513883;-1.0344537;-2.705042;-1.1906872;-1.9006383;2.532745;-
linearmodelloss needs intercept at the end of coefficient array;1.1322587;2.4134989;-0.89518905;-3.0911129;-3.0635707;1.9438788;CODE
algorithms for optimization;5.3305764;-2.9889612;2.9990335;-0.20938298;2.2600687;1.7740593;CODE
note again that our losses implement 1 2 deviance;-0.27131835;0.48003665;0.3235593;1.5161952;1.0657587;-0.25504458;TASK
maxls 50 default is 20;-2.713847;1.3144656;0.4977457;-1.1365819;0.49129257;0.41577706;CODE
the constant 64 was found empirically to pass the test suite;-0.5434282;-0.799365;-3.8963852;0.63789016;-1.2042696;-5.3790703;IRRE
the point is that ftol is very small but a bit larger than;-2.5268877;-0.19435064;0.09972262;-0.63134927;-1.0899198;1.6893523;META
machine precision for float64 which is the dtype used by lbfgs;2.1383295;-0.6197063;-4.9165535;-2.871704;-2.4555526;-1.1254137;CODE
set intercept to zero as the other linear models do;0.49704367;1.8322809;-0.17121053;-0.6894925;-3.1359181;2.9809456;CODE
check array is done in linear predictor;4.919056;4.517567;-1.1622822;0.55339134;-1.8548529;-1.8977717;CODE
todo adapt link to user guide in the docstring once;-6.6143427;-2.6092155;1.1587491;3.7416594;0.53377146;3.295361;CODE
https github com scikit learn scikit learn pull 22118 is merged;-3.8469684;-10.309912;-4.104723;0.41115528;-3.2055135;-3.0879834;CODE
note default score defined in regressormixin is r 2 score;0.12064947;2.4289281;-4.2013125;-1.1263573;-1.9108119;0.01699163;CODE
todo make d 2 a score function in module metrics and thereby get;2.4185615;0.9197605;-1.905921;-0.733347;0.8917329;-0.34108967;CODE
input validation and so on;-0.808794;1.7131853;2.457164;1.3756038;1.9721918;-4.192043;CODE
raw prediction self linear predictor x validates x;3.0875618;1.1836195;-4.741655;2.250014;-0.68870056;0.7003002;CODE
required by losses;0.5040832;1.0778642;2.7540057;2.1740732;2.7710054;-0.014070332;CODE
note that check sample weight calls check array order c required by;3.7441826;4.2122607;-3.614323;-0.46187884;0.49892294;-1.7067;TASK
losses;0.69978666;-0.73770744;5.3066673;1.9306068;-0.5837727;-2.540905;-
missing factor of 2 in deviance cancels out;-3.4083304;3.7222168;-2.5804784;-1.9002193;-1.6315626;-1.5818495;-
create instance of baseloss if fit wasn t called yet this is necessary as;-0.74153316;4.364729;-2.9100888;4.88629;2.7297668;2.7357273;IRRE
tweedieregressor might set the used loss during fit different from;1.7097619;1.1523182;-2.7580578;2.502943;-1.1902263;5.8315864;IRRE
self base loss;0.58256614;0.9423672;0.7338526;2.0519898;-0.77857083;0.08756361;CODE
this happens when the link or power parameter of tweedieregressor is;-4.0267487;0.9718149;-2.2774854;-0.21807587;-1.9928665;4.0229173;IRRE
invalid we fallback on the default tags in that case;-5.3700747;2.1589222;-2.7484248;2.9583688;-1.2765936;2.5431976;CODE
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
identity link;-5.060415;-2.1626422;3.2863913;-2.006899;2.7961302;0.111026704;-
log link;-4.3800325;-1.3474015;3.956053;0.5210135;-1.7576246;-1.2103839;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
find good starting point by nelder mead;-0.3566081;-3.9413164;2.9117944;1.4046947;0.087091304;-2.2591443;CODE
now refine via root finding on the gradient of the function which is;-0.061364863;-0.5833971;-0.2612167;0.8955966;-1.9131463;3.019278;CODE
more precise than minimizing the function itself;3.3159394;1.3353462;1.6410385;0.43638653;-1.7757163;2.4948306;CODE
tweedieregressor power 3 0 too difficult;-2.1917033;-0.22905494;-1.1986915;-0.8160891;0.2401719;0.06847348;-
tweedieregressor power 0 link log too difficult;-2.5161211;0.33559874;-2.5950873;-0.42402974;-2.049134;1.6223084;-
make larger dim more than double as big as the smaller one;0.271383;2.1554503;1.7682418;-3.1544256;-0.9400329;2.3184144;CODE
this helps when constructing singular matrices like x x;2.2689898;-0.70098275;-1.4479424;-3.7166052;0.70101947;4.7795696;CODE
x 1 1 last columns acts as intercept;1.1802205;2.876531;0.10389755;-6.6661487;-2.8519273;0.7623199;CODE
assert np all s 1e 3 to be sure;1.1272998;3.8496368;-5.4898615;2.0420732;0.614424;-5.421004;IRRE
assert np max s np min s 100 condition number of x;2.5288138;5.0822873;-3.8736086;-0.9659655;0.63838315;-2.746445;CODE
minimum norm solution min w 2 such that raw prediction x w;4.292981;0.2650928;-1.9429706;-2.029571;-0.99281037;4.4885674;-
w x xx 1 raw prediction v s 1 u raw prediction;2.3296282;-2.1355312;-0.65667945;1.3966726;1.512723;0.9113753;-
add penalty l2 reg strength coef 2 2 for l2 reg strength 1 and solve with;1.2686278;2.7381184;-2.2970207;-1.499872;0.7125025;-0.34528285;TASK
optimizer note that the problem is well conditioned such that we get accurate;7.2538385;1.5503151;0.03971856;2.6636336;-0.5378687;1.4186732;TASK
results;-0.124750376;-1.7336558;6.189961;3.2482023;0.4808949;-6.011475;IRRE
to be sure;-1.0003752;0.17772356;3.2489638;4.0153337;-1.0458624;-3.5964289;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
same with sample weight;4.182051;1.2892798;1.9825329;1.8257021;0.54765254;-0.468572;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
xxx investigate if the convergencewarning that can appear in some;1.2727437;1.7242587;0.015005522;4.012463;-1.1045281;0.029877588;-
cases should be considered a bug or not in the mean time we don t;-2.5388265;1.5351458;-1.7591748;4.779827;1.5209954;-0.07357223;CODE
fail when the assertions below pass irrespective of the presence of;-0.45718715;8.17968;-3.1757724;6.158137;1.3514302;-2.2008224;CODE
the warning;-3.2763915;-0.46750727;2.1475651;3.7481413;-1.3377142;-1.8589813;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
alpha 0 unpenalized;-4.8876743;0.11254066;-2.1909988;-0.2748291;-1.7551028;-1.1472112;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
the newton solvers should warn and automatically fallback to lbfgs;1.8770282;-1.1335224;-3.9977853;4.6065164;-3.4512017;1.6620079;IRRE
in this case the model should still converge;2.1898766;3.6374197;1.2960097;4.796228;-2.7847064;1.382296;CODE
xxx investigate if the convergencewarning that can appear in some;1.2727437;1.7242587;0.015005522;4.012463;-1.1045281;0.029877588;-
cases should be considered a bug or not in the mean time we don t;-2.5388265;1.5351458;-1.7591748;4.779827;1.5209954;-0.07357223;CODE
fail when the assertions below pass irrespective of the presence of;-0.45718715;8.17968;-3.1757724;6.158137;1.3514302;-2.2008224;CODE
the warning;-3.276393;-0.46750787;2.147566;3.7481427;-1.3377157;-1.8589805;-
fixme assert allclose model coef coef should work for all cases but fails;-1.1682421;3.7904727;-6.8957243;4.634909;-2.5521743;0.9612454;CODE
for the wide fat case with n features n samples most current glm solvers do;6.1060224;-2.3563552;-2.3986216;1.9284695;-0.31370464;3.869401;CODE
not return the minimum norm solution with fit intercept true;3.1473603;3.7190874;-3.0723283;-1.6740631;-4.2771;3.9466062;CODE
as it is an underdetermined problem prediction y the following shows that;4.258339;-0.71576744;-0.5064173;1.0891868;-0.043309774;0.80214703;-
we get a solution i e a non unique minimum of the objective function;1.7178962;1.2628534;-0.35141382;-1.160369;0.93083245;3.2966948;CODE
xxx this solver shows random behaviour sometimes it finds solutions;-2.5685356;3.1382537;-2.3701742;0.4397091;-2.628338;-1.4951454;IRRE
with norm model norm solution so we check conditionally;0.82193196;3.652508;-0.49993598;1.3780272;-0.20421523;2.1511562;-
but it is not the minimum norm solution otherwise the norms would be;1.2245442;1.7501714;-0.8931536;-2.2431679;-0.9761704;4.471432;IRRE
equal;-0.672778;2.152373;4.7423453;0.36144674;1.098367;-5.7088175;-
see https github com scikit learn scikit learn issues 23670;-1.9534199;-10.410392;-7.2492266;-1.0325739;-5.2696285;-4.515151;CODE
note even adding a tiny penalty does not give the minimal norm solution;2.5646515;1.7149065;-3.3391383;-0.061327066;-0.63879573;6.341868;TASK
xxx we could have naively expected lbfgs to find the minimal norm;2.5137398;0.9086423;-2.9859617;-1.5322958;-0.47652295;2.9385488;-
solution by adding a very small penalty even that fails for a reason we;-0.9415236;4.198166;-1.5201398;4.4627485;-1.8731401;2.069997;TASK
do not properly understand at this point;-2.3956158;0.26271424;2.6891718;-1.7176564;-1.0263118;-3.7744632;CODE
when fit intercept false lbfgs naturally converges to the minimum norm;4.0205235;1.9852092;-4.4967613;1.7878999;-3.9660697;5.2903867;CODE
solution on this problem;-2.0113425;3.1442459;4.663702;-1.522114;0.66164905;-3.0884902;CODE
xxx do we have any theoretical guarantees why this should be the case;-1.9455087;2.1104345;0.048706405;2.6199393;0.8125499;0.81900215;CODE
alpha 0 unpenalized;-4.8876753;0.1125411;-2.1910002;-0.27482924;-1.7551033;-1.147211;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
to know the minimum norm solution we keep one intercept column and do;3.3209202;1.0379957;-0.4092289;-3.5728226;-3.0902772;3.4579558;CODE
not divide by 2 later on we must take special care;-1.4001645;2.9116085;2.841695;0.40954185;2.1187434;-1.1711473;-
the newton solvers should warn and automatically fallback to lbfgs;1.8770282;-1.1335224;-3.9977853;4.6065164;-3.4512017;1.6620079;IRRE
in this case the model should still converge;2.189876;3.637419;1.2960097;4.796229;-2.7847066;1.3822961;CODE
xxx investigate if the convergencewarning that can appear in some;1.2727437;1.7242587;0.015005522;4.012463;-1.1045281;0.029877588;-
cases should be considered a bug or not in the mean time we don t;-2.5388265;1.5351458;-1.7591748;4.779827;1.5209954;-0.07357223;CODE
fail when the assertions below pass irrespective of the presence of;-0.45718715;8.17968;-3.1757724;6.158137;1.3514302;-2.2008224;CODE
the warning;-3.2763915;-0.46750727;2.1475651;3.7481413;-1.3377142;-1.8589813;-
here we take special care;-3.712568;-0.3751544;3.3912113;1.0112919;0.6166729;-0.5971771;-
model coef 2 model coef 1 exclude the other intercept term;0.16498506;2.7663372;-2.3873785;0.18235964;-1.3336916;2.3146868;CODE
for minimum norm solution we would have;2.2133994;1.494416;-0.011291112;-2.259801;-1.1126171;3.8609266;CODE
assert model intercept pytest approx model coef 1;2.1374755;2.5445516;-5.5386806;3.7513878;-3.5363417;0.7094362;CODE
as it is an underdetermined problem prediction y the following shows that;4.258339;-0.71576744;-0.5064173;1.0891868;-0.043309774;0.80214703;-
we get a solution i e a non unique minimum of the objective function;1.7178962;1.2628534;-0.35141382;-1.160369;0.93083245;3.2966948;CODE
same as in test glm regression unpenalized;0.85067934;0.78765625;-0.19922912;4.3652964;-1.6316208;0.39692956;IRRE
but it is not the minimum norm solution otherwise the norms would be;1.2245442;1.7501714;-0.8931536;-2.2431679;-0.9761704;4.471432;IRRE
equal;-0.672778;2.152373;4.7423453;0.36144674;1.098367;-5.7088175;-
for minimum norm solution we would have;2.2133994;1.494416;-0.011291112;-2.259801;-1.1126171;3.8609266;CODE
assert model intercept pytest approx model coef 1;2.1374755;2.5445516;-5.5386806;3.7513878;-3.5363417;0.7094362;CODE
alpha 0 unpenalized;-4.8876753;0.1125411;-2.1910002;-0.27482924;-1.7551033;-1.147211;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
the newton solvers should warn and automatically fallback to lbfgs;1.8770282;-1.1335224;-3.9977853;4.6065164;-3.4512017;1.6620079;IRRE
in this case the model should still converge;2.189876;3.637419;1.2960097;4.796229;-2.7847066;1.3822961;CODE
xxx investigate if the convergencewarning that can appear in some;1.2727437;1.7242587;0.015005522;4.012463;-1.1045281;0.029877588;-
cases should be considered a bug or not in the mean time we don t;-2.5388265;1.5351458;-1.7591748;4.779827;1.5209954;-0.07357223;CODE
fail when the assertions below pass irrespective of the presence of;-0.45718715;8.17968;-3.1757724;6.158137;1.3514302;-2.2008224;CODE
the warning;-3.2763915;-0.46750727;2.1475651;3.7481413;-1.3377142;-1.8589813;-
as it is an underdetermined problem prediction y the following shows that;4.258339;-0.71576744;-0.5064173;1.0891868;-0.043309774;0.80214703;-
we get a solution i e a non unique minimum of the objective function;1.7178962;1.2628534;-0.35141382;-1.160369;0.93083245;3.2966948;CODE
xxx this solver shows random behaviour sometimes it finds solutions;-2.5685356;3.1382537;-2.3701742;0.4397091;-2.628338;-1.4951454;IRRE
with norm model norm solution so we check conditionally;0.82193196;3.652508;-0.49993598;1.3780272;-0.20421523;2.1511562;-
same as in test glm regression unpenalized;0.85067934;0.78765625;-0.19922912;4.3652964;-1.6316208;0.39692956;IRRE
but it is not the minimum norm solution otherwise the norms would be;1.2245442;1.7501714;-0.8931536;-2.2431679;-0.9761704;4.471432;IRRE
equal;-0.672778;2.152373;4.7423453;0.36144674;1.098367;-5.7088175;-
y np abs y poisson requires non negative targets;0.31908002;2.4749808;-2.4668753;-0.13415587;-3.3971765;1.7899132;CODE
as we intentionally set max iter 1 such that the solver should raise a;-0.8058246;3.4563515;-1.9237875;0.67269814;-2.0169728;0.5176408;CODE
convergencewarning;2.642272;-0.37466958;1.6840618;5.241669;-2.1976569;1.7515508;-
the two models are not exactly identical since the lbfgs solver;2.000593;-1.607364;-3.9234064;2.0501204;-1.1910219;1.808906;TASK
computes the approximate hessian from previous iterations which;3.0913777;-1.134305;-1.5475203;0.31809086;-3.8147795;2.6172798;IRRE
will not be strictly identical in the case of a warm start;-1.6503425;2.5287335;1.8281754;3.0935028;0.119669594;0.4139334;CODE
library glmnet;1.7435246;-6.3789;-0.77504534;-0.73447734;-2.475978;0.6637523;CODE
options digits 10;-1.1813027;0.89560837;2.9125817;-2.7862477;1.688684;-4.1414394;-
df data frame a c 2 1 1 2 b c 0 0 1 1 y c 0 1 1 2;3.1823194;0.76449615;0.50513875;-7.336538;-2.787567;-1.6275281;-
x data matrix df c a b;4.5723047;0.46776718;-0.40215677;-6.7947726;-1.5805168;0.84090775;-
y df y;-0.58565485;-1.4634933;2.9284792;-1.4153535;-3.7086473;-1.587876;-
fit glmnet x x y y alpha 0 intercept t family poisson;1.6260792;1.8747764;-1.8361892;-2.1652207;-4.1037493;3.383131;CODE
standardize f thresh 1e 10 nlambda 10000;-0.10564424;0.7774783;-2.7739608;-3.6451297;-0.020250168;1.8314484;CODE
coef fit s 1;1.7265074;-0.9201445;-1.2122482;0.028096084;0.10178501;0.9354578;-
intercept 0 12889386979;-1.4672192;2.8157976;-1.1960222;-4.3508067;-3.0707126;-2.674546;CODE
a 0 29019207995;-3.1345968;1.6074426;0.37414855;-4.5206804;0.013179575;-4.208772;-
b 0 03741173122;-3.857755;-0.84692043;0.45215237;-5.776245;1.5586597;-5.012349;-
y np array 0 1 0 5 in range of all distributions;3.961048;1.5231538;-1.2734596;-6.40696;-3.0829265;-1.2443836;META
use at least 20 samples to reduce the likelihood of getting a degenerate;4.9072084;2.9034288;-0.6303688;2.4144714;2.819892;-0.88903636;CODE
dataset for any global random seed;5.0643244;-4.581772;0.9169444;0.02185214;2.1255233;-0.008782312;IRRE
collinear variation of the same input features;5.1951;-0.38846287;0.64239055;-2.1035147;0.8160299;1.8378617;CODE
let s consider the deviance of a constant baseline on this problem;-0.053908054;3.6318877;1.1570374;1.7719867;-0.49972284;-0.24762383;CODE
no warning raised on well conditioned design even without regularization;0.4646151;2.138995;-5.8750257;5.4731374;0.061271336;4.760556;CODE
on this dataset we should have enough data points to not make it;5.788542;-0.34195122;-0.26006424;-0.052284982;0.21840325;0.44734794;CODE
possible to get a near zero deviance for the any of the admissible;-2.653094;3.0326092;-2.0745342;-0.4421942;1.6512176;0.81662804;CODE
random seeds this will make it easier to interpret meaning of rtol in;-2.2340667;-2.1107624;1.5356537;2.0067844;2.0224457;-2.31353;CODE
the subsequent assertions;-1.2435495;1.984302;1.2734815;5.279989;2.9509084;-1.5599071;CODE
we check that the model could successfully fit information in x orig to;1.3369788;-1.67822;-2.493474;0.06535643;2.0911968;2.9420094;CODE
improve upon the constant baseline by a large margin when evaluated on;5.3693194;1.602374;0.14156574;3.188024;0.2189896;1.2049832;CODE
the traing set;-0.53667504;-1.273474;5.2456617;0.7525198;2.1085546;-0.96424085;IRRE
lbfgs is robust to a collinear design because its approximation of the;4.716501;-0.74889165;-2.8023505;0.011536124;-1.9299214;4.330543;-
hessian is symmeric positive definite by construction let s record its;-1.1668195;-2.047229;-2.500558;-1.7594663;0.6514222;2.0758893;CODE
solution;-3.4635136;1.2015494;5.2439394;0.13359228;0.30726975;-4.005283;-
the lbfgs solution on the collinear is expected to reach a comparable;3.5278277;1.2574279;-1.9762957;-1.4487162;-4.3223066;2.9921227;-
solution to the newton solution on the original data;3.8363297;-0.40880567;-0.64830875;-1.3382443;-4.291887;1.5536622;CODE
fitting a newton solver on the collinear version of the training data;5.205292;-2.8940494;-2.6484516;0.51601297;-3.4199715;2.4745948;META
without regularization should raise an informative warning and fallback;1.6231968;-0.081562646;-3.5580585;5.7498593;1.5130506;3.1569948;CODE
to the lbfgs solver;2.575499;-2.3570662;-1.3711818;0.7330658;0.29002753;-0.94077957;-
as a result we should still automatically converge to a good solution;0.7786678;-0.31077167;0.68342835;4.7931223;-1.6871009;1.2599736;IRRE
increasing the regularization slightly should make the problem go away;1.3641983;1.7227008;-4.271593;0.92674994;-2.9255264;6.5112805;-
the slightly penalized model on the collinear data should be close enough;4.859036;0.31588253;-1.2291975;0.9929108;-1.8673487;3.3912969;CODE
to the unpenalized model on the original data;3.8609302;-1.9288454;1.0115786;2.8789067;1.7396505;2.9174688;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
calculate the values where y x w c sigma epsilon;2.0866263;1.7296109;-1.4284931;-2.5483346;-2.1204891;-1.0192376;IRRE
the values above this threshold are outliers;4.438819;2.4247391;-1.2084918;-1.0257158;-1.9336908;-2.0679593;IRRE
calculate the linear loss due to the outliers;4.7860365;1.1084697;0.082243495;-1.9669691;-2.9235773;1.4482423;-
this is equal to 2 m y x w c sigma m 2 sigma;1.4871101;1.3214896;-0.47491378;-4.8582315;0.5523552;-1.0513461;CODE
n sq outliers includes the weight give to the outliers while;3.6965683;1.0676388;-1.470661;-1.3309834;-0.6731518;1.4879144;CODE
num outliers is just the number of outliers;3.3487093;0.10575501;-0.4637947;-1.1080995;-0.44548884;-0.31059083;-
calculate the quadratic loss due to the non outliers;3.5628476;1.0839646;-0.8563357;-1.5309118;-3.0018978;2.0063486;-
this is equal to y x w c 2 sigma 2 sigma;0.38488823;0.89257854;-1.0293219;-4.278033;-0.15559861;-0.88054454;CODE
gradient due to the squared loss;0.8162702;-1.8522005;0.92857903;-0.5611573;-1.9911367;3.3306246;-
gradient due to the linear loss;1.7322115;-1.6500087;0.7231993;-1.0182436;-1.4302545;3.7272217;-
gradient due to the penalty;1.5656258;-0.52665764;0.29429922;0.6909879;-1.1057693;4.8268847;-
gradient due to sigma;2.4690344;-1.0416877;-0.30398563;-0.5246851;-0.27940938;3.399628;-
gradient due to the intercept;-0.5071056;-0.33437017;1.8180803;-1.4681903;-2.504877;2.70911;CODE
make sure to initialize the scale parameter to a strictly;-0.37439907;4.187907;-1.3507704;-1.0316354;-5.4312143;3.8421605;IRRE
positive value;-1.4694424;3.8093917;2.8727725;-1.6198933;-1.2128701;-5.944077;IRRE
sigma or the scale factor should be non negative;1.6268468;4.3357987;-0.60679483;-2.028525;-2.5175707;0.10376887;-
setting it to be zero might cause undefined bounds hence we set it;-3.3213398;4.932129;-1.4330945;-2.488011;-3.8204477;-0.81719273;IRRE
to a value close to zero;1.078476;4.706048;2.444239;-2.759368;-2.4313457;-3.7531912;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
mypy error module sklearn utils has no attribute arrayfuncs;-0.55107635;-1.7383772;-6.870378;-2.141152;-5.304331;-2.2735825;META
force copy setting the array to be fortran ordered;0.8388989;3.1213655;-1.5578035;-2.695328;-2.7025905;0.49871713;CODE
speeds up the calculation of the partial gram matrix;4.015129;-1.9593492;-2.254443;-2.6203685;-1.551789;1.9371964;-
and allows to easily swap columns;-0.45174295;-2.9352283;4.089155;-3.5856018;2.6973746;2.3244925;-
use the precision level of input data if it is consistent;5.632927;4.4390883;-0.9181031;-0.75163114;-1.3123808;-1.5150143;IRRE
fallback to double precision otherwise;2.4131033;3.8835237;-2.9626439;0.7962999;-1.4158833;-0.24769428;CODE
above better ideas;-1.8707378;-2.6669996;5.870534;2.8596292;1.4418741;-0.3628813;-
holds the sign of covariance;-1.0373143;0.8041904;-0.25399166;0.7927888;-1.5710466;3.4102075;CODE
will hold the cholesky factorization only lower part is;1.5725912;-0.13501929;-2.6286066;-1.9295303;-0.16436559;4.531164;CODE
referenced;-3.340789;-3.2170718;4.6792493;2.3726883;1.1131933;-1.5868682;CODE
tiny32 np finfo np float32 tiny to avoid division by 0 warning;-1.112684;2.2500567;-4.917224;-3.8587108;-3.1592484;-1.4742212;CODE
if alpha 0 alpha min equality tolerance early stopping;0.0071745794;3.802471;-1.4163337;2.7145162;-0.9552278;1.4992522;-
interpolation factor 0 ss 1;2.1236339;3.1220224;-2.3714812;-5.3592296;-2.2530441;0.057193533;CODE
in the first iteration all alphas are zero the formula;0.67976683;3.6618664;-0.6672538;-3.1540322;-3.3424602;-2.8283262;CODE
below would make ss a nan;0.67496204;1.2970742;0.45546263;-3.643199;0.23492265;-3.5792131;-
append x j to the cholesky factorization of xa xa;0.6743774;-0.25131118;-2.1815903;-3.919252;-0.61912984;4.4150553;CODE
l 0;-2.0350406;1.7228789;4.227051;-2.7588475;0.055277992;-2.9647932;-
l where l w xa x j;-2.461895;1.240588;3.048703;-2.206452;1.9455028;-0.37962034;-
w z and z x j;-1.9721391;1.8099608;4.3647833;-4.7256246;1.8092031;-2.4756296;-
cov cov 1 remove cov 0;-1.5649254;2.7047951;-1.1053057;-2.8806615;-2.1431308;0.13120209;-
swap does only work inplace if matrix is fortran;-0.62790096;2.2391882;-3.0792983;-4.72392;-3.878144;0.8964525;CODE
contiguous;0.79755783;2.2487147;5.957217;-3.53925;2.9711454;-1.4591527;-
update the cholesky decomposition for the gram matrix;1.0964658;-2.381294;-3.6762893;-3.7463467;-2.0464125;2.7677467;CODE
the system is becoming too ill conditioned;-0.42425323;3.512276;1.8975071;4.3334246;-2.0464864;0.13511425;CODE
we have degenerate vectors in our active set;1.8181996;0.1578378;-0.12971166;-2.4199219;3.260595;3.4036427;IRRE
we ll drop for good the last regressor added;-0.67247355;1.4541683;1.5424942;1.2721463;-1.339422;0.8128122;TASK
xxx need to figure a drop for good way;0.11805713;2.7854674;5.3071337;-1.8997148;-1.618626;-1.0582733;CODE
alpha is increasing this is because the updates of cov are;-1.246822;-0.097376995;0.0004866359;0.21840475;-3.7128675;0.98077524;CODE
bringing in too much numerical error that is greater than;3.3771741;4.6634774;-2.4522173;1.0369438;-2.8968651;-2.3740683;CODE
than the remaining correlation with the;2.4710414;2.1957102;3.348986;-0.16488189;-1.9650235;-1.96869;CODE
regressors time to bail out;0.120998055;1.7025214;1.0184718;2.040382;-2.4281237;1.420957;-
least squares solution;3.871021;-0.38678017;0.47671524;-2.4004068;-3.027353;2.3993692;-
this happens because sign active n active 0;-5.3729687;2.7163994;-1.0503803;-2.4496677;-1.2661555;-1.0550631;CODE
is this really needed;-2.3083732;-1.9086058;4.4859567;2.596407;-0.10454338;1.2505885;CODE
l is too ill conditioned;-1.0264764;4.300731;1.8601869;3.2314954;-0.17842203;-0.33938563;-
equiangular direction of variables in the active set;0.9741105;1.4691348;1.1892295;-3.4680643;1.0643902;3.7464676;IRRE
correlation between each unactive variables and;2.4980953;1.9488307;1.8667619;-1.8825867;1.5299485;-0.2905559;IRRE
eqiangular vector;1.2158654;0.22057411;-0.2720235;-6.6464095;-1.7165228;2.3838277;-
if huge number of features this takes 50 of time i;2.019351;-3.964462;2.1642663;2.2426908;2.257214;1.43214;TASK
think could be avoided if we just update it using an;-3.176461;-1.3826936;1.2357546;5.5053;0.43785417;1.8009818;CODE
orthogonal qr decomposition of x;-1.0438694;0.6891145;-0.827599;-5.0647216;-0.023882415;4.9883347;-
explicit rounding can be necessary to avoid np argmax cov yielding;4.206259;0.08341602;-3.876346;-3.5654888;-3.6532671;2.4604838;CODE
unstable results because of rounding errors;4.435318;4.17341;-3.181682;0.72509414;-5.896768;-2.4749475;IRRE
todo better names for these variables z;-0.7386224;1.3990862;2.1532094;-3.6766686;2.5747957;-2.3708267;CODE
some coefficients have changed sign;-1.3566905;2.3560014;-1.7906104;-3.07479;-4.105754;0.25630277;-
update the sign important for lar;-4.0578804;1.1747463;1.2390896;-1.4530963;-0.48906702;-0.2975941;CODE
resize the coefs and alphas array;1.5771497;1.406682;0.051558904;-3.976472;-2.8183348;2.1395357;-
mimic the effect of incrementing n iter on the array references;1.5500478;2.3531966;0.82094425;-1.9455234;1.2167346;-0.92392224;CODE
update correlations;2.7987313;-0.41551647;1.8883029;0.15303713;0.0036271184;0.57622135;CODE
see if any coefficient has changed sign;0.5770593;4.0172067;-0.0033114615;-1.1316918;-2.0710027;-2.0434823;-
handle the case when idx is not length of 1;-1.52014;6.196258;-0.8772393;-3.0737832;3.8531141;-0.23159505;CODE
handle the case when idx is not length of 1;-1.52014;6.196258;-0.8772393;-3.0737832;3.8531141;-0.23159505;CODE
propagate dropped variable;-1.9604249;2.6607373;-1.2789358;1.3815036;-1.7024089;1.9411913;IRRE
yeah this is stupid;-2.810756;-0.2931833;2.4887083;0.97005403;-0.97063035;0.372359;CODE
todo this could be updated;-4.5344095;-3.0212705;2.0441391;2.7950692;-0.8895896;0.44493544;CODE
cov n cov j x j x increment betas todo;-0.24812089;0.017193684;1.5609288;-1.868378;0.8398109;-2.7074008;TASK
will this still work with multiple drops;-2.12459;1.4162667;2.0017405;2.491474;1.32279;2.278027;TASK
recompute covariance probably could be done better;3.6600416;-1.1722953;-2.200575;4.8631673;-0.91665626;4.274729;CODE
wrong as xy is not swapped with the rest of variables;-2.7721045;2.5560873;-0.57718325;-4.674833;-3.3096943;-1.5146825;IRRE
todo this could be updated;-4.5344095;-3.0212705;2.0441391;2.7950692;-0.8895896;0.44493544;CODE
ign active np append sign active 0 0 just to maintain size;-4.4326105;1.9428284;-0.62982506;-2.6887276;-2.1807659;1.5780444;CODE
resize coefs in case of early stop;0.9253327;2.6954315;0.9108606;1.4610912;-1.2601988;4.1308494;CODE
estimator classes;3.2407925;-1.597892;-0.02509517;3.061484;1.8668847;2.053277;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
grad pointwise shape n samples n classes;6.3700876;-2.6655853;-0.93854374;-3.9599295;2.5130923;0.6288589;CODE
gradient shape n samples n classes;6.2196045;-2.9673555;0.47294784;-4.064193;2.958317;1.5691463;IRRE
allocate gradient;2.338059;-0.8157002;1.5443801;-1.9782306;-1.2720907;5.6809354;-
allocate hessian;0.9258603;-1.1359401;-1.490907;-1.4269807;-2.2719233;4.6271696;-
n coef size for multinomial this equals n dof n classes;2.7184725;-0.70430744;-1.7570988;-2.919217;4.508071;-1.3755566;CODE
for non canonical link functions and far away from the optimum the;0.1818273;-0.7384784;0.0078806365;-0.5846071;2.3578522;5.230436;CODE
pointwise hessian can be negative we take care that 75 of the hessian;1.0766505;0.43282378;-1.9281539;-1.1953896;-3.7398074;1.8219801;CODE
entries are positive;0.30473286;4.553204;0.9137296;-1.0387515;1.1379662;-5.9318213;-
exit early without computing the hessian;0.48420224;0.4284269;-0.1749317;1.8856763;-3.1778183;2.5641522;-
the l2 penalty enters the hessian on the diagonal only to add those;0.3927395;-0.9044929;-2.7816355;-0.98012185;-1.7579849;5.1576405;TASK
terms we use a flattened view of the array;2.2529035;-0.3132365;3.7031918;-3.075799;1.4388669;2.2213361;-
with intercept included as added column to x the hessian becomes;-0.21548066;-0.024608335;-1.9922235;-3.297915;-4.690922;3.5943239;CODE
hess x 1 diag h x 1;0.20863846;0.08594038;-1.9658531;-4.493217;-1.8916051;2.4108639;-
x diag h x x h;-1.7217698;0.20224561;1.9894971;-3.771838;1.4999206;-1.4211173;-
h x sum h;-1.9879295;0.017469922;3.5154696;-3.7271118;0.16306737;-2.0508516;-
the left upper part has already been filled it remains to compute;-2.0128863;2.8624327;2.5301182;-2.0110059;-1.4849731;-1.7208201;CODE
the last row and the last column;-0.3620181;1.9646397;5.280578;-4.6045403;0.2540343;-3.0546327;-
here we may safely assume halfmultinomialloss aka categorical;-0.32676357;-0.29094073;0.32929963;0.31694493;2.750598;-2.435328;-
cross entropy;1.9531684;-1.5149857;1.3503629;-1.2302281;1.7094232;-0.5818726;-
halfmultinomialloss computes only the diagonal part of the hessian i e;0.030867694;-0.8991567;-3.1823213;-3.6931076;-3.072174;2.9998314;-
diagonal in the classes here we want the full hessian therefore we;0.2617008;-2.2778745;-1.9100403;-2.5233278;-0.14717507;3.945784;CODE
call gradient proba;2.1826427;-0.7948413;0.7464931;-0.31758672;0.22721824;2.0398214;IRRE
the full hessian matrix i e not only the diagonal part dropping most;2.1977022;-1.171581;-1.187891;-1.3148932;-3.759157;2.96495;-
indices is given by;1.7130694;1.913686;0.47901732;-6.301046;0.8238768;-3.6404676;-
hess x h x;-0.62835443;-1.0060132;0.23783669;-2.5953727;-1.4421703;1.0859989;-
here h is a priori a 4 dimensional matrix of shape;2.221538;-0.020331701;2.98702;-7.960283;-0.30169305;1.4694387;-
n samples n samples n classes n classes it is diagonal its first;2.9465468;-1.0558505;-0.2532282;-3.8537111;3.932933;-1.3594784;IRRE
two dimensions the ones with n samples i e it is;3.6287818;0.07372617;1.4022812;-6.594562;1.0277486;-1.393517;-
effectively a 3 dimensional matrix n samples n classes n classes;7.098318;-3.1187017;-0.69413847;-4.703829;4.8648486;1.2194546;IRRE
h diag p p p;-3.0999906;-0.21259217;2.4440937;-1.1278667;1.5657469;-0.4923944;-
or with indices k and l for classes;3.9603412;-1.4399312;-0.88280743;-3.1000443;6.5254154;-2.125868;CODE
h kl p k delta kl p k p l;-2.0323193;-0.17701054;2.0287638;-1.5461432;1.84127;-0.8758078;-
with p k the predicted probability for class k only the dimension in;3.9151225;-2.1423872;-0.94433266;0.15409759;2.4456713;1.6149083;CODE
n samples multiplies with x;4.002372;2.5082476;1.4881439;-5.7949004;0.28437516;-2.119229;META
for 3 classes and n samples 1 this looks like is a bit misused;1.2537184;-1.5247548;-2.8223855;0.28474584;4.883034;-1.9265041;CODE
here;-3.1311445;-2.971849;4.6706944;0.6372306;-0.5145004;-1.7063813;-
hess x h00 h10 h20 x;-0.7475303;-0.07201479;-1.5496006;-4.5113807;-0.99915147;1.7411286;-
h10 h11 h12;-3.8968477;-1.3473297;1.6257895;-3.0479312;1.6765659;-1.5509346;-
h20 h12 h22;-4.36417;-0.6995968;1.5027055;-2.4262097;1.2830434;-1.2073966;-
x diag h00 x x diag h10 x diag h20;-1.101119;0.8682002;0.61103606;-6.15006;3.777795;-2.5748713;-
x diag h10 x x diag h11 x diag h12;-1.294805;-0.1376972;1.0010456;-6.265513;3.3970323;-2.4829903;-
x diag h20 x x diag h12 x diag h22;-1.9219635;0.4949768;0.7733464;-5.892073;3.2735493;-2.0228016;-
now coef of shape n classes n dof is contiguous in n classes;2.332636;-0.52240753;-0.27918082;-3.0504937;2.4119942;1.3600225;CODE
therefore we want the hessian to follow this convention too i e;-1.8502821;-1.9328494;-1.5867132;-0.41977665;-1.8841226;4.9176955;CODE
hess n classes n classes x0 h00 x0 x0 h10 x0;1.4245938;-2.303395;-3.606199;-3.711537;1.9278886;1.3272591;IRRE
x0 h10 x0 x0 h11 x0;-3.3922598;-0.22132349;1.419829;-5.585538;1.5043168;0.8429366;-
x0 h20 x0 x0 h12 x0;-3.2940342;0.2610684;1.733229;-5.610906;1.8983184;0.1581207;-
is the first feature x0 for all classes in our implementation we;-1.3795016;-3.8288324;-1.4583527;0.676912;4.394514;1.0240626;TASK
still want to take advantage of blas x t x therefore we have some;-2.4783862;-0.022234386;1.278585;-0.45005482;1.452105;2.2039437;TASK
index slicing battle to fight;0.12881145;0.057627324;0.6162405;-0.2517531;1.9511201;0.3749617;CODE
diagonal terms in classes hess kk;0.65460247;-3.101514;-3.7066226;-3.457682;0.3791829;2.4700086;IRRE
note that this also writes to some of the lower triangular part;-3.2003856;-0.5488052;2.1906645;-4.3546686;-0.06385701;0.8679879;TASK
see above in the non multiclass case;-2.7403512;-2.4006226;-2.003142;-0.5869244;6.1800537;2.6402664;CODE
off diagonal terms in classes hess kl;0.53695637;-2.2044895;-4.0995064;-3.0313256;0.37526932;4.505793;IRRE
upper triangle in classes;-0.4061075;-0.000839447;1.8538667;-3.1625893;2.6017663;-1.5277678;IRRE
fill lower triangle in classes;1.2804066;0.7674187;2.6056383;-3.6154737;2.6729543;-0.5888569;IRRE
see above in the non multiclass case;-2.7403512;-2.4006226;-2.003142;-0.5869244;6.1800537;2.6402664;CODE
the pointwise hessian is always non negative for the multinomial loss;1.2793766;-0.55288744;-3.3498256;-1.4580226;-2.189118;3.6269197;CODE
precompute as much as possible hx hx sum and hessian sum;2.8320563;-3.6745925;-1.4636427;-1.9377913;-1.0915489;2.1383798;-
calculate the double derivative with respect to intercept;-2.7448156;-0.305644;1.9950155;-1.8791622;-3.2599273;0.6232683;CODE
note in case hx is sparse hx sum is a matrix object;2.2449713;-0.15971644;-3.8496358;-4.5490346;-0.18152583;4.508306;IRRE
prevent squeezing to zero dim array if n features 1;4.5003653;3.5058978;-2.6898372;-3.0820007;-0.2985785;1.9166921;TASK
with intercept included and l2 reg strength 0 hessp returns;1.2258248;1.308461;-3.80152;-1.0747588;-2.9719455;1.6466354;CODE
res x 1 diag h x 1 s;-1.4237163;1.2227619;1.3903188;-6.802194;0.51676387;-1.1091548;-
x 1 hx s n features sum h s 1;3.258721;-1.4743509;-0.37603152;-6.1413345;2.9801085;-0.20461832;TASK
res n features x hx s n features sum h s 1;2.8645742;-2.0737286;-0.35618344;-5.1097198;2.9665027;-0.14888392;TASK
res 1 1 hx s n features sum h s 1;2.791705;-1.9383397;-0.6997382;-5.8846536;2.648724;-0.4048397;TASK
here we may safely assume halfmultinomialloss aka categorical;-0.32676357;-0.29094085;0.3292989;0.31694472;2.7505987;-2.4353275;-
cross entropy;1.9531684;-1.5149857;1.3503629;-1.2302281;1.7094232;-0.5818726;-
halfmultinomialloss computes only the diagonal part of the hessian i e;0.03086841;-0.8991565;-3.182323;-3.6931071;-3.0721738;2.9998317;-
diagonal in the classes here we want the matrix vector product of the;-0.8203023;-2.6748867;0.057748817;-5.1774745;1.7922293;0.4680638;CODE
full hessian therefore we call gradient proba;-0.5390047;-2.4512422;-0.17592636;-0.6057158;-0.03199866;2.9324908;IRRE
full hessian vector product i e not only the diagonal part of the;-0.82162505;-2.6773014;-0.90536433;-3.4329648;-2.271866;2.5055766;-
hessian derivation with some index battle for input vector s;0.7234844;-3.3723662;-3.5263956;-1.0590146;-1.1358123;3.394249;CODE
sample index i;4.1697035;1.3844082;2.5957458;-1.5336434;3.1900632;-3.0731564;-
feature indices j m;2.441451;-1.2056211;0.6196016;-4.1708817;2.031906;-2.01081;TASK
class indices k l;2.1462626;-1.4255579;-0.32211876;-3.0483186;4.103618;-1.9316655;IRRE
1 k l is one if k l else 0;-0.57264364;2.6022782;1.6437461;-2.5279157;2.0260131;-3.6891255;-
p i k is the predicted probability that sample i belongs to class k;3.3266299;-2.4562738;0.495879;2.146333;3.4316852;-2.2353287;IRRE
for all i sum k p i k 1;-0.08388396;-0.38545707;2.9410446;-2.5988076;0.8176864;-2.7372408;CODE
s l m is input vector for class l and feature m;2.343682;-1.9435918;-2.0735915;-3.4586768;3.3006232;0.31336692;CODE
x x transposed;-0.9290828;1.4232452;3.45621;-5.516156;-1.539967;0.59411645;-
note hessian with dropping most indices is just;2.5005035;-0.4431999;-2.8485186;-0.80055535;-3.5503838;2.3540792;TASK
x p k 1 k l p l x;-1.4069148;1.6490211;2.0550005;-3.2026768;1.5038049;-2.331111;-
result k j sum i l m hessian i k j m l s l m;1.5977238;-1.3459389;-1.4945716;-2.6678886;-2.2371051;0.587266;IRRE
sum i l m x ji p i k 1 k l p i l;-0.14132775;1.0103673;1.6699594;-3.395684;0.5693194;-1.1180182;-
x im s l m;-1.6601484;0.37658444;2.843454;-1.331852;0.27802584;-0.12567252;-
sum i m x ji p i k;-0.16252536;0.37076616;1.9465932;-3.2000933;-0.06530126;-1.2542596;-
x im s k m sum l p i l x im s l m;-0.14283484;0.5950145;0.7216345;-3.0597064;1.0672277;-0.669037;-
see also https github com scikit learn scikit learn pull 3646 discussion r17461411;-2.237687;-11.248633;-5.6203613;-0.67625874;-3.5733788;-1.7709168;CODE
s reshape n classes 1 order f shape n classes n dof;3.3547354;-1.3734097;0.08884944;-5.637097;2.0774424;2.0243433;CODE
s 1 shape n classes n features;3.1257522;-3.8718565;-0.02493908;-4.3005376;4.532368;-0.61418015;TASK
tmp x s t s intercept x im s k m;1.3512645;0.62029576;0.66171;-5.097299;-1.8009938;-0.5360977;CODE
tmp proba tmp sum axis 1 np newaxis sum l;2.7469308;1.2886826;1.1144332;-6.6355033;-2.4467468;-0.63193905;CODE
tmp proba p i k;0.24951658;-0.5138137;1.4626564;-2.8602808;-0.30787858;-3.568771;CODE
hess prod empty like grad but we ravel grad below and this;-1.253578;-1.8104017;-2.993434;-0.49886876;-1.4845927;1.3430604;META
function is run after that;-4.6458564;3.992255;3.2672265;0.89501846;-2.4749308;-3.1476336;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
logistic regression;2.809552;-1.0302848;3.411831;1.2820225;0.3050766;-3.8180432;-
preprocessing;-1.4568691;-1.3095288;2.599795;1.609255;3.0133092;-0.8643697;-
halfbinomialloss used for those solvers represents y in 0 1 instead;-0.038169388;2.221999;-2.6077347;-5.634315;-4.6569576;-1.6631416;CODE
of in 1 1;-0.13529824;1.5685321;3.04659;-1.395946;1.2078874;-5.0498157;-
all solvers capable of a multinomial need labelencoder not labelbinarizer;0.87100077;-1.8708465;-4.8150387;-2.3073978;3.2412817;0.68509376;-
i e y as a 1d array of integers labelencoder also saves memory;1.1711979;0.68301886;-0.61987126;-5.0983043;0.2978868;0.15805131;CODE
compared to labelbinarizer especially when n classes is large;2.8647025;-3.7197087;-3.0396895;-0.091084026;5.4688396;-0.13496932;IRRE
it is important that w0 is f contiguous;-0.8909749;1.0771441;2.443206;-1.6671733;1.0086645;1.8677303;CODE
important note;-3.1498046;-2.5711458;3.9458148;1.5201327;-0.9893518;-1.0960561;CODE
all solvers relying on linearmodelloss need to scale the penalty with n samples;5.659791;0.12748998;-2.7521234;1.318313;-1.104742;3.899094;TASK
or the sum of sample weights because the implemented logistic regression;4.462133;-2.5691109;0.49688303;4.27786;1.9285342;1.6119726;TASK
objective here is unfortunately;-1.1650367;-2.1611855;2.0835087;1.784907;-0.44472975;0.049278095;CODE
c sum pointwise loss penalty;2.7359483;0.8018139;-1.2501943;-0.62749904;-1.7123235;2.4916902;CODE
instead of as linearmodelloss does;-1.0058953;0.0073016086;-0.046403416;-0.61231434;-0.17026898;2.8256495;CODE
mean pointwise loss 1 c penalty;1.9687662;1.6350372;-0.0095655685;-0.37463492;-2.2323263;2.0098834;CODE
this needs to be calculated after sample weight is multiplied by;3.9538968;3.5250714;0.07591956;-0.5409272;0.010597919;-0.0651025;TASK
class weight it is even tested that passing class weight is equivalent to;1.4633734;0.56052923;-2.5622833;4.5033517;2.268473;-0.24283293;IRRE
passing sample weights according to class weight;4.758298;0.6698465;-0.49197716;1.7461904;3.0548992;1.6147152;IRRE
hess loss gradient hessian product hess gradient hessp;-0.5521249;-3.4745376;-1.6553539;0.25224108;-1.3939028;2.9482906;-
else multinomial;1.0101109;1.8699147;3.3111188;-2.6362753;4.6583486;-4.555754;-
scipy optimize minimize and newton cg accept only ravelled parameters;3.6183646;-1.7965198;-4.847371;-1.6359664;-4.151693;1.9998635;IRRE
i e 1d arrays linearmodelloss expects classes to be contiguous and;2.8964345;1.9130557;-2.094178;-5.184789;-0.43940058;0.114771135;IRRE
reconstructs the 2d array via w0 reshape n classes 1 order f;2.8749545;0.4170569;-1.2034376;-7.189037;-0.6134331;2.2063577;CODE
as w0 is f contiguous ravel order f also avoids a copy;-1.4887118;2.955457;-0.8988483;-2.0313287;1.7975799;1.3700494;CODE
hess loss gradient hessian product hess gradient hessp;-0.5521249;-3.4745376;-1.6553539;0.25224108;-1.3939028;2.9482906;-
maxls 50 default is 20;-2.713847;1.3144656;0.4977457;-1.1365819;0.49129257;0.41577706;CODE
n iter i is an array for each class however target is always encoded;-1.1206138;2.4580445;-2.293214;-1.5198541;1.2291601;-0.9445473;CODE
in 1 1 so we only take the first element of n iter i;-1.6519139;2.2998555;1.4662997;-4.158033;1.762928;-3.3627698;-
alpha is for l2 norm beta is for l1 norm;-0.29144317;0.9430949;-1.8084928;-2.7512743;-0.7170068;1.4870907;CODE
else elastic net penalty;0.8536886;2.5245419;-0.4379268;1.5006894;-0.015363301;3.3291266;-
helper function for logisticcv;1.1977923;-0.7429281;-1.1859196;-1.3871375;-0.57940537;-1.7307798;CODE
note we pass classes for the whole dataset to avoid inconsistencies i e;5.201558;-3.0040176;-3.9693263;1.2317792;3.964818;0.44786692;CODE
different number of classes in different folds this way if a class is empty;1.0046078;1.805564;0.34743243;-0.11027628;4.7139273;-0.4599197;CODE
in a fold logistic regression path will initialize it to zero and not change;-0.626427;1.6611903;-2.5525422;0.57902724;-2.7198741;1.4886606;IRRE
the score method of logistic regression has a classes attribute;2.022838;-3.3969433;-2.2834444;1.1693603;3.0846841;-1.4830793;CODE
if self c 1 0 default values;-1.1253885;5.521087;-1.4538528;-1.3652653;-0.3761758;-2.8416967;IRRE
note that check for l1 ratio is done right above;2.360479;5.0383506;-2.4701006;-1.6279935;-2.6066918;-1.5014074;CODE
todo enable multi threading if benchmarks show a positive effect;1.2037915;0.21334837;-0.774194;5.815722;-0.44397548;2.4003396;CODE
see https github com scikit learn scikit learn issues 32162;-1.9175138;-10.762428;-6.925956;-0.7571746;-4.9176025;-4.4352713;CODE
encode for string labels;0.538832;-0.62890255;-0.45188662;-3.958012;2.4742486;-0.93808043;CODE
the original class labels;-0.5220908;-5.1341367;0.98175365;-0.5756009;5.880316;-0.659725;IRRE
init cross validation generator;-0.2904346;1.115008;-2.3603437;2.4087567;1.8598351;-1.430702;IRRE
compute the class weights for the entire dataset y;6.431653;-2.0192897;-0.90690213;-2.1462536;0.9143457;0.39513907;IRRE
the sag solver releases the gil so it s more efficient to use;0.78159803;-1.6769288;0.60783845;1.8802341;-1.9914957;2.3200088;-
threads for this solver;-0.42627528;-1.0519013;2.3128226;1.6939785;0.020912666;-2.032335;CODE
fold coefs is a list and would have shape n folds n l1 ratios;2.0561607;-0.049671937;1.2624111;-4.4050393;2.309122;-1.5077746;-
after reshaping;-1.6804299;0.2901338;4.378934;-1.491964;-2.101473;3.3914623;CODE
coefs paths is of shape n classes n folds n cs n l1 ratios n features;2.0584273;-3.1653483;-1.1468618;-2.7655005;2.2368896;0.74927455;TASK
scores is of shape n classes n folds n cs n l1 ratios;4.8745756;-1.2480922;0.44883758;-3.5456529;2.8388512;-3.2907467;IRRE
n iter is of shape 1 n folds n cs n l1 ratios;0.7710452;-0.14099206;1.9566609;-5.6394095;0.47041297;-1.590365;-
elf cs cs 0 the same for all folds and l1 ratios;-0.5967895;-0.038176853;-2.261338;-3.5627027;0.6221581;1.0418986;CODE
coefs paths shape n folds n l1 ratios n cs n features;2.8157525;-2.8490782;-0.5291166;-3.9803061;0.9649516;1.1058327;TASK
coefs paths shape n folds n l1 ratios n cs n classes n features;2.680627;-3.4343894;-1.1605873;-3.4424157;2.0554025;0.71888787;TASK
n iter shape n folds n l1 ratios n cs;1.8189363;-0.39443928;2.6827075;-5.967548;0.27895543;-1.2414421;-
scores shape n folds n l1 ratios n cs;4.866021;-0.3476172;1.6993482;-5.202734;1.3510724;-2.6395874;-
repeat same scores across all classes;3.5873468;0.47593987;2.1373022;1.3598809;4.967728;-2.097217;IRRE
all scores are the same across classes;2.2802403;0.17479943;-0.7979235;0.97939056;3.5335085;-3.2292626;IRRE
best index over folds;3.3828094;0.55421054;2.4421759;-2.5437965;1.4190185;2.0191517;-
cores sum scores sum axis 0 shape n cs n l1 ratios;5.448384;0.64681464;-1.1786536;-6.013273;-2.2123582;-0.52378845;-
note that y is label encoded;-1.8798696;-0.07255008;-0.6745958;-5.548157;-0.9454845;-1.9532253;TASK
take the best scores across every fold and the average of;5.661129;0.542235;4.107744;1.021759;1.174464;-2.413091;-
all coefficients corresponding to the best scores;5.6619797;0.31868723;1.1307172;-0.909123;1.7012637;-1.3473457;-
cores scores reshape n folds 1 n folds n cs n l1 ratios;5.3102527;-1.6832263;-0.96811926;-3.981625;-0.2610111;0.6739867;-
best indices np argmax scores axis 1 n folds;5.279234;-1.0725577;-0.4194005;-6.0973945;-1.7550122;1.3713417;-
best indices list zip best indices n folds 2;2.8869607;-0.23577073;-0.06490434;-3.7905524;1.0342494;-1.448282;-
each row of best indices has the 2 indices for cs and l1 ratios;4.6137137;2.0091553;-0.94126743;-5.3041244;1.0653954;0.023636952;CODE
if elasticnet was not used remove the l1 ratios dimension of some;2.3932576;1.4932278;-3.1190207;-0.9249192;-1.8893851;4.3314233;OUTD
attributes;0.2576558;-3.22067;3.3483093;0.8768757;4.9077525;-1.3673276;META
same for all classes;-1.8311901;-3.924445;0.78798443;2.8158038;3.167947;-0.12951647;CODE
newpaths shape n classes n folds n cs n l1 ratios n dof;1.8828068;-2.2277107;0.3118794;-3.3969355;1.883528;1.2503533;CODE
self coefs paths shape should be;-1.4806476;-0.75994754;0.060020737;-1.3396989;-1.6030374;2.906353;CODE
n folds n l1 ratios n cs n classes n dof;3.1109993;-1.5246432;-0.622629;-3.6353045;3.5137653;-1.3976973;CODE
newscores shape n folds n cs n l1 ratios;2.2962785;-0.6687445;0.88718665;-4.487777;0.60974365;1.1680235;CODE
self scores shape should be n folds n l1 ratios n cs;4.109472;0.23859866;0.6137998;-4.316222;0.62711436;-2.3802655;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo 1 10 remove;-4.2360096;2.7419758;3.1437685;-0.0066302237;-0.0970523;-1.9662911;TASK
for an explanation see;-2.3096898;-1.2320204;3.9647205;0.06587759;-1.5394181;-2.3351731;CODE
https github com scikit learn scikit learn pull 1259 issuecomment 9818044;-3.2390895;-8.225889;-7.6294374;-0.6277848;-5.570987;-4.1612153;CODE
todo 1 10 remove;-4.2360096;2.7419758;3.1437685;-0.0066302237;-0.0970523;-1.9662911;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
note that centering y and x with preprocess data does not work;1.0123043;1.5123459;0.9778518;-5.1156073;-5.84305;1.2952918;TASK
for quantile regression;2.703787;-0.95911485;3.1836288;0.37767822;-2.0738504;-0.0138392;CODE
the objective is defined as 1 n sum pinball loss alpha l1;2.8849862;-0.8629895;-0.061683305;0.123957396;1.64009;0.12659553;CODE
so we rescale the penalty term which is equivalent;0.31126976;1.6657048;1.6182486;2.1637242;0.4465083;4.527618;CODE
make default solver more stable;-0.92312014;1.2234501;-2.4432342;2.3404076;-3.456197;2.8062081;CODE
after rescaling alpha the minimization problem is;2.9392517;0.532917;-0.45877236;-1.9954165;-4.3067713;6.0728807;-
min sum pinball loss alpha l1;1.5850682;2.0734909;-0.43947834;-1.26096;-1.391862;0.3918231;-
use linear programming formulation of quantile regression;2.578757;-0.90673053;1.2807971;-0.836711;-0.26437113;2.1274364;CODE
min x c x;0.098684825;0.6117505;2.9859016;-3.509516;0.5634454;-1.624506;-
a eq x b eq;-2.6846287;3.0896971;2.627827;-2.983633;2.8442197;-1.5411779;-
0 x;-2.0428934;2.4329786;2.7228777;-5.37668;-0.7332196;-4.401444;-
x s0 s t0 t u v slack variables 0;-0.20361264;0.6086393;-2.1355865;-3.9210076;-1.2865422;-0.9000509;IRRE
intercept s0 t0;-0.9542156;1.0488082;0.6304425;-2.013201;-2.1965294;-0.32262456;CODE
coef s t;-0.32668597;-2.1735926;1.6003684;1.5357198;-0.9047503;-1.9873431;-
c 0 alpha 1 p 0 alpha 1 p quantile 1 n 1 quantile 1 n;0.44005457;2.79348;0.49473068;-6.6671453;0.39905626;-3.059194;-
residual y x coef intercept u v;-0.64675385;1.6293545;-0.07260943;-2.119508;-5.165334;2.206829;CODE
a eq 1 n x 1 n x diag 1 n diag 1 n;0.10903418;2.689383;0.6362822;-6.9386115;1.0357162;-2.3091884;-
b eq y;-2.5323493;0.990372;3.713388;-2.8882365;0.06344671;-2.2026422;-
p n features;3.1464684;-4.6844687;1.6136805;-1.9224745;4.474722;-0.20026548;TASK
n n samples;4.180982;-0.3763316;3.3108666;-2.5151005;2.6093395;-5.115188;-
1 n vector of length n with entries equal one;1.7348036;1.6208695;0.982173;-6.641229;1.8341498;-2.8130898;-
see https stats stackexchange com questions 384909;-1.1556385;-1.0004015;0.7452015;0.00041396118;-1.9019847;-3.32929;CODE
filtering out zero sample weights from the beginning makes life;5.329526;2.6251545;-1.9702929;2.4308972;-0.37336555;2.5819812;CODE
easier for the linprog solver;2.8484137;-1.8456855;-1.5789379;-0.28512496;0.8966283;0.8008379;CODE
n indices len indices use n mask instead of n samples;3.477819;1.9554842;-4.0812674;-5.839826;-0.8661924;-0.2749255;CODE
do not penalize the intercept;1.0609586;3.260342;0.19693257;0.99119157;-2.6985524;2.6757088;CODE
note that highs methods always use a sparse csc memory layout internally;1.8698475;-1.6847872;-2.3009017;0.9997366;0.84872144;3.5954175;TASK
even for optimization problems parametrized using dense numpy arrays;5.7708826;-1.0913966;-3.1371708;-3.8966484;-3.274264;1.7729337;CODE
therefore we work with csc matrices as early as possible to limit;3.2110271;-0.093868114;-1.2555268;-0.17274761;0.49038658;3.755609;CODE
unnecessary repeated memory copies;-0.20335433;1.1671923;0.17806742;1.5373125;1.7405543;0.09089691;IRRE
positive slack negative slack;0.7339144;0.8083222;0.35742617;-0.08251539;-1.6146839;-0.07889533;-
solution is an array with params pos params neg u v;-0.4328964;3.932402;0.77504605;-4.697198;0.04852173;-3.014858;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
ransacregressor estimator is not validated yet;-0.5545027;2.9145982;-6.238847;2.815327;-2.825332;1.7984982;TASK
need to validate separately here we can t pass multi output true;0.5110818;6.96942;-1.7047791;1.0882062;2.3841217;-4.5529084;TASK
because that would allow y to be csr delay expensive finiteness;-1.1985687;1.1363486;-2.5700815;1.0551655;-1.397495;2.2138305;IRRE
check to the estimator s own input validation;2.6643746;4.708904;-1.8539425;5.2212934;-1.4265198;-0.46731916;CODE
mad median absolute deviation;2.3084834;1.6058793;1.6262542;-1.9890622;-2.710193;1.0883846;-
try not all estimator accept a random state;1.2791996;4.560538;-1.9434392;3.209554;-1.9129804;2.9361396;IRRE
number of data samples;5.2350116;-0.21025135;1.611291;-1.1753883;2.4155781;-3.2247896;-
choose random sample set;4.7788334;0.44320765;3.5857768;0.887691;4.709904;-1.1459816;IRRE
check if random sample set is valid;4.665908;4.7525177;-1.4561492;3.7988462;2.907113;-5.2374473;IRRE
cut fit params down to subset idxs;4.035844;2.818992;-1.2373744;-2.7177587;3.1277523;3.9191318;IRRE
fit model for current random sample set;5.7617836;-0.45972902;0.8530044;2.6210413;1.4496155;1.7266908;IRRE
check if estimated model is valid;2.6790607;5.1954885;-2.9888184;5.954927;-1.3339747;-0.64400285;IRRE
residuals of all data for current random sample model;2.0103028;0.94948053;0.73787934;3.0458422;-1.8518031;2.3226788;IRRE
classify data into inliers and outliers;5.2653904;-1.8385382;1.9322933;-0.60335606;1.2465918;-0.40106815;CODE
less inliers skip current random sample;4.1902013;2.9725192;-1.127638;3.2013745;-1.6623406;1.3564032;IRRE
extract inlier data set;6.1642456;0.46248344;1.4621598;-2.166532;-0.22999646;-0.54217863;IRRE
cut fit params down to inlier idxs subset;5.2619705;3.1984308;-2.2161477;-1.5924262;1.2413886;4.277785;IRRE
score of inlier data set;5.3894987;1.715804;1.2811058;-1.1314361;-0.68753886;-2.36289;IRRE
same number of inliers but worse score skip current random;3.6530764;3.8177497;-0.79993945;2.5464473;-1.4017946;-0.7486516;IRRE
sample;1.7340889;-0.29218516;6.123778;1.5984565;2.6697383;-5.329025;-
save current random sample as best sample;3.5480878;1.3635647;1.7979858;4.084529;2.6090512;1.0070074;IRRE
break if sufficient number of inliers or score is reached;4.9542146;5.1658607;0.50753397;2.1748903;0.24304542;-2.6244164;CODE
if none of the iterations met the required criteria;3.868315;5.411432;0.7595069;2.2951603;2.1642468;-3.7023396;CODE
estimate final model using all inliers;4.7700896;1.8512974;0.32192242;3.0736065;-2.1909435;3.1241841;CODE
tags input tags sparse true default estimator is linearregression;2.4176323;0.10727466;-3.9279459;1.4411772;-1.2310631;4.8775544;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
kernel ridge;3.4968002;-3.8374374;0.69622636;-3.9051905;-2.1886346;4.5035996;-
w x t inv x x t alpha id y;-1.8907609;1.3958157;-0.365396;-5.0784273;3.5918877;-1.2969325;-
linear ridge;2.657139;-1.4096577;2.2047684;-5.4681964;-3.2545593;3.1919675;-
w inv x t x alpha id x t y;-2.2126234;1.4398264;-0.15005776;-5.103161;3.6953306;-1.1839484;-
no need to touch anything;-4.4586287;0.02242718;5.0808663;1.7675186;-3.467742;0.6066386;TASK
according to the lsqr documentation alpha damp 2;-3.4052913;0.6279608;-1.2148273;0.91910475;-0.4602698;2.907218;CODE
w inv x t x alpha id x t y;-2.2126234;1.4398264;-0.15005776;-5.103161;3.6953306;-1.1839484;-
dual coef inv x x t alpha id y;0.047486734;0.75420165;-3.8292148;-3.1062465;2.1199677;2.529868;-
unlike other solvers we need to support sample weight directly;5.0892773;0.46217975;-2.8868058;1.3240842;0.25900894;2.2275767;TASK
because k might be a pre computed kernel;0.83274686;-2.8046215;-2.9325042;-0.82753605;-1.5626256;1.7394702;-
only one penalty we can solve multi target problems in one time;1.3754234;1.3978109;1.8260778;3.362146;2.1970625;2.0868962;-
note we must use overwrite a false in order to be able to;-2.9821837;5.83145;-1.5928677;2.8292503;0.9303607;-0.033288702;TASK
use the fall back solution below in case a linalgerror;-1.223974;2.3766267;-0.6821762;-1.5545518;-2.3739486;2.8141427;IRRE
is raised;-2.4058323;-0.7176697;3.6481931;0.33711284;-0.41101578;-0.27748954;CODE
k is expensive to compute and store in memory so change it back in;0.1444756;-0.9067721;0.2974537;-0.93733054;-1.3159598;0.3979958;-
case it was user given;-4.143825;-0.17675848;1.8156835;1.5768181;1.2500329;-2.7213407;CODE
one penalty per target we need to solve each target separately;2.2041857;1.2858365;1.9066114;2.2017348;1.5876217;1.8277801;TASK
idx s 1e 15 same default value as scipy linalg pinv;-1.202563;0.15816014;-7.2151527;-4.5096164;-3.4694211;0.7752339;IRRE
sag supports sample weight directly for other solvers;3.3650312;-1.13549;-2.598708;1.5024596;-0.03495365;3.7147558;CODE
we implement sample weight via a simple rescaling;7.3793473;-2.1538892;1.194517;0.14551422;2.1583703;4.2221513;TASK
some callers of this method might pass alpha as single;-2.0303364;2.787887;-1.5816137;2.4458413;0.7676092;-0.33974054;IRRE
element array which already has been validated;0.07569742;7.0748963;-0.61036235;2.1750097;2.0217738;-2.1114345;CODE
there should be either 1 or n targets penalties;-1.1004431;2.4543076;1.5463051;1.1741611;1.1177325;0.052667037;-
use svd solver if matrix is singular;2.688463;1.0018487;-4.3929186;-2.7808418;-1.6930097;2.5748153;-
use svd solver if matrix is singular;2.688463;1.0018487;-4.3929186;-2.7808418;-1.6930097;2.5748153;-
precompute max squared sum for all targets;5.7703953;-1.0247046;-0.5022115;-1.4231331;-2.1108513;1.3833147;CODE
at the moment array api dispatch only supports the svd solver;0.38384378;-2.7760465;-4.8985033;-0.34057397;-1.2967739;3.2480307;CODE
sag supports fitting intercept directly;1.0144515;-0.5781194;-2.1235783;-0.63439876;-2.658491;5.4689555;CODE
when x is sparse we only remove offset from y;3.6129653;2.6535158;0.31980282;-3.6338751;-3.3627784;4.121588;IRRE
add the offset which was subtracted by preprocess data;2.795409;3.7132022;0.9572325;-2.4612756;-1.6951258;1.2099386;TASK
required to fit intercept with sparse cg and lbfgs solver;3.4568188;0.3186868;-4.6131907;-1.566199;-3.0988455;4.5218425;CODE
for dense matrices or when intercept is set to 0;2.8889818;2.3088439;-1.6505462;-3.4508746;-2.4062667;2.9290013;CODE
todo update this line to avoid calling convert to numpy;-0.19283733;1.5777954;-3.960016;-3.9256082;-7.572876;-1.1866945;CODE
once labelbinarizer has been updated to accept non numpy array api;-0.32437608;-1.3521328;-7.2849636;-2.139984;-2.6899405;1.0983036;CODE
compatible inputs;-0.06756991;-1.2394736;2.2197816;-2.7721543;1.5991657;-1.3008676;CODE
threshold such that the negative label is 1 and positive label;2.399485;2.864701;1.0436718;-2.9844203;2.7203553;-1.8905898;-
is 1 to use the inverse transform of the label binarizer fitted;1.7527254;1.8476052;-1.6974043;-4.6598606;-0.40308827;1.6307178;IRRE
during fit;0.307962;0.28348142;5.00618;3.3167274;-0.48551401;0.30728507;-
if x has more rows than columns use decomposition of x t x;3.743839;2.8590696;-0.060236823;-4.589208;0.06577227;0.20303886;-
otherwise x x t;-1.479408;1.3091724;2.120928;-1.3340954;-0.54264355;-0.016579427;-
if x is dense it has already been centered in preprocessing;-0.18752833;2.2348473;-0.34555292;-1.6114143;-2.5090065;2.1941023;CODE
to emulate centering x with sample weights;5.1274624;0.32681176;2.5561085;-1.5363189;-2.010695;4.974879;-
ie removing the weighted average we add a column;3.8087537;1.8461417;2.7821836;-1.9351568;-0.8249689;1.443822;TASK
containing the square roots of the sample weights;2.8596323;0.017868856;0.2679877;-0.77715605;-1.0254781;1.8646029;-
by centering it is orthogonal to the other columns;1.5622241;0.8956129;3.5015566;-6.5475373;-2.366563;3.7837062;-
the vector containing the square roots of the sample weights 1;2.942786;-1.3174002;-1.5206987;-3.178614;-2.0112655;1.9778198;-
when no sample weights is the eigenvector of xx t which;2.8146422;1.8528172;-3.1514707;-1.4183298;-0.73028266;3.950019;-
corresponds to the intercept we cancel the regularization on;1.1951611;0.43047872;-1.2907282;-1.3584486;-3.0242963;6.2038713;CODE
this dimension the corresponding eigenvalue is;-0.5713184;-0.116289414;-0.23992497;-4.2612944;-0.83818394;2.1838326;IRRE
sum sample weight;3.8982718;1.3292533;1.4253612;-0.010709968;0.4886259;-0.8531446;-
w intercept dim 0 cancel regularization for the intercept;0.92478657;1.4411206;-2.7404587;-3.3755517;-3.4544446;3.9340272;CODE
handle case where y is 2 d;-1.5774469;1.7962289;3.240206;-5.395861;0.31637552;-0.96669483;CODE
to emulate centering x with sample weights;5.127463;0.32681206;2.5561078;-1.536319;-2.010696;4.9748783;-
ie removing the weighted average we add a column;3.8087537;1.8461417;2.7821836;-1.9351568;-0.8249689;1.443822;TASK
containing the square roots of the sample weights;2.8596323;0.017868856;0.2679877;-0.77715605;-1.0254781;1.8646029;-
by centering it is orthogonal to the other columns;1.5622241;0.8956129;3.5015566;-6.5475373;-2.366563;3.7837062;-
when all samples have the same weight we add a column of 1;6.6941247;3.2793298;0.6041537;-2.3968198;1.9818246;-0.38852948;TASK
remove eigenvalues and vectors in the null space of x t x;0.10097617;1.8879309;-2.1065285;-3.4295373;-2.3947802;3.8919005;IRRE
handle case where y is 2 d;-1.5774469;1.7962289;3.240206;-5.395861;0.31637552;-0.96669483;CODE
the vector 0 0 0 1;-0.8618729;0.4430604;-1.012927;-6.599529;-0.86849767;-1.7009355;-
is the eigenvector of x tx which;-0.7754246;-1.8141208;-2.485764;-2.7129304;-1.0469955;3.0096846;-
corresponds to the intercept we cancel the regularization on;1.1951611;0.43047872;-1.2907282;-1.3584486;-3.0242963;6.2038713;CODE
this dimension the corresponding eigenvalue is;-0.5713184;-0.116289414;-0.23992497;-4.2612944;-0.83818394;2.1838326;IRRE
sum sample weight e g n when uniform sample weights;3.5811498;1.4952086;0.021113927;-0.6595365;1.1574125;1.2668256;CODE
add a column to x containing the square roots of sample weights;3.962644;0.49197465;0.5916024;-3.596428;-2.064226;2.1015532;TASK
return 1 hat diag y y hat;-1.1807119;3.3526323;1.2056569;-2.01064;-1.2995269;-0.7789689;IRRE
handle case where y is 2 d;-1.5774469;1.7962289;3.240206;-5.395861;0.31637552;-0.96669483;CODE
x already centered;-1.8076905;3.2013457;4.8951697;-4.1818066;-3.6213148;-0.0038374811;CODE
to emulate fit intercept true situation add a column;4.062051;3.0892382;1.1221894;-1.0747827;-1.7316024;1.1809641;TASK
containing the square roots of the sample weights;2.8596323;0.017868856;0.2679877;-0.77715605;-1.0254781;1.8646029;-
by centering the other columns are orthogonal to that one;2.0165431;0.87704;2.4636495;-6.308618;-2.7890632;3.9921403;-
detect intercept column;3.01879;3.2885196;-0.36612025;-2.3859046;-1.4936715;-1.7677683;CODE
cancel the regularization for the intercept;1.2084752;1.9577967;-1.6148547;-1.0189266;-4.759754;5.236759;CODE
handle case where y is 2 d;-1.5774469;1.7962289;3.240206;-5.395861;0.31637552;-0.96669483;CODE
for x that does not have a simple dtype e g pandas dataframe;1.9273741;-2.5853949;-2.8692143;-4.49406;-1.8908376;-2.0025165;CODE
the attributes will be stored in the dtype chosen by;-0.13426517;-3.215946;-2.4615963;-1.484111;3.7894294;0.5466283;CODE
validate data i e np float64;2.0835629;3.5645902;-4.2565584;-3.402217;-1.7196605;-4.7819743;CODE
using float32 can be numerically unstable for this estimator so if;2.1713817;3.0115428;-5.386835;0.1066829;-4.940753;2.0640028;CODE
the array api namespace and device allow convert the input values;-1.0172327;0.1421392;-0.63518953;-2.2017756;0.032656047;0.7683877;IRRE
to float64 whenever possible before converting the results back to;-0.018303217;4.0628586;-0.5161468;-1.2772146;-3.755988;-0.7976308;CODE
float32;-2.4756181;-1.0934297;0.8584504;-5.7870455;-0.5436979;-3.2685924;CODE
alpha per target cannot be used in classifier mode all subclasses;0.66902566;-0.6537483;-4.6350517;1.4896743;1.6636426;1.9050525;IRRE
of ridgegcv that are classifiers keep alpha per target at its;3.879495;-2.5774124;-3.1503158;-0.013667372;0.17527881;3.163218;IRRE
default value false so the condition below should never happen;-1.3549906;8.568753;-0.9194563;0.7923854;-0.84328806;-1.2315284;IRRE
rescale predictions back to original scale;4.8026524;-0.6098901;1.9185652;1.6249746;-4.3943987;5.019523;-
if sample weight is not none avoid the unnecessary division by ones;5.9311104;4.8918395;-1.5009005;-0.12665556;1.75402;-0.37359458;IRRE
keep track of the best model;4.482412;-3.1279469;3.3131;5.3148127;2.0256534;0.54720354;-
initialize;-4.5158596;1.9297284;2.6293108;0.22035694;1.0241722;-1.9811414;IRRE
update;-4.81619;-2.1328092;3.2103221;1.4595699;0.22711016;-1.7162327;CODE
avoid torch warning about x t for x with ndim 2;-1.2186081;1.4669714;-3.1405413;-2.5280657;-2.1055095;2.6800995;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
default value of epsilon parameter;-0.89606947;3.9062517;-3.0838816;0.44530135;-2.007467;1.9311117;IRRE
todo consider whether pa1 and pa2 could also work for other losses;0.37138265;3.0027716;1.0400869;0.752952;2.993921;1.9917161;CODE
raises valueerror if not registered;-1.533834;4.2040343;-6.70563;3.4319026;-2.4610064;-1.6502932;IRRE
plain sgd expects a float any value is fine since at this point;0.9642722;2.3838148;-5.677419;-1.7251605;-4.1307917;-0.36711052;CODE
penalty can t be elsaticnet so l1 ratio is not used;-1.8315243;3.4474819;-2.673291;0.6499513;-1.3631002;2.1560998;OUTD
allocate coef for multi class;1.5179797;0.5374129;-2.2748148;0.14034687;4.39785;2.8719873;CODE
allocate intercept for multi class;1.3842046;1.5344117;-1.1666456;-1.3483108;2.0477674;3.3031502;CODE
allocate coef;0.15637654;1.3077148;-0.31241632;-0.357728;1.5013529;1.832239;-
allocate intercept;0.19856921;2.7872298;1.6142594;-2.9630318;-2.1341379;2.0629635;CODE
initialize average parameters;1.8455243;2.7636898;0.9678889;-0.14460939;-1.3921752;2.6623912;IRRE
use the full set for training with an empty validation set;2.3741496;1.916254;-0.44667405;2.1082847;2.2995813;0.30731988;IRRE
y in 0 1;-1.020609;1.7678;2.994675;-5.1678395;-2.9550436;-4.4836106;-
y in 1 1;-1.2284769;1.0104737;3.8601134;-3.853179;-1.6493872;-4.713647;-
if average is not true average coef and average intercept will be;2.4503672;3.6763208;-0.11994999;-0.33994132;-2.7250063;-0.27409697;META
unused;-4.7602663;0.5192549;3.97546;1.7563446;0.7801238;-1.4610127;OUTD
numpy mtrand expects a c long which is a signed 32 bit integer under;-0.15825732;1.1298544;-5.210725;-5.549439;-5.79344;-2.564994;CODE
windows;-3.1146262;-3.9511354;6.107957;-1.1331433;-0.31103083;-1.8824025;CODE
allocate datastructures from input arguments;2.1072476;2.5265744;-0.3716686;-1.8780061;4.0438905;2.0684688;CODE
delegate to concrete training procedure;-1.1131136;-4.267465;1.200345;5.045485;3.9144254;1.0246233;-
delete the attribute otherwise partial fit thinks it s not the first call;0.38619334;5.630894;-1.5748802;2.3731487;-0.35374656;4.1576614;CODE
labels can be encoded as float int or string literals;-1.4480321;0.5439329;-2.480315;-5.3177476;0.94580275;-1.1319419;CODE
np unique sorts in asc order largest class id is positive class;1.2355037;1.2848196;-3.8472512;-2.6723588;2.0065365;0.09775145;IRRE
clear iteration count for multiple call to fit;3.7815852;5.058245;1.4108437;2.7982497;0.9992999;-0.34380388;IRRE
always scale the input the most convenient way is to use a pipeline;4.492161;0.9016531;2.6238248;-1.6978441;-1.7128458;3.7342014;CODE
always scale the input the most convenient way is to use a pipeline;4.492161;0.9016531;2.6238248;-1.6978441;-1.7128458;3.7342014;CODE
the one class svm uses the sgd implementation with;2.272373;-6.264493;-3.2114394;-0.4277592;1.5772399;2.5245264;TASK
y np ones n samples;4.249598;-2.5552292;1.1846248;-3.4873533;-0.4021236;-4.143143;-
early stopping is set to false for the one class svm thus;1.371222;0.5782346;-4.048422;3.2008128;-1.2040466;2.5143743;IRRE
validation mask and validation score cb will be set to values;0.85143596;3.2122617;-1.7232982;0.0032663974;1.1273675;-0.21200077;IRRE
associated to early stopping false in make validation split and;0.87399435;3.3846574;-3.4823856;5.7271247;-0.12502514;0.40430522;-
make validation score cb respectively;2.5532043;3.896621;-1.0525212;1.3779744;4.242981;-3.1158085;-
numpy mtrand expects a c long which is a signed 32 bit integer under;-0.158257;1.1298544;-5.210726;-5.54944;-5.7934413;-2.5649946;CODE
windows;-3.1146262;-3.9511354;6.107957;-1.1331433;-0.31103083;-1.8824025;CODE
there are no class weights for the one class svm and they are;1.2391651;-2.2888446;-3.997584;-1.332445;0.350489;0.8489313;CODE
therefore set to 1;-3.4094417;3.5067995;3.042791;-0.30277592;0.9363692;-5.068784;IRRE
average coef none not used;1.4892707;1.7855872;-2.8054667;0.07592416;-2.6497424;-1.9678485;OUTD
average intercept 0 not used;0.17140111;3.6355188;-1.7052094;-2.743719;-5.663176;-0.44013083;OUTD
made enough updates for averaging to be taken into account;2.704744;-0.3016202;1.9785919;4.360697;-2.0149977;0.5076107;CODE
allocate datastructures from input arguments;2.107247;2.526573;-0.37166855;-1.878007;4.0438895;2.0684676;CODE
we use intercept 1 offset where intercept is the intercept of;-0.25571603;1.8285568;2.213284;-2.8157852;-2.5443494;1.3835771;CODE
the sgd implementation and offset is the offset of the one class svm;1.9743431;-4.3691163;-1.9985212;-1.4774076;0.66736716;3.5095048;IRRE
optimization problem;2.5644038;1.6644166;4.3225617;-2.6098242;0.40021658;-0.18358947;-
delegate to concrete training procedure;-1.1131136;-4.267465;1.200345;5.045485;3.9144254;1.0246233;-
clear iteration count for multiple call to fit;3.7815852;5.058245;1.4108437;2.7982497;0.9992999;-0.34380388;IRRE
y y 0 1 for consistency with outlier detectors;5.18558;1.2463391;-1.3460046;0.41808587;-1.9408255;0.76318383;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
x old equals one of our samples;2.7761552;4.0937934;0.9353743;-2.112559;1.9088054;-3.976279;-
if quotient norm epsilon to avoid division by zero;0.43214995;3.574902;-1.2628856;-0.8772337;-1.8873808;2.0130253;CODE
tol 2 we are computing the tol on the squared norm;0.49592677;-0.18521233;-0.41012;-2.9640281;-2.2159696;1.823495;-
gelss need to pad y subpopulation to be of the max dim of x subpopulation;2.5134847;1.8311977;1.595034;-5.479008;-0.86099535;0.80656606;TASK
target type should be integral but can accept real for backward compatibility;-2.495259;0.7416443;-3.8620708;1.4559921;0.46772286;3.5685925;CODE
else if n samples n features;4.49848;1.9322529;0.6022952;-1.1521087;3.7819235;-4.307411;TASK
determine indices of subpopulation;4.2666354;2.3639035;2.901166;-3.8520715;2.0169537;-2.403457;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
test linearregression on a simple dataset;6.49615;3.1542032;-2.2104385;1.3381008;-1.5442472;-3.1188989;IRRE
a simple dataset;7.5347157;-4.491467;4.574859;-2.4933405;3.2221801;-2.8894997;IRRE
test it also for degenerate input;2.359556;4.42485;-1.6780947;1.6098473;0.9224934;-5.232817;CODE
it would not work with under determined systems;-0.017795684;-0.26841882;-1.2565193;0.9492051;2.1493075;3.1932049;CODE
linearregression with explicit sample weight;4.4995527;1.7363139;-2.8753834;-0.24956396;-0.29597253;3.4424849;-
assert reg coef shape x shape 1 sanity checks;1.7937744;4.1172767;-4.671913;0.72437495;-0.35918942;-1.3149463;CODE
closed form of the weighted least square;1.9842186;-0.3137242;-1.1429938;-2.1044955;-0.8454029;3.7320256;CODE
theta x t w x 1 x t w y;-0.28862652;1.4496694;1.566556;-4.2546935;-0.33660766;0.007823372;-
x must not be sparse if positive true;3.3097744;4.2409687;-2.653656;-2.1607246;-1.3747123;-0.17893718;IRRE
sample weights must be either scalar or 1d;4.446743;1.6766646;-4.447715;-2.6533482;-1.148371;1.82855;TASK
make sure the ok sample weights actually work;4.0543437;1.8596311;-2.8638642;2.5920014;-2.3384178;0.44286782;META
test assertions on betas shape;1.3717749;2.4077117;-3.0989537;3.7858315;0.43361238;-2.703273;IRRE
test that linear regression also works with sparse data;4.616231;2.3538842;-2.451638;2.4333982;-2.3558614;0.052460134;IRRE
test that linear regression agrees between sparse and dense;4.5939817;2.7318811;-3.0855377;1.6410352;-2.5110435;0.5244955;IRRE
test multiple outcome linear regressions;3.0824378;3.2233374;0.89223266;3.0935426;-0.3191942;-3.3879414;IRRE
test multiple outcome linear regressions with sparse data;5.539769;1.3363138;-1.0265642;2.755095;-0.27255827;-0.4770018;IRRE
test nonnegative linearregression on a simple dataset;5.573036;3.044733;-2.9552348;1.4532355;-1.5845412;-2.729568;IRRE
test it also for degenerate input;2.359557;4.424848;-1.6780938;1.6098461;0.9224958;-5.2328153;CODE
test multiple outcome nonnegative linear regressions;2.49242;4.127188;-0.6302226;2.857903;-0.57060206;-3.2318392;IRRE
test differences with linearregression when positive false;3.0735023;6.4616446;-3.4261756;2.9201794;-1.490551;-3.2385213;IRRE
test linearregression fitted coefficients;2.9499693;4.2542233;-2.204592;0.538756;-2.829799;-0.31040424;IRRE
when the problem is positive;-0.3647933;2.4648294;2.4434583;2.5687213;-1.5267704;-3.5699883;-
check that the data is not modified inplace by the linear regression;2.5396397;4.7729735;-0.9174066;0.6566397;-4.279642;-0.047405228;-
estimator;0.71077764;1.1009765;3.4146838;2.5535047;-1.9124054;0.09262009;-
xxx note hat y sparse is not supported broken in the current;-3.7799692;1.6027858;-3.9433963;-1.481293;-3.5001981;2.8504486;TASK
implementation of linearregression;3.9194043;-0.43172064;-1.4620637;-0.6442166;-0.3404305;3.1046858;TASK
do not allow inplace preprocessing of x and y;-3.1522143;2.922726;-0.004745683;-2.37822;-0.97718877;0.82546335;CODE
allow inplace preprocessing of x and y;-2.2820108;2.6468759;0.40718102;-1.8837361;-0.1372081;1.7103478;-
no optimization relying on the inplace modification of sparse input;4.968696;0.600328;-1.7541095;-2.7555547;-0.65481395;5.591066;IRRE
data has been implemented at this time;0.7307445;-3.9532616;2.6031592;1.0353819;2.2560492;0.5474083;TASK
x has been offset and optionally rescaled by sample weights;4.8061433;3.1673977;-0.7672823;-1.8402631;-2.7244987;4.2726884;IRRE
inplace the 0 42 threshold is arbitrary and has been found to be;-0.4088592;3.2939227;-2.4784634;-1.9557251;-0.105854414;-1.6351427;-
robust to any random seed in the admissible range;3.7900617;-0.09709718;-0.68394804;2.6178799;2.0950935;0.903646;IRRE
y should not have been modified inplace by linearregression fit;1.8421242;3.7250912;-3.1378357;-1.0218644;-5.4794884;3.536392;-
sample weights have no reason to ever be modified inplace;2.5787985;2.36715;-2.8837984;2.8052108;-1.0138316;4.223062;-
warning is raised only when some of the columns is sparse;2.795511;3.2744937;-3.4004838;0.4394014;-1.9909415;2.227549;CODE
all columns but the first column is sparse;4.09368;2.035776;-0.355647;-4.105039;-2.721203;1.4639933;IRRE
does not warn when the whole dataframe is sparse;3.5718405;2.466061;-3.1625564;1.8438123;-4.163663;1.1595963;IRRE
generate random data with 50 of zero values to make sure;4.3337383;3.1164448;0.9998476;-1.5924984;-0.13683519;-3.745995;IRRE
that the sparse variant of this test is actually sparse this also;5.014663;1.1453015;-3.2742093;3.2830665;0.33321732;-1.3624445;IRRE
shifts the mean value for each columns in x further away from;3.736327;2.0816305;1.6396253;-5.526316;-5.4344444;1.9894544;CODE
zero;-2.359473;1.2926373;2.9025295;-2.352723;-1.7710636;-5.686084;-
scale the first feature of x to be 10 larger than the other to;2.8447645;1.5750707;3.4035318;-4.6796565;-1.5835389;2.0944712;TASK
better check the impact of feature scaling;4.268142;-1.2879881;-0.8324138;3.734202;-2.395651;4.0139594;TASK
constant non zero feature;1.8793805;2.2430267;-2.0038579;-2.6349614;-0.088294856;1.3917178;TASK
constant zero feature non materialized in the sparse case;2.3903549;0.8496885;-4.307873;-0.85125506;0.18538174;4.1899424;CODE
near constant features should not be scaled;3.5551403;1.6595776;-2.1474576;-0.98875624;-4.652865;5.433026;TASK
simplifies asserts;-0.7111646;3.72273;-0.6570785;2.038983;2.74035;-1.9298371;CODE
test output format of preprocess data when input is csr;1.7092481;3.6560266;-2.7565782;1.1739618;0.0032644242;-4.301227;IRRE
ample weight sw 32 sample weight must have same dtype as x;1.2927907;1.0311469;-4.009456;-2.2262757;0.18639337;0.533494;-
ample weight sw 64 sample weight must have same dtype as x;1.0055318;0.8550348;-4.2089434;-2.2209582;-0.056029838;0.5726192;-
array;0.32504454;2.3025823;5.5294733;-3.8580654;0.6459899;-5.286;-
csr;-1.9517441;-2.1731985;2.3376567;0.095433205;1.0228496;-3.156976;-
reason known to fail for csr arrays see issue 30131;-0.9837903;3.6779377;-5.335848;-1.0612383;-2.5314329;-2.2378287;CODE
1 sample weight np ones must be equivalent to sample weight none;4.2189093;2.1041043;-4.8032074;-1.1704397;0.500629;-0.12178981;TASK
a special case of check sample weight equivalence name reg but we also;2.5975697;3.7490466;-3.2770143;1.0527917;4.547877;-0.023546949;META
test with sparse input;6.92665;3.777558;-1.576058;2.6149158;-0.33922958;-4.0452495;IRRE
2 sample weight none should be equivalent to sample weight number;3.615535;4.6566334;-2.0281537;-0.3334533;1.0718311;-0.17136174;-
3 scaling of sample weight should have no effect cf np average;2.6594372;2.5177906;-3.4611275;-1.7644624;-3.3357205;3.2711575;-
4 setting elements of sample weight to 0 is equivalent to removing these samples;4.5543966;4.27509;-1.2645483;-1.2462727;0.7624328;0.96879846;IRRE
y 5 1000 to make excluding those samples important;5.6116676;2.0011446;-0.030649072;0.9568371;0.89463943;-2.5011477;CODE
5 check that multiplying sample weight by 2 is equivalent to repeating;4.018049;4.5940194;0.24260023;0.022441719;1.6973591;-3.503033;-
corresponding samples twice;5.362505;2.6526663;1.568535;-1.759456;2.778848;-1.8409333;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
note gammaregressor and tweedieregressor power 1 have a non canonical link;-4.966784;-1.2965941;-2.2944582;-0.86214966;0.52133083;3.9789476;IRRE
todo fix saga which fails badly with sample weights;1.9282367;0.7296559;-2.8627887;2.9556556;-2.8665864;2.1681752;TASK
this is a known limitation see;-2.6025288;1.4277635;0.61295885;2.552383;2.000993;3.5703428;CODE
https github com scikit learn scikit learn issues 21305;-3.3017647;-9.7319355;-6.236579;-0.19464628;-5.1881585;-5.574159;CODE
tweedieregressor power 0 same as ridge;-1.536465;-0.13288806;-2.7450163;-2.6687365;-2.2211597;3.9365969;-
test that sum y predicted sum y observed on the training set;5.4467616;0.84339136;0.016906613;4.707252;-0.6438337;-4.3834157;IRRE
this must hold for all linear models with deviance of an exponential disperson;0.48762712;0.48151812;-1.09568;0.63846225;-1.1388507;4.8629985;CODE
family as loss and the corresponding canonical link if fit intercept true;1.7218795;1.1955353;-1.4185368;-0.061462816;-0.04135206;5.1835704;IRRE
examples;-1.0020732;-4.934585;5.766821;2.66193;2.03393;-3.340021;-
squared error and identity link most linear models;1.5612112;-1.5475214;-0.8040587;1.1256455;-0.70249254;2.9125066;IRRE
poisson deviance with log link;-2.033979;1.7714534;0.7520923;0.67716646;-1.6998255;1.5570077;-
log loss with logit link;-2.2826636;0.5912949;-0.40732205;1.7620951;-2.6296384;2.3946161;-
this is known as balance property or unconditional calibration unbiasedness;3.309775;1.2323748;-0.28305924;2.424208;1.4805632;2.472805;CODE
for reference see corollary 3 18 3 20 and chapter 5 1 5 of;-4.7758594;-1.208154;-3.9025056;-0.72850543;0.41624877;6.898381;CODE
m v wuthrich and m merz statistical foundations of actuarial learning and its;2.5624878;-4.1138024;-1.1613364;3.9047363;1.8077767;1.5841012;-
applications june 3 2022 http doi org 10 2139 ssrn 3822407;-3.209819;-4.4364476;-3.2214458;0.2512578;1.5305609;-0.7352906;CODE
model clone model avoid side effects from shared instances;-0.22989762;-0.14098974;-0.3761138;5.631397;0.14112699;3.8335683;CODE
rel 2e 4 test precision;1.6473682;3.963259;-4.468958;1.5741047;-2.2985475;-3.122521;IRRE
y rng poisson lam expectation 1 strict positive i e y 0;-1.4041941;3.0851278;-1.6346995;-1.3854142;-3.302928;0.71692085;-
model set params fit intercept true to be sure;2.8664286;3.3974512;-1.3635211;1.50869;-2.0091085;1.8099308;IRRE
assert balance property;0.30603072;6.443621;-2.203116;5.0816894;1.1175412;-1.9022886;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
from sklearn linear model import cd fast as cd fast type ignore attr defined;1.782471;-1.162579;-6.1405125;-1.6782414;-1.9584217;1.298828;CODE
for alpha max coefficients must all be zero;-0.4524321;2.3965325;-2.6680553;-3.3852139;-2.063368;0.7190356;CODE
without gap safe screening rules;1.1748831;2.1335394;-0.83762616;3.4448261;2.7143848;-1.7235035;-
at least 2 coefficients are non zero;-0.5894121;3.9553003;-2.0066779;-3.997867;-0.5833027;-0.98170227;-
with gap safe screening rules;1.3244811;1.0770195;-0.2518151;3.4588752;2.4885702;-2.2628667;-
sparse;4.7815304;-2.4953928;2.4479089;-1.8432587;0.88839895;1.0305685;IRRE
gram;-0.57754457;-1.3275719;2.3707104;-0.6887172;1.3766906;-1.9246825;-
check that the lasso can handle zero data without crashing;2.6234927;2.3066943;-3.7851963;1.7161188;-1.8938661;1.0656704;-
pytest mark filterwarnings ignore runtimewarning overflow and similar;0.1580401;1.99211;-4.684385;2.1196728;-3.7785428;3.510218;IRRE
check elasticnet throws valueerror when dealing with non finite parameter;0.079704046;4.6936703;-6.227701;1.450803;-3.6486228;0.702958;IRRE
values;2.3852327;2.8150017;4.596041;-3.805712;2.3660839;-6.126723;IRRE
test lasso on a toy example for various values of alpha;3.4737523;1.1458259;-1.6670078;0.42413205;-1.7613292;-1.955495;IRRE
when validating this against glmnet notice that glmnet divides it;0.32185286;2.533741;-3.70768;2.2100637;-0.2011331;-0.36955416;CODE
against nobs;-1.6049168;-0.83702296;2.2423463;0.38630396;0.46604905;-2.6538389;-
y 1 0 1 just a straight line;-1.2709646;1.5544807;4.1182394;-4.8336725;-3.9625614;-2.7233343;-
t 2 3 4 test sample;0.8918927;3.928626;0.4489716;-0.8326951;1.0839016;-5.940148;IRRE
test elasticnet for various parameters of alpha and l1 ratio;2.7440116;1.8024862;-2.4063864;0.57111377;-2.388063;0.9154042;IRRE
actually the parameters alpha 0 should not be allowed however;-4.4393024;1.9918343;-2.8658035;-1.2619532;-1.3809747;1.9560596;IRRE
we test it as a border case;-2.5952523;1.3185781;3.6206486;4.534533;0.87471545;-2.9117951;IRRE
elasticnet is tested with and without precomputed gram matrix;2.5268574;0.27109674;-5.439699;1.0351241;-1.5080522;2.238723;IRRE
y 1 0 1 just a straight line;-1.2709645;1.5544801;4.1182384;-4.833673;-3.9625607;-2.7233338;-
t 2 0 3 0 4 0 test sample;1.9362624;4.6485014;-0.6829069;-2.8385725;-0.9191218;-5.6320744;IRRE
this should be the same as lasso;3.743192;-3.621519;1.6908168;0.6069354;-0.19335811;3.4997277;CODE
clf fit x y with gram;3.2773921;0.7785211;-1.3849169;-4.3034086;-0.4908136;0.28550822;-
clf fit x y with gram;3.2773921;0.7785211;-1.3849169;-4.3034086;-0.4908136;0.28550822;-
dual pt r n samples dual constraint norm x t theta inf alpha;2.2463923;0.50399154;-4.1983852;-2.7060552;-0.032090228;4.8018403;CODE
check that the lars and the coordinate descent implementation;3.3888433;-1.6308935;-4.097867;-1.5805362;-3.4861696;3.5563703;TASK
select a similar alpha;0.903692;0.76149744;3.003156;-1.5917612;3.0854852;-0.2741164;CODE
for this we check that they don t fall in the grid of;0.725348;2.8446124;2.4825113;0.37905055;-2.1451516;-1.6186165;CODE
clf alphas further than 1;-0.3061843;1.2619544;0.1956814;-1.4565634;0.13730538;-1.9686421;-
check that they also give a similar mse;-2.1442466;-1.5989316;-1.9856303;2.9297264;-0.09687891;0.74601215;-
test set;3.2042842;3.4155014;2.6115146;2.4797702;2.3319228;-7.5599284;IRRE
ensure the unconstrained fit has a negative coefficient;3.7062159;4.093587;-3.020344;-0.27130908;-2.564844;3.9416518;CODE
on same data constrained fit has non negative coefficients;3.0580275;2.9655259;-4.0593605;-1.8629704;-2.3311474;3.5738559;CODE
set initial coefficients to very bad values;2.9582455;4.663531;-1.4687847;-0.95332247;-3.550777;1.0416328;IRRE
check that the model converges w o convergence warnings;1.1086521;2.6917439;-2.8048387;5.0604377;-2.8564441;-1.1618187;-
check that the model converges w o convergence warnings;1.1086521;2.6917439;-2.8048387;5.0604377;-2.8564441;-1.1618187;-
x x astype int make it explicit that x is int;-2.3406765;3.1985476;-0.66556;-2.8552647;2.1826415;-1.2947052;CODE
1 sample weight np ones should be equivalent to sample weight none;4.331637;2.095593;-4.6787033;-0.7728979;0.27794185;0.2877459;-
2 sample weight none should be equivalent to sample weight number;3.615535;4.6566334;-2.0281537;-0.3334533;1.0718311;-0.17136174;-
3 scaling of sample weight should have no effect cf np average;2.6594372;2.5177906;-3.4611275;-1.7644624;-3.3357205;3.2711575;-
4 setting elements of sample weight to 0 is equivalent to removing these samples;4.5543966;4.27509;-1.2645483;-1.2462727;0.7624328;0.96879846;IRRE
y 5 1000 to make excluding those samples important;5.6116676;2.0011446;-0.030649072;0.9568371;0.89463943;-2.5011477;CODE
5 check that multiplying sample weight by 2 is equivalent to repeating;4.018049;4.5940194;0.24260023;0.022441719;1.6973591;-3.503033;-
corresponding samples twice;5.362505;2.6526663;1.568535;-1.759456;2.778848;-1.8409333;-
assign random integer weights only to the first cross validation group;4.0391016;2.3106954;-0.96346396;0.7758385;3.3806267;1.523606;IRRE
the samples in the other cross validation groups are left with unit;2.858503;3.1964872;-1.6813182;0.76841456;0.71707886;-0.68129957;CODE
weights;2.7202175;-1.3401426;5.5330563;0.6395905;0.23873325;-0.60408145;-
check that the alpha selection process is the same;-0.051743913;2.9796793;-2.1012046;2.9029632;-0.40354696;0.0721675;CODE
check that the final model coefficients are the same;1.6953349;4.857709;-1.9453822;2.5906022;-1.5497853;-0.72247446;CODE
sample weight np ones should be equivalent to sample weight none;4.16498;1.6280899;-4.960566;-0.15807518;-0.14525384;0.5675243;-
sample weight none should be equivalent to sample weight number;3.4890945;4.042065;-2.6177902;0.3942953;0.45965645;0.1845447;-
scaling of sample weight should have no effect cf np average;3.4315646;2.2215571;-3.548551;-0.38967794;-4.3267536;4.0680237;-
test alpha max makes coefs zero;-0.07279515;3.7505996;-4.8173075;0.9602023;-4.0131636;-2.3439648;IRRE
test smaller alpha makes coefs nonzero;0.50375885;4.4271927;-4.7863083;1.9661566;-3.3119538;-2.3379762;IRRE
linearmodelscv fit performs operations on fancy indexed memmapped;4.0937157;1.0199919;-4.8048277;-0.5646784;-2.566783;5.6511254;CODE
data when using the loky backend causing an error due to unexpected;-3.5700614;2.0817435;-1.4907454;0.45215547;-1.3557725;-1.1245842;CODE
behavior of fancy indexing of read only memmaps cf numpy 14132;1.2130332;0.23384963;-3.7290049;-3.8824887;-3.8747213;0.540743;CODE
create a problem sufficiently large to cause memmapping 1mb;1.491245;1.3493727;0.49474666;0.9287614;0.5088045;0.4092459;IRRE
unfortunately the scikit learn and joblib apis do not make it possible to;-1.8263278;-10.705914;-4.901135;1.8660512;-4.4236345;-1.730414;CODE
change the max nbyte of the inner parallel call;0.911845;2.4690325;-0.54278094;-2.9385238;-0.6219767;1.7289009;IRRE
assert x nbytes 1e6 1 mb;1.3364973;3.6523855;-4.1774187;-1.4487683;-0.50859356;-3.9207423;CODE
asses warning message raised by linearmodelcv when n alphas is used;0.7344296;1.745091;-5.6149006;-0.28505307;-3.2243927;1.3877922;CODE
asses no warning message raised when n alphas is not used;-4.0248976;2.5841744;-3.1392405;1.4053831;-1.959079;-0.8501049;OUTD
todo 1 9 remove;-3.8011727;2.5783017;2.8172538;-0.61260426;0.7241015;-2.6205137;TASK
asses no warning message raised when n alphas is not used;-4.0248976;2.5841744;-3.1392405;1.4053831;-1.959079;-0.8501049;OUTD
todo 1 9 remove;-3.8011727;2.5783017;2.8172538;-0.61260426;0.7241015;-2.6205137;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
generate data with outliers by replacing 10 of the samples with noise;5.6373653;1.5335295;1.0052452;-0.71410674;-0.7367785;-0.025033515;CODE
replace 10 of the sample with noise;3.4251153;2.5900474;1.379658;0.50081074;0.44534764;-1.8659765;-
test that ridge matches linearregression for large epsilon;4.40424;1.7375021;-4.7432013;1.5790395;-4.005792;2.059007;IRRE
test that the gradient calculated by huber loss and gradient is correct;1.747667;1.5114796;-3.326703;1.9521018;-2.8459294;0.5394898;IRRE
check using optimize check grad that the gradients are equal;4.3121963;2.7551644;-2.8972528;-0.09445059;-2.0964556;0.36909848;-
check for both fit intercept and otherwise;2.7946713;5.811397;-0.90048766;-0.5355919;-1.7220402;-1.3695692;CODE
the ridge regressor should be influenced by the outliers and hence;4.267957;-0.3078021;-0.8530295;0.06329775;-2.8285174;4.939229;-
give a worse score on the non outliers as compared to the huber;3.893101;0.75547045;-0.20365603;1.7232491;-1.4387016;0.388551;IRRE
regressor;0.08184406;0.21342912;3.8615754;-1.6881057;-0.78836936;-0.7719704;-
the huber model should also fit poorly on the outliers;3.0858;-0.37501407;-2.0893214;1.3142034;-1.799995;3.4651368;-
test that it does not crash with bool data;-0.16879648;6.169328;-2.4963057;4.456774;-0.39984444;-5.650149;CODE
todo use another dataset that has multiple drops;4.149911;2.0021622;1.81269;1.2361349;1.1956718;0.47942013;TASK
principle of lars is to keep covariances tied and decreasing;1.445635;-1.6466963;-1.231131;1.6889156;-1.3963101;6.225651;CODE
also test verbose output;-1.0665267;4.4344954;-1.1681617;2.825202;-0.9286717;-7.5981374;IRRE
no more than max pred variables can go into the active set;-0.53979266;2.9317346;-0.23972768;0.3504492;3.841266;0.69954497;IRRE
the same with precomputed gram matrix;2.8765774;-2.0605662;-0.906072;-3.2863975;0.34373114;1.4952587;-
no more than max pred variables can go into the active set;-0.53979266;2.9317346;-0.23972768;0.3504492;3.841266;0.69954497;IRRE
test that lars path with no x and gram raises exception;0.6140959;3.6613944;-5.179536;0.90567845;-2.0597088;-2.3618245;CODE
test that lars path with precomputed gram and xy gives the right answer;1.727387;1.7772746;-2.4386466;-1.6343914;-2.225926;-3.4536285;IRRE
todo remove warning filter when numpy min version 2 0 0;-1.0992025;2.0983856;-5.69209;-0.6451171;-5.8009205;1.0019178;TASK
test that lars gives least square solution at the end;2.9065635;2.9463484;-2.7376738;-0.2040661;-4.471882;-1.5823225;IRRE
of the path;-3.1739779;-2.0319474;6.612183;0.59419876;0.013359596;-1.4092687;-
x1 3 x use un normalized dataset;5.0759387;0.57227063;-2.9621449;-5.4704137;0.43880674;3.1930008;IRRE
todo remove warning filter when numpy min version 2 0 0;-1.0992025;2.0983856;-5.69209;-0.6451171;-5.8009205;1.0019178;TASK
test that lars lasso gives least square solution at the end;3.2636802;0.8060952;-3.5715039;1.4343292;-3.9497342;0.8040494;IRRE
of the path;-3.1739779;-2.0319474;6.612183;0.59419876;0.013359596;-1.4092687;-
check that lars path is robust to collinearity in input;2.4160578;0.9752279;-3.4289978;-1.7589903;-4.2711096;1.8218757;CODE
assert residual 2 sum 1 0 just make sure it s bounded;0.8867036;6.679608;-2.7823951;1.7434205;-3.9144142;-1.5802523;CODE
test that the return path false option returns the correct output;-1.6510804;6.9557014;-2.831216;4.8053374;-2.7757494;-4.0116467;IRRE
test that the return path false option with gram remains correct;-1.1227571;4.894894;-4.4227843;3.7375984;-1.2274765;-3.1839013;IRRE
test that the return path false option with gram and xy remains;-0.64418495;4.759561;-4.142226;2.6583269;-1.6555464;-3.017823;IRRE
correct;-1.910879;-1.5264444;3.937237;1.1246055;1.1218234;-1.7695826;-
check for different values of precompute;2.323022;4.3211665;0.11200758;0.11828047;0.58728695;-5.871159;IRRE
test when input is a singular matrix;3.5261695;4.8924108;-2.7930894;-0.8686436;-2.0011942;-2.9731011;IRRE
consistency test that checks that lars lasso is handling rank;3.4180806;1.7492402;-4.406887;3.7929406;-1.6742625;0.7116693;IRRE
deficient input data with n features rank in the same way;5.1697683;0.19824736;-3.2106826;-1.7696682;0.39407238;-0.21346109;CODE
as coordinate descent lasso;5.143512;-3.8211365;-0.17845273;-0.7462225;0.1383228;4.608108;-
to be able to use the coefs to compute the objective function;3.7419326;-2.5570242;-1.5044212;1.0657369;0.1013185;2.3113132;CODE
we need to turn off normalization;-0.31165987;-0.94666845;-1.1278417;0.87438315;-2.1827188;5.0659623;TASK
test that lassolars and lasso using coordinate descent give the;2.843848;-0.24502932;-1.9120816;0.29055524;-0.8442551;0.22572315;IRRE
same results;-0.6933502;0.28111652;2.8099964;1.9312195;-0.5798681;-3.2996407;IRRE
similar test with the classifiers;6.235769;-0.12268838;-0.59231746;3.8553655;4.312866;-4.7215905;IRRE
same test with normalized data;5.25171;5.4027433;0.56075984;0.75842375;0.88111633;-1.9714905;IRRE
test that lassolars and lasso using coordinate descent give the;2.843848;-0.24502932;-1.9120816;0.29055524;-0.8442551;0.22572315;IRRE
same results when early stopping is used;0.58436465;4.221725;0.12464551;6.472563;-2.4127648;0.22996993;IRRE
test before in the middle and in the last part of the path;-1.2526249;5.009587;3.148068;3.313702;0.28058288;-3.3917785;CODE
same test with normalization;3.5317369;5.667484;-0.7138639;1.5240513;0.32120374;-1.8148812;IRRE
test that the path length of the lassolars is right;0.43008906;1.6249577;-0.2496072;-0.20829067;-1.9929318;-0.64347625;IRRE
also check that the sequence of alphas is always decreasing;0.13932252;3.320718;-0.701983;-0.33932227;-3.1918814;-2.600038;-
test lasso lars on a very ill conditioned design and check that;3.4005754;1.0891511;-4.242915;2.8996098;-2.0146415;1.1035696;IRRE
it does not blow up and stays somewhat close to a solution given;-2.9939764;2.1707087;0.54398435;1.3029374;-4.559647;-0.47648585;CODE
by the coordinate descent solver;5.407929;-2.4376276;-0.8335685;-2.7691298;-1.8692982;3.3284373;-
also test that lasso path using lars path output style gives;2.7634203;-2.0507736;-4.1326942;0.017320637;-3.461826;1.433673;IRRE
the same result as lars path and previous lasso output style;2.0957928;-2.3190393;-1.5610169;-0.6544325;-2.629443;3.8451815;IRRE
under these conditions;-0.82028073;2.9183366;4.272292;0.9906718;3.4903677;-1.2917267;-
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
create an ill conditioned situation in which the lars has to go;0.4106614;2.3443968;1.9928709;3.8980021;-0.3146414;1.6259111;IRRE
far in the path to converge and check that lars and coordinate;1.6185563;-0.43083596;-0.8499114;-0.6437387;-5.010424;1.9719054;CODE
descent give the same answers;-0.23931812;-0.40435144;2.804602;-0.4266761;0.24496669;-0.4975384;-
note it used to be the case that lars had to use the drop for good;-1.9117696;0.19429897;0.6216827;2.7056003;-1.9203887;2.5544486;IRRE
strategy for this but this is no longer the case with the;-2.8670685;0.7222858;4.6557326;4.4718885;1.5263808;2.6099024;CODE
equality tolerance checks;-0.6119148;3.150941;-0.9586053;3.6765647;1.3449559;-1.5385852;-
assure that at least some features get added if necessary;-1.1970369;-1.8596389;0.65235764;4.747994;3.5212734;1.905413;TASK
test for 6d2b4c;-0.034069847;3.3666801;-2.6648698;-0.21191493;0.69951975;-4.800181;IRRE
hilbert matrix;1.0677524;-0.1877824;1.308087;-4.540642;-0.35073414;0.79855907;-
the path should be of length 6 1 in a lars going down to 6;-1.1353862;-0.43515667;1.9529173;-1.979244;-2.1755977;-0.2610228;CODE
non zero coefs;0.1826781;2.1376638;-2.4270425;-2.3148856;-0.44024348;-0.4461322;-
assure that estimators receiving multidimensional y do the right thing;3.2547963;1.69772;-0.7719431;0.6953216;-1.3759266;4.936078;IRRE
regression test for gh 1615;0.8273751;2.5021148;-2.5603511;3.5694206;-4.2461586;-4.8832955;IRRE
test the lassolarscv object by checking that the optimal alpha;3.6552365;0.13648717;-2.7880127;0.95159864;-1.3321612;0.9193652;IRRE
increases as the number of samples increases;3.9936507;0.97748;3.459587;1.1308404;0.88536006;-0.6641108;-
this property is not actually guaranteed in general and is just a;-2.4181724;3.0451021;-1.1364886;2.9121943;3.8039486;2.0528903;META
property of the given dataset with the given steps chosen;5.803747;0.42819503;2.7281377;-0.8642078;1.9126589;-1.3084964;IRRE
x np c x x x add correlated features;2.4158084;-1.2290766;-2.0210292;-4.3326573;0.54244214;2.1022837;TASK
check that there is no warning in general and no convergencewarning;-0.24475843;3.488911;-3.095485;7.0107827;-3.4096582;-0.43006742;-
in particular;-2.0218616;-3.1796997;5.520001;1.2871132;0.2727208;0.8032856;-
materialize the string representation of the warning to get a more;-1.2564615;2.2404559;-0.38519603;1.41681;1.2384644;-1.0664037;CODE
informative error message in case of assertionerror;-1.5825074;4.0150695;-4.894864;3.4974413;-0.8305592;-3.726247;CODE
test the lassolarsic object by checking that;2.0510755;1.5968236;-0.909735;1.6932577;-1.2724719;-2.050483;IRRE
some good features are selected;0.52467954;-5.4206753;3.3611557;2.2929556;2.9129577;1.1093637;TASK
alpha bic alpha aic;-2.294083;-0.8612018;-0.21883899;-2.2388752;0.01564378;-2.5738761;-
n nonzero bic n nonzero aic;-0.70718396;1.1154791;1.0297977;-1.9680961;2.1917174;-2.4596186;-
x np c x rng randn x shape 0 5 add 5 bad features;2.9221117;-1.0404745;-2.4835913;-3.8464713;0.55298686;-2.0819511;TASK
when using automated memory mapping on large input the;1.7212533;-1.5214372;0.6595562;0.20470284;1.4499336;0.6247562;CODE
fold data is in read only mode;-2.1179407;1.7377243;-0.33522478;-1.824931;-2.2269533;1.8719287;CODE
this is a non regression test for;1.5283767;2.7842178;-0.24509597;3.7354827;-1.4746063;-6.018745;CODE
https github com scikit learn scikit learn issues 4597;-3.1442137;-9.622609;-6.062467;-0.5058759;-4.678228;-5.388226;CODE
the following should not fail despite copy false;-1.9272594;6.503365;-3.453922;3.4395702;-0.44522664;-3.0879004;-
this is the main test for the positive parameter on the lars path method;1.687598;1.2723808;-3.0522869;1.5809096;-3.2064517;0.19239189;CODE
the estimator classes just make use of this function;1.8174114;-1.0266081;-1.4730605;2.2111373;0.064596064;3.0140977;CODE
we do the test on the diabetes dataset;4.6327167;-1.6763631;1.2376418;3.451131;0.88671434;-3.784905;IRRE
ensure that we get negative coefficients when positive false;2.147141;5.791742;-2.452172;0.67727417;-0.040513936;-2.2909884;-
and all positive when positive true;0.39102465;1.8005149;2.08864;2.052724;2.0874774;-3.3557932;-
for method lar default and lasso;2.1559675;-0.64023393;-2.6791303;1.8984364;-1.2937922;2.7381737;CODE
now we gonna test the positive option for all estimator classes;1.8352269;1.1068834;-2.289992;7.0967;0.34197715;-0.55143106;IRRE
testing the transmissibility for the positive option of all estimator;0.45156422;4.5991697;-2.539024;5.2824264;-1.3235608;1.9116455;IRRE
classes in this same function here;-0.0068275947;-0.12335561;2.2860992;-1.9429554;3.7467475;-2.564392;CODE
test that lassolars and lasso using coordinate descent give the;2.843848;-0.24502932;-1.9120816;0.29055524;-0.8442551;0.22572315;IRRE
same results when using the positive option;-1.4000968;5.4481316;0.05916553;0.42836174;-1.3197821;-3.4278045;IRRE
this test is basically a copy of the above with additional positive;-1.4396373;3.8648398;-1.9893235;3.3354836;0.78993016;-5.834018;IRRE
option however for the middle part the comparison of coefficient values;2.8884385;5.6379457;2.5393188;-1.2722884;-0.19861324;-1.827551;IRRE
for a range of alphas we had to make an adaptations see below;-1.0335215;-1.053226;2.284481;-0.6969471;-2.1501367;1.6115317;CODE
not normalized data;6.459277;0.9219901;1.4124674;-3.2845373;1.5025694;1.7533953;-
the range of alphas chosen for coefficient comparison here is restricted;2.5395637;3.2781746;-1.7122794;-1.3000101;-2.664786;-1.5598447;CODE
as compared with the above test without the positive option this is due;-0.67009336;6.178222;-3.2244601;4.532871;-2.0672684;-4.23113;IRRE
to the circumstance that the lars lasso algorithm does not converge to;4.1724806;-1.4851861;-3.0585701;2.1136858;-3.5538607;3.696758;CODE
the least squares solution for small alphas see least angle regression;2.6760628;-1.3969374;-1.778261;-1.4332842;-5.142973;4.007575;CODE
by efron et al 2004 the coefficients are typically in congruence up to;-0.45500463;-0.40076107;-2.006354;-3.221157;0.14310989;1.177575;IRRE
the smallest alpha reached by the lars lasso algorithm and start to;6.1330023;-3.836874;-1.1880729;-0.9354275;-1.4213058;2.312884;-
diverge thereafter see;-1.527065;2.9434693;3.9167578;1.1234007;-0.53879756;-1.6750919;-
https gist github com michigraber 7e7d7c75eca694c7a6ff;-4.764906;-3.9205194;-1.5434334;-0.9406053;-2.813722;1.2865839;CODE
normalized data;7.641921;-0.55345356;3.0583558;-3.750378;2.776639;1.7470506;-
for c a in zip lasso path t 1 alphas 1 don t include alpha 0;0.6978345;-0.020798584;-3.8532035;-2.9659631;-1.2378838;-0.45243835;CODE
test that sklearn lassolars implementation agrees with the lassolars;4.021053;-5.158664;-3.7969995;2.9678688;-1.0465844;0.10767172;TASK
implementation available in r lars library when fit intercept false;3.5382044;0.23093848;-4.721175;-0.6976969;-3.685755;2.982343;TASK
let s generate the data used in the bug report 7778;0.19024284;-1.8961275;-3.1500514;0.33707517;0.4049455;-2.7045507;CODE
the r result was obtained using the following code;2.597072;2.1134646;-0.697922;-5.0610976;-1.1004988;-5.4714346;IRRE
library lars;-0.70766413;-6.644667;0.7590479;-0.7725918;0.2697281;-0.9066861;CODE
model lasso lars lars x t y type lasso intercept false;0.9835024;0.9303177;-4.487463;-0.48343703;-3.8798969;2.4183176;CODE
trace true normalize false;2.6936166;4.3483267;-3.7355912;0.27995765;-2.6485317;1.8489467;-
r t model lasso lars beta;2.4869752;-2.8285146;-2.5657265;0.58191365;-3.4115674;2.442962;-
est clone est avoid side effects from previous tests;-2.5033054;2.7973955;-2.1611829;7.057082;-1.4507204;0.27577847;CODE
test that a small amount of jitter helps stability;1.7925401;1.8817811;0.56757194;3.8368359;-3.7309783;-0.46813852;IRRE
using example provided in issue 2746;-6.6052885;0.57261056;-3.72219;0.69602513;2.7461898;-2.418575;-
set to fit intercept to false since target is constant and we want check;2.0293236;5.6092763;-0.6769578;1.2659997;-3.6171858;1.4398713;CODE
the value of coef coef would be all zeros otherwise;0.5857957;2.7210383;-3.027059;-3.4790893;-3.6464398;-0.4328793;IRRE
non regression test for 17789 copy x true and gram auto does not;0.2767966;3.1599777;-6.9991846;1.9719757;-3.5922527;-2.7540255;CODE
overwrite x;-3.6548529;2.2104979;2.6173737;-1.868241;-0.63073677;-1.1717353;TASK
x did not change;-4.7961073;2.4298522;2.4251025;-0.30518535;-2.3411;-0.9040952;-
max iter 5 is for avoiding convergencewarning;1.1543938;0.60594636;-1.4369465;3.5738568;-0.5982056;2.3684285;CODE
the test ensures that the fit method preserves input dtype;3.5395489;1.9659905;-6.530628;3.555184;-2.3539946;-1.1772076;IRRE
max iter 5 is for avoiding convergencewarning;1.1543938;0.60594636;-1.4369465;3.5738568;-0.5982056;2.3684285;CODE
the test ensures numerical consistency between trained coefficients;4.936558;0.89809006;-5.0968876;5.5231752;0.7955355;-0.9775404;IRRE
of float32 and float64;-2.3672097;0.5757656;-1.4033333;-5.1040044;-1.124461;-1.5615897;CODE
we do not need to test all losses just what linearmodelloss does on top of the;3.5738735;0.5568168;-1.0742152;5.6780415;-0.50626874;0.34653556;CODE
base losses;1.120531;-0.30398107;3.258848;1.0002259;0.73447424;-0.85634965;-
x 1 1 make last column of 1 to mimic intercept term;1.5864038;2.2201393;1.6979073;-6.357372;-1.9058282;0.5195099;CODE
exclude intercept column as it is added automatically by loss inter;2.5237334;3.8865726;-2.2362041;0.24577186;-0.61232644;3.7208476;CODE
note that intercept gets no l2 penalty;-1.3526983;1.7683148;0.041071497;0.11022714;-1.3278769;1.7564528;TASK
coef coef ravel order f this is important only for multinomial loss;2.039866;0.6224455;-0.9515658;-1.171234;2.874524;0.70090616;CODE
1 check gradients numerically;4.430011;2.5441544;-1.667301;-1.2571913;-0.8694982;-0.6814294;IRRE
use a trick to get central finite difference of accuracy 4 five point stencil;4.9493136;2.6425786;0.6766149;-3.147636;-1.9466895;-0.5897793;IRRE
https en wikipedia org wiki numerical differentiation;-0.8122129;-3.5122945;-0.94640917;-3.2898705;-0.17291123;-0.33584422;CODE
https en wikipedia org wiki finite difference coefficient;0.004142387;-1.2725703;1.0876762;-2.9678872;0.70608634;0.056238875;IRRE
approx g1 f x eps f x eps 2 eps;4.24585;1.0779326;0.9178918;-5.4582124;0.1265939;1.4767836;-
approx g2 f x 2 eps f x 2 eps 4 eps;3.1621811;0.78666097;1.8714389;-6.273749;0.12457571;1.3638695;-
five point stencil approximation;4.2839494;1.0817336;1.3486564;-4.431387;-2.0852468;1.2247323;CODE
see https en wikipedia org wiki five point stencil 1d first derivative;-1.4146597;-0.7167867;-0.28522262;-4.8165197;-0.9552548;-0.032360867;CODE
2 check hessp numerically along the second direction of the gradient;0.7557718;0.64987695;-2.3624096;-0.7841345;-1.986027;1.1535965;IRRE
computation of the hessian is particularly fragile to numerical errors when doing;1.7667537;-1.0555744;-4.5219326;-0.67540747;-5.2201266;1.5344003;CODE
simple finite differences here we compute the grad along a path in the direction;1.4189923;-0.1303996;1.1589724;-1.54706;-0.7218641;1.5036699;IRRE
of the vector and then use a least square regression to estimate the slope;3.0893466;-0.4673747;0.67880136;-1.8616129;-3.0239165;2.4319007;IRRE
cs 2 has the highest score 0 8 from mockscorer;0.23453835;1.1499276;-0.75148535;2.8640575;-1.320302;-3.7660794;CODE
scorer called 8 times cv len cs;-0.5447698;0.5517664;-0.14359671;-0.46490252;0.8934888;-2.946994;IRRE
reset mock scorer;-1.6247195;4.186194;0.16394722;4.980555;-1.9667324;-2.4904208;IRRE
clf clone clf avoid side effects from shared instances;-1.962222;0.10387758;-2.0080504;3.5637774;-1.027807;2.7486897;CODE
for numerical labels let y values be taken from set 1 0 1;3.9011688;1.8500341;1.9487656;-7.2078233;-0.15666488;-1.8915637;IRRE
test for string labels;1.9731665;3.3589284;-0.43816793;1.3020116;2.2253554;-6.4240727;CODE
the predictions should be in original labels;1.8707974;-2.5586617;0.66467613;3.1463695;1.0407037;0.7659719;-
cv does not necessarily predict all labels;2.891833;-0.71832365;-4.0963697;1.64293;0.11883701;0.11926605;CODE
we use explicit cs parameter to make sure all labels are predicted for each c;3.4925678;0.04190324;-1.3793426;0.7057083;2.294396;0.07427377;CODE
make sure class weights can be given with string labels;3.3159835;0.075738944;-2.1549003;0.6738957;3.3358507;1.1450418;CODE
todo 1 12 remove deprecated use legacy attributes;-5.102784;0.48468658;-3.3455405;2.3339965;1.2781252;3.7003365;OUTD
test that multinomial logisticregressioncv is correct using the iris dataset;2.539365;0.6736159;-4.9580545;0.7821779;0.39510834;-3.4480479;IRRE
the cv indices from stratified kfold;3.3106463;-2.7721193;-2.787214;-2.106852;2.1630147;0.72280717;CODE
train clf on the original dataset;4.776223;-2.912504;-1.2190882;0.17919856;0.94742984;0.99334985;IRRE
test the shape of various attributes;5.6001277;1.6624475;1.6684073;0.045392398;3.0565917;-3.674623;IRRE
test that for the iris data multinomial gives a better accuracy than ovr;4.040985;0.70385045;-3.4085882;0.5338474;0.43638104;-1.9467436;IRRE
lbfgs requires scaling to avoid convergence warnings;2.316307;0.3634186;-5.0641656;3.016752;-3.1038;4.5463576;CODE
test attributes of logisticregressioncv;2.6030033;1.0456271;-4.5250683;2.310902;0.11070166;-2.883368;IRRE
norm of coefficients should increase with increasing c;1.5122997;0.54648244;-0.43546736;-2.7561288;-3.023077;3.7332702;-
with use legacy attributes true coefs paths is a dict whose keys;-3.5686777;-2.4959877;-5.085408;1.015296;2.0787423;1.9872447;IRRE
are classes and each value has shape;3.0590086;-1.0028358;2.0937936;-3.1446302;4.301782;-0.94139034;IRRE
n folds n l1 ratios n cs n features;4.318274;-2.2290366;-0.6479523;-5.1001344;2.4157405;0.483134;TASK
note that we have to exclude the intercept hence the 1;-0.48193893;2.8136265;0.2181488;-3.8936014;-4.0916214;-0.66459894;TASK
on the last dimension;-0.15123391;-0.60668254;5.1473613;-3.6382265;-0.07606239;1.2612126;CODE
norms np sum coefs coefs axis 1 l2 norm for each c;3.7683375;-0.5588298;-2.6031818;-5.8308167;-2.9778152;2.8794174;CODE
norm of coefficients should increase with increasing c;1.5122997;0.54648244;-0.43546736;-2.7561288;-3.023077;3.7332702;-
with use legacy attributes false coefs paths has shape;-2.9757283;0.1674305;-4.8656397;1.6686825;0.23040098;4.8386626;META
n folds n l1 ratios n cs n classes n features 1;3.843344;-2.8250535;-1.1215047;-4.0892506;4.3489532;-0.68902695;TASK
note that we have to exclude the intercept hence the 1;-0.48193893;2.8136265;0.2181488;-3.8936014;-4.0916214;-0.66459894;TASK
on the last dimension;-0.15123391;-0.60668254;5.1473613;-3.6382265;-0.07606239;1.2612126;CODE
norms np sum coefs coefs axis 1 l2 norm for each c;3.7683375;-0.5588298;-2.6031818;-5.8308167;-2.9778152;2.8794174;CODE
override max iteration count for specific solvers to allow for;1.5328526;2.020956;-1.8383006;2.6115148;-0.5339201;1.5598181;CODE
proper convergence;-0.45167977;1.418465;0.75551516;4.541926;-1.991945;1.2024736;-
xxx lbfgs line search can fail and cause a convergencewarning for some;1.0913068;2.1119914;-4.4019527;2.0498724;-2.4403808;1.0664898;CODE
10 of the random seeds but only on specific platforms in particular;0.2781363;-2.6593459;0.75702876;0.81605494;-0.35620394;-1.2834677;IRRE
when using atlas blas lapack implementation doubling the maxls internal;0.23949765;-0.5374093;-4.159712;-2.0823061;-1.3815013;3.5104275;TASK
parameter of the solver does not help however this lack of proper;-1.3369081;3.5232222;-3.328325;-1.3202869;-2.8938625;0.44226217;CODE
convergence does not seem to prevent the assertion to pass so we ignore;0.398498;3.9703023;-3.7757075;6.2250075;-2.7979457;1.7699121;CODE
the warning for now;-4.582001;-0.6459425;0.3700421;3.4446611;-1.9658499;-0.8042722;CODE
see https github com scikit learn scikit learn pull 27649;-1.3941549;-11.417788;-4.71519;-1.7017174;-3.756224;-4.256806;CODE
todo 1 10 remove filterwarnings with deprecation period of use legacy attributes;-1.0178616;1.3982744;-3.1005714;3.6728501;1.2263987;4.820631;CODE
we weight the first fold 2 times more;-0.14752889;1.4872828;4.097987;0.8094946;-0.8099883;0.19744696;-
lbfgs has convergence issues on the data but this should not impact;4.7874713;0.96369064;-4.4509726;3.3564878;-2.9532175;2.739627;META
the quality of the results;3.802604;-1.5608257;3.1561072;5.6037326;0.89584357;-4.5587993;IRRE
test that passing class weight as 1 2 is the same as;3.0487022;3.8683984;-2.3941796;2.368292;2.4107168;-3.8914235;IRRE
passing class weight 1 1 but adjusting sample weights;4.3035874;1.6993235;-1.7615775;1.674887;1.9198236;2.4826274;IRRE
to be 2 for all instances of class 1;-1.1153793;1.0477388;-0.43563947;0.07159538;6.6529675;-1.5714066;CODE
test the above for l1 penalty and l2 penalty with dual true;1.6864935;4.6296525;-2.3513205;3.1187575;1.6884611;-0.7563009;IRRE
since the patched liblinear code is different;-5.3644567;-1.4843428;-4.426651;1.4191562;-0.8450163;1.85704;-
helper for returning a dictionary instead of an array;-1.0059375;1.2914722;0.6635172;0.40680277;-0.29472592;-0.573022;CODE
scale data to avoid convergence warnings with the lbfgs solver;6.1965547;0.49816772;-4.414217;1.9575485;-3.3311098;2.4778547;CODE
multinomial case remove 90 of class 0;0.24359955;3.4112122;-1.5985839;-2.4294012;4.671076;-3.1781902;CODE
same as appropriate sample weight;4.3443336;0.9441438;2.5304644;1.4209684;2.499842;-1.1190091;-
binary case remove 90 of class 0 and 100 of class 2;-0.634547;2.9722822;-1.9159093;-2.2067223;4.5534964;-3.6665056;CODE
tests for the multinomial option in logistic regression;2.1716328;1.697904;-0.78126997;3.8013475;1.9563997;-3.4642522;IRRE
some basic attributes of logistic regression;2.34029;-3.2583196;1.8339232;1.9028624;1.5410297;-1.7318357;META
lbfgs solver is used as a reference it s the default;-2.1005433;-2.701144;-3.6026857;1.1302333;-1.174199;1.1083734;CODE
compare solutions between lbfgs and the other solvers;2.4887197;1.6104825;-2.1466267;0.7046411;-1.5006729;-0.92384076;IRRE
test that the path give almost the same results however since in this;0.49443138;5.3644943;-1.0984102;4.6431947;-2.16202;-3.4848776;IRRE
case we take the average of the coefs after fitting across all the;5.638865;0.9900877;-0.066758625;1.8605293;-0.6115331;2.870896;CODE
folds it need not be exactly the same;-1.7973841;0.49590418;2.4747617;-1.1027008;0.71046895;3.8803632;-
test negative prediction when decision function values are zero;3.4741433;4.3023643;-2.8171678;4.244278;-1.9362904;-3.0350254;IRRE
liblinear predicts the positive class when decision function values;2.6004093;-3.1154141;-3.349741;2.3398178;1.0557497;-0.3157156;IRRE
are zero this is a test to verify that we do not do the same;-0.4598806;6.4098916;-1.2488142;1.5350658;-2.273679;-7.232349;CODE
see issue https github com scikit learn scikit learn issues 3600;-3.0257022;-8.747498;-6.785041;-0.27549374;-5.9112234;-4.007981;CODE
and the pr https github com scikit learn scikit learn pull 3623;-2.8238704;-10.818926;-4.9588223;0.7503187;-3.3890407;-4.0351753;CODE
dummy data such that the decision function becomes zero;4.0736275;4.3195167;-0.6157636;0.7102424;0.6477556;-0.29458618;CODE
test logregcv with solver liblinear works for sparse matrices;2.918669;-0.96477145;-7.715327;-0.8864063;-2.4662793;2.10539;IRRE
test logregcv with solver liblinear works for sparse matrices;2.918669;-0.96477145;-7.715327;-0.8864063;-2.4662793;2.10539;IRRE
test that intercept scaling is ignored when fit intercept is false;2.9471714;6.2830696;-3.682637;2.0852222;-6.71432;2.3159719;CODE
because liblinear penalizes the intercept and saga does not we do not;-2.0285943;-0.8678606;-2.2312636;2.3218908;-2.8218606;3.4948401;CODE
fit the intercept to make it possible to compare the coefficients of;3.8458607;3.6314967;1.0460958;-1.311586;-2.9260023;0.43567526;CODE
the two models at convergence;1.8439722;-1.3942187;2.3218532;6.7795014;0.2199811;2.1863205;-
because liblinear penalizes the intercept and saga does not we do not;-2.0285943;-0.8678606;-2.2312636;2.3218908;-2.8218606;3.4948401;CODE
fit the intercept to make it possible to compare the coefficients of;3.8458607;3.6314967;1.0460958;-1.311586;-2.9260023;0.43567526;CODE
the two models at convergence;1.8439722;-1.3942187;2.3218532;6.7795014;0.2199811;2.1863205;-
noise and constant features should be regularized to zero by the l1;4.9270916;-0.58711237;-4.5469112;-0.6956399;-0.21081042;5.725638;TASK
penalty;-2.1904392;1.9072111;4.3043013;1.5768403;0.13383591;-1.8719968;-
check that solving on the sparse and dense data yield the same results;6.4600334;0.9974557;-4.377878;-0.16951568;-2.2979488;0.24326344;IRRE
test that when refit true logistic regression cv with the saga solver;1.7948523;0.7995849;-5.214759;5.3570857;-1.6613228;-0.3534567;IRRE
converges to the same solution as logistic regression with a fixed;1.4237661;1.4733148;-1.6401514;3.7649388;-3.6989486;2.78937;-
regularization parameter;3.3940642;1.1343868;-1.111258;-0.7883462;0.9311637;4.9176025;IRRE
internally the logisticregressioncv model uses a warm start to refit on;0.3193527;-2.1753302;-3.3225849;3.3125186;-2.2520206;2.4549384;CODE
the full data model with the optimal c found by cv as the penalized;5.7427883;-1.848075;-1.2172471;2.4123507;1.7603703;2.9536166;-
logistic regression loss is convex we should still recover exactly;2.0781145;-0.523157;-1.7949432;2.5102882;-1.9606025;2.9869764;TASK
the same solution as long as the stopping criterion is strict enough and;1.4169403;3.9667737;-0.2514879;4.5685573;0.71389586;2.90587;-
that there are no exactly duplicated features when penalty l1;0.61551523;-0.39543244;-2.072553;3.9617877;4.101327;2.3661656;TASK
predicted probabilities using the true entropy loss should give a;2.2559838;-1.0516888;-0.3789766;2.8772616;0.48995316;-0.90827835;-
smaller loss than those using the ovr method;4.7179976;1.0215364;-1.1006567;1.5773765;-0.82655567;2.389759;-
predicted probabilities using the soft max function should give a;3.5320175;-0.21028374;0.50718707;1.1480869;-0.013179625;0.078815855;CODE
smaller loss than those using the logistic function;4.244155;0.61452776;-0.6891396;1.0745156;-1.5948609;0.16335295;CODE
test that the maximum number of iteration is reached;2.806386;4.88473;1.9663268;4.294237;-0.90765095;-5.696054;IRRE
test that self n iter has the correct format;-1.4963204;3.9709704;-4.311111;-0.2753287;0.07975271;-6.1721263;CODE
lbfgs requires scaling to avoid convergence warnings;2.316307;0.3634186;-5.0641656;3.016752;-3.1038;4.5463576;CODE
also generate a binary classification sub problem;4.2850604;-2.6439545;-0.60837823;-1.2659228;6.1002626;-3.4935756;IRRE
binary classification case;3.7156124;-2.5201063;-0.23454544;-0.96540695;7.69636;-4.4365654;CODE
multinomial case;1.2170463;1.2107071;3.0353944;-2.003121;5.930181;-3.0932288;CODE
this solver only supports one vs rest multiclass classification;0.93685234;-3.2685277;-3.8736637;0.91441923;3.1810892;1.1273195;CODE
when using the multinomial objective function there is a single;1.3835384;0.9903856;-0.9070554;-1.609916;3.0519292;0.18595068;CODE
optimization problem to solve for all classes at once;4.5191603;-0.4777335;1.3772386;-0.7370959;4.577409;0.74233055;CODE
a 1 iteration second fit on same data should give almost same result;8.832904;4.0326166;-0.55005705;-0.4310796;-1.8524199;1.2348896;IRRE
with warm starting and quite different result without warm starting;-0.5184279;2.5717952;2.7194188;3.1453252;0.2345727;-0.34794453;IRRE
warm starting does not work with liblinear solver;-2.565929;-1.1445111;-3.6773221;0.5753082;-3.8209941;0.52397543;CODE
reproduce the exact same split as default logisticregressioncv;2.758325;-0.52086866;-3.8009923;-0.046816256;0.10761037;2.218296;CODE
some combinations of fold and value of c;0.3810724;1.1987331;1.97863;-4.8830037;1.6966416;-2.9506416;IRRE
train fold 0 folds idx fold 0 0 is training fold;-0.71245766;0.14340018;-2.174685;-2.6014657;1.6637663;0.08414506;-
coefficients without intecept;0.5534861;1.9898663;0.21482566;-3.3711495;0.160961;0.12460084;CODE
intercepts;-0.19795336;0.093012504;4.7351613;-2.1550207;-1.7223866;-1.6249534;CODE
compare elasticnet penalty in logisticregression and sgd loss log;2.0187943;-1.4238412;-3.8921516;3.2872312;-1.2238368;3.4128878;IRRE
make sure that the returned coefs by logistic regression path on a;1.1914356;1.9031066;-3.6371386;3.4416795;-1.782729;0.6513884;IRRE
multiclass multinomial don t override each other used to be a;-0.42199934;0.26270452;-3.1449378;0.42991722;3.833192;1.299184;CODE
bug;-5.940214;1.5497031;1.1962962;2.9229598;-1.6394417;-1.407692;-
for n class 3 coef should be of shape;0.86945146;-1.466307;-0.67029613;-3.0072494;2.5035617;-0.84635437;CODE
n classes features int fit intercept;4.342031;-1.0709388;-2.029196;-3.2451475;1.2102758;-0.8613348;CODE
for the binary case coef should be of shape;1.5325102;1.74097;-3.07368;-4.9365973;3.0311003;-2.6554365;CODE
1 features int fit intercept or;3.2019732;1.5315224;-0.051912405;-2.8502882;-0.24068978;-1.1746194;CODE
features int fit intercept;3.674701;0.70694035;-0.56313723;-2.9408262;-2.0282986;0.10337056;CODE
make sure warning is raised if penalty none and c is set to a;-1.845916;4.9149976;-1.518602;4.530195;-0.05650788;-1.5543472;IRRE
non default value;-2.7919486;5.135963;-0.08330203;-1.235448;0.5135732;-0.83883935;IRRE
make sure setting penalty none is equivalent to setting c np inf with;-0.060924117;2.4890578;-5.2367816;1.1992539;-2.1845253;1.895984;IRRE
l2 penalty;-1.5413345;1.5781043;1.7560177;1.413718;0.08336005;0.37955654;-
xxx investigate thread safety bug that might be related to;-5.4984403;0.679384;-2.4884226;3.391522;-2.3378441;0.7210903;CODE
https github com scikit learn scikit learn issues 31883;-3.2621658;-9.731856;-6.257578;-0.5373271;-4.9049897;-5.2970567;CODE
check that we support sample weight with liblinear in all possible cases;1.9058319;0.36859646;-4.4726715;3.058591;0.7635086;1.6344417;CODE
l1 primal l2 primal l2 dual;-0.638356;-0.67618644;-2.0266597;-0.9523874;2.0974896;3.0275505;-
non regression test for issue 14955;-0.67702514;3.9207046;-4.9832287;3.1503918;-4.17131;-6.3195195;IRRE
when penalty is elastic net the scores attribute has shape;2.8168693;1.089041;0.020055646;0.71284777;0.4493693;2.8425903;META
n classes n cs n l1 ratios;2.8603406;-0.8616008;-0.9184023;-3.0549326;4.1254196;-2.4793026;IRRE
we here make sure that the second dimension indeed corresponds to cs and;-0.60140276;-2.374311;-0.6957959;-3.5934646;0.75675815;3.420994;-
the third dimension corresponds to l1 ratios;1.0461563;-0.7714591;-0.56113255;-6.7609367;-0.17149375;3.06955;-
avg scores lrcv lrcv scores 1 mean axis 0 average over folds;2.9531019;1.388087;-1.8082577;-3.2771773;-3.1379688;1.0925823;CODE
test logistic regression with the iris dataset;3.136841;-1.1108215;-1.6272719;1.8549951;-0.6314822;-3.6588535;IRRE
scaling x to ease convergence;3.844883;-0.1213068;1.8114978;-0.2588065;-4.0710974;4.6859846;-
axis 0 is sum over classes;1.8868945;2.0339046;-1.0411657;-5.9702663;-1.5555085;-0.40475315;IRRE
solvers either accept large sparse matrices or raise helpful error;4.8154945;-1.5803298;-3.799371;-0.65359354;-2.0334659;4.0995765;IRRE
non regression test for pull request 21093;-0.86932373;2.316671;-4.4509706;5.126556;-3.1560009;-3.899415;CODE
generate sparse matrix with int64 indices;3.9173203;-0.16163816;-3.5153658;-7.42613;-1.0566602;1.5910158;IRRE
liblinear freezes when x max 1e100 see issue 7486;-3.5805404;0.04357211;-3.6243966;-0.6414157;-2.780063;2.1065512;-
we preemptively raise an error when x max 1e30;-2.7879746;2.911502;-3.9894624;2.355609;-1.9940419;0.7794769;CODE
generate sparse matrix with int64 indices;3.9173203;-0.16163816;-3.5153658;-7.42613;-1.0566602;1.5910158;IRRE
test that newton cg works with a single feature and intercept;1.764946;1.4696646;-2.5217993;3.9169993;-2.3325813;-1.4989249;CODE
non regression test for issue 23605;-0.98889375;4.0736527;-5.8000255;2.3460097;-3.6964507;-5.9240394;IRRE
non regression https github com scikit learn scikit learn issues 18264;0.9945928;-7.186787;-7.0790167;0.4436513;-6.9137483;-4.0155473;CODE
test that the fit does not raise a convergencewarning;4.3621044;4.1247897;-3.3532665;6.485998;-3.390889;1.047532;CODE
make sure we can inspect the state of logisticregression right after;-2.394161;0.8129937;-1.9196717;5.9805818;-1.2525507;-1.0797797;-
initialization before the first weight update;-0.75723696;1.8614554;-0.53997403;2.9561396;0.21882522;4.80021;CODE
xxx sag and saga have n iter 1;-2.1443136;0.29810962;1.1827027;-4.2246356;1.7768133;0.31542167;-
xxx lbfgs has already started to update the coefficients;-1.0668432;1.5737741;-4.044757;-1.2718945;-4.3023834;1.6368997;CODE
wide data matrix should lead to a rank deficient hessian matrix;4.56529;-0.855614;-3.7187078;-1.5897089;-2.6752722;5.030044;CODE
hence make the newton cholesky solver raise a warning and fallback to;0.57057905;-1.1866887;-4.081914;2.1994407;-3.7793992;1.904857;CODE
lbfgs;-0.99047095;-1.897019;1.9659259;1.274319;0.38107535;-0.6509021;-
c 1e30 very high c to nearly disable regularization;0.4422125;0.4748567;-2.7958229;-0.21495043;-2.8840885;3.5888624;-
check that lbfgs can converge without any warning on this problem;1.4534817;3.1902611;-4.585429;3.1927693;-3.7912245;-0.55716395;CODE
check that the newton cholesky solver raises a warning and falls back to;0.6452205;0.75144273;-5.1563315;1.2839001;-5.523635;-1.2053057;CODE
lbfgs this should converge with the same number of iterations as the;3.238241;2.0849254;-0.37622863;0.9568084;-2.194497;-0.62243116;CODE
above call of lbfgs since the newton cholesky triggers the fallback;-0.28923413;-1.3044596;-2.309285;3.0011237;-1.8196275;2.8034444;IRRE
before completing the first iteration for the problem setting at hand;-1.0195268;2.749718;0.7952092;3.5445604;-0.94738954;1.5575497;CODE
trying to fit the same model again with a small iteration budget should;3.7361033;0.4769993;0.68881303;3.6259694;-0.58244205;2.794494;CODE
therefore raise a convergencewarning;1.1520827;0.8475991;0.1915159;5.9239073;-1.9879025;3.1966968;CODE
todo 1 10 remove filterwarnings with deprecation period of use legacy attributes;-1.0178616;1.3982744;-3.1005714;3.6728501;1.2263987;4.820631;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
make x not of norm 1 for testing;2.8165991;6.243235;-2.5879428;-1.6490709;-2.7837331;0.40862232;IRRE
this makes x n samples n features;5.2451305;-2.7388155;0.28628677;-2.9596841;4.060685;0.16052033;TASK
and y n samples 3;2.0498724;-1.5794728;0.8366758;-3.5897822;1.6417739;-3.2076325;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 5956;-3.3558016;-9.782207;-6.078247;-0.08294195;-5.3149376;-5.1856084;CODE
todo 1 10 move to test sgd py;-1.2765268;1.0856192;-2.5547338;1.5703211;-3.5474288;-3.1578937;TASK
mimic sgd s behavior for intercept;2.3810236;-0.8992211;-1.8021697;-0.2420729;-2.493676;2.795681;CODE
classifier can be retrained on different labels and features;2.4527588;-5.1749854;0.5099214;2.1658554;5.5460434;2.2378087;CODE
todo 1 10 move to test sgd py;-1.2765268;1.0856192;-2.5547338;1.5703211;-3.5474288;-3.1578937;TASK
test class weights;4.692654;2.189813;-0.6019876;3.5225523;1.5255094;-3.7345;IRRE
we give a small weights to class 1;1.9407842;-1.7340997;1.4117161;2.1025894;2.3243234;0.72891825;IRRE
now the hyperplane should rotate clock wise and;-2.0261626;-0.8952377;1.2159475;-2.538273;-1.4041644;2.2316236;-
the prediction on this point should shift;2.838462;0.460218;3.5977085;2.6946073;-2.710725;0.7086012;CODE
partial fit with class weight balanced not supported;2.8922317;2.0187237;-4.7549686;0.91673225;0.88246906;3.3346004;IRRE
already balanced so balanced weights should have no effect;1.1792893;3.1491275;0.16407394;1.5877715;-0.81029147;1.9016958;CODE
should be similar up to some epsilon due to learning rate schedule;3.4464495;-3.9276981;0.60397345;3.7454758;0.9312427;-0.41829884;-
valueerror due to wrong class weight label;0.93695736;1.0797702;-5.0289927;-0.74540454;-1.9643972;-0.69140023;IRRE
todo 1 10 move to test sgd py;-1.2765284;1.08562;-2.5547342;1.5703224;-3.5474308;-3.1578927;TASK
todo 1 10 remove;-4.2360086;2.7419755;3.143769;-0.006628793;-0.09705227;-1.9662911;TASK
check that we raise the proper deprecation warning;-3.7082715;3.0278296;-3.1710408;5.6777287;-1.6385968;-0.4532513;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
for 50 quantile w o regularization any slope in 1 10 is okay;3.598598;2.2512946;0.10037907;-2.9478178;-2.1048162;0.72565126;CODE
if positive error costs more the slope is maximal;2.7500896;2.600777;-0.79709804;0.88267636;-2.62537;1.7069175;-
if negative error costs more the slope is minimal;2.8946612;3.1671946;-1.0938562;1.078316;-3.0886168;1.9844395;-
for a small lasso penalty the slope is also minimal;2.6259122;-0.8696371;-1.38992;0.5462745;-1.8748707;4.477591;CODE
for a large lasso penalty the model predicts the constant median;4.1899405;-1.3434974;-0.51916516;3.1746154;-2.881997;3.8438098;CODE
test how different parameters affect a small intuitive example;3.3508594;4.732037;2.090881;4.013644;-0.7457127;-3.5016828;IRRE
check that we still predict fraction;2.938479;2.430948;1.1817684;3.150249;-3.6469762;-3.7791607;TASK
test that model estimates percentage of points below the prediction;6.2049813;2.608052;1.6204883;4.927914;-2.1291823;-0.6097432;IRRE
test that with unequal sample weights we still estimate weighted fraction;3.922211;4.48004;-2.555852;3.3353007;-1.0466729;0.46802408;TASK
when we increase weight of upper observations;4.2388077;0.8229712;3.3593228;2.9371066;-0.3317503;3.8932104;-
estimate of quantile should go up;1.5133497;3.5546043;1.7489148;1.1158262;-3.2985203;1.5754899;-
generate coordinates of line;0.13674255;0.46203646;4.0105796;-5.4890885;-2.6841524;-0.8597233;-
add some faulty data;2.1218493;2.4130208;1.1436116;1.0539728;0.65201086;-3.7917552;TASK
estimate parameters of corrupted data;5.6738224;2.7186663;-2.1424499;1.605486;-1.8996156;0.457734;IRRE
ground truth reference inlier mask;1.4747417;-0.7938339;-2.562978;-0.7342258;-0.8495986;2.3467548;CODE
there is a 1e 9 chance it will take these many trials no good reason;0.12465361;1.3310516;-0.42878264;4.836948;0.7188526;-2.0067747;-
1e 2 isn t enough can still happen;-2.4296086;2.3952863;0.9634735;2.1048021;-0.5210249;-0.67168385;TASK
2 is the what ransac defines as min samples x shape 1 1;3.7735279;0.5138509;-2.380851;-2.768331;2.5180461;-0.66286266;CODE
gh 19390;-3.0277736;-0.5202805;2.6315317;-1.1240311;0.007221614;-2.2836924;-
3 d target values;4.3193765;2.1051762;2.5237505;-5.485653;-0.16691527;-0.79643404;IRRE
estimate parameters of corrupted data;5.6738224;2.7186663;-2.1424499;1.605486;-1.8996156;0.457734;IRRE
ground truth reference inlier mask;1.4747417;-0.7938339;-2.562978;-0.7342258;-0.8495986;2.3467548;CODE
multi dimensional;3.2043328;-1.2447405;4.2666078;-7.349123;2.5606697;-0.40441048;-
one dimensional;2.6786785;-1.4115047;4.419497;-4.526343;0.942339;-0.20451288;-
estimate parameters of corrupted data;5.6738224;2.7186663;-2.1424499;1.605486;-1.8996156;0.457734;IRRE
ground truth reference inlier mask;1.4747417;-0.7938339;-2.562978;-0.7342258;-0.8495986;2.3467548;CODE
numbers hand calculated and confirmed on page 119 table 4 3 in;-2.0671194;2.6836727;0.17882562;-1.7564566;1.1908796;-4.0692024;CODE
hartley r i and zisserman a 2004;-0.65418005;0.028870123;-0.10829083;-0.43826413;0.74784833;-0.26568735;-
multiple view geometry in computer vision second edition;0.32872283;-2.5467727;2.336078;-3.3098707;1.7619452;3.9100323;CODE
cambridge university press isbn 0521540518;-1.0084682;-5.712319;2.8557193;-1.1813197;1.630072;-1.0238613;-
e 0 min samples x;3.0352137;3.3124166;0.76139206;-3.2487073;-0.768753;-2.01307;-
e 5 min samples 2;2.0630836;0.67737514;3.3030844;-0.030815136;1.2471592;-3.921073;-
e 10 min samples 2;2.351259;0.3081554;3.285257;0.027604166;0.9867968;-3.52105;-
e 30 min samples 2;2.3002148;0.19984026;2.73396;0.55756587;0.7237707;-3.30157;-
e 50 min samples 2;2.551861;0.6255178;2.7197864;0.23851515;0.6643953;-3.3720338;-
e 5 min samples 8;1.9813194;0.10843595;3.1031559;0.2176027;1.0045848;-3.3901148;-
e 10 min samples 8;2.370681;-0.39716974;3.057216;0.32452035;0.81668264;-3.047223;-
e 30 min samples 8;2.3296509;-0.29476947;2.625647;0.7997437;0.5933935;-2.8477583;-
e 50 min samples 8;2.6327658;0.017742226;2.727269;0.4308173;0.5948226;-2.8951554;-
e 0 min samples 10;3.6467493;2.6029027;1.1589854;-2.7178893;-0.423069;-3.4739394;-
sanity check;-2.0208912;3.6404388;2.9253924;3.8377485;-0.29781756;-4.864077;-
check that mask is correct;-1.5933368;2.4782507;0.5860991;-2.1961474;-1.6376239;-0.8068343;-
check that fit x fit x1 x2 x3 sample weight n1 n2 n3 where;4.535739;4.58144;-2.7071943;-3.516839;1.0381997;-0.8767742;-
x x1 repeated n1 times x2 repeated n2 times and so forth;1.1513261;1.43656;2.9442863;-5.4754405;2.0598962;-2.8600092;CODE
check that if estimator fit doesn t support;1.8049008;4.348312;-3.7723663;2.9138393;-5.111442;1.738376;CODE
sample weight raises error;2.496927;3.4396832;-3.4841266;1.7280573;-2.4622214;-0.8568687;CODE
make larger dim more than double as big as the smaller one;0.271383;2.1554503;1.7682418;-3.1544256;-0.9400329;2.3184144;CODE
this helps when constructing singular matrices like x x;2.2689898;-0.70098275;-1.4479424;-3.7166052;0.70101947;4.7795696;CODE
x 1 1 last columns acts as intercept;1.1802205;2.876531;0.10389755;-6.6661487;-2.8519273;0.7623199;CODE
assert np all s 1e 3 to be sure;1.1272998;3.8496368;-5.4898615;2.0420732;0.614424;-5.421004;IRRE
add a term that vanishes in the product x y;-1.6634911;2.090239;0.51229537;-2.4709375;-0.47292784;1.1796726;TASK
w x xx 1 y v s 1 u y;-1.5883787;-0.50984603;1.8097752;-3.9049704;1.364245;-1.4777061;-
add penalty alpha coef 2 2 for alpha 1 and solve via normal equations;0.41062897;1.5682467;-2.3364844;-2.0051312;-2.7677915;2.9698105;TASK
note that the problem is well conditioned such that we get accurate results;7.0954685;2.3177593;0.5687242;6.4189363;0.48562017;-1.3229076;TASK
d 1 1 0 intercept gets no penalty;-1.8631665;3.975127;-0.87435764;-1.1218146;-2.846956;-0.039458945;CODE
to be sure;-1.0003752;0.17772356;3.2489638;4.0153337;-1.0458624;-3.5964289;-
alpha 1 0 because ols ridge dataset uses this;2.420747;-1.4464347;-2.425576;-4.1672597;-2.6863139;0.5988484;IRRE
calculate residuals and r2;0.727859;2.4113946;2.171812;-1.3562748;-3.2644815;-0.7057222;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
same with sample weight;4.182051;1.2892798;1.9825329;1.8257021;0.54765254;-0.468572;-
alpha 1 0 because ols ridge dataset uses this;2.420747;-1.4464347;-2.425576;-4.1672597;-2.6863139;0.5988484;IRRE
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
coefficients are not all on the same magnitude adding a small atol to;1.0858082;2.8361616;-2.012096;-3.4683433;-5.1031795;0.9479964;TASK
make this test less brittle;1.8036873;4.9665794;-2.2586613;4.7126093;-1.9938855;-5.6407847;IRRE
alpha 1 0 because ols ridge dataset uses this;2.420747;-1.4464347;-2.425576;-4.1672597;-2.6863139;0.5988484;IRRE
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
coefficients are not all on the same magnitude adding a small atol to;1.0858082;2.8361616;-2.012096;-3.4683433;-5.1031795;0.9479964;TASK
make this test less brittle;1.8036873;4.9665794;-2.2586613;4.7126093;-1.9938855;-5.6407847;IRRE
alpha 0 ols;-1.636081;0.061740275;0.93490046;-3.2970424;-1.766136;-2.8912868;-
note that cholesky might give a warning singular matrix in solving dual;1.8845296;-0.9190519;-5.8424416;-1.4107835;-1.4788164;4.410873;TASK
problem using least squares solution instead;3.1021068;1.0625361;-0.18750581;-2.2569098;-3.7747586;1.612013;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
fixme assert allclose model coef coef should work for all cases but fails;-1.1682421;3.7904727;-6.8957243;4.634909;-2.5521743;0.9612454;CODE
for the wide fat case with n features n samples the current ridge solvers do;6.695652;-4.0001864;-3.2492661;-1.1421648;-0.07816436;4.489184;CODE
not return the minimum norm solution with fit intercept true;3.1473603;3.7190874;-3.0723283;-1.6740631;-4.2771;3.9466062;CODE
as it is an underdetermined problem residuals 0 this shows that we get;1.4904176;2.7049716;-3.075226;-0.16729017;-3.8992708;2.3428168;CODE
a solution to x w y;-1.3764055;0.38058683;2.8937058;-3.5090165;-0.04857872;-0.46322045;-
but it is not the minimum norm solution this should be equal;1.4678242;2.403705;-2.237026;-3.2091537;-1.9107361;3.9831848;META
alpha 0 ols;-1.6360815;0.061739232;0.93490136;-3.2970424;-1.7661357;-2.8912854;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
cholesky is a bad choice for singular x;0.7111281;-0.7199492;-3.110302;-1.877972;-0.7313807;2.1990738;CODE
fixme same as in test ridge regression unpenalized;1.1826463;0.27983168;-3.7275121;2.1376224;-3.272651;2.6999333;IRRE
as it is an underdetermined problem residuals 0 this shows that we get;1.4904203;2.7049706;-3.0752265;-0.1672904;-3.8992693;2.3428183;CODE
a solution to x w y;-1.3764055;0.38058683;2.8937058;-3.5090165;-0.04857872;-0.46322045;-
but it is not the minimum norm solution this should be equal;1.4678242;2.403705;-2.237026;-3.2091537;-1.9107361;3.9831848;META
alpha 0 ols;-1.6360815;0.061739232;0.93490136;-3.2970424;-1.7661357;-2.8912854;-
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
fixme same as in test ridge regression unpenalized;1.1826463;0.27983168;-3.7275121;2.1376224;-3.272651;2.6999333;IRRE
as it is an underdetermined problem residuals 0 this shows that we get;1.4904191;2.704972;-3.075225;-0.1672905;-3.8992693;2.3428178;CODE
a solution to x w y;-1.3764055;0.38058683;2.8937058;-3.5090165;-0.04857872;-0.46322045;-
but it is not the minimum norm solution this should be equal;1.4678242;2.403705;-2.237026;-3.2091537;-1.9107361;3.9831848;META
x x 1 remove intercept;-0.20640557;4.1423874;0.92032105;-4.414641;-2.5315473;0.68682635;CODE
test shape of coef and intercept;1.8158699;2.8178;-0.2670484;-1.2349446;-4.1784754;-1.6191226;IRRE
test intercept with multiple targets gh issue 708;0.5494183;4.59442;-3.594862;1.4652736;-3.3592243;-0.5036641;CODE
on alpha 0 ridge and ols yield the same solution;0.12985846;0.6245627;-3.1544683;-3.5715208;-4.410584;3.281332;CODE
we need more samples than features;3.8451033;-4.847948;0.9920724;3.434771;3.5777576;-0.4146155;TASK
tests the ridge object using individual penalties;4.579086;1.5495065;-1.0392271;1.5044354;-1.7819567;-0.028997138;IRRE
test error is raised when number of targets and penalties do not match;1.1756315;6.776609;-4.1662054;4.6026406;-2.2991595;-3.2623503;CODE
manually scale the data to avoid pathological cases we use;6.408329;-0.6347614;2.0884793;-0.022708293;-0.18853924;2.1185079;CODE
minmax scale to deal with the sparse case without breaking;5.417409;1.423944;-0.893091;-1.7667251;0.43182936;4.6855044;CODE
the sparsity pattern;3.9659736;-2.2460232;2.231658;-1.6244723;0.8206181;2.7191734;-
avoid convergencewarning for sag and saga solvers;2.2588792;-1.788767;-2.7209773;3.6373742;-2.0348341;4.50858;CODE
checking on asymmetric scoring;3.6435988;3.633656;0.9869252;2.2566328;0.6760722;-5.054155;-
test that can work with both dense or sparse matrices;5.483799;2.323712;-3.144542;0.22272606;-0.5423271;0.5512192;IRRE
check best alpha;-0.09429559;0.033381145;2.1731293;2.1522555;-1.6705079;-4.5350294;-
check that we get same best alpha with custom loss func;0.9734604;1.6635793;-2.1717527;2.8159332;-0.5381895;1.6835834;-
check that we get same best alpha with custom score func;1.4590682;2.4026434;-1.5089918;2.6669755;0.5852509;-1.3225266;-
check that we get same best alpha with a scorer;1.0973532;2.352138;1.2631075;2.8894048;-0.30029675;-1.595515;-
check that we get same best alpha with sample weights;5.865258;2.4391806;-0.7593526;2.4867597;0.48730412;-0.094114885;-
simulate several responses;2.0935447;2.5601547;4.6723785;2.8173566;0.8868133;-1.4994516;CODE
check that cv results is not stored when store cv results is false;2.1839154;5.4810643;-3.965411;3.7390666;-0.71073;-1.7097098;IRRE
check that the best score is store;1.8073032;1.9716947;0.87532103;2.4586887;0.6977564;-3.987661;-
ridge clone ridge avoid side effects from shared instances;-0.32855546;-0.5258205;-1.6000559;1.5439464;-1.589785;5.0944295;CODE
tests the ridge cv object optimizing individual penalties for each target;5.6365275;-0.872612;-2.4822946;2.7993112;-0.19945619;2.4192731;CODE
create random dataset with multiple targets each target should have;5.2729435;-1.723697;1.261956;0.39443412;3.3647387;0.993395;IRRE
a different optimal alpha;2.7655427;1.0022159;1.9439828;-0.057929214;0.20622757;1.7438983;-
find optimal alpha for each target;5.0942335;0.9201639;2.5226567;-1.2728897;-0.6350794;1.3735743;CODE
find optimal alphas for all targets simultaneously;4.9099016;1.0400589;2.1406205;-0.93361264;-0.23921108;2.795497;CODE
the resulting regression weights should incorporate the different;3.639375;0.9587875;0.23226178;0.9530616;-0.24591085;3.403935;IRRE
alpha values;0.2187076;2.2807527;2.0434525;-3.0505967;-1.4836435;-4.0462346;IRRE
test shape of alpha and cv results;4.9446673;1.8862448;-0.46502304;-0.6717205;-1.3970982;-2.6474366;IRRE
test edge case of there being only one alpha value;1.1222407;6.2815967;-0.5780606;-0.8959879;-0.33007377;-4.5710564;IRRE
test edge case of there being only one target;1.5741953;5.703423;0.07196092;2.6930346;0.72269875;-3.3744025;IRRE
try with a custom scoring function;3.6165104;1.6373581;1.859533;1.1552682;1.6323228;-2.0235884;CODE
using a custom cv object should throw an error in combination with;-0.2645545;3.1542876;-4.733142;3.6432495;1.7097718;0.30305856;CODE
alpha per target true;1.5054327;1.6165258;1.4282062;1.7518777;0.11186058;-0.537747;-
simulate several responses;2.0935447;2.5601547;4.6723785;2.8173566;0.8868133;-1.4994516;CODE
non regression test for 14672;0.15748835;3.2069376;-3.9745436;3.1313438;-3.5821133;-6.729968;IRRE
check that ridgeclassifiercv works with all sort of scoring and;4.5578976;-2.1552446;-4.0148044;-0.33474118;-1.1723579;1.3399495;IRRE
cross validation;2.493245;1.2475493;2.397642;1.889912;3.7310712;-3.8565283;-
smoke test to check that fit predict does not raise error;3.8018954;4.4597306;-3.74245;5.503468;-3.208525;-0.93026507;CODE
check that custom scoring is working as expected;1.1356112;4.816693;-1.8689252;3.1115243;-0.024328616;-3.1760721;-
check the tie breaking strategy keep the first alpha tried;-0.8563389;3.8970163;2.1226482;3.2283628;-0.7891523;-2.1660087;CODE
in case of tie score the first alphas will be kept;-1.1260105;2.3213644;3.129145;1.7369739;0.9196184;-0.61733115;CODE
ridgegcv is not very numerically stable with float32 it casts the;0.75173086;-0.14543422;-5.3639565;-4.357579;-4.7250633;2.5594249;IRRE
input to float64 unless the device and namespace combination does;-2.305164;2.4297948;-2.2895565;-3.4370048;-2.303569;0.2340063;CODE
not allow float64 specifically torch with mps;-4.844102;0.73926014;-2.6979415;-3.7335525;-2.2604525;3.0696335;IRRE
all numpy namespaces are compatible with all solver in particular;-0.91680205;-2.8462958;-5.956685;-2.683701;-5.0557947;1.6387888;-
solvers that support positive true like lbfgs should work;2.3003662;2.1011984;-4.3381853;0.3184731;-1.341855;0.1495304;-
test dense matrix;4.116903;3.6158996;-2.6438515;-0.97206575;-1.8422644;-2.176705;IRRE
test sparse matrix;6.28019;2.4068792;-2.5185935;-0.7501953;-1.3729798;-1.7494153;IRRE
test that the outputs are the same;3.255286;5.6184397;-0.043362655;1.6145378;0.38296738;-6.0614443;IRRE
test class weights;4.692654;2.189813;-0.6019876;3.5225523;1.5255094;-3.7345;IRRE
we give a small weights to class 1;1.9407831;-1.7340999;1.4117153;2.1025896;2.3243237;0.7289186;IRRE
now the hyperplane should rotate clock wise and;-2.0261626;-0.8952377;1.2159475;-2.538273;-1.4041644;2.2316236;-
the prediction on this point should shift;2.838462;0.460218;3.5977085;2.6946073;-2.710725;0.7086012;CODE
check if class weight balanced can handle negative labels;3.0774424;2.892269;-2.6323254;0.22693944;2.5875661;-0.33414924;IRRE
class weight balanced and class weight none should return;1.7315066;3.6156826;-2.695711;1.0620009;0.47163334;-1.2307526;IRRE
same values when y has equal number of all labels;3.5906646;3.6897595;2.9012895;-5.0113378;1.2147713;-2.9808278;IRRE
there are different algorithms for n samples n features;5.753426;-3.684942;-1.6733714;-1.8970221;2.9897783;-0.4162802;TASK
and the opposite so test them both;-0.5273781;3.0625417;1.2534937;4.9633784;0.43319967;-5.0068517;IRRE
check using gridsearchcv directly;1.0305926;2.1608167;-3.084437;0.986661;-1.2683301;-1.3648663;-
sample weights must be either scalar or 1d;4.4467425;1.6766672;-4.4477158;-2.6533499;-1.1483713;1.8285505;TASK
make sure the ok sample weights actually work;4.0543437;1.8596311;-2.8638642;2.5920014;-2.3384178;0.44286782;META
sample weights must work with sparse matrices;6.1761675;-1.3069832;-3.2588844;-1.5124327;-0.21958965;4.922154;IRRE
integers;-1.535075;1.6926205;4.1309;-3.6342149;1.1508596;-5.8508134;CODE
test excludes svd solver because it raises exception for sparse inputs;3.6085398;2.197572;-8.218359;2.491042;-1.7738633;0.71475315;CODE
check type consistency 32bits;-3.039717;5.2073956;-5.981262;0.7984057;2.5558274;-1.743899;-
check type consistency 64 bits;-2.7791088;4.5713124;-5.339287;-0.25223535;1.3599617;-3.4100041;-
do the actual checks at once for easier debug;-0.96571916;2.316169;-0.13078105;3.6898317;-0.43607754;-4.034059;CODE
test different alphas in cholesky solver to ensure full coverage;3.042652;2.1854267;-4.0987916;1.0934924;-1.4140255;-0.23663776;IRRE
this test is separated from test dtype match for clarity;1.2176796;2.3547664;-4.613017;1.2606834;1.892912;-5.7284827;CODE
check type consistency 32bits;-3.039717;5.2073956;-5.981262;0.7984057;2.5558274;-1.743899;-
check type consistency 64 bits;-2.7791088;4.5713124;-5.339287;-0.25223535;1.3599617;-3.4100041;-
do all the checks at once like this is easier to debug;-1.397047;2.427776;0.29423904;3.17451;0.42977342;-4.558272;CODE
xxx sparse cg seems to be far less numerically stable than the;1.9947829;-0.39050427;-4.220665;-2.396881;-3.0582678;3.1329029;IRRE
others maybe we should not enable float32 for this one;-3.9786308;-2.1653237;-2.5789447;-2.2518926;-3.1831782;1.3532519;CODE
check that fortran array are converted when using sag solver;1.6833313;2.3530083;-4.7276015;-1.9888914;-4.5427504;-0.981763;CODE
for the order of x and y to not be c ordered arrays;1.2958277;3.240034;-0.35357124;-5.522888;-0.875962;-1.6960822;CODE
case of multioutput;2.106016;-0.5036052;2.2163942;-0.11781533;2.7814417;-0.5852457;IRRE
single output this part of the code should not be reached in the case of;-2.9149668;6.12742;0.08164505;-0.14171043;-0.71295065;-3.85041;CODE
multioutput scoring;5.410717;-2.1673076;2.2447999;0.9017389;2.2138512;-3.4175766;IRRE
return mean errors pragma no cover;0.866194;5.769139;-3.0234437;2.4154115;-3.4873183;-2.808167;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
this is used for sag classification;1.6603879;-4.2072344;2.1687152;0.92238754;3.2563846;0.25749037;CODE
approximately equal and saves the computation of the log;1.4113168;2.3008635;0.98587817;0.23943701;-2.0159419;-1.3554285;CODE
this is used for sag regression;1.1318445;-3.208124;1.54924;0.40489745;-0.28322092;1.254362;CODE
function for measuring the log loss;2.4677665;0.89792216;1.0819827;1.333835;-1.9279796;-0.7469865;CODE
sparse data has a fixed decay of 01;4.138528;0.4554235;-3.4925883;-1.8960451;-2.431655;0.49722084;IRRE
idx k;-2.463445;-1.642987;2.7480843;-3.4823396;2.5204372;-1.8813359;-
sparse data has a fixed decay of 01;4.138528;0.4554235;-3.4925883;-1.8960451;-2.431655;0.49722084;IRRE
idx k;-2.463445;-1.642987;2.7480843;-3.4823396;2.5204372;-1.8813359;-
y must be 0 or 1;-1.2955184;3.128357;0.47429132;-4.033149;-2.5834339;-4.741613;TASK
saga variance w r t stream order is higher;1.5055481;0.018896798;-1.1744286;-0.8349914;-1.7074653;3.7607932;CODE
2 y 1 y must be 1 or 1;-1.0002197;1.4296219;0.13114056;-3.1507308;0.55491334;-3.748571;TASK
2 y 1 y must be 1 or 1;-1.0002197;1.4296219;0.13114056;-3.1507308;0.55491334;-3.748571;TASK
simple linear function without noise;3.5359123;1.7579888;1.1771715;-2.7949734;-2.6499345;1.1545388;CODE
simple linear function with noise;3.6717162;1.4952433;0.7999995;-2.6137385;-2.6007867;1.4305669;CODE
note the very crude accuracy i e high rtol;3.2186828;-1.1533273;0.29973596;0.22778358;-1.7137089;-1.753332;TASK
xxx untested as of v0 22;-3.9396555;2.3748124;-2.8836467;0.17303783;0.5737305;-2.378341;IRRE
test data;4.9782953;3.7145596;3.5389454;2.529613;1.4033569;-8.802647;IRRE
test sample 1;1.0420071;5.573231;2.1273274;1.6454653;1.6077108;-8.21046;IRRE
test sample 2 string class labels;2.1097105;2.7403119;-1.6231353;0.8694597;3.5816119;-5.0814853;IRRE
test sample 3;0.60255426;4.5514646;2.1877344;0.2756583;2.2177098;-8.817728;IRRE
test sample 4 two more or less redundant feature groups;3.1637304;2.1286433;-0.83845544;2.4507518;4.1731544;-1.3473444;IRRE
test sample 5 test sample 1 as binary classification problem;3.2649062;2.0203972;-2.8745973;-0.5262769;5.06681;-5.766896;IRRE
common test case to classification and regression;4.830719;-1.1086009;-0.26356113;6.4445643;3.0499694;-3.190112;IRRE
a simple implementation of asgd to use for testing;-0.6454886;0.8328435;-1.5539922;2.1974628;2.1741273;-1.3925967;TASK
uses squared loss to find the gradient;0.9283672;-1.650259;1.1727806;-1.6894695;-2.7480388;1.38865;-
sparse data has a fixed decay of 01;4.138525;0.45542344;-3.4925878;-1.8960446;-2.431656;0.49722022;IRRE
test that explicit warm restart;-1.2868273;2.8221939;-0.2715407;6.409189;-1.47537;-2.3053856;IRRE
and implicit warm restart are equivalent;-2.4020846;-0.40493685;1.0765206;4.25351;0.45292965;2.6762247;-
input format tests;1.4654726;2.4754422;-1.1379992;0.23653114;0.61310714;-7.5240564;CODE
todo 1 10 remove this test;-3.0449722;5.832788;-0.8860404;3.1743498;-1.4538953;-6.3706603;CODE
multi class test case;1.650004;2.7375271;0.1492933;3.2714067;6.129015;-4.7818236;IRRE
multi class average test case;3.5445182;2.513097;0.070049904;1.9406023;3.964338;-3.1108103;CODE
multi class test case;1.650004;2.7375271;0.1492933;3.2714067;6.129015;-4.7818236;IRRE
multi class test case with multi core support;0.923234;0.37851563;-2.5239239;5.437428;3.7060783;-0.14349447;IRRE
checks coef init and intercept init shape for multi class;0.8959354;2.401812;-3.317312;0.99985445;1.1143659;0.4654508;IRRE
problems;-3.0171123;-0.553015;4.68023;0.62431496;-0.48628157;-4.6495686;-
provided coef does not match dataset;3.1612198;-0.00092991197;-5.5423775;-0.18094712;-0.94601125;-0.7014091;IRRE
provided coef does match dataset;5.436818;-1.0407774;-3.2813966;0.21349221;2.1291523;-0.5510283;IRRE
provided intercept does not match dataset;2.317331;1.8450916;-3.7058165;-0.9925753;-2.7360985;-0.3895411;CODE
provided intercept does match dataset;4.422971;1.3350761;-1.5465486;-0.51613575;0.3385463;-0.6150993;CODE
checks that sgdclassifier predict proba and predict log proba methods;3.2882223;-3.1871245;-5.87819;4.800341;1.9277574;-0.4045413;IRRE
can either be accessed or raise an appropriate error message;-7.612379;2.3929799;-0.9890943;4.2327976;-1.201344;-0.3092241;CODE
otherwise see;-2.8890011;-0.7327737;1.33149;0.5986838;-0.13135257;-1.1382492;-
https github com scikit learn scikit learn issues 10938 for more;-3.171519;-9.973488;-6.26453;-0.47763973;-4.7945223;-4.9517646;CODE
details;-1.9197476;-2.4566455;5.9425316;0.8847738;1.0150981;-1.1708876;-
check sgd predict proba;4.1546454;-0.47110704;-2.4124315;2.9590082;-1.3564837;-1.8104564;-
hinge loss does not allow for conditional prob estimate;0.35105628;3.4636633;-2.9392016;2.94927;-1.8789269;4.340215;CODE
we cannot use the factory here because it defines predict proba;1.9765573;-1.3025221;-1.4614211;4.798384;1.4413004;-0.6023081;IRRE
anyway;-2.7767022;-0.91247493;2.5929296;-0.4887096;0.6263005;-0.5336386;-
log and modified huber losses can output probability estimates;3.0814197;-2.5023673;-0.5847515;1.3556895;-0.4312236;4.089758;IRRE
binary case;-0.8755281;2.0601676;1.2152951;-4.2926903;6.311612;-6.347426;CODE
if predict proba is 0 we get runtimewarning divide by zero encountered;3.3673923;1.3010306;-4.221094;2.77786;-1.5014426;-1.3274249;CODE
in log we avoid it here;-3.494149;1.5551381;-0.38135412;3.0288405;-2.2623076;-0.46390417;CODE
log loss multiclass probability estimates;3.8646743;-2.7693713;-2.2460947;2.5166388;2.7694976;2.5749273;IRRE
modified huber multiclass probability estimates requires a separate;2.6532114;-2.312161;-3.9373143;2.2064476;2.8097723;5.772484;CODE
test because the hard zero one probabilities may destroy the;1.2492796;4.965221;-0.9358719;3.5200038;-0.082012735;-5.2791233;IRRE
ordering present in decision function output;1.934435;2.0994713;0.9163867;-1.0552772;2.7654326;-1.0138981;IRRE
else xxx the sparse test gets a different x2;2.6818626;5.0718656;-4.5805426;-0.60467285;-0.78020054;-2.0773273;IRRE
the following sample produces decision function values 1;4.928671;2.4376984;-0.0052757324;-0.99105495;1.1826254;-4.3129106;IRRE
which would cause naive normalization to fail see comment;0.0654766;0.20946743;-3.4489062;1.8349862;-0.4753993;0.80378;-
in sgdclassifier predict proba;4.137272;-4.095952;-3.9825938;1.6572775;2.796306;-0.74791324;IRRE
if np all d 1 xxx not true in sparse test case why;3.7260697;4.0652237;-6.651997;-0.8446625;-0.74450904;-2.1560829;IRRE
test l1 regularization;4.819366;2.8632662;-3.2728164;2.3065774;0.34996223;0.08550583;IRRE
test sparsify with dense inputs;4.300403;1.6831646;-1.8795513;3.1376295;-0.5336318;-0.92608416;IRRE
pickle and unpickle with sparse coef;3.2868245;-1.5320795;-1.9341811;-1.8275267;-0.35236534;2.6608367;IRRE
test class weights;4.692654;2.189813;-0.6019876;3.5225523;1.5255094;-3.7345;IRRE
we give a small weights to class 1;1.9407842;-1.7340997;1.4117161;2.1025894;2.3243234;0.72891825;IRRE
now the hyperplane should rotate clock wise and;-2.0261626;-0.8952377;1.2159475;-2.538273;-1.4041644;2.2316236;-
the prediction on this point should shift;2.838462;0.46021703;3.5977066;2.6946087;-2.710725;0.7086016;CODE
test if equal class weights approx equals no class weights;4.7408657;4.3773303;-2.8814356;3.2355957;0.8467687;-1.5176007;IRRE
should be similar up to some epsilon due to learning rate schedule;3.4464495;-3.9276981;0.60397345;3.7454758;0.9312427;-0.41829884;-
valueerror due to not existing class label;-1.4532944;1.1189399;-4.8013916;0.6399804;-0.07896685;-1.581291;IRRE
tests that class weight and sample weight are multiplicative;4.717424;2.114227;-1.9291234;2.7276974;2.4840214;-1.8412354;IRRE
non regression test for 23255;0.08139229;3.2577837;-3.7433407;2.7732787;-3.1583025;-7.0811353;IRRE
check that the sparse coef property works;4.010486;1.5965106;-5.8230762;-0.123816505;-1.3309573;3.293027;IRRE
check that the sparse lasso can handle zero data without crashing;3.165299;1.4910574;-4.09474;1.2887517;-1.815318;1.7870923;IRRE
test elasticnet for various values of alpha and l1 ratio with list x;4.0630474;3.374976;-2.3260543;-0.40671235;-1.1632384;-0.48657283;IRRE
y 1 0 1 just a straight line;-1.2709645;1.5544801;4.1182384;-4.833673;-3.9625607;-2.7233338;-
t np array 2 3 4 test sample;3.9106152;4.069368;-2.5675993;-3.7673707;-1.803138;-4.990038;IRRE
this should be the same as unregularized least squares;5.667139;-2.015813;-1.8063786;-0.71770006;-1.3133047;4.973463;CODE
catch warning about alpha 0;-4.400215;3.3244;-3.7947776;2.6504438;-3.141905;-3.3602886;CODE
this is discouraged but should work;-3.236114;-2.6080275;4.4163413;2.1149454;0.61864203;1.2931163;META
test elasticnet for various values of alpha and l1 ratio with sparse x;4.4711027;1.4448237;-3.7841291;-1.1457633;-2.503143;2.0322127;IRRE
training samples;5.6865387;-4.4665546;2.4762259;2.9833963;3.4423862;-3.4638374;-
x 1 0 0;-1.2639314;2.6768537;2.8576667;-5.6830516;-0.7793303;-3.4365692;-
y 1 0 1 just a straight line the identity function;-2.4023714;1.2615811;2.3694623;-4.5939116;-1.993099;-1.7025632;CODE
test samples;4.5546703;2.2021575;2.8846357;2.9201732;2.5435987;-7.83056;IRRE
this should be the same as lasso;3.743192;-3.621519;1.6908168;0.6069354;-0.19335811;3.4997277;CODE
build an ill posed linear regression problem with many noisy features and;6.6634345;-1.059335;-0.47851628;-0.061170276;0.0115315365;4.162062;TASK
comparatively few samples;4.9795747;1.5962963;0.22215295;0.59802157;-1.0112045;-3.6176686;-
generate a ground truth model;3.011821;-0.5581828;-0.049054127;1.7970675;2.54098;-0.6879185;-
w n informative 0 0 only the top features are impacting the model;1.7536013;-1.7713138;-2.2117221;1.0841962;-0.28180632;2.2189498;TASK
x rnd 0 5 0 0 50 of zeros in input signal;2.4960487;3.52127;-1.078067;-5.8535404;-1.9101223;-2.0375633;CODE
generate training ground truth labels;3.3231866;-2.9218605;-0.7126048;-0.56231326;3.7725604;-0.8713196;-
check the convergence is the same as the dense version;0.16704635;1.8973643;-3.197862;3.153813;-3.542009;2.0672357;META
check that the coefs are sparse;3.6599913;1.0090187;-5.3264103;0.70083064;-1.877662;0.044907555;IRRE
check the convergence is the same as the dense version;0.16704635;1.8973643;-3.197862;3.153813;-3.542009;2.0672357;META
check that the coefs are sparse;3.6599913;1.0090187;-5.3264103;0.70083064;-1.877662;0.044907555;IRRE
xxx there is a bug when precompute is not false;-4.5942483;3.9113572;-3.904549;2.5856934;-3.3072803;-2.001155;-
compare with dense data;7.361783;0.4038454;1.1248127;0.3351439;1.1590152;-3.2004516;IRRE
balance property;-0.71168005;2.387647;2.7957683;0.6226081;2.4255888;-0.093394324;-
make x data read only;0.07207265;3.6269457;0.75246865;-1.0300647;-0.672742;1.3321664;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
linear model y 3 x n 2 0 1 2;1.3743372;1.8147699;-0.23043382;-5.2656875;-1.879961;-0.5635015;-
add some outliers;4.5602713;-0.09494259;2.9461763;0.4609042;-0.23813012;-1.1692656;TASK
linear model y 5 x 1 10 x 2 n 1 0 1 2;2.9266796;2.1084158;0.9404952;-5.2757173;-2.155924;-1.0838255;-
add some outliers;4.5602713;-0.09494259;2.9461763;0.4609042;-0.23813012;-1.1692656;TASK
linear model y 5 x 1 10 x 2 42 x 3 7 x 4 n 1 0 1 2;3.5681612;2.391904;0.47794396;-5.981105;-1.5046592;-1.1958057;-
add some outliers;4.5602713;-0.09494207;2.9461758;0.46090418;-0.23813006;-1.1692652;TASK
check startvalue is element of x and solution;-1.7842807;7.238396;0.7490738;0.7602526;0.8344645;-2.8261285;IRRE
check startvalue is not the solution;-3.5521164;7.696134;-0.9294652;2.7792275;-1.3691279;-1.9549768;IRRE
check startvalue is not the solution but element of x;-2.264375;8.416475;-0.5166017;0.8139802;-0.8703083;-3.461876;IRRE
check that a single vector is identity;1.0161364;1.8749186;-2.4901433;-3.1825895;1.0687156;-1.9438249;-
check first two iterations;1.3540301;6.0753584;3.312433;1.5422944;0.2677774;-6.158998;-
check fix point;-1.724475;3.361973;1.1571065;1.9201798;-2.503569;-4.15048;CODE
test larger problem and for exact solution in 1d case;3.4225824;6.0327563;-0.3500182;0.16414164;-1.428574;-2.0137372;CODE
check if median is solution of the fermat weber location problem;0.59167135;3.4545622;1.4534177;-0.85838497;-1.9929924;-1.2555187;IRRE
check when maximum iteration is exceeded a warning is emitted;1.6181518;5.1446004;-0.6393019;6.40485;-1.2550174;-2.4184628;-
check that least squares fails;5.6047993;3.9520686;-3.824246;0.27360556;-4.828028;-1.1375803;-
check that theil sen works;-5.0600986;0.6770268;-0.6899065;3.3114643;-1.7349513;-0.28043586;-
check that least squares fails;5.6047993;3.9520686;-3.824246;0.27360556;-4.828028;-1.1375803;-
check that theil sen works;-5.0600986;0.6770268;-0.6899065;3.3114643;-1.7349513;-0.28043586;-
non regression test for 18104;-0.028793396;3.6342719;-3.431914;2.9423113;-3.616569;-6.4587884;IRRE
check that least squares fails;5.6047993;3.9520686;-3.824246;0.27360556;-4.828028;-1.1375803;-
check that theil sen works;-5.0600986;0.6770268;-0.6899065;3.3114643;-1.7349513;-0.28043586;-
check for exact the same results as least squares;6.3935895;2.9624164;-1.5271552;-0.55672073;-3.6903892;-1.3507198;IRRE
pytest mark thread unsafe manually captured stdout;-3.4542491;1.6311595;-2.386387;2.2372425;-4.13873;0.8035803;CODE
check that theil sen can be verbose;-4.542149;2.1115086;-1.6921355;4.442209;0.16531014;-1.9551166;IRRE
check that least squares fails;5.6047993;3.9520686;-3.824246;0.27360556;-4.828028;-1.1375803;-
check that theil sen works;-5.0600986;0.6770268;-0.6899065;3.3114643;-1.7349513;-0.28043586;-
check that theil sen falls back to least squares if fit intercept false;3.4788501;4.259216;-3.9467647;-0.24183017;-4.8581057;0.8654289;CODE
check fit intercept true case this will not be equal to the least;3.452123;6.260019;-2.3777115;-1.0027604;-1.342249;-0.36155242;CODE
squares solution since the intercept is calculated differently;-1.2387568;2.2605698;0.62761134;-1.3015213;-5.285288;0.9584745;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
double centering;-0.24287903;0.54853576;6.182681;-2.622473;-1.3800297;1.6370813;CODE
eigendecomposition;1.5051501;-0.92628163;0.13026711;-2.4270687;1.170992;3.322671;CODE
reversing the order of the eigenvalues eigenvectors to put;-0.2729677;-0.58975035;-0.4327555;-2.471543;-0.16087648;4.6719403;IRRE
the eigenvalues in decreasing order;-0.47214854;1.6015301;0.76318634;-1.5406673;-1.8132439;2.2344491;IRRE
set the signs of eigenvectors to enforce deterministic output;2.3063745;0.4927787;-3.8705614;0.89793915;-0.21318077;4.531873;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
randomly choose initial configuration;0.08781153;1.7609239;1.4957641;3.1232276;2.7632966;2.6587508;IRRE
overrides the parameter p;-4.298724;4.466628;-0.8530764;1.6651617;0.41506648;2.5424902;IRRE
out of bounds condition cannot happen because we are transforming;-0.78477097;5.0674176;0.15773785;-1.3386191;-2.5043676;2.6510448;CODE
the training set here but does sometimes get triggered in;-0.67428535;-3.1562846;-0.64713854;4.7887683;-0.018377196;0.5016347;IRRE
practice due to machine precision issues hence clip;1.5006926;-0.5452724;0.8599399;-0.36048844;-1.6450448;-1.4692465;CODE
compute distance and monotonic regression;4.414109;1.0350528;1.6969202;-1.2313186;-2.0595336;0.8263052;-
dissimilarities with 0 are considered as missing values;2.2957313;5.9066734;-4.440123;-4.1406446;-1.5190463;-1.2624336;IRRE
compute the disparities using isotonic regression;3.9053023;0.66905236;1.3650419;-3.1581392;-1.240568;0.07100528;-
for the first smacof iteration use scaled original dissimilarities;4.9098406;-0.5644981;-3.102358;-1.2412972;-2.9713852;3.9272003;CODE
this choice follows the r implementation described in this paper;3.0370133;-1.4581597;-1.4375819;-2.6532874;2.4461784;3.2132523;CODE
https www jstatsoft org article view v102i10;-4.0975056;-2.4626906;1.3572793;0.90034586;0.17921633;0.30250412;CODE
update x using the guttman transform;-0.57664764;0.06004436;-0.48988992;-2.7146502;0.5588193;2.5454683;CODE
compute stress;2.444724;0.41959545;1.6427233;-2.191501;-1.9695385;-1.896912;IRRE
if verbose 2 pragma no cover;-3.1949923;4.2171283;2.4021022;1.7088149;1.8626688;-2.4875178;IRRE
if verbose pragma no cover;-2.8491418;3.647935;2.0468888;3.1629767;1.6601048;-1.0123562;IRRE
todo 1 9 change default n init to 1 see pr 31117;-6.079142;1.5289922;-0.41576657;-0.80639;0.3735506;-1.1812323;CODE
todo 1 9 change default n init to 1 see pr 31117;-6.079142;1.5289922;-0.41576657;-0.80639;0.3735506;-1.1812323;CODE
todo 1 10 change default init to classical mds see pr 32229;-5.2348447;0.74664205;-2.7025168;0.10530901;0.06640292;3.465444;CODE
todo 1 10 drop support for boolean metric see pr 32229;0.8597468;0.76308244;-2.7710774;1.0334704;1.3614746;0.14591418;CODE
todo 1 10 drop support for dissimilarity see pr 32229;-0.50265145;-0.05157905;-1.2164873;1.5643262;1.9424899;2.9041407;CODE
make the matrix symmetric;0.60130835;0.3896569;1.5742689;-5.586818;-1.7835565;0.15352969;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this is the exact and barnes hut t sne implementation there are other;-0.74975294;-3.861933;1.8418199;-0.2372356;1.5328857;1.413455;TASK
modifications of the algorithm;5.030609;-0.61395043;1.0040851;-0.8105256;1.7519245;-0.3592134;-
fast optimization for t sne;4.15596;-2.0706692;-0.24574518;-1.1869419;0.086522676;3.289312;CODE
https cseweb ucsd edu lvdmaaten workshops nips2010 papers vandermaaten pdf;-3.7503533;-5.9000964;-1.483971;-1.6341873;1.5817337;0.70159405;CODE
mypy error module sklearn manifold has no attribute utils;-1.4082732;-2.9106832;-7.2053995;-2.3574429;-4.76859;-0.35677728;META
mypy error module sklearn manifold has no attribute barnes hut tsne;-1.7777092;-2.7227404;-7.37947;-2.5067239;-4.3254805;-0.17730384;IRRE
from sklearn manifold import barnes hut tsne utils type ignore attr defined;-0.57728505;0.012821789;-6.8255897;-2.2644248;-2.058373;1.5662104;CODE
compute conditional probabilities such that they approximately match;3.6003766;2.7720664;1.7453946;0.4017272;1.9355578;-0.57657075;-
the desired perplexity;-0.8441801;-0.4646686;4.2347527;0.5290372;1.873897;-0.9109051;-
compute conditional probabilities such that they approximately match;3.6003766;2.7720664;1.7453946;0.4017272;1.9355578;-0.57657075;-
the desired perplexity;-0.84418106;-0.46466836;4.234753;0.52903825;1.8738973;-0.9109058;-
symmetrize the joint probability distribution using sparse operations;3.8916752;-1.9470179;-0.86010176;-2.046876;3.283722;3.4952295;IRRE
normalize the joint probability distribution;0.22117448;0.0906562;2.2886438;-2.0957296;0.58675444;2.6637635;META
q is a heavy tailed distribution student s t distribution;0.25105235;-0.88441294;1.4958774;0.9345948;-0.5002343;-1.8253404;META
optimization trick below np dot x y is faster than;3.2398622;-0.14701934;-2.0025694;-3.3791995;-3.3125541;1.7675605;CODE
np sum x y because it calls blas;-0.63096815;0.5169064;-1.516893;-5.3897753;-0.39891323;-2.454126;IRRE
objective c kullback leibler divergence of p and q;0.85021776;-0.38564256;-2.2355661;-0.078364834;0.8012587;1.056141;IRRE
gradient dc dy;0.42606226;-2.0580533;0.90621024;-2.998115;-1.5480607;2.203887;-
pdist always returns double precision distances thus we need to take;3.6516798;0.26466003;-4.3780727;-0.07362333;-3.2971408;1.3929988;CODE
only compute the error when needed;1.5808877;5.7566953;-1.7313759;1.0504228;-1.5541291;-4.445336;-
we set the diagonal to np inf to exclude the points themselves from;3.7775185;1.4963003;-1.3135203;-4.1830583;-1.9068415;3.013154;CODE
their own neighborhood;-0.9191476;-1.7900434;3.1504881;-0.2161302;-0.8355006;0.35891634;-
ind x i is the index of sorted distances between i and other samples;5.1484118;1.2639478;1.5315307;-6.1691546;1.1026677;-1.3402714;CODE
we build an inverted index of neighbors in the input space for sample i;7.3799973;-0.40426704;0.626496;-3.9661455;2.3877158;1.8861562;CODE
we define inverted index i as the inverted index of sorted distances;1.3174185;0.9394551;0.79134715;-3.9396675;2.2448852;2.4195101;CODE
inverted index i ind x i np arange 1 n sample 1;3.1369092;3.2521226;-2.3673756;-6.5656304;0.17307174;-0.8688804;-
control the number of exploration iterations with early exaggeration on;3.3000667;-0.8738;2.664284;5.2685013;-1.0650992;1.4428782;-
control the number of iterations between progress checks;1.9938002;2.606332;2.9779549;4.6310983;0.4486257;-0.8926062;-
t sne minimizes the kullback leiber divergence of the gaussians p;1.9106205;-2.6349514;-2.3090847;-0.29343873;-1.4942095;4.571964;-
and the student s t distributions q the optimization algorithm that;5.2547436;-5.171125;0.96388173;1.4737877;1.6896551;0.65010285;META
we use is batch gradient descent with two stages;3.7136214;-2.7814393;0.8685339;3.5321467;2.601784;3.708137;-
initial optimization with early exaggeration and momentum at 0 5;1.8617377;0.87492263;-0.6515942;1.0884866;-2.7675033;2.405662;IRRE
final optimization with momentum at 0 8;0.5193721;1.266644;0.024046117;-0.8820892;-1.3439205;2.0710833;CODE
repeat verbose argument for kl divergence bh;-0.62052995;1.577771;-2.9709601;-0.8777103;0.015353476;2.025978;IRRE
get the number of threads for gradient computation here to;2.3847907;-1.521252;-0.27400655;-1.2232221;-1.0866133;1.3087603;CODE
avoid recomputing it at each iteration;2.2900026;2.512684;-0.45502418;3.829464;-0.287352;0.64726007;CODE
learning schedule part 1 do 250 iteration with lower momentum but;2.6830735;-1.4778273;1.7842623;1.8868066;-0.4540957;-1.1589912;META
higher learning rate controlled via the early exaggeration parameter;4.896372;-3.6014445;-0.7270897;4.175677;-0.90476084;3.1803246;IRRE
learning schedule part 2 disable early exaggeration and finish;1.6622444;-0.8320971;1.8305906;5.819836;-1.2187116;0.21888973;TASK
optimization with a higher momentum at 0 8;1.2836479;0.7704416;0.5042912;-1.3641516;-0.7426351;2.2449744;-
save the final number of iterations;1.9910911;2.4675295;4.3709035;1.4019138;-0.365892;-2.1031666;CODE
tsne metric is not validated yet;-0.22277153;1.4479942;-5.266404;0.7507287;-2.1664584;0.9361388;TASK
tsne metric is not validated yet;-0.22277153;1.4479942;-5.266404;0.7507287;-2.1664584;0.9361388;TASK
swap the signs if necessary;-2.998296;2.4779983;3.110273;-2.5881996;1.777586;-1.2461461;-
non symmetric input;0.6109681;2.6075099;1.0324287;-4.664786;1.2999315;-3.531426;CODE
non square input;1.1987169;2.5680392;2.6686032;-5.546679;-1.8496674;-2.5829892;CODE
grid of equidistant points in 2d n components n dim;2.7034156;0.5846661;0.7843645;-7.8005624;-1.161736;2.678669;CODE
add noise in a third dimension;3.5369756;-0.9368018;0.48569375;-3.5596297;0.46394423;3.9265785;TASK
isomap should preserve distances when all neighbors are used;3.6377432;0.24916862;0.47388387;-2.2322285;-0.70379233;6.036834;-
distances from each point to all others;3.9506538;0.5904313;5.5697165;-4.623614;-0.7031909;-0.21420775;CODE
same setup as in test isomap simple grid with an added dimension;3.0568135;1.5847633;-0.58683676;-3.4445996;-0.7663389;3.573762;IRRE
compute input kernel;2.5615957;-1.8671614;-0.14143692;-3.8047333;-0.26105013;-0.8394561;CODE
compute output kernel;2.5476196;-1.733668;-0.47545996;-3.154841;-0.5099529;-0.4262708;IRRE
make sure error agrees;-4.165554;2.8422678;-1.3610688;2.6356049;-1.801084;-4.2861543;-
create s curve dataset;3.9821312;-4.2746406;1.3663281;-3.77034;-0.90035945;-0.28088522;IRRE
compute isomap embedding;2.5572746;-1.7988853;0.2554568;-4.9823003;0.84584916;3.3267558;-
re embed a noisy version of the points;5.675617;-0.047564555;2.1023114;-2.3082232;-1.1606716;4.6751256;META
make sure the rms error on re embedding is comparable to noise scale;2.148166;0.28889933;-4.4000998;-0.8142337;-3.6602342;5.668533;CODE
check that isomap works fine as a transformer in a pipeline;-0.11494835;1.9238403;-3.8478835;-0.16969757;-2.8204033;3.1667635;CODE
only checks that no error is raised;-1.6604867;6.544864;-2.138551;6.8003974;-0.47681534;-3.6665206;CODE
todo check that it actually does something useful;-4.298829;-1.3004408;2.1685581;5.652349;-0.6672285;-1.1697541;CODE
test chaining nearestneighborstransformer and isomap with;3.7277334;2.374098;-2.5293126;-0.995989;0.2229828;1.1241235;IRRE
neighbors algorithm precomputed;4.146752;-0.5808849;0.024512345;-3.319306;0.7681873;0.4478813;-
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
isomap must work on various metric parameters work correctly;2.1539533;0.33307013;-3.1637585;-2.6565108;-2.2820616;4.0300846;IRRE
and must default to euclidean;0.56923676;0.71666986;-0.114416994;-4.0700293;-1.6381315;0.38696703;CODE
regression test for bug reported in 6062;-1.2224091;2.5093124;-6.0589647;4.6771064;-4.388563;-4.1596036;IRRE
todo compare results on dense and sparse data as proposed in;7.3099213;-0.7692195;-1.5265115;-0.24283126;0.60952896;0.86733806;IRRE
https github com scikit learn scikit learn pull 23585 discussion r968388186;-2.609029;-10.687988;-5.6083736;-1.002882;-4.7453384;-3.762259;CODE
isomap fit transform must yield similar result when using;4.445046;1.8102139;-2.7096996;-3.5893846;-3.572764;4.9809175;IRRE
a precomputed distance matrix;4.585357;-1.0078003;1.4147123;-4.4556184;-0.7307182;3.1096077;-
test utility routines;2.034332;0.6208947;-0.7119215;6.1766567;1.2926557;-5.5583;IRRE
check that columns sum to one;3.6730118;4.2750106;1.2503268;-3.2026474;0.33430853;-5.556769;-
test lle by computing the reconstruction error on some manifolds;3.6289546;1.5965872;-3.1641505;0.44995776;-1.4890875;1.1538366;CODE
note arpack is numerically unstable so this test will fail for;0.29143974;3.946038;-6.192788;2.2499924;-4.5743856;-4.1103196;IRRE
some random seeds we choose 42 because the tests pass;1.189363;1.0392902;1.3290403;3.4855363;1.7410674;-5.1375914;IRRE
for arm64 platforms 2 makes the test fail;-3.7762616;1.6119108;-4.905384;2.4926338;-4.427856;-3.2559664;CODE
todo rewrite this test to make less sensitive to the random seed;1.8597869;4.8997073;-1.8160282;5.663157;0.44243202;-3.7788494;CODE
irrespective of the platform;-3.6567945;-5.1744685;3.2967641;2.3030705;0.13469276;0.9449428;CODE
grid of equidistant points in 2d n components n dim;2.7034156;0.5846661;0.7843645;-7.8005624;-1.161736;2.678669;CODE
re embed a noisy version of x using the transform method;3.6174827;0.8447788;-0.63233745;-2.1811876;-1.5911877;4.7729487;META
similar test on a slightly more complex manifold;1.8061061;3.6711547;-0.11814446;2.9523387;0.010167335;1.1872439;IRRE
check that locallylinearembedding works fine as a pipeline;-2.654961;0.62497467;-3.1188486;1.9852253;-2.9160454;4.308762;CODE
only checks that no error is raised;-1.6604877;6.544864;-2.1385508;6.8003983;-0.47681504;-3.666521;CODE
todo check that it actually does something useful;-4.2988305;-1.300441;2.1685584;5.652347;-0.66722876;-1.1697538;CODE
test the error raised when the weight matrix is singular;4.5323467;4.318809;-5.724556;0.049073104;-3.7377627;1.580282;IRRE
regression test for 6033;0.62891346;2.869345;-0.21242863;2.32124;-2.3567674;-5.621691;IRRE
clf fit x this previously raised a typeerror;0.6923638;2.1116283;-5.0336494;-1.9884137;-3.0766995;-0.103622615;CODE
test metric smacof using the data of modern multidimensional scaling;5.8088903;-1.9016495;-2.6933768;0.46575075;-2.4047828;1.0379901;IRRE
borg groenen p 154;-2.8517377;-0.37212846;0.59901667;-1.4763473;-0.10479862;-1.9181733;-
testing that nonmetric mds results in lower normalized stress compared;2.3758547;2.0430696;-2.9328997;2.3909438;-1.2936106;1.3502922;IRRE
compared to metric mds non regression test for issue 27028;2.0589166;0.65333563;-5.1296554;3.1656504;-2.492573;-2.6224072;IRRE
a metric mds solution local minimum of the raw stress can be rescaled to;2.9498966;-0.3701464;-2.0799053;-1.1697693;-1.8330817;5.337655;-
decrease the stress 1 which is returned with normalized stress true;2.2268922;3.7891767;-1.1065809;0.39746147;-1.5446568;1.952526;IRRE
the optimal rescaling can be computed analytically see borg groenen;4.845991;-1.5989273;0.6522862;-1.3333675;-1.2621853;6.042887;IRRE
modern multidimensional scaling chapter 11 1 after rescaling stress 1;3.829077;-1.476099;0.1693216;-2.7684703;-3.0085883;6.639708;-
becomes sqrt s 2 1 s 2 where s is the value of stress 1 before;-0.96271765;1.8861538;1.1148505;-2.0193338;-2.180847;-1.6134782;IRRE
rescaling;2.2124317;0.023155073;6.491121;-3.2258081;-2.291242;1.8253025;-
test that stress is decreasing during nonmetric mds optimization;3.47874;2.0090907;-2.8683708;3.7241702;-1.4472425;1.2777034;IRRE
non regression test for issue 27028;-0.26459128;3.7997222;-5.120966;3.0050483;-3.4333217;-5.672503;IRRE
not symmetric similarity matrix;3.6399891;0.10489864;-0.1621525;-5.198053;-0.10902759;0.8581629;-
not squared similarity matrix;4.395003;-0.14822944;-0.046144046;-5.157499;-2.144394;1.7628659;-
init not none and not correct format;-6.630164;3.3204906;-3.0405865;-2.189249;-1.2668958;-2.1155393;IRRE
todo remove mark once loky bug is fixed;-5.863762;1.7962039;-1.221311;2.4669986;-1.3744892;2.2256227;TASK
https github com joblib loky issues 458;-5.9445925;-3.3966901;-3.4007475;-0.13234863;-4.2971582;-1.9892539;CODE
todo 1 10 remove warning filter;-3.3696961;3.5489328;-1.3291543;2.88569;-1.4556284;0.98706913;TASK
from pyamg import smoothed aggregation solver noqa f401;1.7086288;-0.9164797;-3.6641834;-3.150302;-1.9238365;2.2963805;CODE
non centered sparse centers to check the;5.4355817;1.0648745;0.4538785;-2.7163634;-2.9738295;2.2663274;IRRE
connect all elements within the group at least once via an;1.0556332;2.6107714;4.5678787;-1.8751963;3.830723;-0.32336748;CODE
arbitrary path that spans the group;-2.1859808;-0.39402482;3.931693;-0.9258894;1.3104964;2.4780555;-
add some more random connections within the group;0.37025207;0.35464343;3.7986963;0.3522371;3.0869777;1.2857647;CODE
build a symmetric affinity matrix;4.1683006;-2.0317142;-1.7106558;-5.322076;0.28030965;3.9570007;IRRE
we should retrieve the same component mask by starting by both ends;-2.218939;2.8660307;1.5612966;-2.1301455;0.61179304;6.04053;CODE
of the group;-0.930272;-1.1991524;6.561298;-0.051445156;1.6437633;-3.0899827;-
todo investigate why this test is seed sensitive on 32 bit python;-0.74711084;1.0208673;-6.871292;0.13059741;-4.0693474;-5.434051;CODE
runtimes is this revealing a numerical stability problem or is it;1.6448462;0.51965123;-2.1319592;0.9812978;-1.7227387;0.70656246;CODE
expected from the test numerical design in the latter case the test;2.551828;5.374293;-2.760646;2.1391652;-1.3415443;-3.3003588;IRRE
should be made less seed sensitive instead;-1.3473667;0.15224348;-1.1360556;2.3494215;-0.9709187;1.975988;-
test spectral embedding with two components;3.2909029;1.0487858;-3.3983424;0.16280746;1.623276;3.1402404;IRRE
first component;-3.5163953;-0.2723066;5.1581926;-2.1617785;3.00034;0.41095638;-
second component;-2.9235184;-0.8755963;5.620612;-1.8016368;3.8780534;1.6602924;-
test of internal graph connected component before connection;-0.16533883;3.1112902;0.9632943;2.6800797;-1.0974641;0.16159351;CODE
connection;-3.1349523;-2.938472;6.484959;-0.986669;0.3640594;-2.288878;CODE
thresholding on the first components using 0;2.9100397;3.3792508;-0.57630527;-3.4903016;0.26903024;1.7613986;-
test spectral embedding with precomputed kernel;2.563186;-0.63124585;-3.9626706;1.0937604;-0.5129859;2.9686208;IRRE
test precomputed graph filtering when containing too many neighbors;4.407429;3.7151287;-0.7922878;0.5674351;-0.30734453;-0.8178661;IRRE
test spectral embedding with callable affinity;2.366124;-0.20940875;-3.527964;1.6318475;0.5494613;3.4573207;IRRE
same with special case in which amg is not actually used;-4.8280125;0.5277648;-0.4690928;1.1066674;2.3974576;2.7950175;META
regression test for 10715;0.88147056;3.1424809;-1.6052392;3.1044695;-3.6271436;-5.4021583;IRRE
affinity between nodes;3.936919;-0.9179485;1.1404319;-2.3035607;2.1436088;3.677675;IRRE
check that passing a sparse matrix with np int64 indices dtype raises an error;2.3686216;1.1612985;-9.255492;-4.502765;-3.818795;0.106601015;CODE
or is successful based on the version of scipy which is installed;-0.5833533;-5.056394;-5.0731897;1.1841782;-4.6385565;-3.5240853;META
use a csr matrix to avoid any conversion during the validation;3.551389;4.3338637;-3.5319865;-0.38273922;0.21725756;0.12838967;META
pr https github com scipy scipy pull 18913;-2.9733577;-5.243074;-3.483448;-2.8923519;-4.3504505;-4.310889;CODE
first integration in 1 11 3 https github com scipy scipy pull 19279;-2.440125;-3.9447534;-5.601685;-3.3128705;-5.636152;-1.6713947;CODE
non regression test for amg solver failure issue 13393 on github;-1.488771;1.8893924;-6.684597;3.0446005;-5.529539;-1.9700614;IRRE
check that the learned embedding is stable w r t random solver init;1.5133307;-1.330348;-5.246692;2.1374621;-1.6324077;2.4041162;IRRE
test using pipeline to do spectral clustering;4.7373705;0.5356214;-2.7053185;2.1702745;0.21089795;-0.124839425;CODE
test that graph connectivity test works as expected;1.0535011;4.2948046;-0.8366807;3.0445056;-3.6446128;-3.0130215;IRRE
test that spectral embedding is deterministic;1.9552343;0.9864818;-3.7531843;2.6624064;0.7492079;3.0270634;IRRE
test that spectral embedding is also processing unnormalized laplacian;3.5034587;-0.7321564;-2.4706602;0.652823;-0.1756011;4.6755323;IRRE
correctly;-2.1148818;-0.60388666;5.2938895;-0.05464032;0.68399626;-2.1474285;-
verify using manual computation with dense eigh;3.2866514;3.02096;-2.8064802;-1.0717813;-0.6115533;-3.2846532;-
test that the first eigenvector of spectral embedding;0.76148176;0.7044634;-3.070801;0.041516542;-0.4588567;3.456449;IRRE
is constant and that the second is not for a connected graph;-1.1550035;2.1267383;3.2752259;-2.6185746;-1.512413;0.7096363;CODE
mypy error module sklearn manifold has no attribute barnes hut tsne;-1.7777092;-2.7227404;-7.37947;-2.5067239;-4.3254805;-0.17730384;IRRE
from sklearn manifold import type ignore attr defined;-0.7916428;-1.5123405;-7.4173536;-1.3485183;-2.7290843;2.591757;CODE
test stopping conditions of gradient descent;2.5462074;2.412667;-1.2089534;6.2682557;-2.1086857;0.13308538;IRRE
gradient norm;1.9747543;-1.8887532;1.3892348;-2.2284412;-1.532672;3.5004327;-
maximum number of iterations without improvement;3.3176682;0.47902405;2.7118676;1.3391751;0.4294591;-0.61179584;TASK
maximum number of iterations;2.2015543;0.7159932;3.2313077;0.46261773;0.73114437;-1.8414809;-
test if the binary search finds gaussians with desired perplexity;3.132674;3.5377514;-3.5300136;-0.8842182;0.5763417;-2.035959;IRRE
test if the binary search finds gaussians with desired perplexity;3.132674;3.5377514;-3.5300136;-0.8842182;0.5763417;-2.035959;IRRE
a more challenging case than the one above producing numeric;3.123834;1.2774403;0.641274;-3.1394434;1.9402277;-4.7938504;CODE
underflow in float precision see issue 19471 and pr 19472;1.2386006;2.0818572;-3.454776;-2.6045477;-2.5821292;-0.3663687;CODE
binary perplexity search approximation;4.0319395;0.5660993;-1.4725354;-2.3689253;2.3012116;-0.99438596;-
should be approximately equal to the slow method when we use;3.5219362;1.2060267;-0.24599212;2.996385;-2.5817342;0.95384914;-
all points as neighbors;1.941178;-0.8731289;3.8587654;-1.2449702;0.020819101;0.687255;CODE
test that when we use all the neighbors the results are identical;4.3822703;3.684529;1.005542;2.002906;0.82277614;-5.1355996;IRRE
test that the highest p ij are the same when fewer neighbors are used;4.8169994;3.0523937;0.40543973;1.3223011;1.0590707;-2.617175;IRRE
topn k 10 check the top 10 k entries out of k k entries;3.1555862;-0.27089167;2.595279;-2.5503561;1.5766288;-3.119268;-
binary perplexity search should be stable;0.45046163;0.2712303;-2.5629818;-0.4192586;2.0008266;-1.273881;-
the binary search perplexity had a bug wherein the p array;-1.090825;1.3471296;-4.315102;-1.4699951;-0.20464796;-2.6491137;CODE
was uninitialized leading to sporadically failing tests;-0.5496702;3.503055;-4.667822;5.028411;-3.024511;-3.293048;IRRE
convert the sparse matrix to a dense one for testing;6.760173;1.41049;-3.5151184;-1.6376067;-1.688391;1.4674969;IRRE
test gradient of kullback leibler divergence;1.7586353;-0.9724469;-3.41059;1.3523492;-1.0009581;0.49361748;IRRE
test trustworthiness score;1.53665;3.0626798;-2.7534053;4.1744347;-0.26626855;-5.3589315;IRRE
affine transformation;-0.042688344;-1.0176438;2.1353862;-4.663692;-3.44225;3.1633162;CODE
randomly shuffled;1.8399272;0.4872409;4.513809;-1.3792924;1.0523245;-3.5195763;IRRE
completely different;-1.4683797;-0.7602264;4.0332546;-0.044199612;0.5410227;-0.029708907;CODE
nearest neighbors should be preserved approximately;6.1891966;0.3339416;0.8931774;-1.7530408;-0.53676564;4.291591;-
computed distance matrices must be positive;3.7507641;1.7753936;-2.427465;-2.6677966;-2.610483;2.4034455;TASK
negative computed distances should be caught even if result is squared;3.5094914;3.626323;-1.4118463;-0.3389579;-3.951348;1.6773148;IRRE
initialize tsne with ndarray and test fit;2.3832076;2.6590858;-4.5848703;-1.5431335;-2.5872371;0.9302698;IRRE
initialize tsne with ndarray and metric precomputed;1.98628;0.95948535;-3.8506415;-3.4874096;-2.2859268;2.7737215;IRRE
make sure no futurewarning is thrown from fit;-0.46453673;0.84928733;-1.2221754;6.2523313;-1.6333421;1.464755;CODE
precomputed distance matrices cannot use pca initialization;2.6228907;0.9666986;-4.3935547;-4.0921187;-2.293633;4.931415;IRRE
barnes hut method should only be used with n components 3;-1.7449453;-0.75756615;-2.1819386;-0.8433878;1.6954615;2.3834977;IRRE
check that the early exaggeration parameter has an effect;2.591531;5.205702;-1.9550847;5.2897964;-3.2455473;1.4115831;IRRE
check that the max iter parameter has an effect;0.027488647;5.941261;-1.8340479;1.8377537;-1.6840285;-0.036601707;IRRE
test the tree with only a single set of children;1.1317326;3.6170557;1.1755341;3.5467257;3.766927;-4.875407;IRRE
these tests answers have been checked against the reference;-1.4604523;1.4055957;-2.7714536;5.6042857;-0.13222024;-4.805842;IRRE
implementation by lvdm;1.6206146;-1.1216654;-0.29253113;-2.355624;1.8251683;4.101363;TASK
four points tests the tree with multiple levels of children;1.3801732;1.2131059;2.9151938;1.5406388;3.343712;-4.1083436;IRRE
these tests answers have been checked against the reference;-1.4604523;1.4055957;-2.7714536;5.6042857;-0.13222024;-4.805842;IRRE
implementation by lvdm;1.6206146;-1.1216654;-0.29253113;-2.355624;1.8251683;4.101363;TASK
test the kwargs option skip num points;2.713465;4.2653203;-1.8166109;0.31834713;-1.6784898;-1.2603642;IRRE
skip num points should make it such that the barnes hut gradient;2.955489;-0.05640902;1.0267134;-1.7248025;-1.2927605;2.4954038;IRRE
is not calculated for indices below skip num point;2.8069587;5.2009177;-2.5031993;-5.906304;-3.3748615;-1.4524169;CODE
aside from skip num points 2 and the first two gradient rows;5.8829784;-1.289861;1.8482932;-4.1614175;1.0473533;3.091875;CODE
being set to zero these data points are the same as in;5.606525;3.2611358;-0.38296485;-4.7159085;-1.1158137;0.8149085;IRRE
test answer gradient four points;3.2612355;3.5102804;1.6466621;-1.8624883;-0.94601685;-2.5922985;IRRE
pytest mark thread unsafe manually captured stdout;-3.4542491;1.6311595;-2.386387;2.2372425;-4.13873;0.8035803;CODE
verbose options write to stdout;-4.30011;1.7627038;0.7293026;1.9876319;-0.7872433;-0.883865;CODE
t sne should allow metrics that cannot be squared issue 3526;1.6070683;-0.46204078;-3.0167758;-1.1195103;-0.8086799;0.02735886;-
t sne should allow reduction to one component issue 4154;-2.1155612;2.381385;-2.9625826;1.7545587;2.4469066;3.2455592;-
ensure 64bit arrays are handled correctly;-0.70704126;4.6705976;-3.099932;-2.089305;-0.44878754;-1.1323321;-
tsne cython code is only single precision so the output will;-0.15347454;3.230988;-4.2232766;-3.4103513;-3.2104533;-2.3913214;IRRE
always be single precision irrespectively of the input dtype;2.9585001;0.6433056;-5.2523384;-1.0175344;-1.881873;-0.25016618;CODE
ensure kl divergence is computed at last iteration;2.810027;2.5138457;-2.6727536;1.1970441;-0.7324758;3.3356407;-
even though max iter n iter check 0 i e 1003 50 0;-0.47461966;4.397631;-1.5782484;-2.7118747;-1.5979456;-4.1109557;-
when barnes hut s angle 0 this corresponds to the exact method;-0.34339684;-0.59624654;2.191853;-1.8170694;-1.739898;-0.122528955;CODE
use a dummy negative n iter without progress and check output on stdout;-0.9099423;4.9672813;0.0059868707;2.0337296;-1.6007811;-2.2906833;CODE
the output needs to contain the value of n iter without progress;0.33368444;3.8985665;0.31019098;-1.4881183;-1.7355604;-3.435339;IRRE
make sure that the parameter min grad norm is used correctly;2.056115;1.0353038;-5.3001986;-0.77284986;-3.2798562;3.2073379;IRRE
extract the gradient norm from the verbose output;3.4462535;-0.08536786;-0.93992394;-2.1910834;-1.4357892;3.3650334;IRRE
when the computation is finished just an old gradient norm value;2.1748738;-0.3215395;-2.210302;-0.64423;-3.6157248;3.9074712;TASK
is repeated that we do not need to store;-1.5704634;1.7211432;3.7161725;3.1765552;2.4664972;1.8177519;TASK
compute how often the gradient norm is smaller than min grad norm;4.9249105;-0.9801174;-1.1892734;-1.2075721;-1.1356721;3.5964746;-
the gradient norm can be smaller than min grad norm at most once;2.6446786;-0.7825134;-2.8803594;-0.42541713;-1.6687617;5.5379148;-
because in the moment it becomes smaller the optimization stops;2.2372653;0.7376511;0.64433795;1.4486227;-2.8281486;4.8001885;CODE
ensures that the accessible kl divergence matches the computed value;1.5158021;1.1288657;-3.7683325;0.6919861;0.69508034;4.0167136;IRRE
the output needs to contain the accessible kl divergence as the error at;1.0321231;1.9336003;-5.745801;-2.7304707;-3.1827676;0.61374336;TASK
the last iteration;-0.3906098;0.6711391;6.157298;2.0493207;-0.13246891;-4.0874724;-
if the test fails a first time re run with init y to see if;-2.0583394;5.811643;-1.7453983;5.924709;-2.5185907;-4.051838;IRRE
this was caused by a bad initialization note that this will;-6.7859116;2.3902786;-3.2534785;2.4233909;-3.5578249;1.4825758;CODE
also run an early exaggeration step;0.3273931;0.7506103;1.4633666;4.6796765;-1.3966722;0.8774475;CODE
ensure that the resulting embedding leads to approximately;3.4935844;2.2779014;-0.89099544;-0.48350525;-0.6878158;5.5911865;IRRE
uniformly spaced points the distance to the closest neighbors;3.7178037;0.28919888;2.9393795;-3.810563;-1.8969965;1.7650142;CODE
should be non zero and approximately constant;0.30077016;4.6480417;-0.6086902;-3.5672195;-4.5361595;-0.43913364;CODE
check that the barnes hut method match the exact one when;-0.019573243;0.3623782;0.53906876;1.9895508;-0.78567;-1.272886;IRRE
angle 0 and perplexity n samples 3;0.66089314;1.9472182;-1.1632268;-5.422727;-0.46542975;-1.788877;-
kill the early exaggeration;0.70297486;1.6271544;2.2549412;4.2384715;-2.7501993;0.838962;-
check that the bh gradient with different num threads gives the same;1.8992088;1.5239905;-3.6340363;-1.1812166;-2.1297846;3.022777;CODE
results;-0.124750376;-1.7336558;6.189961;3.2482023;0.4808949;-6.011475;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
swap average weight score weight;2.4199455;2.6037114;-0.0063213767;-0.51821744;-1.1469406;1.2631038;-
average the results;4.29996;1.1738774;5.1180334;1.6373558;-2.393286;-3.7948751;IRRE
scores with 0 weights are forced to be 0 preventing the average;2.7375352;4.0700097;-2.4988117;0.39980373;-3.325134;0.31432378;CODE
score from being affected by 0 weighted nan elements;5.2229824;4.0568347;-2.0898092;-2.348209;-1.7171862;-1.8559121;CODE
compute scores treating a as positive class and b as negative class;3.1553583;1.5400523;-1.1399156;-1.9136764;3.6633193;-3.472288;IRRE
then b as positive class and a as negative class;-0.5615647;1.1981355;-0.04263518;-0.3598339;4.9480095;-1.2008067;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
else np isnan zero division;-0.88780874;1.9886562;-2.4306762;-3.9873657;-0.7441554;-3.3391147;-
we can t have more than one value on y type the set is no more needed;0.73061615;3.0975642;-0.09050042;-3.7574024;3.644639;-1.599162;IRRE
no metrics support multiclass multioutput format;3.1458693;-3.669079;-3.9606507;-0.87202835;1.9832873;1.2244132;IRRE
we expect y true and y pred to be of the same data type;2.0500884;2.2778938;-2.5113523;0.8747973;1.1075253;-0.85853845;-
if y true was provided to the classifier as strings;2.0013413;0.7948494;-2.3222418;1.324627;2.292518;-4.268327;CODE
y pred given by the classifier will also be encoded with;0.61372036;-1.3847647;-2.5225375;-0.99321467;3.2794507;-0.70058316;IRRE
strings so we raise a meaningful error;-1.3722811;3.4010608;-0.4677262;1.1438329;0.026295573;-6.1290803;CODE
xxx do we really want to sparse encode multilabel indicators when;4.06206;-2.1259816;-0.833956;-1.9472767;4.4802046;3.1401722;IRRE
they are passed as a dense arrays this is not possible for array;0.9460524;4.2398114;-1.344923;-2.7292097;-1.4362361;-1.0934471;CODE
api inputs in general hence we only do it for numpy inputs but even;2.5125659;-2.0640686;-2.113704;-3.214333;-3.9147255;-0.0036864132;CODE
for numpy the usefulness is questionable;3.9722183;-4.380078;-1.3827584;-4.3366237;-6.0522375;-1.4518459;CODE
for classification metrics both array api compatible and non array api;4.4966908;-2.863485;-2.9437966;0.9886214;2.9377878;0.5267724;CODE
compatible inputs are allowed for y true this is because arrays that;-0.61614674;2.8055592;-2.2528327;-3.4489946;-1.4983494;-2.5607498;CODE
store class labels as strings cannot be represented in namespaces other;-2.858937;-0.6517524;-3.2394543;-0.62580794;2.8732054;2.2987564;CODE
than numpy thus to avoid unnecessary complexity we always convert;4.752515;-0.7775096;-2.0733368;-5.0323577;-5.283292;-0.07194368;IRRE
y true to a numpy array so that it can be processed appropriately by;4.3825493;2.2953641;-1.1895062;-3.9120593;-5.159668;-1.4297706;-
labelbinarizer and then transfer the integer encoded output back to the;-0.14142764;0.80891305;-1.8652529;-3.5610497;2.8917296;-0.66673994;IRRE
target namespace and device;-4.7146773;-3.3007119;-0.20443928;1.0246439;2.0161526;4.130861;-
labelbinarizer does not respect the order implied by labels which;-1.7864656;1.4188664;-3.50012;-1.4856137;3.0460722;1.4757518;CODE
can be misleading;-1.5642657;-0.45862472;1.8601087;1.9042472;-0.19480911;-1.1660432;META
if y prob is of single dimension assume y true to be binary;2.4425707;2.420416;-2.6284277;-4.9233985;1.5237374;-0.8342972;-
and then check;-2.5100977;1.7135761;1.5594841;4.744031;0.16744336;-4.7865443;-
make sure y prob is normalized;-0.98388964;1.8558391;-2.237839;-1.1081815;-2.5158372;-0.05357866;-
check if dimensions are consistent;3.6326826;5.0047565;-0.22217198;-2.1037147;-1.1060759;-0.9503229;IRRE
compute accuracy for each possible representation;6.4554577;-1.6423956;-0.7208579;-2.4847202;2.1100376;-1.6012406;CODE
convert the input arrays to numpy on cpu irrespective of the original;4.6213655;-0.49974582;-1.9292907;-5.278092;-6.543027;0.82659113;CODE
namespace and device so as to be able to leverage the the efficient;-1.877211;-5.5610194;2.4190078;0.93213046;4.5256863;3.8948722;CODE
counting operations implemented by scipy in the coo matrix constructor;2.4179254;-2.4489274;-3.3492851;-4.150892;-0.47334442;-1.6447479;CODE
the final results will be converted back to the input namespace and device;-3.0616806;-0.85832065;-0.6886766;0.8038561;0.66046643;0.9492903;CODE
for the sake of consistency with other metric functions with array api support;3.8617387;0.43242893;-2.3815188;0.27400494;0.1459305;1.9109571;CODE
this is needed to handle the special case where y true y pred and;-3.5312693;2.1443877;0.7305674;3.4661918;5.325548;0.49551803;CODE
sample weight are all empty;1.5824785;3.9216602;-0.8452384;0.666635;-1.7279147;-1.3970492;-
in this case we don t pass sample weight to check targets that would;3.813821;3.6556861;-2.7812035;5.4262824;0.87455624;1.3536379;CODE
check that sample weight is not empty and we don t reuse the returned;2.0512972;6.259338;-2.2086322;4.509939;-1.155058;-0.72812295;IRRE
sample weight;4.0873704;1.7719023;2.1019504;1.0490122;0.65234363;-2.1117196;-
if labels are not consecutive integers starting from zero then;0.6960269;4.2188344;1.3952953;-4.299721;1.3023914;-3.9001434;CODE
y true and y pred must be converted into index form;1.0065026;4.1634;-0.79259145;-3.5441737;0.50268775;-2.7026043;CODE
intersect y pred y true with labels eliminate items not in labels;1.1209452;3.2424977;1.5814703;-1.6749532;1.4438328;-1.5829748;CODE
also eliminate weights of eliminated items;3.1059346;2.937504;3.1095793;0.77995634;2.1808617;3.0422754;-
choose the accumulator dtype to always have high precision;3.0371454;1.068311;-4.4806824;-1.8438263;-0.21978675;-0.9566004;IRRE
labels are now from 0 to len labels 1 use bincount;-0.7849468;2.0908318;-0.7909493;-4.542032;0.2908584;-2.1481047;CODE
pathological case;-4.755823;0.623592;1.9037637;1.57294;0.5641476;-1.2085569;CODE
retain only selected labels;0.88739157;0.94640636;2.634127;0.34066772;3.1818764;3.0078466;CODE
all labels are index integers for multilabel;0.14110726;1.9537282;-0.8428418;-5.282062;2.9593482;-1.3022139;CODE
select labels;1.2909181;-0.5291341;3.2590256;-2.8965485;4.742096;-0.7694032;CODE
calculate weighted counts;4.5946116;2.3675282;2.5437262;-1.7330688;1.1039492;-2.960188;-
array api strict only supports floating point dtypes for truediv;-0.7278728;1.959971;-7.392196;-1.7290056;-3.7349017;-1.1256974;CODE
which is used below to compute expected as well as k therefore;1.3337326;1.132141;-0.49356467;-0.9129835;1.4380084;-2.2171464;CODE
we use the maximum floating point dtype available for relevant arrays;3.8327553;-1.6279227;-2.774245;-3.2519162;-0.28101796;-0.9764788;CODE
to avoid running into this problem;-4.2547436;2.2124844;2.4845338;3.6990728;0.037862215;-2.66695;CODE
else linear or quadratic;0.30483022;2.3882835;2.5442657;-3.637884;-0.12218186;-2.1733232;-
numerator is 0 and warning should have already been issued;-3.5660543;5.4739604;-3.1869528;-0.83644086;-2.2606273;-3.5785956;CODE
denominator mask 1 avoid infs nans;1.6245321;3.5658472;-2.7862053;-2.1681633;-3.2310307;0.8708534;CODE
set those with 0 denominator to zero division and 0 when warn;-1.4030517;5.1173983;-0.8045628;-2.6460512;-1.076173;-2.2145123;IRRE
we assume the user will be removing warnings if zero division is set;-1.4876803;5.306907;-2.5235794;1.304126;0.38192382;-2.4937017;IRRE
to something different than warn if we are computing only f score;2.4463809;0.70786995;-0.4865155;4.8950295;0.24714324;-3.0160165;-
the warning will be raised only if precision and recall are ill defined;-0.48361;2.2306087;-4.9768734;5.141847;0.16101182;-0.36671513;CODE
build appropriate warning;-4.649095;-0.12186163;-1.9858268;4.5797367;-0.16808587;-2.2771792;-
convert to python primitive type to avoid numpy type python str;-0.846476;-0.581783;-4.95613;-4.645721;-3.872506;-1.3310546;CODE
comparison see https github com numpy numpy issues 6784;1.2271737;-2.138397;-6.806182;-4.5255895;-8.654392;-1.2292714;CODE
calculate tp sum pred sum true sum;0.4284387;2.2976997;-0.11203828;-2.243369;-0.55367404;-2.392745;-
finally we have all our sufficient statistics divide;2.0414877;0.39556524;2.1287313;2.2734942;1.1184573;0.20558198;CODE
divide and on zero division set scores and or warn according to;2.9201334;4.5915837;0.6490513;-0.9443538;1.9703188;-5.1733937;CODE
zero division;-1.5087464;2.841717;2.427828;-4.5406117;-0.11711597;-5.1105866;-
the score is defined as;1.7141509;1.172921;1.7280806;1.0296284;2.3309975;-3.399146;CODE
score 1 beta 2 precision recall beta 2 precision recall;1.0818813;-1.6370169;-1.8400177;1.6286405;1.8766117;-2.8381505;IRRE
therefore we can express the score in terms of confusion matrix entries as;5.0588093;0.5213628;0.44302118;-1.6718004;3.9994893;-3.3096728;CODE
score 1 beta 2 tp 1 beta 2 tp beta 2 fn fp;0.15976764;-0.29371676;0.7832671;-0.8091592;2.88078;-3.5772755;-
array api strict requires all arrays to be of the same type so we;-1.2984779;4.8634515;-3.6409538;1.0968475;-1.208499;0.61228085;CODE
need to convert true sum pred sum and tp sum to the max supported;2.0419853;2.186667;-0.44400725;-2.4498532;0.011394714;-0.71667665;TASK
float dtype because beta2 is a float;-0.33030698;0.0154740615;-3.1048112;-3.370168;-1.5758164;-1.1586479;CODE
average the results;4.29996;1.1738774;5.1180334;1.6373558;-2.393286;-3.7948751;IRRE
true sum none return no support;-1.6201102;5.7018504;-4.068616;0.74989474;-1.4748199;-4.0895143;IRRE
todo 1 9 when raise warning is removed the following changes need to be made;-5.041312;3.1107457;-0.90478534;4.06776;-1.3302921;1.8093661;TASK
the checks for raise warning true need to be removed and we will always warn;-2.5547225;2.174023;-1.8037659;4.370008;-1.4196022;0.7017602;CODE
remove futurewarning and the warns section in the docstring should not mention;-5.634921;-0.14725575;-3.6495125;6.6956167;-2.0493171;0.63293135;CODE
raise warning anymore;-3.7654312;1.8903689;-0.2830924;4.55404;-1.9600365;-0.11375587;OUTD
if support pos 0 a division by zero will occur;-1.1205498;3.946874;-1.2994822;-2.8058906;0.34649223;-1.4709395;-
if fp 0 a division by zero will occur;-1.6396546;3.8158557;-0.08293194;-3.3382266;-0.911164;-2.196261;-
replace undefined by is a dict and;-3.4027503;2.1343381;-1.1694746;-1.2121786;-0.411188;-3.94416;CODE
isinstance replace undefined by get lr none real this includes;-4.4837537;5.144512;-2.2599869;0.64744526;-1.5454221;-1.8629707;CODE
np inf and np nan;1.5698092;0.6244803;-2.1191442;-3.601188;-1.8795677;-2.6432486;-
if tn 0 a division by zero will occur;-0.8921834;3.7393029;0.23471418;-4.6411676;-0.8666564;-3.5490842;-
replace undefined by is a dict and;-3.4027503;2.1343381;-1.1694746;-1.2121786;-0.411188;-3.94416;CODE
isinstance replace undefined by get lr none real this includes;-4.4837537;5.144512;-2.2599869;0.64744526;-1.5454221;-1.8629707;CODE
np nan;-1.5824972;-0.50477827;1.5554569;-4.5749903;-2.6200979;-3.7662601;-
array api strict only supports floating point dtypes for truediv;-0.7278728;1.959971;-7.392196;-1.7290056;-3.7349017;-1.1256974;CODE
which is used below to compute per class;2.6345413;-2.6728134;0.76488036;-1.2368485;6.8587418;-1.795163;IRRE
labelled micro average;3.9575665;0.7811363;1.6411966;-2.2086415;-0.23231584;-0.66367054;-
compute per class results without averaging;7.0553794;-0.32060453;1.0986682;0.82448184;3.6169403;-1.7066946;IRRE
compute all applicable averages;4.9449615;3.0583107;2.4385824;-2.0483892;0.18393034;-2.4450831;-
compute averages with specified averaging method;4.300732;1.9915733;1.7594842;-0.27461;-2.1933074;0.62731934;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
pairwise distances reductions;5.521117;0.21553612;-0.29458696;-2.78189;1.1014055;2.7216828;-
overview;-2.2394018;-5.855224;6.047078;1.8830787;2.5841618;-0.8255663;-
this module provides routines to compute pairwise distances between a set;4.0052958;-1.4888215;0.80892056;-4.349951;1.6342987;-0.6683036;CODE
of row vectors of x and another set of row vectors of y and apply a;2.3964965;0.039296787;1.2887357;-3.717151;-0.22958037;-0.54128814;IRRE
reduction on top the canonical example is the brute force computation;3.3079808;-1.4719526;-0.3532657;2.0573127;1.8557831;-0.34108716;CODE
of the top k nearest neighbors by leveraging the arg k min reduction;6.433978;-2.0415123;-0.3875684;-3.2059278;0.8947758;3.175149;-
the reduction takes a matrix of pairwise distances between rows of x and y;4.315996;0.78957665;0.20347941;-4.5687604;-2.2928379;3.218986;-
as input and outputs an aggregate data structure for each row of x the;6.4046497;0.3952912;3.325537;-5.9247537;3.0462945;-0.8870283;CODE
aggregate values are typically smaller than the number of rows in y hence;3.8749483;3.7104936;-0.7366012;-3.8406465;-3.0992997;-0.6300946;IRRE
the term reduction;-0.46734983;0.3968728;2.541631;2.2334757;3.020549;0.89744556;-
for computational reasons the reduction are performed on the fly on chunks;3.1026907;-0.8266698;-0.13142654;0.123547435;0.035015646;1.9068419;CODE
of rows of x and y so as to keep intermediate data structures in cpu cache;4.4947376;1.3483288;2.4885032;-5.070534;1.015897;2.4173903;CODE
and avoid unnecessary round trips of large distance arrays with the ram;2.2928345;-0.36565804;1.1354648;-0.93041736;0.12935981;2.8224034;IRRE
that would otherwise severely degrade the speed by making the overall;-0.68357337;1.3660554;3.1245747;0.8879905;0.42092547;4.4041924;CODE
processing memory bound;2.1080766;-1.1153913;1.5293794;0.8338743;0.6554373;0.82592595;-
finally the routines follow a generic parallelization template to process;0.59894276;-3.2960153;0.14734864;0.8889367;1.5036062;3.7811594;CODE
chunks of data with openmp loops via cython prange either on rows of x;4.0070643;2.0758207;-0.45112705;-6.026804;-1.4466147;0.77821285;IRRE
or rows of y depending on their respective sizes;5.422412;2.6519492;4.9642725;-6.4304576;2.0538523;-1.3983613;TASK
dispatching to specialized implementations;-1.5304053;-4.93605;-0.69451684;3.7605748;3.3103395;2.7197332;TASK
dispatchers are meant to be used in the python code under the hood a;-4.380131;-3.8795054;-1.7652626;1.6638154;-0.65976757;0.5257053;CODE
dispatcher must only define the logic to choose at runtime to the correct;-4.184141;2.5493379;-2.5784528;4.1630588;1.7406293;2.6304822;CODE
dtype specialized class basedistancesreductiondispatcher implementation based;-0.42978096;-2.4356894;-4.8856525;-0.8238203;0.8301148;0.9727111;TASK
on the dtype of x and of y;0.77814686;-1.7570844;-0.891524;-3.0856645;0.6094273;-1.8016173;CODE
high level diagram;-0.16425206;-2.537197;5.1785164;-3.627284;1.3752228;-0.26508614;-
legend;-2.146919;-0.844511;5.3660975;1.84187;-0.5071146;-2.340314;CODE
a b a inherits from b;-3.646002;0.50715154;2.484489;0.23995548;3.7927864;-0.8688067;CODE
a x b a dispatches to b;-2.8514786;1.1795857;2.6261325;-0.041293677;3.020973;0.31043622;-
base dispatcher;-4.245826;-2.52054;3.0472934;1.7696277;2.320362;1.6709596;-
basedistancesreductiondispatcher;-0.6049957;-0.83049583;-1.600808;1.3808798;0.89610803;2.1922646;-
dispatcher dispatcher;-4.205646;-1.9087696;2.9314594;1.9465901;1.6398139;1.6891545;-
argkmin radiusneighbors;-0.27683908;-0.55706286;3.018735;-2.9248185;-0.9670004;-1.4025422;-
float 32 64 implem;-3.5198314;1.498025;-1.029005;-4.6071672;-2.1707878;-2.4762673;CODE
basedistancesreduction 32 64;-4.639492;-1.7665422;-4.019735;-1.2425371;-0.208316;-0.94153637;-
dispatcher dispatcher;-4.205646;-1.9087696;2.9314594;1.9465901;1.6398139;1.6891545;-
argkminclassmode radiusneighborsclassmode;-0.636662;-1.0982034;-2.753944;-1.379056;1.8064708;1.5487636;IRRE
x x;-2.7816641;-0.2696263;3.766455;-2.9149847;0.05220214;-1.8572488;-
argkmin 32 64 radiusneighbors 32 64;-4.8242536;-0.94431263;-0.8861617;-3.738309;-1.6192229;-0.8728912;-
x x;-2.7816641;-0.2696263;3.766455;-2.9149847;0.05220214;-1.8572488;-
argkminclassmode 32 64 radiusneighborsclassmode 32 64;-3.8638036;-1.8038858;-4.1375675;-1.5919278;0.16549364;0.7789848;IRRE
specializations;-0.3533377;-5.522448;3.486605;2.7368927;4.21418;0.7939302;-
x x;-2.7816641;-0.2696263;3.766455;-2.9149847;0.05220214;-1.8572488;-
euclideanargkmin 32 64 euclideanradiusneighbors 32 64;-2.104996;-0.55152607;-1.0678602;-5.907658;-1.1798437;-1.3776317;CODE
for instance class argkmin dispatches to;-3.4335768;-2.8696125;-1.2198199;3.7279253;2.4045632;3.3614826;CODE
class argkmin64 if x and y are two float64 array likes;1.1772212;3.0963812;-0.39673644;-5.1589694;0.063191004;-3.4086823;CODE
class argkmin32 if x and y are two float32 array likes;2.1082947;2.469818;-1.0374553;-5.6822295;1.0311174;-2.6392956;CODE
in addition if the metric parameter is set to euclidean or sqeuclidean;0.41078943;0.9964353;-0.39193967;-1.8281554;-1.6300385;2.6392167;IRRE
then some direct subclass of basedistancesreduction 32 64 further dispatches;-3.6799552;-2.278112;-3.8934112;1.8141296;2.9084342;3.156334;IRRE
to one of their subclass for euclidean specialized implementation for instance;2.1560018;-3.7369347;-1.8610178;-1.1484903;3.431587;2.288764;CODE
class argkmin64 dispatches to class euclideanargkmin64;-2.3248446;-1.5804611;-4.5931044;-0.64011675;0.093381055;2.3711872;CODE
those euclidean specialized implementations relies on optimal implementations of;4.48829;-3.5589373;-1.0521556;-0.76092905;0.35538444;2.159818;TASK
a decomposition of the squared euclidean distance matrix into a sum of three terms;3.6120193;-2.0782714;0.37583047;-4.8165965;-1.6283164;3.8336415;CODE
see class middletermcomputer 32 64;-4.918732;-3.0277803;-1.1858802;-0.5670216;0.43905693;-0.24540934;CODE
ruff noqa e501;-3.963279;0.45672655;-0.20830372;-3.740623;1.3280871;-2.2385979;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
pyfunc cannot be supported because it necessitates interacting with;-3.4848745;-1.661928;-3.783456;0.45198005;-6.1885366;1.3639349;CODE
the cpython interpreter to call user defined functions;-3.6004643;-3.142926;-1.2401803;-0.40560782;-2.52731;-1.5385662;CODE
mahalanobis is numerically unstable;1.2849144;0.97610164;-3.219663;-1.9122834;-3.5406287;1.6684066;IRRE
in order to support discrete distance metrics we need to have a;3.3229916;-0.7426931;1.1634514;-1.4718219;3.2743254;2.5247545;TASK
stable simultaneous sort which preserves the order of the indices;0.1587704;1.7766074;1.0115519;-1.7929653;1.6119518;3.090787;-
because there generally is a lot of occurrences for a given values;4.182556;2.4270525;0.22736877;-0.305507;1.2829657;-3.6616888;IRRE
of distances in this case;2.045941;1.1676974;5.980735;-2.9648585;-0.06548844;-2.4687285;CODE
todo implement a stable simultaneous sort;1.367415;2.134316;1.9489619;0.7096877;2.3313894;1.5159085;TASK
fixme the current cython implementation is too slow for a large number of;-0.3080163;-0.9380048;-1.9225076;-0.13599953;-2.5933056;0.07883094;TASK
features we temporarily disable it to fallback on scipy s implementation;-2.3956158;-3.1491544;-5.567449;2.0954769;-4.6847744;1.0923063;TASK
see https github com scikit learn scikit learn issues 28191;-1.9463588;-11.153437;-6.957923;-0.29902726;-5.0260296;-3.691114;CODE
todo support csr matrices without non zeros elements;1.4048443;1.9533228;-2.343613;-3.7337856;0.42081484;2.048061;TASK
todo support csr matrices with int64 indices and indptr;0.9003767;0.12967788;-3.9965127;-5.140725;-0.50689495;0.7773577;CODE
see https github com scikit learn scikit learn issues 23653;-2.068475;-10.843309;-6.9200687;-0.8119561;-4.86073;-4.701573;CODE
euclidean is technically usable for argkminclassmode;1.440306;-1.8107185;-3.4580982;-0.8395179;0.24805906;2.8203757;CODE
but its current implementation would not be competitive;-0.61517715;-0.81757605;1.0962847;3.6466513;2.8760872;1.7762802;TASK
todo implement euclidean specialization using gemm;1.2087626;-1.4923782;-2.3962684;-1.6956743;2.7823524;2.3789673;TASK
euclidean is technically usable for radiusneighborsclassmode;1.7978324;-0.57432956;-1.5718802;-3.215043;0.44618818;1.5210714;CODE
but it would not be competitive;0.30670068;1.3085647;2.1623101;2.6715393;1.9757568;1.0336303;META
todo implement euclidean specialization using gemm;1.2087626;-1.4923782;-2.3962684;-1.6956743;2.7823524;2.3789673;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
print text with appropriate color depending on background;-1.2516563;0.9504974;3.3761702;-2.3272276;0.9330446;-1.669645;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
we have the following bounds;-1.5537744;1.8958273;4.909807;-0.57249475;-0.6243994;-2.7654715;-
sp stats norm ppf 0 0 np inf;2.3272738;0.94626516;-4.6462526;-3.2429194;-3.1109552;0.15834181;-
sp stats norm ppf 1 0 np inf;2.7453222;0.83660555;-4.0050955;-3.2448196;-2.469877;0.40585572;-
we therefore clip to eps and 1 eps to not provide infinity to matplotlib;1.5567713;0.073189594;-1.4936688;-4.2200127;-7.7770863;2.4825048;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
force to have a squared axis;-0.8734279;0.31482735;4.0007415;-3.2204912;-4.639126;1.6103271;CODE
else kind residual vs predicted;1.7927198;0.9707758;0.38934872;5.3760695;-1.9720376;0.15158339;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
return single artist if only one curve is plotted;2.227576;3.8478696;3.3752716;-1.5943484;-1.4284717;0.46937808;IRRE
case 1 multiclass classifier with multiclass target;2.5911462;-1.6557388;-2.302947;1.6237257;5.5448675;1.6073836;CODE
case 2 multiclass classifier with binary target;1.8333764;-0.92646587;-3.56788;0.30053312;5.8341994;0.04006721;CODE
case 3 binary classifier with multiclass target;1.2212667;-1.0921508;-3.2963192;-0.64245105;6.712965;0.086804405;CODE
clone since we parametrize the test and the classifier will be fitted;3.1885254;1.0398511;-1.9261833;3.6604254;2.1445003;-0.29234126;IRRE
when testing the second and subsequent plotting function;0.84328735;4.985943;2.198352;1.2202442;-5.4053235;-2.1133802;IRRE
safe guard for the binary if else construction;-3.2869053;2.8694093;-2.1097534;1.2083027;3.1763341;-3.1126904;CODE
diagonal text is black;-3.9037263;-0.1764866;2.2510302;-3.78004;-1.8793578;-0.18886189;-
off diagonal text is white;-4.2746296;1.1112685;1.7598162;-3.6032906;-2.3136306;0.38637298;-
diagonal text is white;-3.7493415;0.801402;1.9327341;-4.0654263;-1.9352825;-0.33051538;-
off diagonal text is black;-4.5183887;0.044995826;2.0821788;-3.3471887;-2.108551;0.5584643;-
regression test for 15920;0.85322005;3.2310777;-1.1819508;3.5884094;-4.2470236;-6.986055;IRRE
from estimator passes the font size;1.7306725;1.7013571;-1.3259254;0.73420256;-2.7569768;4.6702895;CODE
plot adjusts plot to new font size;-0.30911666;0.94555837;2.7735827;-3.1791115;-7.710828;3.5082893;CODE
from predictions passes the font size;2.5794134;-1.4018581;1.215474;2.0792594;-2.0600684;0.9550915;CODE
binarize the data with only the two first classes;4.743653;2.3282468;-0.6259462;-3.3012114;5.3257713;-2.0782557;IRRE
safe guard for the binary if else construction;-3.2869053;2.8694093;-2.1097534;1.2083027;3.1763341;-3.1126904;CODE
cannot fail thanks to pyplot fixture;-2.441599;3.0537264;-1.8450438;0.24071625;-6.636554;0.09477772;-
check the default name display in the figure when name is not provided;-2.095587;3.4832327;0.6337629;0.96488655;-1.3175011;1.3182567;CODE
binarize the data with only the two first classes;4.743653;2.3282468;-0.6259462;-3.3012114;5.3257713;-2.0782557;IRRE
todo 1 10 remove;-4.2360086;2.7419755;3.143769;-0.006628793;-0.09705227;-1.9662911;TASK
checking for chance level line styles;0.05079263;-0.4754616;0.73540276;1.8759962;1.9280729;-1.4231983;CODE
check that we can provide the positive label and display the proper;-2.3823125;3.7871957;0.28930247;-1.3642153;2.0421314;-3.0709963;-
statistics;3.9476264;-1.4593278;6.955704;2.5886195;-0.1404738;-4.8412933;-
create a highly imbalanced version of the breast cancer dataset;5.524809;-1.4152482;0.09369349;1.2615206;1.0490558;-1.0102924;IRRE
only use 2 features to make the problem even harder;0.9976812;-0.1338072;1.3932428;1.5583471;2.5978005;1.9886526;TASK
sanity check to be sure the positive class is classes 0 and that we;-0.23907307;2.1043127;-3.921078;1.0373125;2.148628;-2.248449;IRRE
are betrayed by the class imbalance;1.2707032;0.14628221;-0.88613814;2.6646252;0.31467888;-0.7495637;IRRE
we select the corresponding probability columns or reverse the decision;3.1819093;-0.68509895;3.278596;-0.7451688;4.5843368;0.32553613;IRRE
function otherwise;-3.246307;3.4929173;3.6387045;1.9178146;-1.4460636;-2.5331316;CODE
we should obtain the statistics of the cancer class;2.5967155;-2.5830956;2.7492478;2.0013347;2.036981;-2.4346104;CODE
otherwise we should obtain the statistics of the not cancer class;2.7003145;-0.86008793;0.41521627;2.8955703;1.6631898;-1.8033761;CODE
check that even if one passes plot chance level false the first time;1.098509;5.1522613;1.0862705;3.092616;-2.993769;-2.1313972;IRRE
one can still call disp plot with plot chance level true and get the;0.4144714;-0.33452722;2.0074227;0.88538074;-3.5288355;0.738847;TASK
chance level line;0.5243987;-0.30938265;4.629316;0.56893957;0.48453456;-2.135666;-
when calling from estimator or from predictions;1.713937;-0.79489934;1.2838384;6.0808616;-1.0818782;2.3176112;CODE
prevalence pos label should have been set so that directly;-0.48779166;0.9911412;-2.1247146;1.9911767;1.4945168;0.41410995;IRRE
calling plot chance level true should plot the chance level line;0.057336625;1.1272695;2.696158;0.11095175;-4.487312;0.48804832;IRRE
check that raises correctly when plotting chance level with;2.1003118;2.8404462;1.8183731;-0.24537334;-5.1368976;-2.0697768;CODE
no prvelance pos label is provided;-4.4590225;-1.3354918;-0.4881402;-1.1727017;0.993874;-0.500973;-
check that the despine keyword is working correctly;-3.8285048;3.4333985;-1.7747377;1.8705006;0.15268172;-2.7879224;-
safe guard for the binary if else construction;-3.2869053;2.8694093;-2.1097534;1.2083027;3.1763341;-3.1126904;CODE
todo 1 10 remove;-4.2360086;2.7419755;3.143769;-0.006628793;-0.09705227;-1.9662911;TASK
list of length 1 is always allowed;-1.6725276;3.960714;0.039576463;-0.35882258;3.0546293;-4.1962457;CODE
initialize display with test inputs;-1.8244243;4.8455253;2.2207875;1.8124645;-0.18256277;-1.7808279;IRRE
default alpha used;-4.405422;-1.7122968;0.963123;-0.20134729;-0.9684257;0.18367594;CODE
alpha from dict used for all curves;-0.5604315;-2.0394995;-0.43564036;-3.5330925;-3.397556;-1.7897934;CODE
different alpha used for each curve;1.1258872;0.2763457;2.7841084;-3.0119638;-1.7525632;0.9651369;CODE
other default kwargs should be the same;-3.6068556;-1.843089;-1.9124756;0.92642576;-0.33279;4.635789;IRRE
todo 1 9 remove in 1 9;-2.6143658;3.3037894;2.963878;-1.8551879;1.6594012;-3.2166712;TASK
default alpha for from cv results;0.9877088;0.1459749;-2.8947003;0.76046056;-0.6694052;0.97730404;CODE
each individual curve labelled;4.183797;-1.4324002;4.905491;-5.122061;1.1011876;-0.57273865;-
single aggregate label;3.0927105;0.3477464;2.348555;-1.3914679;6.072448;0.6147405;-
multiple labels in legend;-0.36866826;0.43016806;3.8077667;-2.5260189;2.956666;0.23341887;CODE
name is a list of different strings;-0.95382625;-0.44802454;2.2632914;-1.3337699;4.295853;-5.019644;CODE
single label in legend;-1.0824319;0.5887112;2.7189937;-1.3205582;2.6268713;0.60596734;CODE
name is single string;-4.5583324;1.1701636;1.2080694;-0.6520322;2.344234;-3.296666;CODE
should be estimator classes 1;1.8209876;-0.48415634;-0.6449806;2.6029425;0.48554364;0.53153414;IRRE
checking for legend behaviour;-0.6072119;4.125032;1.7030877;3.0515463;-1.1570883;-2.1871228;CODE
assert legend is not none legend should be present if any label is set;-0.76178586;6.7903976;-2.4986749;3.353772;1.0413198;-1.8356774;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
reductions such as sum used internally in trapezoid do not return a;0.95577556;5.051479;-1.525211;-1.5301977;-1.263822;0.85398257;CODE
scalar by default for numpy memmap instances contrary to;1.49615;-0.14940734;-5.246065;-2.488564;-4.6191645;3.9498725;CODE
regular numpy ndarray instances;2.7941372;-1.60537;-3.5285914;-4.631783;-4.3682623;1.9457617;-
return the step function integral;-2.6058462;1.2717342;2.4210007;-0.50879794;-2.7083333;-0.028351173;CODE
the following works because the last entry of precision is;1.0135589;2.963361;-0.60926163;-1.7794689;-1.079842;-3.7237637;IRRE
guaranteed to be 1 as returned by precision recall curve;3.5207198;1.7097759;-1.8819654;2.779349;-0.62796944;-2.075536;IRRE
due to numerical error we can get 0 0 and we therefore clip it;0.034874137;3.695754;-1.3497897;-2.8313608;-4.5315905;0.23874469;CODE
convert to python primitive type to avoid numpy type python str;-0.846476;-0.581783;-4.95613;-4.645721;-3.872506;-1.3310546;CODE
comparison see https github com numpy numpy issues 6784;1.2271737;-2.138397;-6.806182;-4.5255895;-8.654392;-1.2292714;CODE
add a threshold at inf where the clf always predicts the negative class;3.472294;1.3558258;-3.193518;1.9672986;0.42155525;1.0442022;TASK
i e tps fps 0;-2.3963928;-0.84868115;2.153217;-1.9200357;-3.190645;-0.7248528;-
drop thresholds where true positives tp do not change from the;3.245215;3.6997733;-1.5614556;1.6572462;-0.5605881;0.21068144;CODE
previous or subsequent threshold as tp fn is fixed for a dataset;3.9502099;1.2402123;-1.1306993;1.4193946;-0.020297576;2.044057;IRRE
this means the false negative rate fnr remains constant while the;-0.0055628438;3.0927145;-1.5989105;0.15045212;-1.599391;0.28455126;CODE
false positive rate fpr changes producing horizontal line segments;0.15832172;4.277929;-2.1086342;-0.86859846;-3.1609766;-0.25323403;CODE
in the transformed normal deviate scale these intermediate points;0.6199471;0.9634573;0.83811134;-4.101136;-2.3889515;5.134688;CODE
can be dropped to create lighter det curve plots;1.7084084;-0.07670199;1.9657298;-2.4970496;-3.7013054;2.9182444;IRRE
start with false positives zero which may be at a finite threshold;2.2166092;4.751171;-2.0658684;1.8644229;0.842765;-4.3583884;IRRE
stop with false negatives zero;-0.9284594;7.077573;-0.42117327;-0.123151936;-2.7038114;-4.4756923;-
reverse the output such that list of false positives is decreasing;2.5594044;4.8404427;0.8569209;-0.46216708;-0.3452541;-4.7534566;IRRE
is 00 04 stern school of business new york university;-2.82418;-1.0637069;-0.85857105;-1.319369;1.6242665;-0.61169094;CODE
get a list of n output containing probability arrays of shape;4.890401;-0.9066377;2.7644997;-3.2282715;0.76697475;-1.194422;IRRE
n samples n classes;5.010179;-1.7182858;0.3866853;-1.9464281;5.822587;-4.26262;IRRE
extract the positive columns for each output;4.781103;1.5215809;1.7881583;-5.9465256;0.51751316;-3.6781976;CODE
we have ground truth relevance of some answers to a query;-0.21960036;-1.1830043;1.2160946;1.9560055;3.7100794;-0.98507917;CODE
we predict scores for the answers;4.546076;-2.7673788;3.6856167;4.860249;0.95673746;-4.2455373;CODE
we can set k to truncate the sum only top k answers contribute;1.4860904;0.064826705;2.3791487;-0.040036988;-0.009898211;-1.0899436;IRRE
now we have some ties in our prediction;2.0678444;-1.5311916;3.7545688;3.1499894;-0.4038295;0.3883639;-
by default ties are averaged so here we get the average true;2.1803637;1.7360729;2.6290264;0.50504357;-0.76748663;0.22909261;CODE
relevance of our top predictions 10 5 2 7 5;2.5651355;-2.2593215;3.0428758;4.003653;0.26868972;-0.7080668;-
we can choose to ignore ties for faster results but only;2.7860956;1.1531099;2.277868;3.963181;2.1649797;0.8967112;IRRE
if we know there aren t ties in our scores otherwise we get;1.7332975;1.7455983;2.4582233;2.4104671;0.8641911;-2.2068894;-
wrong results;0.9442473;3.8227627;1.2322803;0.42111146;-3.0318258;-6.308828;IRRE
we have ground truth relevance of some answers to a query;-0.21960036;-1.1830043;1.2160946;1.9560055;3.7100794;-0.98507917;CODE
we predict some scores relevance for the answers;3.723315;-2.06052;1.9824208;3.8899283;2.2960608;-3.0026302;CODE
we can set k to truncate the sum only top k answers contribute;1.4860904;0.064826705;2.3791487;-0.040036988;-0.009898211;-1.0899436;IRRE
the normalization takes k into account so a perfect answer;3.630924;-0.34460774;-0.53410333;-3.1920562;0.32266518;1.7555637;CODE
would still get 1 0;-0.6779493;3.5841095;2.4707203;-0.85137993;0.14231512;-1.5444257;TASK
now we have some ties in our prediction;2.0678444;-1.5311916;3.7545688;3.1499894;-0.4038295;0.3883639;-
by default ties are averaged so here we get the average normalized;3.2004552;0.939249;1.9052806;-1.3767782;-0.166511;1.4325303;CODE
true relevance of our top predictions 10 10 5 10 2 75;2.9543436;-1.2450656;2.7344933;3.8397322;-0.3651888;-0.41173676;-
we can choose to ignore ties for faster results but only;2.7860956;1.1531099;2.277868;3.963181;2.1649797;0.8967112;IRRE
if we know there aren t ties in our scores otherwise we get;1.7332975;1.7455983;2.4582233;2.4104671;0.8641911;-2.2068894;-
wrong results;0.9442473;3.8227627;1.2322803;0.42111146;-3.0318258;-6.308828;IRRE
y score np array 0 5 0 2 0 2 0 is in top 2;3.4301734;1.776241;0.029806608;-5.8950076;-2.4297836;-4.231012;CODE
0 3 0 4 0 2 1 is in top 2;-0.25854713;1.2445829;2.944863;-4.662572;1.0549439;-3.0294561;CODE
0 2 0 4 0 3 2 is in top 2;-0.35491696;1.033494;3.1109161;-4.4774966;0.9611821;-2.9751909;CODE
0 7 0 2 0 1 2 isn t in top 2;0.14213091;2.0555403;1.5923972;-2.9868007;-0.5899674;-2.3848445;CODE
not normalizing gives the number of correctly classified samples;4.969901;1.3105361;-4.438012;-1.1904217;0.6771086;-0.5869324;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
pass none as weights to average uniform mean;3.8718014;3.7095842;-0.18697274;-0.82560337;-1.9124073;1.7037067;CODE
average across the outputs if needed;5.557275;1.8948752;4.7245846;-1.3417219;-0.20082584;-0.9377793;IRRE
the second call to average should always return;0.9619794;5.7437325;1.6065522;3.3487463;-2.6044734;-0.8378669;IRRE
a scalar array that we convert to a python float to;3.3281448;-1.3541408;-1.3066665;-6.642055;-5.151017;-1.1709945;CODE
consistently return the same eager evaluated value;1.8408843;5.5702834;-0.27260178;5.200899;2.8880503;-0.043468624;IRRE
therefore axis none;-1.5867393;4.486978;1.9397966;-6.1526065;-4.30363;-0.35239795;CODE
pass none as weights to average uniform mean;3.8718014;3.7095842;-0.18697274;-0.82560337;-1.9124073;1.7037067;CODE
average across the outputs if needed;5.557275;1.8948752;4.7245846;-1.3417219;-0.20082584;-0.9377793;IRRE
the second call to average should always return;0.9619794;5.7437325;1.6065522;3.3487463;-2.6044734;-0.8378669;IRRE
a scalar array that we convert to a python float to;3.3281448;-1.3541408;-1.3066665;-6.642055;-5.151017;-1.1709945;CODE
consistently return the same eager evaluated value;1.8408843;5.5702834;-0.27260178;5.200899;2.8880503;-0.043468624;IRRE
therefore axis none;-1.5867393;4.486978;1.9397966;-6.1526065;-4.30363;-0.35239795;CODE
pass none as weights to average uniform mean;3.8718026;3.709586;-0.18697423;-0.8256042;-1.9124074;1.7037075;CODE
average across the outputs if needed;5.557275;1.8948752;4.7245846;-1.3417219;-0.20082584;-0.9377793;IRRE
the second call to average should always return;0.9619794;5.7437325;1.6065522;3.3487463;-2.6044734;-0.8378669;IRRE
a scalar array that we convert to a python float to;3.3281448;-1.3541408;-1.3066665;-6.642055;-5.151017;-1.1709945;CODE
consistently return the same eager evaluated value;1.8408843;5.5702834;-0.27260178;5.200899;2.8880503;-0.043468624;IRRE
therefore axis none;-1.5867393;4.486978;1.9397966;-6.1526065;-4.30363;-0.35239795;CODE
pass none as weights to average uniform mean;3.8718026;3.709586;-0.18697423;-0.8256042;-1.9124074;1.7037075;CODE
average across the outputs if needed;5.557275;1.8948752;4.7245846;-1.3417219;-0.20082584;-0.9377793;IRRE
the second call to average should always return;0.9619794;5.7437325;1.6065522;3.3487463;-2.6044734;-0.8378669;IRRE
a scalar array that we convert to a python float to;3.3281448;-1.3541408;-1.3066665;-6.642055;-5.151017;-1.1709945;CODE
consistently return the same eager evaluated value;1.8408843;5.5702834;-0.27260178;5.200899;2.8880503;-0.043468624;IRRE
therefore axis none;-1.5867393;4.486978;1.9397966;-6.1526065;-4.30363;-0.35239795;CODE
pass none as weights to average uniform mean;3.8718026;3.709586;-0.18697423;-0.8256042;-1.9124074;1.7037075;CODE
average across the outputs if needed;5.557275;1.8948752;4.7245846;-1.3417219;-0.20082584;-0.9377793;IRRE
the second call to average should always return;0.9619794;5.7437325;1.6065522;3.3487463;-2.6044734;-0.8378669;IRRE
a scalar array that we convert to a python float to;3.3281448;-1.3541408;-1.3066665;-6.642055;-5.151017;-1.1709945;CODE
consistently return the same eager evaluated value;1.8408843;5.5702834;-0.27260178;5.200899;2.8880503;-0.043468624;IRRE
therefore axis none;-1.5867393;4.486978;1.9397966;-6.1526065;-4.30363;-0.35239795;CODE
pass none as weights to np average uniform mean;3.9716353;2.5016925;-1.9100753;-2.1381764;-2.5814314;1.6527747;CODE
extreme stable y any real number y pred 0;0.03616624;1.6443684;0.0035593447;-1.6451803;-2.5890715;-0.7555691;-
normal distribution y and y pred any real number;-2.5878143;1.7897351;1.9584426;-3.1637177;-2.177686;-0.91330683;META
poisson distribution;-1.6010735;1.4324383;5.6033306;-0.34037507;-0.43233034;-3.0628865;META
gamma distribution;-2.6138241;-0.25164017;3.8284981;-1.5275599;-1.6896755;-0.77955544;META
extreme stable y any real number y pred 0;0.036164504;1.6443678;0.003558987;-1.6451796;-2.589073;-0.7555703;-
normal y and y pred can be any real number;-1.500973;2.6566253;-0.0915329;-3.495483;-1.510037;-1.7421546;-
poisson and compound poisson distribution y 0 y pred 0;-2.8580453;2.796892;0.7641624;-1.3806647;-2.3764277;-1.5736792;META
gamma and extreme stable distribution y and y pred 0;-1.9822015;0.732294;0.25716424;-1.0908419;-3.085427;1.3587664;META
else pragma nocover;-3.1405852;1.4872587;1.1520178;1.3366095;0.32284197;-1.403905;-
unreachable statement;-4.5020366;3.9481037;-0.27624336;1.4365844;-0.48033473;-5.131134;-
return scores individually;3.3072836;3.1168606;2.1230738;1.0901304;2.3753462;-3.0310624;IRRE
else multioutput uniform average;5.923709;2.2014067;1.1985976;-1.4161115;-0.60771483;-1.4855566;IRRE
passing none as weights to np average results in uniform mean;3.881395;2.4471214;-2.3187277;-1.3487763;-3.0274909;1.8563846;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo slep006 remove when metadata routing is the only way;-4.5955753;1.2996536;-2.7545958;2.408434;0.5266434;5.507071;TASK
https scikit learn org stable glossary html term scoring;-0.48950842;-6.213042;-2.4957814;0.90368193;-0.5451248;-1.7449447;CODE
standard regression scores;1.7605524;0.15989946;0.4801092;-0.3123025;-1.3343375;-1.5645124;-
standard classification scores;4.4139977;-3.7861018;-0.9782067;-0.13520437;4.142243;-2.6786327;IRRE
score functions that need decision values;4.7465677;-0.3493233;1.4916073;0.79010135;2.646475;-2.4988546;IRRE
score function for probabilistic classification;5.150456;-3.9605734;0.20342821;1.2544688;5.1278524;-0.7901722;CODE
clustering scores;6.0831413;-2.5578802;2.2324955;-0.5208651;1.9807;-1.4130048;-
cluster metrics that use supervised evaluation;5.1249375;-3.0439012;0.77131325;2.6698713;3.5263805;1.3472598;CODE
heuristic to ensure user has not passed a metric;2.5317347;2.6017501;-1.0901601;4.9950347;0.8768027;-0.40860307;-
transfer the metadata request;-3.39344;-1.8377469;1.069549;1.3686318;0.2995271;3.9032953;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo 1 10 remove;-4.2360086;2.7419755;3.143769;-0.006628793;-0.09705227;-1.9662911;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
input checks;-1.0483352;2.3586025;2.8633597;1.5049845;1.2827436;-6.913283;CODE
wk https en wikipedia org wiki rand index adjusted rand index;-0.77265596;-2.8548036;-0.11716222;-0.9529143;0.47456798;-2.1791463;IRRE
b contains 2 of the 3 biclusters in a so score should be 2 3;0.966962;2.5912855;0.76381767;-1.9166217;4.286632;-4.347256;-
dictionaries of metrics;3.3530006;-4.05332;0.5614094;-2.404708;1.378336;0.88952136;-
the goal of having those dictionaries is to have an easy way to call a;-2.657172;-4.1264477;0.48346668;0.5634355;2.4204597;-0.26401985;IRRE
particular metric and associate a name to each function;3.180792;-0.90328443;1.2617882;-1.550495;2.6801589;2.7681396;CODE
supervised metrics all supervised cluster metrics when given a;4.522285;-2.7681925;-0.60386205;0.40564626;3.0282414;2.995823;CODE
ground truth value;0.46300027;2.5544314;-1.3869276;0.28076977;0.7219193;-2.0699914;IRRE
unsupervised metrics all unsupervised cluster metrics;3.908172;-3.64606;-1.356117;-0.5458407;-0.2641877;3.754311;CODE
those dictionaries will be used to test systematically some invariance;2.3509011;-2.9012403;-2.0760357;2.7367997;1.8583791;-2.129802;IRRE
properties e g invariance toward several input layout;2.0092328;-1.3297942;2.5911045;-0.68503314;2.8419378;5.283317;CODE
lists of metrics with common properties;3.4819753;-1.6595917;1.3754863;-1.0582591;2.5868347;0.4534473;-
lists of metrics with common properties are used to test systematically some;5.3504972;-1.6874546;-0.36344105;3.134564;2.075194;-1.8465441;IRRE
functionalities and invariance e g symmetric metrics lists all metrics;0.17438018;-3.2377856;-0.25055146;-0.013675091;1.212837;3.306121;CODE
that are symmetric with respect to their input argument y true and y pred;-1.8286493;1.520334;-0.8676985;-2.7229364;1.0948279;-2.9045823;CODE
symmetric with respect to their input arguments y true and y pred;-0.795821;1.8200513;-0.39626545;-2.4427662;1.7840918;-1.3835815;CODE
symmetric metrics only apply to supervised clusters;3.526307;-3.114882;-3.1387115;-0.19187582;1.6658194;3.7167377;CODE
metrics whose upper bound is 1;1.2262385;0.17783974;1.7018051;-0.9746113;-0.36150727;0.35981685;-
all clustering metrics do not change score due to permutations of labels;3.6164157;0.11042343;-1.8009533;-0.60100895;1.2863275;1.5722483;CODE
that is when 0 and 1 exchanged;-3.9605234;1.8043982;2.3465014;-4.264106;0.42898855;-2.482465;-
for all clustering metrics input parameters can be both;4.5171933;-1.6696036;-1.49486;-0.48857915;1.197774;3.959998;CODE
in the form of arrays lists positive negative or string;0.8273906;2.7248328;1.0300051;-4.9469132;1.1452599;-6.3495975;CODE
only the supervised metrics support single sample;5.0541363;-3.7475893;-1.5599109;2.2830951;3.4805858;2.5934215;CODE
non regression tests for https github com scikit learn scikit learn issues 30950;0.14795345;-5.3645673;-8.738195;3.5104036;-6.9240375;-5.556888;CODE
homogeneous but not complete clustering;3.8233802;1.0111145;-1.1128552;-2.2965822;1.1643915;2.2024124;META
complete but not homogeneous clustering;3.7929163;0.29822946;-0.34586754;-1.7244748;2.052619;2.4598536;META
neither complete nor homogeneous but not so bad either;-0.030574234;-0.531876;-0.5325348;0.67941636;1.1744211;-0.5525674;META
test for when beta passed to;-0.9884459;2.601862;-1.1105008;6.2706027;0.6929438;-4.8148246;IRRE
homogeneity completeness v measure;1.4311454;1.0180404;-1.3305457;1.2179433;0.92805004;3.0088615;CODE
and v measure score;3.2247357;0.0039177635;1.2151171;1.057003;2.9980392;-1.6132659;-
regression tests for labels with gaps;4.7162013;3.0290363;-0.13318427;2.3769093;0.7130236;-2.993091;IRRE
compute score for random uniform cluster labelings;5.596803;-1.5402355;-0.2726416;-2.180856;3.902005;0.045998648;CODE
check that adjusted scores are almost zero on random labels;4.7451262;3.5548728;-2.8522317;1.9622747;-0.20237342;-3.0347786;IRRE
compute the adjusted mutual information and test against known values;4.4574623;3.1365707;-1.3287629;0.76926184;1.5065215;-1.2584206;IRRE
mutual information;1.7550395;-1.6118329;3.938444;-0.7349133;3.7452667;1.8543168;CODE
with provided sparse contingency;5.229458;0.30492705;0.25143436;1.841849;3.922793;1.6693504;IRRE
with provided dense contingency;0.12843314;1.3296362;2.2962599;2.7550054;3.6830473;0.23979451;-
expected mutual information;1.0397135;-0.32310697;3.070226;0.8317004;2.139437;2.1517391;CODE
adjusted mutual information;2.8865795;0.069076754;1.560626;-0.36726427;2.5837665;4.142364;CODE
test with a very large array;4.341714;5.5126996;0.28113765;2.0866475;-1.3048947;-6.222023;IRRE
test for regression where contingency cell exceeds 2 16;1.725626;5.175041;0.013169163;1.7263151;-1.4567206;-4.099311;IRRE
leading to overflow in np outer resulting in emi 1;-0.6516365;1.0379989;-3.5023353;-1.343114;-3.7435524;0.6474581;IRRE
test overflow in mutual info classif and fowlkes mallows score;2.3680594;1.6002656;-4.633724;2.772625;0.2092472;-2.455399;IRRE
todo 1 10 remove;-4.2360086;2.7419755;3.143769;-0.006628793;-0.09705227;-1.9662911;TASK
check numerical stability when information is exactly zero;3.433821;4.7039266;-2.5535629;-0.82208186;-1.5039388;-0.058826536;CODE
check relation between v measure entropy and mutual information;1.0945581;-0.10093697;-1.3210087;-0.5968333;2.1541831;2.8994708;CODE
general case;-1.6987612;-0.11409626;4.625744;2.7893512;2.2690465;-0.9544086;CODE
perfect match but where the label names changed;-1.4631275;0.63064814;0.59850603;0.025492016;1.2672675;-0.4116984;META
worst case;-1.3931215;0.54451895;3.4867089;2.7994769;-0.45057383;-0.8212973;CODE
handcrafted example;-3.645292;-2.3118112;5.3603;-0.295201;2.6501029;-0.7467537;-
fmi tp sqrt tp fp tp fn;-1.5311064;0.5562576;-1.0581621;-3.7677674;-0.17161462;-0.2868249;-
symmetric property;-2.682882;1.2075186;2.5129046;-1.0557957;2.8065844;-0.7065322;-
permutation property;-0.95229185;1.4236164;4.3696804;-0.9747313;4.1767397;-2.7149308;-
symmetric and permutation both together;-1.6939893;0.3854239;3.3428257;-2.3342948;2.8772662;-2.1425722;-
check that mi 0 when one or both labelling are constant;1.3273582;5.77331;-2.3738935;-1.0512041;1.355604;-1.5963211;CODE
non regression test for 16355;-0.2994565;2.9838502;-3.7703261;3.3313003;-2.7398868;-6.4389787;IRRE
test warning message for continuous values;-0.012885721;6.131559;-2.355366;3.3773441;-2.6733408;-4.484694;IRRE
edge case every element is its own cluster;1.0253373;0.67205936;1.1471012;-2.755293;2.074268;3.3042958;CODE
edge case only one cluster;0.78727627;0.9935457;1.1652373;-2.1848269;2.0321624;3.2658029;CODE
regular case different non trivial clusterings;2.5649;0.63997;-1.3389537;-1.2679566;3.2311332;3.0896244;IRRE
basic quadratic implementation;0.019868923;0.30961797;1.7230049;-4.300135;-0.18248975;-0.44658068;TASK
edge case 1 every element is its own cluster;0.8354808;0.87432116;0.7902445;-2.947644;1.9226042;2.526705;CODE
edge case 2 only one cluster;0.63722515;0.6730414;1.3675351;-1.8744291;1.8472046;2.8115616;CODE
regular case different non trivial clusterings;2.5649;0.63997;-1.3389537;-1.2679566;3.2311332;3.0896244;IRRE
pair confusion matrix;3.2037976;2.0259078;-0.6012434;-4.6553864;2.0943635;-2.5954485;-
d11 2 2 ordered pairs 1 3 5 6;-1.6835523;0.9125229;1.4730899;-5.8593736;3.2742858;-3.592417;CODE
d10 2 4 ordered pairs 1 2 2 3 4 5 4 6;-0.5284353;1.3219801;2.5586364;-6.314687;3.1000285;-3.2432542;CODE
d01 2 1 ordered pair 2 4;-1.3470311;1.6778002;0.8811488;-6.1607866;2.8550053;-2.701265;CODE
d00 5 6 d11 d01 d10 the remaining pairs;0.51900053;1.3395269;0.58697623;-6.0452647;2.4769354;-2.9106026;CODE
rand score;2.3788583;0.10033587;2.0800374;0.57132375;0.26827338;-6.2515264;IRRE
labels1 is constant the mutual info between labels1 and any other labelling is 0;0.066141486;1.8616717;-1.1365596;-2.7796943;1.5326158;0.38856256;CODE
non constant non perfect matching labels;3.6780384;3.1786168;-1.3966731;-2.4145775;2.7726178;-0.59995383;CODE
todo 1 9 remove;-3.8011727;2.5783017;2.8172538;-0.61260426;0.7241015;-2.6205137;TASK
tests the silhouette coefficient;2.9773915;0.6365058;1.5225724;0.391387;-2.7828228;-1.0180498;IRRE
given that the actual labels are used we can assume that s would be positive;1.2904185;1.4804841;0.5001156;-0.4704483;2.0692816;-2.6813736;-
assert silhouette coefficient 0 when there is 1 sample in a cluster;4.0326877;4.558523;-3.4202063;0.99138904;-0.8302105;0.29331747;CODE
cluster 0 we also test the case where there are identical samples;4.3053184;4.0798783;-1.9880177;0.56036955;0.8393461;-2.7244904;IRRE
as the only members of a cluster cluster 2 to our knowledge this case;1.1142582;-2.7681553;0.614247;1.2886071;2.5026205;1.0463692;CODE
is not discussed in reference material and we choose for it a sample;-0.17919639;-2.8257554;0.7874021;3.81792;3.2668428;-0.8569641;CODE
score of 1;-0.57873136;2.2638168;2.7771208;-0.54647917;-0.11413851;-6.5529056;-
cluster 0 1 sample score of 0 by rousseeuw s convention;3.110564;1.1553525;-3.277241;-2.7059426;0.6298072;0.054182157;-
cluster 1 intra cluster 5 5 1;0.4993675;-0.5933855;0.12719542;-2.6569514;1.903749;1.4100909;CODE
inter cluster 1 1 1;0.7649522;-0.5224283;1.3261598;-2.932441;1.868965;0.26582032;CODE
silhouette 5 5 0;-2.534907;-0.93183136;2.271991;-2.1639636;-1.138926;-1.4070326;-
cluster 2 intra cluster 0 0;-0.22155683;1.2435846;-1.7128955;-2.9862833;-1.2322338;1.2092007;CODE
inter cluster arbitrary arbitrary;3.8526146;-0.12666738;0.6557612;-3.9442296;4.608939;2.8252628;CODE
silhouette 1 1;-2.1038857;-1.7459645;3.4136941;-1.6262106;-1.3487632;-0.99577624;-
explicitly check per sample results against rousseeuw 1987;6.2404795;0.72331625;-2.3481138;3.3390613;1.9996842;-3.1614993;IRRE
data from table 1;2.5308628;2.9356172;4.499981;-3.8185334;1.7754087;-4.3914323;CODE
data from figure 2;2.9229844;0.42777637;6.2840147;-4.255364;-3.3243976;-2.2973385;CODE
data from figure 3;2.8507297;-0.6787743;5.9304705;-5.08047;-2.237731;-2.3136978;CODE
we check to 2dp because that s what s in the paper;-2.5100057;-0.60962087;-0.6754914;0.37953535;0.3649836;0.12600638;IRRE
assert 1 n labels n samples;4.6697063;4.052547;-1.9692804;-0.0786252;3.325288;-4.5986533;CODE
n labels n samples;4.17876;-0.17284603;1.9267143;-4.865336;3.8330543;-2.9541843;-
n labels 1;0.78176546;-0.4145126;3.7303975;-6.0971093;4.444251;-4.429178;-
make sure silhouette samples requires diagonal to be zero;1.6595613;2.6796672;-2.6193411;-2.4123158;-2.9744322;2.3709283;CODE
non regression test for 12178;0.97617054;3.903374;-3.371166;2.5558887;-2.8199854;-6.279997;IRRE
construct a zero diagonal matrix;0.5952188;1.3924875;-0.42741808;-6.1558013;-0.012882943;1.0984507;CODE
small values on the diagonal are ok;1.8834684;2.3981605;0.6052626;-5.4980283;-4.432334;-1.3947443;IRRE
values bigger than eps 100 are not;2.2973661;3.8299768;-1.8348831;-4.341278;-4.373701;-1.2909501;IRRE
non regression test for 22107;0.3293674;2.6110578;-4.5607576;2.3789425;-2.4100049;-5.492971;IRRE
only check the number of features if 2d arrays are enforced otherwise;4.0742664;4.135079;-1.8486512;-1.0102202;0.5387201;-1.1463071;CODE
validation is left to the user for custom metrics;0.3322891;2.53728;-2.0295367;3.5735888;-1.9495587;1.0411751;CODE
pairwise distances;3.819307;1.1231358;3.3071086;-5.4049735;0.078791894;-1.0797776;-
to minimize precision issues with float32 we compute the distance;4.4685774;0.553102;-1.240306;-3.3184128;-1.8292114;0.79776204;CODE
matrix on chunks of x and y upcast to float64;3.9337444;1.7327236;-0.79177105;-8.325693;-4.813119;2.5499396;CODE
if dtype is already float64 no need to chunk and upcast;-0.2812209;-1.0978842;-3.2675726;-2.716843;-0.50167227;1.1075238;CODE
ensure that distances between vectors and themselves are set to 0 0;3.002042;2.2617984;-1.076151;-3.6808276;-2.5179827;1.0129589;IRRE
this may not be the case due to floating point rounding errors;2.664406;3.867229;-3.6760728;-2.327695;-6.163007;-1.4696423;CODE
get missing mask for x;-1.6818507;3.069532;0.11737096;-4.2838435;-0.6582032;0.09675671;CODE
get missing mask for y;-0.45846727;2.7540581;0.8514951;-3.7899828;-2.2507844;-0.24752556;CODE
set missing values to zero;1.9330223;6.6343975;0.028972829;-2.5951304;-1.2619885;-2.458782;IRRE
adjust distances for missing values;5.983584;3.893679;1.6144929;-3.4203832;-1.5637574;0.17928375;IRRE
ensure that distances between vectors and themselves are set to 0 0;3.002042;2.2617984;-1.076151;-3.6808276;-2.5179827;1.0129589;IRRE
this may not be the case due to floating point rounding errors;2.664406;3.867229;-3.6760728;-2.327695;-6.163007;-1.4696423;CODE
avoid divide by zero;0.34895852;5.4533916;0.59773654;-3.6587234;-1.9878566;-3.5471234;CODE
allow 10 more memory than x y and the distance matrix take at;4.6177864;1.1499097;0.5202108;-4.8824086;-1.7273576;2.7771034;-
least 10mib;0.08277622;0.8029262;1.5479974;-1.187467;-0.255197;-2.856549;-
the increase amount of memory in 8 byte blocks is;-1.7894459;0.06575627;1.5746719;-1.6150677;0.33513504;1.0640693;-
x density batch size n features copy of chunk of x;4.5574145;-0.7351702;-1.3659067;-3.8928862;0.7798089;3.3622768;TASK
y density batch size n features copy of chunk of y;4.7508545;-1.3671327;-0.87994874;-3.516684;-1.031609;2.8686025;TASK
batch size batch size chunk of distance matrix;5.2228775;0.036900472;0.28962362;-3.6927733;-1.140687;3.3933702;-
hence x xd yd kx m where x batch size k n features m maxmem;4.4234486;-1.0395379;-1.0141039;-4.156633;3.4161923;2.624773;TASK
xd x density and yd y density;-1.0322585;-0.10383203;1.045644;-3.6436672;-1.1034836;0.58538485;-
when x is y the distance matrix is symmetric so we only need;2.09132;0.17377065;0.2950679;-4.5933785;-2.4308732;2.663879;-
to compute half of it;-0.6791413;1.9589887;3.6501515;-3.349891;-0.5877593;-4.9382253;-
start is specified in the signature but not used this is because the higher;-6.4611387;2.3384378;-0.7677501;-0.9974227;1.1576856;0.6438707;CODE
order pairwise distances chunked function needs reduction functions that are;3.7319987;1.2077146;-0.5096649;-2.395948;0.88853973;3.4032521;CODE
passed as argument to have a two arguments signature;-3.514753;3.9989493;0.0022872176;-0.31716236;2.4241781;0.040863864;-
start is specified in the signature but not used this is because the higher;-6.4611387;2.3384378;-0.7677501;-0.9974227;1.1576856;0.6438707;CODE
order pairwise distances chunked function needs reduction functions that are;3.7319987;1.2077146;-0.5096649;-2.395948;0.88853973;3.4032521;CODE
passed as argument to have a two arguments signature;-3.514753;3.9989493;0.0022872176;-0.31716236;2.4241781;0.040863864;-
if sp base version parse version 1 17 pragma no cover;-4.512085;1.7432877;-2.7309327;1.9956177;2.187092;-1.3324171;META
deprecated in scipy 1 15 and removed in scipy 1 17;-2.458454;-3.4493773;-6.26776;-1.6260276;-5.346883;-2.2577693;OUTD
if sp base version parse version 1 11 pragma no cover;-4.5089583;1.5377903;-3.1018414;2.1933272;2.477872;-0.944568;META
deprecated in scipy 1 9 and removed in scipy 1 11;-2.520132;-3.4337127;-6.5122194;-1.5159146;-4.785934;-2.353669;OUTD
deprecated in scipy 1 0 and removed in scipy 1 9;-2.3380766;-2.812114;-6.8748617;-2.0440319;-5.2191343;-2.695229;OUTD
prefer skip nested validation false metric is not validated yet;1.1553506;4.5664725;-5.399117;4.0061145;-0.17553315;1.3955313;TASK
this is an adaptor for one sqeuclidean specification;-3.9032102;0.07904432;0.077773295;-3.3808162;1.2794942;1.7087514;CODE
for this backend we can directly use sqeuclidean;-6.319354;-2.600259;1.286426;-0.22267786;-0.4435027;0.7441628;CODE
joblib based backend which is used when user defined callable;-4.2574105;-2.0687234;-1.4234246;2.4738839;-1.2140088;1.999684;CODE
are passed for metric;2.080099;1.0702726;-0.87834793;0.7389316;0.7541588;-0.4445842;CODE
this won t be used in the future once pairwisedistancesreductions support;2.1273875;0.684168;-3.7282515;0.7667973;-0.0635403;5.152021;CODE
distancemetrics which work on supposedly binary data;4.82508;-1.1211932;-0.49674195;-3.481206;1.1848285;-1.0303714;-
csr dense and dense csr case if euclidean in metric;1.1343883;1.4339437;-1.8185651;-2.1851861;-0.21975683;1.2969888;CODE
turn off check for finiteness because this is costly and because arrays;1.4758662;6.427446;-3.0165083;1.2736821;-1.7897329;-1.777552;IRRE
have already been validated;-3.0400345;2.4132845;-1.7239617;4.4336133;2.487819;-2.6496208;CODE
prefer skip nested validation false metric is not validated yet;1.1553506;4.5664725;-5.399117;4.0061145;-0.17553315;1.3955313;TASK
this is an adaptor for one sqeuclidean specification;-3.9032102;0.07904432;0.077773295;-3.3808162;1.2794942;1.7087514;CODE
for this backend we can directly use sqeuclidean;-6.319354;-2.600259;1.286426;-0.22267786;-0.4435027;0.7441628;CODE
joblib based backend which is used when user defined callable;-4.2574105;-2.0687234;-1.4234246;2.4738839;-1.2140088;1.999684;CODE
are passed for metric;2.080099;1.0702726;-0.87834793;0.7389316;0.7541588;-0.4445842;CODE
this won t be used in the future once pairwisedistancesreductions support;2.1273875;0.684168;-3.7282515;0.7667973;-0.0635403;5.152021;CODE
distancemetrics which work on supposedly binary data;4.82508;-1.1211932;-0.49674195;-3.481206;1.1848285;-1.0303714;-
csr dense and dense csr case if euclidean in metric;1.1343884;1.433944;-1.8185648;-2.1851866;-0.21975681;1.2969874;CODE
turn off check for finiteness because this is costly and because arrays;1.4758662;6.427446;-3.0165083;1.2736821;-1.7897329;-1.777552;IRRE
have already been validated;-3.0400345;2.4132845;-1.7239617;4.4336133;2.487819;-2.6496208;CODE
this returns a np ndarray generator whose arrays we need;1.8281014;-1.1538411;-2.1809478;-4.8753486;-1.5271609;-1.3053294;CODE
to flatten into one;0.037980314;0.30457273;4.5938168;-2.6608756;1.0701132;0.85582703;CODE
x sum duplicates this also sorts indices in place;1.5676477;2.6925027;0.2509792;-4.390444;-1.1166757;-1.6948224;IRRE
array api support;-1.2046576;-0.6906439;0.20753631;0.13437688;0.36315432;0.28347576;CODE
1 0 cosine similarity x y without copy;2.397228;1.8688402;0.9974923;-4.9006763;-3.755432;0.35332042;-
ensure that distances between vectors and themselves are set to 0 0;3.002042;2.2617984;-1.076151;-3.6808276;-2.5179827;1.0129589;IRRE
this may not be the case due to floating point rounding errors;2.664406;3.867229;-3.6760728;-2.327695;-6.163007;-1.4696423;CODE
paired distances;3.9960759;0.7542687;4.4193907;-3.8934755;0.38160247;-0.08752905;-
check the matrix first it is usually done by the metric;3.0543332;2.0901067;-1.4136268;-3.421911;-3.2596042;-0.09350066;CODE
kernels;1.2187121;-5.4096274;2.7301493;-0.50641847;1.279747;-0.18999429;-
compute tanh in place for numpy;1.7931925;0.22784732;0.04023736;-6.5021787;-7.0315037;-1.9953889;CODE
exponentiate k in place when using numpy;2.4811046;-1.7294216;-2.074269;-6.794165;-5.84233;0.3116598;-
np exp k k exponentiate k in place;1.131023;-1.3707523;-2.0235453;-4.15179;-0.5311507;0.6399031;-
helper functions distance;1.0724655;0.7693163;3.2037723;-1.186386;-0.8799213;0.37709385;CODE
if updating this dictionary update the doc in both distance metrics;0.25362659;-1.3132362;-1.7654599;0.7300952;-0.7768679;2.0799465;CODE
and also in pairwise distances;3.0459626;-0.19383924;2.6728592;-3.8487494;2.3746912;0.1049978;-
precomputed none hack precomputed is always allowed never called;-3.7329848;1.9075103;-1.5585932;4.157967;0.20102045;0.35901278;IRRE
no input dimension checking done for custom metrics left to user;1.5446403;2.3312995;-3.0803196;-0.43425864;-1.4711173;0.7640892;CODE
todo below 2 lines can be removed once min scipy 1 14 support for;-2.4474442;-0.97751135;-3.053003;-3.412539;-3.7721133;-1.4671375;CODE
1d shapes in scipy sparse arrays coo dok and csr formats only;4.2337856;-1.8263044;-5.1185102;-6.944242;-4.2214537;0.86581135;CODE
added in 1 14 we must return 2d array until min scipy 1 14;2.6325364;0.9230717;-2.6363924;-6.530403;-5.375304;-3.8336496;TASK
when metric is a callable 1d input arrays allowed in which case;3.826413;2.36033;-1.3200506;-1.6784873;0.8131829;0.7185548;CODE
scalar should be returned;-0.2793079;3.249387;-1.8083647;-0.07515423;-3.0679662;-1.3617193;IRRE
only calculate metric for upper triangle;1.5237615;1.7853477;1.653534;-2.876722;-1.8774344;-0.24768429;CODE
make symmetric;-0.66407406;0.76360613;2.3464735;-3.2719352;2.103361;-1.8893222;-
nb out out t will produce incorrect results;1.2746657;3.7368042;-3.5272412;0.064840876;-2.0278943;-3.591352;IRRE
calculate diagonal;-0.4420082;0.77720875;3.2739537;-5.8975034;-0.78482306;-2.0035377;-
nb nonzero diagonals are allowed for both metrics and kernels;1.0213325;-1.4095211;-4.5586653;-3.1922503;0.23472741;4.6179852;CODE
calculate all cells;2.9248054;2.879292;3.1813424;-4.724683;-0.2362319;-3.3911839;-
prefer skip nested validation false metric is not validated yet;1.1553506;4.5664725;-5.399117;4.0061145;-0.17553315;1.3955313;TASK
we get as many rows as possible within our working memory budget to;3.4449298;-1.0692037;3.4573305;0.40103447;1.0202174;-0.5906763;-
store len y distances in each row of output;5.480075;0.24048202;3.8369555;-7.101217;-2.329915;-0.5160083;IRRE
note;-3.3711183;-3.1659377;3.2370715;0.61941224;-1.1384028;-2.1694984;TASK
this will get at least 1 row even if 1 row of distances will;4.5991573;3.026704;3.4163883;-3.8780203;1.0567623;-1.2170466;CODE
exceed working memory;-0.7801094;-0.3028627;1.5619897;2.2750046;-1.0753103;-0.6815643;-
this does not account for any temporary memory usage while;-3.872108;1.4031646;-0.24442416;2.4470758;-1.2036922;0.8115406;CODE
calculating distances e g difference of vectors in manhattan;4.21612;-0.1483858;1.5723317;-5.9854755;-1.5698848;-1.0629392;-
distance;1.4023498;-0.3891127;7.0120068;-1.8333019;-0.94189316;-3.102107;-
precompute data derived metric params;5.590687;-3.516649;-1.3857903;-0.19341326;0.28537488;0.9714727;-
x chunk x enable optimised paths for x is y;-0.048952255;0.7034649;-2.0113769;-1.1549599;0.30009827;2.7770867;CODE
zeroing diagonal taking care of aliases of euclidean;0.8484122;2.2276633;-1.0608044;-4.909102;-1.6689533;2.3533568;CODE
i e l2;-1.94075;-0.69193286;3.3381298;-1.088794;0.07303233;-0.3367622;-
precompute data derived metric params;5.590687;-3.516649;-1.3857903;-0.19341326;0.28537488;0.9714727;-
these distances require boolean arrays when using scipy spatial distance;3.3076186;0.62263834;-4.1250134;-4.0005784;-3.916923;-2.9845061;CODE
deprecated in scipy 1 15 and removed in scipy 1 17;-2.458454;-3.4493773;-6.26776;-1.6260276;-5.346883;-2.2577693;OUTD
deprecated in scipy 1 9 and removed in scipy 1 11;-2.520132;-3.4337127;-6.5122194;-1.5159146;-4.785934;-2.353669;OUTD
deprecated in scipy 1 0 and removed in scipy 1 9;-2.3380766;-2.812114;-6.8748617;-2.0440319;-5.2191343;-2.695229;OUTD
helper functions distance;1.0724655;0.7693163;3.2037723;-1.186386;-0.8799213;0.37709385;CODE
if updating this dictionary update the doc in both distance metrics;0.25362659;-1.3132362;-1.7654599;0.7300952;-0.7768679;2.0799465;CODE
and also in pairwise distances;3.0459626;-0.19383924;2.6728592;-3.8487494;2.3746912;0.1049978;-
import gpkernel locally to prevent circular imports;-3.006086;-1.7815099;-2.83938;0.60713655;-2.33445;4.2631884;CODE
utilities for testing;-0.12664372;-2.0595217;0.09941908;5.2427063;0.12561277;-6.0257063;IRRE
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
restrict to a binary classification task;2.4954395;-1.2153791;-0.009427256;3.0182338;4.629471;-0.30802155;TASK
add noisy features to make the problem harder and avoid perfect results;5.8624406;-0.40308812;0.54360384;3.5235572;1.4295573;0.58413005;TASK
run classifier get class probabilities and label predictions;2.9337661;-4.1194158;-1.1204755;2.326365;1.9875882;-1.8970088;CODE
only interested in probabilities of the positive case;-0.7847116;0.6898156;2.8522158;0.36872435;2.0541356;-2.9937763;CODE
xxx do we really want a special api for the binary case;-3.9192255;-2.5079882;-2.0959933;-0.58679897;4.8200293;-1.3909414;CODE
tests;0.88049054;1.2949181;4.1925097;6.4629726;0.08019503;-9.306;IRRE
test performance report with dictionary output;3.537073;0.94297016;-1.9092795;3.6677585;0.29190972;-4.788627;IRRE
print classification report with class names;1.2430348;-3.9380457;-1.4390162;-0.7000598;4.1264377;-1.7785796;CODE
assert the 2 dicts are equal;-0.1549434;5.292775;-1.9069358;0.7377413;1.2747159;-4.055666;CODE
assert the 2 dicts are equal;-0.15494421;5.2927747;-1.9069364;0.73774236;1.2747154;-4.0556655;CODE
we need always instead of once for free threaded with;-3.0345738;0.4213203;-0.24862537;3.9016662;0.7585313;4.6963487;CODE
pytest run parallel to capture all the warnings in the;-0.20773731;1.006466;-2.488095;3.058241;-3.059969;-0.16786264;CODE
zero division warn case;-2.0878444;4.3936243;-1.7679859;-0.596972;0.83899254;-3.6640785;CODE
else accuracy should be shown;1.7825744;3.7455578;0.3329485;2.63826;-1.3317981;-3.386557;-
dense label indicator matrix format;4.6611395;-1.4618393;-1.0155562;-6.927385;1.8752182;1.5938876;CODE
test precision recall and f1 score for binary classification task;3.351971;-1.9801998;-2.439925;3.1736596;2.7689195;-4.6995635;IRRE
detailed measures for each class;4.842835;-3.865858;2.21823;1.9225596;5.2704678;-0.9712758;CODE
individual scoring function that can be used for grid search in the;5.803594;-0.2877429;1.5314442;-1.0585986;2.3968096;-1.5479784;CODE
binary class case the score is the value of the measure for the positive;2.180301;1.0427506;-0.9934504;-1.3181516;4.8265347;-4.115439;IRRE
class e g label 1 this is deprecated for average binary;-0.052703086;-0.926469;-3.7239707;-2.2294722;2.6694577;-2.4244416;CODE
test precision recall and f scores behave with a single positive or;2.510177;2.5227134;-3.4123266;3.7467647;1.6172042;-4.157752;IRRE
negative class;-0.64677244;0.21782897;0.5897904;0.24254104;2.4993932;-2.3422;IRRE
such a case may occur with non stratified cross validation;0.18316126;4.392223;-3.3455262;3.5528412;3.2864325;-0.8053986;CODE
test handling of explicit additional not in input labels to prf;1.1231142;4.5340824;-3.5409498;2.8411849;2.6607795;-3.263177;TASK
no average zeros in array;3.164374;4.5550265;-0.5108127;-4.4179454;-4.8658385;-2.970355;-
macro average is changed;1.3709271;2.2954328;0.2041437;-0.5034382;-2.9878085;0.74145687;CODE
no effect otherwise;-4.051559;0.48434845;3.381996;1.9098879;-2.3756301;0.16866665;-
error when introducing invalid label in multilabel case;-1.7275162;3.0935323;-3.530535;-0.7347848;2.8170602;-0.32199585;CODE
although it would only affect performance if average macro none;2.4686198;2.9169216;-0.52270937;2.9111285;1.5105925;2.0119715;CODE
tests non regression on issue 10307;-1.1222085;3.7166889;-5.5536375;3.4331636;-4.5456457;-4.4581747;IRRE
test a subset of labels may be requested for prf;3.3226547;3.2142265;-2.1084275;3.4731212;4.49858;-2.6256855;IRRE
ensure the above were meaningful tests;0.50167876;2.728461;-1.0155343;6.5440674;-0.040332224;-6.215492;IRRE
when fp 0 and tp 0 lr is undefined;-4.097068;3.4801164;-2.282838;-1.7394763;-2.1368797;-1.0159161;CODE
when fp 0 and tp 0 lr is undefined;-4.097068;3.4801164;-2.282838;-1.7394763;-2.1368797;-1.0159161;CODE
when tn 0 lr is undefined;-3.0044749;3.5327847;-3.1768854;-2.6724038;-2.0145895;-2.146852;CODE
when tp fn 0 both ratios are undefined;-1.285156;4.3179073;-2.5470545;-3.5531955;-2.4570787;-1.547126;CODE
likelihood ratios must raise warnings when at;1.0862947;3.214707;-3.98181;3.450558;-2.475873;1.4264888;CODE
least one of the ratios is ill defined;1.4787498;4.9100943;-1.826998;-2.3633726;-0.8052729;-3.0203757;CODE
likelihood ratios must raise error when attempting;1.7520568;4.6711755;-4.6086636;2.7517014;-3.373109;0.9986622;CODE
non binary classes to avoid simpson s paradox;2.7945826;0.07819722;-3.1323674;-0.23559952;3.2872157;-1.9237939;CODE
build confusion matrix with tn 9 fp 8 fn 1 tp 2;2.1493132;0.6722031;-2.820359;-4.5433264;0.8015113;-0.051887706;-
sensitivity 2 3 specificity 9 17 prevalence 3 20;-0.57506233;1.4530948;-2.6176336;0.6182929;0.79536694;-1.0306122;-
lr 34 24 lr 17 27;-2.3079648;0.9878371;3.0230532;-3.571694;0.6806626;-4.059386;-
build limit case with y pred y true;-1.0282578;3.6387756;0.18709847;1.8889816;1.4168158;-1.3246182;CODE
ignore last 5 samples to get tn 9 fp 3 fn 1 tp 2;3.875439;4.1293044;-1.2648484;-1.1107284;1.2559335;-2.6554961;-
sensitivity 2 3 specificity 9 12 prevalence 3 20;-0.24036862;1.1354359;-2.5798445;0.7226692;1.1961684;-1.0564296;-
lr 24 9 lr 12 27;-2.375114;0.7227492;3.1904075;-3.7212825;1.2194241;-4.671042;-
todo 1 9 remove test;-2.324636;5.831067;-0.6011175;3.3548503;-0.39841035;-5.810658;TASK
this data causes fp 0 0 false positives in the confusion matrix and a division;3.011791;3.8221724;-3.9056456;-2.8314557;-1.9236084;-4.369205;CODE
by zero that affects the positive likelihood ratio;1.5137607;3.5705197;-1.9154986;0.37688428;-2.5798051;1.6508847;-
this data causes tn 0 0 true negatives in the confusion matrix and a division;3.2030027;3.232021;-3.443708;-4.141714;-2.2550123;-3.6327643;CODE
by zero that affects the negative likelihood ratio;1.4828206;3.8734336;-1.631017;0.4474511;-2.7433074;1.9248321;-
this data causes fp 0 0 false positives in the confusion matrix and a division;3.011791;3.8221724;-3.9056456;-2.8314557;-1.9236084;-4.369205;CODE
by zero that affects the positive likelihood ratio;1.5137607;3.5705197;-1.9154986;0.37688428;-2.5798051;1.6508847;-
this data causes tn 0 0 true negatives in the confusion matrix and a division;3.2030027;3.232021;-3.443708;-4.141714;-2.2550123;-3.6327643;CODE
by zero that affects the negative likelihood ratio;1.4828206;3.8734336;-1.631017;0.4474511;-2.7433074;1.9248321;-
these label vectors reproduce the contingency matrix from artstein and;2.0624955;-1.4784713;-0.4391206;-2.3319597;1.9874991;0.9240736;CODE
poesio 2008 table 1 np array 20 20 10 50;1.5016575;2.0688074;-1.1156341;-6.149092;0.41236207;-2.7770283;-
add spurious labels and ignore them;1.4362295;2.3792038;-0.28066432;1.6397425;2.252717;0.6430765;TASK
multiclass example artstein and poesio table 4;-1.2066483;-2.8951876;-0.72612;-0.45816368;4.862893;-0.1405486;IRRE
weighting example none linear quadratic;2.9848478;1.6559412;-0.65752584;-3.889821;-1.4713333;1.5241612;-
this should not raise an error;-5.004735;5.2315326;-2.3678343;4.176829;-1.6402361;-1.6716458;CODE
test for inconsistency between multiclass problem and pred decision;2.5021126;3.2162936;-3.5380905;5.2534766;4.15629;-2.5028741;IRRE
argument;-2.922641;0.6521082;4.6576743;2.8854768;0.15559238;-4.0643554;-
test for inconsistency between pred decision shape and labels number;4.4572515;3.1717913;-2.5052135;0.57379144;3.101364;-3.232325;IRRE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 17630;-3.598533;-9.944066;-5.1705494;-0.41243085;-5.1848764;-5.3140635;CODE
check that we can compute the hinge loss when providing an array;2.3237667;3.8625548;-0.72179973;-0.5759971;-1.5511383;0.45625556;-
with labels allowing to not have all labels in y true;1.5222089;3.105255;1.0671884;-0.970712;2.885559;-0.6278115;-
currently invariance of string and integer labels cannot be tested;1.0568107;4.195049;-5.0464935;-0.34273386;0.73545593;-2.0715632;CODE
in common invariance tests because invariance tests for multiclass;2.8998055;0.6129339;-3.4292374;3.980949;2.2752898;0.018764034;CODE
decision functions is not implemented yet;-2.8608377;-2.2193298;-1.0519143;2.74282;-0.20360291;-0.034821793;TASK
binary case with symbolic labels no yes;-1.1828847;2.7975886;-2.293866;-3.5678968;5.910326;-3.2107735;CODE
multiclass case adapted from http bit ly rjjhwa;-1.238675;-1.5280222;-2.1090276;0.9339675;5.971674;2.7703047;CODE
check that we got all the shapes and axes right;-0.08503166;0.85682905;4.783305;-4.369265;-3.3347151;-1.2621022;-
by doubling the length of y true and y pred;1.124947;2.6033404;2.3679843;-3.2639089;-1.5501145;-1.8932377;CODE
raise error if number of classes are not equal;3.1160696;5.3165975;-3.1256526;2.8445535;3.991163;-4.2777696;CODE
raise error if labels do not contain all values of y true;2.718592;6.3957944;-1.7376789;0.22393046;-0.029912736;-3.5646489;IRRE
case when y true is a string array object;0.28377354;4.696693;0.46728316;0.33686274;1.2161417;-4.2733226;CODE
test labels option;0.79655886;1.8515933;0.8648791;2.1305337;2.4545393;-3.0622847;IRRE
works when the labels argument is used;-3.1957643;2.6550217;-0.93982;1.1128743;0.2546883;0.04814489;-
ensure labels work when len np unique y true y pred shape 1;3.6105096;2.695273;-2.4006126;-3.287806;2.3689308;-0.5761756;-
because of the clipping the result is not exactly 0;-0.6459795;4.971817;-1.151366;-3.0173025;-5.315477;-1.2823715;TASK
case when input is a pandas series and dataframe gh 5715;0.9053373;1.4845289;-1.9870464;-2.0934134;-2.4526818;-3.0129242;CODE
y pred dataframe y true series;1.9558873;1.8213068;0.9134075;-2.1517582;-5.024221;-2.9656425;-
check brier score loss function;1.0279;3.1862552;-1.6237015;0.59269387;-1.0509303;-3.1894798;CODE
check that using n samples 2 y prob or y true gives the same score;4.8212957;4.762607;-2.8364131;0.18559179;0.13425079;-5.8211217;-
check scale by half argument;3.3047845;6.6288;0.65437335;-1.5726223;-3.0797682;-2.186529;-
calculate correctly when there s only one class in y true;3.0902896;3.6204627;0.14185001;-0.4289134;3.0353332;-4.4247046;IRRE
test cases for multi class;2.3496718;2.342081;-0.10260234;3.4924598;6.0276666;-4.962265;CODE
check perfect predictions for 3 classes;4.9895773;1.1134032;-0.18335205;4.028914;3.0666845;-4.4410906;CODE
check perfectly incorrect predictions for 3 classes;4.256402;2.2822735;-2.5935452;4.6797986;1.6763042;-4.231122;CODE
binary case;-0.87552834;2.0601687;1.2152932;-4.2926917;6.3116117;-6.347424;CODE
bad length of y prob;-1.5463283;2.6672015;0.3830036;-2.0993085;-5.866227;-2.4317284;-
y pred has value greater than 1;-0.93145704;4.6879554;-0.04732556;-2.6579978;-1.8651918;-4.948063;IRRE
y pred has value less than 0;-1.0378885;5.349276;-1.1073381;-3.224909;-3.9154675;-4.3785105;IRRE
multiclass case;-0.5991156;-1.3194052;0.30118492;0.5482351;7.7955008;0.32770672;CODE
bad length of y pred;-1.5020969;3.1944396;-0.52085125;-1.2775036;-4.463743;-1.1019412;-
y pred has value greater than 1;-0.93145704;4.6879554;-0.04732556;-2.6579978;-1.8651918;-4.948063;IRRE
y pred has value less than 0;-1.0378885;5.349276;-1.1073381;-3.224909;-3.9154675;-4.3785105;IRRE
raise an error for multiclass y true and binary y prob;0.15104789;3.16995;-5.9612226;0.54790014;1.9079423;-2.3823438;CODE
raise an error for wrong number of classes;0.78529596;3.3023582;-3.4132483;3.5803218;2.5207539;-3.2659297;CODE
raise error message when there s only one class in y true;-0.5344736;4.675691;-1.9369472;3.4308467;1.7062058;-1.9279593;CODE
error is fixed when labels is specified;-2.4938138;3.8670895;-3.9224424;-0.6480108;0.11731778;-0.23981409;-
warnings are tested in test balanced accuracy score unseen;2.2940292;2.780092;-6.4623146;5.8984456;-1.0477995;-4.5535874;IRRE
brier score loss requires probabilities;1.2855287;1.0956495;-0.5041124;2.9794345;1.204512;-0.0873216;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
check that using sample weight also gives the correct d2 score;3.2511182;3.7004125;-3.9264958;1.4067594;0.1541829;-2.3663993;-
check if good predictions give a relatively higher value for the d2 score;5.105109;2.2142222;-0.35623416;3.9525228;-0.554461;-3.461504;IRRE
check that a similar value is obtained for string labels;2.9149644;4.3957057;-0.14909744;-0.5735845;3.4880834;-4.352611;CODE
check if poor predictions gives a relatively low value for the d2 score;4.739341;3.051716;-2.288726;3.997384;-1.7422733;-3.3022342;IRRE
check that a similar value is obtained for string labels;2.9149644;4.3957057;-0.14909744;-0.5735845;3.4880834;-4.352611;CODE
check if simply using the average of the classes as the predictions;6.8812447;0.6541912;-0.18193105;5.1199956;0.79437685;-2.4767618;IRRE
gives a d2 score of 0;-0.052732904;2.5165026;-0.78190523;-0.94063586;-1.3817865;-4.392489;-
check if simply using the average of the classes as the predictions;6.8812447;0.6541912;-0.18193105;5.1199956;0.79437685;-2.4767618;IRRE
gives a d2 score of 0 when the positive class has a higher proportion;2.0688093;2.6737506;-2.4780397;-1.2938634;1.7511849;-2.5386846;IRRE
check that the d2 scores seem correct when more than 2;2.2395444;3.8711917;-1.2498417;1.264612;0.42482322;-6.0557265;-
labels are specified;-2.5608282;0.18848895;0.042949267;-3.0899057;3.8440192;-0.056921527;-
null model consists of weighted average of the classes;3.68695;1.1329963;-1.4445331;1.1383979;1.3646376;1.9025036;IRRE
given that the sum of the weights is 3;1.8214248;1.9389533;2.3440502;-2.6285343;1.2156997;-0.96379775;-
weighted average of 0s is 0 6 0 3 3 0 3;1.6878453;2.7246554;0.077096395;-5.0511956;-1.6397929;-1.9805957;-
weighted average of 1s is 0;2.3227236;3.4360063;0.61728024;-2.5871441;-3.2732708;-0.54173243;-
weighted average of 2s is 1 4 0 7 3 0 7;2.5451615;2.3150995;1.3113062;-3.708439;-2.082971;-1.4569727;-
check when labels are provided and some labels may not be present inside;-1.1497306;3.4566884;-0.28300685;1.585478;2.4710653;-1.6408788;-
y true the d2 score is 0 when we use the label proportions based on;1.9110211;2.4217947;-1.4842811;-1.0352705;-0.2587774;-2.3095937;IRRE
y true as the predictions;1.3670096;-0.7400477;2.8662763;2.886528;-2.5950868;-2.1516943;-
also confirm that the order of the labels does not affect the d2 score;1.1398358;0.4119875;-0.5526241;0.6885763;3.070362;-0.7652248;CODE
check that a simple model with wrong predictions gives a negative d2 score;2.4757643;3.5247524;-2.8351984;3.9629889;-2.7513483;-3.3514066;META
binary case;-0.87552834;2.0601687;1.2152932;-4.2926917;6.3116117;-6.347424;CODE
brier score loss and d2 brier score require specifying the;-0.9086305;2.385772;-1.3611541;0.5474835;2.5780962;-1.1601876;CODE
pos label;-1.3955425;-1.5300236;3.2075188;-0.77958757;2.1525743;-1.7422897;-
multi class case;0.13904852;-0.8371299;1.3895577;0.44663343;8.206068;-0.81335914;CODE
note toward developers about metric testing;1.9056772;-3.2477658;-0.54975754;6.1558423;-1.6699975;-4.643253;TASK
it is often possible to write one general test for several metrics;4.3623476;0.5545025;0.0701746;4.20538;1.4253414;-2.0633588;CODE
invariance properties e g invariance to sample order;1.3979459;0.7145713;0.8316594;0.45477676;1.6233842;3.7738204;CODE
common behavior for an argument e g the normalize with value true;0.7137005;3.833863;-0.024212306;1.3416114;-0.76477057;0.39542145;IRRE
will return the mean of the metrics and with value false will return;2.4525757;4.404082;-0.23191532;1.0780243;-2.6789868;-2.055339;IRRE
the sum of the metrics;1.4835284;-0.4599738;2.7672994;-2.2928917;-0.6836486;-0.28474832;-
in order to improve the overall metric testing it is a good idea to write;2.4939072;-0.804999;0.114349656;5.801078;0.5285501;-2.4921062;TASK
first a specific test for the given metric and then add a general test for;3.3462718;2.825173;0.5675179;2.621757;0.5168443;-1.8504236;IRRE
all metrics that have the same behavior;3.5384195;0.564001;0.22162741;1.7814018;-0.10745772;1.7388037;-
two types of datastructures are used in order to implement this system;1.6926873;-1.098715;1.9526399;-3.0524268;6.9739294;1.5872916;CODE
dictionaries of metrics and lists of metrics with common properties;3.4550674;-3.6873748;-0.15566221;-1.4578243;2.4920824;1.1689587;-
dictionaries of metrics;3.3530006;-4.05332;0.5614094;-2.404708;1.378336;0.88952136;-
the goal of having those dictionaries is to have an easy way to call a;-2.6571717;-4.1264477;0.4834665;0.5634354;2.4204614;-0.2640202;IRRE
particular metric and associate a name to each function;3.180792;-0.90328443;1.2617882;-1.550495;2.6801589;2.7681396;CODE
regression metrics all regression metrics;2.5009248;-2.606282;0.23525655;0.91507417;-1.7777767;1.3861046;-
classification metrics all classification metrics;3.466176;-5.662552;-0.48021874;0.5560073;2.850029;0.9547347;IRRE
which compare a ground truth and the estimated targets as returned by a;4.3801155;1.8061335;0.8328237;4.7929616;-0.15268077;-1.0082847;IRRE
classifier;5.374577;-5.4938245;2.4601524;1.5816483;5.5953484;-3.0490227;IRRE
continuous classification metrics all classification metrics which;3.2647092;-4.926391;0.52618396;0.59372467;2.8624432;1.6782695;IRRE
compare a ground truth and a continuous score e g estimated;4.7483945;2.845177;0.34185666;4.590958;0.7873152;-1.6104013;IRRE
probabilities or decision function format might vary;1.5500255;-0.92716366;-0.86650795;0.6909683;1.8360574;-2.4231606;CODE
those dictionaries will be used to test systematically some invariance;2.3509011;-2.9012403;-2.0760357;2.7367997;1.8583791;-2.129802;IRRE
properties e g invariance toward several input layout;2.0092328;-1.3297942;2.5911045;-0.68503314;2.8419378;5.283317;CODE
confusion matrix returns absolute values and hence behaves unnormalized;4.2859;3.8010154;-4.1377563;-3.4878175;-2.7019384;0.9370159;IRRE
naming it with an unnormalized prefix is necessary for this module to;-4.764544;-0.2291624;-3.3355212;-1.0757486;3.485893;2.7034376;CODE
skip sample weight scaling checks which will fail for unnormalized;5.301363;3.5828764;-4.3519;2.1712952;-1.9633214;3.5051672;CODE
metrics;3.7460873;-2.4628732;4.808624;0.18980567;0.3642099;-1.9201218;-
these are needed to test averaging;3.8681922;2.6422725;1.9322773;3.010335;-0.6389423;-3.2530131;IRRE
roc auc score roc auc score default average macro;2.2738147;-0.61136645;-2.6370523;-0.79955983;0.5592577;-0.16860832;CODE
average precision score average precision score default average macro;3.4657242;0.6199382;-2.0559123;-0.2745291;-0.80337685;-1.4411501;CODE
lists of metrics with common properties;3.4819753;-1.6595917;1.3754863;-1.0582591;2.5868347;0.4534473;-
lists of metrics with common properties are used to test systematically some;5.3504972;-1.6874546;-0.36344105;3.134564;2.075194;-1.8465441;IRRE
functionalities and invariance e g symmetric metrics lists all metrics that;0.26285538;-3.2583544;0.04567396;0.052972857;1.2948717;2.930853;CODE
are symmetric with respect to their input argument y true and y pred;-1.294988;1.648308;-0.6683672;-1.2974132;0.7814789;-1.254434;CODE
when you add a new metric or functionality check if a general test;0.06005853;1.1455007;-1.4966761;6.671947;0.3687276;-2.3759065;IRRE
is already written;-4.7993693;-2.032493;3.389242;2.7387958;0.96483606;-2.5455196;CODE
those metrics don t support binary inputs;2.4038162;-0.9583397;-4.563239;-2.2187428;0.15473184;-1.317014;CODE
those metrics don t support multiclass inputs;2.850827;-2.7892432;-4.687254;0.56011397;1.6785555;1.2652304;CODE
with default average binary multiclass is prohibited;0.2878626;0.2939499;-5.334149;-0.2841379;3.0725658;0.41835973;CODE
curves;0.99191177;-1.5341109;6.932674;-3.3817167;-3.4643686;-1.7690781;-
metric undefined with binary or multiclass input;0.52442557;-0.12227728;-5.513765;-2.5168786;0.24349886;-2.1100733;CODE
metrics with an average argument;4.1797;0.40108597;2.2503893;0.9065741;-0.68121445;1.1639138;-
threshold based metrics with an average argument;5.791811;-0.11278986;0.5916372;1.2339294;0.6221716;1.8513194;-
metrics with a pos label argument;2.130932;-0.13404053;-0.6388515;-0.98532915;1.3994186;1.4963522;-
metrics with a labels argument;3.3667848;-0.23849107;0.71458554;-1.2738765;1.6604967;1.018704;-
todo handle multi class metrics that has a labels argument as well as a;1.6296858;-0.06088339;-1.2462469;2.251352;3.9339707;2.439003;CODE
decision function argument e g hinge loss;0.4356556;-0.020550614;0.701972;2.0674143;1.3705966;1.6498787;CODE
metrics with a normalize option;4.86742;-0.38441378;0.56972456;-2.1662972;-0.07177887;4.924837;-
threshold based metrics with multilabel indicator format support;4.819283;-1.5179772;0.075151645;-1.8229083;3.5652826;1.4329052;CODE
classification metrics with multilabel indicator format;3.7385876;-3.2951686;0.22675467;-2.3088183;4.579092;0.84144515;CODE
regression metrics with multioutput continuous format support;6.096657;-3.7519248;-0.39890712;0.84810835;-0.7287565;1.6032467;IRRE
symmetric with respect to their input arguments y true and y pred;-0.795821;1.8200513;-0.39626545;-2.4427662;1.7840918;-1.3835815;CODE
metric y true y pred metric y pred y true;0.8160904;1.3622661;1.3226486;0.4379578;-0.8601578;-0.37896892;-
p r f accuracy in multiclass case;3.5754092;-0.07217712;-4.2690773;2.148521;2.4403865;0.7613673;CODE
pinball loss is only symmetric for alpha 0 5 which is the default;-1.2755992;1.6079774;-1.7901238;-0.69698024;-2.7216265;0.6247675;CODE
asymmetric with respect to their input arguments y true and y pred;0.86627746;2.9319592;0.3963793;-2.0230098;-0.31975088;-0.61330384;CODE
metric y true y pred metric y pred y true;0.8160904;1.3622661;1.3226486;0.4379578;-0.8601578;-0.37896892;-
no sample weight support;1.0501064;1.291125;-1.7082548;1.4939358;-1.1116978;0.57557404;-
metrics involving y log 1 x;1.065662;-0.6050576;0.7230051;-1.4320725;-2.034668;1.0700041;-
we shouldn t forget any metrics;2.7636826;-1.5649488;0.62495035;2.4840012;-0.42517564;1.5252763;CODE
test the symmetry of score and loss functions;4.4742417;2.5653617;-0.26950514;2.746493;0.35561472;-1.8527014;CODE
test the symmetry of score and loss functions;4.4742417;2.5653617;-0.26950514;2.746493;0.35561472;-1.8527014;CODE
the metric can be accidentally symmetric on a random draw;1.8609762;0.4483167;0.211575;-0.44277254;-1.6028342;1.9985278;IRRE
we run several random draws to check that at least of them;1.8050437;2.6542325;2.3419192;4.453599;1.0809293;-3.4439282;IRRE
gives an asymmetric result;-1.0495648;4.5527425;2.6353781;-3.678454;-2.991802;-2.963862;IRRE
check test symmetric metric and test not symmetric metric;0.9403137;4.3560624;-2.7640996;-0.050238248;-1.2127782;-3.1068506;IRRE
test symmetric metric passes on a symmetric metric;-0.01367416;2.2232623;-1.4530412;0.432721;-0.22542635;-0.76380765;IRRE
but fails on a not symmetric metric;-0.6934162;2.8198426;-3.5241504;-0.62260383;-2.040332;0.6092361;META
test not symmetric metric passes on a not symmetric metric;0.4939062;3.7747023;-2.7290976;0.4709307;-1.136054;-1.5538038;IRRE
but fails on a symmetric metric;-0.71902347;2.4063787;-2.8643043;-0.7673577;-1.6060003;0.8938602;META
generate some data;4.357832;-0.6496195;4.4381747;-2.5545719;2.4259079;-4.16194;-
some metrics e g log loss require y score to be probabilities sum to 1;2.8533661;-0.8429415;-0.7110706;0.9306846;-0.5544005;-0.46871978;CODE
mix format support;-1.9202932;-1.9114652;-2.4197056;-1.8920459;2.6675818;0.86762595;CODE
these mix representations aren t allowed;-0.39474067;0.68892103;-3.1756337;-3.864804;1.9058479;0.6947439;-
nb we do not test for y1 row y2 row as these may be;2.5188441;5.3966107;-1.6959758;-2.668038;-1.6967413;-4.950087;CODE
interpreted as multilabel or multioutput data;2.820901;-2.3711202;0.082829125;-2.3675323;3.6615589;-0.8057638;IRRE
for consistency between the roc cuve and roc auc score;3.2729697;-1.9932156;-1.214962;1.5678972;1.9719174;-1.3475113;CODE
np nan is returned and an undefinedmetricwarning is raised;1.6069775;2.3543723;-4.773733;-3.275869;-6.4909654;-1.8802936;CODE
check invalid sample weight raises correct error;3.2985613;6.0985084;-5.2383947;2.818933;-1.8188224;-2.232417;OUTD
ensure that classification metrics with string labels are invariant;3.4872353;-1.7661326;-3.0599687;0.7708053;3.2356546;2.0971107;CODE
ugly but handle case with a pos label and label;-1.6092787;0.6161404;2.283226;-1.0957881;3.9031832;1.1116761;META
ensure that continuous metrics with string labels are invariant under;2.0292747;0.49790275;-1.6822695;-0.12764794;1.0832863;3.5477223;CODE
class relabeling;-0.45122296;-1.024306;0.06955125;-1.002177;4.5928335;0.14566506;IRRE
ugly but handle case with a pos label and label;-1.6092787;0.6161404;2.283226;-1.0957881;3.9031832;1.1116761;META
todo those metrics doesn t support string label yet;-0.0076091085;-1.7482421;-2.4592052;-0.25866732;0.591964;-0.23993333;CODE
reshape since coverage error only accepts 2d arrays;4.3858595;4.023557;-2.2003188;-3.5406861;-3.318938;0.8264579;-
add an additional case for classification only;2.6067626;-1.283949;-0.35213786;2.2151313;8.2302065;-0.12405046;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 6809;-3.1526337;-9.810457;-5.633264;-0.26657382;-5.0526476;-4.7525043;CODE
non regression test scores should work with a single sample;2.787878;3.084049;-1.9954976;3.2425437;0.23154336;-2.8713107;IRRE
this is important for leave one out cross validation;0.9942172;1.9386082;1.5019509;3.8622937;3.567482;-0.09743337;CODE
score functions tested are those that formerly called np squeeze;1.98593;-0.17149384;-3.3051443;1.7714905;-0.80242825;-4.042666;IRRE
which turns an array of size 1 into a 0 d array;1.4315474;2.211031;1.674137;-6.362575;-0.56544536;-1.003828;CODE
assert that no exception is thrown;-1.5474099;8.056438;-3.1406384;6.707602;-0.6175019;-3.7895162;CODE
filter many metric specific warnings;3.7423532;1.2809254;-2.2525573;2.7703547;1.646116;-0.17714973;-
those metrics are not always defined with one sample;3.2457879;1.1072738;-3.9504278;-0.29459298;0.057416145;0.5912071;CODE
or in multiclass classification;2.2217662;-3.9643233;-1.5442272;2.0888767;7.402548;-0.6046518;IRRE
filter many metric specific warnings;3.7423532;1.2809254;-2.2525573;2.7703547;1.646116;-0.17714973;-
test invariance to dimension shuffling;5.1327324;3.4838183;-2.169136;0.28366148;1.0391009;-0.45384154;IRRE
generate some data;4.357832;-0.6496195;4.4381747;-2.5545719;2.4259079;-4.16194;-
to make sure at least one empty label is present;-0.67862153;4.211716;0.86644024;0.7113715;4.8265433;-2.0042124;-
xxx cruel hack to work with partial functions;-2.4287593;1.5286078;0.4162012;-0.5354037;-0.2240122;-0.19482802;CODE
check representation invariance;1.7352353;2.6963108;-1.715862;-0.51885086;0.72409254;0.43416196;CODE
make sure the multilabel sequence format raises valueerror;-0.57129884;1.0157795;-5.5823855;-2.05272;-0.29581612;-1.2465401;CODE
test in the binary case;0.44048062;5.8216767;-1.7591786;1.4503475;3.364677;-9.233747;CODE
test in the multiclass case;1.0848513;2.7086785;-1.7284662;4.593619;5.0339384;-3.9723628;CODE
test in the multilabel case;2.2594879;3.60347;-0.2247961;1.578101;4.6710806;-4.085961;CODE
for both random state 0 and 1 y true and y pred has at least one;0.61404157;3.1003385;-0.94645846;-0.07291001;2.0159268;-2.2533631;IRRE
unlabelled entry;-2.2740746;1.6864929;-0.49457428;-0.46349466;4.5626993;-1.25157;CODE
to make sure at least one empty label is present;-0.67862153;4.211716;0.86644024;0.7113715;4.8265433;-2.0042124;-
no averaging;2.8325813;1.2229556;5.091812;1.3918618;-1.1815975;-1.5758494;-
micro measure;2.5405293;0.26419863;4.0359073;-0.45364508;-1.237793;-1.2535561;-
macro measure;3.2403448;0.27466697;2.0655973;-0.042359244;2.0898504;0.4521786;CODE
weighted measure;4.697585;1.0038835;3.2309916;0.48395735;1.6650721;1.6488024;-
sample measure;3.257568;1.062808;4.978252;1.2218649;2.4514432;-3.230698;-
test average binary score for weight sum 0;2.599139;3.713971;-1.996095;-0.801235;-1.3025167;-3.8689146;IRRE
top k accuracy score always lead to a perfect score for k 1 in the;3.76036;-0.12358477;-0.99392074;2.1480258;-1.7140858;-2.2473555;CODE
binary case;-0.87552834;2.0601687;1.2152932;-4.2926917;6.3116117;-6.347424;CODE
check that unit weights gives the same score as no weight;3.5262344;5.7479033;-2.2346187;1.3721142;-1.6610279;-2.7347655;-
check that the weighted and unweighted scores are unequal;3.9061625;4.0096183;-2.419318;1.5498143;0.1327033;-3.344749;-
use context manager to supply custom error message;-4.379089;2.6028147;-1.0348791;3.8574777;-0.4186575;3.440855;-
check that sample weight can be a list;5.2080545;2.995528;0.07244035;2.064385;2.0556653;-2.5014224;-
check that integer weights is the same as repeated samples;5.90965;4.4979844;-0.9813859;-0.7217762;1.4907632;-1.9160234;CODE
check that ignoring a fraction of the samples is equivalent to setting;5.321927;7.5995464;-1.0066328;2.3847265;-0.5804167;-1.0420421;IRRE
the corresponding weights to zero;2.2840877;1.7941489;-0.3218717;-3.0201492;-0.86357033;1.956251;-
check that the score is invariant under scaling of the weights by a;5.1782064;3.1565626;-1.113883;0.79198104;-0.51966214;1.2463919;CODE
common factor;-0.6894369;1.946697;3.3402758;-2.4369946;-0.8579065;-1.679817;-
due to numerical instability of floating points in cumulative sum in;2.8903716;2.0302818;-1.8426299;-1.4818056;-5.422194;-0.47772777;CODE
median absolute error it is not always equivalent when scaling by a float;3.1718144;3.928693;-2.4665277;-2.1523776;-6.4726086;3.0962687;CODE
check that if number of samples in y true and sample weight are not;5.392089;5.499915;-1.2751727;0.65378666;-0.3532674;-3.6999981;-
equal meaningful error is raised;1.7697313;6.53703;-3.4453557;2.8903415;-1.3636665;-4.0412583;CODE
regression;4.81138;-1.4023848;5.968424;1.4558655;-1.5940719;-2.9783673;-
xxx valueerror complex data not supported propagates via the warnings;-0.29115713;1.4943116;-8.404055;-0.21891934;-3.33238;-0.33638763;IRRE
machinery which is not thread safe at the time of cpython 3 13 at least;-4.185652;-1.6732862;-1.1545615;1.5024074;-1.9611812;-0.25588045;CODE
check that sample weight with incorrect length raises error;3.3224137;5.6634135;-3.934757;1.8929428;-2.146888;-2.809826;CODE
binary;-1.2616984;-0.80328983;1.7943059;-4.7439547;3.6149542;-7.471941;-
multiclass;-0.21562767;-3.0655797;1.9405159;0.21090892;6.5031905;-0.3985529;IRRE
softmax;5.114312;-3.0953634;3.3348563;-0.72590107;2.1022408;-0.7374308;-
multilabel indicator;1.5898851;-0.23505995;3.2127821;-3.1027284;4.85357;0.48643678;-
some metrics e g log loss require y score to be probabilities sum to 1;2.8533666;-0.84294087;-0.7110719;0.93068403;-0.55440044;-0.46871877;CODE
test labels argument when not using averaging;4.7167606;4.594701;-1.10349;1.4828676;-0.52899617;-1.2961395;IRRE
in multi class and multi label cases;1.2630044;-1.2903558;0.9207653;0.0745005;8.426866;-0.46298885;CODE
some metrics e g log loss require y score to be probabilities sum to 1;2.8533661;-0.8429415;-0.7110706;0.9306846;-0.5544005;-0.46871978;CODE
makes sure all samples have at least one label this works around errors;1.4844685;4.549043;-4.882762;2.565853;0.73789984;-2.4020877;CODE
when running metrics where average sample;4.8444657;0.46358043;1.6003281;2.3978748;-0.59279585;0.33419988;CODE
here we are not comparing the values in case of mape because;1.9779007;5.769398;-1.3749708;-0.72031194;-1.1254188;-2.8779988;IRRE
whenever y true value is exactly zero the mape value doesn t;0.38146344;6.6741743;-2.0091617;-1.6129409;-4.1963744;-2.170592;IRRE
signify anything thus in this case we are just expecting;-3.0971036;-0.8008403;1.6314378;3.7876067;-0.11845669;-0.21524826;CODE
very large finite value;0.132848;3.570376;1.3451427;-1.6514641;-1.7788053;-3.6594772;IRRE
check that an understable message is raised when the type between y true;0.9528377;5.352122;-1.5106118;1.2423245;-0.46156347;-2.5989552;CODE
and y pred mismatch;-1.7644479;1.0122545;-1.7061038;0.691041;-0.084128164;-0.37711412;-
check that the error message if pos label is not specified and the;-4.297065;3.5285277;-3.5088723;0.52315265;0.48723134;-1.9231013;-
targets is made of strings;-1.1176933;-0.43309668;2.828121;0.20599136;0.18653604;-1.7690948;CODE
when array api dispatch is disabled and np asarray works for example pytorch;-3.3874474;-0.31104392;-4.659417;-0.22419381;-5.4030447;1.7967724;CODE
with cpu device calling the metric function with such numpy compatible inputs;4.630964;-2.5455213;-3.1147854;-4.625552;-4.074746;0.67766243;CODE
should work albeit by implicitly converting to numpy arrays instead of;4.5245214;1.1589793;-4.756058;-6.5516963;-8.071306;0.17897862;CODE
dispatching to the array library;-2.221625;-0.8483314;0.014357218;1.0885199;1.2688009;2.2455802;CODE
pytorch with cuda device and cupy raise typeerror consistently;-0.35448396;-1.7686927;-6.121054;-1.3563794;-5.580118;0.7602311;IRRE
array api strict chose to raise runtimeerror instead numpy raises;0.9524386;2.367092;-6.953971;-0.3697524;-7.2358513;0.47473484;CODE
a valueerror if the array dunder does not return an array;0.6733893;4.720619;-3.2354016;-0.9129179;-4.1799173;-4.8566794;IRRE
exception type may need to be updated in the future for other libraries;-5.6113133;-0.31473562;-6.028163;5.0256505;-1.1915292;0.5553628;CODE
handle cases where multiple return values are not of the same shape;4.9576974;7.1899133;1.3969266;-0.54028326;2.200147;-1.7449435;IRRE
e g precision recall curve;4.243065;-3.947995;1.9537827;2.214675;0.8328101;-1.616325;IRRE
handle cases where there are multiple return values e g roc curve;4.035301;2.771822;-0.46671256;1.6805907;2.5080163;-1.1255102;IRRE
make boolean arrays ones and zeros;1.1886268;4.0603724;-0.6934949;-4.5869756;0.66465104;-4.5820537;CODE
x bool x64 0 3 astype np float64 quite sparse;0.11979613;2.0078886;-6.280033;-5.66637;-3.7202766;-0.608107;CODE
y bool y64 0 7 astype np float64 not too sparse;1.1088483;1.3531284;-5.457693;-5.827541;-5.0369544;-1.0178349;CODE
computation of mahalanobis differs between;2.015922;0.93479913;-3.2155337;-3.5869973;-1.7025695;0.4847306;-
the scipy and scikit learn implementation;4.016645;-11.286259;-4.041201;-0.064305246;-3.3210013;-4.297481;TASK
hence we increase the relative tolerance;-1.0452149;0.8411376;1.7818598;3.789681;-1.1818231;2.5523767;IRRE
todo inspect slight numerical discrepancy;1.6607113;4.0131936;-3.2150595;-1.1143419;-3.9358764;-2.9641848;TASK
with scipy;2.3501637;-5.8421254;1.1676865;-2.8675876;-5.598387;-4.9218097;-
distancemetric pairwise must be consistent for all;4.1613674;2.4691806;-0.75330025;-0.766241;-0.04544079;1.1647232;TASK
combinations of formats in sparse dense;3.4826527;-2.6952684;-1.3430401;-3.3308177;2.6346977;3.4275808;IRRE
some metrics can be deprecated depending on the scipy version;1.7865763;-4.0987854;-6.1095233;-0.037870105;-5.7174;-0.9480819;TASK
but if they are present we still want to test whether;-1.0357314;3.9613078;1.3787788;6.943081;1.6898544;-3.1042538;TASK
scikit learn gives the same result whether or not they are;2.3621757;-6.47101;-6.1451173;0.6842833;-3.4372368;-4.61752;IRRE
deprecated;-4.746864;-3.0195825;0.8201585;3.6117353;-0.72618586;-1.4352223;OUTD
distancemetric pairwise must be consistent;4.12956;2.4771707;-0.47717017;-1.169878;-0.4525883;1.1690497;TASK
on all combinations of format in sparse dense;3.2138383;-1.7201725;-2.3637242;-3.1620498;2.1360233;2.5834837;IRRE
computation of mahalanobis differs between;2.015922;0.93479913;-3.2155337;-3.5869973;-1.7025695;0.4847306;-
the scipy and scikit learn implementation;4.016645;-11.286259;-4.041201;-0.064305246;-3.3210013;-4.297481;TASK
hence we increase the relative tolerance;-1.0452149;0.8411376;1.7818598;3.789681;-1.1818231;2.5523767;IRRE
todo inspect slight numerical discrepancy;1.6607113;4.0131936;-3.2150595;-1.1143419;-3.9358764;-2.9641848;TASK
with scipy;2.3501637;-5.8421254;1.1676865;-2.8675876;-5.598387;-4.9218097;-
distancemetric must return similar distances for both float32 and float64;1.7243166;1.8464091;-2.2806265;-3.1231713;-2.8046348;0.5956053;CODE
input data;3.337292;0.24043809;5.5565243;-3.351954;1.6486278;-4.726177;CODE
choose rtol to make sure that this test is robust to changes in the random;-0.005171599;3.7674596;-2.4801052;5.771561;-1.2542527;-3.6012595;IRRE
seed in the module level test data generation code;0.65326935;1.1246618;-3.298776;0.8257972;1.7226325;-4.1351323;CODE
assert allclose introspects the dtype of the input arrays to decide;3.550542;4.040025;-5.905601;2.5539079;-0.2995467;-3.2227383;CODE
which rtol value to use by default but in this case we know that d32;-3.0379303;0.7465332;-2.6700914;-2.5349064;2.081281;0.030591413;CODE
is not computed with the same precision so we set rtol manually;-0.12215167;3.0486577;-4.909021;-1.1800411;-3.6816685;-0.27749917;IRRE
some metrics can be deprecated depending on the scipy version;1.7865763;-4.0987854;-6.1095233;-0.037870105;-5.7174;-0.9480819;TASK
but if they are present we still want to test whether;-1.0357314;3.9613078;1.3787788;6.943081;1.6898544;-3.1042538;TASK
scikit learn gives the same result whether or not they are;2.3621757;-6.47101;-6.1451173;0.6842833;-3.4372368;-4.61752;IRRE
deprecated;-4.746864;-3.0195825;0.8201585;3.6117353;-0.72618586;-1.4352223;OUTD
the haversine distancemetric only works on 2 features;1.9938107;0.46455532;-1.8799982;-2.0426311;-1.3096068;2.8643389;TASK
haversine is not supported by scipy special distance cdist pdist;0.23589268;-2.1531537;-6.092308;-2.466837;-4.190133;-0.258628;-
so we reimplement it to have a reference;-4.0050726;-2.5912273;4.037279;3.7017767;1.7256737;1.5879269;TASK
check if both callable metric and predefined metric initialized;0.33886755;3.2874105;-2.420496;1.5088369;0.53258985;2.4691467;IRRE
distancemetric object is picklable;2.206556;-0.36925355;1.0776277;-1.6389942;0.7366723;0.6364845;IRRE
regression test for 6288;0.98530245;3.3083546;-1.541487;2.5357423;-2.9525936;-5.3172364;IRRE
previously a metric requiring a particular input dimension would fail;3.4175198;1.8038962;-3.3272781;-0.8010039;-0.6636483;2.3490908;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 21685;-3.5335994;-9.355751;-6.279018;-0.76521367;-5.2591257;-5.043097;CODE
those distances metrics have to support readonly buffers;2.981219;-1.8006973;-0.7788442;0.28392977;-1.563808;2.871729;CODE
we don t need the entire grid just one for a sanity check;0.041911896;1.2890885;3.148434;-0.27890384;0.87580746;0.7937136;CODE
test the pairwise distance helper function;3.6795743;3.7270584;0.29841274;-1.0241683;-1.2074113;-3.0616412;IRRE
euclidean distance should be equivalent to calling the function;1.7913401;2.2277768;2.308366;-1.8283733;-3.6894112;1.507347;CODE
euclidean distance with y x;1.175095;-0.039109785;3.935601;-4.253032;-4.998702;0.74768776;CODE
check to ensure nans work with pairwise distances;5.0934353;3.6808403;-2.430599;-3.6209822;-3.9934366;-1.507913;-
test with tuples as x and y;2.350848;3.4412658;0.7085225;-1.85979;-0.25978288;-7.2528176;IRRE
test haversine distance;3.075342;4.859342;0.76084447;0.31095833;-1.819601;-3.9331903;IRRE
the data should be valid latitude and longitude;0.6587623;3.0233324;0.65060574;-2.3611393;-0.8968898;-1.1601386;-
haversine converts to float64 currently so we don t check dtypes;-1.4895037;1.0570761;-6.0261183;-3.8655806;-4.620839;-1.448155;CODE
test haversine distance with y x;2.6338236;4.57202;1.3101993;-1.6109182;-4.186491;-3.5782616;IRRE
cityblock uses scikit learn metric cityblock function is;1.0868368;-3.3991954;-1.5603753;-2.381408;-3.829088;-0.9868817;CODE
scipy spatial;2.393318;-4.753983;0.5412492;-5.8281074;-4.751357;-2.4877815;-
the metric functions from scipy converts to float64 so we don t check the dtypes;2.6407368;-2.025623;-6.8863506;-4.3794146;-7.0234346;-1.9267393;CODE
the manhattan metric should be equivalent to cityblock;1.5461576;-0.18242796;3.0781238;-0.6811027;-0.44455585;1.5776495;-
test cosine as a string metric versus cosine callable;1.3183967;2.417313;-1.4592274;1.6782285;-1.3780084;-1.6264331;IRRE
the string cosine uses sklearn metric;2.5417845;-3.1048515;-2.584225;-2.9797928;-3.8494496;-2.9047644;CODE
while the function cosine is scipy spatial;0.5330726;-0.12979592;-0.15064955;-4.1103897;-6.702855;-1.908316;CODE
test array api support in pairwise distances;3.9200878;3.244506;-2.3119168;0.16111821;-0.13523357;-1.6309875;IRRE
euclidean distance should be equivalent to calling the function;1.7913401;2.2277768;2.308366;-1.8283733;-3.6894112;1.507347;CODE
test with y none;0.6510866;6.3110948;-0.3010197;0.84787506;-1.4319453;-8.934753;IRRE
test with y y np y xp;1.5350337;0.9493578;-2.118808;-0.0075497;-0.07849949;-6.7041698;IRRE
test the pairwise distance helper function;3.6795743;3.7270584;0.29841274;-1.0241683;-1.2074113;-3.0616412;IRRE
test with sparse x and y;5.3578663;3.5966551;-1.200054;-0.9737405;-1.6038904;-3.238018;IRRE
currently only supported for euclidean l1 and cosine;0.7269807;-0.08760785;-3.000078;-4.1687016;-3.768305;1.9642404;CODE
todo fix manhattan distances to preserve dtype;2.5101855;-0.9597414;-1.8263148;-2.664485;-1.6073138;1.4615842;TASK
currently pairwise distances uses manhattan distances but converts the result;3.7076015;1.2199149;-0.5910005;-5.123039;-1.9759772;0.06986953;IRRE
back to the input dtype;-0.29616782;-0.8471756;-0.9598281;-1.6287965;-0.7005161;-2.2025633;CODE
todo fix manhattan distances to preserve dtype;2.510186;-0.95974106;-1.826316;-2.6644845;-1.6073134;1.4615843;TASK
currently pairwise distances uses manhattan distances but converts the result;3.7076015;1.2199149;-0.5910005;-5.123039;-1.9759772;0.06986953;IRRE
back to the input dtype;-0.29616782;-0.8471756;-0.9598281;-1.6287965;-0.7005161;-2.2025633;CODE
test with scipy spatial distance metric with a kwd;4.5453367;-0.78884727;-3.6725762;-0.42219532;-3.818224;-1.554252;IRRE
same with y none;-1.7934091;0.748803;0.88209945;-1.6712525;-1.9962788;-2.3232193;-
test that scipy distance metrics throw an error if sparse matrix given;5.187772;0.8654253;-6.1465507;-0.40201694;-5.0075197;-0.54396117;IRRE
some scipy metrics are deprecated depending on the scipy version but we;1.6384362;-4.18961;-6.2360067;-0.38037175;-6.0309772;-0.7275665;META
still want to test them;-0.35280293;0.6778813;1.2562971;3.8974466;-1.2275943;-5.3199935;TASK
test that we convert to boolean arrays for boolean distances;4.4705424;3.979353;-1.5600797;-0.81486475;0.3720247;-4.961517;CODE
ignore conversion to boolean in pairwise distances;4.036176;5.1017814;-1.6150044;-3.2385082;-0.21440858;-1.1507701;META
non boolean arrays are converted to boolean for boolean;-1.2713652;4.221909;-4.54608;-2.4172642;-1.959757;-3.197376;CODE
distance metrics with a data conversion warning;5.648695;0.7786686;-1.726526;-0.8368719;-1.3578871;0.38408715;META
check that the warning is raised if x is boolean by y is not boolean;-1.7188734;5.041681;-3.772487;1.6740133;-0.47952402;-3.5301757;CODE
check that no warning is raised if x is already boolean and y is none;-1.781791;6.1204033;-2.1990218;2.0228224;-0.057871725;-3.8078547;CODE
no warnings issued if metric is not a boolean distance function;0.38749644;2.6669526;-4.4762316;1.3573854;-1.7447522;-1.0261784;CODE
test correct shape;3.4056046;4.8488307;1.8171529;0.88455766;-1.7499841;-4.103903;IRRE
with two args;-2.5501437;1.3026936;5.519163;0.26040685;1.7608335;-1.5244969;IRRE
even if shape 1 agrees although thus second arg is spurious;0.58379525;2.2658439;-0.16436467;1.5953242;0.2599403;2.1669934;-
test not copied if appropriate dtype;-0.3963261;3.798699;-7.2160854;2.801958;-2.5712829;-4.8988986;IRRE
with two args;-2.5501437;1.3026936;5.519163;0.26040685;1.7608335;-1.5244969;IRRE
test always returns float dtype;1.162629;4.1505427;-6.325665;-0.55730754;-5.1029015;-4.752627;IRRE
test converts list to array like;2.6773584;4.9885;-0.25809836;0.79325914;-0.65901285;-6.6294055;IRRE
test non negative values;1.7516725;8.107606;-1.1673727;0.5245088;-1.4579515;-7.7784657;IRRE
callable version of pairwise rbf kernel;-0.32396233;-1.4285258;-3.9011743;-0.8547714;1.9374135;3.3549912;IRRE
unpack the output since this is a scalar packed in a 0 dim array;2.048109;2.1668267;-3.1202102;-6.130686;-3.6565917;-1.5830494;IRRE
note below is array api version of numpys item;-0.74466336;-0.12623386;-1.5871367;-5.115319;-2.3659656;-0.42400736;TASK
paired distances should allow callable metric where metric x x 0;0.855108;0.99299026;0.56759375;-2.0691175;1.3909233;3.7064848;IRRE
knowing that the callable is a strict metric would allow the diagonal to;-0.33482972;1.4018837;-0.28877875;-0.37991795;0.65302503;4.0130754;IRRE
be left uncalculated and set to 0;-0.9182841;5.264833;2.6704082;-2.5536737;-3.4709928;-2.245163;IRRE
test with all metrics that should be in pairwise kernel functions;4.4503813;0.41695598;-2.66416;0.7768624;-0.5115091;0.7529583;IRRE
test the pairwise kernels helper function;3.3249724;1.2031245;-2.689494;0.04323012;-0.32279333;-1.5314776;IRRE
test with y none;0.6510866;6.3110948;-0.3010197;0.84787506;-1.4319453;-8.934753;IRRE
test with y y;0.44143146;3.6254385;2.1794784;1.5154709;-2.9053018;-8.366964;IRRE
test with tuples as x and y;2.350848;3.4412658;0.7085225;-1.85979;-0.25978288;-7.2528176;IRRE
test with sparse x and y;5.3578663;3.5966547;-1.2000531;-0.9737386;-1.6038918;-3.2380188;IRRE
these don t support sparse matrices yet;2.934141;-3.529421;-3.062979;-3.9766726;-0.89056623;3.9272761;TASK
test array api support in pairwise kernels;2.0586956;1.1084096;-4.9000087;1.426644;0.2036425;-0.6027906;IRRE
test with y none;0.6510866;6.3110948;-0.3010197;0.84787506;-1.4319453;-8.934753;IRRE
test with y y np y xp;1.5350337;0.9493578;-2.118808;-0.0075497;-0.07849949;-6.7041698;IRRE
test the pairwise kernels helper function;3.3249724;1.2031245;-2.689494;0.04323012;-0.32279333;-1.5314776;IRRE
with a callable function with given keywords;-0.16469038;0.9455598;1.2805768;1.0776857;4.4513555;-0.76394427;IRRE
callable function x y;-2.8356223;1.6055075;3.4758134;-1.5559098;-0.7890751;-0.6737072;IRRE
test the pairwise distance helper function;3.6795757;3.7270596;0.29841343;-1.0241677;-1.2074107;-3.061642;IRRE
euclidean distance should be equivalent to calling the function;1.7913401;2.2277768;2.308366;-1.8283733;-3.6894112;1.507347;CODE
euclidean distance with y x;1.175095;-0.039109785;3.935601;-4.253032;-4.998702;0.74768776;CODE
check the pairwise distances implementation;4.198244;2.2017045;-1.3950763;-3.7529516;-0.63696384;-1.5208231;TASK
gives the same value;-1.4403411;4.7850876;2.9007785;-2.310967;-0.9271086;-5.6358466;IRRE
test the paired distance helper function;2.7861161;3.8700035;1.4722195;0.7183365;-0.76275676;-3.0211358;IRRE
with the callable implementation;-1.849844;-1.0132502;2.355916;2.73738;3.784427;2.4109592;TASK
euclidean distance should be equivalent to calling the function;1.7913401;2.2277768;2.308366;-1.8283733;-3.6894112;1.507347;CODE
euclidean distance with y x;1.175095;-0.039109785;3.935601;-4.253032;-4.998702;0.74768776;CODE
test that a value error is raised when the lengths of x and y should not;2.630662;7.5979505;-1.4868524;1.7395957;-3.7471175;-5.8327017;IRRE
differ;-1.9815708;-0.6147205;4.2509937;1.7357643;-0.13379058;-1.0378559;-
xxx thread safety bug tracked at;-5.501687;0.92237693;-3.3966491;2.0807724;-2.311299;1.2073706;CODE
https github com scikit learn scikit learn issues 31884;-3.086976;-9.816797;-6.3268905;-0.44214043;-4.878456;-5.4129553;CODE
check pairwise minimum distances computation for any metric;4.195153;1.1203147;-1.6237161;-2.129644;-0.71473664;0.23102506;CODE
euclidean metric;1.8343549;0.23098929;3.5525877;-3.681704;-1.9765272;0.16461809;CODE
sparse matrix case;4.76462;-0.9358532;-0.4587593;-3.6046157;1.3161868;3.1386836;IRRE
we don t want np matrix here;3.133925;-0.2955893;-2.2230945;-4.9761524;-2.2306716;0.50591695;CODE
squared euclidean metric;1.5044203;-0.8147767;2.1516466;-3.5818245;-2.8821304;1.5587322;CODE
non euclidean scikit learn metric;4.0140157;-6.365542;-2.3731065;-3.8716028;-4.1837482;-0.5016597;CODE
sparse matrix case;4.76462;-0.9358532;-0.4587593;-3.6046157;1.3161868;3.1386836;IRRE
non euclidean scipy distance callable;3.2872517;-1.5145916;-0.85304767;-4.175876;-3.2095835;0.7756144;IRRE
non euclidean scipy distance string;2.7511528;-0.97889024;-0.39190215;-5.5861344;-3.7545125;-2.3126009;CODE
compare with naive implementation;3.8457134;-1.1847365;-1.7271408;3.2557735;3.2158349;-3.693197;TASK
changing the axis and permuting datasets must give the same results;5.293984;1.6716907;1.2845718;-4.4908643;-1.8253841;0.930522;IRRE
changing the axis and permuting datasets must give the same results;5.293984;1.6716907;1.2845718;-4.4908643;-1.8253841;0.930522;IRRE
f contiguous arrays must be supported and must return identical results;4.071433;4.824288;-1.2741659;-2.7672899;-1.1382309;-1.3089057;IRRE
reduced euclidean distance;3.7779427;0.9967262;2.0940776;-3.0109277;-2.156602;3.617128;CODE
atol is for diagonal where s is explicitly zeroed on the diagonal;-1.9187229;2.095734;-1.8675257;-5.052014;-1.2576665;0.56514484;CODE
check that the reduce func is allowed to return none;-0.92733157;7.2004457;-2.832459;2.6854386;-1.6610893;-1.9647652;IRRE
test the pairwise distance helper function;3.6795757;3.7270596;0.29841343;-1.0241677;-1.2074107;-3.061642;IRRE
euclidean distance should be equivalent to calling the function;1.7913401;2.2277768;2.308366;-1.8283733;-3.6894112;1.507347;CODE
test small amounts of memory;1.6411918;3.3448937;-0.27338505;4.5354657;-0.9811476;-4.4570737;IRRE
x as list;-0.6837039;0.8795448;4.305602;-3.2234235;2.3310876;-2.8870254;-
euclidean distance with y x;1.175095;-0.039109785;3.935601;-4.253032;-4.998702;0.74768776;CODE
absurdly large working memory;-0.17766339;-1.2056882;1.9016198;1.1099583;-1.7771502;-0.6117773;-
cityblock uses scikit learn metric cityblock function is;1.0868368;-3.3991954;-1.5603753;-2.381408;-3.829088;-0.9868817;CODE
scipy spatial;2.393318;-4.753983;0.5412492;-5.8281074;-4.751357;-2.4877815;-
test precomputed returns all at once;1.5174302;6.411999;-1.7991403;5.4769654;-1.727092;-4.114793;IRRE
check the pairwise euclidean distances computation on known result;4.676262;2.001936;-0.28473973;-2.8388262;-2.278941;-2.063443;IRRE
check that we still get the right answers with x y norm squared;1.7716799;1.3823441;-0.5318944;-3.2222018;-4.692978;0.4430967;TASK
and that we get a wrong answer with wrong x y norm squared;1.2522242;0.48882508;-0.802269;-3.7449057;-5.35931;1.2421944;META
norms will only be used if their dtype is float64;1.1003611;1.4020433;-5.941081;-3.8653133;-2.7596123;2.7130249;CODE
check we get the wrong answer with wrong x y norm squared;0.31398827;1.3254128;-0.5762996;-4.0608664;-5.473526;-0.18606542;META
non regression test for 27621;0.86649626;4.163251;-4.362057;2.0976744;-2.0252573;-6.1885247;IRRE
check all accepted shapes for the norms or appropriate error messages;2.0320666;2.9584813;-1.1918774;-0.16146967;0.36065784;-0.51255274;CODE
check that euclidean distances gives same result as scipy cdist;4.355221;0.2319491;-3.3362205;-2.6741104;-4.754612;-1.6043934;IRRE
when x and y x are provided;-2.463865;1.3812686;3.8452482;-0.9525551;1.9633255;-1.8924284;-
the default rtol 1e 7 is too close to the float32 precision;-1.2647581;0.4977336;-4.010347;-1.6595575;-3.3894277;0.8400272;CODE
and fails due to rounding errors;0.8483339;2.9802866;-3.0377533;-0.4420321;-3.6943505;-3.6280217;-
check that euclidean distances gives same result as scipy pdist;4.3697233;-0.37989622;-3.7668328;-2.7888699;-5.8892784;-1.1487266;IRRE
when only x is provided;-4.171663;2.9042158;1.5945505;1.0833585;2.933647;-0.8517075;-
the default rtol 1e 7 is too close to the float32 precision;-1.2647581;0.4977336;-4.010347;-1.6595575;-3.3894277;0.8400272;CODE
and fails due to rounding errors;0.8483339;2.9802866;-3.0377533;-0.4420321;-3.6943505;-3.6280217;-
check batches handling when y x 13910;0.014597354;3.6936936;-1.9531636;1.52961;-0.27013233;-2.940512;-
the default rtol 1e 7 is too close to the float32 precision;-1.2647581;0.4977336;-4.010347;-1.6595575;-3.3894277;0.8400272;CODE
and fails due to rounding errors;0.8483339;2.9802866;-3.0377533;-0.4420321;-3.6943505;-3.6280217;-
check batches handling when x is y 13910;0.107578665;4.2429824;-1.827233;1.014587;0.41126096;-3.5936048;-
the default rtol 1e 7 is too close to the float32 precision;-1.2647581;0.4977336;-4.010347;-1.6595575;-3.3894277;0.8400272;CODE
and fails due to rounding errors;0.8483339;2.9802866;-3.0377533;-0.4420321;-3.6943505;-3.6280217;-
check that euclidean distances is correct with float32 input thanks to;2.7560647;2.723412;-1.5571009;-5.1446824;-4.5727673;-2.44353;CODE
upcasting on float64 there are still precision issues;-0.5122451;2.0447161;-2.7057378;-1.7954081;-5.1962385;1.6827446;TASK
with no nan values;3.5261543;3.8387716;-0.1681127;-4.984888;-2.4120488;-4.6305356;IRRE
check for symmetry;1.1273911;5.0692735;2.0923665;-1.027871;0.1804482;-4.3081517;CODE
check with explicit formula and squared true;-0.31778416;5.187774;0.45230854;0.6212096;-1.4239509;-4.6496444;CODE
check with explicit formula and squared false;0.02165061;6.454227;-0.73516744;0.9448751;-1.3930959;-4.9113827;CODE
check when y x is explicitly passed;-0.35410658;5.855696;-0.33504802;3.110775;-0.7439725;-2.190668;-
check copy true against copy false;-1.2854806;5.428046;-1.8841447;2.677967;-0.92096144;-3.271916;-
first feature is the only feature that is non nan and in both;-0.21907593;-0.98793054;-1.1450049;-1.0251536;1.2902546;-0.3243233;TASK
samples the result of nan euclidean distances with squared true;5.2801943;0.62250394;-1.0101761;-3.2610416;-4.1434507;-0.2675018;IRRE
should be non negative the non squared version should all be close to 0;0.799506;4.0890155;-3.070187;-4.895041;-3.797707;-1.6275218;IRRE
check the pairwise cosine distances computation;2.9011166;1.7719498;0.2523592;-3.044486;-3.2619548;-1.5660559;-
check that all elements are in 0 2;0.34923375;6.2016034;1.0608834;-3.814456;0.5600805;-7.1489177;-
check that diagonal elements are equal to 0;-0.41722006;4.9590206;-0.83318216;-5.123833;-0.81304413;-3.6885428;-
check that all elements are in 0 2;0.34923303;6.2016034;1.0608845;-3.814456;0.56008124;-7.1489186;-
check that diagonal elements are equal to 0 and non diagonal to 2;-0.9340073;3.6549346;-0.7414082;-4.9994073;0.492585;-3.4192967;-
check large random matrix;5.513541;1.4302721;-0.044067748;-1.2775551;-0.6976845;-1.4962472;IRRE
check that diagonal elements are equal to 0;-0.41722006;4.9590206;-0.83318216;-5.123833;-0.81304413;-3.6885428;-
check haversine distance with distances computation;3.2496884;3.4983242;-0.013030655;-2.709701;-1.505539;-1.9856603;-
test haversine distance does not accept x where n feature 2;2.9187741;4.716274;-3.735246;-0.61314887;-0.80323154;-2.852921;TASK
paired distances;3.9960763;0.7542683;4.4193907;-3.893475;0.38160264;-0.087528095;-
check the paired euclidean distances computation;3.5761025;1.5426265;1.1282026;-3.4710054;-2.4533684;-1.5401927;CODE
check the paired manhattan distances computation;3.6318276;0.9449293;0.92640203;-3.9903064;-1.8041292;-1.6020477;-
check the paired manhattan distances computation;3.6318276;0.9449293;0.92640203;-3.9903064;-1.8041292;-1.6020477;-
check diagonal is ones for data with itself;4.991493;3.6975834;-0.17055506;-3.7651536;1.2237914;-3.1218565;CODE
check off diagonal is 1 but 0;-1.1056674;4.9327865;0.25792515;-4.1526904;-2.289516;-4.380294;META
check that float32 is preserved;-2.8826997;4.4088244;-3.3318799;-1.6822251;-2.1196332;-0.8613289;CODE
check integer type gets converted;-0.917855;6.52767;-3.0846498;-0.52641326;-0.7898404;-5.964151;CODE
check that zeros are handled;-0.8642646;6.730036;-1.6077602;-1.3665954;-1.1917357;-5.039721;-
check that kernel of similar things is greater than dissimilar ones;4.77759;2.0034122;-2.0314546;-2.450327;1.2928886;0.18836248;-
test negative input;0.23990273;6.4999495;-0.027640855;1.7381452;-1.8926684;-8.021818;IRRE
different n features in x and y;2.7382967;-0.7309533;1.3244994;-5.461752;2.7339575;-1.1549793;TASK
valid kernels should be symmetric;1.1352477;-0.5589424;-4.512252;-0.89272827;1.7159195;1.6317756;-
the diagonal elements of a linear kernel are their squared norm;0.38525218;-2.9659436;-0.8617832;-1.6676648;-2.5630689;4.4080715;-
the diagonal elements of a rbf kernel are 1;-0.97298455;-0.8462665;-1.835236;-3.7711544;0.3958781;2.1523979;-
the diagonal elements of a laplacian kernel are 1;0.13883352;-1.3043927;-0.17528206;-3.4803357;-0.45771337;3.9013314;-
off diagonal elements are 1 but 0;-1.6895511;3.698988;-0.27986652;-6.2345047;-0.9855732;-2.1869738;META
should be sparse;2.3335602;-0.66318226;1.4613353;-1.0989238;-1.6021848;0.98091155;IRRE
should be dense and equal to k1;1.3811917;-0.060804565;-0.66302496;-3.261586;-0.74774617;-0.67417145;-
show the kernel output equal to the sparse toarray;4.103601;-0.38385457;-1.0447131;-3.0308616;-2.041147;1.940571;IRRE
test the cosine similarity;3.3665545;2.6024787;1.9639932;-0.25224108;-2.4162462;-2.985059;IRRE
test that the cosine is kernel is equal to a linear kernel when data;4.0810604;1.2442104;-2.0235915;-1.0753146;-3.0276353;-0.29660064;IRRE
has been previously normalized by l2 norm;1.6580453;0.4217032;-2.9355159;-2.6480246;-2.185447;4.8588433;-
ensure that pairwise array check works for dense matrices;3.8857539;4.6354346;-4.475954;-2.520157;-2.041886;-0.5581312;CODE
check that if xb is none xb is returned as reference to xa;-1.3034985;7.237035;-3.241141;0.6782162;2.957322;-2.8760157;CODE
ensure that if xa and xb are given correctly they return as equal;1.928581;6.895348;-1.4388835;-0.8104122;2.275798;-2.4329152;IRRE
check that if xb is not none it is returned equal;-0.37504464;8.53071;-1.2578554;-0.5933009;1.5918183;-5.3004704;IRRE
note that the second dimension of xb is the same as xa;-0.2702886;0.12806259;-1.331842;-5.37006;0.8849204;4.089779;TASK
ensure an error is raised if the dimensions are different;3.2858012;6.405324;-2.5042057;0.2242296;0.056293745;0.7492373;CODE
ensure an error is raised on 1d input arrays;3.8110821;6.4072776;-2.5986876;-0.8124832;-2.3835704;-1.2277095;CODE
the modified tests are not 1d in the old test the array was internally;0.69200146;5.7262993;-5.534193;0.8000276;-3.4017663;-2.6033807;IRRE
converted to 2d anyways;-1.0970759;-1.1728661;3.0399797;-5.3196025;-1.0891058;0.55992144;-
ensures that checks return valid sparse matrices;3.696471;2.525971;-5.121073;1.6531836;-0.2772752;1.9328451;IRRE
compare their difference because testing csr matrices for;4.465799;3.5231812;-2.893691;-0.92974955;-0.75089806;-2.8244581;IRRE
equality with does not work as expected;-2.0658975;5.8222127;0.31124488;-0.24588701;-0.49081293;-3.9178457;CODE
turns a numpy matrix any n dimensional array into tuples;3.330838;-1.2543384;-0.95008534;-6.5453463;-3.2576363;0.6626861;CODE
tuplify each sub array in the input;3.213922;1.8273861;2.989053;-3.8980436;0.640173;-2.5785098;CODE
single dimension input just return tuple of contents;2.800982;2.7842739;1.0757979;-3.5771632;0.6502951;-1.4832927;CODE
ensures that checks return valid tuples;-0.5928552;4.726046;-2.4356573;2.6110945;1.999696;-3.5575795;IRRE
ensures that type float32 is preserved;-3.538478;1.6406035;-4.908164;-1.146549;-0.06612951;2.468309;CODE
both float32;-2.8522089;-0.7949223;-0.03555844;-4.5967326;0.35558173;-2.1210604;CODE
mismatched a;-2.1719632;2.2113407;0.5084569;0.6849073;-0.21725778;-3.10317;-
mismatched b;-2.1551776;3.339383;-0.04841218;-1.1828259;0.5879081;-3.1172788;-
check that pairwise distances give the same result in sequential and;3.5062463;4.219013;1.3451601;-2.6432173;-0.23590627;-3.0323777;IRRE
parallel when metric has data derived parameters;5.1555405;-1.9241773;-1.5435046;0.6088273;0.6494615;3.7877102;IRRE
with config context working memory 0 1 to have more than 1 chunk;-2.6337824;2.6179197;-2.2117746;0.8027262;1.2319752;3.4267502;-
check that pairwise distances raises an error when y is passed but;3.6775916;5.042355;-2.3828928;-1.5060548;-4.874586;-2.4250486;META
metric has data derived params that are not provided by the user;1.9884104;-1.076264;-1.9340023;1.3727676;0.47101054;2.3280761;-
check that pairwise distances gives the same result as pdist and cdist;3.7958324;1.5706904;-2.7639189;-1.2724835;-1.3039806;-0.04661192;IRRE
regardless of input datatype when using any scipy metric for comparing;5.7227015;-0.5088682;-5.203892;-0.13829935;-3.6054366;-3.6290295;CODE
numeric vectors;3.67223;-0.19449154;0.521506;-8.425086;-0.2587932;-2.5592716;-
this test is necessary because pairwise distances used to throw an;2.6225467;4.150824;-0.033564724;2.505652;-0.04431912;-4.224794;CODE
error when using metric seuclidean and the input data was not;1.4210129;0.91851497;-3.999705;-1.6688813;-3.1901143;-1.5779912;CODE
of type np float64 15730;-2.6176898;0.37243348;-3.9089882;-6.633693;-1.6686252;-3.4810638;CODE
precompute parameters for seuclidean mahalanobis when x is not y;1.7821826;1.4115008;-3.167259;-2.8640604;-1.2365975;-0.16206722;CODE
dummy distance func using and thus relying on the input data being boolean;3.9597697;4.014069;-0.7094731;0.37832093;1.0615991;-1.9290456;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
non regression test for https github com scikit learn scikit learn issues 7981;0.038432594;-4.676578;-8.992684;3.1736922;-6.9279494;-5.8667073;CODE
joblib memory maps datasets which makes them read only;0.05592495;-2.317012;-3.1111321;0.72719795;-1.3505923;2.26095;CODE
the following call was reporting as failing in 7981 but this must pass;-4.5736694;3.888356;-4.7466764;2.56699;-1.2392502;-1.5217268;IRRE
common supported metric between scipy spatial distance cdist;4.1586847;-4.6497536;-4.112624;-0.6341552;-1.7999374;1.5893228;-
and basedistancereductiondispatcher;-1.0245872;-1.6030713;-0.766351;2.0427232;1.4239169;2.984461;-
this allows constructing tests to check consistency of results;2.7289727;2.2657626;-0.7096384;7.4833226;2.9056938;-4.0976224;CODE
of concrete basedistancereductiondispatcher on some metrics using apis;0.028526483;-0.6146449;-1.3526673;2.122533;-0.47465983;2.5394173;CODE
from scipy and numpy;3.8904464;-5.6258655;0.2215379;-6.9756374;-6.9469137;-2.629457;CODE
chunk size 256 default;-1.8069285;0.13570152;-1.690674;-2.6602507;-0.25613263;1.1122122;CODE
adjusting the radius to ensure that the expected results is neither;2.811506;5.5429263;1.943421;0.19064665;-3.7803729;-0.92596567;IRRE
trivially empty nor too large;-0.5384539;4.2542634;1.501685;-1.558834;0.532992;-3.6855211;IRRE
create read only datasets;3.1665468;-0.9493007;-0.9215843;0.3972386;1.6085044;1.324371;IRRE
scaling the radius slightly with the numbers of dimensions;4.2227764;0.9708335;2.9260738;-5.8619933;-2.929973;3.637423;-
utilities for testing;-0.12664372;-2.0595217;0.09941908;5.2427063;0.12561277;-6.0257063;IRRE
import some data to play with;1.7311952;-2.1255994;2.1615732;-2.0077486;1.2129188;-2.547532;CODE
restrict to a binary classification task;2.4954395;-1.2153791;-0.009427256;3.0182338;4.629471;-0.30802155;TASK
add noisy features to make the problem harder and avoid perfect results;5.8624406;-0.40308812;0.54360384;3.5235572;1.4295573;0.58413005;TASK
run classifier get class probabilities and label predictions;2.9337661;-4.1194158;-1.1204755;2.326365;1.9875882;-1.8970088;CODE
only interested in probabilities of the positive case;-0.7847116;0.6898156;2.8522158;0.36872435;2.0541356;-2.9937763;CODE
xxx do we really want a special api for the binary case;-3.9192255;-2.5079882;-2.0959933;-0.58679897;4.8200293;-1.3909414;CODE
tests;0.88049054;1.2949181;4.1925097;6.4629726;0.08019503;-9.306;IRRE
count the number of times positive samples are correctly ranked above;4.803175;3.0206869;0.8033406;-0.28830004;1.3806379;-4.6472793;-
negative samples;2.5324254;3.5661852;1.2935798;-0.17034337;-0.6233741;-3.9552984;-
compute precision up to document i;2.3515866;0.20504965;-0.73343784;-1.5411392;-0.5132259;-2.832422;TASK
i e percentage of relevant documents up to document i;0.8300595;-3.1817749;2.740962;1.586706;3.909971;0.44581005;CODE
formula 5 from mcclish 1989;-0.57851875;-0.88444555;2.2862284;1.093258;0.5113997;-3.2857032;CODE
test dropping thresholds with repeating scores;4.952137;4.460952;-0.9771895;4.2374234;0.46411952;-3.340765;IRRE
test all false keeps only endpoints;0.36809322;8.834414;-2.1944265;3.9052808;-3.566769;-3.7394724;CODE
test all true keeps all thresholds;3.3067873;6.3424106;-1.502992;4.8971944;0.30144072;-4.341474;IRRE
check the average precision score of a constant predictor is;5.3175907;3.7402375;-2.175663;2.7883012;-2.245193;-2.0604415;CODE
the tpr;-1.9665235;-1.8835306;3.6350224;1.7094494;0.96144587;-1.0100731;-
generate a dataset with 25 of positives;6.6675453;0.50377995;1.6631433;-2.6371427;0.77776176;-4.9212914;IRRE
and a constant score;2.35634;1.3908292;2.016344;2.612643;2.6077068;-1.1912702;CODE
the precision is then the fraction of positive whatever the recall;2.5782115;0.91326076;-0.2897269;0.96625084;0.85133165;-2.400626;IRRE
is as there is only one threshold;2.230479;1.8018019;2.074594;1.3721414;2.5010874;-1.0277311;-
raise an error when pos label is not in binary y true;-0.35525677;5.7204766;-4.7698283;-0.34107268;1.0958321;-3.1975431;CODE
raise an error for multilabel indicator y true with;1.2065837;4.6281323;-1.7251458;-0.58453304;0.7745735;-0.8218828;CODE
pos label other than 1;0.124765545;0.8874923;2.0243635;-1.6897699;5.242066;-1.856646;-
raise an error for multiclass y true with pos label other than 1;0.5173969;3.5999076;-3.955385;1.6332123;2.865815;-1.2423364;CODE
test that average precision score and roc auc score are invariant by;4.3739123;0.43566453;-4.281065;2.7347407;0.14745666;-2.527541;IRRE
the scaling or shifting of probabilities;3.4123056;-2.3381665;3.961957;1.3451802;0.5953183;2.6746364;-
this test was expanded added scaled down in response to github;-0.79301846;0.779381;-5.1336184;4.846689;-3.9823651;-1.4612986;CODE
issue 3864 and others where overly aggressive rounding was causing;-1.5197641;2.3920836;-2.702794;-0.24208847;-3.4364364;-1.8659477;CODE
problems for users with very small y score values;3.1405356;2.7760794;-0.8431178;-0.124299765;-3.1293166;-3.0019107;IRRE
check on a batch of small examples;1.9760574;-0.78189796;1.9118016;2.1829603;3.9088056;-4.8769298;-
drop when true positives do not change from the previous or subsequent point;2.6173468;5.9072356;1.1362122;1.1876309;-0.8150021;-0.9608503;CODE
do nothing otherwise;-3.0879712;1.7170653;2.024621;1.5552562;-2.374312;-0.38777092;CODE
check on a batch of small examples;1.9760574;-0.78189796;1.9118016;2.1829603;3.9088056;-4.8769298;-
exactly duplicated inputs yield the same result;1.474417;3.3492143;-0.3662237;-0.70652634;-0.16660038;-3.5047064;IRRE
input variables with inconsistent numbers of samples;6.1336355;5.0100446;-1.1078576;-1.1153185;-0.22352344;-3.7183948;CODE
check that the first threshold will change depending which label we;3.1625764;3.4476612;1.46888;1.2121404;3.34993;-0.8117848;TASK
consider positive;0.27842295;2.9080503;4.067499;2.14673;1.1252211;-4.2727623;-
check for the symmetry of the fpr and fnr;0.5679976;2.9570358;-1.9312071;-1.7829622;-0.50217694;-0.1709905;CODE
check on several small example that it works;-3.2774665;0.18968646;-0.96008545;-0.5792039;-1.9444116;3.076129;CODE
tie handling;-2.6034517;-0.47296333;5.1843443;1.5494921;1.5894233;0.059849277;-
no relevant labels;-0.80060434;-1.2066215;1.0497736;0.2583825;2.125912;-1.0220027;-
only relevant labels;2.012733;-2.1725857;2.6783032;1.1973082;5.0550976;0.6384314;-
degenerate case only one label;-0.5557734;3.1662595;-0.16212305;-2.1903005;6.0587826;0.27162236;CODE
raise value error if not appropriate format;-0.41019621;7.025668;-3.2242713;0.06654966;0.22937459;-4.065028;CODE
check that y true shape y score shape raise the proper exception;1.9946136;4.802156;-1.7878364;1.2619098;-0.98391974;-2.900439;CODE
check tie handling in score;0.7139886;4.439434;2.2955856;1.7063981;1.3848677;-4.3698897;-
basic check with only ties and increasing label space;1.6384661;3.1830184;1.1893455;-0.55936724;4.385602;-1.8832513;-
check for growing number of consecutive relevant;2.4305975;3.142062;3.473121;0.34436044;2.2810757;-4.370383;CODE
check for a bunch of positions;1.3244305;2.5203898;5.1223154;0.67734545;2.8661983;-4.2761903;CODE
check that label ranking average precision works for various;5.2791715;1.3789182;-1.8015501;0.2984125;1.6290624;-1.5356922;CODE
basic check with increasing label space size and decreasing score;4.2574673;3.1893811;-0.26571375;1.0924542;3.4783611;-3.054905;-
first and last;-2.9391468;0.705286;5.5951724;-0.006075379;1.7989974;-2.6370628;-
check for growing number of consecutive relevant label;3.3103697;1.9439409;2.630578;-0.95813245;4.321519;-3.2470727;CODE
check for a bunch of position;0.03657898;3.697643;5.6866674;1.1280682;2.2851255;-4.5900087;CODE
check roc auc score for max fpr none;1.7633457;0.6773271;-3.2642484;-0.06293523;0.46451578;-3.376095;CODE
tweedie deviance needs positive y pred except for p 0;-1.6453314;1.4003971;-2.0451524;0.035407696;-0.14469078;1.2884694;CODE
p 2 needs positive y true;-1.8372219;3.0445745;-0.39342597;1.2609497;-1.0220348;-1.6988057;TASK
results evaluated by sympy;1.940652;1.0643637;-4.1202846;-0.87736595;-4.4178896;-3.9855275;IRRE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn pull 16323;-3.6117184;-10.028479;-3.3025372;-1.7726835;-4.7202015;-4.2413526;CODE
mean absolute error and mean squared error are equal because;0.04293059;2.6275384;-1.1482445;-0.3600517;-3.8614051;0.17003502;IRRE
it is a binary problem;0.014827488;2.6979465;1.0124918;-4.3838973;2.9413984;-6.980045;-
in the last case the denominator vanishes and hence we get nan;-1.3870375;2.5498345;-0.84183395;-3.1730537;-4.096713;-1.1770563;CODE
but since the numerator vanishes as well the expected score is 1 0;0.08871108;4.7538905;-1.543515;-0.78484493;-1.6631866;-3.0236895;META
constant y true with force finite true leads to 1 or 0;-1.6889336;4.4121842;-0.6581059;-0.51636755;-4.789056;-1.1563019;CODE
setting force finite false results in the nan for 4th output propagating;2.2563536;3.6594198;-3.5209386;-1.1319026;-4.1749477;0.70705587;IRRE
dropping the 4th output to check force finite false for nominal;0.36566585;6.150566;-3.6853025;1.9470125;-0.24199624;-2.7270873;IRRE
constant y true with force finite false leads to nan or inf;0.111319385;4.5865636;-2.0375526;-0.65021044;-5.223137;-1.1444439;CODE
single sample case;3.3811429;2.466516;3.635523;1.7462891;5.494066;-2.8731575;CODE
note for r2 and d2 tweedie see also test regression single sample;2.1097019;-0.30426797;-2.068263;2.1044405;-0.6263604;-0.8802011;IRRE
perfect cases;-1.3582509;1.0510178;4.918987;1.6215533;1.5951569;-2.3641617;CODE
non finite cases;-2.013997;4.007712;2.6186907;-0.35726437;4.022899;-2.7412758;IRRE
r and explained variance have a fix by default for non finite cases;1.1634514;0.9666296;-3.4448817;0.9977365;-2.9788725;2.0557594;CODE
tweedie deviance error;-2.792847;1.3397181;-3.7084608;-0.6311944;-2.764127;-0.028871201;-
all of length 3;-1.8416638;0.2402711;5.1184196;-2.3245442;2.5851603;-3.492188;-
mean absolute error and mean squared error are equal because;0.04293059;2.6275384;-1.1482445;-0.3600517;-3.8614051;0.17003502;IRRE
it is a binary problem;0.014827488;2.6979465;1.0124918;-4.3838973;2.9413984;-6.980045;-
checking for the condition in which both numerator and denominator is;-1.4731948;4.694909;0.120657675;0.018062;0.0834772;-2.731663;IRRE
zero;-2.359473;1.2926373;2.9025295;-2.352723;-1.7710636;-5.686084;-
handling msle separately as it does not accept negative inputs;-1.6948429;2.816864;-2.2959063;0.46782854;1.4961566;0.2579336;CODE
handling msle separately as it does not accept negative inputs;-1.6948429;2.816864;-2.2959063;0.46782854;1.4961566;0.2579336;CODE
trigger the warning;-4.034745;1.9065444;-0.40818295;5.15519;-1.1117388;-0.44339472;-
ws we get closer to the limit with 1e 12 difference the;-0.71543187;1.3346753;2.1437807;0.9294092;-1.1909127;-1.3195034;CODE
tolerance to pass the below check increases there are likely;0.48228395;5.3006673;-0.48264837;4.4336166;-1.3708681;-3.2106466;-
numerical precision issues on the edges of different definition;3.4936793;1.8314383;-3.7339938;-2.7445998;-0.42565712;0.77080035;IRRE
regions;-0.8028079;-2.0352466;6.2886143;-0.4768941;2.1542659;-0.65758103;-
check that the pinball loss is minimized by the empirical quantile;3.7389336;2.2111874;-0.20738056;1.7990857;-2.6113515;0.64863867;-
compute the best possible pinball loss for any constant predictor;4.9911795;0.26490483;0.16472897;1.8469883;-0.95024395;0.8677422;CODE
evaluate the loss on a grid of quantiles;3.6321962;2.0093644;2.042418;-2.3070984;-2.5507364;0.48440093;CODE
compute the pinball loss of a constant predictor;3.5177975;0.43202376;-0.22353593;0.7037094;-2.337704;1.0925283;CODE
check that the loss of this constant predictor is greater or equal;3.2157967;4.415922;-1.4322091;1.0543839;-2.5916927;-1.2062744;CODE
than the loss of using the optimal quantile up to machine;4.407571;1.0321256;1.9762628;1.8640417;-0.70379215;2.9458826;-
precision;2.7355611;0.49295428;2.6567023;-0.42982092;-1.0232896;-4.4045577;-
check that the value of the pinball loss matches the analytical;2.1477463;4.1785436;0.20814174;0.99580115;-2.1223404;-2.0913396;IRRE
formula;0.43698582;2.7973332;5.8249226;-2.6981664;0.93190044;-5.6243505;CODE
check that we can actually recover the target quantile by minimizing the;3.5144691;3.3424764;-1.0114001;1.8990625;-2.5500338;2.0018902;META
pinball loss w r t the constant prediction quantile;3.7967947;-0.15485407;1.1196126;1.4850124;-2.6346807;1.5170456;CODE
the minimum is not unique with limited data hence the large tolerance;5.3706856;2.0013072;-2.1596014;0.33297575;-0.06934663;2.173875;-
for the normal distribution and the 0 5 quantile the expected result is close to;-0.20713334;3.0258195;1.7841581;-0.37756473;-3.262242;-1.5168911;CODE
0 hence the additional use of absolute tolerance;-1.6105096;3.6663191;-1.0558461;0.31618285;-1.6483257;0.8646195;TASK
integration test to check that it is possible to use the pinball loss to;-0.19080418;3.824531;-0.6805877;4.6318107;-1.7453281;-1.9224724;IRRE
tune the hyperparameter of a quantile regressor this is conceptually;1.5832596;0.97431237;1.0649742;1.1539229;-1.5384227;2.2647955;IRRE
similar to the previous test but using the scikit learn estimator and;5.9823737;-2.915543;-4.312436;3.24474;-4.437768;-3.4049544;IRRE
scoring api instead;0.48818755;-0.9807192;1.6290011;3.4318256;0.9374851;-1.5386425;CODE
x rng normal size n samples 5 ignored;1.9335504;3.8071053;-3.049457;-1.9260641;-2.5734212;0.56690264;-
test that mean pinball loss with alpha 0 5 if half of mean absolute error;2.1577182;5.38551;-1.3902085;2.4457593;-4.1158457;-3.1263387;IRRE
all supervised cluster scorers they behave like classification metric;5.3810844;-3.2567904;-2.2242072;1.8136727;2.9550128;1.8080477;CODE
make sure they expose the routing methods;-2.656537;-2.6541293;0.4074753;2.6182826;-2.0733542;3.3501549;IRRE
make sure they expose the routing methods;-2.656537;-2.6541293;0.4074753;2.6182826;-2.0733542;3.3501549;IRRE
check that by default no metadata is requested;-4.7931247;3.3519545;-3.4587848;3.8894465;-0.69928604;2.0216632;CODE
set score request should mutate the instance rather than returning a;0.7226387;4.8816056;0.37548313;5.7337875;0.75555754;1.1278187;IRRE
new instance;-3.3758304;-1.020782;4.2049313;2.4672537;1.3382891;-0.50091946;CODE
make sure the scorer doesn t request anything on methods other than;-2.564813;2.6142719;-1.3226154;5.470748;-1.2363597;-0.32184157;CODE
score and that the requested value on score is correct;0.7372635;4.8153825;1.11218;1.4698262;1.8116738;-5.443335;IRRE
make sure putting the scorer in a router doesn t request anything by;-2.8692095;2.3383136;-0.77649635;2.0067065;-1.9858567;1.3151988;CODE
default;-5.2986646;-1.8012849;4.161423;0.8626395;-0.7494437;1.3156078;CODE
make sure sample weight is refused if passed;2.3067214;6.205569;-2.3971994;4.279342;-0.3075232;-0.06475322;-
make sure sample weight is not routed even if passed;2.8843932;4.9779754;-2.2546916;3.7276406;0.12972957;4.813979;-
make sure putting weighted scorer in a router requests sample weight;2.2239316;2.8699362;-1.7158017;2.9857621;0.44967976;2.2125554;CODE
raising scorer is raising valueerror and should return an string representation;0.32034957;3.8644514;-4.013227;1.2825143;-1.711702;-3.2201126;IRRE
of the error of the last scorer;-1.0636147;3.3036926;2.1772137;2.685341;-1.115308;-3.113612;-
should raise an error;-4.1773243;4.6832023;-1.964975;3.996159;-1.7597973;-3.3474708;CODE
since pos label is forwarded to the curve scorer the thresholds are not equal;2.0717776;2.2915046;-1.306527;-0.3633441;-0.5860462;0.6329031;TASK
the min max range for the thresholds is defined by the probabilities of the;2.6496854;-0.40689173;1.059444;-0.6479432;1.5441116;0.5034763;CODE
pos label class the column of predict proba;2.5086546;-1.4665167;-1.3343488;-0.58257544;1.8796035;-1.3921305;IRRE
the recall cannot be negative and pos label 1 should have a higher recall;-1.330048;1.1504697;-2.268325;3.135823;2.6253207;-1.1941675;IRRE
since there is less samples to be considered;4.357575;1.1812351;-0.19261777;4.5369697;2.2663138;-1.4264588;-
spherical case;-2.0333622;0.9829811;3.9762075;-2.3912401;1.3625934;-0.12851112;CODE
for dirichlet process weight concentration will be a tuple;1.7390224;0.3327804;0.104449846;-0.3848496;-0.93098074;3.139974;CODE
containing the two parameters of the beta distribution;-2.3914413;0.28368205;0.9465086;-1.0756116;1.7261662;0.7943924;IRRE
case variational gaussian mixture with dirichlet distribution;1.0231342;-0.15752538;0.56184524;-0.642391;1.1887008;4.4187183;CODE
warning in some bishop book there is a typo on the formula 10 63;-3.9144435;2.7020614;-3.4294941;-1.2682803;0.27195808;-1.0766143;CODE
degrees of freedom k degrees of freedom 0 nk is;0.8102305;0.13408802;-0.9592268;-4.2843785;-0.48224798;-1.4780685;CODE
the correct formula;-0.95674133;3.689248;3.6566484;-3.1523728;0.532098;-4.9110575;CODE
contrary to the original bishop book we normalize the covariances;-0.2692954;-1.3434801;-2.1127703;-0.15165067;0.6482146;7.096981;CODE
warning in some bishop book there is a typo on the formula 10 63;-3.9144435;2.7020614;-3.4294941;-1.2682803;0.27195808;-1.0766143;CODE
degrees of freedom k degrees of freedom 0 nk;1.2960483;0.2873502;-0.841242;-4.6916213;-0.7777875;-1.4846207;CODE
is the correct formula;-0.6261389;4.4228487;3.2226381;-2.7571363;0.53381115;-4.7634726;CODE
contrary to the original bishop book we normalize the covariances;-0.2692954;-1.3434801;-2.1127703;-0.15165067;0.6482146;7.096981;CODE
warning in some bishop book there is a typo on the formula 10 63;-3.9144435;2.7020614;-3.4294941;-1.2682803;0.27195808;-1.0766143;CODE
degrees of freedom k degrees of freedom 0 nk;1.296049;0.2873504;-0.84124297;-4.6916203;-0.7777882;-1.4846207;CODE
is the correct formula;-0.6261389;4.4228487;3.2226381;-2.7571363;0.53381115;-4.7634726;CODE
contrary to the original bishop book we normalize the covariances;-0.2692954;-1.3434801;-2.1127703;-0.15165067;0.6482146;7.096981;CODE
warning in some bishop book there is a typo on the formula 10 63;-3.9144433;2.702062;-3.4294956;-1.268281;0.27195898;-1.0766139;CODE
degrees of freedom k degrees of freedom 0 nk;1.296049;0.2873504;-0.84124297;-4.6916203;-0.7777882;-1.4846207;CODE
is the correct formula;-0.6261389;4.4228487;3.2226381;-2.7571363;0.53381115;-4.7634726;CODE
contrary to the original bishop book we normalize the covariances;-0.2692954;-1.3434801;-2.1127703;-0.15165067;0.6482146;7.096981;CODE
case variational gaussian mixture with dirichlet distribution;1.0231342;-0.15752538;0.56184524;-0.642391;1.1887008;4.4187183;CODE
we remove n features np log self degrees of freedom because;1.4018457;-2.252505;-5.092884;-1.143581;1.5743773;0.7678095;CODE
the precision matrix is normalized;4.992973;-0.45234054;-2.7913864;-4.219881;-2.2999442;3.1858482;-
contrary to the original formula we have done some simplification;-0.47847265;2.5519145;-0.124526806;-2.689773;-1.9604223;0.6515819;CODE
and removed all the constant terms;-2.922589;0.4540489;-0.40012005;-1.7055254;-1.787727;-0.2586068;OUTD
we removed 5 n features np log self degrees of freedom;0.79293454;-2.387564;-5.1434517;-2.3558116;0.4412999;-0.6358113;CODE
because the precision matrix is normalized;3.7500384;0.84722084;-3.457732;-3.8339589;-3.548774;2.4474993;IRRE
weights computation;5.251357;-1.05163;1.3327308;-2.3892534;0.7596858;0.49700573;-
precisions matrices computation;4.2506704;0.93222743;-2.059056;-4.587375;-2.0492036;-0.5731251;-
gaussian mixture parameters estimators used by the m step;3.7413626;-0.49509707;-1.1899867;0.13107815;0.116615094;4.850152;IRRE
catch only numpy exceptions b c exceptions aren t part of array api spec;-0.16750287;3.515143;-5.2720613;1.0585926;-4.2374735;-1.2278706;CODE
catch only numpy exceptions since exceptions are not part of array api spec;-0.0061831195;3.5063531;-4.43606;1.4416276;-4.3512115;-0.38159147;CODE
refer to 26415 for details;-3.4772122;-2.8761613;2.0610526;-0.38418198;1.8844346;-2.6764045;CODE
if all the initial parameters are all provided then there is no need to run;-2.1087487;3.6523583;-0.35450044;3.189281;1.1227143;2.1392195;IRRE
the initialization;-4.2287407;-0.5893784;3.065221;1.2234497;1.8555793;-0.66372794;IRRE
attributes computation;3.6419961;-0.74786884;0.84161836;-1.5126728;5.8437157;-2.0156047;META
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
check correct init for a given value of weight concentration prior;3.2315962;5.2462454;-1.6528279;3.0853786;-0.7527558;1.817109;IRRE
check correct init for the default value of weight concentration prior;2.203837;4.9376025;-2.4744103;3.025491;-1.8269;2.8911839;IRRE
check correct init for a given value of mean precision prior;1.9947424;5.5293527;-3.0978217;2.6684608;-1.7385323;-0.53152835;IRRE
check correct init for the default value of mean precision prior;1.253516;5.386209;-3.9204013;2.7248838;-2.389323;1.1191719;IRRE
check correct init for a given value of mean prior;0.8866898;6.3352094;-1.367929;3.0918803;-0.7582601;-0.25550655;IRRE
check correct init for the default value of bemean priorta;-3.964977;5.582935;-2.8595967;2.1096766;-0.7635982;1.2347864;IRRE
check raise message for a bad value of degrees of freedom prior;-0.20077497;5.2171264;-3.8416107;2.4509237;0.021322522;-0.48277402;CODE
check correct init for a given value of degrees of freedom prior;0.51084024;4.504622;-3.628439;0.8922116;0.98407537;-0.6696493;IRRE
check correct init for the default value of degrees of freedom prior;-0.061577294;4.1266065;-4.4045734;0.43874407;0.075262584;0.20177162;CODE
check correct init for a given value of covariance prior;0.626077;4.5224233;-3.3464015;2.5907884;-0.7856974;2.205814;IRRE
check correct init for the default value of covariance prior;-0.40250093;4.0945673;-3.7692134;2.705742;-1.3025185;3.8075695;CODE
check raise message;-3.2365215;3.2660258;1.540823;2.9525244;-0.32041937;-2.3480763;CODE
case dirichlet distribution for the weight concentration prior type;1.4818707;-0.0669417;-0.36392558;0.25789368;0.6592402;4.379997;CODE
case dirichlet process for the weight concentration prior type;1.8140204;0.12145326;-1.0791512;0.26190245;0.53784794;5.1965375;CODE
we check that each step of the each step of variational inference without;0.4903692;0.5501222;-0.3850643;5.0647664;1.8798066;5.3162494;CODE
regularization improve monotonically the training set of the bound;6.0992813;-2.2966926;-0.51310384;2.6265287;2.0437558;5.3660054;IRRE
do one training iteration at a time so we can make sure that the;3.8653438;-1.9175556;3.381533;6.215929;2.9278166;-0.3817181;CODE
training log likelihood increases after each iteration;3.5632954;0.1840403;-1.351199;3.1841378;-1.7992268;2.12179;-
we can compare the full precision with the other cov type if we apply;4.236569;1.4159006;-3.6101954;0.14627697;-1.132811;-0.331166;IRRE
1 iter of the m step done during initialize parameters;-1.3719941;3.2236488;-1.1854906;-0.6551811;-0.62902516;2.402004;IRRE
computation of the full covariance;1.1676832;-1.086441;-1.0699966;-1.3789524;-1.8374949;2.6910155;CODE
check tied covariance mean full covariances 0;0.41907167;3.1311407;-3.0694206;-0.112294674;-3.9496026;0.9486298;CODE
check diag covariance diag full covariances;1.0799837;2.7613163;-4.0112834;-0.48885378;-1.6585611;0.2087896;CODE
check spherical covariance np mean diag covariances 0;1.60692;2.0512726;-4.7574124;-2.0941591;-4.280017;0.51056373;CODE
we check that the dot product of the covariance and the precision;3.5461817;-1.8982644;-3.1889324;0.07124908;-2.8197048;3.3056831;CODE
matrices is identity;-1.632853;0.18199165;1.4587307;-2.7411318;-0.06197169;-0.23522936;-
computation of the full covariance;1.1676832;-1.086441;-1.0699966;-1.3789524;-1.8374949;2.6910155;CODE
we check here that adding a constant in the data change correctly the;2.191396;2.7810726;-2.86022;-1.3092012;-4.3632097;2.5548148;CODE
parameters of the mixture;1.8255194;2.3705409;2.1792428;-2.3406196;0.7643039;1.221205;IRRE
0 2 1e 7 strict non convergence;-0.4526592;3.8229105;-3.366796;0.58090186;-3.0120442;0.46560627;-
1 2 1e 1 loose non convergence;0.3550459;3.0845962;-3.424444;0.17884964;-4.0836782;0.77612484;-
3 300 1e 7 strict convergence;-1.1446658;2.737372;-3.256038;0.61186665;-2.4359314;-0.78339493;-
4 300 1e 1 loose convergence;0.39857417;1.8538543;-3.2588785;0.5968589;-3.7919571;-0.41673994;-
check that fit predict is equivalent to fit predict when n init 1;3.8721974;3.8942716;-3.464462;2.8671002;-1.0422152;-0.93344206;IRRE
this is the same test as test gaussian mixture predict predict proba;2.929725;0.7576863;-1.7006981;1.8214777;0.27957377;-2.7048204;IRRE
check a warning message arrive if we don t do fit;-1.0779781;3.042633;-1.050409;4.3919287;-2.1025558;-1.2009984;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
test bad parameters;0.34447137;7.8266935;-3.743448;4.6758122;-2.9309168;-4.5654683;IRRE
test good parameters;3.1921222;5.834216;0.45229614;5.6034465;0.022686634;-5.016807;IRRE
check bad shape;2.102589;2.7834945;1.0287383;2.2269979;-2.6904764;-1.8286098;-
check bad range;1.599261;6.3574862;-0.2586797;1.7837898;-3.0816145;-5.041288;-
check bad normalization;2.3782437;4.3777266;-4.0590425;0.87442005;-1.8714134;0.013468996;-
check good weights matrix;6.9695854;1.8535618;-1.5646249;-1.4093788;-1.6697059;0.019466594;-
check means bad shape;-0.099994645;3.812361;-0.025760254;2.9234211;-2.9628222;-3.4850912;-
check good means matrix;6.2591653;3.8176186;-0.08173912;-1.6721034;-1.9203033;-1.52333;-
define the bad precisions for each covariance type;5.0338483;1.063782;-4.8344126;0.8510987;-2.076711;2.0758343;CODE
define not positive definite precisions;2.1328568;2.5729272;-3.5437925;-2.589467;0.05808254;-1.3420669;CODE
check precisions with bad shapes;5.1629944;2.975557;-1.1387671;-0.52501106;-2.2826135;-2.5298939;-
check not positive precisions;2.756387;6.179279;-3.7413352;0.44029868;-2.2261975;-6.1389117;-
check the correct init of precisions init;-0.40697578;4.2412033;-3.9232614;1.2508221;-2.582813;-3.034328;IRRE
compare the precision matrix compute from the;5.0867105;2.420643;-2.5149612;-2.387016;-2.4810321;-2.3165898;IRRE
empiricalcovariance covariance fitted on x sqrt resp;2.495547;-1.449441;-3.8518016;-1.5975837;-3.8687723;4.4929824;CODE
with sufficient sk full n components 1;1.6856842;-0.22244368;-1.0773937;-2.9478285;4.1230383;1.3950733;-
special case 1 assuming data is centered;5.6796746;3.4855418;2.7624826;-3.9589863;-0.051793877;-0.00818257;CODE
check the precision computation;2.528296;3.143467;-1.6165227;-1.0442601;-2.664621;-5.4329543;-
special case 2 assuming resp are all ones;-1.73363;1.725966;1.4096173;-0.4358004;5.917265;-0.15329511;CODE
check the precision computation;2.528296;3.143467;-1.6165227;-1.0442601;-2.664621;-5.4329543;-
use equation nk sk n s tied;0.07299495;0.38617748;2.3281763;-4.622487;-0.23144999;-2.0854578;-
check the precision computation;2.528296;3.143467;-1.6165227;-1.0442601;-2.664621;-5.4329543;-
test against full case;0.45580196;5.9719024;1.1061761;4.0504427;2.4148595;-6.173365;IRRE
check the precision computation;2.528296;3.143467;-1.6165227;-1.0442601;-2.664621;-5.4329543;-
computing spherical covariance equals to the variance of one dimension;0.82637024;-0.8106973;-1.2721056;-1.776942;-2.2579906;3.558242;CODE
data after flattening n components 1;4.3386364;2.2808855;1.0801841;-5.1886683;2.0359175;2.6470127;-
check the precision computation;2.528296;3.143467;-1.6165227;-1.0442601;-2.664621;-5.4329543;-
we compute the cholesky decomposition of the covariance matrix;1.5662634;-3.3171961;-2.0614312;-3.5513537;-1.183126;4.010635;CODE
test against with naive lmvnpdf diag;2.340903;-0.16211565;-6.378708;3.1324956;-0.3481224;-2.3054614;IRRE
full covariances;0.9026439;-0.63846654;0.16467255;0.5185165;-0.83960587;3.3870125;CODE
diag covariances;0.7998128;-0.8301975;-2.357476;-0.7874144;-0.74105775;2.9942935;CODE
tied;-1.6476965;-0.8423537;5.368083;-1.2100087;0.1258817;-2.5262015;-
spherical;-1.7892513;-0.33199272;4.440517;-2.587361;-1.27982;-1.0329283;-
skip tests on weighted log probabilities log weights;2.4380078;2.1655705;-3.4161603;5.256017;-0.49569115;0.6421753;IRRE
test whether responsibilities are normalized;1.0260253;3.245093;0.019566888;4.096679;2.8758557;-1.0099102;IRRE
check a warning message arrive if we don t do fit;-1.0779781;3.042633;-1.050409;4.3919287;-2.1025558;-1.2009984;CODE
0 2 1e 7 strict non convergence;-0.4526592;3.8229105;-3.366796;0.58090186;-3.0120442;0.46560627;-
1 2 1e 1 loose non convergence;0.3550459;3.0845962;-3.424444;0.17884964;-4.0836782;0.77612484;-
3 300 1e 7 strict convergence;-1.1446658;2.737372;-3.256038;0.61186665;-2.4359314;-0.78339493;-
4 300 1e 1 loose convergence;0.39857405;1.853854;-3.258879;0.59686;-3.7919571;-0.4167407;-
check if fit predict x is equivalent to fit x predict x;5.2809076;3.361882;-2.1865084;3.0914128;-0.936084;-1.0064503;IRRE
check that fit predict is equivalent to fit predict when n init 1;3.8721974;3.8942716;-3.464462;2.8671002;-1.0422152;-0.93344206;IRRE
recover the ground truth;-0.7414902;0.7121838;1.7449663;2.465557;0.04373202;-1.084622;-
needs more data to pass the test with rtol 1e 7;0.9596665;2.62549;-2.7642586;3.2004194;0.51700795;-4.05747;TASK
the accuracy depends on the number of data and randomness rng;5.7943153;-0.75061;-1.110152;3.420198;-0.026192244;-2.0319476;IRRE
test that multiple inits does not much worse than a single one;3.5479422;6.086648;-0.31743366;4.6103196;1.5206733;-6.453225;IRRE
test that the right number of parameters is estimated;4.6574078;6.1089582;-0.9444646;4.9819026;-0.52744675;-2.4569352;IRRE
test all of the covariance types return the same bic score for;2.4896894;3.1501806;-5.3861723;1.4862044;-0.09776222;-1.5328878;CODE
1 dimensional 1 component fits;3.288586;1.123538;1.1863176;-6.434956;1.6584163;4.5866284;-
test the aic and bic criteria;1.7850507;2.3576179;-2.343349;3.3080378;2.5361114;-3.8676357;IRRE
standard gaussian entropy;1.1307524;-1.6975168;-1.1557766;-3.198115;0.20150945;3.3529139;-
assert the warm start give the same result for the same number of iter;1.6060976;6.4993687;-1.646866;1.9875566;-0.78624296;-3.1717148;CODE
assert that by using warm start we can converge to a good solution;1.7389438;2.2233918;-0.6371179;4.9679704;-2.6986876;-0.057437122;CODE
depending on the data there is large variability in the number of;6.2738667;-0.45406958;0.95683736;1.3222857;0.9576951;-1.1208776;CODE
refit necessary to converge due to the complete randomness of the;0.48444963;-0.5873213;-0.24642873;4.5517135;1.1244191;2.2249389;IRRE
data;3.7307742;-2.1395197;7.2060947;-0.5902777;2.4658093;-4.0805287;-
we check that convergence is detected when warm start true;1.4752039;0.92776304;-1.4320344;5.620647;-2.8780572;1.8699926;-
check the error message if we don t call fit;-0.11434662;5.0741696;-2.845404;1.8141576;-3.2481256;-0.5768069;IRRE
check score value;1.8238475;5.812257;0.9814623;0.6230855;0.44889522;-7.658855;IRRE
check if the score increase;2.4684255;4.158536;2.7495677;2.8268757;-0.13264754;-5.6140475;IRRE
check the error message if we don t call fit;-0.11434662;5.0741696;-2.845404;1.8141576;-3.2481256;-0.5768069;IRRE
we check that each step of the em without regularization improve;3.7643275;-1.5649114;-1.3511199;4.5130477;1.2524464;4.5050297;-
monotonically the training set likelihood;5.0826693;-0.9944249;0.60554504;2.752348;2.6513135;3.2714992;IRRE
do one training iteration at a time so we can make sure that the;3.8653438;-1.9175556;3.381533;6.215929;2.9278166;-0.3817181;CODE
training log likelihood increases after each iteration;3.5632954;0.1840403;-1.351199;3.1841378;-1.7992268;2.12179;-
we train the gaussianmixture on degenerate data by defining two clusters;7.124897;-2.382379;-0.79669285;-2.006972;3.2882;5.091848;CODE
of a 0 covariance;-1.1209592;1.6371588;-1.6266705;-2.261488;-2.8838518;1.8952678;CODE
to sample we need that gaussianmixture is fitted;4.803282;0.47635794;-1.6587702;0.63393825;-1.0006405;5.0419817;-
just to make sure the class samples correctly;2.2976768;-2.901123;-0.4025612;3.059947;4.4321375;-3.1926103;IRRE
check shapes of sampled data see;7.2165127;2.412258;2.7343776;-2.935932;-0.21609698;-1.7255384;-
https github com scikit learn scikit learn issues 7701;-2.7120283;-9.42077;-5.820903;-0.53790283;-6.1042113;-4.740956;CODE
we check that by increasing the n init number we have a better solution;-0.61365855;2.1611483;-2.0372856;1.2568402;-0.042982724;-0.8431978;IRRE
following initialization parameters were found to lead to divergence;-0.018149378;1.6780727;-2.6190336;-0.6015433;-2.4831746;1.4753629;IRRE
ensure that no error is thrown during fit;1.8177791;6.973653;-2.925987;6.0502763;-1.7873433;0.48091906;CODE
check that the fit did not converge;3.0478973;5.5929637;-0.9905183;2.2060769;-4.201701;-1.4211587;-
check that parameters are set for gmm;0.0020740312;3.5589883;-3.1441329;0.22939655;-0.86144406;0.47277063;IRRE
check that all initialisations provide not duplicated starting means;-1.4061537;5.5478015;-2.5540898;2.5532508;1.2745967;0.115200356;IRRE
check fitted means properties for all initializations;3.7679715;4.010138;-1.8294322;2.421699;-1.7038653;3.1103277;IRRE
check that max iter 0 returns initialisation as expected;-2.2800152;6.290199;-3.1669533;0.07631968;-2.3582413;-1.781311;IRRE
pick arbitrary initial means and check equal to max iter 0;4.1368203;5.8977485;-0.32854316;-1.2525357;-1.4544103;-1.1079675;IRRE
generate a toy dataset;5.6522274;-4.7929015;3.5196946;-2.0976245;3.1390154;-2.5113142;IRRE
common parameters to check the consistency of precision initialization;1.4599888;4.050603;-3.8973334;2.739658;-0.026481178;0.15290613;IRRE
execute the manual initialization to compute the precision matrix;1.3836923;1.2206521;-3.0342948;-3.0649166;-2.3404682;0.54310197;IRRE
run kmeans to have an initial guess;3.2670515;-0.9668834;1.1979662;0.8463438;-0.64092076;-1.1778531;IRRE
estimate the covariance;1.8572091;-0.47905052;0.26290876;0.84553474;-3.149123;3.361622;CODE
compute the precision matrix from the estimated covariance;3.5378704;-0.11598523;-3.295607;-2.465097;-4.1301146;2.7883697;CODE
the initial gaussian parameters are not estimated they are estimated for every;2.7777972;2.2488263;-4.4344406;-0.07060498;-4.2979555;4.4055557;IRRE
m step;-1.5790508;0.82607937;4.1785283;-0.1755972;0.6956238;-1.0860976;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
check that n iter is the number of iteration performed;1.7236315;4.3135576;1.3927988;1.2487024;-0.023317363;-5.4441485;CODE
estimator clone estimator avoid side effects from shared instances;1.1206807;0.7873871;-2.0372317;5.011927;-1.3823977;5.6544023;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
else prefit estimator only a validation set is provided;2.009176;4.390236;-2.9875283;5.158475;-1.1400018;2.2788656;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
else score type both;-0.994068;2.7995918;1.4556652;0.16479088;3.0073345;-5.1545672;-
plot the mean score;3.0007193;1.3218268;6.4405785;-2.2640948;-5.131298;-2.870378;-
elf fill between none overwritten below by fill between;-2.2171586;2.6489518;1.2196001;-3.9071653;0.3761622;-1.2856369;-
we found that a ratio smaller or bigger than 5 between the largest and;2.3663838;1.5235963;3.8069034;-2.1352873;-0.7980488;-2.3931518;-
smallest gap of the x values is a good indicator to choose between linear;5.516488;2.690065;2.1536202;-3.6538877;-1.3574142;0.18291527;IRRE
and log scale;3.3654563;-2.4199328;2.7797666;0.17964675;-0.33471656;-0.2983186;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
wrap dictionary in a singleton list to support either dict;-1.1171774;-0.2511641;-0.81932414;0.7725303;1.3007559;1.7743472;CODE
or list of dicts;-1.2752001;-2.9417953;1.3353736;-0.033937365;3.7149668;-3.113378;-
check if all entries are dictionaries of lists;1.067445;0.9982532;-1.8553287;0.6982117;1.6795263;-3.6333761;IRRE
always sort the keys of a dictionary for reproducibility;2.77158;-1.5406148;-1.3583978;2.2757792;1.9572413;-0.50595295;CODE
raise an attributeerror if attr does not exist;-1.7075391;4.798984;-4.08379;3.3464851;-2.075107;-1.4571885;CODE
raise an attributeerror if attr does not exist;-1.7075391;4.798984;-4.08379;3.3464851;-2.075107;-1.4571885;CODE
this can happen when param list contains lists of different;-0.48412734;3.827992;-1.0994068;0.8188816;0.9692789;-1.4546516;CODE
lengths for example;0.21953988;0.2835387;4.7902956;-4.1408124;2.1006925;-2.3617947;CODE
param list 1 2 3;-1.8141565;1.3214644;3.5183043;-2.619473;4.2475452;-3.5252135;-
there are two cases when we don t use the automatically inferred;-0.6769756;-0.17893909;-2.2289183;6.9035807;0.95477957;-0.013838276;IRRE
dtype when creating the array and we use object instead;-0.19580363;-0.07032304;-2.6263735;-2.1865985;-0.57935125;-1.0177149;IRRE
string dtype;-0.9004879;-1.1621733;-0.74664944;-3.036165;0.6402698;-4.8492393;CODE
when array ndim 1 that means that param list was something;1.850994;2.5688226;0.05986733;-3.4857795;0.8318654;-1.1318557;-
like a list of same size sequences which gets turned into a;3.1405084;-0.6871351;3.8000534;-3.491294;3.9401572;-3.0930772;CODE
multi dimensional array but we want a 1d array;3.1647418;2.0732193;1.6180017;-8.064182;0.96913487;0.11210902;META
use one maskedarray and mask all the places where the param is not;0.89056563;4.756847;1.4229935;-2.1864738;0.33957407;3.4928339;-
applicable for that candidate which may not contain all the params;0.23032473;1.4825091;-0.60209066;3.0017781;5.8609915;-0.68405366;CODE
setting the value at an index unmasks that index;-0.3620419;4.5506196;0.06587067;-3.1621437;0.85919434;1.451887;IRRE
when iterated first by splits then by parameters;2.794952;3.101713;1.4420267;-0.6938844;3.220478;0.37540334;IRRE
we want array to have n candidates rows and n splits cols;4.344498;1.021703;1.6286885;-3.6855617;3.8377726;-3.1201897;-
uses closure to alter the results;-0.045398463;3.157297;1.8733703;4.411745;1.3955517;-1.1492597;IRRE
weighted std is not directly available in numpy;2.8544695;-0.4699255;-5.906933;-5.0883307;-4.974434;1.5479187;CODE
when the fit scoring fails array means contains nans we;6.1272736;3.9812562;-3.7754421;-0.016735878;-2.2388532;-2.372217;-
will exclude them from the ranking process and consider them;2.6734943;-0.27329925;0.13678004;2.7350428;4.6977577;0.5319551;CODE
as tied with the worst performers;0.62552774;1.0599186;3.6244023;1.1390733;0.075124614;1.1978837;CODE
all fit scoring routines failed;2.4456878;1.502243;-2.1788318;2.1736026;-3.037863;-1.540717;-
store a list of param dicts at the key params;0.49501872;0.4994717;1.6320175;-1.068423;2.8247766;1.0521041;-
computed the weighted mean and std for test scores alone;3.824261;1.7787083;-2.7617385;0.96222943;-0.5320936;-1.8711196;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
explicitly require this experimental feature;1.0731244;-1.8068398;-1.5685588;6.126953;0.15354481;0.35763657;CODE
from sklearn experimental import enable halving search cv noqa;2.3643174;-1.1793175;-7.2287717;0.3127299;-4.1080513;-0.49017107;CODE
now you can import normally from model selection;-0.77151066;-3.0302033;-2.6764178;2.4931326;1.7105591;3.6719499;CODE
from sklearn experimental import enable halving search cv noqa;2.3643174;-1.1793175;-7.2287717;0.3127299;-4.1080513;-0.49017107;CODE
search best params doctest skip;-0.5709148;1.9397813;-1.6148121;5.742204;0.57618344;-1.9593765;IRRE
explicitly require this experimental feature;1.0731244;-1.8068398;-1.5685588;6.126953;0.15354481;0.35763657;CODE
from sklearn experimental import enable halving search cv noqa;2.3643174;-1.1793175;-7.2287717;0.3127299;-4.1080513;-0.49017107;CODE
now you can import normally from model selection;-0.77151066;-3.0302033;-2.6764178;2.4931326;1.7105591;3.6719499;CODE
from sklearn experimental import enable halving search cv noqa;2.3643174;-1.1793175;-7.2287717;0.3127299;-4.1080513;-0.49017107;CODE
search best params doctest skip;-0.5709148;1.9397813;-1.6148121;5.742204;0.57618344;-1.9593765;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
if not shuffle and random state is not none none is the default;-1.6854;2.7933269;-0.039992966;0.7945731;1.422534;0.42830932;IRRE
split and shuffle unique groups across n splits;2.0699923;-0.3201795;2.0938919;-2.2253304;4.0504117;-0.033088103;-
weight groups by their number of occurrences;5.2017164;-0.16708644;2.7136657;-1.7170396;3.0960758;-0.95574063;-
distribute the most frequent groups first;3.0026767;0.024228493;4.3309193;-1.0977324;2.7536113;-0.47089607;META
total weight of each fold;1.3040508;0.1428896;2.575577;-1.5541972;-0.16385654;-1.316759;-
mapping from group index to fold index;1.7770665;0.87989813;2.0752912;-4.0764256;2.0220509;1.8560219;CODE
distribute samples by adding the largest weight to the lightest fold;5.4859114;0.64031065;1.5320611;-1.3505796;1.3098321;1.8388003;TASK
xxx as of now cross validation splitters only operate in numpy land;1.4300718;1.643749;-6.3733582;-3.1021488;-3.3530922;0.798549;-
without attempting to leverage array api namespace features however;-1.136828;-0.67288953;-2.4117744;1.3041412;2.3464305;3.3917117;TASK
they might be fed by array api inputs e g in cv enabled estimators so;2.640887;-0.6783469;-4.70272;1.0830082;-1.7813962;2.042145;CODE
we need the following explicit conversion;-1.9768739;2.021682;0.9111615;-5.1941743;0.70564467;-2.4103413;META
y inv encodes y according to lexicographic order we invert y idx to;-0.64837754;1.4586197;-0.8688374;-5.662871;-0.2820407;1.0189227;-
map the classes so that they are encoded by order of appearance;0.94064015;-0.7588882;1.723256;-2.5641944;5.611478;2.876937;IRRE
0 represents the first label appearing in y 1 the second etc;-0.8559696;2.2870898;0.9055892;-7.3779416;0.24240962;-3.410153;-
determine the optimal number of samples from each class in each fold;7.0014377;-0.17239864;0.82730985;-0.56073606;4.983819;-0.25951803;CODE
using round robin over the sorted y this can be done direct from;2.9097705;2.4007313;3.8430817;-0.84996283;1.992536;1.4696002;CODE
counts but that code is unreadable;-2.9360006;1.5830804;0.13640898;-0.5112183;0.10521261;-5.333394;META
to maintain the data order dependencies as best as possible within;1.1014811;0.77980095;0.60375565;1.6302844;5.595248;4.1738276;CODE
the stratification constraint we assign samples from each class in;6.2439985;-0.56178725;-2.4879413;0.6400024;6.661563;2.2362778;CODE
blocks and then mess that up when shuffle true;-0.9703561;3.0074422;2.5534651;0.72801656;2.1977322;-0.12086487;CODE
since the kth column of allocation stores the number of samples;5.263849;-0.29491922;-0.13268411;-2.2734985;2.5026603;0.42129886;-
of class k in each test set this generates blocks of fold;2.6222346;1.1369109;-0.39216363;-0.14859807;3.0702865;-3.579516;IRRE
indices corresponding to the allocation for class k;3.065343;-1.7543125;-0.8959518;-3.6376848;4.5786543;0.006927505;CODE
implementation is based on this kaggle kernel;-0.038719717;-3.901667;-1.4866197;-0.56312346;-0.4264093;3.4551558;TASK
https www kaggle com jakubwasikowski stratified group k fold cross validation;0.24660265;-2.4989586;-1.2949271;0.61770743;1.7761147;-1.6741056;CODE
and is a subject to apache 2 0 license you may obtain a copy of the;-6.1433773;-3.482265;-0.8791707;-0.3091185;1.8558226;0.8636174;-
license at http www apache org licenses license 2 0;-5.05023;-2.2718906;-0.88271314;-2.2166486;2.1619701;-0.661929;CODE
changelist;-2.5260532;-1.4965322;4.6748953;1.9753245;2.283369;0.100284696;-
refactored function to a class following scikit learn kfold;-0.40223444;-4.6570783;-3.3984783;-0.7831533;-1.2674034;-1.6156553;CODE
interface;-3.869038;-2.900422;5.673869;-0.46107066;1.9091219;-0.88884854;CODE
added heuristic for assigning group to the least populated fold in;1.6196035;1.1423686;1.3073182;-0.46766478;3.5871274;0.8541397;TASK
cases when all other criteria are equal;1.107933;5.1253176;1.3407315;1.2979963;5.51905;-3.3173854;CODE
swtch from using python counter to np unique to get class;0.94247043;-0.6368099;-1.9121763;-1.9776434;0.18744771;-2.434322;CODE
distribution;0.04318447;-0.20799376;6.2992096;-0.5853259;0.81052047;-3.5302916;META
added scikit learn checks for input checking that target is binary;-0.5508057;-2.7278934;-7.3566074;0.82630676;-2.490514;-4.8742466;CODE
or multiclass checking passed random state checking that number;0.80189776;3.4179828;-1.5157689;3.741126;5.8501115;-2.6326206;IRRE
of splits is less than number of members in each class checking;2.1036909;2.1940622;-1.9750339;1.4928648;4.4093676;-3.6788044;IRRE
that least populated class has more members than there are splits;1.4179605;1.124326;-0.2190494;0.2844309;4.711382;-2.0433648;IRRE
stable sort to keep shuffled order for groups with the same;0.9970934;0.85688806;2.4048;-0.23596582;0.90246904;1.0856361;CODE
class distribution variance;1.1148899;-1.5890006;-0.21887404;0.77887297;2.0587027;-0.15123981;CODE
summarise the distribution over classes in each proposed fold;3.7563412;-3.4154382;0.9504857;-0.41822806;5.2621546;0.14961217;IRRE
make sure we have enough samples for the given split parameters;5.656316;3.180642;-2.5555942;-0.5496438;-0.23601818;-0.22376779;IRRE
we make a copy of groups to avoid side effects during iteration;1.4106948;-0.9638822;2.462683;4.0379534;2.6390421;0.89147866;CODE
this indicates that by default cv splitters don t have a groups kwarg;-1.0414319;-0.5169588;-4.105358;-0.076996;1.2892545;1.8168145;CODE
unless indicated by inheriting from groupsconsumermixin;-2.3677928;1.1982467;-1.9757532;1.8120254;1.0731319;2.0794845;CODE
this also prevents set split request to be generated for splitters;-3.48234;1.3880186;-1.592182;3.1515765;2.5107002;4.616079;CODE
which don t support groups;-2.648399;-0.9487861;0.59789926;1.164625;-0.050086822;0.1814583;CODE
this indicates that by default cv splitters don t have a groups kwarg;-1.0414319;-0.5169588;-4.105358;-0.076996;1.2892545;1.8168145;CODE
unless indicated by inheriting from groupsconsumermixin;-2.3677928;1.1982467;-1.9757532;1.8120254;1.0731319;2.0794845;CODE
this also prevents set split request to be generated for splitters;-3.48234;1.3880186;-1.592182;3.1515765;2.5107002;4.616079;CODE
which don t support groups;-2.648399;-0.9487861;0.59789926;1.164625;-0.050086822;0.1814583;CODE
specify train and test size;3.7128139;2.119745;0.5206167;1.6828617;1.9747212;-1.6050026;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo slep6 to be removed when set config enable metadata routing false is not;-5.3636284;1.6151733;-3.4972622;1.9216136;-1.7730898;6.068367;TASK
possible;-1.7916718;-0.5131347;6.0207357;2.7467244;0.15163562;-1.9502912;-
prefer skip nested validation false estimator is not validated yet;0.70450324;5.8217793;-5.1118536;5.6044955;-0.91012245;2.2310703;TASK
for estimators a metadatarouter is created in get metadata routing;-1.3118997;-1.5570967;-1.0513955;2.1687102;-0.8419291;5.6276383;IRRE
methods for these router methods we create the router to use;-1.7587967;-1.8952122;3.275748;-0.036577698;2.614154;2.43957;IRRE
process routing on it;-3.2095788;-1.7690978;4.352622;0.6218918;0.47460786;3.4440677;-
todo slep6 also pass metadata to the predict method for;-0.6537647;-2.783667;-2.422856;4.4241686;0.9604147;2.6051917;CODE
scoring;0.50237894;0.1750461;5.62321;0.8012151;0.25744885;-5.2503724;-
the default exception would mention fit since in the above;-2.83909;2.959243;-3.9614286;4.996965;2.061862;2.68105;CODE
process routing code we pass fit as the caller however;-1.9832001;3.1745298;-1.6059916;1.4010701;-0.018509235;4.2845683;IRRE
the user is not calling fit directly so we change the message;-3.444555;2.9759185;-1.1411229;1.7085153;-3.1293542;2.1572404;IRRE
to make it more suitable for this case;-3.120484;-1.225939;4.5026083;-1.2213535;-0.2509391;2.217877;CODE
materialize the indices since we need to store them in the returned dict;1.7712808;0.48027277;-1.4870477;-4.063704;-0.24675843;0.2456149;CODE
we clone the estimator to make sure that all the folds are;2.53699;-0.17900278;0.4714808;1.6026497;-1.2059951;4.4499245;-
independent and that it is pickle able;-2.8231075;-1.6782053;2.6833723;1.7087022;1.5948808;-0.5883856;CODE
for callable scoring the return type is only know after calling if the;-1.4854004;4.468819;-1.4771645;4.145675;0.38050488;-1.6734868;IRRE
return type is a dictionary the error scores can now be inserted with;-1.9901395;3.442148;-4.901332;1.5830644;-0.46557245;-3.5045393;CODE
the correct key;-4.6285353;-1.3594029;3.1900685;-2.5402946;0.5172836;-3.3817196;-
adjust length of sample weights;4.5392623;1.9504558;1.3913013;0.4111696;-0.22695605;1.4667434;-
prefer skip nested validation false estimator is not validated yet;0.70450324;5.8217793;-5.1118536;5.6044955;-0.91012245;2.2310703;TASK
the default exception would mention fit since in the above;-2.83909;2.959243;-3.9614286;4.996965;2.061862;2.68105;CODE
process routing code we pass fit as the caller however;-1.9832001;3.1745298;-1.6059916;1.4010701;-0.018509235;4.2845683;IRRE
the user is not calling fit directly so we change the message;-3.444555;2.9759185;-1.1411229;1.7085153;-3.1293542;2.1572404;IRRE
to make it more suitable for this case;-3.120484;-1.225939;4.5026083;-1.2213535;-0.2509391;2.217877;CODE
note do not change order of iteration to allow one time cv splitters;2.15677;1.7102247;-2.5873084;0.3875121;1.1049786;2.566982;TASK
x y x 100 y 100 only 2 classes;0.6930845;0.90378326;-0.26088053;-3.145773;3.3303945;-1.8020902;IRRE
create a dataset and repeat twice the sample of class 0;5.2053556;0.5031442;0.6968301;-1.230076;3.6102712;-1.7634108;IRRE
create a sample weight vector that is equivalent to the repeated dataset;6.056656;-0.042372275;-0.046342127;-1.9714428;2.1202524;2.030161;IRRE
remove feature to degrade performances;1.3834425;1.0679178;-1.13129;4.9453187;0.41442558;2.9354172;TASK
make the problem completely imbalanced such that the balanced accuracy is low;5.0743275;3.3714914;-1.783863;3.2357626;-0.6743368;0.16920193;CODE
encode numeric targets by meaningful strings we purposely designed the class;3.0413303;-0.7982598;-1.9245783;-1.4375409;3.01452;-1.7338792;CODE
names such that the pos label is the first alphabetically sorted class and thus;-1.5311481;-1.5250341;0.546154;-1.5406483;5.479313;-1.2943939;IRRE
encoded as 0;-4.0154495;2.4703221;-1.9670049;-5.712341;-0.3635994;-3.0278134;-
scale the data to avoid any convergence issue;8.464711;2.5192683;1.4492463;0.75377524;-2.4871757;3.0650187;CODE
only use 2 classes and select samples such that 2 fold cross validation;2.972039;1.5778646;-0.8818112;1.8386475;5.888113;-0.27089608;CODE
split will lead to an equivalence with a sample weight of 0;3.6515477;3.13673;-1.7453781;-0.088813275;1.434799;0.80826056;-
case where refit false and cv is a float the underlying estimator will be fit;2.4652312;1.6544292;-4.29884;1.3650999;-1.80322;3.8602827;CODE
on the training set given by a shufflesplit we check that we get the same model;4.0560083;-2.1108654;-1.1111127;4.5065923;3.8846748;0.5579545;IRRE
coefficients;0.1542626;0.67609966;3.312632;-3.8638725;-0.40286815;-2.718494;-
case where refit true then the underlying estimator is fitted on the full;0.964325;1.5845096;-1.5636642;4.4007187;-0.22424707;5.151508;CODE
dataset;5.44219;-5.7372665;3.9904573;-0.84793586;2.432958;-3.183723;IRRE
emulate the response method that should take into account the pos label;1.5879619;1.5114291;1.7413493;3.14672;2.0080538;1.2416956;CODE
else response method decision function;-0.72242796;3.5812829;2.096854;2.5299642;0.6069136;-1.8444611;CODE
check that the underlying estimator is the same;2.0300865;5.956082;-2.6068676;4.2962008;-3.3600464;2.2261055;-
emulate the response method that should take into account the pos label;1.5879619;1.5114291;1.7413493;3.14672;2.0080538;1.2416956;CODE
else response method decision function;-0.72242796;3.5812829;2.096854;2.5299642;0.6069136;-1.8444611;CODE
create a mapping from boolean values to class labels;1.9015698;1.0994018;0.4634891;-1.826769;4.9187393;-1.4193499;IRRE
this should not raise an error;-5.004735;5.2315326;-2.3678343;4.176829;-1.6402361;-1.6716458;CODE
1 0 0 0 0 0 1 0 trust me it s red;-2.6132174;1.8773465;2.2348719;-3.0485592;-1.0339147;-2.9666;-
regression test for bug in refitting;0.34774125;3.0763626;-3.672498;7.297766;-2.2812188;-3.322133;IRRE
simulates re fitting a broken estimator this used to break with;2.7195435;2.395212;-1.8564371;3.4834669;-5.7098846;2.4575179;CODE
sparse svms;7.0217085;-5.313539;-0.033631273;-1.8783165;1.5766649;3.290543;IRRE
fit a dummy clf with refit true to get a list of keys in;0.5591398;-0.4917869;-1.8892124;-0.22468619;1.8971149;0.7397677;-
clf cv results;3.2830932;-1.2561362;-3.682715;1.0756893;-0.43426263;-2.2443218;IRRE
ensure that best index 0 for this dummy clf;1.3337486;5.412414;-3.6598465;-0.7044372;0.041660402;0.0055808276;CODE
assert every key matches those in cv results;3.9797785;3.815221;-4.1280594;2.414513;2.4710915;-3.8038292;IRRE
ensure best score is disabled when using refit callable;-0.5631818;1.9969299;-2.85441;5.026569;0.5894396;2.960482;IRRE
ensure best score is disabled when using refit callable;-0.5631818;1.9969299;-2.85441;5.026569;0.5894396;2.960482;IRRE
pass x as list in gridsearchcv;1.6936405;1.3248345;-1.1872896;-2.0102248;-0.2634881;1.2831744;-
pass x as list in gridsearchcv;1.6936405;1.3248345;-1.1872896;-2.0102248;-0.2634881;1.2831744;-
pass y as list in gridsearchcv;2.132538;0.8127186;-0.9464684;-2.1735816;-1.347399;0.73445296;-
check cross val score doesn t destroy pandas dataframe;2.1453896;2.9294116;-4.0607414;-0.12885816;-5.1342854;-2.7726254;CODE
x dataframe y series;2.2071805;0.34850818;2.4500568;-4.9443083;-4.8610506;-2.1030798;-
test grid search with unsupervised estimator;5.7993236;3.116866;-2.5515623;3.0513651;-0.17493007;0.20367014;IRRE
multi metric evaluation unsupervised;6.268442;-1.1097115;0.12407427;0.25031957;2.5253923;0.7718351;CODE
both ari and fms can find the right number;-0.17950451;2.4380224;-0.2990734;-1.8878314;0.72933775;-2.9788556;CODE
single metric evaluation unsupervised;6.1313343;-0.73650944;-0.4125026;1.2819906;2.086182;0.5618814;CODE
now without a score and without y;-1.0266515;2.5425665;3.253592;1.05586;-0.67829096;-2.8878012;-
test grid search with an estimator without predict;6.0763283;2.3986025;-1.4154363;4.85622;-0.7908905;0.59709644;IRRE
slight duplication of a test from kde;0.17499411;2.7005856;-3.8283162;4.0601687;-0.9641636;-2.2744093;IRRE
test basic properties of param sampler;1.9347986;5.11486;-0.680692;3.23243;1.9160941;-2.9046824;IRRE
test that repeated calls yield identical parameters;1.9105208;6.125548;0.013884247;4.9113874;1.3794376;-3.532035;IRRE
check if the search cv results s array are of correct types;3.5101159;2.9837635;-4.287469;0.8209365;1.1923449;-3.7328773;IRRE
test the search cv results contains all the required results;2.5300179;3.6647289;-2.8186934;4.079498;1.7103593;-5.084764;IRRE
check if score and timing are reasonable;3.2116177;3.6382596;1.5107964;4.8067493;0.5534605;-5.7251325;IRRE
check cv results structure;4.4661903;2.4278848;-1.9582866;1.0258697;2.865312;-4.2383795;IRRE
check masking;0.66819906;2.9575007;1.4245704;1.3094882;0.2541377;-1.532434;-
check results structure;3.472212;4.991587;1.2468549;1.9035974;3.978994;-6.7610955;IRRE
test the iid parameter todo clearly this test does something else;-3.5307033;6.5419993;-2.6738524;5.7815447;0.09254;-2.2821152;CODE
noise free simple 2d data;6.356969;-1.9327546;1.1915971;-4.9639635;-0.92518485;2.1178727;-
split dataset into two folds that are not iid;4.020584;0.4118139;0.2983262;-2.7110448;2.9446466;2.3033948;IRRE
first one contains data of all 4 blobs second only from two;3.5116098;2.7875664;1.5185245;-4.999384;1.4526062;-2.7283392;CODE
this leads to perfect classification on one fold and a score of 1 3 on;3.5849755;-1.6706771;0.64149094;1.4157921;5.513558;-3.2893646;CODE
the other;-3.4255278;-1.1996439;5.1829348;0.9470653;0.058833364;-1.9926634;-
create cv for splits;2.7801878;-1.1674626;0.2013725;-0.8441177;3.8467708;0.66331106;IRRE
scores are the same as above;1.3545808;0.56339866;1.7813936;-0.20339465;1.2081946;-4.098701;-
unweighted mean std is used;0.14115553;2.1390233;-1.1083753;-0.03130607;-0.28363022;1.362219;CODE
for the train scores we do not take a weighted mean irrespective of;3.1813471;2.1512146;-1.33673;2.4104223;-0.67515934;1.3503237;CODE
i i d or not;-1.4101478;-0.30620673;2.1647933;-0.15053278;1.1787771;-1.3629774;CODE
if true for multi metric pass refit accuracy;3.997836;1.8445339;-2.7220287;2.6789882;0.39092085;-0.80820006;CODE
check if score and timing are reasonable also checks if the keys;1.3062758;2.8784702;0.7270476;2.5207772;1.4080149;-4.6551886;IRRE
are present;-2.6678846;-0.18393503;5.422319;0.8211662;1.611026;-2.2649379;-
compare the keys other than time keys among multi metric and;3.6864247;0.2751536;0.5106409;-1.2547774;0.9889746;-1.4554538;IRRE
single metric grid search results np testing assert equal performs a;5.1138635;3.6925704;-6.294374;1.6659191;-2.544507;-2.5947194;IRRE
deep nested comparison of the two cv results dicts;4.596926;-0.82008535;-1.6864225;0.99899703;1.7082775;-1.8242387;IRRE
gridsearchcv with on error raise;0.4724704;3.0422843;-3.3919556;2.1353612;-2.9881546;0.90184855;CODE
ensures that a warning is raised and score reset where appropriate;-1.5598364;2.4100263;-0.8127619;6.2736435;0.8921108;0.8533224;IRRE
refit false because we only want to check that errors caused by fits;-0.2820465;3.1507688;-3.0646923;3.8264513;-0.77633613;0.54563797;-
to individual folds will be caught and warnings raised instead if;-1.5924911;0.6454584;0.18723375;3.4824066;1.6945047;1.6146454;CODE
refit was done then an exception would be raised on refit and not;-3.426113;1.0520892;-3.1040585;3.4236403;0.692737;1.8769566;CODE
caught by grid search expected behavior and this would cause an;1.5032446;3.76315;-1.0220515;1.8239015;-1.2991989;-0.7368878;IRRE
error in this test;-0.52342075;7.169291;-2.1542304;0.94305617;-2.204018;-9.70134;CODE
ensure that grid scores were set to zero as required for those fits;4.7903137;5.334662;-2.2456577;-0.41094977;-0.9693638;1.5890273;CODE
that are expected to fail;-1.6226939;2.344712;1.4028063;4.6858144;0.18054698;-3.6280031;-
check that succeeded estimators have lower ranks;2.5345962;5.150127;-2.4343834;3.7691941;-1.7464837;-0.67239666;-
check that failed estimator has the highest rank;2.4493244;4.5576015;-2.0741506;2.6589813;-1.8885059;-1.1799103;-
gridsearchcv with on error raise raises the error;-0.19527173;3.2835667;-4.9925046;2.044378;-3.6196802;0.62289625;CODE
refit false because we want to test the behaviour of the grid search part;1.2035669;2.6790361;-1.5394615;3.8943703;0.30690607;0.68888015;IRRE
failingclassifier issues a valueerror so this is what we look for;0.7566706;0.88255626;-5.7130013;3.05042;-0.64971244;-2.0782695;CODE
raise warning if n iter is bigger than total parameter space;0.78001714;5.253461;-3.0434923;0.6176608;0.37944087;0.8757078;IRRE
degenerates to gridsearchcv if n iter the same as grid size;3.6858308;2.942352;-3.310097;-2.8882942;-1.2605152;2.23567;IRRE
test sampling without replacement in a large grid;5.6921844;4.363499;0.734916;1.7069883;0.824504;-1.2879683;IRRE
doesn t go into infinite loops;-1.310107;2.8199463;3.5367906;-1.2352248;-1.7946606;-3.374312;IRRE
make sure the predict proba works when loss is specified;2.0312035;1.1799726;-2.4283667;4.688235;-2.3801548;0.7417283;-
as one of the parameters in the param grid;1.3623755;1.0324329;2.516699;-3.966698;0.31664845;2.875081;IRRE
when the estimator is not fitted predict proba is not available as the;-0.5549282;1.6056674;-2.9058821;3.1470723;-4.8197746;1.406717;-
loss is hinge;-1.3202175;0.8625609;2.289043;1.0402374;-1.504066;1.2903315;-
make sure predict proba is not available when setting loss hinge;0.5911207;-0.07956264;-2.6221192;3.7032475;-3.1237926;2.7744322;IRRE
in param grid;0.16002792;0.5784633;4.9965878;-4.521713;0.8702881;0.7818143;-
check if a one time iterable is accepted as a cv parameter;1.2928166;4.6654963;-3.3478236;4.1128535;1.6443117;-0.6095798;IRRE
give generator as a cv parameter;0.85287535;1.4034069;-1.7027596;0.14813158;2.5042117;1.3487953;IRRE
check if generators are supported as cv and;0.18080485;0.99505645;-5.835643;0.8034323;0.97435755;-0.787505;IRRE
that the splits are consistent;1.3446058;-0.29424477;3.6234367;2.5405505;2.3961854;0.68529105;-
onetimesplitter is a non re entrant cv where split can be called only;-1.6739917;1.4327015;-2.210292;2.0072293;1.8714131;3.0784702;IRRE
once if cv split is called once per param setting in gridsearchcv fit;3.4774587;2.7017186;-2.894155;1.7396598;0.16636428;4.5670977;IRRE
the 2nd and 3rd parameter will not be evaluated as no train test indices;1.1937882;4.3268228;-5.2740717;0.14061719;-0.12975512;-2.165195;IRRE
will be generated for the 2nd and subsequent cv split calls;-0.4533974;0.035013046;0.08828593;2.5724835;4.728947;0.25635487;CODE
this is a check to make sure cv split is not called once per param;-0.6677477;2.655835;-3.613724;2.8679354;2.5880785;1.2763177;CODE
setting;-4.106625;-0.3797285;7.250582;0.6279653;-0.011968109;0.6227744;IRRE
check consistency of folds across the parameters;3.0810974;4.245689;-1.5408944;0.51755947;-0.006157602;3.0683699;IRRE
as the first two param settings c 0 1 and the next two param;-2.375829;1.528883;3.0353875;-1.9501461;1.5319238;2.264645;IRRE
settings c 0 2 are same the test and train scores must also be;-0.21330224;1.3002156;-1.7346123;1.5169739;0.17516065;-1.7633544;IRRE
same as long as the same train test indices are generated for all;5.2604628;1.3893737;-1.1056801;2.3546531;4.215212;-0.550459;CODE
the cv splits for both param setting;1.5295304;0.81040347;-1.0082865;1.5616149;2.9882882;4.1039343;IRRE
xxx results params is a list;-1.1750535;2.3432586;-0.12833805;0.6553185;0.8327757;-2.3107343;IRRE
using regressor to make sure each score differs;4.939664;3.7817929;0.734905;0.56454194;2.0004199;-1.8206493;-
this should not raise any exceptions;-5.250412;3.820267;-2.377036;6.22911;1.2580805;1.0024782;CODE
this should raise a notimplementederror;-4.0692987;1.8259884;1.4724218;3.5609264;0.48013073;0.73392165;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
use global x y;-1.978127;0.7051781;3.927066;-2.268322;-0.47849348;1.6364864;-
create cv;0.5616353;-2.816428;0.64633375;-0.6706959;2.4826744;-1.5077648;IRRE
pop all of it this should cause the expected valueerror;-1.8445108;5.4721518;-0.76395404;2.1509242;-3.3191087;-3.0221105;IRRE
cv is empty now;-2.9781947;0.5816109;-0.6408804;0.4107178;-2.0964093;-1.0526088;-
assert that this raises an error;-1.821156;7.7940764;-3.7963607;5.2768574;0.16167507;-4.483752;CODE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
use global x y;-1.978127;0.7051781;3.927066;-2.268322;-0.47849348;1.6364864;-
create bad cv;1.0351893;-0.19561356;-2.0953777;2.1967583;0.5653601;-0.88153315;IRRE
assert that this raises an error;-1.821156;7.7940764;-3.7963607;5.2768574;0.16167507;-4.483752;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 10529;-3.1352391;-9.619541;-5.7701173;-0.042798664;-5.5712633;-5.329596;CODE
check that we raise a userwarning when a non finite score is;1.853189;3.6237013;-1.0490879;5.89433;0.16980985;-1.4692062;IRRE
computed in the searchcv;3.7823217;-0.8200433;-1.9801253;-2.0735753;-0.5484025;-1.6225029;CODE
non regression test for issue 13920;-1.1409993;2.8913395;-5.982115;4.5115867;-3.9409037;-5.5915427;IRRE
non regression test for issue 13920;-1.1409993;2.8913395;-5.982115;4.5115867;-3.9409037;-5.5915427;IRRE
non regression test for issue 13920;-1.1409991;2.8913398;-5.9821167;4.5115867;-3.9409034;-5.591543;IRRE
unfitted shows the original pipeline;-2.1300142;-0.57871234;-0.7016378;3.55707;-0.31185666;1.5612836;CODE
fitted with refit false shows the original pipeline;-1.2788076;0.36878178;-2.471612;1.2185948;-0.4055197;2.3053894;CODE
fitted with refit true shows the best estimator;2.2629914;0.08620886;-1.4146358;3.4608011;-2.1220663;3.1253593;IRRE
metadata routing tests;-0.843307;-0.22733422;-1.494115;5.5445786;1.6963054;-0.69893;IRRE
values of param grid are such that np result type gives slightly;3.4798248;3.4972537;-4.5225744;-3.8795376;-4.2412343;0.08865434;IRRE
different errors in particular valueerror and typeerror;0.20175382;3.817755;-5.562584;0.45688376;-3.7633584;-3.9600244;IRRE
non regression test for 29277;0.24670482;3.073146;-4.574338;2.6548114;-2.442745;-6.3869452;IRRE
from sklearn experimental import enable halving search cv noqa f401;1.9050133;-1.1410071;-6.8692355;-0.5317155;-4.109496;-0.66295934;CODE
update the constraints such that we accept all parameters from a to z;1.4472004;3.6779175;-0.90941864;-1.9413817;2.2524376;3.084467;CODE
estimators that failed during fit predict should always rank lower;3.3902404;2.4094796;-3.1015246;3.7573822;-4.378621;2.7883797;-
than ones where the fit predict succeeded;6.732129;0.078558035;0.24736328;5.4938064;-1.2118003;-1.2754687;-
some scores should be nan;2.4251487;2.5816917;0.09823758;-0.3822623;-1.7614882;-4.519506;-
all nan scores should have the same rank;3.4174654;1.3868036;-1.2348874;-1.6376938;0.14150712;-1.2082812;-
nans should have the lowest rank;2.06842;0.53660166;-0.660037;-2.0803905;-0.75358075;-0.21585663;-
notice how it loops at the beginning;-2.478923;0.75301677;4.7675233;-1.9804496;-1.7521492;-2.3220005;IRRE
also the number of candidates evaluated at the last iteration is;2.5617568;1.5099536;1.4249794;2.8349233;4.3869686;-4.461697;-
factor;-1.682027;0.7231498;4.7950535;-1.7367011;-0.8532306;-3.2210608;-
no aggressive elimination we end up with less iterations and;-0.41172206;1.4949174;2.703985;3.5445766;0.26910803;-0.39837933;CODE
the number of candidates at the last iter is factor which isn t;0.52336764;2.2362795;0.6229463;0.7616917;3.0794432;-2.3926365;-
ideal;-1.5725608;1.0229867;6.0468397;0.93071306;0.7597443;-1.799288;-
when the amount of resource isn t limited aggressive elimination;-0.51541483;1.0094119;2.7828538;4.598332;1.0485663;2.3043728;-
has no effect here the default min resources exhaust will take;-2.0290906;0.76214635;-1.3432597;2.821238;-2.1657202;4.1229844;CODE
over;-3.0372384;-0.042367566;5.483429;0.81239974;-0.87546414;-3.0550003;-
test the aggressive elimination parameter;1.3811315;5.630318;-0.6394974;3.6646726;-0.08833922;-3.3627431;IRRE
h set params verbose true just for test coverage;-0.7785569;5.7215285;-1.996519;3.7834287;1.6041878;-2.1052392;IRRE
same number of candidates as with the grid;3.1519926;1.0634807;3.209489;-0.5366466;4.295109;-1.318708;-
with enough resources;-1.1925027;-2.828995;6.378793;2.5421937;0.39716715;-1.2795917;-
with enough resources but min resources set manually;0.40481102;-0.063768916;2.8938777;1.7437524;1.0581721;3.569217;IRRE
without enough resources only one iteration can be done;1.3092929;1.085678;3.7896311;2.5885391;1.1010249;0.16409619;CODE
with exhaust use as much resources as possible at the last iter;-1.077145;-0.7509969;2.996998;2.7423887;0.91664416;2.1400127;-
test the min resources and max resources parameters and how they affect;1.84308;1.5962408;1.2253996;3.772814;-0.24679458;-0.074289426;IRRE
the number of resources used at each iteration;2.7884743;-1.028268;4.3765526;1.5348603;1.0632986;0.038623266;-
h set params n candidates 6 same number as with the grid;3.0639307;2.8060074;2.3235815;-4.88458;3.3630078;-1.7742952;IRRE
expected n required iterations 2 given 6 combinations and factor 3;0.46446595;1.4860283;1.621411;-0.3086223;1.0061324;-3.2923074;CODE
auto 5 9 all resources are used;-3.7014468;-2.368566;1.7630666;1.8057227;1.8226361;0.6304109;-
4 1 1 max resources min resources only one iteration is;-0.39471278;2.3422384;1.0217175;-0.84265465;-1.1562986;1.603573;-
possible;-1.7916718;-0.5131347;6.0207357;2.7467244;0.15163562;-1.9502912;-
test the number of actual iterations that were run depending on;3.990513;4.5835423;2.0410447;4.630135;-0.61450917;-5.9664626;CODE
max resources;-0.6561751;-2.1115887;4.612344;1.0856208;1.4147108;0.6053841;-
h set params n candidates 20 same as for halvinggridsearchcv;2.9518015;1.7810512;-1.3568486;-3.603879;2.101655;-0.46048814;IRRE
test the resource parameter;-0.9809104;4.1410036;1.267895;5.7873416;0.35420373;-0.8485535;IRRE
512 exhaust 128 generate exactly as much as needed;0.35020006;-0.32950762;-1.0118995;-0.86789757;0.76134783;-0.33286327;-
32 7 7 ask for less than what we could;-0.24493764;1.7374333;2.8601005;-0.7827355;0.54320806;-3.0454612;CODE
32 9 9 ask for more than reasonable;0.3759494;2.5531135;1.4054532;0.5621607;1.2578337;-3.7099094;CODE
test random search and make sure the number of generated candidates is;3.7673957;2.604584;-0.20560408;5.2179046;4.00303;-5.778766;IRRE
as expected;-2.3717954;0.5734663;3.4745007;2.0142334;-1.3120154;-1.2682209;-
make sure exhaust makes the last iteration use as much resources as;-0.15179488;1.5414901;-0.8034772;3.2305422;-2.3847468;1.4636372;-
we can;-1.5865833;-1.7593293;3.8223302;2.0937676;0.10520705;0.010127947;-
a 1 2 2 all lists sample less than n candidates;4.897395;2.3144858;0.49387228;-0.92668945;4.3627086;-4.8534737;-
a randint 1 3 10 not all list respect n candidates;1.007558;1.5212218;-0.31113315;-0.26030597;4.3254075;-4.9228663;IRRE
make sure random search samples the appropriate number of candidates when;4.5243115;0.8699264;-0.5430227;4.3608546;4.148407;-2.680644;IRRE
we ask for more than what s possible how many parameters are sampled;4.297149;1.7591177;2.6577551;1.017485;2.8679664;-1.3360525;IRRE
depends whether the distributions are all lists or not see;1.4398412;-0.47639796;1.5433797;0.38246256;1.84215;-0.3440112;META
parametersampler for details this is somewhat redundant with the checks;3.4716756;4.963185;-1.3989352;1.1130661;0.39417073;-0.4534515;IRRE
in parametersampler but interaction bugs were discovered during;-0.09878278;0.58614665;-4.1335816;2.8439133;-2.6072526;1.3972968;IRRE
development of sh;-2.7197554;-3.5934255;3.214448;0.013246094;-2.0590274;-2.94094;-
tests specific to halvingrandomsearchcv;2.597743;3.2399857;-3.4177582;4.0682335;-0.94122213;-2.8764734;IRRE
make sure splits returned by subsamplemetasplitter are of appropriate;2.711307;2.3646924;-4.222808;0.98783594;2.1956742;2.5917;IRRE
size;-1.293162;-0.48505983;5.254666;-1.905388;0.41176203;-2.3314316;-
make sure subsamplemetasplitter is consistent across calls to split;1.8875769;2.9646518;-4.520114;1.8691237;1.1171186;3.5408428;IRRE
we re ok having training sets differ they re always sampled with a;4.5411725;-1.2876956;-0.2310925;3.4298844;3.3488905;0.62566864;IRRE
different fraction anyway;-1.008692;2.6483161;2.939389;-2.5934238;-0.58146536;-3.006226;-
when we don t subsample the test set we want it to be always the same;3.328931;4.4055405;-1.4403917;5.8358893;2.8156295;-1.3831197;IRRE
this check is the most important this is ensured by the determinism;-1.772796;0.17727993;-0.6379004;4.4895573;2.4354815;-0.8261626;CODE
of the base cv;0.60953164;-2.703357;2.0217628;-0.46140477;2.7850215;-1.1761677;-
note we could force both train and test splits to be always the same if;1.9423895;1.5050931;-0.3976917;5.613966;2.7878423;0.63116854;TASK
we drew an int seed in subsamplemetasplitter init;1.34502;-0.1392359;-1.178304;-1.8068305;1.6729244;0.4744005;IRRE
results this isn t a real world result dict;0.71324444;0.30689588;0.1495145;1.0159917;-1.6251694;-7.2422976;IRRE
test that the cv results matches correctly the logic of the;3.5604775;4.985713;-2.1627223;4.833858;2.582923;-5.9981046;IRRE
tournament in particular that the candidates continued in each;0.20013654;-0.7354983;3.9458907;2.8772407;3.3781297;-0.89346904;CODE
successive iteration are those that were best in the previous iteration;4.0308847;1.7612989;3.67251;3.1193686;2.1923678;-2.2865584;IRRE
generate random scores we want to avoid ties which would otherwise;4.318177;-0.051016826;3.100354;1.5014197;3.402096;-2.0282223;CODE
mess with the ordering and make testing harder;1.8854481;4.771336;-0.3746137;4.3174653;1.3253313;-5.5207744;IRRE
same number of candidates as with the grid;3.151992;1.0634818;3.2094898;-0.5366469;4.2951107;-1.3187085;-
non regression check for;1.9749563;4.540932;-2.2169712;3.9530194;-1.8624351;-4.4446044;CODE
https github com scikit learn scikit learn issues 19203;-3.3694682;-8.233114;-5.9530487;-1.3313428;-7.2046475;-3.988772;CODE
just make sure we don t have ties;-1.4339911;1.2983505;3.3140748;1.5782621;1.4152262;0.874151;CODE
table looks like something like this;-0.49987882;-0.8724456;7.086503;-5.3047366;1.9694053;-1.0002339;CODE
iter 0 1 2 3 4 5;-1.2060097;1.3580463;3.318281;-6.0330176;-0.40072122;-5.5084443;-
params str;-2.276345;1.0403854;2.489586;-1.514271;1.2965682;-1.6026453;-
a l2 b 23 0 75 nan nan nan nan nan;0.5717428;2.51114;0.8961301;-5.8106585;-1.2348244;-4.789795;-
a l1 b 30 0 90 0 875 nan nan nan nan;1.6377144;2.5718186;-0.37834787;-6.512113;-1.2152548;-5.267217;-
a l1 b 0 0 75 nan nan nan nan nan;1.3821793;3.01806;0.22849685;-5.968142;-1.4294422;-4.293664;-
a l2 b 3 0 85 0 925 0 9125 0 90625 nan nan;2.9310875;2.2677946;-1.7549784;-7.8377113;-0.6968512;-3.9068775;-
a l1 b 5 0 80 nan nan nan nan nan;1.2324983;2.6718786;1.0153385;-5.349458;-1.188206;-4.3841596;-
where a nan indicates that the candidate wasn t evaluated at a given;2.29136;2.7440732;-1.8863472;2.1064932;0.4787042;-4.5957246;IRRE
iteration because it wasn t part of the top k at some previous;1.2319553;0.7257404;2.863233;1.1780418;-0.5683835;-0.6824478;-
iteration we here make sure that candidates that aren t in the top k at;3.2337472;-0.28144684;1.8861227;3.302298;2.6597202;-1.4003507;IRRE
any given iteration are indeed not evaluated at the subsequent;1.6946743;4.72571;-1.1093622;3.1868548;-1.4538553;-2.654617;TASK
iterations;1.8315902;-0.21061747;6.710878;1.8012992;1.6812203;-4.3973355;-
make sure that if a candidate is already discarded we don t evaluate;0.9249617;3.6637685;-0.72028166;6.78425;3.2287674;-1.2569364;CODE
it later;-3.3153317;-1.5729165;5.904507;3.9566612;-0.9955669;-0.38009;-
make sure that the number of discarded candidate is correct;2.329468;4.185693;-0.53721875;4.818542;4.3582063;-3.3359957;-
make sure that all discarded candidates have a lower score than the;2.0239437;3.8682106;-1.3996987;5.441248;3.1298468;-1.0546333;-
kept candidates;-0.23261529;0.6380492;3.4888935;2.6783473;2.6420758;-1.3385507;-
we now make sure that the best candidate is chosen only from the last;0.7500736;0.26103237;2.3614156;3.5111895;3.3390849;0.35998714;CODE
iteration;1.7445554;1.5809857;6.271018;0.91151935;0.96636754;-4.5030293;-
we also make sure this is true even if there were higher scores in;1.8756833;2.7248137;-0.56535167;5.121251;-0.5609403;-2.1901636;CODE
earlier rounds this isn t generally the case but worth ensuring it s;-0.9906582;2.7836604;0.03535851;5.6328764;0.4044329;0.92650056;CODE
possible;-1.7916709;-0.51313454;6.020733;2.7467246;0.15163323;-1.9502914;-
make sure that the base estimators are passed the correct parameters and;1.981369;2.9173512;-3.5150652;1.637103;-4.137104;3.078311;IRRE
number of samples at each iteration;5.594331;0.7753917;2.5935357;1.0397521;1.3164577;-2.4921894;-
same number of candidates as with the grid;3.151992;1.0634818;3.2094898;-0.5366469;4.2951107;-1.3187085;-
lists are of length n splits n iter n candidates at i;2.6918802;-0.3665904;2.2427027;-2.822699;5.246377;-5.0176454;-
each chunk of size n splits corresponds to the n splits folds for the;1.0560217;-1.2933372;1.6731924;-3.8325949;2.6211572;-0.35578972;CODE
same candidate at the same iteration so they contain equal values we;4.573545;4.549419;1.3073993;-0.10710539;3.5825016;-3.9028597;IRRE
subsample such that the lists are of length n iter n candidates at it;3.6535113;0.38456932;2.2570264;-1.7162355;5.0161247;-3.1531272;-
check if valueerror when groups is none propagates to;1.1622978;5.4645934;-3.9994037;2.2869608;-1.4809768;-2.2709527;IRRE
halvinggridsearchcv and halvingrandomsearchcv;1.4013458;0.9673316;-2.3540933;-0.90559244;-1.0359062;2.2652838;IRRE
and also check if groups is correctly passed to the cv object;0.85775197;2.4363344;-1.6897198;3.1016355;1.9082551;-1.4028385;IRRE
should not raise an error;-3.5205157;6.021319;-2.8749404;4.93623;-2.3655174;-1.8975159;CODE
results this isn t a real world result dict;0.71324444;0.30689588;0.1495145;1.0159917;-1.6251694;-7.2422976;IRRE
we expect the index of i;0.362273;0.17703225;1.7196215;0.6486104;0.833086;-1.9129128;-
check results structure;3.472212;4.991587;1.2468549;1.9035974;3.978994;-6.7610955;IRRE
training score becomes worse 2 1 test error better 0 1;2.4225128;3.2862327;-4.5127106;2.9401913;-2.0628774;-3.5151222;IRRE
xxx use 2d array since 1d x is being detected as a single sample in;5.177912;5.2255664;-1.5935738;-5.9715347;-0.61426;-0.6032423;-
check consistent length;2.5218568;6.4800086;0.5990919;-0.02840329;0.28218725;-4.1032267;-
the number of samples per class needs to be n splits;4.9786496;-0.29749396;-0.9530255;-0.86213243;4.967786;-2.0247922;TASK
for stratifiedkfold n splits 3;-1.0338718;-0.94448787;0.85308653;-3.9790866;3.6585004;-2.6063037;CODE
smoke test;1.3261306;2.8305657;2.4601343;3.7173204;-0.34919217;-4.738874;IRRE
test with multioutput y;3.843516;3.80704;0.53168386;0.6881208;-1.6026325;-6.246842;IRRE
test with multioutput y;3.843516;3.80704;0.53168386;0.6881208;-1.6026325;-6.246842;IRRE
test with x and y as list;2.7731628;4.7208877;1.7138757;-0.01529887;0.19376767;-7.960918;IRRE
test with 3d x and;0.29929113;3.9250815;-0.1664105;-2.8041527;-0.3771519;-4.4841623;IRRE
regression test for 12154 cv warn with n jobs 1 trigger a copy of;1.0605376;1.7685199;-4.3107057;3.7065983;-2.0857403;-2.9417973;IRRE
the parameters leading to a failure in check cv due to cv is warn;-1.119564;3.748951;-4.3390617;2.5375109;-1.1102498;-1.705352;IRRE
instead of cv warn;-2.6718526;-0.44720444;-1.8403975;3.4918451;-0.5773254;0.99015856;CODE
test the errors;0.46856266;5.4474144;0.6831239;4.782905;-1.6180383;-9.386528;IRRE
list tuple of callables should raise a message advising users to use;-2.7224042;-0.31647655;1.3002852;4.112153;2.3581657;0.39081174;IRRE
dict of names to callables mapping;-2.2374156;-0.682856;-0.3607368;-1.5818819;2.7137678;0.35578424;IRRE
so should empty lists tuples;0.7721928;1.684345;-0.08070458;-1.1266598;0.6048446;-3.245119;-
so should duplicated entries;-0.9342338;1.598712;2.1346667;1.7017832;4.017967;-0.36012942;-
nested lists should raise a generic error message;-0.03260124;4.1692777;-2.0222237;2.9849308;1.1537968;-0.48908857;CODE
empty dict should raise invalid scoring error;-0.6999777;3.1230812;-5.1529794;0.52989215;-1.2877042;-4.1044536;OUTD
multiclass scorers that return multiple values are not supported yet;1.6980326;1.0076525;-3.3866074;2.1527517;4.358289;-1.458397;IRRE
the warning message we re expecting to see;-4.536046;0.20638631;0.30946407;4.1443615;-2.375655;-0.6202725;-
non regression test to ensure that nested;1.6698451;6.1601686;-1.0748229;4.60178;0.3835298;-2.9788074;IRRE
estimators are properly returned in a list;3.2825084;3.1429093;-1.0939249;2.5879824;-3.1574905;-0.23129617;IRRE
https github com scikit learn scikit learn pull 17745;-3.1082175;-10.708237;-4.4188623;-1.0176316;-4.305313;-5.2708125;CODE
compute train and test mse r2 scores;4.1487045;1.0512072;-1.7049054;1.280341;0.89709413;-3.363916;IRRE
regression;4.8113813;-1.4023851;5.968424;1.4558641;-1.5940726;-2.9783654;-
classification;5.668271;-5.8220553;4.2595444;1.7214531;6.909542;-2.19592;IRRE
it s okay to evaluate regression metrics on classification too;3.7062795;-3.451576;-1.5535992;3.8542542;1.136074;-0.308888;IRRE
to ensure that the test does not suffer from;-0.537926;5.5541573;-2.0485737;7.5674067;-0.03409877;-4.258117;CODE
large statistical fluctuations due to slicing small datasets;7.52549;-3.116782;-1.3734854;1.2096263;-2.4630997;1.6589713;IRRE
we pass the cross validation instance;-0.16299993;0.91611177;0.9837319;3.8829346;2.939665;-1.0341165;-
test single metric evaluation when scoring is string or singleton list;4.5655966;2.7763238;-1.5864074;4.284743;2.8909736;-3.156849;CODE
single metric passed as a string;2.1815956;1.3476331;-0.8133071;-1.4256974;1.2029161;-0.07097609;CODE
single metric passed as a list;3.7077239;0.48467746;0.23901293;-0.50942546;2.1796052;0.46224436;-
it must be true by default deprecated;-6.295865;-0.10510687;-3.8978841;3.6118038;-2.4235623;1.8318008;TASK
test return estimator option;1.532093;5.537694;-1.5739342;6.128118;-2.7057655;-1.1659628;IRRE
test multimetric evaluation when scoring is a list dict;3.3069088;2.1909082;-1.2316902;1.4123029;1.583358;-6.1163497;IRRE
return train score must be true by default deprecated;-0.38417205;2.473241;-4.6281347;4.1660085;-1.2275363;-1.1860813;CODE
make sure all the arrays are of np ndarray type;0.64451575;1.0325884;-6.0435534;-4.5754294;-5.2283726;-0.30199766;-
ensure all the times are within sane limits;2.1739378;3.1570568;2.3273492;3.1752715;1.3076351;-1.3402411;-
check if valueerror when groups is none propagates to cross val score;3.4237318;5.515309;-3.8207672;1.563603;-0.60253704;-2.846261;IRRE
and cross val predict;3.0935605;-1.8247273;1.2641579;1.7955071;-0.075519435;-0.71524787;-
and also check if groups is correctly passed to the cv object;0.85775197;2.4363344;-1.6897198;3.1016355;1.9082551;-1.4028385;IRRE
check cross val score doesn t destroy pandas dataframe;2.1453896;2.9294116;-4.0607414;-0.12885816;-5.1342854;-2.7726254;CODE
x dataframe y series;2.20718;0.3485086;2.4500556;-4.944307;-4.861051;-2.1030798;-
3 fold cross val is used so we need at least 3 samples per class;3.6295147;-0.0702735;-1.0857259;-1.2602054;5.5197763;-1.8237842;IRRE
test that cross val score works with boolean masks;2.6973982;4.4104133;-3.685661;1.2423801;1.0615747;-3.076693;IRRE
test for svm with precomputed kernel;4.0056505;-0.41850796;-3.8662937;1.2693679;-0.39368623;-0.2653972;IRRE
test with callable;-1.3090639;4.6527295;0.15750569;6.8885465;-0.008566718;-4.313039;IRRE
error raised for non square x;-0.38719305;4.6489663;-4.624197;-4.0056167;-4.374513;-2.1288767;CODE
test error is raised when the precomputed kernel is not array like;1.6096594;4.7845025;-5.651055;1.2892278;-2.914374;-2.3273885;IRRE
or sparse;3.1627376;-2.0483086;2.717828;0.15820086;0.6528181;1.9024613;IRRE
function to test that the values are passed correctly to the;2.6806223;7.939223;0.6453071;2.9562156;-1.0170512;-7.5520363;IRRE
classifier arguments for non array type;2.9171865;-0.81228167;-3.4576242;-0.46951282;3.7247708;-0.45148802;CODE
test that score function is called only 3 times for cv 3;1.6509155;4.98006;-3.6687253;1.8847653;0.7670728;-4.605188;CODE
default score should be the accuracy score;1.7667388;1.3138744;-1.9797521;2.6583867;-0.27425757;-2.110226;CODE
correct classification score aka zero one score should be the;3.4054253;-0.057011683;-2.2663233;1.1871964;3.636502;-3.791057;IRRE
same as the default estimator score;1.9615194;-0.28680885;-0.28670055;3.5620894;-0.54012376;1.6220459;IRRE
f1 score class are balanced so f1 score should be equal to zero one;2.48186;3.0454772;-1.9657711;0.5146835;2.4796848;-3.3878481;IRRE
score;-0.7900283;1.0264367;5.1333914;-0.32696462;0.69945973;-6.6552067;-
default score of the ridge regression estimator;1.1269155;-0.08720111;-2.5755103;0.23016018;-3.9947796;2.7220285;CODE
r2 score aka determination coefficient should be the;2.8234794;1.2302023;0.8472678;0.2835055;0.84328604;-4.0112004;-
same as the default estimator score;1.9615194;-0.28680885;-0.28670055;3.5620894;-0.54012376;1.6220459;IRRE
mean squared error this is a loss function so scores are negative;1.4505298;2.2307541;-0.9427181;-0.6567261;-4.105238;-2.6291606;CODE
explained variance;0.76192284;-1.6652234;2.9067252;0.17304549;-2.2222366;-0.41576767;CODE
check that we obtain the same results with a sparse representation;7.9122515;0.67066544;-2.5960984;-1.0004184;0.30490175;1.4943451;IRRE
test with custom scoring object;2.5893831;4.0281467;-0.35679942;4.7310185;2.7788124;-5.5830994;IRRE
set random y;0.7425957;0.98617226;4.404736;-0.5183333;0.46979937;-2.243095;IRRE
check that permutation test score allows input data with nans;3.8000867;5.2674365;-3.2042997;-0.85531884;-0.5710385;-6.3909307;IRRE
check that cross val score allows input data with nans;3.6776307;3.7959087;-3.9149976;-1.8125626;-2.877739;-4.187163;CODE
naive loop should be same as cross val predict;3.343322;0.21208999;-2.6639528;-0.21817705;-1.4423795;-2.069992;IRRE
this specifically tests imbalanced splits for binary;3.8400297;2.3606055;-2.5007992;1.4397596;2.0616465;-4.8358936;IRRE
classification with decision function this is only;4.1107483;-0.6641254;0.19261968;0.48355842;5.46399;-1.4601091;CODE
applicable to classifiers that can be fit on a single;5.4841967;-3.7192943;-1.6429137;1.4429501;6.482164;1.8847703;CODE
class;-1.8242638;-3.5874555;4.3454294;1.6283791;3.6255476;-4.2723403;IRRE
3 fold cv is used at least 3 samples per class;2.7087288;0.084484436;-3.4672983;-0.88043505;4.740775;-0.6473882;IRRE
smoke test;1.3261306;2.8305657;2.4601343;3.7173204;-0.34919217;-4.738874;IRRE
test with multioutput y;3.843516;3.80704;0.53168386;0.6881208;-1.6026325;-6.246842;IRRE
test with multioutput y;3.843516;3.80704;0.53168386;0.6881208;-1.6026325;-6.246842;IRRE
test with x and y as list;2.7731633;4.7208886;1.7138759;-0.015299258;0.19376886;-7.960919;IRRE
test with x and y as list and non empty method;1.611279;5.9457097;-0.195523;2.17245;-0.5409455;-6.9711733;IRRE
test with 3d x and;0.29929113;3.9250815;-0.1664105;-2.8041527;-0.3771519;-4.4841623;IRRE
check cross val score doesn t destroy pandas dataframe;2.1453896;2.9294116;-4.0607414;-0.12885816;-5.1342854;-2.7726254;CODE
x dataframe y series;2.20718;0.3485086;2.4500556;-4.944307;-4.861051;-2.1030798;-
change the first sample to a new class;1.036327;1.5629871;1.5304892;2.0942452;4.612397;-0.10450193;CODE
assert y test 0 0 2 sanity check for further assertions;1.0528841;7.2453256;-4.5232983;3.4513526;-2.5369334;-6.5717287;CODE
ensure that cross val predict works when y is none;2.4399889;3.714205;-2.761727;1.3403293;-2.8889873;-0.6002429;-
cannot use assert array almost equal for fit and score times because;5.2151413;6.9548464;-4.3753676;3.3032553;-1.787029;-3.9545999;CODE
the values are hardware dependent;2.066371;0.91561407;-0.5008481;-3.1452885;0.78869694;-1.4041461;IRRE
test a custom cv splitter that can iterate only once;3.3207552;4.0501733;-2.1372333;4.165367;1.8746182;-1.3340646;IRRE
the mockup does not have partial fit;-0.6728299;1.5716963;-1.7492656;1.9189495;-3.1802437;2.0115805;CODE
following test case was designed this way to verify the code;-2.8662434;5.739304;-3.7188294;3.1668527;1.8308744;-5.1573853;CODE
changes made in pull request 7506;-4.377512;-0.85137004;-0.9043289;2.6190133;-1.0275998;1.6775844;CODE
splits on these groups fail without shuffle as the first iteration;2.0066395;2.1431346;0.39386225;0.068562776;1.9175577;-1.175167;-
of the learning curve doesn t contain label 4 in the training set;1.4724913;-1.4122901;-2.6704214;-0.8269803;0.37087744;-0.08936317;CODE
the onetimesplitter is a non re entrant cv splitter unless the;-1.908845;1.356086;-3.036657;1.2883214;-0.28572476;3.343944;CODE
split is called for each parameter the following should produce;0.7914717;1.9062629;1.176272;-3.3887525;3.8551023;-0.9104041;IRRE
identical results for param setting 1 and param setting 2 as both have;-1.8951143;4.556199;-0.8753788;0.96274346;-0.17249265;2.5036767;IRRE
the same c value;0.16449547;2.8870375;1.6247302;-3.4966679;-0.21468845;-3.7329152;IRRE
for scores2 compare the 1st and 2nd parameter s scores;3.3609145;2.6710474;1.9644108;-0.6231705;2.0254395;-4.9026723;IRRE
since the c value for 1st two param setting is 0 1 they must be;-1.4157739;4.834857;-2.6270876;-4.1022396;-3.1417959;-0.6396683;IRRE
consistent unless the train test folds differ between the param settings;2.1713228;3.9144285;-1.1855749;4.4626718;-0.57158124;1.5367506;IRRE
onetimesplitter is basically unshuffled kfold n splits 5 sanity check;-2.4418929;1.1831019;-0.40492135;1.1755044;-0.547835;-0.29391724;IRRE
check if the additional duplicate indices are caught;2.5373604;5.512157;-2.2010877;-0.5454187;1.9801079;-2.633468;TASK
check that cross val predict gives same result for sparse and dense input;5.3742633;1.2706575;-5.310337;0.57563514;-3.106181;0.35430324;IRRE
generate expected outputs;4.114362;1.6497152;2.8217456;-0.0519195;1.7204242;-3.594973;IRRE
check actual outputs for several representations of y;4.5817976;2.4225938;0.5316733;-3.5307488;-0.8541976;-3.2564182;IRRE
create empty arrays of the correct size to hold outputs;3.3290188;3.859856;2.098961;-3.9573412;-0.13103604;-1.0281557;IRRE
generate expected outputs;4.114362;1.6497152;2.8217456;-0.0519195;1.7204242;-3.594973;IRRE
decision function with 2 classes;2.2353837;0.6181581;1.621878;-0.16499084;5.463435;-1.1249019;CODE
check actual outputs for several representations of y;4.5817976;2.4225938;0.5316733;-3.5307488;-0.8541976;-3.2564182;IRRE
this test includes the decision function with two classes;2.1569338;2.687969;-1.2262285;3.7275996;4.441786;-5.577854;CODE
this is a special case it has only one column of output;-2.7955706;2.617789;0.6306558;-4.840995;1.1854196;-2.701321;CODE
regression test for issue 9639 tests that cross val predict does not;0.67617387;3.484163;-5.8792057;3.3400831;-3.8681567;-3.4907188;IRRE
check estimator methods e g predict proba before fitting;3.8494976;1.2924528;-1.1029501;5.820765;-2.1064801;0.5665903;CODE
ovr does multilabel predictions but only arrays of;3.0131123;-0.8440001;-2.42854;0.2649829;0.91016144;1.0693048;META
binary indicator columns the output of predict proba;4.6750717;-0.73682624;-0.6559072;-3.238449;1.0669698;-1.1751068;IRRE
is a 2d array with shape n samples n classes;5.692309;-0.8334591;0.75856644;-5.704558;2.333665;-0.8784732;IRRE
none of the current multioutput multiclass estimators have;3.230758;-2.960716;-5.2522564;2.5621;-0.35485348;2.6100414;IRRE
decision function methods create a mock decision function;1.5963962;0.5818456;0.27264714;5.1529117;1.5148238;-2.0719514;CODE
to test the cross val predict function s handling of this case;3.5884564;2.4029665;-2.9406526;4.776447;-1.4622157;-2.4973884;CODE
the randomforest allows multiple classes in each label;1.4639947;-5.122764;0.14557387;2.144547;7.038872;1.2436434;IRRE
output of predict proba is a list of outputs of predict proba;3.0729923;-2.2634385;0.81973433;2.3041992;1.0192796;-1.6410671;IRRE
for each individual label;3.3016617;-1.7714453;4.6205916;-3.727821;5.8148465;-1.9028293;CODE
y 0 y 1 put three classes in the first column;1.6158607;-0.11790606;1.3473934;-6.5114517;2.295839;-2.5585115;CODE
suppress runtimewarning divide by zero encountered in log;0.09918493;4.767887;-3.6717503;2.2921839;-2.2721894;0.30264345;CODE
test a multiclass problem where one class will be missing from;1.2082827;4.053438;-2.559291;3.4791834;3.0855212;-4.0060506;IRRE
one of the cv training sets;4.98392;-4.602369;0.6840354;0.92977715;3.685986;-0.78171235;IRRE
suppress warning about too few examples of a class;-0.4417723;2.024436;-2.7925208;4.600678;2.9262264;-1.4874725;IRRE
the randomforest allows anything for the contents of the labels;0.042991515;-5.0937705;0.66262454;2.4091845;4.5713224;0.60661155;CODE
output of predict proba is a list of outputs of predict proba;3.0729923;-2.2634385;0.81973433;2.3041992;1.0192796;-1.6410671;IRRE
for each individual label;3.3016617;-1.7714453;4.6205916;-3.727821;5.8148465;-1.9028293;CODE
in this test the first label has a class with a single example;0.6021369;2.2366154;-1.3775084;2.4622493;4.8192854;-4.657056;CODE
we ll have one cv fold where the training data don t include it;2.939945;-2.9799924;-0.97662187;2.3222783;3.2941146;1.6609976;CODE
suppress runtimewarning divide by zero encountered in log;0.09918493;4.767887;-3.6717503;2.2921839;-2.2721894;0.30264345;CODE
to avoid 2 dimensional indexing;6.122047;0.13928826;1.2395853;-5.169773;2.1977148;2.3781886;CODE
test with n splits 3;2.350389;3.9846225;0.4688858;0.19413051;2.499705;-6.8393264;IRRE
runs a naive loop should be same as cross val predict;3.1839054;0.25194;-3.0836596;1.282801;-1.4216821;-2.238021;IRRE
test with n splits 4;2.5524378;3.998149;0.42569336;0.58720624;2.0962527;-6.4730477;IRRE
testing unordered labels;1.0946622;3.4724572;0.47659504;0.68961746;3.3614452;-3.8581266;IRRE
ensure a scalar score of memmap type is accepted;2.453433;2.5086372;-5.0747366;1.831506;1.0747259;2.6620464;-
best effort to release the mmap file handles before deleting the;-4.357487;-1.0264685;-0.4786344;2.9951732;-0.98042744;3.9802895;CODE
backing file under windows;-3.302161;-1.416033;1.7282116;-0.3929485;-2.0399048;1.4369286;CODE
check permutation test score doesn t destroy pandas dataframe;1.8024777;3.2643926;-3.1213365;0.46908414;-3.3473036;-4.783116;IRRE
x dataframe y series;2.20718;0.3485086;2.4500556;-4.944307;-4.861051;-2.1030798;-
create a failing classifier to deliberately fail;2.3337107;0.9141908;-2.5174584;5.8982677;2.3971093;-1.362875;IRRE
dummy x data;2.8132563;2.314031;1.0922567;-2.9479427;1.4361627;-1.6578492;-
passing error score to trigger the warning message;-1.3857832;4.711328;-2.5858335;3.9427466;-0.6959184;-1.0008653;-
check if exception was raised with default error score raise;-0.31343475;6.1873565;-3.6908915;5.5897593;-0.8941534;-1.7968804;CODE
assert failing clf score 0 0 failingclassifier coverage;1.4616328;3.028329;-7.456744;3.460433;-0.7609529;-4.4809785;CODE
test return parameters option;0.2431796;6.778911;-0.4587711;5.220412;-0.3563751;-3.2677155;IRRE
create a failing classifier to deliberately fail;2.3337107;0.9141908;-2.5174584;5.8982677;2.3971093;-1.362875;IRRE
dummy x data;2.8132563;2.314031;1.0922567;-2.9479427;1.4361627;-1.6578492;-
passing error score to trigger the warning message;-1.3857832;4.711328;-2.5858335;3.9427466;-0.6959184;-1.0008653;-
check if the warning message type is as expected;-2.7205758;5.48873;-4.2924953;3.029193;-1.3315489;-2.6273162;IRRE
create a failing classifier to deliberately fail;2.3337107;0.9141908;-2.5174584;5.8982677;2.3971093;-1.362875;IRRE
dummy x data;2.8132563;2.314031;1.0922567;-2.9479427;1.4361627;-1.6578492;-
check that an estimator can fail during scoring in cross val score and;2.8515413;5.002916;-2.6377952;4.264459;-1.5022628;-2.246651;-
that we can optionally replaced it with error score;-2.0299747;0.34697837;-0.29962218;4.9620595;2.2986293;-1.2786598;-
check that an estimator can fail during scoring in cross validate and;3.221677;4.7469554;-3.8703697;5.259441;0.2449694;-2.3525767;-
that we can optionally replace it with error score in the multimetric;1.2322088;1.0026834;-1.344848;3.285537;2.2555597;-0.42270505;CODE
case also check the result of a non failing scorer where the other scorers;0.38263497;4.956165;-0.033510752;3.0022626;0.53529567;-3.7051275;IRRE
are failing;-2.15507;1.8184806;1.201045;5.8961973;-2.4907465;-4.946725;-
check the test and optionally train score for the;1.3483887;3.0894725;-0.87540734;4.457538;2.6700208;-5.7586064;CODE
scorer that should be non failing;0.0724442;3.6108449;1.021458;4.02553;-0.77507985;-3.1870742;-
check the test and optionally train score for all;2.5506916;3.9776726;-0.7743773;4.4578934;2.9570339;-5.916522;CODE
scorers that should be assigned to error score;1.1293823;2.5422146;-0.3670233;2.1376395;1.5145422;-2.3082805;IRRE
test print without train score;1.8624212;1.7137091;-0.8857129;2.324931;0.5044773;-4.2286015;IRRE
does not error;-6.531916;4.0080504;-0.96240205;-0.015028414;-2.6570966;-4.9928555;TASK
x scale x scale features for better convergence;5.5740366;-2.840425;0.91259253;-0.11534907;-1.9899266;4.9630666;TASK
tests for metadata routing in cross val and in curve;1.2542174;-0.005307039;-2.1860898;2.871747;0.4608391;0.74501836;IRRE
cross val predict doesn t use scoring;2.418567;0.24559586;-2.516131;2.0582829;-2.1224055;-1.2028074;CODE
cross val predict doesn t need a scorer;1.9383054;0.7583161;-0.50769496;2.6135633;-0.8859324;-0.42308643;CODE
end of metadata routing tests;-1.7941252;-0.11229565;-1.954581;6.186775;1.3086045;0.12526533;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
predict proba threshold;5.5433054;-0.24129963;0.7141442;3.1401224;0.9243031;-1.9269127;-
onevsoneclassifier estimator is not validated yet;0.98104155;0.739781;-6.1182966;3.0178304;-0.9485355;0.8406277;TASK
we need to validate the data because we do a safe indexing later;2.9105814;2.6957667;-0.58272654;3.8039417;2.5235403;-1.1710178;TASK
onevsoneclassifier estimator is not validated yet;0.98104155;0.739781;-6.1182966;3.0178304;-0.9485355;0.8406277;TASK
outputcodeclassifier estimator is not validated yet;0.632087;-0.8180396;-6.6839867;3.1298769;-0.88559973;0.38127422;IRRE
fixme there are more elaborate methods than generating the codebook;-1.9410499;-5.3037586;-0.12397925;0.39978594;0.9746749;-2.2597048;-
randomly;0.9037473;-0.68823195;5.8525248;2.610535;0.9995652;-4.9739895;IRRE
argkmin only accepts c contiguous array the aggregated predictions need to be;3.8887024;1.510927;-2.9124568;-0.9053476;-2.9811056;1.0722859;TASK
transposed we therefore create a f contiguous array to avoid a copy and have;2.5599923;3.3806539;2.1470046;-3.9179792;0.16017738;0.8369495;CODE
a c contiguous array after the transpose operation;1.6681035;1.3387098;1.2639083;-6.38734;-1.1342864;0.9933211;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
multioutput estimator is not validated yet;2.421456;1.4839298;-4.6879196;2.6824856;-3.01707;2.0653853;IRRE
multioutput estimator is not validated yet;2.421456;1.4839298;-4.6879196;2.6824856;-3.01707;2.0653853;IRRE
raise an attributeerror if predict proba does not exist for;2.4644547;2.8116977;-5.5513754;4.6435895;-2.7046132;-1.6795452;CODE
each estimator;3.3721917;0.21005474;3.122821;1.5802065;0.13079181;2.1850863;-
raise an attributeerror if predict proba does not exist for the;2.5334604;2.6856413;-5.310044;4.4398355;-2.739472;-1.923699;CODE
unfitted estimator;1.3452519;3.2585902;-2.3878057;4.7155776;-1.9252782;1.752968;-
fixme;-3.8509557;-1.3406411;3.207323;2.4430208;-0.8963127;-1.2272774;-
todo 1 9 remove base estimator;0.68988;3.5737414;-1.1739409;0.9179994;-1.5281408;1.7021216;TASK
todo 1 9 this is a temporary getter method to validate input wrt deprecation;-1.8646834;4.013805;-2.056325;4.9511123;1.5286992;-3.0125966;CODE
it was only included to avoid relying on the presence of self estimator;-0.3923687;0.06528369;-3.362052;5.564174;-1.4946778;4.7551103;CODE
regressorchain does not have a chain method parameter so we;-2.845319;2.8978045;-3.7908976;0.73767674;-2.7022781;3.597229;IRRE
default to predict;1.7697778;-2.9048398;0.7590843;4.9462385;-1.5408386;1.354963;CODE
if x is a scipy sparse dok array we convert it to a sparse;4.2781096;-2.2259338;-3.6610854;-5.053567;-2.06374;0.66807616;IRRE
coo array format before hstacking it s faster see;2.0705895;2.3127604;0.2810281;-3.2275152;-0.67681736;-0.54263145;CODE
https github com scipy scipy issues 20060 issuecomment 1937007039;-1.9767686;-3.8771703;-6.9936223;-2.3635824;-7.3384843;-3.8836613;CODE
todo remove this condition check when the minimum supported scipy version;0.25110123;0.06768013;-8.412496;-0.6760889;-4.8897285;-2.341128;CODE
doesn t support sparse matrices anymore;1.9536579;-2.5930939;-3.8505042;-3.4231625;-2.4470246;4.4373407;IRRE
if x is a scipy sparse dok array we convert it to a sparse;4.2781096;-2.2259338;-3.6610854;-5.053567;-2.06374;0.66807616;IRRE
coo array format before hstacking it s faster see;2.0705895;2.3127604;0.2810281;-3.2275152;-0.67681736;-0.54263145;CODE
https github com scipy scipy issues 20060 issuecomment 1937007039;-1.9767697;-3.8771713;-6.993622;-2.3635817;-7.338483;-3.8836622;CODE
in case that x is a sparse array we create y pred chain as a;2.6234114;0.8636281;-0.048102863;-3.8561177;1.2696241;2.6984825;IRRE
sparse array format;4.662428;0.14056168;-0.54003274;-5.937281;0.95825607;-0.6337846;IRRE
regressorchain does not have a chain method parameter;-2.8859684;2.5522957;-3.6549628;0.34384125;-2.8225086;3.5998678;IRRE
predict proba output is 2d we use only output for classes 1;3.9935014;-0.4305649;-1.6182021;-1.0172678;0.00087678875;-0.39605707;IRRE
todo 1 9 remove base estimator from init;-1.0597091;3.7614534;-2.1065786;2.137479;-2.3848596;3.2312198;CODE
classifierchain base estimator is not validated yet;0.1147186;-0.580684;-6.9894686;3.3528943;0.16561809;1.0091525;TASK
fixme;-3.8509557;-1.3406411;3.207323;2.4430208;-0.8963127;-1.2272774;-
regressorchain base estimator is not validated yet;-0.9703921;2.7065353;-6.1189585;0.98613805;-3.9832647;2.4365673;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
compute potentially weighted mean and variance of new datapoints;6.6620464;-0.17041461;0.67805636;0.7046725;-0.49638522;2.2886705;CODE
combine mean of old and new data taking into consideration;3.740298;1.8916891;3.6523216;0.6548989;0.3024129;1.8614644;CODE
weighted number of observations;7.0511675;0.60606515;2.8756182;-0.05334067;1.3217056;1.495736;-
combine variance of old and new data taking into consideration;3.5922067;1.1768785;2.3321843;1.4354806;0.69842416;2.3717327;CODE
weighted number of observations this is achieved by combining;7.011048;0.035224;3.1672652;-0.5175361;2.9724157;2.091894;CODE
the sum of squared differences ssd;3.2448227;-0.38232127;-1.1895919;-1.861945;0.7068843;0.2605222;-
if the ratio of data variance between dimensions is too small it;6.072919;2.1491494;-1.5890094;-2.247385;-2.5588667;3.9795685;CODE
will cause numerical errors to address this we artificially;2.5514;1.4491187;-1.824111;1.199556;-0.19649358;-1.2725736;TASK
boost the variance by epsilon a small fraction of the standard;3.7784855;0.0069959112;-2.686919;0.4362346;-0.6393267;3.5378227;CODE
deviation of the largest dimension;4.4728208;-0.1339676;0.18940206;-3.7999375;-0.85101795;2.2550964;CODE
this is the first call to partial fit;2.0001552;0.8724871;1.7883965;2.5222518;0.8939533;4.0788574;IRRE
initialize various cumulative counters;0.19664615;2.5498474;2.405395;-1.3280466;1.3784766;-2.244004;IRRE
initialise the class prior;-1.9986608;0.9699341;1.0647789;2.5647395;4.134768;2.1702628;IRRE
take into account the priors;0.19175065;2.0005074;2.8618076;4.2333484;3.7740393;1.0384927;CODE
check that the provided prior matches the number of classes;1.9876547;3.6900997;-0.46028697;2.7717714;6.9374633;-3.298413;IRRE
check that the sum is 1;-1.0504354;4.510385;0.9287132;-0.3786081;-1.6300936;-7.7389455;-
check that the priors are non negative;0.52573746;4.8696914;-0.7382964;2.7675571;1.5796034;-0.83953184;-
initialize the priors to zeros for each class;1.9988313;2.1738436;0.099463895;-0.37508744;4.257012;1.9016788;CODE
put epsilon back in each time;0.3486359;3.794062;1.2301272;1.5390314;-1.1076617;-0.81398666;-
update if only no priors is provided;-1.7386992;3.7646964;1.0900742;4.0894237;3.1432245;0.8378467;CODE
empirical prior with sample weight taken into account;3.2740111;0.114300914;-1.3473004;2.2976024;0.8500324;3.4701555;CODE
silence the warning when count is 0 because class was not yet;-2.177805;3.9044755;-2.4191267;4.2803016;0.8992686;-3.0543299;TASK
observed;0.41108716;-0.07757937;5.5445857;3.7185633;0.18092045;-2.7030647;-
empirical prior with sample weight taken into account;3.2740111;0.114300914;-1.3473004;2.2976024;0.8500324;3.4701555;CODE
check that all alpha are positive;-1.2944249;4.7806573;-0.9687437;0.39135385;-1.5797715;-5.6373496;-
this is the first call to partial fit;2.0001552;0.8724871;1.7883965;2.5222518;0.8939533;4.0788574;IRRE
initialize various cumulative counters;0.19664615;2.5498474;2.405395;-1.3280466;1.3784766;-2.244004;IRRE
else degenerate case just one class;-1.1909425;1.8811847;-0.8621109;1.4164698;7.6024065;-0.7516326;CODE
label binarize returns arrays with dtype np int64;0.7639468;0.51899105;-6.7584147;-6.492785;-2.9778736;-2.2064972;CODE
we convert it to np float64 to support sample weight consistently;3.3937724;-0.6315794;-4.078234;-1.3864375;-3.0139167;0.70169294;CODE
count raw events from data before updating the class log prior;1.1017059;0.39556804;1.3493441;3.631239;1.1599851;-0.4270784;CODE
and feature log probas;-2.1843936;-5.4070816;-0.4413323;2.9154983;2.6376922;-1.2961835;TASK
xxx optim we could introduce a public finalization method to;-2.1569881;-0.9031125;0.17728424;3.7983332;4.512844;1.4839114;CODE
be called by the user explicitly just once after several consecutive;-3.8484626;3.5825164;4.3016944;3.1830258;2.9231746;-0.35271716;IRRE
calls to partial fit and prior any call to predict log proba;2.6349828;0.29859853;-0.717376;5.897886;0.7551732;3.4207845;IRRE
to avoid computing the smooth log probas at each call to partial fit;3.9579325;1.8872466;-2.3143184;2.4738147;-0.35512736;4.6105475;IRRE
else degenerate case just one class;-1.1909425;1.8811847;-0.8621109;1.4164698;7.6024065;-0.7516326;CODE
labelbinarizer fit transform returns arrays with dtype np int64;2.2416332;-0.14023785;-7.3881354;-5.12264;-3.253888;0.51083666;CODE
we convert it to np float64 to support sample weight consistently;3.3937724;-0.6315794;-4.078234;-1.3864375;-3.0139167;0.70169294;CODE
this means we also don t have to cast x to floating point;-0.8974215;1.9555974;-0.5056039;-2.3194103;-1.7064564;1.43191;CODE
count raw events from data before updating the class log prior;1.1017059;0.39556804;1.3493441;3.631239;1.1599851;-0.4270784;CODE
and feature log probas;-2.184392;-5.407082;-0.44133243;2.915499;2.6376915;-1.296184;TASK
compute neg prob 1 x t as neg prob x neg prob;0.44848454;3.140451;-0.8247008;-4.9490666;1.6533327;-5.3612885;-
callable metric is only valid for brute force and ball tree;1.5080391;-0.2239088;-1.8940707;1.9761062;0.6059569;-0.8930893;CODE
classification targets require a specific format;1.5446866;-3.6731827;-4.362671;0.36388063;3.891975;-0.2313119;CODE
using dtype np intp is necessary since np bincount;-0.24444199;-0.9713108;-6.5702596;-3.5572846;-0.70972437;-1.4114056;CODE
called in classification py fails when dealing;-0.59311175;-2.065346;-5.928456;1.6801485;-0.7317483;-0.4488726;IRRE
with a float64 array on 32bit systems;-1.5297611;1.0518625;-1.2878413;-5.6838603;-1.14099;-0.12470349;CODE
for minkowski distance use more efficient methods where available;4.485325;-2.4461582;0.87027305;-2.8001013;-2.2867072;3.0196972;CODE
use the generic minkowski metric possibly weighted;3.6175992;-0.9076562;-0.99570936;-2.562288;-1.0986639;4.8092165;IRRE
precomputed matrix x must be squared;1.3893969;1.891881;-2.1954117;-3.9783187;-2.7632394;1.7267691;TASK
a tree approach is better for small number of neighbors or small;3.1095755;-2.1881907;2.4988844;1.6221197;2.8001626;1.0962849;CODE
number of features with kdtree generally faster when available;2.4700158;-4.2259994;-1.7977421;0.86843425;0.919818;2.0388737;TASK
minkowski with weights is not supported by kdtree but is;0.4158502;-1.9251508;-5.120941;-2.2615957;-3.3216145;4.510989;META
supported byballtree;-3.875606;-4.440296;0.19821188;2.3298786;0.46497583;0.47723776;-
for 0 p 1 minkowski distances aren t valid distance;0.5537853;1.7462168;-3.6581774;-3.8926346;-4.031143;1.0985004;CODE
metric as they do not satisfy triangular inequality;0.8200379;2.0613573;1.1675156;-2.3149705;-1.3362517;0.98493135;CODE
they are semi metrics;1.2269331;-1.967154;1.5100256;-2.639395;0.60470635;1.0440016;-
algorithm kd tree and algorithm ball tree can t be used because;-1.5125504;-0.14970304;-1.8324956;-0.6245617;0.732664;-1.154394;-
kdtree and balltree require a proper distance metric to work properly;1.5174403;-0.48239818;-2.0058796;0.19236732;-1.6231867;2.5395615;CODE
however the brute force algorithm supports semi metrics;4.1230426;-2.4836223;-1.3749994;1.2458273;1.1231942;-0.9316012;CODE
else self fit method in kd tree ball tree;2.4670117;1.4501606;-0.27274048;-0.30759743;1.0616634;1.5156041;CODE
for cross validation routines to split data correctly;6.10021;0.5046104;0.40176022;1.9318234;3.5086007;-0.899393;CODE
when input is precomputed metric values all those values need to be positive;4.279442;3.1822236;-1.5198177;-2.3946319;-2.202421;-1.6764227;IRRE
joblib based backend which is used when user defined callable;-4.2574105;-2.0687234;-1.4234246;2.4738839;-1.2140088;1.999684;CODE
are passed for metric;2.080099;1.0702726;-0.87834793;0.7389316;0.7541588;-0.4445842;CODE
this won t be used in the future once pairwisedistancesreductions;2.3091872;1.3492701;-3.0734823;1.1031958;-0.08625995;4.615447;CODE
support;-3.0227196;-1.8991643;5.2507143;1.0532941;0.61170673;-2.089047;-
distancemetrics which work on supposedly binary data;4.82508;-1.1211932;-0.49674195;-3.481206;1.1848285;-1.0303714;-
csr dense and dense csr case if euclidean in metric;1.1343884;1.433944;-1.8185648;-2.1851866;-0.21975681;1.2969874;CODE
for efficiency use squared euclidean distances;6.0033836;-1.9410918;2.4697156;-3.0598512;-1.3664513;2.2751737;CODE
if the query data is the same as the indexed data we would like;2.691545;1.9949443;1.8686848;-0.74169075;4.464707;1.7407581;CODE
to ignore the first nearest neighbor of every sample i e;6.742839;2.4662855;1.0409157;-0.5655197;1.3370225;0.10615148;-
the sample itself;1.918664;-1.3871171;3.9456303;2.5689173;1.5060201;-3.191054;CODE
check the input only in self radius neighbors;2.002168;3.5086377;1.310331;-2.1269352;-1.7722356;-2.084;CODE
construct csr matrix representation of the nn graph;2.8161945;-1.5052196;-0.78708386;-7.6561713;0.7554993;1.5770001;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo implement a brute force version for testing purposes;-1.4934361;1.4866068;-0.89288163;5.771281;0.10902644;-4.72365;CODE
todo create a density estimation base class;3.1981957;-1.7286248;0.0682936;0.18195805;2.139001;3.8388896;IRRE
given the algorithm string metric string choose the optimal;4.0288453;0.003339319;-0.121209055;-1.1980158;2.779158;-0.32297307;CODE
algorithm to compute the result;4.7434115;1.9126251;4.2584987;-3.2350688;1.4194;-6.1472726;IRRE
use kd tree if possible;-0.27835378;-3.6819968;1.6132838;-1.4681071;4.130254;0.324939;-
else kd tree or ball tree;-1.648926;-1.8421817;3.1023948;-0.085299015;3.5837834;-0.6612535;-
kerneldensity metric is not validated yet;2.2581856;-1.8353416;-6.8300085;0.5981322;-1.959868;1.7977883;TASK
the returned density is normalized to the number of points;3.628246;1.2041417;0.9918048;-2.5633767;-1.2157595;3.2221518;CODE
for it to be a probability we must scale it for this reason;1.6011914;0.5543904;3.9812493;2.2964942;-0.71310806;1.4732447;CODE
we ll also scale atol;0.0066123586;0.3065813;3.5196416;0.46863878;-1.3972775;1.5947512;-
todo implement sampling for other valid kernel shapes;4.2139044;-1.6366394;-1.2608113;-0.57387143;2.8219717;3.728806;TASK
we first draw points from a d dimensional normal distribution;2.8172216;-0.6135001;2.5609417;-5.23157;-1.8367603;4.057879;CODE
then use an incomplete gamma function to map them to a uniform;1.9915308;2.4966333;2.3866067;-3.319721;-0.63068944;1.1746724;CODE
d dimensional tophat distribution;2.6975281;-0.9823721;0.55876905;-3.070093;-0.40516168;2.8698;META
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
as fit predict would be different from fit predict fit predict is;2.5224743;-0.603471;-0.43714422;2.9418173;-0.46426648;0.64860547;CODE
only available for outlier detection novelty false;2.6290843;-0.4747568;-1.840397;2.2458515;0.6014679;0.8232646;CODE
localoutlierfactor metric is not validated yet;1.1169469;0.40517375;-6.465492;2.0939922;-3.6512141;3.0823925;TASK
compute lof score over training samples to define offset;6.4844007;0.9093755;-1.8018156;-0.52600837;1.2713397;0.52511925;IRRE
inliers score around 1 the higher the less abnormal;3.609359;2.116132;-0.13719845;0.40233463;-1.402944;-1.8213075;-
verify if negative outlier factor values are within acceptable range;3.7130103;5.7824206;-2.6826255;-1.2609226;-2.8794801;-1.6461289;IRRE
novelty must also be false to detect outliers;3.4889705;-0.04158302;-1.1414958;3.2339115;1.1307516;0.62505484;IRRE
as bigger is better;-0.439282;0.7737037;4.4737787;1.0927483;-0.56187725;1.018288;-
1e 10 to avoid nan when nb of duplicates n neighbors;3.8686101;2.8040037;-0.94819325;-2.9021606;0.75153536;-2.5215735;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
validate the inputs x and y and converts y to numerical classes;4.042375;2.1798368;-1.5434717;-0.9992543;1.9680077;-4.2790523;CODE
check the preferred dimensionality of the projected space;3.8600109;1.8480413;-0.82487494;-1.6032374;0.8447443;2.42864;-
if warm start is enabled check that the inputs are consistent;-1.2043155;3.4243739;-1.7672058;2.1751206;-3.0446603;0.16049732;CODE
check how the linear transformation should be initialized;-0.042693887;4.208638;-0.18451388;-2.9303408;-2.41044;-0.3855424;IRRE
assert that init shape 1 x shape 1;1.4006174;5.2773232;-1.5801464;-1.1239327;0.41962117;-0.0026230663;IRRE
assert that init shape 0 init shape 1;-0.7204187;5.0313764;-2.4995944;-0.07152009;-0.52230257;-0.34019703;IRRE
assert that self n components init shape 0;-0.05203742;4.5213494;-3.3322713;-1.8314809;0.8975746;0.03108199;CODE
initialize the random generator;-1.743907;0.6063705;1.3577375;0.4177848;1.1492376;-1.1854352;IRRE
measure the total training time;4.5986624;-2.2066743;2.6976478;3.2080777;1.2762;-1.4921206;-
compute a mask that stays fixed during optimization;4.9351406;1.6946806;-0.8301718;-1.5143973;-0.8571961;5.7028546;-
n samples n samples;3.2683773;0.67745686;2.4860063;-2.470738;2.5379689;-4.08578;-
initialize the transformation;-1.7661963;2.0500038;2.5401754;-2.9420567;-1.7839296;1.5860035;IRRE
create a dictionary of parameters to be passed to the optimizer;4.276141;-0.26421472;-0.8052073;0.056293;2.0639458;2.5809994;IRRE
call the optimizer;3.10654;1.743178;2.2700856;0.16017412;-0.92456156;1.4150109;IRRE
reshape the solution found by the optimizer;4.915024;0.9460565;0.022405172;-3.2268105;-2.8518662;5.5707164;-
stop timer;-4.0500526;1.4308454;4.787671;2.0231435;-2.2430575;-1.0867214;-
warn the user if the algorithm did not converge;0.74599886;3.98896;-0.69602555;5.89609;-2.709407;-1.7945558;-
x embedded np dot x transformation t n samples n components;3.297179;-2.0039792;-3.894087;-6.157192;-1.1177075;3.9312787;CODE
compute softmax distances;5.4566526;-1.584491;1.2774459;-3.4448197;0.34454829;0.80761534;-
p ij softmax p ij n samples n samples;4.500573;-1.3357466;-1.2862136;-3.004681;2.2460232;-0.118432835;-
compute loss;3.7301135;1.1453454;1.1987909;-1.4552909;-1.3138866;-1.8014416;-
p np sum masked p ij axis 1 keepdims true n samples 1;6.076914;2.7685935;-2.893006;-5.8266916;-2.173373;1.3349234;-
compute gradient of loss w r t transform;1.3103153;-2.331876;-0.1807515;-1.8019001;-2.4351435;2.9474158;CODE
time complexity of the gradient o n components x n samples x;4.692255;-1.6897994;-1.6069404;-2.4431355;0.50650173;3.8775153;META
n samples n features;5.852936;-2.6180372;0.8141393;-3.781754;3.215305;-2.277004;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
if x is sparse and the metric is manhattan store it in a csc;4.4441986;0.0034454712;-1.4599569;-3.0553021;0.78151035;1.2415311;IRRE
format is easier to calculate the median;2.3015187;-0.20521785;2.9327068;-2.5977187;-0.5217795;-1.7101535;CODE
if self priors empirical estimate priors from sample;2.1365979;0.70515424;-1.1842507;2.5433369;0.7068779;3.4089465;CODE
class counts np unique y return inverse true non negative ints;3.7169127;2.3534808;-3.2767422;-3.5534618;0.4240506;-3.8347797;IRRE
mask mapping each class to its members;2.0337172;-1.0335052;0.94886047;-1.7579771;5.0540195;2.1947675;IRRE
number of clusters in each class;2.8447247;-1.8874943;1.1945902;-1.5701282;4.0213633;-1.0306923;IRRE
numpy does not calculate median of sparse matrices;3.3521945;-0.15497448;-3.976721;-4.809504;-7.358092;2.365343;IRRE
else metric euclidean;1.688659;1.89793;2.4521556;-3.1504052;-1.3340681;-0.89620477;CODE
compute within class std dev with unshrunked centroids;2.4595058;0.7595852;-3.1233819;-2.3848734;-0.6594026;1.8604032;CODE
m parameter for determining deviation;4.6265655;3.434685;-0.59553176;-1.2444316;-0.5180728;0.04141836;IRRE
calculate deviation using the standard deviation of centroids;2.5522482;1.1166282;0.84464866;-3.809269;-2.081194;0.79194355;-
to deter outliers from affecting the results;5.2746754;1.38843;1.1014184;4.452442;-1.0039644;-1.0038084;IRRE
mm m reshape len m 1 reshape to allow broadcasting;0.020834861;0.5095394;1.0769124;-4.872579;-0.26294056;4.790831;-
soft thresholding if the deviation crosses 0 during shrinking;4.52701;2.2152689;-0.88426775;0.30034816;-2.7047057;3.3529992;-
it becomes zero;-2.9339032;3.9570892;1.9003035;-2.685618;-4.581134;-1.9266852;-
now adjust the centroids using the deviation;4.87088;1.2387288;2.6373315;-3.823131;-1.7199941;2.6274188;-
validate data is called here since we are not calling super;-1.4938588;4.86072;-2.4166224;3.557253;-0.053801384;-1.8204185;IRRE
return discriminant scores see eq 18 2 p 652 of the esl;1.3449508;-0.41882104;-4.096327;-0.5971901;1.2426016;-1.4321426;IRRE
test the number of neighbors returned;3.4106724;4.013801;2.3024838;1.5020734;-0.7000993;-5.8120503;IRRE
with n neighbors;0.31303006;-2.1414928;5.290224;-1.031705;0.47101215;-1.4884446;-
with radius;-0.545325;-0.0012478804;7.214682;-2.2869477;-1.4134018;-2.0308733;-
xxx duplicated in test neighbors tree test kde;-0.36072883;2.7161963;-3.7816927;0.87989014;0.5902403;-2.1354153;IRRE
draw a tophat sample;1.9463321;-0.70174265;4.161914;-2.0102015;-0.39779043;0.36999434;-
check that samples are in the right range;5.1465178;5.5084343;-1.4713091;1.045636;-2.3239;-5.465094;CODE
5 standard deviations is safe for 100 samples but there s a;2.5720975;1.9708757;-1.6639193;0.81864214;-0.62618154;-2.8602972;META
very small chance this test could fail;1.0174779;4.5511875;-1.6128615;6.1132884;-1.592587;-6.1630435;IRRE
check unsupported kernels;-0.07472642;0.101293005;-4.1183653;0.8696111;-1.1915305;-2.999347;-
non regression test used to return a scalar;2.9188597;4.284637;-2.9448435;3.3874035;-3.997977;-2.840645;IRRE
smoke test for various metrics and algorithms;5.2309504;0.58774465;-0.20204556;2.9436312;-0.22051445;-1.5068463;CODE
x rng randn 10 2 2 features required for haversine dist;0.22709697;-1.0111408;-3.3729022;-2.0811267;3.2758687;-0.92119527;CODE
fixme;-3.8509557;-1.3406411;3.207323;2.4430208;-0.8963127;-1.2272774;-
rng np random randomstate 0;0.421138;-0.021391427;-2.2613485;-1.844431;-1.0276811;-3.0563698;IRRE
x rng random sample n samples n features;2.8813949;-2.3973768;-0.74661237;-1.7712793;2.522062;-0.8450315;IRRE
y rng random sample n samples n features;2.792918;-2.7866824;-0.08493451;-1.6558669;1.2778275;-1.3711694;IRRE
test that kde plays nice in pipelines and grid searches;3.0187967;-0.42719287;-1.8334237;5.1053853;0.1875855;-0.060053587;IRRE
test that adding a constant sample weight has no effect;1.7655603;7.021593;-2.2635658;4.092944;-1.9488567;-1.3982157;TASK
test equivalence between sampling and integer weights;3.8535435;4.279018;-1.2581644;2.5382597;1.6018628;-0.46240997;IRRE
test that sample weights has a non trivial effect;3.3527758;3.985344;-1.2179513;3.9547157;-0.72379297;-0.5601176;IRRE
test invariance with respect to arbitrary scaling;5.207093;3.425073;-1.8309191;1.8560474;-3.166345;3.5099463;IRRE
make sure that predictions are the same before and after pickling used;1.189115;-0.18506429;1.3886671;5.7155013;-1.0973022;-1.0158101;CODE
to be a bug because sample weights wasn t pickled and the resulting tree;1.328441;1.2991701;-2.9198873;3.5772316;-0.7907488;0.34915215;IRRE
would miss some info;-2.6103878;-2.0026972;1.8463224;1.2755994;0.44633552;-0.10906054;-
check that predict raises an exception in an unfitted estimator;1.7783461;5.166444;-4.967141;6.9503913;-2.495224;-0.8686649;CODE
unfitted estimators should raise a notfittederror;1.5749109;3.8365788;-5.496181;5.3528824;-4.730703;2.1211956;CODE
test that the attribute self bandwidth has the expected value;2.411267;4.1953607;-1.224762;3.3276424;0.16176003;-0.009295985;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the iris dataset;2.0183184;-3.0560672;-0.28385037;-2.0855289;-0.37324175;0.11386831;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
toy sample the last two samples are outliers;3.938262;2.7343266;0.16710347;0.44581923;-1.2977624;-2.6877098;CODE
test localoutlierfactor;1.7434014;2.896714;-3.3745294;4.070462;-1.86687;-0.9857241;IRRE
assert largest outlier score is smaller than smallest inlier score;3.9245036;4.5493207;-4.029958;2.434176;-2.1864462;-1.972574;CODE
assert predict works;3.3434079;3.3325765;-4.85416;7.470832;-1.125531;-4.325157;CODE
generate train test data;5.4570518;1.0310016;1.0194211;0.9852596;1.6887379;-4.5770183;CODE
generate some abnormal novel observations;5.389696;-1.1086786;1.1809517;1.1423573;-0.67577666;-1.1810746;-
fit the model for novelty detection;4.9155064;-1.7433404;0.90473986;3.1465;2.8723023;1.0718604;CODE
predict scores the lower the more normal;5.2460318;0.73912823;1.653883;1.6293417;-0.15331498;-2.2397165;-
check that roc auc is good;0.9386383;-1.9349498;-2.0312889;1.2339569;0.5825969;-2.1765757;-
toy samples;0.7133222;-1.3726614;4.922041;0.8843622;1.931808;-3.5150962;-
check predict;3.8367894;1.6049302;1.6527702;4.119329;-1.8573006;-6.539268;-
check predict one sample not in train;4.632356;4.0646644;-1.7365421;5.0303955;0.9424096;-3.8441033;CODE
check predict one sample already in train;4.411026;3.0704672;0.41337985;5.686284;2.1966949;-2.9418602;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
load and shuffle the iris dataset;4.7541437;-1.1975107;0.16730386;-1.8146402;1.6444948;1.1930717;CODE
avoid having test data introducing dependencies between tests;2.230546;3.7527108;-1.6193337;5.132241;2.345113;-0.8675856;CODE
elf loss np inf initialize the loss to very high;0.8334689;0.35927287;-4.8690233;0.5725142;-3.4624631;-0.1051223;IRRE
initialize a fake nca and variables needed to compute the loss;2.619707;1.8597287;-3.2388518;0.5293493;-0.06744724;0.61458576;IRRE
initialize a fake nca and variables needed to call the loss;0.5254751;2.5794926;-2.8619578;1.6265966;0.76428777;0.49339068;IRRE
function;-1.2390599;1.4956939;6.532339;-1.7183864;-0.46752357;-4.8876433;CODE
check that no error is raised when parameters have numpy integer or;2.7159984;5.3172426;-5.6043253;-2.174024;-5.325754;-3.4844377;CODE
floating types;-0.3341263;-0.4044065;0.75737876;-2.7979574;0.67717814;-1.5052545;CODE
toy sample;0.09531039;-1.1268612;5.4498596;1.2328323;2.0021768;-3.605327;-
also load the iris dataset;1.5464042;-4.3465104;-0.13598996;-1.1130621;-0.53984874;0.6428218;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
check classification on a toy dataset including sparse versions;6.232069;-3.2516024;-3.2538314;2.3024101;3.554597;-1.5464346;IRRE
check classification on a toy dataset including sparse versions;6.232069;-3.2516024;-3.2538314;2.3024101;3.554597;-1.5464346;IRRE
test uniform priors;1.3537252;3.4270642;-0.05092939;4.6414595;3.3504598;-1.3462332;IRRE
test custom priors;-0.3389116;4.716615;-0.7920423;6.012412;3.151039;-1.1385711;IRRE
same test but with a sparse matrix to fit and test;6.5640726;4.0306726;-2.7969184;-0.16907372;-1.6617854;-0.3628427;IRRE
fit with sparse test with non sparse;6.0820436;2.141584;-2.8386207;0.62915945;-1.0196471;1.2777859;IRRE
fit with non sparse test with sparse;6.0956125;1.7885727;-2.9869554;0.7126172;-0.9946801;1.6423045;IRRE
fit and predict with non csr sparse matrices;7.2047744;-2.3162723;-3.6490934;-0.8180873;-1.1400257;4.1941047;IRRE
check consistency on dataset iris;4.410563;1.6984775;-3.7309673;1.764228;0.5863222;-1.2973349;IRRE
check consistency on dataset iris when using shrinkage;4.5873375;1.3977389;-4.10614;1.0719188;-0.63691837;2.1400485;IRRE
classification;5.668271;-5.8220553;4.2595444;1.7214531;6.909542;-2.19592;IRRE
ensure that the shrinking is correct;1.5481951;2.304989;2.3990114;2.1227975;-2.842347;1.8418756;-
the expected result is calculated by r pamr;1.6892577;2.218224;-1.7818215;-1.3205701;-2.6280487;-3.1852956;IRRE
which is implemented by the author of the original paper;-1.1383462;-4.6955137;0.3869753;1.1561571;2.6357713;2.7081618;META
one need to modify the code to output the new centroid in pamr predict;0.8121393;1.2569579;-0.64080644;-2.1541343;-2.147402;1.1426088;TASK
test that nearestcentroid gives same results on translated data;3.421526;3.5017006;-1.5368454;1.3797168;-1.2279356;-0.86233515;IRRE
test the manhattan metric;3.2983768;1.9489207;1.9657521;-1.3641905;-1.9424105;-3.2790146;IRRE
test that features with 0 variance throw error;2.4424517;4.670154;-5.177004;4.0947633;-1.7092035;-3.500196;CODE
load and shuffle iris dataset;5.0458307;-1.2368498;-0.3332762;-1.9072682;1.8084507;0.79746825;IRRE
load and shuffle digits;1.9015276;1.1541922;2.387795;-2.553847;2.1881707;-1.9769796;CODE
filter deprecation warnings;-0.4871992;2.282337;-4.1443086;5.360926;-0.8745392;1.170803;-
a list containing metrics where the string specifies the use of the;2.167896;-1.6202979;0.64113563;0.27235702;2.8621547;-2.357475;CODE
distancemetric object directly as resolved in parse metric;1.8009398;-0.37445357;-1.1758592;-0.7374043;1.2166961;2.865868;IRRE
note smaller samples may result in spurious test success;3.4814725;5.1851387;-2.9492831;5.283686;-2.8322742;-3.261058;IRRE
todo also test radius neighbors but requires different assertion;0.10682377;4.6448708;-1.8051878;2.6365833;-2.5195549;-2.2383409;CODE
as a feature matrix n samples by n features;6.9180245;-4.2741356;0.31227815;-3.8106875;2.957595;1.9203023;TASK
as a dense distance matrix n samples by n samples;7.0437765;-1.9176896;0.2994555;-3.4569116;1.6764768;3.0365524;-
check auto works too;-5.0770226;2.6052444;-0.002827077;4.6929984;-2.4156768;-1.6144212;-
check x none in prediction;3.0450082;4.565889;-1.780664;1.5508505;-0.8294929;-3.6853037;-
must raise a valueerror if the matrix is not of correct shape;4.914364;3.7746637;-4.7729483;-3.4016643;-5.80112;-0.023976773;IRRE
we do not test radiusneighborsclassifier and radiusneighborsregressor;0.691064;1.5257962;-3.7498453;1.0602022;-0.13573986;-1.4995868;IRRE
since the precomputed neighbors graph is built with k neighbors only;2.6222937;-1.2578936;0.4968557;-3.0160153;-0.94070405;1.0507771;-
we do not test kneighborsclassifier and kneighborsregressor;1.0529168;-0.18664365;-4.781871;1.370384;-0.13373946;-2.8867588;IRRE
since the precomputed neighbors graph is built with a radius;1.8238319;-0.10801347;2.3579535;-2.8866298;-2.241334;1.6174601;-
test that is sorted by data works as expected in csr sparse matrix;4.8440638;3.0373704;-5.0813656;-0.6443507;-2.1503196;-0.31611228;IRRE
entries in each row can be sorted by indices by data or unsorted;4.702695;1.3544664;1.0374979;-5.893574;1.8448021;-0.3202106;CODE
is sorted by data should return true when entries are sorted by data;2.7027667;3.6692016;0.5310851;-0.029546436;0.46495607;-1.470401;IRRE
and false in all other cases;-2.2183707;3.0586593;-0.043563932;2.17345;2.3644063;-3.9685855;CODE
test with sorted single row sparse array;5.7487774;4.354431;-1.970649;-0.5839112;-0.41459665;-3.1062174;IRRE
test with unsorted 1d array;3.6779792;6.6057982;-0.6030839;-1.3947169;-0.9952963;-4.792441;IRRE
test when the data is sorted in each sample but not necessarily;4.7770686;6.0030146;1.0047095;1.4471592;0.9349158;-3.9942849;IRRE
between samples;5.2620277;2.2976627;5.3041534;-1.1727458;2.4851778;-2.505972;-
test with duplicates entries in x indptr;2.3991969;5.325604;-1.6680995;0.72452456;1.6488726;-5.1935644;IRRE
test that sort graph by row values returns a graph sorted by row values;3.8307433;4.466619;0.31726602;-1.8782027;-1.6173234;-2.7365437;IRRE
test with a different number of nonzero entries for each sample;5.2275963;6.2666965;0.96466;1.2456145;3.828069;-5.6735506;CODE
test if the sorting is done inplace if x is csr so that xt is x;0.841983;5.5052733;-1.582719;-0.0039142338;0.17899886;-2.991427;IRRE
sort graph by row values is done inplace if copy false;2.4734108;4.787686;0.1099711;-3.3451555;-2.9413896;0.2198716;IRRE
check precomputed is never done inplace;-1.5614942;6.654445;-1.0127286;3.9472055;-0.9977153;-1.0495566;CODE
do not raise if x is not csr and copy true;-1.0040518;4.8160377;-1.9584777;0.23539901;-0.19067143;-1.6977222;CODE
raise if x is not csr and copy false;-0.53918576;5.2161274;-2.0637426;0.39998907;-0.09084814;-2.193714;IRRE
test that the parameter warn when not sorted works as expected;-0.16768754;7.5063624;-2.9297435;4.7711606;-1.3180488;-3.1617203;IRRE
warning;-3.0231862;-0.29702285;2.0558126;3.4345493;-1.4731644;-1.9746032;-
no warning;-3.428291;0.15151484;1.1328743;2.8978696;-2.249273;-1.5405139;-
test that sort graph by row values and check precomputed error on bad formats;4.8097553;5.089532;-2.6913974;-1.5367935;-1.9793701;-3.466176;IRRE
ensures enough number of nearest neighbors;4.4424562;-0.027829787;0.48477143;-0.38225654;1.5114496;2.2631674;-
checks error with inconsistent distance matrix;3.6133552;4.8373313;-4.354269;-2.1534452;-3.3508236;-1.4942541;META
ensure array is split correctly;2.9711673;5.742598;0.33751062;-0.32928985;0.4051192;-2.7484825;-
test unsupervised radius based query;3.59315;4.7508817;0.21942084;1.3790172;1.3084685;-3.138812;CODE
sort the results this is not done automatically for;1.3119789;1.4759661;1.1957799;1.2807466;-0.74933064;-1.0072887;CODE
radius searches;2.5712056;0.35131013;3.9844213;-1.0096494;-0.005606088;-1.5456907;-
test k neighbors classification;6.5995502;-1.4067677;-0.65361917;0.120937824;2.32673;-3.7657976;IRRE
test prediction with y str;4.6909714;1.9072396;-0.06804569;3.1476502;-2.1267943;-5.8211236;IRRE
test k neighbors classification;6.5995502;-1.4067677;-0.65361917;0.120937824;2.32673;-3.7657976;IRRE
test kneighborsclassifier predict proba method;5.37574;-1.9881797;-4.0193915;1.8005792;1.2194225;-3.8324168;IRRE
cls neighbors kneighborsclassifier n neighbors 3 p 1 cityblock dist;2.060875;-2.692567;0.2232949;-4.375219;1.98628;-0.7244868;IRRE
check that it also works with non integer labels;-1.5791936;3.4548914;-2.843375;-3.3515396;1.6737527;-1.90057;CODE
check that it works with weights distance;1.920518;2.807335;0.34243327;1.717718;-2.3777978;0.2266763;-
test radius based classification;6.214827;-0.41710827;0.33761385;1.9505616;3.007475;-3.1162236;IRRE
test radius based classifier when no neighbors found;4.255498;1.589724;-2.0301044;1.84526;0.7582379;-2.1847925;IRRE
in this case it should rise an informative exception;-3.1562214;2.9548252;-1.8556888;5.6609664;1.5943817;0.32883745;CODE
no outliers;3.3783967;-0.37661895;1.5278533;1.1625649;-1.7764087;-1.7228116;-
one outlier;3.513075;1.16213;2.7999327;0.4231547;-0.39187515;-2.5504475;-
test radius based classifier when no neighbors found and outliers;4.9963493;0.889306;-2.4134948;1.2973326;0.060833637;-1.0519395;IRRE
are labeled;0.8443185;-2.69267;3.2516906;1.3131723;5.7155275;-2.0010283;-
no outliers;3.3783967;-0.37661895;1.5278533;1.1625649;-1.7764087;-1.7228116;-
one outlier;3.513075;1.16213;2.7999327;0.4231547;-0.39187515;-2.5504475;-
test outlier labeling of using predict proba;5.60472;1.8342774;-2.5009665;4.22032;0.48870108;-1.9574155;IRRE
test outlier label scalar verification;5.1720757;3.6921146;-4.3031745;1.3899071;-0.28319284;-2.783223;IRRE
test invalid outlier label dtype;2.431111;3.464976;-6.6420374;0.123966455;-2.5359073;-3.6778412;IRRE
test most frequent;3.9499128;2.1846933;3.0575888;5.9398685;0.94793266;-5.8050413;IRRE
test manual label in y;-0.3222394;1.8956311;0.21864808;-0.60071677;0.0447968;-5.336373;IRRE
test manual label out of y warning;-2.9626665;3.7116158;-3.8376968;2.6635773;-1.8206155;-4.375209;IRRE
test multi output same outlier label;5.3342934;5.3768144;-1.3196626;0.64595795;0.65606385;-3.470642;IRRE
test multi output different outlier label;5.0937643;5.3760877;-1.354679;0.51005685;0.5649853;-2.7428288;IRRE
test inconsistent outlier label list length;4.074045;4.4215236;-3.100164;0.9735984;-1.2058327;-3.0300226;IRRE
test radius based classifier when distance to a sample is zero;5.23588;2.5798643;-1.4220897;1.2866782;0.8118981;-1.7603545;IRRE
ignore the warning raised in weight func when making;-1.4038637;3.1640658;-3.0363874;3.2912242;-2.6650212;1.815846;CODE
predictions with null distances resulting in np inf values;5.5023746;1.450449;-4.690677;-0.7440286;-3.6328213;0.19366245;IRRE
test radius based regressor when distance to a sample is zero;3.5479438;5.6474166;-0.6349708;-0.03381061;-3.0384371;0.0014752148;IRRE
we don t test for weights weight func since user will be expected;1.3312782;2.7596624;-0.574804;5.0557528;-1.2849483;-1.2470226;CODE
to handle zero distances themselves in the function;1.966775;3.1046417;2.1618865;-3.2809453;-1.675932;1.6290458;CODE
check that we can pass precomputed distances to;3.1663463;3.1897607;1.6201036;0.5734937;0.07268528;0.37604794;-
nearestneighbors radius neighbors;4.0468607;-0.43116087;2.0447361;-4.365145;-0.9351035;-0.10160695;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 16036;-3.6653893;-10.147303;-5.56287;-0.24672401;-5.0413504;-5.072;CODE
for several candidates for the k th nearest neighbor position;5.857505;-3.486891;1.6052991;-0.27163827;4.3053646;-0.13009576;CODE
the first candidate should be chosen;0.065152764;0.5634025;2.3148594;2.738437;3.8742177;-0.5823473;CODE
the 3rd and 4th points should not replace the 2nd point;-1.2026072;3.910857;3.0030324;-2.1511288;-0.23543637;0.023711905;CODE
for the 2th nearest neighbor position;5.767139;-2.021104;3.1100504;-4.300097;2.0530357;-0.037669398;CODE
test radius neighbors graph output when sort result is true;3.5805724;4.1657243;0.17861895;-0.84472996;-2.3390954;-3.1673183;IRRE
self radius neighbors;2.273895;0.016228432;2.6300774;-2.7942486;-1.0878857;0.7533239;CODE
sort results true and return distance false;3.0285141;5.1929717;0.29732162;-0.027910706;-2.2203708;-2.7192614;IRRE
if metric precomputed no need to raise with precomputed graph;2.042765;1.9669566;1.2166526;-0.77794033;-1.3632482;3.0095513;TASK
self radius neighbors graph;2.1436355;-0.4585667;3.3286273;-4.8169656;-1.9446089;0.17703743;CODE
test k nn classifier on multioutput data;5.496318;-1.5238814;-2.7576046;1.0487933;2.1677234;-2.5710406;IRRE
stack single output prediction;5.2913046;-1.4024917;1.8560693;2.2346802;0.5128969;0.2053678;IRRE
multioutput prediction;6.2035656;-3.7319953;2.1973424;1.7338898;1.1487288;0.2918016;IRRE
test k nn classifier on sparse matrices;6.4351735;-1.7658566;-5.1765404;-0.62638116;0.92627877;-0.35271657;IRRE
like the above but with various types of sparse matrices;5.2017217;-3.048083;0.6010594;-4.1148524;1.7807411;3.9448626;IRRE
test k nn classifier on multioutput data;5.4963217;-1.523881;-2.7576044;1.048793;2.1677244;-2.5710413;IRRE
stack single output prediction;5.2913046;-1.4024917;1.8560693;2.2346802;0.5128969;0.2053678;IRRE
multioutput prediction;6.2035656;-3.7319953;2.1973424;1.7338898;1.1487288;0.2918016;IRRE
check proba;-1.6145716;2.4372585;3.6974647;2.0023658;1.0976346;-7.7522244;-
test k neighbors regression;5.556822;0.57462007;-0.7924981;1.6977166;-2.6798823;-2.8769972;IRRE
test k neighbors in multi output regression with uniform weight;6.6073475;1.3523259;-1.739446;0.018711273;-1.5014994;0.69058704;IRRE
test k neighbors in multi output regression;5.5712366;1.0854101;-0.6863627;0.8915307;-1.3655229;-1.1719848;IRRE
test radius based neighbors regression;6.0496383;0.98761433;0.32594395;1.649779;-2.6906345;-0.7468945;IRRE
test that nan is returned when no nearby observations;4.119862;6.397095;-0.9887298;1.6502744;-3.7773378;-3.584569;IRRE
test radius neighbors in multi output regression uniform weight;6.5327287;2.3323379;-1.3669612;-0.1429531;-2.1510167;1.3821541;IRRE
test k neighbors in multi output regression with various weight;6.5400352;0.899851;-1.0410213;0.32546258;-0.97597593;0.23256399;IRRE
test radius based regression on sparse matrices;7.650194;1.1830354;-1.5719801;-0.40836525;-2.6261587;1.3202689;IRRE
like the above but with various types of sparse matrices;5.2017217;-3.048083;0.6010594;-4.1148524;1.7807411;3.9448626;IRRE
sanity checks on the iris dataset;2.6185799;-2.1582098;-0.99976385;0.46672168;-0.16625962;-2.6466954;IRRE
puts three points of each label in the plane and performs a;2.919859;1.8718224;5.6143627;-4.8958707;2.1114628;-1.6787852;CODE
nearest neighbor query on points near the decision boundary;5.662899;-1.3612678;1.1333672;-1.4830571;3.2813807;2.1076648;CODE
sanity check on the digits dataset;5.518833;0.44211498;-1.2122077;-1.6694255;0.4041498;-5.254419;IRRE
the brute algorithm has been observed to fail if the input;1.0779577;1.9684414;-1.0775849;2.6247616;-1.7034426;-6.2543483;CODE
dtype is uint8 due to overflow in distance calculations;2.6789184;-0.2847787;-4.6065397;-4.0974555;-4.428002;-0.23587872;CODE
test kneighbors graph to build the k nearest neighbor graph;4.840083;-1.6935197;-0.64068407;-3.505608;-1.0383271;-2.3562565;IRRE
n neighbors 1;0.14256665;-1.284511;3.9972322;-3.7150402;0.2905087;-3.5170882;-
n neighbors 2;-0.40888616;-1.8742939;4.0993724;-3.3349702;0.039473537;-3.0295959;-
n neighbors 3;-0.7421287;-1.9496372;4.064561;-3.7495003;0.39310881;-3.0557497;-
test kneighbors graph to build the k nearest neighbor graph;4.840083;-1.6935197;-0.64068407;-3.505608;-1.0383271;-2.3562565;IRRE
for sparse input;6.424659;-2.609811;2.1156719;-2.196126;0.6291453;1.232453;CODE
test radius neighbors graph to build the nearest neighbor graph;3.9598339;0.7739823;1.0210835;-1.3075126;-1.4665408;-2.4120572;IRRE
test radius neighbors graph to build the nearest neighbor graph;3.9598339;0.7739823;1.0210835;-1.3075126;-1.4665408;-2.4120572;IRRE
for sparse input;6.424659;-2.609811;2.1156719;-2.196126;0.6291453;1.232453;CODE
test computing the neighbors for various metrics;6.897891;0.24310188;-0.4523946;-0.7883478;-0.5971516;-3.0689206;CODE
some metric e g weighted minkowski are not supported by kdtree;0.4037662;-1.7940896;-5.4011827;-1.8453293;-3.0419471;4.69082;-
if tree in algorithm pragma nocover;0.19555026;3.0168579;-1.4737271;0.73460823;3.5620873;-3.4084244;-
haversine distance only accepts 2d data;2.7287776;2.8115141;-1.1425467;-5.81964;-3.3201606;1.9603883;-
the returned distances are always in float64 regardless of the input dtype;2.4082835;0.9597821;-4.5811815;-4.5551095;-5.3935347;-0.60056025;CODE
we need to adjust the tolerance w r t the input dtype;1.242563;0.699784;-2.6910415;-0.79309267;-3.4947145;-0.09375817;TASK
todo remove ignore warnings when minimum supported scipy version is 1 17;-1.821073;-0.63705105;-7.7278175;1.7962054;-5.229206;-1.718294;TASK
some scipy metrics are deprecated depending on the scipy version but we;1.6384361;-4.189609;-6.236003;-0.38037127;-6.030978;-0.7275666;META
still want to test them;-0.35280293;0.6778813;1.2562971;3.8974466;-1.2275943;-5.3199935;TASK
both backend for the brute algorithm of kneighbors must give identical results;2.0810907;-0.3886504;-1.9963802;-1.7502964;-0.8235297;-3.5612981;CODE
haversine distance only accepts 2d data;2.7287776;2.8115141;-1.1425467;-5.81964;-3.3201606;1.9603883;-
use the legacy backend for brute;-4.2142773;-2.2932851;1.0538913;3.3544173;-0.34066007;-1.43709;CODE
use the pairwise distances reduction backend for brute;6.193036;0.7003291;0.25799373;-3.73866;0.01577368;-1.2007388;CODE
haversine distance only accepts 2d data;2.7287776;2.8115141;-1.1425467;-5.81964;-3.3201606;1.9603883;-
find a reasonable radius;0.7537122;2.8901303;4.4382005;-0.5622982;-2.36726;-2.007756;-
test kneighbors graph;3.1275842;0.5726142;0.82937974;-3.7794619;-2.1315887;-4.7993126;IRRE
test radiusneighbors graph;2.3420622;3.0059984;2.1424444;-2.1136503;-2.3840396;-4.2513213;IRRE
raise error when wrong parameters are supplied;-0.80276716;7.1169486;-3.801911;4.1473217;-1.0028164;0.34554902;IRRE
test kneighbors et al when query is not training data;2.3513591;0.49065864;-4.291241;2.2701263;0.38864234;-3.3885853;IRRE
test neighbors;2.5257187;1.309504;2.1596563;4.125769;-0.600346;-5.3858266;IRRE
test the graph variants;4.028282;1.4444315;2.0687892;0.020610694;0.7968171;-3.5827637;IRRE
test kneighbors et al when query is none;-0.064311415;3.344072;-4.0128083;0.16520387;-0.11153654;-5.620827;IRRE
test the graph variants;4.028282;1.4444315;2.0687892;0.020610694;0.7968171;-3.5827637;IRRE
test behavior of kneighbors when duplicates are present in query;1.4605396;3.6788547;-1.4845805;2.1182134;2.1361868;-3.7591848;CODE
do not do anything special to duplicates;-2.1176975;0.88065046;2.163981;1.3493541;2.3947937;-1.7154588;CODE
mask the first duplicates when n duplicates n neighbors;2.5172422;1.5487401;2.0183342;-3.158855;2.0063117;-0.9652871;CODE
test that zeros are explicitly marked in kneighbors graph;1.8170764;3.5069945;-1.9273249;-3.2578478;-1.9174092;-3.5852246;IRRE
test include self parameter in neighbors graph;1.8165054;4.0234237;-2.0579298;0.65372986;-0.43858665;-1.5572711;CODE
todo remove mark once loky bug is fixed;-5.863762;1.7962039;-1.221311;2.4669986;-1.3744892;2.2256227;TASK
https github com joblib loky issues 458;-5.9445925;-3.3966901;-3.4007475;-0.13234863;-4.2971582;-1.9892539;CODE
non regression test which ensures the knn methods are properly working;3.1897185;1.9069973;-3.9110491;4.650983;-1.947712;-2.215233;IRRE
even when forcing the global joblib backend;-4.9053;-2.0087268;-3.066595;3.9154472;-3.5626233;2.9360175;CODE
def sparse metric x y metric accepting sparse matrix input only;5.0559487;-1.1674957;-3.4354937;-4.003515;-1.9612033;3.7500424;IRRE
1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 population matrix;3.3099456;2.2317007;-0.052180454;-7.2617526;-0.043973472;-0.89830744;-
y csr container 1 1 0 1 1 1 0 0 1 1 query matrix;3.2673254;2.5106027;-1.5161039;-8.094289;0.72995913;0.31846774;CODE
gs indices of nearest neighbours in x for sparse metric;5.097241;-1.4856797;-1.7521011;-4.1971297;1.0594555;3.7237496;IRRE
ignore conversion to boolean in pairwise distances;4.036176;5.1017814;-1.6150044;-3.2385082;-0.21440858;-1.1507701;META
non regression test for 4523;0.26711738;4.0188265;-2.9496293;2.3982286;-2.0171235;-6.0396543;IRRE
brute uses scipy spatial distance through pairwise distances;5.0248504;-2.3951824;-0.78350574;-4.229675;-3.3080578;-2.536428;-
ball tree uses sklearn neighbors dist metrics;4.6799426;-3.9458306;-3.2024145;-1.8309966;-1.3782927;-0.3134168;-
test chaining kneighborstransformer and classifiers regressors;5.485692;-1.7792275;-4.7032413;0.26487923;2.2186;-0.6053172;IRRE
we precompute more neighbors than necessary to have equivalence between;2.1924918;-2.3905292;0.47960258;1.0064275;0.3689066;1.1198789;-
k neighbors estimator after radius neighbors transformer and vice versa;3.5530698;-0.69840986;-0.60208005;-1.2846972;-2.7109916;5.7265215;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
todo remove ignore warnings when minimum supported scipy version is 1 17;-1.821073;-0.63705105;-7.7278175;1.7962054;-5.229206;-1.718294;TASK
some scipy metrics are deprecated depending on the scipy version but we;1.6384361;-4.189609;-6.236003;-0.38037127;-6.030978;-0.7275666;META
still want to test them;-0.35280293;0.6778813;1.2562971;3.8974466;-1.2275943;-5.3199935;TASK
both backends for the brute algorithm of radius neighbors;2.7581446;-2.3015203;1.3232614;-1.6654626;-0.5829157;-1.5520358;CODE
must give identical results;2.2932787;4.171516;2.1737177;0.24185559;1.8340542;-6.414786;IRRE
haversine distance only accepts 2d data;2.7287776;2.8115141;-1.1425467;-5.81964;-3.3201606;1.9603883;-
use the legacy backend for brute;-4.2142773;-2.2932851;1.0538913;3.3544173;-0.34066007;-1.43709;CODE
use the pairwise distances reduction backend for brute;6.193036;0.7003291;0.25799373;-3.73866;0.01577368;-1.2007388;CODE
set the radius for radiusneighborsregressor to some percentile of the;1.6687526;2.5502403;2.2146232;-3.7527308;-2.395569;3.0610137;IRRE
empirical pairwise distances to avoid trivial test cases and warnings for;6.2806797;0.27311787;-2.2524314;2.5947602;1.1113068;-1.9156215;CODE
predictions with no neighbors within the radius;6.0949507;-0.5880858;2.6146846;0.8778178;-1.969691;-0.5655377;CODE
evaluating nn model on its training set should lead to a higher;4.7047997;-1.7112169;-1.164204;3.3003926;1.6935948;-0.6333751;IRRE
accuracy value than leaving out each data point in turn because the;7.4095364;3.2369034;1.2966275;-0.28911114;-1.4932239;-1.7634561;IRRE
former can overfit while the latter cannot by construction;-2.9625256;2.9184554;-0.58976203;2.1802785;2.5935795;1.2729359;CODE
test chaining kneighborstransformer and spectralclustering;4.896343;-1.6639333;-4.317739;-1.6144631;-0.69472855;1.9150223;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining kneighborstransformer and spectralembedding;4.3022013;-0.9665548;-4.005267;-2.0510755;0.7971241;2.919543;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining radiusneighborstransformer and dbscan;1.6870944;2.5325134;-2.6638746;-0.5594032;1.3463876;-0.07727136;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining kneighborstransformer and isomap with;2.6278944;1.2158297;-3.6432817;-1.9759926;0.08679258;1.2104045;IRRE
neighbors algorithm precomputed;4.146752;-0.5808849;0.024512345;-3.319306;0.7681873;0.4478813;-
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining kneighborstransformer and tsne;1.7307259;2.1708887;-3.6945965;-0.027177926;0.61662936;-1.5174695;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining kneighborstransformer and localoutlierfactor;2.4813204;1.2354287;-4.5153875;0.9290908;-0.6280975;1.1380037;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining kneighborstransformer and localoutlierfactor;2.4813204;1.2354287;-4.5153875;0.9290908;-0.6280975;1.1380037;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
test chaining kneighborstransformer and classifiers regressors;5.485692;-1.7792263;-4.7032404;0.26487863;2.2185996;-0.60531604;IRRE
we precompute more neighbors than necessary to have equivalence between;2.1924918;-2.3905292;0.47960258;1.0064275;0.3689066;1.1198789;-
k neighbors estimator after radius neighbors transformer and vice versa;3.5530698;-0.69840986;-0.60208005;-1.2846972;-2.7109916;5.7265215;IRRE
compare the chained version and the compact version;-1.9314504;-0.48583004;0.51629364;2.5253923;1.9819181;1.2141652;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
eps 1e 15 roundoff error can cause test to fail;0.1483953;4.659585;-4.619526;1.2895015;-4.370257;-1.7475077;IRRE
eps 1e 15 roundoff error can cause test to fail;0.1483953;4.659585;-4.619526;1.2895015;-4.370257;-1.7475077;IRRE
simultaneous sort rows using function;3.105447;2.9404306;3.5619752;-4.283363;0.53005904;-1.6155583;CODE
simultaneous sort rows using numpy;2.5344508;-0.31388327;1.1403301;-5.6207447;-4.391035;-0.18162714;-
compare gaussian kde results to scipy stats gaussian kde;5.2407913;-2.0939612;-3.578915;-0.8639975;-3.3327625;-1.1718985;IRRE
don t check indices here if there are any duplicate distances;4.3867397;3.7263806;0.6591889;-4.6199;-0.07397469;-2.3610423;CODE
the indices may not match distances should not have this problem;3.34117;3.890102;-2.3384614;-5.3009734;-2.640361;0.042180315;CODE
introduce a point into a quad tree with boundaries not easy to compute;1.4003785;0.29547152;2.2360604;-3.5404992;0.121204674;1.4797785;CODE
check a random case;1.0476824;4.1319256;2.287576;2.8485456;3.3852093;-6.6714597;IRRE
check the case where only 0 are inserted;-1.0589136;8.370519;0.13575137;-1.849514;1.5122586;-6.7955065;CODE
check the case where only negative are inserted;-1.1486217;7.1061482;0.17168301;-1.90493;1.2098643;-5.9718747;CODE
check the case where only small numbers are inserted;0.7518242;6.290422;0.88762957;-0.81187254;1.1028934;-6.3347044;CODE
introduce a point into a quad tree where a similar point already exists;0.8716023;1.2818348;2.1753452;-2.7914248;1.5296934;2.0918577;CODE
test will hang if it doesn t complete;-2.8027105;4.0940843;-0.38019437;6.249175;-2.8990138;-5.4723115;CODE
check the case where points are actually different;3.8850043;5.1302314;0.5309898;-1.7345041;-0.30435553;-2.4427943;CODE
check the case where points are the same on x axis;4.0824485;5.437165;3.086826;-5.982556;-2.3344188;-1.885823;CODE
check the case where points are arbitrarily close on x axis;3.370808;5.114641;1.542803;-4.68695;-3.2034786;-1.2737216;CODE
check the case where points are the same on y axis;3.4505098;4.8155785;2.8753698;-5.6565785;-4.0882797;-2.53719;CODE
check the case where points are arbitrarily close on y axis;3.0109894;4.752539;1.2736555;-4.3963113;-4.580956;-2.0557966;CODE
check the case where points are arbitrarily close on both axes;3.106702;4.983299;0.5947966;-4.597829;-4.331564;-0.19212846;CODE
check the case where points are arbitrarily close on both axes;3.106702;4.983299;0.5947966;-4.597829;-4.331564;-0.19212846;CODE
close to machine epsilon x axis;2.6415203;0.98436576;0.9363946;-4.9383254;-3.6703787;1.825921;IRRE
check the case where points are arbitrarily close on both axes;3.106702;4.983299;0.5947966;-4.597829;-4.331564;-0.19212846;CODE
close to machine epsilon y axis;2.7866502;0.7486184;1.2454803;-4.7250876;-4.574619;1.1836289;IRRE
create some duplicates;0.2681461;0.4681736;4.0846252;-0.63038695;5.0251355;-2.8887327;IRRE
epsilon 1e 6 is defined in sklearn neighbors quad tree pyx but not;-0.46694785;-1.2864953;-7.502492;-2.1735368;-2.1425972;-2.841663e-05;CODE
accessible from python;-3.808997;-6.2753615;0.6528256;-0.9941718;-2.5320446;-3.840342;CODE
add slight noise duplicate detection should tolerate tiny numerical differences;5.5825896;1.8197544;-2.8223522;0.41621232;2.649649;0.3242202;TASK
assert that the first 5 are indeed duplicated and that the next;0.3285826;4.678699;1.5158064;2.2736318;3.5776377;-5.2602353;CODE
ones are single point leaf;0.50837904;-0.28806463;2.9777195;-2.675198;1.7448367;-0.8517432;CODE
simple check for quad tree s summarize;2.8864033;0.7342934;0.43804872;-1.6259326;3.1777909;-3.1622362;CODE
summary should contain only 1 node with size 3 and distance to;1.5529075;2.8092425;2.395273;-3.649528;0.80246496;0.38411275;-
x 1 barycenter;0.025004579;0.035834473;2.581107;-5.244026;0.15367147;-2.5336795;IRRE
summary should contain all 3 node with size 1 and distance to;1.8216577;1.9648323;3.1476762;-4.203064;1.0969325;0.18404461;-
each point in x 1 for angle 0;-0.13393492;2.3510776;3.1251261;-5.838156;-2.029784;-0.95123565;CODE
input validation would remove feature names so we disable it;-2.0937889;1.0854391;-2.4364383;3.6494913;0.22209707;0.31978023;TASK
matrix of actions to be taken under the possible combinations;0.32582048;-0.6049532;4.0766897;-1.7288343;3.3003514;1.0174067;-
the case that incremental true and classes not defined is;-1.71387;1.0860336;-1.7240459;3.2971208;4.642676;-0.16161035;CODE
already checked by check partial fit first call that is called;0.12640691;5.176943;-3.1520355;2.2206523;-1.7078742;1.8620936;IRRE
in partial fit below;2.9887235;2.4219215;2.4246337;-1.9616866;0.44808114;2.2794564;-
the cases are already grouped into the respective if blocks below;-0.69792736;4.315753;1.7733603;-0.94468945;3.5573642;-2.5677183;CODE
incremental warm start classes def action;-0.46527228;-1.5179505;0.5244214;3.176008;2.114763;1.4956007;CODE
0 0 0 define classes;-1.8068078;0.9802994;-2.6101286;-3.1897936;2.5122538;-2.009566;CODE
0 1 0 define classes;-1.7375343;0.29729468;-1.7987276;-3.12177;3.2820718;-2.0972881;CODE
0 0 1 redefine classes;-2.662686;1.5328592;-2.6176708;-2.080587;3.2412326;-0.1740111;CODE
0 1 1 check compat warm start;-2.5076807;3.3664;-0.31688803;-1.2729113;-1.9877886;-3.4829164;-
1 1 1 check compat warm start;-2.183952;3.201479;0.39792067;-1.5037817;-0.4419439;-3.2802992;-
1 0 1 check compat last fit;-0.7862549;4.7832026;-2.1533968;-3.7241106;-0.79987806;-2.6563797;-
note the reliance on short circuiting here so that the second;-1.7291849;0.77314514;1.8002087;1.9990882;0.55955994;-0.2887387;TASK
or part implies that classes is defined;-3.150938;-0.7969818;-2.0177674;2.1351066;6.501084;0.44120312;CODE
this downcast to bool is to prevent upcasting when working with;-4.8135347;0.91892856;0.34186602;2.7676363;-0.43353197;3.3061604;CODE
float32 data;1.0347733;0.6864523;-0.6359387;-6.7811923;-0.6001221;-1.2310643;CODE
y proba is equal to one should result in a finite logloss;-0.19075084;2.3543074;-0.16927312;-0.30338055;0.34155488;-0.98604953;IRRE
y proba is equal to 1 should result in a finite logloss;-0.5597809;2.2977502;-0.66293126;-0.79087573;-0.1854969;-1.1909198;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
test that larger alpha yields weights closer to zero;3.474374;4.6004605;-1.8987181;1.6224893;-3.1524732;-1.6827639;IRRE
test that the algorithm solution is equal to a worked out example;2.666041;4.717709;-0.8902481;4.0952477;-0.19798401;-5.550446;IRRE
set weights;3.2620604;1.1360731;4.752411;-0.27702442;0.9147665;1.2565048;IRRE
initialize parameters;-2.4375098;3.457137;0.7710395;-0.37739763;0.9161005;1.5690955;IRRE
compute the number of layers;1.0285724;0.035946768;3.550567;-3.1824894;0.49354753;-0.97229916;-
pre allocate gradient matrices;3.0447264;-1.0902579;-0.6385984;-2.7567348;-0.68609154;7.0175195;-
manually worked out example;-2.3551376;-1.2479299;1.8403693;2.0424225;-0.18009782;-4.2138133;CODE
h1 g x1 w i1 b11 g 0 6 0 1 0 8 0 3 0 7 0 5 0 1;2.4608595;1.3599833;0.49574786;-7.562589;1.0542765;-1.1053569;-
0 679178699175393;-3.71416;-0.09288179;-0.16446303;-4.2795663;-0.11872574;-5.276955;-
h2 g x2 w i2 b12 g 0 6 0 2 0 8 0 1 0 7 0 0 1;1.0889697;1.4187074;0.8421145;-7.437138;-0.269455;-1.6054283;-
0 574442516811659;-4.530767;-0.7299736;0.34817907;-4.0743036;0.008289789;-5.3481803;-
o1 g h w2 b21 g 0 679 0 1 0 574 0 2 1;0.33505476;1.4046534;-0.24058622;-7.4582267;1.1898203;-3.5593758;-
0 7654329236196236;-3.6252506;-0.8305312;0.020259703;-3.7038362;-0.17987531;-4.7379375;-
d21 0 0 765 0 765;-0.08616415;0.87510985;-0.5533921;-5.9270434;-1.0532793;-4.187638;-
d11 1 0 679 0 679 0 765 0 1 0 01667;1.0138149;1.0717505;-0.81530976;-8.693051;1.1664461;-5.090217;-
d12 1 0 574 0 574 0 765 0 2 0 0374;1.8833625;0.7073108;0.30788362;-8.264842;0.88117164;-5.061589;-
w1grad11 x1 d11 alpha w11 0 6 0 01667 0 1 0 1 0 0200;-0.50917697;-0.41658086;-2.7552898;-7.15949;1.6657987;-1.4765948;-
w1grad11 x1 d12 alpha w12 0 6 0 0374 0 1 0 2 0 04244;0.19687428;-0.26695892;-2.2159774;-7.2144217;1.8463627;-1.3944902;-
w1grad21 x2 d11 alpha w13 0 8 0 01667 0 1 0 3 0 043336;-0.8913986;-0.2934436;-2.5681746;-7.701863;1.4584368;-2.1309123;-
w1grad22 x2 d12 alpha w14 0 8 0 0374 0 1 0 1 0 03992;-0.5475725;0.029388228;-1.4818774;-7.23317;1.1089064;-2.6059222;-
w1grad31 x3 d11 alpha w15 0 6 0 01667 0 1 0 5 0 060002;-0.79834545;-0.50695515;-2.056119;-8.021213;1.8850869;-2.2977986;-
w1grad32 x3 d12 alpha w16 0 6 0 0374 0 1 0 0 02244;-1.0466326;-0.291177;-3.2764885;-7.068916;1.6290357;-1.5969206;-
w2grad1 h1 d21 alpha w21 0 679 0 765 0 1 0 1 0 5294;-0.8653833;-0.14751251;-1.5809728;-6.411987;0.4988332;-2.7771697;-
w2grad2 h2 d21 alpha w22 0 574 0 765 0 1 0 2 0 45911;-2.0949075;-0.08090993;-1.5524403;-5.87442;0.10593802;-2.31615;-
b1grad1 d11 0 01667;-3.1334784;-0.1331146;-2.2402039;-5.526424;1.4241382;-4.784699;TASK
b1grad2 d12 0 0374;-2.5164244;-0.2407244;-1.2118938;-4.7693934;1.086;-4.4145694;TASK
b2grad d21 0 765;-2.397471;-0.93708414;-2.2999644;-3.90475;0.13987222;-2.665183;TASK
w1 w1 eta w1grad11 w1grad32 0 1 0 2 0 3 0 1;-1.108533;-0.003992637;-2.160392;-4.890825;2.8221433;-1.282437;-
0 5 0 0 1 0 0200 0 04244 0 043336 0 03992;1.6152602;1.146437;-0.9566128;-10.1391115;-0.12714145;-5.711866;-
0 060002 0 02244 0 098 0 195756 0 2956664;-0.98080635;0.39434227;-0.6556328;-8.882981;0.34216282;-6.571032;-
0 096008 0 4939998 0 002244;-1.2240638;1.0942965;-0.8439382;-8.686374;-0.40335357;-5.5789766;-
w2 w2 eta w2grad1 w2grad2 0 1 0 2 0 1;-0.90454394;-0.02295067;-0.4734081;-3.2016091;1.4237413;-0.8158245;-
0 5294 0 45911 0 04706 0 154089;-2.2836025;0.7781575;-1.1941452;-6.967612;0.4595779;-6.9167733;-
b1 b1 eta b1grad1 b1grad2 0 1 0 1 0 01667 0 0374;1.4527453;1.1175331;0.18961853;-8.543198;0.58387035;-5.5332055;-
0 098333 0 09626;-2.601527;0.46850932;-0.5166616;-6.524407;0.5073064;-5.0558705;-
b2 b2 eta b2grad 1 0 0 1 0 765 0 9235;-0.17157598;0.15827073;-1.1863588;-5.4981856;0.723599;-3.0890288;-
testing output;1.1609591;5.718175;0.84808296;3.0591712;-1.6222112;-9.849249;IRRE
h1 g x1 w i1 b11 g 0 6 0 098 0 8 0 2956664;1.148538;1.1790122;0.15063491;-8.509619;0.74120003;-3.0204604;-
0 7 0 4939998 0 098333 0 677;-0.19232672;0.9560934;0.55845016;-8.323313;-0.79362315;-6.1256795;-
h2 g x2 w i2 b12 g 0 6 0 195756 0 8 0 096008;-1.1074734;1.0983899;-0.47900432;-7.0603347;-0.020852286;-2.9262915;-
0 7 0 002244 0 09626 0 572;-0.5830593;0.5700961;0.95387965;-8.272967;-0.9998415;-6.287392;-
o1 h w2 b21 0 677 0 04706;-3.0480163;0.64444435;-1.7104161;-6.7054973;1.154983;-3.4485931;-
0 572 0 154089 0 9235 1 043;-1.317452;1.6826887;-0.20789433;-7.795345;-0.61324185;-7.2711062;-
prob sigmoid o1 0 739;-2.124267;-0.1362585;-1.941331;-4.4161363;-0.5234037;-2.3633547;CODE
test gradient;3.4326344;1.8622967;0.3930979;1.633077;-1.9306126;-2.4938803;IRRE
this makes sure that the activation functions and their derivatives;-2.6730542;-2.4329123;0.97027844;-0.55126166;-0.8516535;3.5243168;CODE
are correct the numerical and analytical computation of the gradient;1.5184517;-2.1623664;-0.6191744;-1.7780101;-1.2051051;2.5282497;-
should be close;-1.9552557;-0.23178495;4.3475647;1.0805172;-0.08980655;-1.6506894;CODE
analytically compute the gradients;2.440091;-2.260966;1.2363352;-2.134401;-0.1152735;2.6752388;IRRE
numerically compute the gradients;3.3397844;-1.7297639;0.3217677;-3.2388484;-0.77928346;2.2231362;IRRE
test lbfgs on classification;5.8280926;-0.919463;-3.8231413;4.2980967;3.406955;-2.8814745;IRRE
it should achieve a score higher than 0 95 for the binary and multi class;2.0225253;-0.88061273;-3.7149208;0.5276875;3.3474119;-4.3176656;CODE
versions of the digits dataset;3.9105234;-3.564288;-0.14253312;-3.2133543;1.2214947;-3.2753928;IRRE
test lbfgs on the regression dataset;4.493778;1.066765;-3.4938214;3.7736626;-2.0366564;-2.1881864;IRRE
non linear models perform much better than linear bottleneck;4.437165;-2.027419;-1.3047189;1.7982754;-3.201907;2.3893087;CODE
test lbfgs parameter max fun;1.8261962;4.5100126;-2.8987122;2.7115564;-0.6533888;-2.2404943;IRRE
it should independently limit the number of iterations for lbfgs;2.847679;1.9071587;-1.3182093;2.8856905;-0.07374815;1.8872867;CODE
classification tests;5.3988085;-2.4291635;1.2939936;4.3924003;4.4409447;-6.3580017;IRRE
test lbfgs parameter max fun;1.8261962;4.5100126;-2.8987122;2.7115564;-0.6533888;-2.2404943;IRRE
it should independently limit the number of iterations for lbfgs;2.847679;1.9071587;-1.3182093;2.8856905;-0.07374815;1.8872867;CODE
regression tests;3.3711073;2.1266837;2.326818;5.602503;-2.525502;-6.452263;IRRE
tests that warm start reuse past solutions;-0.36317378;2.2351615;-1.7274194;6.767474;-1.0590029;-1.8835284;IRRE
test that multi label classification works as expected;2.8477194;1.7126961;-2.8811972;3.2062922;3.1030378;-3.0355854;IRRE
test fit method;5.585967;4.383887;-0.51413447;3.6226273;-1.1039677;-4.0672674;IRRE
test partial fit method;5.1739693;5.3614473;-1.2324275;4.5887747;-0.6045546;-1.9091872;IRRE
make sure early stopping still work now that splitting is stratified by;-0.8760924;3.258592;-1.2917292;4.3712173;0.11425911;1.9779748;TASK
default it is disabled for multilabel classification;-1.878656;-2.762025;-1.4418741;0.37722185;2.2012558;3.1938095;CODE
test that multi output regression works as expected;2.7467859;5.330376;-1.9972438;4.1191764;-2.83022;-2.9666257;IRRE
tests that passing different classes to partial fit raises an error;3.0609765;4.320424;-5.986313;5.274668;0.32912698;-0.4748758;IRRE
test partial fit on classification;5.4833727;0.8806619;-1.1111389;3.623909;2.9565833;-1.7596142;IRRE
partial fit should yield the same results as fit for binary and;4.551768;1.9643047;-3.806978;-1.5774529;1.3116955;0.9655443;IRRE
multi class classification;4.6807666;-5.1017866;0.7374978;0.31634367;7.2296243;-0.7677803;IRRE
non regression test for bug 6994;-0.59840953;3.9251077;-6.826038;4.611739;-3.6208856;-4.301251;IRRE
tests for labeling errors in partial fit;4.503114;2.893719;-2.846149;3.957771;0.57029736;-0.965065;IRRE
test partial fit on regression;3.0683172;4.264883;-0.0800603;3.585761;-2.3002634;-1.0998108;IRRE
partial fit should yield the same results as fit for regression;3.3894994;1.9273013;0.118549496;3.0028248;-1.7065477;2.9314103;IRRE
test partial fit error handling;4.040106;6.550402;-3.9232266;5.570705;-1.3061733;-1.1038259;IRRE
no classes passed;-4.924953;-0.86197335;-2.5295568;1.062866;1.0239594;-3.3727026;IRRE
lbfgs doesn t support partial fit;0.56580925;0.6717554;-4.2182236;0.83112204;-1.8639778;4.091118;CODE
check that mlpregressor throws valueerror when dealing with non finite;2.4175835;4.619698;-6.9404078;2.5042028;-2.477032;-0.9895904;IRRE
parameter values;1.095785;3.979132;2.3594053;-2.8443184;2.1664894;-1.8315636;IRRE
runtimewarning overflow encountered in square;-0.71751106;1.8352945;-1.6340395;-0.27823514;-4.25828;1.3945004;CODE
test that predict proba works as expected for binary class;1.9078631;1.8279403;-5.0326424;4.0633197;0.8620585;-4.947641;IRRE
test that predict proba works as expected for multi class;3.3569381;2.0830214;-3.2641122;5.534312;2.0667677;-3.4077199;IRRE
test that predict proba works as expected for multilabel;2.8280752;1.4231625;-1.9834396;3.723848;1.5793295;-2.1599698;IRRE
multilabel should not use softmax which makes probabilities sum to 1;1.7567811;-0.42177835;-1.1939191;-0.59606236;2.378689;1.678603;-
test that the shuffle parameter affects the training process it should;3.477051;2.4492662;-1.4947495;6.262814;1.7341231;-1.3422002;IRRE
the coefficients will be identical if both do or do not shuffle;2.3630505;3.351126;-0.37538573;-2.5055869;1.8229764;0.29776764;CODE
the coefficients will be slightly different if shuffle true;3.1311107;3.1483235;-1.4714869;-2.418375;0.7501094;0.81261826;CODE
test that sparse and dense input matrices output the same results;6.13464;2.460175;-4.4313326;-0.31439263;-2.3036797;0.7536328;IRRE
test tolerance;1.1302063;3.9738224;0.02600559;6.4985294;-1.1709586;-5.192369;IRRE
it should force the solver to exit the loop when it converges;-0.9954639;3.5488439;-1.0028554;2.6936553;-4.5316563;-0.37035888;IRRE
test verbose;-0.5125068;4.8636394;-0.51745856;6.2540307;-0.16278036;-7.6213193;IRRE
check that the attributes validation scores and best validation score;3.865801;2.9168608;-0.6527644;2.709114;2.4674277;-3.64223;META
are set to none when early stopping false;-1.3351293;6.6796727;-1.2774343;5.033913;-2.3838794;-0.6322781;IRRE
no error raised;-5.290681;3.8558218;-3.2325153;1.4214585;-3.3378975;-2.851687;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 16812;-3.34806;-9.38567;-6.103278;-0.62349546;-5.0086174;-5.17773;CODE
check that the mlp estimator accomplish max iter with a;2.4896636;2.9217165;-3.8763254;2.371922;-1.4634228;2.1510963;-
warm started estimator;1.5164593;1.1727364;0.63919175;2.8869095;-3.5980926;1.6310483;-
test n iter no change using binary data set;2.3647358;5.1384606;-3.3442218;-0.96323127;0.49671277;-5.2349086;IRRE
the classifying fitting process is not prone to loss curve fluctuations;7.0844126;-3.5373213;-2.7220552;2.2088766;-1.7619973;3.827083;IRRE
test multiple n iter no change;1.5348456;6.2596383;-0.4087192;2.8014927;0.9054087;-6.4749846;IRRE
validate n iter no change;-1.9221871;5.1573267;-1.6911513;1.567734;1.9046776;-2.8339243;-
test n iter no change using binary data set;2.3647358;5.1384606;-3.3442218;-0.96323127;0.49671277;-5.2349086;IRRE
the fitting process should go to max iter iterations;2.732842;1.6900793;-1.4442755;-0.8254937;-3.0175998;3.2139752;-
set a ridiculous tolerance;-0.900622;3.387215;1.9491566;3.1950493;-2.1578958;0.023223832;IRRE
this should always trigger update no improvement count;-1.1932222;0.8972861;0.110698454;5.5299277;-0.3026918;0.67082787;CODE
fit;0.26204967;0.27998868;4.9577327;0.11692925;0.031527434;-1.2871358;-
validate n iter no change doesn t cause early stopping;-1.261175;5.9361024;-3.0337553;5.305773;-1.3651607;-0.9210582;CODE
validate update no improvement count was always triggered;-0.41645932;3.9600716;-2.6053298;5.096526;-1.7110579;-1.4950253;TASK
make sure data splitting for early stopping is stratified;4.1483517;3.0861833;-1.8645407;4.271683;1.2309215;1.9779238;CODE
compare predictions for different dtypes;5.696286;-1.1467072;-2.2111084;2.7403827;-0.38583615;-2.3190222;IRRE
checks if input dtype is used for network parameters;1.0358533;2.0344324;-4.401475;0.53008205;-0.2385217;-0.74616826;CODE
and predictions;2.3574393;-3.0931704;4.599612;4.681033;0.43718803;-1.6790437;-
fit on x 2 y 4;0.5307937;0.6755324;2.9877727;-4.241605;-0.5338521;1.2753607;-
dump and load model;-0.22267073;-1.1978137;0.8094931;2.5319698;0.70487994;0.92992413;CODE
train for a more epochs on point x 2 y 1;3.4208126;-0.77801305;1.0180677;-2.2192962;-1.667032;0.96971816;CODE
finetuned model learned the new target;0.5584582;-3.0972285;0.2348625;6.5201054;0.99120575;1.9285835;CODE
unfortunately we can t set a zero hidden layer size so we use a trick by using;-0.9667745;2.6139352;-0.6800477;-2.8772998;-2.864858;6.0884113;IRRE
just one hidden layer node with an identity activation coefficients will;-0.37825868;0.40794367;-0.8187229;-1.3184263;2.996094;4.158616;-
therefore be different but predictions are the same;2.859644;-0.020045957;2.39349;4.8279443;1.030899;-0.639858;META
the same does not work with the squared error because the output activation is;1.2417927;1.8799303;-3.9008815;-1.225237;-4.3284416;1.8255383;IRRE
the identity instead of the exponential;-4.409148;0.59495795;1.3222255;-1.5935254;-0.35856077;-0.8766524;CODE
in place tricks shouldn t have modified x;-3.2284954;1.7490687;1.684428;1.11002;-0.4357596;0.76493186;-
bernoullirbm should work on small sparse matrices;5.913107;-2.4212968;-2.8690655;-3.5218222;-0.36335197;3.5619042;IRRE
bernoullirbm fit x no exception;0.49012128;2.76282;-4.0086126;-0.73338467;-0.84995306;0.27533993;CODE
xxx this test is very seed dependent it probably needs to be rewritten;-0.4581312;3.5534697;-2.6000452;2.5662177;-1.3460076;-4.5278783;CODE
gibbs on the rbm hidden layer should be able to recreate 0 1;0.011427684;0.29933196;-1.7654325;-2.5732627;0.20188437;3.2298837;IRRE
from the same input;-0.71912235;-0.26439852;6.841174;-0.03718854;3.1158001;-3.4892015;CODE
you need that much iters;-1.7298653;-0.0518728;2.2056248;-1.1453406;-1.2323881;-1.5882254;-
gibbs on the rbm hidden layer should be able to recreate 0 1 from;0.027204497;0.6208471;-1.8501823;-2.7398458;0.11735215;3.0915182;CODE
the same input even when the input is sparse and test against non sparse;4.363633;2.1903727;-3.2234483;0.94045645;-2.0592396;0.34972203;IRRE
check if we don t get nans sampling the full digits dataset;4.69384;3.3333867;-3.040201;-1.2351416;-2.8294768;-4.873853;IRRE
also check that sampling again will yield different results;2.8100688;5.5242662;-1.6633598;3.3852632;-1.5757188;-3.0745258;IRRE
test score samples pseudo likelihood method;3.4066741;1.9571061;-2.182232;1.8734877;0.9977878;-2.2722936;IRRE
assert that pseudo likelihood is computed without clipping;2.1445425;3.937736;-4.15999;3.3108156;-1.620626;2.3155618;CODE
see fabian s blog http bit ly 1iyefrk;-4.431145;-5.062937;0.7483518;-0.897286;0.44321403;-0.61376226;CODE
sparse vs dense should not affect the output also test sparse input;4.939302;2.4417455;-3.7830675;1.3157156;-2.6982985;0.3410365;IRRE
validation;0.9612818;3.4564471;2.1926444;3.89224;3.9736898;-5.883083;-
test numerical stability 2785 would previously generate infinities;1.2006942;2.3187687;-4.610861;0.5262848;-2.6437604;-2.4530911;IRRE
and crash with an exception;-4.560831;0.96928704;0.63619393;4.606438;0.32105514;-1.4788293;CODE
pytest mark thread unsafe manually captured stdout;-3.4542491;1.6311595;-2.386387;2.2372425;-4.13873;0.8035803;CODE
make sure rbm works with sparse input when verbose true;1.9353273;2.298651;-4.4246526;1.6798102;-0.0042163385;1.9714367;IRRE
make sure the captured standard output is sound;-2.0301821;2.3219752;-2.9315627;0.76583344;-2.6588805;0.9823642;IRRE
dtype in and dtype out should be consistent;0.8132284;-0.7907671;-4.4830737;-0.17041118;-0.21227749;-0.63212526;-
float 64 transformer;-2.1564546;0.9350264;0.0071701496;-4.8915873;-2.4521508;-0.13448851;CODE
float 32 transformer;-2.1199663;0.9582204;0.19275624;-5.1076646;-1.9282696;-0.102441385;CODE
results and attributes should be close enough in 32 bit and 64 bit;0.063997336;-1.4745576;-2.6109421;-0.4738523;2.9057977;-0.589968;IRRE
the pipeline can be used as any other estimator;1.7967923;-1.5985687;0.27947456;3.606052;0.105696425;5.1597915;CODE
and avoids leaking the test set into the train set;0.40087938;0.13056576;1.1101164;6.9090524;2.8588226;0.0036486536;IRRE
an estimator s parameter can be set using syntax;-0.004160935;1.2441521;-0.8318401;1.3092923;1.2003758;3.1778166;IRRE
warning the sparse tag can be incorrect;-0.8519516;0.54601663;-2.7287683;2.4490323;-0.11080443;1.7906071;IRRE
some pipelines accepting sparse data are wrongly tagged sparse false;3.819222;0.011078085;-6.1118565;2.0226479;-0.028194483;1.6584076;IRRE
for example pipeline pca estimator accepts sparse data;4.4927626;-2.6301801;-3.7625704;-1.1911272;-0.64000595;5.099374;CODE
even if the estimator doesn t as pca outputs a dense array;4.1027503;2.8146102;-3.1381135;0.090839334;-2.5507147;3.886838;IRRE
this happens when the steps is not a list of name estimator;-0.39204997;1.8727198;-3.3842385;2.4173608;-1.4139653;1.0140909;CODE
tuples and fit is not called yet to validate the steps;0.9179587;3.2590964;-3.612386;0.74555844;-1.3836975;-2.4432163;TASK
this happens when the steps is not a list of name estimator;-0.39204997;1.8727198;-3.3842385;2.4173608;-1.4139653;1.0140909;CODE
tuples and fit is not called yet to validate the steps;0.9179587;3.2590964;-3.612386;0.74555844;-1.3836975;-2.4432163;TASK
delegate to first step which will call check is fitted;-2.8297603;3.7293103;0.34463364;5.996674;0.3846416;3.003182;IRRE
first find the last step that is not passthrough;-4.3813715;2.3080525;1.1340675;0.9597793;-0.33997542;-1.3180739;-
all steps are passthrough so the pipeline is considered fitted;-1.5898147;-0.16391517;-1.6412287;3.266861;0.6040948;3.4221897;CODE
check if the last step of the pipeline is fitted;0.31239125;3.5693398;0.3302024;3.6359398;-0.8473789;0.25255394;IRRE
we only check the last step since if the last step is fit it;-1.8996843;3.0914493;1.4674097;3.0986543;-0.028860357;-0.28848618;-
means the previous steps should also be fit this is faster than;0.9053465;0.1573122;1.9614412;1.3868295;1.043279;1.2994853;CODE
checking if every step of the pipeline is fit;1.9759665;2.863263;-0.5060309;3.5677242;0.17717916;-0.28594607;CODE
is an estimator;0.80328447;0.55833966;2.5133379;3.4479637;-1.6711975;1.6555442;-
first we add all steps except the last one;-3.0728397;0.4006778;4.7631207;-0.8114214;1.2986279;-1.3813764;TASK
fit fit predict and fit transform call fit transform if it;3.7195568;1.0195272;-0.8907102;-0.81565577;-1.7268698;1.8906208;CODE
exists or else fit and transform;2.2058215;3.7237601;0.8643412;-0.2987827;2.0909145;-0.4264291;CODE
then we add the last step;-3.3653455;0.42479935;4.9655704;2.1063747;1.3305209;0.27652627;TASK
an estimator s parameter can be set using syntax;-0.004160935;1.2441521;-0.8318401;1.3092923;1.2003758;3.1778166;IRRE
todo slep6 remove when metadata routing cannot be disabled;-5.61098;1.6930459;-3.205838;2.6438422;-0.20211492;5.64911;TASK
all transformers are none;-3.5435138;0.30099002;1.1844393;-0.69685453;-1.5148534;-1.6475946;CODE
check if xs dimensions are valid;1.5982002;4.8396897;-2.4054496;-3.8962648;-0.22810417;-2.2720306;IRRE
x is passed to all transformers delegate to the first one;-5.4198065;0.85537547;0.20065495;0.14468175;1.0001432;2.3380566;CODE
delegate whether feature union was fitted;0.5226558;0.8772047;-2.1434572;4.7531714;2.5682247;2.255556;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
in scikit learn variance is always computed using float64 accumulators;1.821467;-4.4683065;-6.60377;-1.727169;-5.6907587;-1.3208817;CODE
if we are fitting on 1d arrays scale might be a scalar;7.5479546;0.84398645;-1.6416293;-4.109835;-4.0742283;4.448921;-
scale is an array;1.8838592;3.2294252;3.5850797;-4.438207;-3.5623019;0.38862225;-
detect near constant values to avoid dividing by a very small;5.9310007;5.7314277;1.1639993;-1.1620402;-1.348629;-2.5798342;IRRE
value that could lead to surprising results and numerical;3.1738505;3.0839565;0.42918205;0.3716201;-3.0959709;-5.6055646;IRRE
stability issues;-0.42386943;1.0880592;0.58176845;0.76089257;-3.569091;0.60776794;-
new array to avoid side effects;1.3238194;3.2937644;1.9599324;-0.3045215;1.270612;-0.68108946;CODE
xr is a view on the original array that enables easy use of;-1.5304114;-0.9849837;2.7184098;-3.6234312;1.2992587;1.7264807;-
broadcasting on the axis in which we are interested in;0.63755125;-2.4056468;5.747056;-1.8231257;-1.8800628;3.7626944;CODE
verify that mean 1 is close to zero if x contains very;2.2314026;6.6128335;-0.64222425;-1.7680879;-2.4127336;-4.48702;IRRE
large values mean 1 can also be very large due to a lack of;3.23302;3.7100565;-0.88160133;-1.1593407;-3.3638008;-2.5918427;IRRE
precision of mean in this case a pre scaling of the;3.8267581;2.676268;1.2444419;-0.16921166;-4.9553022;2.027031;CODE
concerned feature is efficient for instance by its mean or;3.6944182;-1.3915751;1.2022574;4.129926;2.5474653;1.7829031;TASK
maximum;-1.3596199;0.006275604;5.2153406;-0.6442335;0.47318798;-3.35568;-
if mean 2 is not close to zero it comes from the fact that;1.4181345;3.6073549;-0.26933783;-1.6997986;-2.8466358;-2.6918228;CODE
scale is very small so that mean 2 mean 1 scale 0 even;1.230054;3.4755495;0.6185821;-3.461147;-5.37873;-0.5949213;-
if mean 1 was close to zero the problem is thus essentially;2.3624537;5.156243;-1.4136645;-0.09247568;-4.002317;-1.4159042;IRRE
due to the lack of precision of mean a solution is then to;2.4557967;3.4031126;-1.5256685;1.2071024;-5.213027;-0.20850186;-
subtract the mean again;1.106068;4.3781657;4.2540045;-0.48807338;-2.2179973;-2.1307623;-
checking one attribute is enough because they are all set together;2.2284625;4.7925944;-0.2339853;1.5955614;5.248193;-2.122538;IRRE
in partial fit;3.579035;0.90820867;3.2477043;1.7530845;1.5209756;1.4426845;-
reset internal state before fitting;-0.30172843;3.8110201;-0.7896041;2.7747083;-2.161242;5.397594;CODE
unlike the scaler object this function allows 1d input;1.427194;1.7026393;1.646984;-5.3434463;-2.8424778;2.5591753;CODE
if copy is required it will be done inside the scaler object;-1.6672268;1.9134804;0.18650866;0.6200996;-1.6362491;5.1665664;CODE
checking one attribute is enough because they are all set together;2.2284625;4.7925944;-0.2339853;1.5955614;5.248193;-2.122538;IRRE
in partial fit;3.579035;0.90820867;3.2477043;1.7530845;1.5209756;1.4426845;-
reset internal state before fitting;-0.30172843;3.8110201;-0.7896041;2.7747083;-2.161242;5.397594;CODE
even in the case of with mean false we update the mean anyway;0.45018685;4.4919243;-0.11297696;5.260826;-1.4375957;0.6012839;CODE
this is needed for the incremental computation of the var;1.4786043;1.0428777;-0.6669155;-0.7166887;2.1918924;0.7854775;CODE
see incr mean variance axis and incremental mean variance axis;1.6604222;-0.14416634;1.8651074;-4.470592;-3.2407877;2.453672;CODE
if n samples seen is an integer i e no missing values we need to;4.495809;5.3066697;-1.0663174;-2.4406443;1.1523992;-4.2878804;IRRE
transform it to an array of shape n features required by;5.084351;-0.85371023;2.379337;-5.614321;1.566633;0.91954565;CODE
incr mean variance axis and incremental variance axis;2.0236976;1.6989455;1.0382565;-4.251297;-3.4955719;3.8355222;CODE
first pass;-2.334604;0.56066936;3.5713375;1.3039509;1.4124656;-2.9345164;-
next passes;-2.025406;0.27055162;5.2882;2.8313613;1.2603582;-2.685759;-
we force the mean and variance to float64 for large arrays;3.4431016;0.7333309;-1.5834246;-1.9620981;-3.234164;0.8830508;CODE
see https github com scikit learn scikit learn pull 12338;-2.4825134;-10.564038;-3.982134;-1.3074828;-3.7427762;-4.2825427;CODE
elf mean none as with mean must be false for sparse;3.010414;1.7823354;-4.5487275;-0.44801024;-1.7191933;0.068758786;TASK
first pass;-2.334604;0.56066936;3.5713375;1.3039509;1.4124656;-2.9345164;-
for backward compatibility reduce n samples seen to an integer;5.277574;2.5741794;-4.302207;-0.43107983;2.682871;-1.1633934;CODE
if the number of samples is the same for each feature i e no;6.4878526;1.3178372;1.4850439;0.9386879;4.643808;-1.9330097;CODE
missing values;0.6812976;4.817846;0.061043583;-2.770763;-0.9457375;-5.3258653;IRRE
extract the list of near constant features on the raw variances;5.946001;-0.9522842;-1.5247728;-0.9445219;-0.79631895;1.6084231;CODE
before taking the square root;-3.4241104;1.059631;2.5445998;0.18424386;-2.5177226;-2.0010867;CODE
checking one attribute is enough because they are all set together;2.2284625;4.7925944;-0.2339853;1.5955614;5.248193;-2.122538;IRRE
in partial fit;3.579035;0.90820867;3.2477043;1.7530845;1.5209756;1.4426845;-
reset internal state before fitting;-0.30172843;3.8110201;-0.7896041;2.7747083;-2.161242;5.397594;CODE
unlike the scaler object this function allows 1d input;1.427194;1.7026393;1.646984;-5.3434463;-2.8424778;2.5591753;CODE
if copy is required it will be done inside the scaler object;-1.6672268;1.9134804;0.18650866;0.6200996;-1.6362491;5.1665664;CODE
at fit convert sparse matrices to csc for optimized computation of;7.3889055;-1.5016562;-3.8302553;-2.5189834;-0.9526908;3.8580272;IRRE
the quantiles;1.6108327;0.36839727;4.7627797;-1.484991;0.050850276;-2.4130175;-
else axis 1;-0.2548074;2.0973346;5.6780205;-7.115998;-1.9667096;-2.1973996;-
todo this should be refactored because binarize also calls;-4.3269186;2.359491;-2.1956623;1.5460509;1.0190003;0.8964869;CODE
check array;0.11556828;6.5429287;2.3546858;-0.35303265;-0.31944588;-7.39154;-
x is called k in these methods;0.071199834;-0.163938;1.1390939;-2.8217778;1.0319345;-0.6246813;IRRE
for inverse transform match a uniform distribution;0.6661152;1.7385551;1.5823473;-1.6989838;-1.5411589;1.2992932;CODE
with np errstate invalid ignore hide nan comparison warnings;1.8950509;4.7508836;-6.4562306;-0.426775;-3.0797799;-1.2528368;OUTD
else output distribution is already a uniform distribution;-0.36406022;2.7496722;-0.30038714;-0.2752348;-1.040288;0.2846794;META
find index for lower and higher bounds;2.4614847;3.1389186;2.1737344;-4.9840684;0.67865545;-3.1413941;IRRE
with np errstate invalid ignore hide nan comparison warnings;1.8950509;4.7508836;-6.4562306;-0.426775;-3.0797799;-1.2528368;OUTD
interpolate in one direction and in the other and take the;2.7205746;1.5781103;5.5499835;-4.441715;-1.4422097;-0.21672843;CODE
mean this is in case of repeated values in the features;3.9633732;1.1142716;1.7408036;-1.0828997;1.3917747;-1.7125375;CODE
and hence repeated quantiles;1.3331716;1.8594518;3.084977;-0.24519396;1.8003433;-0.73669577;-
if we don t do this only one extreme of the duplicated is;-1.5656137;0.2702798;2.328441;2.1238961;2.4685414;1.0653924;CODE
used the upper when we do ascending and the;-3.113753;0.9173952;4.890365;-0.9604234;0.31344095;-0.8108119;CODE
lower for descending we take the mean of these two;1.9260694;3.1912088;3.237285;-0.2795193;-1.0560484;-0.6305419;CODE
for forward transform match the output distribution;2.0762124;1.7020906;1.1431612;-2.0426762;0.16564454;2.2024546;CODE
with np errstate invalid ignore hide nan comparison warnings;1.8950509;4.7508836;-6.4562306;-0.426775;-3.0797799;-1.2528368;OUTD
find the value to clip the data to avoid mapping to;4.453195;4.175368;3.839905;-3.5086396;-0.34517694;-0.6656648;CODE
infinity clip such that the inverse transform will be;-1.4019494;2.1319366;2.874294;-2.1658459;-3.2642395;2.871654;IRRE
consistent;0.123794615;1.70566;4.5007706;4.532128;0.55036336;-0.94481415;-
else output distribution is uniform and the ppf is the;0.7536336;2.885482;0.38710397;-0.9248486;-0.94966716;-0.6868417;IRRE
identity function so we let x col unchanged;-1.2477248;2.318153;1.6187637;-3.7492142;-0.16108182;0.4269865;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
else self dtype is none;-1.2237551;-0.9725507;-3.679736;0.19640449;0.514349;-1.891048;CODE
take a subsample of x;0.67518866;2.729213;2.2598767;-1.3471903;2.7458203;-0.33544055;-
when resampling it is important to subsample with replacement to;3.4763343;1.5524454;0.6586706;1.7860389;2.3320959;2.4686923;CODE
preserve the distribution in particular in the presence of a few data;4.901702;1.9155979;2.8807504;1.4222178;1.9477358;3.7572508;META
points with large weights you can check this by setting replace false;4.3522005;2.4147973;0.7623374;-0.5433628;-1.6587324;1.8778801;CODE
in sklearn utils test test indexing test resample weighted and check that;4.51521;1.7872186;-5.3441753;1.4048966;-1.9275783;-2.9855433;IRRE
it fails as a justification for this claim;-2.2742395;1.0705643;-1.7633051;3.8098774;-0.28893408;0.84837806;CODE
since we already used the weights when resampling when provided;3.3582604;-0.5620364;1.0470601;2.396696;-1.0018244;4.3800173;CODE
we set them back to none to avoid accounting for the weights twice;1.1141902;2.0756369;-0.45234257;3.1688092;-1.0876112;2.8212128;CODE
in subsequent operations to compute weight aware bin edges with;2.9090085;-0.5315741;-0.65708053;-3.2393982;0.9968958;1.9643713;-
quantiles or k means;1.9999968;0.5185084;2.9207754;-2.5482879;-0.3000503;-1.3625333;-
todo 1 9 remove and switch to quantile method averaged inverted cdf;0.5142743;3.161986;-0.93989193;-0.10182741;-4.0460563;2.1841202;CODE
by default;-3.7054193;-1.7235909;3.475118;1.2879664;-0.51767796;1.6184187;CODE
prepare a mask to filter out zero weight samples when extracting;4.459696;3.3128881;-2.9297729;-1.4486011;-0.5164224;2.1997716;-
the min and max values of each columns which are needed for the;4.6579213;1.813415;1.9153769;-6.3905225;1.2789466;-1.6595086;IRRE
uniform and kmeans strategies;2.0003269;-1.3457998;2.6624587;0.9802767;0.85550344;1.906028;CODE
otherwise all samples are used use a slice to avoid creating a;2.489444;2.2899761;-1.4373324;0.74309546;2.2369413;-0.34175032;CODE
new array;-0.58145285;2.2055924;4.371897;-2.5012321;1.0280544;-2.8022661;CODE
method linear is the implicit default for any numpy;1.4167918;0.050288424;-4.0111766;-2.17423;-5.2421646;2.245541;CODE
version so we keep it version independent in that case by;-4.2192564;-1.6346211;-0.06326295;3.5042772;2.929225;1.632463;CODE
using an empty param dict;-2.9261382;3.1915934;-0.9541945;-0.97551584;-0.2583718;-1.4019419;-
from sklearn cluster import kmeans fixes import loops;1.750329;-1.9523935;-4.5669146;-1.4039123;-4.617635;0.25269192;CODE
deterministic initialization with uniform spacing;-0.10952175;1.763649;-1.3603777;0.4142453;0.8340546;2.3142576;CODE
1d k means procedure;3.7108493;0.55411714;0.08144008;-3.311665;1.2405449;0.23763157;-
must sort centers may be unsorted even with sorted init;-0.836614;2.4616475;-0.57641363;-0.6058116;-3.0567858;2.0615926;IRRE
remove bins whose width are too small i e 1e 8;-0.87485826;2.4115932;0.6142732;-3.9205399;-0.5457561;0.44066063;-
fit the onehotencoder with toy datasets;3.994593;-2.4760303;-0.36481827;-2.1890397;0.53113145;1.7436956;IRRE
so that it s ready for use after the kbinsdiscretizer is fitted;-4.524523;-0.8872135;-0.14653903;1.4206903;0.3768203;5.388469;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
if not a dataframe do normal check array validation;3.2015817;4.789101;-2.5964777;-0.9338611;-2.3431401;-3.5352988;CODE
pandas dataframe do validation later column by column in order;1.160074;1.9522818;-0.56709206;0.19294736;-1.2817371;-0.44301048;CODE
to keep the dtype information to be used in the encoder;-0.4786014;-1.6385479;-3.8824103;-2.694582;0.4302144;1.3883388;CODE
always convert string categories to objects to avoid;0.6614547;-0.068603836;0.041271202;3.2134137;2.706548;1.0310051;CODE
unexpected string truncation for longer category labels;-1.0757952;0.39412555;-1.5387052;-0.5236857;-0.13903257;-0.95549834;CODE
passed in the constructor;-4.069291;1.8763763;1.1957457;1.8110919;4.027361;-1.23951;CODE
nan must be the last stated category;-0.6288136;-1.0146389;0.019681478;-0.91515934;-0.116920285;-2.7467556;TASK
f in column i;1.9456391;2.5634336;2.8643043;-6.162231;-0.16956013;-3.7818687;-
if there are nans nan should be the last element;0.1485058;3.725836;0.5462008;-3.8481243;-0.396336;-3.9486384;-
nan values can only be placed in the latest position;1.8012979;4.694864;-0.55295795;-3.3949554;-4.428626;-1.3792299;IRRE
set the problematic rows to an acceptable value and;2.5925763;6.3295865;0.9520787;-2.1802292;1.2421112;-4.0090303;IRRE
continue the rows are marked x mask and will be;1.0320829;4.8873806;3.1685216;-5.482415;0.31982937;-0.50480855;CODE
removed later;-5.695968;-1.861946;4.3344593;0.9089336;0.4810459;-0.6306782;OUTD
cast xi into the largest string type necessary;0.69475484;2.1967146;-0.3231275;-2.7196474;1.7851706;1.0570351;CODE
to handle different lengths of numpy strings;2.9903939;0.1577488;0.9544137;-6.1498017;-2.7144384;-1.1751065;CODE
categories are objects and xi are numpy strings;1.1122155;-2.199104;-2.4782715;-4.683589;-1.4764361;-2.1778476;CODE
cast xi to an object dtype to prevent truncation;-1.0724306;1.861771;-2.9769053;-0.10818857;-0.46687338;2.689569;CODE
when setting invalid values;-1.1456529;7.082273;-2.1620219;0.79708564;-0.35109124;-2.4925113;IRRE
we use check unknown false since check unknown was;-2.4209256;6.6824107;-2.9068286;3.9477258;-0.6777395;-4.7736382;-
already called above;-4.1470265;-1.2714587;4.4132876;2.1264768;1.7597048;-0.49544916;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
dataframes can have multiple dtypes;2.307225;-1.7224482;-3.9663212;-3.185635;-0.80008334;-0.25694376;-
not all dtypes are numpy dtypes they can be pandas dtypes as well;1.8295969;-4.4363465;-5.3422174;-3.5199814;-3.7347257;-1.2698321;-
check the consistency between the column provided by transform and;3.47249;5.924176;-1.8131298;-2.498826;-1.3343349;-0.3547793;CODE
the column names provided by get feature names out;-0.6913841;-2.302138;-1.4614687;-1.0272676;1.9872372;0.0014338045;TASK
we can override the column names of the output if it is inconsistent;1.162128;3.9362907;-2.351217;-0.49755254;1.0022916;0.94732106;IRRE
with the column names provided by get feature names out in the;-0.29320672;-2.7772627;0.052223258;-1.534155;3.1686108;0.37586585;TASK
following cases;-1.6973559;2.6380496;5.2610393;-0.09307936;3.8040373;-4.2521453;CODE
func preserved the column names between the input and the output;1.3081259;1.101039;0.56344163;-1.3194984;-0.7770329;-0.049383298;IRRE
the input column names are all numbers;-1.1422507;0.53832823;-0.5394817;-5.650201;0.6925076;-4.532209;CODE
the output is requested to be a dataframe pandas or polars;0.7076522;-1.5527184;-1.6036264;-5.024902;-4.2257094;-3.1552215;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
transform of empty array is empty array;-1.2238828;4.41724;-0.36782134;-3.8365684;-3.2099319;-0.33572352;CODE
inverse transform of empty array is empty array;-0.6819408;4.103574;-0.5276775;-3.672743;-3.7888699;0.6826626;IRRE
xxx workaround that will be removed when list of list format is;-2.632659;3.3749096;-3.0890238;-0.034186732;0.27036706;0.750376;OUTD
dropped;-1.6039472;1.3710659;4.3890543;1.4298252;-0.7007899;-2.52439;-
to account for pos label 0 in the dense case;1.5222834;2.7714708;-3.069498;-2.806626;1.489391;1.0890245;CODE
pick out the known labels from y;3.8234847;-0.66320485;2.1973062;-2.2417626;2.9904873;-1.8896681;CODE
preserve label ordering;0.8212495;1.7032907;1.9329635;-1.7883269;3.2526863;2.9397311;-
find the argmax for each row in y where y is a csr matrix;4.53513;0.5409824;-0.3546636;-6.7142134;-3.0913475;1.7730314;CODE
picks out all indices obtaining the maximum per row;4.899976;2.2565262;0.80819315;-4.476414;0.4133651;-1.7851396;-
for corner case where last row has a max of 0;1.5670978;4.419833;2.6493907;-6.5493593;1.3718674;-2.266221;CODE
gets the index of the first argmax in each row from y i all argmax;4.347754;1.477036;1.8500487;-7.010695;-1.5023034;0.86955065;CODE
first argmax of each row;4.6497474;1.148473;2.8109524;-6.5787044;-0.52339655;2.2970212;-
handle rows of all 0;1.7522902;6.174185;2.0959575;-4.416401;0.9323198;-2.690195;-
handles rows with max of 0 that contain negative numbers;2.4781895;5.2281303;0.3718026;-5.2048965;0.03378794;-2.89844;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
pragma nocover;-2.9399703;0.33913997;2.156259;0.7398745;0.19083531;-1.6718117;-
we also record the number of output features for;2.8253734;-3.529698;2.0384905;0.6243383;3.815161;-1.3060223;TASK
min degree 0;0.7314612;2.4345732;-0.39241713;-4.4574275;-0.49564484;-3.0564365;-
edge case deal with empty matrix;0.8561454;3.5453749;-0.576721;-4.6203513;0.50461113;2.2421896;CODE
do as if min degree 0 and cut down array after the;3.6315973;5.139177;0.48512888;-5.4790964;-0.47164506;-3.0201406;CODE
computation i e use n out full instead of n output features;4.547093;-0.6439615;-0.6454928;-3.3827672;0.78960747;-1.1775503;TASK
what follows is a faster implementation of;2.2765164;-2.8036954;1.0405802;1.5106715;2.983318;2.1284864;TASK
for i comb in enumerate combinations;0.005071787;0.18234019;4.1198916;-3.5580287;3.7223206;-4.5461;CODE
xp i x comb prod 1;-4.8077717;-0.6629798;0.6973761;-3.8500385;2.3104782;-0.9953822;-
this implementation uses two optimisations;3.577955;-1.1569449;0.089691445;-0.7077504;3.471691;4.2373934;TASK
first one is broadcasting;-2.3321357;-1.6714835;5.432187;0.22397321;1.47258;-1.3793643;-
multiply x1 xn x1 x1 x1 xn x1;2.0751183;2.0863106;0.43885434;-8.3934965;0.39878055;-1.886178;-
multiply x2 xn x2 x2 x2 xn x2;0.04746629;1.4396155;1.1588732;-7.548657;0.6879313;-1.9855179;-
multiply x start end x start;-0.77022344;3.384754;4.62778;-5.2915688;-0.96378595;-1.6433146;CODE
second optimisation happens for degrees 3;2.7649682;0.6580785;-2.1324456;-0.9770089;0.33553496;2.5994053;CODE
xi 3 is computed reusing previous computation;-1.1144317;0.5936039;-2.0365927;-0.432417;-0.9311425;2.380883;-
xi 3 xi 2 xi;-3.9184153;0.24643488;2.9004376;-2.8389015;2.812783;-0.45856053;-
degree 0 term;-1.8381964;1.4165205;-0.82557434;-3.1577628;0.4108953;-3.3473587;-
degree 1 term;-1.5752401;-0.8615255;0.82371455;-1.9800035;2.496957;-2.4396944;-
loop over degree 2 terms;0.2729888;2.1908438;2.7215035;-3.8133864;-1.4138222;-3.0340374;IRRE
xp start end are terms of degree d 1;-2.5479875;-0.26215717;-0.7208049;-4.0548453;3.0952785;-1.3696619;CODE
that exclude feature feature idx;-2.4745169;-0.7912107;-1.4287449;2.3456619;2.5350547;2.1697702;TASK
numpy performs this multiplication in place;2.7721717;-0.4914808;-0.23870477;-6.814508;-6.124337;-1.1375537;CODE
knots uniform;-0.9582792;0.035534132;4.050195;-1.2802334;-0.19552954;0.15707682;CODE
note that the variable knots has already been validated and;-1.4640777;1.3375664;-0.91147697;-1.444784;-0.749595;-0.08997759;CODE
else is therefore safe;-4.232481;1.8493949;1.1470808;2.1280391;0.34614986;-1.6618782;CODE
disregard observations with zero weight;4.4750876;5.510286;-1.7394149;0.86569506;-1.9545083;2.2735515;CODE
number of knots for base interval;-0.3775957;1.5806624;3.2194335;-3.1664171;0.25781015;-0.3144095;CODE
number of splines basis functions;0.16244811;-1.4793191;0.23072094;-4.180762;0.10865865;2.519964;CODE
periodic splines have self degree less degrees of freedom;-0.5252675;-0.048788268;-0.39525527;-2.987421;-1.8582526;3.7999;CODE
we have to add degree number of knots below and degree number knots;-1.2997675;0.7554358;2.436235;-4.6859965;0.6764744;-1.3588119;TASK
above the base knots in order to make the spline basis complete;-0.68981975;0.17208023;0.47103542;-2.5727158;-0.7017287;4.2077227;CODE
for periodic splines the spacing of the first last degree knots;-0.5947713;-0.23040937;2.905653;-3.5928512;-1.0188004;1.9696263;CODE
needs to be a continuation of the spacing of the last first;-2.1993225;1.9871995;5.8440366;-2.1113846;0.97505766;-1.6045214;TASK
base knots;-1.8076926;-0.5841626;4.71756;-2.2299283;-0.30182025;1.0034986;-
eilers marx in flexible smoothing with b splines and;0.82047004;-1.0275841;0.74816626;-0.6291707;-2.9062698;4.023201;-
penalties https doi org 10 1214 ss 1038425655 advice;-3.5481365;1.6187305;-0.8659999;1.2900282;-0.57825786;-2.209456;CODE
against repeating first and last knot several times which;-2.4602637;2.067455;4.266329;0.9766054;1.6070609;-0.98233706;-
would have inferior behaviour at boundaries if combined with;-1.8061404;2.5068257;3.691404;2.735086;1.2963324;1.160061;-
a penalty hence p spline we follow this advice even if our;-1.9480093;2.8051445;2.2748926;3.317254;-0.28631547;1.1152667;CODE
splines are unpenalized meaning we do not;-2.664705;-0.951598;0.23110461;0.9487844;-1.7412341;2.7195635;CODE
knots np r;-0.8450421;-0.80262476;2.7939026;-4.9001346;-1.5532191;-2.6170497;-
np tile base knots min axis 0 reps degree 1;0.45228714;1.6211835;-0.4703653;-6.1055284;-4.489519;1.318134;-
base knots;-1.8076926;-0.5841626;4.71756;-2.2299283;-0.30182025;1.0034986;-
np tile base knots max axis 0 reps degree 1;0.19662593;1.4238592;0.07440018;-5.79672;-4.019124;1.5265597;-
instead we reuse the distance of the 2 fist last knots;-0.5023465;0.39728802;4.8735237;0.4478554;-0.34630933;2.4559817;IRRE
with a diagonal coefficient matrix we get back the spline basis;-0.26680827;-1.5496547;-0.48030937;-4.020209;-2.5236278;4.75977;-
elements i e the design matrix of the spline;0.47556025;-2.7789714;2.2165687;-4.4614863;1.3908784;2.0064058;-
note bspline appreciates c contiguous float64 arrays as c coef;0.20175725;-0.8614712;-2.774127;-6.554429;-1.1550626;-0.3739416;TASK
note that scipy bspline returns float64 arrays and converts input;0.5174923;-1.3516715;-4.9999933;-6.2662787;-6.7212744;-3.7461405;CODE
x x i to c contiguous float64;0.24027288;2.699383;0.72777236;-8.722873;-2.8192558;-1.5795263;CODE
get indicator for nan values in the current column;2.9799945;3.8127224;0.68269104;-3.7000191;-2.2249749;-2.6286352;IRRE
with periodic extrapolation we map x to the segment;2.9447567;1.0391617;4.295024;-4.267899;-1.3710842;4.5631614;-
spl t k spl t n;-0.21613765;-1.5004414;2.2870216;-1.8800699;1.1511065;-1.8865038;-
this is equivalent to bspline extrapolate periodic;1.2794156;-0.6780087;1.9790689;-3.4885118;-0.824894;1.5216746;CODE
for scipy 1 0 0;0.7911333;-3.1093776;-2.5211332;-6.781201;-5.0299983;-5.673777;CODE
assign to new array to avoid inplace operation;0.0066924747;4.4790874;0.95020175;-1.5569487;1.1196641;0.56544936;CODE
this can happen if the column has a single non nan;1.9111286;5.5461807;-2.8809364;-3.6829953;-3.2421353;-2.6333206;CODE
value treat as a constant feature;1.5782932;3.150674;-0.36723778;-0.8027288;1.8625202;0.36737627;TASK
else self extrapolation in continue error;-0.52154076;6.662089;-0.7136492;0.77138454;-2.4074256;-2.2788706;CODE
we replace the nan values in the input column by some;3.9870787;2.4345539;-0.0952887;-4.9683194;-1.7512152;-3.567645;IRRE
arbitrary in range numerical value since;3.7636;4.8642573;0.10856523;-4.088585;1.2370735;-2.6536043;IRRE
bspline design matrix would otherwise raise on any nan;1.3284227;-0.24502331;-4.151843;-3.4386907;-1.0041972;1.779416;CODE
value in its input the spline encoded values in;0.6148653;1.4610724;0.27778736;-5.624034;-0.14825882;-2.227117;IRRE
the output of that function that correspond to missing;-0.323141;3.6392343;0.3279028;-2.8513637;-3.153585;-3.8137946;IRRE
values in the original input will be replaced by 0 0;0.7944419;5.058703;0.08542829;-4.8727064;-2.726952;-4.070463;IRRE
afterwards;-4.134412;-0.6452403;7.4072113;2.7307963;-0.5941199;-0.80797637;-
note that in the following we use np nanmin x as the;1.608788;-0.2863836;-2.1849763;-5.9498696;-1.7781874;-0.18618588;TASK
input replacement to make sure that this code works even;-1.4842503;3.7740223;0.6908452;0.0025855484;1.2523263;-5.5623345;CODE
when extrapolation error any other choice of;2.0062869;4.456768;-1.5877496;0.21237883;-2.149538;-1.2284869;-
in range value would have worked work since the;0.42247185;6.478496;0.8448578;-2.6729329;-2.0992947;-2.4156666;IRRE
corresponding values in the array are replaced by zeros;1.9186456;4.707354;-0.5898302;-5.2407985;-3.163379;-3.3248458;IRRE
the column is all np nan valued replace it by a;2.075221;2.052468;-3.267118;-6.8056107;-2.8494017;-2.9022517;IRRE
constant column with an arbitrary non nan value;3.0313036;4.143337;-1.0187237;-5.9313035;-1.2188218;-0.84969544;IRRE
inside so that it is encoded as constant column;-0.7888563;3.35581;0.42032588;-4.644542;2.2077057;1.1234202;CODE
x np zeros like x avoid mutation of input data;3.4186723;2.4505098;-4.015806;-2.817853;-0.2806587;-1.0059291;CODE
x x copy avoid mutation of input data;1.0295717;3.0224717;-1.6260544;-0.6738189;-0.03554749;-0.6881678;CODE
note self bsplines 0 extrapolate is true for extrapolation in;-0.018338265;1.4778041;-3.1788628;-0.37321517;-1.7315619;0.8546475;CODE
periodic continue;-2.1620312;2.7191312;6.1244235;-0.26183975;-1.5354782;-1.754757;CODE
see the construction of coef in fit we need to add the last;2.914777;0.62487775;-1.2821274;0.3445099;0.7902326;2.1464174;TASK
degree spline basis function to the first degree ones and;0.7914765;-1.0907204;-1.1615967;-5.575903;-0.5270177;2.108727;CODE
then drop the last ones;0.83923835;2.1600306;5.265047;-0.08924568;1.5994574;-2.032198;CODE
note see comment about sparseefficiencywarning below;6.2528896;-1.797036;-3.1686084;0.82783586;1.2690994;5.441562;TASK
note see comment about sparseefficiencywarning below;6.2528896;-1.797036;-3.1686084;0.82783586;1.2690994;5.441562;TASK
replace any indicated values with 0;1.1530577;5.583481;1.0950319;-6.038107;-0.49967694;-5.088738;IRRE
else extrapolation in constant linear;2.5545714;3.8530834;1.0247706;-2.431829;-2.0278714;1.0516361;CODE
spline values at boundaries;1.3009189;1.8864424;2.4789395;-4.1014915;-1.6780536;0.20296986;IRRE
values outside of the feature range during fit and nan values get;4.8602457;3.8885229;-3.5048225;-1.9144067;-4.5592194;-0.2403559;IRRE
filtered out;-1.7923461;0.4401771;3.7421434;1.7676331;-0.08463075;-0.6230233;CODE
set to some arbitrary value within the range of values;2.9973068;4.1933436;4.005552;-2.8620553;2.3266459;-2.0265257;IRRE
observed on the training set before calling;1.6015006;-0.22177313;1.3560038;6.674183;2.2850788;0.490218;IRRE
bspline design matrix those transformed will be;0.21316022;-2.5026093;-1.2766565;-4.1867595;1.9344587;3.7864528;IRRE
reassigned later when handling with extrapolation;0.7593657;4.0182533;-0.23137453;2.1399393;0.045411978;3.262663;IRRE
note without converting to lil matrix we would get;3.3593504;-1.3698113;0.5894546;-5.6464047;-1.6191211;0.24665685;TASK
scipy sparse base sparseefficiencywarning changing the sparsity;4.6150317;-3.4842997;-5.373935;-1.8139731;-2.9428613;2.7446563;IRRE
structure of a csr matrix is expensive lil matrix is more;3.4258838;-0.7264866;-2.1421108;-3.1522684;-0.49960515;2.788603;CODE
efficient;1.3963814;-1.4108818;6.7344275;2.953174;2.24408;-1.6208967;-
note for extrapolation;3.117042;0.11667278;3.2524333;-1.8779883;-0.6671651;-1.5564712;TASK
continue is already returned as is by scipy bsplines;-2.850536;0.2543488;-1.6050581;0.5624202;-4.8300133;-2.86474;CODE
early convert to csr as the sparsity structure of this;2.3262675;-0.4833526;-1.9953053;-1.9252338;0.43062803;1.9781307;CODE
block should not change anymore this is needed to be able;-7.303729;2.6060274;1.4920897;1.3112185;-2.1521945;3.198039;OUTD
to safely assume that data is a 1d array;5.0225296;4.2054834;-0.4528497;-3.7305374;-0.2260448;-0.64680177;-
set all values beyond xmin and xmax to the value of the;1.4270449;4.087996;4.4281034;-4.2426257;-0.3876635;-0.84477615;IRRE
spline basis functions at those two positions;0.8483025;-0.08086916;0.8280548;-5.45021;-1.2994624;3.5230708;IRRE
only the first degree and last degree number of splines;-0.12085211;0.46797886;0.6413903;-4.989782;0.9172335;-1.2537642;CODE
have non zero values at the boundaries;1.0828724;5.7094398;2.3403823;-5.3633714;-1.2506281;-2.2070923;IRRE
note see comment about sparseefficiencywarning above;5.760993;-2.1598284;-3.089794;1.1366034;1.0644999;5.285168;TASK
note see comment about sparseefficiencywarning above;5.760993;-2.1598284;-3.089794;1.1366034;1.0644999;5.285168;TASK
continue the degree first and degree last spline bases;0.5915862;0.4226271;0.19849014;-4.4563794;0.46756813;0.15981342;CODE
linearly beyond the boundaries with slope derivative at;0.26309118;0.94430953;2.4227667;-1.595699;-2.7223747;1.4473438;-
the boundary;-2.7794204;-0.7226278;7.610274;-0.06360321;0.33867463;-1.0394261;-
note that all others have derivative value 0 at the;-1.9206285;1.685433;-0.36262733;-3.095089;-1.5091751;-1.9871353;TASK
boundaries;-1.6434424;-1.002054;7.6815934;-0.08176462;1.2331918;-1.6635784;-
spline derivatives slopes at boundaries;-1.2989159;-1.3416626;0.6027966;-1.8900162;-2.2422125;2.5818892;-
compute the linear continuation;-0.7240857;3.3905752;2.6149752;-3.449294;-2.205953;0.6193459;-
for degree 1 the derivative of 2nd spline is not zero at;-2.682452;1.1970503;-1.9712572;-3.2823925;-2.4999013;0.6645971;CODE
boundary for degree 0 it is the same as constant;-2.9147394;1.6175692;1.0976886;-3.3714247;-1.3812566;-0.015994966;CODE
note see comment about sparseefficiencywarning above;5.760993;-2.1598284;-3.089794;1.1366034;1.0644999;5.285168;TASK
note see comment about sparseefficiencywarning above;5.760993;-2.1598284;-3.089794;1.1366034;1.0644999;5.285168;TASK
we throw away one spline basis per feature;2.1665506;-2.26585;-1.2421575;-0.32171687;1.4763693;5.6027026;TASK
we chose the last one;-1.9236226;0.4255893;5.489496;1.8442749;1.7905457;-1.6551965;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
from sklearn model selection import avoid circular import;2.0867414;-2.1085508;-4.473999;0.79604846;-2.2707026;2.2156887;CODE
the cv splitter is voluntarily restricted to kfold to enforce non;-1.4476434;-0.607709;-4.6377354;0.75044173;0.9517568;3.0543637;CODE
overlapping validation folds otherwise the fit transform output will;2.8502905;3.3361566;-1.9120699;0.28260946;-1.3391987;2.9764323;IRRE
not be well specified;-2.411276;-0.8590948;1.9348944;0.93970066;0.8626905;-1.4309386;-
if multiclass multiply axis 1 by num classes else keep shape the same;4.25621;2.247334;0.52399427;-5.571468;0.5049017;1.3390871;IRRE
if multiclass multiply axis 1 by num of classes else keep shape the same;4.3639655;2.061721;0.86852545;-5.389753;0.7594817;1.0417663;IRRE
repeat feature indices by n classes;4.7615128;-1.7921133;-0.055583425;-3.1789768;5.2916393;-0.67534393;TASK
cycle through each class;1.5393939;-0.99733484;4.069073;0.5490519;6.1304493;-1.0544019;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
make some data to be used many times;3.2366683;0.12137381;5.1553054;0.89982325;4.4378786;0.102853104;-
sample weights must be either scalar or 1d;4.4467425;1.6766672;-4.4477158;-2.6533499;-1.1483713;1.8285505;TASK
make sure error is raised the sample weights greater than 1d;5.0443516;5.3317256;-4.4917154;0.49530995;-2.1019576;0.49898735;CODE
weighted standardscaler;4.1829123;0.51373357;-1.4265504;1.1600118;1.6084168;2.878847;-
unweighted but with repeated samples;5.2374916;2.6917453;0.895817;1.033625;1.8153534;-0.64417434;META
n b the sample statistics for xw w sample weight should match;3.4748542;2.2807858;-0.21786565;-1.1040192;1.7264997;-1.530042;CODE
the statistics of x w uniform sample weight;3.1168625;0.5911036;-0.04761923;-0.6367509;0.14039062;1.0288073;CODE
test array api support and correctness;0.4059198;3.9439194;-3.0583494;4.2560806;-0.6753459;-3.860687;IRRE
unweighted but with repeated samples;5.2374916;2.6917458;0.8958161;1.0336255;1.8153536;-0.6441742;META
check that both array api outputs match;0.85215855;5.855853;-1.077782;1.1141671;-0.17124186;-3.0708241;IRRE
test scaling of dataset along single axis;7.890377;3.1773274;1.0036979;-1.6924342;-4.0993767;1.2060654;IRRE
x np array x cast only after scaling done;2.0192459;3.5239873;-2.21169;-4.7440853;-4.8462534;4.2164593;CODE
check inverse transform;-0.5308256;4.027286;1.3617593;-2.1264;-3.9868453;-2.3141272;IRRE
constant feature;2.0085027;-0.48933795;1.0784005;0.38041162;1.4948478;1.8030206;TASK
ensure scaling does not affect dtype;2.2475412;1.209199;-5.19869;-0.15209821;-3.6305435;4.5721903;CODE
scipy sparse containers do not support float16 see;0.36749014;-1.788826;-6.3630877;-5.030699;-6.2549524;0.12179772;CODE
https github com scipy scipy issues 7408 for more details;-2.201978;-5.0227175;-6.5309067;-2.7938764;-7.4256554;-4.084271;CODE
caler clone scaler avoid side effects from previous tests;-0.12927449;2.10392;-1.6510022;4.1063156;-3.6634057;2.5716448;CODE
the variance info should be close to zero for constant features;4.0692735;0.34409335;-3.8760455;-1.0360961;-2.1019397;3.1205308;CODE
constant features should not be scaled scale of 1;2.4233067;2.2172663;-1.9422753;-1.9986817;-3.9393868;4.9871287;TASK
assert x scaled is not x make sure we make a copy;0.044703867;6.112634;-4.1852803;2.0576043;-2.6527581;-0.09639713;CODE
also check consistency with the standard scale function;4.8710756;3.8815997;-1.6909353;-0.38129765;-3.4470174;1.5526433;CODE
assert x scaled 2 is not x make sure we did a copy;-0.4420572;6.7034936;-4.2117004;2.244103;-2.3616683;-0.9703244;CODE
check that when the variance is too small var mean 2 the feature;2.6238158;3.6885421;-2.0356529;2.7370255;-2.6901646;-0.8630071;CODE
is considered constant and not scaled;0.57201576;2.5217793;0.16582692;-1.490646;-3.104563;3.124114;CODE
make a dataset of known var scales 2 and mean average;5.476834;-0.031395573;1.2348442;-1.3368758;-2.1478431;1.1194385;IRRE
standardscaler uses float64 accumulators even if the data has a float32;-0.86648697;2.9393013;-5.475464;-2.0143409;-2.995661;2.6259587;CODE
dtype;-0.4287421;-3.9655383;0.034483336;-0.6825941;0.050455067;-2.456922;-
if var bound n eps var n eps mean the feature is considered;3.2379766;1.8792324;-2.2508562;-1.1847721;1.3371813;0.27556646;CODE
constant and the scale attribute is set to 1;0.33416703;3.5648143;0.59121287;-2.9401853;-3.5370357;3.1582804;IRRE
check that scale min is small enough to have some scales below the;1.8310349;3.553868;-0.4615028;-1.3011757;-5.037156;2.7120628;-
bound and therefore detected as constant;0.91666394;4.3473916;-0.94226444;1.7401156;-0.7460223;-0.34274966;CODE
check that such features are actually treated as constant by the scaler;3.188347;3.2494576;-3.7917306;-0.276147;-2.7313335;3.3707628;TASK
depending the on the dtype of x some features might not actually be;0.25028625;-2.3110685;-4.3863335;-0.43453288;0.34162548;0.6122703;TASK
representable as non constant for small scales even if above the;2.6234775;2.3266132;0.3849761;-2.0071936;-0.58251625;4.2384944;CODE
precision bound of the float64 variance estimate such feature should;3.363477;0.20938252;-4.533667;0.055257235;-2.9587123;1.9351963;CODE
be correctly detected as constants with 0 variance by standardscaler;1.9460063;4.397743;-5.780491;0.47165948;-3.4271114;2.7382617;CODE
the other features are scaled and scale is equal to sqrt var assuming;2.028904;-0.07175007;-0.65726703;-3.1055222;-2.6563497;1.9414052;TASK
that scales are large enough for average scale and average scale to;4.048565;-1.6809602;2.4826188;0.16750547;-1.8721449;2.0022001;CODE
be distinct in x depending on x s dtype;3.2863922;1.834955;-2.5998914;-3.713841;4.4290867;-0.97830534;TASK
1 d inputs;4.063301;0.6776875;3.9459944;-6.0627203;-0.014709766;-1.6989166;CODE
test numerical stability of scaling;4.723004;2.4871485;-0.807157;0.47139803;-4.9769707;1.8265964;IRRE
np log 1e 5 is taken because of its floating point representation;0.41096795;1.2702396;-5.0345793;-3.6313381;-4.848649;-1.5239053;CODE
was empirically found to cause numerical problems with np mean np std;3.6042821;-1.3389227;-5.1358647;-1.6540853;-3.3459666;0.38187093;CODE
this does not raise a warning as the number of samples is too low;1.6976511;3.68793;-2.9107156;4.4196734;0.49308777;-1.739203;CODE
to trigger the problem in recent numpy;2.776781;0.01704506;-1.330913;-1.9963001;-7.574935;-1.2034205;-
with 2 more samples the std computation run into numerical issues;5.206352;1.9021239;-3.544573;-1.8909856;0.37355584;0.32781976;CODE
large values can cause often recoverable numerical stability issues;4.025812;1.8461963;-3.4725926;-0.56479156;-4.356679;-0.10301062;IRRE
test scaling of 2d array along first axis;6.1719913;4.8980465;1.2491038;-4.187762;-5.56335;-0.03991203;IRRE
x 0 0 0 first feature is always of zero;-0.30285433;3.1251614;-2.2745519;-4.2864685;-1.3725779;0.3652066;TASK
check that x has been copied;-3.2204416;3.372408;-0.15501443;0.9894656;-0.93927103;-2.4884434;-
check inverse transform;-0.5308256;4.027286;1.3617593;-2.1264;-3.9868453;-2.3141272;IRRE
check that the data hasn t been modified;1.4772341;4.767838;0.5831079;3.0301657;-1.580207;-2.238297;-
check that x has not been copied;-2.9501579;4.1913033;-0.85304976;1.3106664;-0.85326636;-2.689439;-
x 0 1 0 first feature is a constant non zero feature;-0.23690683;2.1254818;-2.7155273;-3.9897692;-0.9781273;1.8377281;TASK
check that x has not been copied;-2.9501579;4.1913033;-0.85304976;1.3106664;-0.85326636;-2.689439;-
test if the scaler will not overflow on float16 numpy arrays;3.5404375;3.4017375;-3.6497326;-2.9268184;-8.518016;0.3751106;IRRE
float16 has a maximum of 65500 0 on the worst case 5 200000 is 100000;1.0776668;2.7777069;-2.3658664;-2.9314456;-2.110624;-1.9119827;CODE
which is enough to overflow the data type;1.5492564;1.7683983;-0.25997776;-1.9205769;2.1465719;-0.20101382;-
calculate the float64 equivalent to verify result;0.38190514;4.4600954;-1.6511298;-2.7010288;-2.5200078;-4.75734;IRRE
overflow calculations may cause inf inf or nan since there is no nan;1.3306158;3.6949956;-3.379646;-1.6350576;-5.3608723;-1.8756012;CODE
input all of the outputs should be finite this may be redundant since a;1.4354022;3.8174527;0.75736207;-2.055394;0.67576593;-2.7961338;IRRE
floatingpointerror exception will be thrown on overflow above;-0.7482444;3.1077473;-5.056923;0.8664654;-5.962878;-1.1233574;CODE
the normal distribution is very unlikely to go above 4 at 4 0 8 0 the;-0.2680428;3.8444984;1.3609382;-1.7536474;-2.8630073;-0.9106226;META
float16 precision is 2 8 which is around 0 004 thus only 2 decimals are;-0.72831285;2.9463952;-3.0532415;-4.469591;-4.0120153;-1.9670826;CODE
checked to account for precision differences;4.6914725;3.9926832;-1.4919646;0.9718152;-0.1718907;-3.6843328;CODE
test if partial fit run over many batches of size 1 and 50;5.6764703;4.693743;0.13290638;3.2965655;0.032864187;-1.4129792;IRRE
gives the same results as fit;4.0704303;0.50535053;1.2332901;2.315187;-0.77200764;0.25665566;IRRE
test mean at the end of the process;0.95837563;4.471665;3.4734907;5.528927;-1.8739603;-3.2094383;CODE
test std after 1 step;-0.29570007;5.5172048;-0.44842213;2.8255634;0.8207993;-3.9961686;IRRE
test std until the end of partial fits and;1.6556059;4.5867925;-0.016362047;2.3952923;1.0777392;-1.2098198;CODE
caler incr minmaxscaler clean estimator;3.4635556;0.9311751;-2.5273411;0.19572231;-1.7635251;5.1572843;TASK
test if partial fit run over many batches of size 1 and 50;5.6764703;4.693743;0.13290638;3.2965655;0.032864187;-1.4129792;IRRE
gives the same results as fit;4.0704303;0.50535053;1.2332901;2.315187;-0.77200764;0.25665566;IRRE
test mean at the end of the process;0.95837563;4.471665;3.4734907;5.528927;-1.8739603;-3.2094383;CODE
assert scaler batch var scaler incr var nones;1.0672894;5.823817;-5.0442653;1.9079823;-2.9704373;0.32971007;CODE
test std after 1 step;-0.29570007;5.5172048;-0.44842213;2.8255634;0.8207993;-3.9961686;IRRE
no constants;-1.8715689;2.3375802;2.055758;-2.5468671;-3.047139;-2.4157968;CODE
test std until the end of partial fits and;1.6556059;4.5867925;-0.016362047;2.3952923;1.0777392;-1.2098198;CODE
caler incr standardscaler clean estimator;0.53874975;1.2340153;-3.3959093;1.9807146;-1.2441708;3.1291952;TASK
test if the incremental computation introduces significative errors;1.9422371;5.3838696;-3.2919216;5.2716985;-0.8419576;-4.911531;IRRE
for large datasets with values of large magniture;7.2641788;-3.773423;3.0808818;-1.8963944;-0.8971886;1.6151702;IRRE
regardless of abs values they must not be more diff 6 significant digits;2.3811228;4.3437667;-1.9463706;-3.0697732;-1.313339;-3.7623734;IRRE
note be aware that for much larger offsets std is very unstable last;1.1639454;1.9095571;-0.75012976;-2.9731028;-1.3505934;2.6487603;CODE
assert while mean is ok;1.0324267;5.606245;-0.9834726;6.308265;-1.011261;-2.849069;CODE
sparse input;6.00329;-0.724858;1.4851028;-1.9386766;-0.31889528;1.0251421;IRRE
with mean false is required with sparse input;5.261118;4.1879997;-3.6104822;-0.035415407;-1.9761814;0.7277032;CODE
sparse arrays can be 1d in scipy 1 14 and later while old;3.295074;-0.74488944;-5.6042137;-5.1699805;-5.646159;-0.0420496;IRRE
sparse matrix instances are always 2d;3.8228328;0.785768;-2.3547084;-5.2346354;-1.5208389;4.659509;IRRE
regardless of magnitude they must not differ more than of 6 digits;3.0182734;2.1538303;0.46480393;-3.0171914;-0.23664594;-3.2308087;-
check that sparsity is not destroyed;0.06786734;3.5192435;-2.0233352;1.99412;-2.1935248;1.6395401;-
check some postconditions after applying partial fit and transform;3.2179775;4.7344065;-2.8879826;0.60619545;-1.7379674;2.9904928;CODE
assert array almost equal x sofar chunks copy no change;3.5739288;6.5795474;-4.0867043;-0.7078199;-1.4577868;-2.3817847;CODE
assert array less zero scaler incr var epsilon as less or equal;4.2122965;7.179075;-4.5348415;-0.53576857;-2.9497232;-0.47892922;CODE
i 1 because the scaler has been already fitted;-0.9861548;0.23245518;1.3589745;-0.18888606;-1.9011798;1.4712634;IRRE
check if standardscaler inverse transform is;0.22876975;4.755008;-2.434414;0.38232222;-2.648881;2.0146143;IRRE
converting the integer array to float;1.1901809;3.41571;0.8461707;-6.528131;-3.4299242;-3.1896873;CODE
the of inverse transform should be converted;-1.5541584;1.834728;1.2094129;-3.8684154;-3.4112048;0.36942673;IRRE
to a float array;2.2925837;2.8129714;2.9016345;-5.901857;-2.139076;-2.6517944;CODE
if not x self scale will fail;0.6776644;3.7563846;-1.036077;0.3209432;-3.5896218;1.589045;CODE
default params;-3.8634183;1.3461583;1.3939332;0.36800277;0.99481267;2.7258253;CODE
not default params min 1 max 2;-2.774039;3.8207214;-0.90405697;-1.5237354;0.3663409;1.6140329;CODE
min 5 max 6;-2.0623016;0.48330858;3.6151617;-2.54045;1.6592194;-2.569377;-
raises on invalid range;1.176287;5.6156006;-1.0965092;-0.12063271;-1.7514747;-2.2544854;OUTD
check min max scaler on toy data with zero variance features;5.233248;2.0110214;-2.4744298;-0.9411187;-2.2685742;2.7705595;TASK
default params;-3.8634183;1.3461583;1.3939332;0.36800277;0.99481267;2.7258253;CODE
not default params;-5.1064196;2.5063708;0.34076297;0.96597344;-0.5231541;3.1294503;CODE
function interface;-2.7576349;-0.8833247;3.511072;-1.0791446;1.0107559;-0.36040992;CODE
test scaling of dataset along single axis;7.890377;3.1773274;1.0036979;-1.6924342;-4.0993767;1.2060654;IRRE
x np array x cast only after scaling done;2.0192459;3.5239873;-2.21169;-4.7440853;-4.8462534;4.2164593;CODE
check inverse transform;-0.5308256;4.027286;1.3617593;-2.1264;-3.9868453;-2.3141272;IRRE
constant feature;2.008505;-0.48933843;1.0784005;0.38041186;1.4948465;1.8030213;TASK
function interface;-2.7576349;-0.8833247;3.511072;-1.0791446;1.0107559;-0.36040992;CODE
x 0 0 0 first feature is always of zero;-0.30285433;3.1251614;-2.2745519;-4.2864685;-1.3725779;0.3652066;TASK
check that x has not been modified copy;-2.1462138;4.1446;-1.5802716;1.7306913;-0.541442;-1.178379;-
test that the scaler return identity when with mean and with std are;3.1574302;5.9463515;-2.3164563;0.1725378;-1.0821099;-0.34870523;IRRE
false;-1.7588302;2.0770767;1.4182303;3.2893414;-1.3142923;-3.3325477;-
test that scaler converts integer input to floating;2.839115;5.8624425;-1.4520358;-1.1128038;-4.829401;-2.3310268;CODE
for both sparse and dense matrices;4.155594;-1.7375176;-1.0991699;-3.9516368;0.17468672;4.0410657;IRRE
x 0 0 first feature is always of zero;-0.4922614;3.279741;-2.115085;-3.9230533;-1.3273243;0.36617804;TASK
check that x has not been modified copy;-2.1462138;4.1446;-1.5802716;1.7306913;-0.541442;-1.178379;-
check that standardscaler fit does not change input;-0.058793813;4.930902;-3.777088;1.2308241;-3.4148962;2.6561234;CODE
x 0 0 0 first feature is always of zero;-0.30285433;3.1251614;-2.2745519;-4.2864685;-1.3725779;0.3652066;TASK
check scaling and fit with direct calls on sparse data;7.662019;1.5417812;-2.8731031;0.5405123;-2.117688;3.9258387;IRRE
check transform and inverse transform after a fit on a dense array;5.435367;4.9945765;-1.1229798;-1.475221;-3.6786942;2.2411554;CODE
check if non finite inputs raise valueerror;2.278384;6.5625825;-4.287812;1.3498585;-1.901475;-4.8062806;IRRE
check consistent type of attributes;2.0675166;4.32536;-2.9797723;2.0751464;4.840286;-0.89363635;META
check that the scaler is working when there is not data materialized in a;2.4068062;6.340443;-1.5938452;1.8408489;-3.7472494;2.580716;-
column of a sparse matrix;4.504199;-0.64468986;-0.20267539;-6.149897;-1.1522293;2.8354468;IRRE
test robust scaling of 2d array along first axis;7.2499256;3.8502748;0.48230284;-3.8417883;-5.122176;1.8342348;IRRE
x 0 0 0 first feature is always of zero;-0.30285433;3.1251614;-2.2745519;-4.2864685;-1.3725779;0.3652066;TASK
check the equivalence of the fitting with dense and sparse matrices;6.030387;1.5913283;-4.1723413;-1.5937185;-2.2035515;4.376928;IRRE
check robustscaler on transforming csr matrix with one row;4.446631;2.0917313;-3.9159055;-4.053411;-3.4223611;3.3941722;CODE
uniform output distribution;1.8513525;1.3405626;3.3075912;-1.8947036;-0.94733155;-0.9324055;IRRE
normal output distribution;0.7998996;1.2913492;2.7548525;-2.6714153;-1.4430451;-0.9483286;IRRE
make sure it is possible to take the inverse of a sparse matrix;4.9474783;0.6236554;-1.6196084;-3.1784368;-2.1661766;4.623657;IRRE
which contain negative value this is the case in the iris dataset;1.7208086;2.62773;-1.9304277;-3.63211;-1.0310786;-2.4777036;CODE
check that an error is raised if input is scalar;2.2492688;5.6751895;-3.3129482;1.823482;-2.2112126;-3.5612473;CODE
check that a warning is raised is n quantiles n samples;3.1114657;5.0982485;-1.5038493;0.35727894;-0.007441486;-3.7778397;CODE
dense case warning raise;-1.1088703;2.2185867;-1.8847989;2.2227454;0.67257905;-0.08085738;CODE
consider the case where sparse entries are missing values and user given;5.536422;3.228595;-0.4824886;-0.5147214;2.337026;-1.4572228;IRRE
zeros are to be considered;-0.5661924;4.4400477;-1.927373;-3.011579;0.6402545;-2.955164;-
check in conjunction with subsampling;5.0222745;5.2772326;0.3172301;1.777222;1.8157352;-2.156771;-
using a uniform output each entry of x should be map between 0 and 1;2.4742987;3.7760494;2.1431322;-5.6911845;-0.6390843;-1.5520221;CODE
and equally spaced;1.5761467;0.23487644;5.2993536;-2.1491985;1.1460989;-0.9216764;-
test that subsampling the input yield to a consistent results we check;6.880311;4.7433424;-1.5097755;5.956884;0.119174875;-4.436462;IRRE
that the computed quantiles are almost mapped to a 0 1 vector where;2.957125;0.6666184;-1.67014;-3.669125;-1.3883643;2.6222415;-
values are equally spaced the infinite norm is checked to be smaller;3.2518868;4.923057;-0.31349063;-3.9528093;-4.7243223;1.3883814;IRRE
than a given threshold this is repeated 5 times;1.6376057;3.7019823;3.0948112;0.37697363;0.7810872;-4.157506;CODE
dense support;0.7921645;-2.40792;2.27507;0.36267325;0.6996636;1.9243987;-
each random subsampling yield a unique approximation to the expected;5.577533;-0.01431336;1.1157956;3.1605067;1.2299618;2.6441844;IRRE
linspace cdf;-0.49502826;-0.2074997;0.19638222;-1.7869117;-0.37336585;0.7033719;-
sparse support;4.6690483;-3.4064586;0.5759787;0.028006855;1.2685117;5.10313;IRRE
each random subsampling yield a unique approximation to the expected;5.577533;-0.01431336;1.1157956;3.1605067;1.2299618;2.6441844;IRRE
linspace cdf;-0.49502861;-0.20749983;0.19638121;-1.7869107;-0.3733654;0.70337045;-
https github com scikit learn scikit learn issues 23319 issuecomment 1464933635;-2.676561;-8.82546;-7.4632616;-0.28451073;-5.5740232;-4.453711;CODE
warnings simplefilter always ensure all warnings are captured;-0.2412546;3.6493695;-3.1666646;4.826646;-1.5984797;1.8600641;-
full dataset should not trigger overflow in variance calculation;3.8242207;1.8963852;-4.1644993;1.6122003;-2.9251606;1.6632785;IRRE
subset of data should not trigger overflow in power calculation;4.34615;3.5002725;-2.3059099;0.2593402;0.17223892;0.99893725;IRRE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
ignore the warning on removed small bins;-3.3298774;3.3907187;-2.2165809;1.6137296;-2.314808;0.69539934;OUTD
bad shape;-0.7639508;-0.03150915;3.5173068;0.025023226;-3.3751032;-0.106213704;-
incorrect number of features;0.84801656;-0.616388;-1.9611357;-0.3371693;1.099612;-3.3195004;TASK
bad bin values;-0.26985043;3.6263168;-3.090562;-3.569864;-3.191447;-5.321872;IRRE
float bin values;1.937969;2.8793616;0.10319566;-7.0413365;-1.8890107;-4.049688;IRRE
warn default will not warn when strategy quantile;-2.098498;3.7711556;-1.1361791;4.4899898;-2.471219;2.1189728;CODE
warn default will not warn when strategy quantile;-2.098498;3.7711556;-1.1361791;4.4899898;-2.471219;2.1189728;CODE
warn default will not warn when strategy quantile;-2.098498;3.7711556;-1.1361791;4.4899898;-2.471219;2.1189728;CODE
test the shape of bin edges;2.8836849;2.140868;1.1441051;-2.8345156;-0.8182718;-3.6983361;IRRE
replace the feature with zeros;0.63076544;3.080601;-0.1270271;-3.554519;-0.39493057;-1.4397748;TASK
test up to discretizing nano units;4.6976585;0.07454108;-1.4080564;-1.7000581;-2.7312307;-1.1342481;IRRE
with 2 bins;-1.0804627;-0.29553217;4.751115;-2.7163014;2.2680805;-3.1523914;-
with 3 bins;-1.1201589;-0.7489628;4.5126634;-3.3526149;2.6688228;-3.2847776;-
with 5 bins;-0.21756768;-1.1159079;4.6725645;-2.743072;2.174918;-3.2431836;-
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
warn default will not warn when strategy quantile;-2.098498;3.771155;-1.1361792;4.4899893;-2.4712186;2.1189733;CODE
todo change to averaged inverted cdf but that means we only get bin;-0.7230367;3.046219;-0.85819155;0.45634988;-3.2854416;0.4840476;TASK
edges of 0 05 and 0 95 and nothing in between;0.92615867;2.4529712;0.37083367;-4.592845;-2.1406894;-2.1640863;-
test output dtype;1.7696878;1.4322321;-4.545164;-0.42932135;-1.8041611;-6.147406;IRRE
wrong numeric input dtype are cast in np float64;-0.15255325;0.65732676;-7.022611;-6.083938;-5.68391;-2.4015281;CODE
todo this check is redundant with common checks and can be removed;-3.8597398;5.0902033;-1.9075574;3.048787;3.4230015;-1.0012467;CODE
once 16290 is merged;-4.053993;-0.2859291;1.4143347;0.014228287;1.387018;-0.20889069;-
32 bit output;-3.5004623;-0.3079869;0.8500323;-4.6651998;0.0586153;-2.6801922;IRRE
64 bit output;-3.9836552;-0.68131;1.4091547;-4.3154426;-0.8185786;-3.2790332;IRRE
since the size of x is small 2e5 subsampling will not take place;2.628178;3.2423606;-1.4335052;-3.198717;-2.7044752;4.6191525;-
check that the bin edges are almost the same when subsampling is used;4.274085;3.8671758;-2.3268788;-1.4304508;-1.5014731;0.7033478;-
we use a large tolerance because we can t expect the bin edges to be exactly the;0.6957824;1.3794925;-0.25235802;0.9926744;-1.5865407;1.2590841;-
same when subsampling is used;3.4123757;1.9002233;0.7226907;1.3072795;-0.19484425;3.370126;-
check that sparse and dense will give the same results;5.312214;2.0809069;-3.907467;-1.6305882;-1.965153;0.777966;IRRE
check outcome;-0.36132044;4.7791495;4.891508;4.159082;1.0451934;-7.55715;-
test that one hot encoder raises error for unknown features;0.62791973;2.2964141;-7.6753006;2.4603086;-1.1440406;-2.3920846;CODE
present during transform;-2.228082;1.1152557;3.5559008;-1.5437678;-0.6171368;1.0998247;CODE
test the ignore option ignores unknown features giving all 0 s;0.63447726;6.2646565;-5.4060497;4.5465655;-1.4497246;-2.7073045;TASK
ensure transformed data was not modified in place;2.1633158;4.310918;-0.18092017;0.56450814;-1.0699229;4.235444;CODE
non regression test for the issue 12470;-0.13705719;4.1255536;-4.6741157;3.6824193;-3.8351452;-5.8558717;IRRE
test the ignore option when categories are numpy string dtype;2.0932097;3.187984;-5.562533;1.0340072;-3.1280253;-2.5525265;IRRE
particularly when the known category strings are larger;2.9046848;-2.8432863;0.3895939;1.8973894;2.7114065;-1.1781349;CODE
than the unknown category strings;0.5194279;-1.685043;-0.40243202;0.63063306;2.6137195;-4.463225;CODE
ensure transformed data was not modified in place;2.163316;4.3109183;-0.18091917;0.564508;-1.0699213;4.2354436;CODE
last value is np nan;1.2098726;3.2567322;-1.7469627;-6.5416956;-3.517042;-5.1345916;IRRE
do not include the last column which includes missing values;1.3150872;5.215165;-0.2081992;-2.663697;-0.19568805;-2.1180866;CODE
check last column is the missing value;0.54318136;6.708239;0.4438827;-2.2250342;-0.7584087;-6.0246024;IRRE
check handle unknown ignore;-3.793255;6.9954786;-1.5243922;4.35764;-1.1236458;-0.94241107;-
a is dropped;-1.6747992;2.3534217;4.2751455;1.685207;-0.4793875;-1.816366;-
x 0 1 and 2 are infrequent;1.0598345;3.7586036;1.2460107;-3.1151137;-2.7616649;-3.5060508;-
x 1 1 and 10 are infrequent;2.048934;3.8920314;1.8516718;-2.0138142;-2.368564;-3.0253983;-
x 2 nothing is infrequent;-1.2504044;2.8739827;1.138821;-0.38815397;-4.1053605;-2.3314636;-
infrequent is used to denote the infrequent categories;-0.045599904;-1.37985;1.0165111;2.2895076;0.07028117;0.10370979;TASK
for the first column 1 and 2 have the same frequency in this case;3.4891808;3.2211325;2.0697925;-6.073628;0.17050302;-1.6248935;CODE
1 will be chosen to be the feature name because is smaller lexiconically;-0.8294294;-3.0245636;-0.9039989;0.8145698;4.5388956;-0.17303677;TASK
x 2 does not have an infrequent category thus it is encoded as all;-2.5599759;0.58836097;-3.117377;-1.7714055;1.5595618;0.28861785;CODE
zeros;-1.0459442;1.3927598;2.9658995;-4.0785174;-0.8314887;-5.4617844;-
error for unknown categories;-1.9978547;-0.6526581;-3.537757;-0.36550486;-0.032298412;-3.1139455;CODE
only infrequent or known categories;2.0440943;-2.8084037;0.6509911;3.9625773;2.5614016;-0.12310295;-
both categories are unknown;-3.2453759;-2.6995285;0.5000209;0.13905758;2.3665602;-1.7739311;-
inverse transform maps to none;-0.51999485;3.3205945;1.0494534;-2.8705668;-2.470919;2.2380097;IRRE
checks pandas dataframe with categorical features;0.7619088;0.92493767;-2.8225448;-1.122837;-1.7395568;-3.521656;TASK
c is unknown and is mapped to np nan;1.018919;1.2650676;-4.0167465;-4.9444666;-4.1615233;-2.2356713;-
none is a missing value and is set to 3;-3.0122552;5.337483;-1.170116;-3.7956674;0.21739441;-5.2353606;IRRE
non regression test for 24082;1.2145615;3.9055624;-3.6909313;1.9359294;-2.3981402;-4.9458485;IRRE
np nan is unknown so it maps to none;-0.09483308;2.4963703;-2.8408594;-5.117613;-3.8869095;-1.9134228;-
3 is the encoded missing value so it maps back to nan;-1.3685062;2.9827538;-2.5799878;-6.017115;-1.0379449;-3.6362348;IRRE
the 0 th feature has no missing values so it is not included in the list of;-3.2060552;1.4673615;-3.283683;0.117331386;0.4157419;-0.36269462;CODE
features;1.4263527;-6.2441335;5.031171;1.4146436;3.9154737;-1.3022918;TASK
missing value is not in training set;1.584557;2.2979124;-2.3113713;1.0107135;-0.2542883;-2.5448997;IRRE
inverse transform will considering encoded nan as unknown;1.3509164;2.8000426;-2.5633433;-4.3393764;-3.8721163;0.31612232;IRRE
missing value in training set;2.8308408;1.7404555;-1.6889077;0.47146446;0.5756443;-2.728037;IRRE
inverse transform will considering encoded nan as missing;0.63295007;2.7562373;-3.0577865;-4.5395474;-4.509515;0.16172345;IRRE
both nan and unknown are encoded as nan;0.3926851;1.6217691;-2.9553869;-4.2761664;-1.403963;-3.378907;-
x 0 a b c have the same frequency a and b will be;0.5623306;3.5094502;1.3754015;-5.1621337;-0.2669035;-2.2969077;-
considered infrequent because they appear first when sorted;1.1065177;2.6401706;1.8550014;0.6441249;0.030303154;0.032151535;IRRE
x 1 0 3 5 10 has frequency 2 and 12 has frequency 1;0.2329311;1.5940082;1.944204;-6.6741037;1.6415925;-2.040851;-
0 3 12 will be considered infrequent because they appear first when;0.11363715;2.9567654;-0.098601885;-1.2051053;-0.106213294;-2.6545787;IRRE
sorted;-2.109953;-1.8315852;5.487784;-0.96291023;0.35683295;-3.5668275;-
x 2 snake and bird or infrequent;-0.47262114;-1.1216028;3.903466;-1.6051208;1.2056582;-1.8469182;CODE
args kwargs store will hold the positional and keyword arguments;-3.5132964;0.09813976;-0.9943666;0.36305878;0.7421712;2.3504224;IRRE
passed to the function inside the functiontransformer;-2.7124646;2.3223436;0.9833926;-0.456415;-1.6495196;1.9697794;CODE
the function should only have received x;-4.19334;4.583223;1.0820132;-1.4558755;-2.633188;-3.1087713;CODE
reset the argument stores;-5.193206;3.4501593;0.6188122;2.9902477;-0.7161906;0.068625934;IRRE
the function should have received x;-3.8704026;3.1345575;2.2131956;-1.9340957;-1.6871264;-3.8600733;CODE
test that the numpy log example still works;0.720696;1.5942707;-4.022375;0.26207256;-7.6248097;-3.2977695;TASK
test that rounding is correct;1.4179164;5.8226275;0.45973316;0.58878255;-3.7176101;-6.443271;IRRE
test that rounding is correct;1.4179164;5.8226275;0.45973316;0.58878255;-3.7176101;-6.443271;IRRE
test that rounding is correct;1.4179164;5.8226275;0.45973316;0.58878255;-3.7176101;-6.443271;IRRE
test that inverse transform works correctly;0.32440037;6.2903624;-1.1872554;1.6681516;-4.4290586;-3.6091886;IRRE
check that we don t check inverse when one of the func or inverse is not;-0.621313;5.8965707;-2.1100647;1.4817525;-1.1369734;-2.2386744;CODE
provided;-4.4815845;-3.5240974;3.9669585;-0.12733248;0.8143789;-2.5639029;-
does not raise an error;-4.2415533;6.323008;-3.1013653;3.8649578;-2.898861;-3.3978536;CODE
numpy inputs default behavior generate names;1.4558569;-0.6718465;-2.6277683;-2.8361788;-2.2472649;-0.9044272;CODE
pandas input default behavior use input feature names;-0.20071024;-1.5610317;-3.505688;-0.46807498;-1.4572272;-0.13226251;CODE
numpy input feature names out callable;1.1500947;-2.4534297;-2.7981703;-2.9290276;-2.8966074;-1.1719112;TASK
pandas input feature names out callable;0.38903934;-2.576766;-3.2541156;-0.54247713;-0.7508746;-1.2179877;TASK
numpy input feature names out callable default input features;0.046076503;-2.2844346;-3.239583;-2.579649;-2.8204463;0.2667824;CODE
pandas input feature names out callable default input features;-0.22534275;-2.5639062;-3.8313205;-0.7824259;-0.98393315;0.23190816;CODE
numpy input input features list of names;2.3321202;-2.8631637;-0.12380335;-4.092339;-1.5988256;-3.2689676;CODE
pandas input input features list of names;1.4578649;-2.9573543;-0.81974894;-2.268869;-0.297575;-3.2633796;CODE
a b must match feature names in;-0.048573766;0.3155202;-1.3890353;-0.6767835;5.928395;-2.5429792;TASK
numpy input feature names out callable input features list;0.9964135;-2.9673407;-2.267489;-3.056653;-2.7078433;-1.2298751;TASK
pandas input feature names out callable input features list;0.4982574;-3.2115867;-2.8062449;-1.0179596;-0.8773145;-1.108538;TASK
a b must match feature names in;-0.048573766;0.3155202;-1.3890353;-0.6767835;5.928395;-2.5429792;TASK
no warning is raised when feature names out is defined;-4.058546;0.10504723;-4.531078;4.7680464;0.49809647;1.0775632;CODE
no warning is raised when func returns a panda dataframe;-0.73507386;1.3356333;-4.610526;2.015045;-6.1703606;-1.5646611;CODE
warning is raised when func returns a ndarray;-1.7303938;1.8290124;-5.0410748;0.838317;-4.578777;0.27259016;CODE
default transform does not warn;-3.4300187;2.6180942;-3.3076882;0.82944626;-4.0510025;2.9408965;CODE
standardscaler will convert to a numpy array;2.3546073;0.5396624;-4.435005;-4.9712834;-6.5616817;1.5743855;-
one class case defaults to negative label;-2.3663502;2.5442665;-2.0034273;-0.15366681;3.1914122;1.2122418;CODE
for dense case;-0.7132823;-0.74262077;2.913336;1.1452882;2.1176817;-2.0163264;CODE
for sparse case;4.2584686;-2.22633;1.4581063;-0.9217787;3.2114403;1.5821563;CODE
two class case;-0.90350276;-0.04419716;1.9906381;1.0177134;7.400529;-1.5702208;CODE
multi class case;0.13904852;-0.8371299;1.3895577;0.44663343;8.206068;-0.81335914;CODE
two class case with pos label 0;-1.9200579;2.539387;-1.9867712;-1.1902219;4.9206576;-0.2833699;CODE
multi class case;0.13904852;-0.8371299;1.3895577;0.44663343;8.206068;-0.81335914;CODE
calling unique creates a pandas array which has a different interface;0.5425556;0.7907414;-3.5345116;-1.6618382;-1.6499985;0.22291148;IRRE
compared to a pandas series specifically pandas arrays do not have iloc;3.4310763;-1.3659364;-3.4529088;-1.832176;-4.092663;-0.5476509;IRRE
check that invalid arguments yield valueerror;-0.8192162;5.72405;-5.441579;1.3809973;-3.907532;-5.334942;IRRE
sequence of seq type should raise valueerror;0.6813247;5.0197673;-6.0008783;-0.25260967;-0.6767195;-2.649747;IRRE
fail on the dimension of binary;0.8819972;2.861723;-4.564641;-6.138253;1.1213245;-2.671362;-
fail on multioutput data;2.4268053;3.6622746;-1.5767437;1.0758269;-1.1934606;-3.3102129;IRRE
fail on y type;-1.5628641;4.591064;-2.9091477;0.69574803;-1.7157948;-4.8398504;-
fail on the number of classes;1.02142;1.9309378;-1.4356357;2.4928343;4.344473;-4.9444375;IRRE
test labelencoder s transform fit transform and;4.0891643;1.6349987;-3.3660529;-1.0284754;-0.15562382;0.42256552;CODE
inverse transform methods;2.3121939;-1.1479547;2.3952196;-3.3694081;-3.1293445;1.4476643;IRRE
check that invalid arguments yield valueerror;-0.8192162;5.72405;-5.441579;1.3809973;-3.907532;-5.334942;IRRE
fail on unseen labels;1.2347324;3.258568;-1.2537107;0.83912605;0.8865291;-1.5200602;-
fail on inverse transform;-0.7337739;4.2219887;-0.61720186;-1.9658892;-4.658101;-0.18157504;IRRE
test empty transform;-0.1890203;7.5877604;-2.2887557;0.9950633;-2.8545501;-3.7408924;IRRE
test empty inverse transform;-0.3388728;6.8240285;-1.9168319;0.6078365;-3.5403793;-2.7744436;IRRE
test input as iterable of iterables;2.4014103;4.54134;0.56112224;3.080834;-0.01578958;-6.86132;IRRE
with fit transform;3.765659;-0.43686524;3.6670306;-3.6383982;-1.7532573;2.655563;CODE
verify csr assumption that indices and indptr have same dtype;1.7322776;2.3571866;-6.7925467;-1.1090467;0.26044443;-0.49273813;-
with fit;0.12462602;-0.0650269;5.1975527;0.69185;-0.77118975;-0.6666515;-
verify csr assumption that indices and indptr have same dtype;1.7322776;2.3571866;-6.7925467;-1.1090467;0.26044443;-0.49273813;-
test input as iterable of iterables;2.4014118;4.5413394;0.56112194;3.080833;-0.015789878;-6.861319;IRRE
with fit transform;3.765659;-0.43686524;3.6670306;-3.6383982;-1.7532573;2.655563;CODE
with fit;0.12462602;-0.0650269;5.1975527;0.69185;-0.77118975;-0.6666515;-
fit transform;3.997811;0.2837951;2.762098;-4.380309;-2.7573237;2.5813391;CODE
fit transform;3.997811;0.2837951;2.762098;-4.380309;-2.7573237;2.5813391;CODE
ensure works with extra class;-3.052748;2.9950802;-2.9116316;4.9873986;2.2974102;-1.0269798;IRRE
ensure fit is no op as iterable is not consumed;1.8260238;5.6900096;-1.7149231;4.096653;0.7594811;1.4712286;-
ensure a valueerror is thrown if given duplicate classes;1.7901425;4.2446036;-3.9738564;5.3250403;2.2016175;-2.0708535;CODE
first call;-3.6611078;1.4315889;5.330195;2.152511;0.3207387;-1.973639;IRRE
second call change class;-3.6923745;2.55891;2.32894;2.8151839;2.9053657;1.2018555;IRRE
ensure sequences of the same length are not interpreted as a 2 d array;3.6523046;5.276604;-1.49808;-3.481143;0.67823994;-2.1881137;CODE
fit transform;3.997811;0.2837951;2.762098;-4.380309;-2.7573237;2.5813391;CODE
fit transform;3.997811;0.2837951;2.762098;-4.380309;-2.7573237;2.5813391;CODE
fit transform;3.997811;0.2837951;2.762098;-4.380309;-2.7573237;2.5813391;CODE
fit transform;3.997811;0.2837951;2.762098;-4.380309;-2.7573237;2.5813391;CODE
not binary;-3.0924966;-1.8217893;0.31892294;-3.5363965;2.547385;-5.801283;-
the following binary cases are fine however;-1.3165781;4.652224;-2.3479772;-3.0459476;4.2431927;-6.7572517;CODE
wrong shape;-1.4754709;1.2893958;3.40319;-2.7609272;-3.7833917;-0.6027336;META
modified class order;-0.732216;0.19236769;0.5663231;1.041074;4.6082644;0.4932529;IRRE
check label binarize;0.7407467;3.7363133;-1.7002512;-3.1867995;1.4888884;-2.8203025;-
check inverse;-0.40570468;5.2687097;2.1653957;-1.4575913;-2.5368295;-4.916739;-
check label binarizer;0.06995684;2.9813595;-2.0278442;-3.2578092;1.447491;-3.5818205;-
binary case where sparse output true will not result in a valueerror;4.1780343;3.8042438;-6.874666;0.4596101;-1.6728837;-1.8571185;IRRE
make the boundaries 0 and 1 part of x train for sure;0.8636702;1.5171816;3.953978;-4.219803;0.7973457;-0.010724902;CODE
n knots n knots degree periodic splines require degree n knots;-1.4663465;0.7905896;0.64108026;-4.4643354;0.13620141;-0.48156902;CODE
use periodic extrapolation backport in splinetransformer;0.9163374;1.6851943;-0.29369023;-2.3882747;-2.8286219;4.9442825;CODE
use periodic extrapolation in bspline;0.7833669;-0.17585169;-0.38162026;-1.0228491;-0.3735061;2.4272146;-
we expect splines of degree degree to be degree 1 times;-0.51109123;-1.3586367;-1.4150585;-1.6670531;0.39542907;-0.060299903;-
continuously differentiable i e for d 0 degree 1 the d th;-1.9568524;0.37350872;2.5491805;-2.0201938;-0.96716064;-1.4288357;CODE
derivative should be continuous this is the case if the d 1 th;-2.6690867;1.2577143;1.330952;-0.2306402;-2.2909842;-0.112878814;CODE
numerical derivative is reasonably small smaller than tol in absolute;0.79860854;1.2408218;-2.8017054;-1.9681389;-3.376447;2.0885043;-
value we thus compute d th numeric derivatives for d 1 degree;-0.31453156;0.53385824;0.17453289;-3.7866735;-0.84744406;-1.9510881;IRRE
and compare them to tol;1.1422645;0.034378674;1.12097;1.1062791;1.9470617;-2.9420094;IRRE
note that the 0 th derivative is the function itself such that we are;-3.5441287;1.2081075;0.38890666;-1.1923099;-2.0984204;-0.9400175;CODE
also checking its continuity;-3.634176;2.2672148;2.5743363;2.7614427;-4.062807;-1.8693076;-
check continuity of the d 1 th derivative;-2.1852686;1.6293131;0.7743742;0.9017442;-2.955694;-0.8378774;-
compute d th numeric derivative;-1.6200565;0.37782195;1.255787;-2.6237314;-1.1410267;-1.944618;-
as degree degree splines are not degree times continuously;-0.16124254;0.071369626;-1.7878913;-2.603112;-2.4263117;0.6653384;-
differentiable at the knots the degree 1 th numeric derivative;-1.8946505;0.43101916;0.20745222;-1.7749095;-1.72475;0.01721786;-
should have spikes at the knots;-1.2662653;-0.15636814;3.2008975;0.1099879;-2.7802784;0.9557279;-
though they should be exactly equal we test approximately with high;3.1460245;5.600373;-1.3444401;1.8618628;-1.0097481;-4.2805586;IRRE
accuracy;3.9306672;-1.6293526;3.9526026;3.971202;-0.6163568;-4.637612;-
extrapolation regime;3.7753475;1.3093128;1.5205868;1.2511736;-1.4671446;2.2249577;-
test some unicode;-1.1981229;1.6510514;-0.20586586;0.22539854;0.4016023;-6.4957433;IRRE
this degree should always be one more than the highest degree supported by;0.18644845;-0.6740291;-2.0323546;-0.3745899;2.898933;-0.3229862;CODE
csr expansion;-0.63741666;-0.12359646;-0.78614646;-1.0395173;2.6022422;-1.4080727;-
an int64 dtype is required to avoid overflow error on windows within the;-4.4181547;-0.14439799;-6.016246;-1.9600279;-2.446542;-0.20138276;CODE
degree 2 calc function;-2.1024232;0.9660103;1.9438106;-4.177584;-2.0592864;-2.8717084;CODE
calculate the number of combinations a priori and if needed check for;0.060185388;3.1973286;2.2043622;0.12645884;4.5344744;-4.643636;CODE
the correct valueerror and terminate the test early;0.7900956;6.7350383;-3.8934982;5.0727386;-4.0621176;-5.696187;IRRE
account for bias of all samples except last one which will be handled;5.1998606;3.055154;1.2346613;2.104449;2.6612382;0.07045014;CODE
separately since there are distinct data values before it;5.8865886;4.177609;3.0092251;-2.5044284;5.781024;-1.2053441;IRRE
ensure that dtype promotion was actually required;-2.4884007;-0.3999304;-3.953634;2.4955726;1.4590299;1.0469973;META
needs promotion to int64 when interaction only false;-5.9478273;3.4833312;-1.7199074;0.952736;-0.56153286;0.1024557;CODE
this guarantees that the intermediate operation when calculating;-2.036872;3.2915728;1.0897232;0.10549557;1.4608493;1.0950497;CODE
output columns would overflow a c long hence checks that python;1.8939606;0.87306046;-2.6602201;-3.7500277;-5.18721;-4.284357;CODE
longs are being used;-2.1517613;-0.7545509;2.9714606;0.46734086;0.68192226;-1.5462896;-
this case tests the second clause of the overflow check which;-2.0404835;6.044515;-1.4900064;2.0068257;2.6241748;-5.23875;IRRE
takes into account the value of n features itself;3.5043643;0.31188002;-0.50716543;-1.1955992;4.2962217;-0.97935003;CODE
use int32 indices as much as we can;1.694561;0.59821016;-2.570228;-4.778923;1.2940013;-0.3454791;CODE
first degree index;1.6430372;0.9452093;0.6255431;-3.3626022;2.4368904;-2.8085608;CODE
second degree index;2.037266;0.7201157;0.6833531;-3.3901813;1.9929191;-1.7697195;-
third degree index;1.2752448;0.6090461;0.45216867;-4.543022;2.942547;-2.3450918;-
calculate the number of combinations a priori and if needed check for;0.060185388;3.1973286;2.2043622;0.12645884;4.5344744;-4.643636;CODE
the correct valueerror and terminate the test early;0.7900956;6.7350383;-3.8934982;5.0727386;-4.0621176;-5.696187;IRRE
terms higher than first degree;-0.97857535;1.4469491;0.31530827;-2.1959457;1.8395475;-1.7685548;CODE
convert to dense array if needed;3.9902012;3.320057;0.03245365;-4.315276;-0.5510941;-1.5047277;-
on windows scikit learn is typically compiled with msvc that;-0.088285565;-12.428994;-4.631298;0.46092767;-2.6305997;-3.1631658;CODE
does not support int128 arithmetic at the time of writing;-3.2915509;0.7986471;-2.9719045;-3.0148382;-1.3948193;-2.1726656;CODE
https stackoverflow com a 6761962 163740;-5.058772;-1.5457826;2.6747189;-2.0695539;-1.318813;-3.0066395;CODE
minimum needed to ensure integer overflow occurs while guaranteeing an;0.7527058;5.119186;-1.1521665;1.1123664;1.0590688;-1.5828433;CODE
int64 indexable output;-1.8682312;1.9445796;-1.637786;-4.2852817;-0.17970632;-2.7012906;IRRE
first degree index;1.6430372;0.9452093;0.6255431;-3.3626022;2.4368904;-2.8085608;CODE
second degree index;2.037266;0.7201157;0.6833531;-3.3901813;1.9929191;-1.7697195;-
third degree index;1.2752448;0.6090461;0.45216867;-4.543022;2.942547;-2.3450918;-
manually compute encodings for cv splits to validate fit transform;5.2546434;-0.42914894;-4.7150097;-1.6154917;0.784059;0.9860568;CODE
f idx 0 0 0 1 1 1;-0.3265436;3.3980875;-0.5773515;-7.9905896;0.44040188;-3.2093654;-
c idx 0 1 2 0 1 2;-0.70529556;1.980771;0.25493097;-8.777635;1.2148862;-3.4773772;-
exp idx 0 1 2 3 4 5;-2.46467;1.9679384;0.44652635;-7.3243213;3.3983924;-2.9376228;-
manually compute encoding to validate transform;2.2753668;1.9025865;-4.0021534;-2.8551593;0.33611286;-1.4784876;CODE
include unknown values at the end;2.412771;5.053354;0.44793218;-1.5727116;2.2374408;-3.7716398;CODE
add unknown values at end;1.3148263;4.802817;2.0883434;-2.5175397;1.4328355;-3.5799675;IRRE
last row are unknowns dealt with later;0.70453817;3.869417;1.1245649;-1.3027078;1.2679269;-2.3474069;-
unknowns encoded as target mean for each class;3.590309;0.7306617;-2.8611672;1.8405354;2.8367088;-0.29408056;CODE
y mean contains target mean for each class thus cycle through mean of;3.8922951;1.0440724;1.859768;0.16393334;0.8075539;0.3858154;CODE
each class n features times;4.123964;-3.1241894;0.51836056;-1.2651991;6.1176896;-2.816884;TASK
np array 0 10 1 10 3 dtype np int64 t 3 is unknown;-0.74879074;0.9803906;-5.9058414;-7.8018384;-3.5571668;-3.7664804;CODE
t snake is unknown;-1.1039593;-1.5679294;1.3334957;-0.23608547;-2.4055915;-2.1318002;-
cardinality 30 not too large otherwise we need a very large n samples;4.713834;0.33772394;0.19808975;-0.78027123;3.0647109;-2.7032807;-
sort by y train to attempt to cause a leak;0.49083352;0.49741927;1.1346993;2.2811692;-0.015688833;-1.3994141;CODE
check that no information about y train has leaked into x train;-1.3305235;1.3598592;-0.08752335;1.8230048;-1.1486105;-2.0224237;CODE
it s impossible to learn a good predictive model on the training set when;4.1153116;-4.6612353;-1.3757477;5.570456;-0.82495195;-0.29167998;IRRE
using the original representation x train or the target encoded;0.43831336;-0.84151226;-0.07978774;-0.72700274;2.1229274;1.9776615;-
representation with shuffled inner cv for the latter no information;4.914973;0.34408447;-1.382511;-3.2588568;4.5422726;1.7678213;CODE
about y train has inadvertently leaked into the prior used to generate;-1.7511017;-1.1836739;-0.50013155;2.9451947;-0.8094812;0.14216466;OUTD
x encoded train shuffled;1.8831362;0.8338441;1.0396342;-4.0534544;2.469666;-0.24662283;-
without the inner cv shuffling a lot of information about y train goes into the;3.6229064;-2.1157515;1.2609346;2.0814846;1.9707901;1.8366461;CODE
the per fold y train mean priors shrinkage is no longer effective in this;2.730434;0.2237408;-1.6796597;2.365962;-1.3892674;3.9168777;CODE
case and would no longer be able to prevent downstream over fitting;-2.378669;1.3596373;-1.7024478;1.9899604;0.6264413;4.6795497;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
skip index generation if totally dense;3.6917348;2.9264352;-1.9571565;-0.446653;0.91402453;1.6774534;-
generate location of non zero elements;2.0021138;4.3314953;2.0516617;-6.601818;0.69554883;-1.5672599;-
find the indices of the non zero components for row i;3.1313546;2.7310493;-0.57630825;-8.742457;-0.039157387;-1.0596193;CODE
among non zero components the probability of the sign is 50 50;-0.3096192;2.4901145;0.95029694;-2.704056;0.6938519;-1.4354032;-
build the csr structure by concatenating the rows;2.1231809;1.0693614;0.83557993;-4.9262815;3.6009371;-1.2170812;CODE
very few components are non zero;-1.8238809;3.5235968;-2.0195591;-3.9042792;-1.6760368;-1.1326593;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
coding utf8;-1.9292312;-0.72272205;0.79766613;-3.4769928;-0.27066323;-2.867783;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
kernel parameters;1.7528411;-1.7116746;0.07670659;-2.3587527;0.8014217;1.9574231;IRRE
clamping factor;0.94266284;3.0820115;1.29245;-2.7210906;-1.2876587;0.8225664;-
note since predict does not accept semi supervised labels as input;2.1148086;-1.8825339;-3.6777012;0.636769;0.28404942;0.16370794;CODE
fit x y predict x fit x y transduction;3.819463;-0.48310134;-1.8482708;1.1484212;-2.803212;2.1804333;-
hence fit predict is not implemented;1.7720698;-1.0902864;-4.7294283;2.7908125;-4.001286;1.2167125;TASK
see https github com scikit learn scikit learn pull 24898;-1.4927635;-11.577812;-5.4998894;-1.351024;-4.019702;-4.0125794;CODE
actual graph construction implementations should override this;-0.26740226;-1.1344512;-0.5757996;-0.35309893;1.7888852;3.6986103;CODE
label construction;1.571732;-2.0860288;3.8792436;-1.9865688;7.1154222;-0.38215697;CODE
construct a categorical distribution for classification only;3.4046457;-2.960549;0.47440338;-0.14757371;5.0894284;-0.004796937;CODE
initialize distributions;-1.1043496;-0.06713052;1.348826;0.49766335;0.9049113;2.001472;IRRE
labelpropagation;2.363838;-2.2953904;1.1912383;-0.71033865;2.7660325;0.9041154;-
labelspreading;1.5383664;-3.4381936;5.4911547;0.84411496;2.431289;0.9734591;CODE
clamp;-1.0455639;0.4032248;5.4080915;-1.0743787;-0.3715488;-2.3585355;-
set the transduction item;-3.6088793;2.291783;1.1790537;0.7449361;1.6128747;0.79589474;IRRE
compute affinity matrix or gram matrix;3.9469519;-2.4789255;-2.0827777;-4.9893203;-0.34844598;2.1605709;IRRE
laplacian flat n samples 1 0 0 set diag to 0 0;2.7680461;1.9343396;-2.2384822;-5.137532;-1.3549565;3.0366917;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
we don t require predic proba here to allow passing a meta estimator;0.087525025;2.4074657;-2.2983012;4.749354;0.25596008;4.4315343;CODE
that only exposes predict proba after fitting;5.4533167;-1.9784344;-0.40851462;4.4188294;-0.67422634;2.8636208;-
selftrainingclassifier estimator is not validated yet;1.0469893;-1.3687477;-5.9596863;4.1783705;-0.6560067;0.94723547;CODE
we need row slicing support for sparse matrices but costly finiteness check;4.5317416;0.6158877;-3.843156;-1.9044987;0.8440542;3.238131;IRRE
can be delegated to the base estimator;1.051362;-0.19546254;-0.14401352;4.049462;0.7839035;6.7480702;-
predict on the unlabeled samples;6.8657255;0.16157743;0.31004024;1.8910991;2.7933552;-0.555941;-
select new labeled samples;3.9755852;0.25924978;1.4762391;0.77875686;5.5161223;-0.83775973;CODE
nb these are indices not a mask;0.12187469;1.3743203;-2.5280168;-6.167779;0.24212113;-1.1112851;-
map selected indices into original array;2.6903346;2.5008876;1.8584166;-3.9025476;0.5863992;0.8276317;CODE
add newly labeled confident predictions to the dataset;3.7637315;-2.228903;0.73799384;4.7573733;1.7142539;0.45756602;TASK
no changed labels;-3.4232442;-0.95801914;1.3298625;-0.7432712;-0.117358424;0.5753454;-
metadata routing is enabled;-4.6983147;-1.3902187;-0.7262132;0.8494856;-0.82539123;5.258602;-
metadata routing is enabled;-4.6983147;-1.3902187;-0.7262132;0.8494856;-0.82539123;5.258602;-
metadata routing is enabled;-4.6983147;-1.3902187;-0.7262132;0.8494856;-0.82539123;5.258602;-
metadata routing is enabled;-4.6983147;-1.3902187;-0.7262132;0.8494856;-0.82539123;5.258602;-
metadata routing is enabled;-4.6983147;-1.3902187;-0.7262132;0.8494856;-0.82539123;5.258602;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
load the iris dataset and randomly permute it;4.629802;-0.6900109;0.08184903;-1.3635143;1.8827618;1.1239957;IRRE
estimator clone estimator avoid side effects from previous tests;0.96562195;3.2865026;-3.3117712;6.980396;-3.0731986;2.5886402;CODE
check classification for various parameter settings;3.2985556;-0.02190016;-1.4320148;2.51045;3.6795504;-0.4528095;IRRE
also assert that predictions for strings and numerical labels are equal;5.3982477;1.8162022;-3.0950859;2.3362508;0.9703534;-3.4631543;CODE
also test for multioutput classification;5.6100454;-3.6728513;-0.6614462;2.884429;4.045353;-3.394195;IRRE
check consistency between labeled iter n iter and max iter;2.8681545;4.2449574;-1.860732;-0.1543051;2.9380825;-1.378246;IRRE
assert that labeled samples have labeled iter 0;2.8338988;4.8712068;-3.8449664;0.5870388;1.923949;-2.8328834;CODE
assert that labeled samples do not change label during training;2.980191;3.4876392;-2.6080914;4.7360287;2.2462502;-1.3866364;CODE
assert that the max of the iterations is less than the total amount of;3.4958742;4.675318;0.8329633;3.0091736;-0.8505563;-3.124673;CODE
iterations;1.8315902;-0.21061747;6.710878;1.8012992;1.6812203;-4.3973355;-
check shapes;2.2112184;1.2723973;4.6544037;-0.98042905;0.27517173;-3.4933782;-
check labeled iter;-1.4448762;1.2502861;0.3055286;1.1490762;2.6147473;-3.294296;-
check that the all samples were labeled after a reasonable number of;5.1293845;5.461018;-1.4284357;2.9766903;2.3744195;-5.356378;-
iterations;1.8315902;-0.21061747;6.710878;1.8012992;1.6812203;-4.3973355;-
estimator clone estimator avoid side effects from previous tests;0.96562195;3.2865026;-3.3117712;6.980396;-3.0731986;2.5886402;CODE
check classification for zero iterations;5.16364;2.257754;-2.2960525;2.9362242;1.7722359;-2.4854753;CODE
fitting a selftrainingclassifier with zero iterations should give the;4.5790377;-1.0478532;-2.7264755;1.8395597;0.64720696;0.72657925;CODE
same results as fitting a supervised classifier;6.076445;-2.188742;-0.57691455;2.3183513;2.607074;0.03642516;IRRE
this also asserts that string arrays work as expected;-1.3173339;3.7625077;-2.668125;0.119669676;0.5226991;-3.44892;CODE
test that passing a pre fitted classifier and calling predict throws an;3.0686083;1.9086561;-3.1246502;6.282609;-1.3105152;-2.095541;IRRE
error;-5.63395;2.4462695;1.2432225;-0.761733;-1.536994;-4.77406;-
check that the amount of datapoints labeled in iteration 0 is equal to;6.311434;5.47076;-0.04533445;-0.9045145;-1.321582;-3.201367;IRRE
the amount of labeled datapoints we passed;6.082372;-0.48448431;1.4991776;-0.22196335;3.4999087;-0.96690524;CODE
check that the max of the iterations is less than the total amount of;3.5067658;4.8230023;0.7314113;1.8494803;-1.6667379;-4.371155;-
iterations;1.8315902;-0.21061747;6.710878;1.8012992;1.6812203;-4.3973355;-
test that training on a fully labeled dataset produces the same results;5.404728;0.90526885;-3.1404612;4.2728515;2.2069848;-2.6895185;IRRE
as training the classifier by itself;4.5266943;-6.2725015;2.0737453;4.0940228;5.094199;0.08368138;CODE
assert that all samples were labeled in iteration 0 since there were no;4.7671175;6.679967;-2.6140816;3.1736825;0.40461984;-3.94113;IRRE
unlabeled samples;4.0544996;1.5676979;-0.4145827;-0.6023566;3.5688434;-0.043342575;-
x 0 5 cannot be predicted on with a high confidence so training;2.934308;0.55587685;-1.7094809;2.383774;-2.8249447;-1.9987735;CODE
stops early;-2.701238;0.9550292;5.0603647;2.305667;-1.5083296;-1.5965055;-
tests that the labels added by st really are the 10 best labels;2.23996;-0.124245554;-0.0781206;2.250141;2.4155982;-4.055362;TASK
check that a meta estimator relying on an estimator implementing;0.6624515;3.704067;-3.1015778;6.990533;-1.5654489;2.336411;TASK
predict proba will work even if it does not expose this method before being;3.2845619;0.2263196;-0.9940571;7.030166;0.38778317;0.10780728;CODE
fitted;-0.06687482;-0.34276965;4.4376845;-1.183443;-1.1989026;0.042320862;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 19119;-3.4859931;-9.552596;-5.2307777;0.1899884;-4.993307;-5.0125923;CODE
svc with probability false does not implement predict proba that;2.9311862;-0.11521705;-5.6021624;2.9942212;-1.2041854;0.57761544;TASK
is required internally in fit of selftrainingclassifier we expect;1.2431623;-2.8746333;-3.9477406;3.6904957;2.2599037;2.371992;CODE
an attributeerror to be raised;-1.1218842;2.9745138;-4.53562;1.7326694;-2.692456;-1.9747434;META
decisiontreeclassifier does not implement decision function and;-0.41442725;-2.110879;-4.5511584;1.5801398;1.0144062;-0.52330804;CODE
should raise an attributeerror;-1.4672492;3.093444;-4.6775675;3.320211;-3.265146;-1.1925842;META
metadata routing tests;-0.843307;-0.22733422;-1.494115;5.5445786;1.6963054;-0.69893;IRRE
make sure that the estimator thinks it is already fitted;0.7392653;3.9016798;-2.414973;3.864552;-5.533349;3.8037558;CODE
end of routing tests;-0.30803326;2.701596;1.652701;5.8366446;-1.0417191;-2.267333;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
from sklearn svm import liblinear as liblinear type ignore attr defined;-0.52818096;-2.6679509;-8.383231;-1.2025845;-1.9676691;1.9786307;CODE
mypy error error module sklearn svm has no attribute libsvm;-0.9285989;-4.0712004;-6.885327;-2.5683086;-3.0751426;0.30186433;META
and same for other imports;-3.6452684;-3.4806464;-0.48769248;2.0159125;1.2035568;1.076565;CODE
from sklearn svm import libsvm as libsvm type ignore attr defined;-0.11977429;-2.0558546;-7.620799;-1.75379;-1.2630813;2.1186562;CODE
from sklearn svm import libsvm sparse as libsvm sparse type ignore attr defined;1.8220037;-2.8692648;-8.50207;-2.3937888;-1.2034807;3.3561687;CODE
get 1vs1 weights for all n n 1 classifiers;4.774639;-2.0314777;-2.6121342;-2.3508782;2.5695636;1.2205532;CODE
this is somewhat messy;-2.0273159;-0.92184407;5.6462564;-0.2422929;1.2720625;0.94597566;CODE
shape of dual coef is nsv n classes 1;-0.26685774;-3.1547394;-3.7457256;-3.6026878;1.334923;2.6680193;IRRE
see docs for details;-3.5439441;-2.4085562;1.8849424;1.5898745;0.3481367;-0.5879647;CODE
xxx we could do preallocation of coef but;-3.031761;0.4909158;2.3515623;-0.35241577;2.486316;-0.44418523;META
would have to take care in the sparse case;1.5053908;0.5459408;-0.1240607;1.0237925;1.2350495;3.9241118;CODE
svs for class1;0.9817399;-3.9405015;-0.741252;-1.8785347;3.2389348;-0.5627415;CODE
svs for class1;0.9817399;-3.9405015;-0.741252;-1.8785347;3.2389348;-0.5627415;CODE
dual coef for class1 svs;1.17142;-3.3088412;-4.677847;-0.4564991;1.9946414;3.7297845;CODE
dual coef for class2 svs;0.8674499;-3.9996011;-4.4547925;-0.3953504;1.8819098;3.6895032;CODE
build weight for class1 vs class2;2.5107372;-1.2021375;-0.5348929;1.081823;2.9486215;1.1871884;CODE
the order of these must match the integer values in libsvm;0.5793356;2.47534;-3.4883425;-5.448608;2.3740466;-2.0177052;IRRE
xxx these are actually the same in the dense case need to factor;-1.3204179;2.3120525;-0.35163718;-4.6473427;1.0197809;0.1437123;CODE
this out;-1.4655148;-1.9691916;3.4655967;2.331168;0.46835312;-1.024757;CODE
used by cross val score;0.48281273;0.31205767;1.3322388;-0.94847447;1.2240843;-3.0642176;-
input validation;0.31818083;2.8770173;2.1738682;0.81683624;2.1409276;-5.336971;CODE
unused but needs to be a float for cython code that ignores;-3.2896347;3.4413373;-2.0498776;-2.0940518;-1.8803828;-0.016260669;CODE
it anyway;-3.0287535;-0.2501873;2.2810338;0.59073055;-1.4100504;1.0075972;-
var e x 2 e x 2 if sparse;3.56444;3.4295678;-1.6241655;-4.145043;0.12982854;0.29849273;IRRE
see comment on the other call to np iinfo in this file;-5.7692327;-1.309608;-3.525009;-0.62593526;-1.8660871;0.66906714;CODE
in binary case we need to flip the sign of coef intercept and;-0.96904767;2.009249;-2.3437302;-4.3119416;-1.2434747;-1.1534786;CODE
decision function use self intercept and self dual coef;0.8366706;-0.2969874;-1.9337295;0.32112545;0.10126368;3.0271473;CODE
internally;-4.055462;-1.3671008;5.1622043;2.8519888;1.4884795;-1.1398739;CODE
since in the case of svc and nusvc the number of models optimized by;4.64087;-3.9573987;-2.185024;1.3513825;2.3256056;2.642888;CODE
libsvm could be greater than one depending on the input n iter;-1.0597781;0.16154449;-3.0939415;-2.219352;0.9147642;-1.565777;CODE
stores an ndarray;0.6137081;-1.5099119;0.26889563;-3.6347728;-1.2563801;2.377262;-
for the other sub classes svr nusvr and oneclasssvm the number of;1.6723763;-1.7597134;-2.177791;-1.9454899;4.294165;-0.3991448;CODE
models optimized by libsvm is always one so n iter stores an;1.2143639;-4.4671445;-3.112172;1.9694642;3.083504;2.4103875;-
integer;-1.9968137;2.0383642;3.629917;-3.4943144;1.239549;-6.506533;CODE
you must store a reference to x to compute the kernel in predict;1.7161705;-2.2663114;-2.719402;-0.213602;-1.3261431;2.6162124;CODE
todo add keyword copy to copy on demand;-4.624853;-1.3595202;-0.15179726;2.6028867;1.0861667;2.538162;TASK
we don t pass self get params to allow subclasses to;-2.827625;0.23431928;-2.4243438;2.5906749;2.4676275;3.043603;CODE
add other parameters to init;-4.3592544;2.1268816;1.2601733;1.1225462;1.8063245;3.8612888;IRRE
else regression;2.5437534;0.42102078;3.8507135;2.3737898;-0.4968408;-3.1722927;-
precondition x is a csr matrix of dtype np float64;0.21491143;0.85993326;-7.0221615;-5.1603236;-3.4009705;0.377079;CODE
c 0 0 c is not useful here;-2.0263383;1.0448515;-0.31213385;-3.4763007;-2.6696327;-3.2673373;-
svr and oneclass;0.3494526;-2.293783;-2.4412732;-0.1835737;2.9132953;1.361894;IRRE
n support has size 2 we make it size 1;-0.9058787;0.71280366;1.6917164;-4.4312787;1.1935604;0.27632362;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
test sample 1;1.0420079;5.573233;2.1273274;1.6454655;1.6077106;-8.21046;IRRE
test sample 2;0.64228404;5.0192604;2.0351098;1.2337152;1.192714;-8.442924;IRRE
use the original svm model for dense fit and clone an exactly same;3.6586692;-1.1256545;-2.8269582;-0.109049395;-0.1955213;4.723084;IRRE
svm model for sparse fit;6.322734;-3.6037734;-0.911318;-0.7962714;0.74525315;4.292512;IRRE
xxx probability true is not thread safe;-1.355634;3.078417;-0.25520182;2.7159088;0.3180606;-1.1133006;CODE
https github com scikit learn scikit learn issues 31885;-3.5852835;-9.549582;-6.159857;-0.32361242;-4.5833344;-5.1757755;CODE
mypy error module sklearn svm has no attribute libsvm;-1.0350256;-4.2954106;-6.979923;-2.4023142;-2.9845192;0.33488744;META
from sklearn svm import type ignore attr defined;-0.258435;-1.2982223;-8.117464;-0.78684074;-1.9296718;1.8561708;CODE
toy sample;0.095309615;-1.126863;5.4498596;1.2328314;2.0021777;-3.6053288;-
test parameters on classes that make use of libsvm;0.23812985;-0.21368611;-3.6441503;3.0057278;2.3685517;-0.40255755;IRRE
xxx this test is thread unsafe because it uses libsvm cross validation;-0.8815063;1.6177644;-5.5370827;3.615998;-0.46688148;-1.672625;CODE
https github com scikit learn scikit learn issues 31885;-3.5852835;-9.549582;-6.159857;-0.32361242;-4.5833344;-5.1757755;CODE
check consistency on dataset iris;4.410563;1.6984775;-3.7309673;1.764228;0.5863222;-1.2973349;IRRE
shuffle the dataset so that labels are not ordered;3.7201414;0.7468607;1.2120229;-1.9910364;3.2158816;1.4785818;IRRE
check also the low level api;-3.9077551;-2.7276866;-1.0132984;3.1969078;0.17843774;-0.9336468;CODE
we unpack the values to create a dictionary with some of the return values;2.0817125;0.70600045;-0.48173216;-2.3949785;1.3440137;-2.7646136;IRRE
from libsvm s fit;0.65984786;-5.13689;-1.3422724;-1.430261;1.6061661;1.9853492;CODE
libsvm fit status and libsvm n iter won t be used below;-2.2299607;-0.54143625;-4.706384;-1.2672312;-0.76041824;2.8621345;-
we unpack the values to create a dictionary with some of the return values;2.0817125;0.70600045;-0.48173216;-2.3949785;1.3440137;-2.7646136;IRRE
from libsvm s fit;0.65984786;-5.13689;-1.3422724;-1.430261;1.6061661;1.9853492;CODE
libsvm fit status and libsvm n iter won t be used below;-2.2299607;-0.54143625;-4.706384;-1.2672312;-0.76041824;2.8621345;-
if random seed 0 the libsvm rng is seeded by calling srand hence;-0.28420454;-0.27935386;-4.1284637;-0.48728958;1.2191371;0.0799426;IRRE
we should get deterministic results assuming that there is no other;4.2771015;-0.2343861;0.08526813;7.0639796;2.0796964;-2.4952683;IRRE
thread calling this wrapper calling srand concurrently;-4.644945;1.0184636;0.1063739;2.1292691;0.14964141;1.7188662;IRRE
svc with a precomputed kernel;2.169617;-3.534807;-3.1097705;-0.97323495;-0.13920595;4.1283593;-
we test it with a toy dataset and with iris;3.2987075;-4.33919;0.46067184;2.5157113;0.41548422;-3.601032;IRRE
gram matrix for train data square matrix;4.6843977;-2.9663815;-1.6101431;-4.7978673;-0.16884449;1.00256;CODE
we use just a linear kernel;2.912569;-5.3619213;1.2441294;-1.6694996;0.15004402;3.4151368;-
gram matrix for test data rectangular matrix;4.7391586;1.5465455;-1.9742676;-4.4672313;-1.4167539;-1.6355879;CODE
gram matrix for test data but compute kt i j;4.658018;0.8521084;-2.9451606;-2.6326303;-1.2056237;-1.7614688;CODE
for support vectors j only;2.4646294;-2.6039236;-0.31115028;-2.4921293;1.8112352;1.3590803;CODE
same as before but using a callable function instead of the kernel;-2.236392;-1.4998851;0.58230835;0.9555659;0.015228187;3.5666528;CODE
matrix kernel is just a linear kernel;0.040226005;-2.789971;-0.68241715;-1.3220307;-2.5823119;2.512578;-
test a precomputed kernel with the iris dataset;3.7999046;-0.30750865;-3.7511623;0.41405967;-0.24733567;-0.96401465;IRRE
and check parameters against a linear svc;5.9530044;-0.00066663825;-2.6998327;-1.1969489;-0.028798688;1.3601567;IRRE
gram matrix for test data but compute kt i j;4.658018;0.8521084;-2.9451606;-2.6326303;-1.2056237;-1.7614688;CODE
for support vectors j only;2.4646294;-2.6039236;-0.31115028;-2.4921293;1.8112352;1.3590803;CODE
test support vector regression;5.092816;-1.1538012;-1.6611925;2.907532;-0.5886023;-2.600926;IRRE
non regression test previously baselibsvm would check that;0.8895042;3.3302312;-4.4741716;5.7072234;-2.8189037;-1.461334;IRRE
len np unique y 2 which must only be done for svc;2.4510696;-0.65605015;-4.484288;-4.268305;1.7903514;-0.43634456;CODE
check that svr kernel linear and linearsvc give;1.5027796;-0.7857289;-4.1166363;-3.4075394;-2.1144412;0.9023817;IRRE
comparable results;4.9565163;0.40194646;4.406414;2.0634544;1.4240428;-3.2559104;IRRE
check correct result when sample weight is 1;4.7628756;6.2471194;-1.2122604;1.9104611;-0.466427;-3.0097032;IRRE
check that svr kernel linear and linearsvc give;1.5027796;-0.7857289;-4.1166363;-3.4075394;-2.1144412;0.9023817;IRRE
comparable results;4.9565163;0.40194646;4.406414;2.0634544;1.4240428;-3.2559104;IRRE
check that fit x fit x1 x2 x3 sample weight n1 n2 n3 where;4.535739;4.58144;-2.7071943;-3.516839;1.0381997;-0.8767742;-
x x1 repeated n1 times x2 repeated n2 times and so forth;1.1513261;1.43656;2.9442863;-5.4754405;2.0598962;-2.8600092;CODE
bad kernel;-0.89151615;-0.99430853;-0.11472378;-0.9723046;-2.7612936;-2.079118;-
test oneclasssvm;0.32548022;1.9456711;-3.514678;3.778921;2.6592488;-2.3589149;IRRE
todo rework this test to be independent of the random seeds;1.9486014;3.7700307;-0.21738146;5.571737;0.6657813;-4.719244;CODE
test oneclasssvm decision function;2.8737757;2.692125;-4.2049475;4.2567306;3.3264127;-3.0215738;IRRE
generate train data;5.0086412;-1.8013549;2.7681074;-1.455583;1.9937077;-1.5770707;-
generate some regular novel observations;6.6711416;-2.3114767;1.4646629;0.69427294;0.13626361;0.4097774;-
generate some abnormal novel observations;5.389696;-1.1086786;1.1809517;1.1423573;-0.67577666;-1.1810746;-
fit the model;1.4823507;-1.8818413;3.3056061;0.78029215;0.8633571;-0.14115278;-
predict things;5.022709;-4.3043613;5.3012314;4.845814;0.29486805;-1.8041948;-
make sure some tweaking of parameters works;-0.71831495;3.5120606;-1.8366357;0.22205494;-2.6068406;0.257437;IRRE
we change clf dual coef at run time and expect predict to change;1.2735856;-1.9899039;-3.8643498;5.3913956;-1.0626936;2.5921454;CODE
accordingly notice that this is not trivial since it involves a lot;1.7896376;-0.14753115;2.8390694;1.124607;2.8258612;2.701621;IRRE
of c python copying in the libsvm bindings;-2.4174502;-4.08388;-3.1499832;-1.937232;-1.8605375;1.655645;CODE
the success of this test ensures that the mapping between libsvm and;-0.21931005;-1.1136402;-3.8110487;4.126176;1.2349715;-1.8763005;IRRE
the python classifier is complete;1.7207379;-4.737412;-3.729687;1.3306054;0.13146287;-3.1578436;CODE
xxx this test is thread unsafe because it uses probability true;-0.82056695;3.5495389;-1.6115917;4.7746334;0.29580623;-4.3520613;CODE
https github com scikit learn scikit learn issues 31885;-3.5852835;-9.549582;-6.159857;-0.32361242;-4.5833344;-5.1757755;CODE
predict probabilities using svc;5.260096;-3.6224473;-1.4711668;-0.37853143;0.6569535;0.186544;-
this uses cross validation so we use a slightly bigger testing set;2.9160273;0.35599497;1.037023;4.5547795;3.9135795;-0.80586827;IRRE
test decision function;2.6341703;4.384603;0.23746186;4.855202;2.0733967;-6.499647;CODE
sanity check test that decision function implemented in python;1.1473757;2.3497896;-2.6831062;4.6638155;-1.3456384;-6.908261;CODE
returns the same as the one in libsvm;-2.3969805;0.84165543;-2.2984264;-0.8237509;1.2240858;-0.46922964;IRRE
multi class;-0.016694786;-2.3283238;2.69325;-0.12629086;6.6775117;-1.8396083;IRRE
binary;-1.2616984;-0.80328983;1.7943059;-4.7439547;3.6149542;-7.471941;-
kernel binary;-1.2010608;-2.787751;-2.334533;-3.698771;1.0314296;-1.1418314;-
check that decision function shape ovr or ovo gives;2.2072923;1.1689003;-1.498396;-0.63628757;0.8716925;-1.1930104;CODE
correct shape and is consistent with predict;5.294402;-0.20394446;1.446092;1.2390357;-1.2584203;0.39872682;-
we need to use break ties here so that the prediction won t break ties randomly;3.3803217;-0.324703;2.3918278;4.1177373;1.4830797;-0.55314827;CODE
but use the argmax of the decision function;3.6394165;1.1566776;1.197285;-0.12195161;1.6044276;3.011178;IRRE
with five classes;0.5792341;-4.0502687;3.8382733;1.3167044;4.670356;-3.2814672;IRRE
check shape of ovo decision function true;3.2515237;2.7900987;-1.2383331;-0.27999693;0.24316873;-0.7059609;CODE
test svr s decision function;4.2623243;1.4152944;-3.247061;1.7155987;1.0967852;-3.1198869;IRRE
sanity check test that predict implemented in python;2.3374758;0.60129267;-4.489378;7.0219083;-4.178745;-7.0838933;TASK
returns the same as the one in libsvm;-2.3969803;0.8416552;-2.2984266;-0.8237514;1.2240858;-0.46922815;IRRE
linear kernel;2.702998;-2.6358128;1.4614743;-3.006257;-0.33245054;0.878823;-
rbf kernel;-0.10199413;-4.331178;-2.1373522;-1.3932155;0.40402383;0.7544472;-
todo rework this test to be independent of the random seeds;1.9486014;3.7700307;-0.21738146;5.571737;0.6657813;-4.719244;CODE
test class weights;4.692654;2.189813;-0.6019876;3.5225523;1.5255094;-3.7345;IRRE
we give a small weights to class 1;1.9407842;-1.7340997;1.4117161;2.1025894;2.3243234;0.72891825;IRRE
so all predicted values belong to class 2;3.4514337;-0.54774183;-2.1909816;1.7556262;1.575563;-2.3199737;IRRE
estimator base clone estimator avoid side effects from previous tests;0.93414664;3.0758522;-3.41766;6.390163;-2.3753254;2.6208587;CODE
fit a linear svm and check that giving more weight to opposed samples;6.8579016;0.8436668;-2.181845;-1.0556558;-0.052132305;1.7953576;-
in the space will flip the decision toward these samples;5.574848;-1.1881225;2.0789664;0.83133364;2.0049164;-0.78827584;CODE
check that with unit weights a sample is supposed to be predicted on;6.1877193;3.1116207;-1.8696216;5.47793;-0.60366315;-1.3880055;CODE
the boundary;-2.7794204;-0.7226278;7.610274;-0.06360321;0.33867463;-1.0394261;-
give more weights to opposed samples;6.543166;1.5515633;1.0675306;1.2217618;1.221396;1.1532216;-
estimator base clone estimator avoid side effects from previous tests;0.93414664;3.0758522;-3.41766;6.390163;-2.3753254;2.6208587;CODE
similar test to test svm classifier sided sample weight but for;4.9057627;0.52068603;-2.5891101;1.6509516;2.3112137;-1.5353009;IRRE
svm regressors;4.695306;-3.305229;-0.3426047;-3.1718807;0.587882;2.4335337;-
check that with unit weights a sample is supposed to be predicted on;6.1877193;3.1116207;-1.8696216;5.47793;-0.60366315;-1.3880055;CODE
the boundary;-2.7794204;-0.7226278;7.610274;-0.06360321;0.33867463;-1.0394261;-
give more weights to opposed samples;6.543166;1.5515633;1.0675306;1.2217618;1.221396;1.1532216;-
test that rescaling all samples is the same as changing c;4.2232885;4.5821795;-0.25143048;1.3772877;-3.328652;-0.85470515;IRRE
model generates equal coefficients;2.630732;1.3337001;-1.3185532;-0.07830989;-0.1908114;0.4177816;-
todo rework this test to be independent of the random seeds;1.9486014;3.7700307;-0.21738146;5.571737;0.6657813;-4.719244;CODE
test class weights for imbalanced data;5.84184;1.8504273;-1.4859608;2.9208252;1.2067702;-2.4190342;IRRE
we take as dataset the two dimensional projection of iris so;3.2615654;-2.7664564;1.4968455;-3.5980358;0.093191124;1.7480966;IRRE
that it is not separable and remove half of predictors from;2.8697503;-0.72943455;-1.7394449;0.4814615;0.76986045;1.4668638;CODE
class 1;-1.7661562;-2.9508932;2.4476612;1.0270209;3.734762;-3.5554054;IRRE
we add one to the targets as a non regression test;2.3753784;1.47541;-0.4719651;5.8820157;-0.0064934595;-1.5313394;TASK
class weight balanced;3.33621;-0.18782894;-0.043645985;1.204106;3.2619421;-0.37876508;IRRE
used to work only when the labels where a range 0 k;0.0061741155;1.5104314;-1.2419164;-3.3192472;-0.28659883;-0.5704022;OUTD
check that score is better when class balanced is set;3.878188;3.879207;-1.0331782;2.9610417;2.4554162;-4.0634046;IRRE
test dimensions for labels;4.4917564;2.0230992;0.12670717;-3.4146035;1.4492874;-2.245785;CODE
y2 y 1 wrong dimensions for labels;1.5047634;0.6398398;-0.42467088;-6.0385175;-3.0804985;1.4701232;META
test with arrays that are non contiguous;3.723219;6.8825216;0.43302906;-0.08703756;-0.00723813;-4.5970235;IRRE
error for precomputed kernelsx;-1.260343;-0.42810875;-5.60201;-2.3020654;-2.4792628;1.5172055;CODE
predict with sparse input when trained with dense;5.8026843;-2.2245753;-1.2631932;1.9268633;-0.7070245;2.266851;IRRE
check svc throws valueerror when dealing with non finite parameter values;2.1097767;3.8742735;-7.5561123;-0.36565372;-3.3887546;-0.84270954;IRRE
test that a unicode kernel name does not cause a typeerror;-1.8514148;1.3845066;-7.3577127;1.1723788;-2.1202595;-2.8504114;IRRE
regression test for 14893;0.42737812;2.939304;-2.5067246;2.4217105;-3.952207;-7.01325;IRRE
test possible parameter combinations in linearsvc;3.8478255;3.5362434;-3.1191993;-0.9414403;1.0479839;-0.23932795;IRRE
generate list of possible parameter combinations;2.6693103;0.19737737;2.0420167;-1.9492401;4.6815085;-2.1478002;IRRE
test basic routines using linearsvc;3.5591962;1.885535;-3.3209922;0.39815542;-1.6822171;-1.8953073;IRRE
by default should have intercept;-3.1612854;1.4831926;-1.5105023;0.6584789;-2.7158177;2.6599782;CODE
the same with l1 penalty;-1.1383597;1.4743829;1.1620535;2.7361681;0.7819819;2.2177348;-
l2 penalty with dual formulation;1.3471073;1.2336836;-2.3694966;1.1228274;2.4834092;5.898253;CODE
l2 penalty l1 loss;-0.2858196;1.0036843;0.44592148;0.90677696;-0.94028914;1.0500289;-
test also decision function;1.672655;3.7019625;0.06646802;4.7077003;2.063528;-6.432633;IRRE
test linearsvc with crammer singer multi class svm;3.7669523;-0.30401662;-6.3236647;-0.79474396;1.27539;1.0643302;IRRE
similar prediction for ovr and crammer singer;3.927873;-2.6998394;0.15967011;2.8775682;1.6059592;0.28652328;IRRE
classifiers shouldn t be the same;3.2947218;-2.9561055;-3.1534746;1.7369542;4.0494766;-0.044186704;IRRE
test decision function;2.6341703;4.384603;0.23746186;4.855202;2.0733967;-6.499647;CODE
check correct result when sample weight is 1;4.7628756;6.2471194;-1.2122604;1.9104611;-0.466427;-3.0097032;IRRE
check if same as sample weight none;4.5372343;6.191238;-1.2280495;1.5063155;0.33865482;-2.3892567;IRRE
check that fit x fit x1 x2 x3 sample weight n1 n2 n3 where;4.535739;4.58144;-2.7071943;-3.516839;1.0381997;-0.8767742;-
x x1 repeated n1 times x2 repeated n2 times and so forth;1.1513261;1.43656;2.9442863;-5.4754405;2.0598962;-2.8600092;CODE
test crammer singer formulation in the binary case;2.7311058;1.8422506;-2.6180732;-0.45200384;5.579163;-2.1031098;CODE
test that linearsvc gives plausible predictions on the iris dataset;4.732573;-1.7888716;-2.6117995;0.7552221;-1.3565713;-2.0649946;IRRE
also test symbolic class names classes;-0.9436183;0.41496882;-3.160034;3.0930102;3.9151585;-4.6958456;IRRE
test that dense liblinear honours intercept scaling param;2.0381155;1.6776148;-3.9314082;0.4577297;-2.0195317;1.9648556;IRRE
when intercept scaling is low the intercept value is highly penalized;2.9502342;1.459384;-2.5129616;-0.7408889;-5.375118;5.9008436;CODE
by regularization;5.522033;-1.9746182;1.3018695;-1.1460959;1.7208232;2.6531422;-
when intercept scaling is sufficiently high the intercept value;2.099724;2.0124948;-0.2965714;-1.3133078;-5.756103;5.225878;CODE
is not affected by regularization;2.1516173;1.8331097;-3.1953967;1.5432352;-0.21672127;5.581838;-
when intercept scaling is sufficiently high the intercept value;2.099724;2.0124948;-0.2965714;-1.3133078;-5.756103;5.225878;CODE
doesn t depend on intercept scaling value;2.3660989;2.3979244;-0.2784746;-2.0441322;-5.055839;4.7790604;CODE
multi class case;0.13904852;-0.8371299;1.3895577;0.44663343;8.206068;-0.81335914;CODE
binary class case;-0.69155794;-0.32701865;-1.5671483;-1.9156295;7.8991976;-3.9752805;CODE
check that primal coef modification are not silently ignored;0.7767301;3.1356843;-6.466725;2.983479;-0.6510097;0.7059753;-
stdout redirect;-4.001255;2.3886182;3.64176;1.5535915;-2.6588416;-1.9823653;CODE
tdout os dup 1 save original stdout;-3.5645812;1.2566961;-0.22769117;0.20280205;-1.6722829;-1.1202213;CODE
os dup2 os pipe 1 1 replace it;-3.8395193;0.058001008;-0.5084333;-2.353382;0.030324105;-0.8473384;CODE
actual call;-2.8237488;1.1028602;3.7400415;2.1666303;-0.91221434;-1.8527762;IRRE
stdout restore;-3.6674612;1.0674256;1.7054307;1.2595624;-2.137549;-0.3187344;CODE
os dup2 stdout 1 restore original stdout;-3.2502983;0.84693927;0.056625478;0.5128433;-1.9494746;0.42823422;CODE
xxx this test is thread unsafe because it uses probability true;-0.82056695;3.5495389;-1.6115917;4.7746334;0.29580623;-4.3520613;CODE
https github com scikit learn scikit learn issues 31885;-3.5852835;-9.549582;-6.159857;-0.32361242;-4.5833344;-5.1757755;CODE
create svm with callable linear kernel check that results are the same;4.8674264;0.60123116;-3.0264616;-0.29689184;0.7350833;1.6067721;IRRE
as with built in linear kernel;3.062105;-4.8900313;0.41149804;-2.1729255;0.7800214;2.463261;-
clone for checking clonability with lambda functions;-1.7942687;2.5248663;-2.9247534;3.0995643;-0.1987541;-0.15155049;CODE
xxx this test is thread unsafe because it uses probability true;-0.82056695;3.5495389;-1.6115917;4.7746334;0.29580623;-4.3520613;CODE
https github com scikit learn scikit learn issues 31885;-3.5852835;-9.549582;-6.159857;-0.32361242;-4.5833344;-5.1757755;CODE
x foo input validation not required when svm not fitted;1.3619633;2.7596586;-5.5996523;0.84673744;-0.1381649;2.0441146;CODE
ignore convergence warnings from max iter 1;-0.038103674;2.9457505;-4.4336314;4.2882514;-3.0437982;1.9197236;CODE
xxx this test is thread unsafe because it uses probability true;-0.82056695;3.5495389;-1.6115917;4.7746334;0.29580623;-4.3520613;CODE
https github com scikit learn scikit learn issues 31885;-3.5852835;-9.549582;-6.159857;-0.32361242;-4.5833344;-5.1757755;CODE
test that warnings are raised if model does not converge;1.9373136;5.36442;-3.9280684;8.534026;-1.9625657;-2.3846262;CODE
check that we have an n iter attribute with int type as opposed to a;-1.3318552;4.9044805;-4.585866;-1.6041337;0.93133026;-3.8422236;META
numpy array or an np int32 so as to match the docstring;2.3018024;-0.14696737;-3.7432997;-5.544068;-2.1834016;-2.5171845;CODE
test that svr kernel linear has coef with the right sign;2.1953778;0.81036645;-5.205805;-0.57259107;-2.7790685;1.2354282;IRRE
non regression test for 2933;0.13260785;3.823205;-4.445188;2.0653667;-2.9138768;-6.57134;IRRE
test that intercept scaling is ignored when fit intercept is false;2.9471714;6.2830696;-3.682637;2.0852222;-6.71432;2.3159719;CODE
method must be un available before or after fit switched by;-1.4768462;4.340676;-2.311175;3.428734;-1.9978496;3.0568871;CODE
probability param;-1.0128694;1.8683732;5.387208;1.0634266;2.1333525;-3.054115;-
switching to probability true after fitting should make;2.7985284;3.5020301;0.21010971;3.3323631;-1.8091228;2.529673;CODE
predict proba available but calling it must not work;1.3984057;0.8764952;-1.6063727;4.223903;-1.6485481;-1.8619015;IRRE
one point from each quadrant represents one class;1.54931;0.2970803;2.6546137;-5.8136687;1.5640924;-0.945113;CODE
first point is closer to the decision boundaries than the second point;1.986579;0.9780144;3.6384094;0.6696982;0.865309;0.9692381;CODE
for all the quadrants classes;-0.12034255;-1.4007792;3.550392;-3.8789835;1.0262188;-2.1240823;CODE
base points 1 1 q1;-0.11844635;1.3223734;2.961847;-4.833863;1.7878735;-1.7582766;CODE
base points 1 1 q2;-0.23873359;1.2294757;3.1946208;-5.0494094;1.6782058;-1.5175633;CODE
base points 1 1 q3;-1.117811;1.284359;2.6549182;-5.3178625;2.112266;-1.7190075;CODE
base points 1 1 q4;-0.2026591;1.5323973;3.0533164;-4.8772616;1.829403;-1.4924392;CODE
test if the prediction is the same as y;3.9719288;3.5066144;0.77253294;3.6305556;-2.3099022;-5.177284;IRRE
assert that the predicted class has the maximum value;4.489583;2.512131;-1.4965864;3.6016078;1.3047649;-2.4411426;IRRE
get decision value at test points for the predicted class;4.967847;1.3082377;-0.70023113;3.4324307;1.2577386;-3.7370641;IRRE
assert pred class deci val 0 here;-0.5405518;6.837668;-5.46931;1.58596;1.1568313;-4.568957;CODE
test if the first point has lower decision value on every quadrant;3.6797633;5.5194154;1.4049525;-0.60665196;-1.04044;-3.0116978;IRRE
compared to the second point;0.73679084;1.0497222;5.9136066;1.7066675;-0.9021549;-0.9021654;IRRE
xxx known failure to be investigated either the code needs to be;-5.204784;2.705303;-5.257401;1.6668937;-2.082208;-5.331389;TASK
fixed or the test itself might need to be made less sensitive to;-1.6729474;5.77425;-5.498688;6.1605277;-3.8829072;-3.3217921;CODE
random changes in test data and rounding errors more generally;3.7713263;3.661423;-1.9938151;4.0494328;-4.1004953;-2.8601017;IRRE
https github com scikit learn scikit learn issues 29633;-3.3903708;-10.089891;-5.916586;-0.33850336;-4.9358463;-5.517281;CODE
xxx https github com scikit learn scikit learn issues 31883;-3.6668317;-8.986653;-6.234371;-1.204548;-5.103982;-5.3118234;CODE
make n support is correct for oneclass and svr used to be;0.15688905;-1.3776965;-5.5428033;-1.0601503;3.0014737;1.7119352;CODE
non initialized;-4.9332013;2.8846612;0.0074710296;0.66171175;0.54785603;-1.4187964;IRRE
this is a non regression test for issue 14774;-0.77623284;2.8363492;-4.2052164;2.277706;-2.687741;-6.037129;CODE
non regression test for 18891 and https nvd nist gov vuln detail cve 2020 28975;0.61238253;2.47879;-4.969362;1.8206625;-2.3031254;-3.8088892;IRRE
first check that the names of the metadata passed are the same as;-5.631647;-0.27892402;-4.8378344;1.5825721;0.24213472;1.9184623;-
expected the names are stored as keys in record;-1.3429451;0.66355795;-1.4868685;-0.753978;3.1842985;-1.0309228;-
the following condition is used to check for any specified parameters;0.19169721;6.2049184;-0.6770459;0.3770679;3.254959;-2.5720344;IRRE
being a subset of the original values;3.5773828;3.4720945;2.9148457;-1.2387058;4.5567565;-1.2107896;IRRE
this list is used to get a reference to the sub estimators which are not;1.7399603;-1.0101669;-1.4192139;2.1079905;-0.15234415;1.2299503;CODE
necessarily stored on the metaestimator we need to override deepcopy;-1.0427222;0.49934402;-1.7682669;3.2146013;-1.5712018;6.1025968;CODE
because the sub estimators are probably cloned which would result in a;1.8980167;1.3028953;-3.0244606;2.8692963;-1.7738526;3.2610662;IRRE
new copy of the list but we need copy and deep copy both to return the;-1.927956;0.60375375;0.6555816;1.5485384;0.306241;-0.029565498;CODE
same instance;-3.084399;-0.9604831;4.087921;2.7429814;1.2382541;-0.95708287;-
return np ones len x pragma no cover;0.41928875;3.1433141;-2.2838428;-2.0896797;0.2076759;-1.930773;IRRE
each row sums up to 1 0;4.368579;2.9875498;1.8839868;-6.418531;-0.6513538;-4.573111;-
implementing fit transform is necessary since;3.9579659;1.000991;-0.95301235;-1.1369896;-2.370393;3.6385972;TASK
transformermixin fit transform doesn t route any metadata to;-1.4740183;0.20264594;-4.086067;0.024119053;-3.2858431;5.9083047;CODE
transform while here we want transform to receive;-2.2115142;1.8063843;4.208442;-3.6857631;-0.67798334;1.1696317;CODE
sample weight and metadata;3.6326187;-1.3305756;-0.58118254;1.6350294;3.617224;0.79701525;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
a few test classes;3.2986412;-2.0182126;2.0862188;4.1010857;4.347429;-7.3559527;IRRE
calling pca methods such as get feature names out still works;-1.597358;-0.7267862;-4.1815643;1.7263197;-0.36346406;3.1753054;TASK
fitting on a new data does not alter components;3.2247465;2.389078;-1.9059609;0.46183932;-1.6989791;5.0655165;CODE
fit transform does not alter state;1.3140391;3.3480444;-1.2249757;-0.80375344;-3.9451478;4.6076317;CODE
cloning estimator is a no op;-0.68274665;1.5567962;-2.0279233;2.948915;-1.9533831;2.071722;-
test that we can predict with the restored decision tree classifier;3.2216108;-1.0942848;-1.8520368;6.290726;2.9807181;-3.0391269;IRRE
treenoversion has no getstate like pre 0 18;-4.981086;1.1290569;-1.8444746;0.6911862;-0.43938044;0.1352147;META
check we got the warning about using pre 0 18 pickle;-4.6192026;1.2286643;-2.688793;2.4554539;-2.2841687;-2.9779756;-
the test modifies global state by changing the treenoversion class;-0.02554229;1.6472447;-3.2820232;5.552779;1.5868016;-0.09771751;IRRE
test that changing tags by inheritance is not allowed;-3.463171;4.34118;-2.4362912;5.944926;2.57046;-1.2186722;IRRE
checks the display configuration flag controls the json output;-3.6200511;4.1659603;0.81859475;2.5298164;-2.8646748;2.210205;IRRE
checks the display configuration flag controls the html output;-4.445999;4.394789;1.5299649;1.9805119;-2.0613692;2.0530024;IRRE
fit on dataframe saves the feature names;3.612768;-0.99989367;-2.3386781;-0.43433723;-3.2818973;2.936963;TASK
fit again but on ndarray does not keep the previous feature names see 21383;-2.4519045;-1.2773466;-4.9328823;-2.3090649;-2.1790657;2.7448063;TASK
warns when fitted on dataframe and transforming a ndarray;2.4124253;1.2670801;-5.170455;-1.9626727;-6.6617413;1.8690327;CODE
warns when fitted on a ndarray and transforming dataframe;2.3911674;1.1625051;-5.2785435;-1.990135;-6.6431274;1.9453253;CODE
fit on dataframe with all integer feature names works without warning;3.3681686;2.1626375;-5.4533463;-1.5603098;-3.2955215;0.28517544;TASK
fit on dataframe with no feature names or all integer feature names;4.3706546;0.43195534;-3.063378;-2.8185215;-2.0095255;1.1930779;TASK
do not warn on transform;-2.6462524;3.0991352;-0.6298257;2.2330487;-2.802348;1.1499628;CODE
fit on dataframe with feature names that are mixed raises an error;3.0958126;1.235002;-4.665639;-0.83856684;-3.2049491;1.3360797;TASK
transform on feature names that are mixed also raises;1.5443618;-0.8053878;-1.1623878;-0.39312395;3.7502089;2.117536;CODE
this should not raise;-2.8728483;2.0293982;2.4968486;1.4839445;-1.6324766;0.34648162;CODE
pyarrow does not work with np asarray;-3.676449;-1.1343879;-3.6823146;-2.2262764;-5.8858824;0.9090742;CODE
https github com apache arrow issues 34886;-5.763525;-1.6631056;-1.2873288;-0.4658764;-4.1194963;0.9712365;CODE
passing the metadata to fit transform should raise a warning since it;-0.42425498;1.133035;-4.339511;2.9806707;-1.730114;5.3748336;CODE
could potentially be consumed by transform;-2.0035303;-0.18287192;0.29086527;0.7662519;-1.2911253;2.3792367;CODE
not passing a metadata which can potentially be consumed by transform should;-1.57019;1.7281554;-2.9573686;2.2707238;1.3269446;6.0943875;CODE
not raise a warning;-3.7435272;1.8868885;0.20457432;5.7833495;-1.1427302;-0.4976928;CODE
passing the metadata to fit predict should raise a warning since it;1.3992527;-0.53776294;-4.3361645;5.8537574;-1.1911583;3.2931006;CODE
could potentially be consumed by predict;3.5304577;-2.6876428;0.13424946;6.2083464;-0.27316764;-0.8411857;-
not passing a metadata which can potentially be consumed by predict should;1.0651857;-0.5044937;-2.952819;6.4056582;1.5626167;3.67584;-
not raise a warning;-3.7435272;1.8868885;0.20457432;5.7833495;-1.1427302;-0.4976928;CODE
check that sklearn is built with openmp based parallelism enabled;0.9142287;-4.8071213;-6.0826497;0.18940437;-5.349987;-0.45056057;CODE
this test can be skipped by setting the environment variable;-3.5099308;5.876285;-4.2948937;5.533733;-2.6393313;-3.4793768;IRRE
sklearn skip openmp test;1.3407459;-0.6340814;-5.4057693;2.1777847;-5.5246487;-2.064509;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
check that invalid values raise for the method parameter;-0.31029367;8.103438;-3.3459697;4.463507;-1.3789073;-3.219222;IRRE
test calibration objects with isotonic sigmoid;5.704835;0.3616841;-1.9273479;0.5769326;-1.4877481;0.83921874;IRRE
x x x min multinomialnb only allows positive x;-0.43038225;4.0590034;-2.7025268;-2.9789798;1.9408219;-0.20488322;-
split train and test;4.044643;1.8693123;1.7173284;3.5478806;3.0246403;-3.2907925;IRRE
naive bayes;3.6464386;-2.3002443;1.9687318;2.770644;3.426596;-3.2021356;-
naive bayes with calibration;5.118413;-2.533498;-0.7395981;1.88584;1.7653387;-0.681422;-
note that this fit overwrites the fit on the entire training;1.3310478;-1.869699;-0.8131398;2.192316;0.84716916;2.6161366;TASK
set;-1.4280705;0.15607189;7.4121943;-1.1588911;1.308024;-3.1926973;IRRE
check that brier score has improved after calibration;1.6510828;2.7623904;-2.2218518;3.687387;-2.4296505;-2.1867943;-
check invariance against relabeling 0 1 1 2;2.5115435;4.5800204;-3.1381829;-2.3770227;0.6027811;-0.77666605;CODE
check invariance against relabeling 0 1 1 1;2.4859731;4.59586;-3.0818224;-1.9347395;0.6618105;-0.2855962;CODE
check invariance against relabeling 0 1 1 0;2.3021054;4.8045735;-3.3025494;-2.0148547;0.15045717;-0.23064898;CODE
isotonic calibration is not invariant against relabeling;2.067119;1.1787094;-3.7403045;-0.5386127;-2.497969;4.5305386;CODE
but should improve in both cases;-2.136306;1.0410659;2.6374412;4.6885734;1.2485275;-0.11917435;META
check estimator default is linearsvc;0.914711;3.1272862;-5.0194774;0.6348074;-4.7527857;3.040274;CODE
check when cv is a cv splitter;2.0025556;2.1290176;-2.3881896;1.7347454;2.3205168;0.21333091;-
check error raised when number of examples per class less than nfold;1.9401572;3.0363972;-3.7558725;2.5717025;2.2794652;-3.5434666;CODE
as the weights are used for the calibration they should still yield;3.484679;0.57009;-1.3844906;2.8513608;-2.835098;1.857782;TASK
different predictions;2.5191586;-0.8009287;3.462406;4.3636312;-0.94142646;-2.542887;-
todo remove mark once loky bug is fixed;-5.863762;1.7962039;-1.221311;2.4669986;-1.3744892;2.2256227;TASK
https github com joblib loky issues 458;-5.9445925;-3.3966901;-3.4007475;-0.13234863;-4.2971582;-1.9892539;CODE
x x min multinomialnb only allows positive x;-0.25804546;4.0108643;-2.8757355;-2.9088976;1.8974948;-0.35567173;-
split train and test;4.044643;1.8693123;1.7173284;3.5478806;3.0246403;-3.2907925;IRRE
naive bayes;3.6464386;-2.3002443;1.9687318;2.770644;3.426596;-3.2021356;-
naive bayes with calibration;5.1184125;-2.5334992;-0.7395969;1.8858389;1.7653399;-0.6814237;-
test that ensemble false is the same as using predictions from;5.348647;2.5269265;-3.5033445;7.4747357;0.6819285;-3.6289117;IRRE
cross val predict to train calibrator;4.3162503;-1.7121401;-1.5534981;1.8466381;-2.0071547;0.04242515;-
get probas manually;-4.6930995;-1.0827671;-1.38078;1.5359216;0.15246409;-0.5827993;-
use clf fit on all data;5.797522;1.1189597;-1.5959744;-1.8372086;-0.47723994;2.247342;-
train the calibrator on the calibrating set;4.581089;-0.24464999;0.6339743;1.683481;-0.77974516;2.5373726;IRRE
there is one and only one temperature scaling calibrator;1.7425679;-0.5685053;0.5480325;-1.2079057;-2.4287179;1.0251654;CODE
for each calibrated classifier;5.972022;-3.7489574;-0.07554179;-0.29497516;3.320433;-1.0533086;CODE
should not raise any error;-4.3377614;5.6457486;-3.6578755;4.381948;-3.003606;-1.5170885;CODE
the optimal inverse temperature parameter should always be positive;0.70752835;2.9428055;-1.2903707;-0.54550207;-3.2241232;3.0007105;IRRE
accuracy score is invariant under temperature scaling;5.3039064;-0.08087977;-3.0200129;1.4129045;-3.9019573;0.21195109;CODE
log loss should be improved on the calibrating set;4.780638;0.25691113;-1.920942;2.1315649;-2.301259;1.8942251;IRRE
refinement error should be invariant under temperature scaling;3.1309445;2.4532623;-4.5371885;0.9312931;-5.067787;3.638383;CODE
use roc auc as a proxy for refinement error also note that roc auc;-1.618951;-0.606911;-5.581609;2.7009869;-0.39426416;1.2044178;TASK
itself is invariant under strict monotone transformations;-1.9746621;1.2964694;-1.1679944;1.2981405;-0.22391942;3.879136;CODE
for logistic regression the optimal temperature should be close to 1 0;1.6601164;0.5887843;-1.6609722;-0.71158683;-3.0962327;-0.38618112;CODE
on the training set;1.4760156;-4.4915156;3.5392725;2.5132499;2.7586749;-1.0208386;IRRE
check that temperaturescaling can handle 2d array with only 1 feature;4.779864;3.8378255;-2.210089;-3.0918875;-2.4362757;0.025350437;TASK
test that sum of probabilities is max 1 a non regression test for;2.248777;3.2348468;-1.6646898;3.3017225;-0.7029038;-2.69668;IRRE
issue 7796 when test has fewer classes than train;0.8467394;2.260426;-5.79492;3.5582132;1.3683155;-4.62398;IRRE
in the first and last fold test will have 1 class while train will have 2;1.1560919;1.2508844;-1.2310613;2.5935535;4.205548;-2.9942913;CODE
test to check calibration works fine when train set in a test train;1.9977381;4.200127;-4.7302732;3.0926743;-3.7568028;-1.7175504;IRRE
split does not contain all classes;-1.6495802;-0.4192008;-2.9132338;0.70357144;3.5178523;-1.0004355;CODE
in 1st split train is missing class 0;-0.88540876;0.5955437;-2.687896;-0.73702955;1.9586115;-1.2896386;IRRE
in 3rd split train is missing class 3;-2.207767;-0.615369;-1.9804372;-0.41258526;2.9889045;-0.4426815;IRRE
check that the unobserved class has proba 0;1.4741342;3.7437658;-4.101679;2.7501063;1.8009971;-1.2871228;IRRE
check for all other classes proba 0;1.1797748;3.3656373;-2.0181363;2.1174169;3.5407586;-6.068191;CODE
when ensemble false cross val predict is used to compute predictions;4.980596;0.0072625377;-4.8807716;3.9651146;0.1926968;-0.17677991;OUTD
to fit only one calibrated classifiers;6.6676855;-1.4863663;-1.2185608;0.65133035;3.406875;2.1028285;IRRE
toy decision function that just needs to have the right shape;2.2367744;-0.43973115;5.25443;-0.35541502;2.369756;-0.72191757;TASK
we should be able to fit this classifier with no error;3.5043619;0.2402242;-3.9471257;-0.12154472;1.4011748;0.12911065;CODE
check attributes are obtained from fitted estimator;3.9146826;3.1749504;-1.4678749;2.1314216;-1.014696;2.077131;META
neither the pipeline nor the calibration meta estimator;-0.52430737;-0.8291488;-3.2254393;3.0809197;-3.8394883;1.1777066;CODE
expose the n features in check on this kind of data;4.016814;0.71840435;0.031018348;-0.6417284;4.924372;-2.7106771;CODE
ensure that no error is thrown with predict and predict proba;2.9012964;3.6751456;-1.6695211;7.2355533;-1.0411769;-1.8387691;CODE
check that n features in and classes attributes created properly;1.10652;1.1455104;-3.252972;1.5001332;4.256996;-3.091319;IRRE
check that n features in from prefit base estimator;3.1560824;2.232737;-3.2973979;1.6642195;1.0293432;0.90326643;TASK
is consistent with training set;4.3173513;-1.1160487;0.38839215;5.1146894;2.4022503;1.4603907;IRRE
check that calibratedclassifier works with votingclassifier;1.9893456;0.040933855;-5.467852;2.6729286;1.3497726;-0.71618545;IRRE
the method predict proba from votingclassifier is dynamically;3.6586235;-1.9744744;-2.4516823;4.3126774;2.4981625;0.2683326;IRRE
defined via a property that only works when voting soft;-1.4679958;2.2911303;-1.8135451;3.5925725;4.660857;3.6470678;CODE
smoke test should not raise an error;-0.7775489;6.789524;-3.2628725;5.5533986;-2.8745596;-1.801525;IRRE
ensure calibrationdisplay from predictions and calibration curve;2.9426749;-0.80613905;-1.8313698;3.6671576;-3.5582514;3.298675;CODE
compute the same results also checks attributes of the;5.863955;4.388989;-0.16825414;0.8915375;4.679296;-4.375981;IRRE
calibrationdisplay object;0.75026923;0.07427136;0.8910168;-1.4862736;-1.9529083;0.9271169;IRRE
cannot fail thanks to pyplot fixture;-2.441599;3.0537264;-1.8450438;0.24071625;-6.636554;0.09477772;-
ensure pipelines are supported by calibrationdisplay from estimator;1.5364436;0.04640649;-4.416948;3.8618972;-2.6888871;4.820996;CODE
checks that when instantiating calibrationdisplay class then calling;-2.1773999;2.127495;-2.5935032;4.5605903;-1.2763945;0.20826386;IRRE
plot self estimator name is the one given in plot;0.3324991;0.24098699;1.2104269;-1.7321824;-5.7957716;2.2532156;CODE
check that the name used when calling;-4.428334;2.6269944;0.6222803;2.4756048;1.309526;-2.2035763;IRRE
calibrationdisplay from predictions or;4.5333586;-3.0265548;0.7613567;2.8906286;-1.7338967;0.73122615;CODE
calibrationdisplay from estimator is used when multiple;2.2710855;2.734781;-2.3220758;0.84874743;-1.59428;3.844058;CODE
calibrationdisplay viz plot calls are made;-0.0075025875;-1.8830781;1.1716799;-1.1262561;-4.8946238;1.0450832;IRRE
check that ref line only appears once;-4.075189;6.0402136;1.2526685;3.0933008;-0.9750312;-1.2148505;-
default case;-3.737243;0.17979208;2.804617;-0.028802615;2.7549024;0.45396617;CODE
if y true contains str then pos label is required;-1.2173158;4.296814;-2.7095392;0.071932316;2.7163382;-4.1048193;CODE
scale the data to avoid any convergence issue;8.464711;2.5192683;1.4492463;0.75377524;-2.4871757;3.0650187;CODE
only use 2 classes;-2.138292;-1.3982093;1.4591465;1.521237;6.2887454;0.602833;IRRE
interlace the data such that a 2 fold cross validation will be equivalent;3.774162;2.8145978;-0.0029502574;0.6402015;3.0338476;0.19601132;CODE
to using the original dataset with a sample weights of 2;5.5576;0.530172;0.24389926;-0.6032289;1.8730569;0.23422073;IRRE
check that the underlying fitted estimators have the same coefficients;3.4532068;4.6850047;-2.7297146;2.3755562;-2.8577352;3.2750812;-
check that the predictions are the same;3.5183966;1.5448618;1.1456734;5.1758647;-1.5789478;-3.525869;-
check that the decision function of sgdclassifier produces predicted;3.626541;-1.4569741;-5.349967;3.5456338;0.83421624;-2.0294216;CODE
values that are quite large for the data under consideration;6.4423666;0.69841605;1.7565227;-0.9206372;0.3748051;-2.9565213;IRRE
compare the calibratedclassifiercv using the sigmoid method with the;5.008727;-1.6084025;-3.5601594;-0.26649785;-1.045862;-1.3561238;IRRE
calibratedclassifiercv using the isotonic method the isotonic method;5.092792;-3.0970385;-3.0752165;-0.9662767;-0.6739576;1.3308746;IRRE
is used for comparison because it is numerically stable;3.2194006;1.5226383;0.5702277;1.0957294;-0.49446505;-2.1111305;IRRE
the isotonic method is used for comparison because it is numerically;2.891821;1.4617889;-0.25570744;-0.024190158;-1.56584;-0.43269894;IRRE
stable;-1.8943725;-1.6073065;4.9279366;1.8391316;-1.4195144;-1.6829987;-
the auc score should be the same because it is invariant under;1.0095035;0.27244312;-1.8060858;1.905507;1.3162699;0.28357196;CODE
strictly monotonic conditions;-1.2847133;4.066129;1.4807839;-0.63611525;1.3713431;-0.36327255;-
check that for small enough predictions ranging from 2 to 2 the;3.2754238;0.81676084;0.9822803;4.1122713;-0.62778026;-4.4936156;CODE
threshold value has no impact on the outcome;1.8596096;5.2061067;-1.7165076;1.7399825;-1.8921752;-0.89696074;IRRE
using a threshold lower than the maximum absolute value of the;1.7867566;3.8201544;1.3003408;-0.9707512;0.21673915;-0.14047746;IRRE
predictions enables internal re scaling by max abs predictions small;4.5990014;-1.4291785;-0.42534983;3.2727458;-3.7809641;4.8866343;CODE
using a larger threshold disables rescaling;2.8053823;2.3929818;0.40063536;1.1289204;-2.5167227;5.201711;-
using default threshold of 30 also disables the scaling;0.45169574;2.3384347;-1.4211866;-0.6936145;-4.358569;4.8557706;CODE
depends on the tolerance of the underlying quasy newton solver which is;1.1530513;1.1550524;-2.2417238;1.134234;-3.066891;1.7175385;CODE
not too strict by default;-2.6237974;0.5109733;0.36077768;2.4934797;-0.332121;0.796683;CODE
use dtype np float64 to check that this does not trigger an;-1.9379528;2.8828492;-6.6861687;-1.6705676;-4.110067;-2.5556695;CODE
unintentional upcasting the dtype of the base estimator should;0.8347167;0.5200567;-5.286916;1.2427542;-2.9205158;2.701457;CODE
control the dtype of the final model in particular the;0.70974714;-1.5734738;-1.3751367;2.6025116;1.0673416;2.8437738;CODE
sigmoid calibrator relies on inputs predictions and sample weights;5.416929;-2.231658;-2.6664512;2.301291;-3.5575497;2.309978;META
with consistent dtypes because it is partially written in cython;-0.052151646;-0.38572052;-3.3625662;-2.230732;0.76080674;-1.6386586;-
as this test forces the predictions to be float32 we want to check;2.2096188;2.944072;-4.4786606;2.9487028;-3.3432934;-5.8208165;CODE
that calibratedclassifiercv internally converts sample weight to;3.3969393;-2.1272414;-4.61891;0.30748218;-1.8908288;1.448131;CODE
the same dtype to avoid crashing the cython call;-2.08353;-1.4039468;-1.795017;0.9561949;-0.18513438;-0.62734467;IRRE
does not raise an error;-4.2415533;6.323008;-3.1013653;3.8649578;-2.898861;-3.3978536;CODE
check with frozen prefit model;-0.9344537;3.6016974;-2.7821443;5.396762;-0.8586895;1.2624272;-
does not raise an error;-4.2415533;6.323008;-3.1013653;3.8649578;-2.898861;-3.3978536;CODE
todo also ensure that calibratedclassifiercv works appropriately with;1.0749011;-1.2109646;-6.672058;1.5593759;-3.6860616;1.7380419;CODE
the array api when y is an ndarray of strings and we fit;4.0719213;0.28872526;-1.569743;-4.1810913;-2.51621;-0.05741471;CODE
lineardiscriminantanalysis beforehand in this regard;3.3521621;1.09242;-0.75459725;-0.9576556;0.5225465;3.1506023;CODE
lineardiscriminantanalysis will also need modifications;3.3617966;0.22320531;-3.1203668;-0.48638704;0.090699755;3.989777;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
make it possible to discover experimental estimators when calling all estimators;3.0270011;-1.0634358;-0.9201475;6.2451954;-1.9835361;1.7491254;IRRE
enable halving search cv noqa f401;-0.5284911;2.3556976;-3.3079474;0.049635503;-0.8269041;1.2772952;-
enable iterative imputer noqa f401;-2.1103415;-0.32210302;-1.8927876;-0.11363155;-0.6608632;1.4015113;-
pytest mark thread unsafe import side effects;-3.6642077;-0.15228383;-3.4843447;2.9204922;-3.1656175;1.5085227;CODE
test that all estimators doesn t find abstract classes;2.2446566;2.6840832;-4.3164024;6.0398607;0.31867775;-0.51266134;IRRE
pass pragma nocover;-2.903933;1.9295914;0.4784397;1.1406045;1.3120474;-1.4013852;-
common tests for estimator instances;3.2635145;2.1554155;-1.2683823;7.599199;0.18782221;-0.63299006;IRRE
pytest mark thread unsafe import side effects;-3.6642077;-0.15228383;-3.4843447;2.9204922;-3.1656175;1.5085227;CODE
smoke test to check that any name in a all list is actually defined;1.4528258;4.408314;-2.2219956;3.6214547;2.42049;-4.3213243;IRRE
in the namespace of the module or package;-6.7016993;-4.2190247;-0.5973065;-0.63484704;1.6399354;0.9375884;CODE
avoid test suite depending on build dependencies for example cython;-1.9886872;0.9747304;-3.304056;4.625061;-0.14072576;0.056327835;CODE
pytest mark thread unsafe import side effects;-3.6642077;-0.15228383;-3.4843447;2.9204922;-3.1656175;1.5085227;CODE
ensure that for each contentful subpackage there is a test directory;-1.5448416;2.3673863;-1.5124644;3.7560978;1.5567921;-0.7972716;CODE
within it that is also a subpackage i e a directory with init py;-5.1600294;-2.909924;-0.39524788;-0.89572006;-0.2924279;0.45474422;IRRE
make sure passing classes to check estimator or parametrize with checks;1.8012395;2.92433;-5.1345453;5.252644;-0.435847;0.6051723;IRRE
raises an error;-4.1813383;4.519439;-2.3081849;1.9306802;-1.3220234;-4.7699113;CODE
todo fix mlp to not check validation set during mlp;0.56628925;3.6247814;-4.5520835;4.692065;-0.612917;1.6376063;TASK
note when running check dataframe column names consistency on a meta estimator that;1.1401367;2.1228607;-6.3050756;1.8327672;-3.51873;0.96275586;TASK
delegates validation to a base estimator the check is testing that the base estimator;-0.002647819;4.134851;-3.2680233;6.4229903;-0.4047616;1.2096952;IRRE
is checking for column name consistency;1.3783741;4.769512;-2.9280941;0.9638133;2.1526487;-1.5067104;CODE
todo as more modules support get feature names out they should be removed;-5.4829354;-2.3744566;-3.190722;2.8731933;0.67255926;2.3783584;TASK
from this list to be tested;0.88853294;-0.18265124;2.4609435;6.310221;2.1152718;-6.677032;CODE
the following estimators can work inplace only with certain settings;2.4507327;3.4538581;-1.6775248;1.5742488;-3.003359;6.4683633;IRRE
not using as a context manager affects nothing;-4.842927;0.19661649;0.00028466556;4.5753474;-1.8451214;5.4578347;-
global setting will not be retained outside of context that;-5.0355644;2.0939987;1.2897031;3.1508694;-1.3921459;6.3081417;IRRE
did not modify this setting;-5.7152424;1.5488896;1.4888104;0.92293525;-2.356992;4.901037;IRRE
no positional arguments;-5.3048797;2.810333;1.014887;-0.9643628;-0.034428995;-1.8244703;-
no unknown arguments;-4.758853;1.0383273;-1.0159569;0.020176914;-0.53098756;-4.029547;-
no unknown arguments;-4.758853;1.0383273;-1.0159569;0.020176914;-0.53098756;-4.029547;-
data is just 6 separable points in the plane;4.791709;1.1315446;1.2070895;-5.946532;-0.47807142;-0.07349895;CODE
degenerate data with only one feature still should be separable;4.1998196;1.5300848;-2.2738087;-1.0918776;3.8639162;3.8374104;TASK
data is just 9 separable points in the plane;5.2813034;1.3818815;1.3689452;-6.161143;-0.34815374;-0.28277516;CODE
degenerate data with 1 feature still should be separable;4.3149877;1.7258644;-2.5466678;-1.3945476;3.9228432;3.62823;TASK
data that has zero variance in one dimension and needs regularization;6.079134;0.019940758;-1.9737008;-2.394073;-0.91752434;5.430543;TASK
one element class;-1.6792533;0.45543042;2.5570264;-0.97487164;5.0568714;-1.5956436;IRRE
test lda classification;3.728327;-0.98784643;-2.9717543;1.9002589;4.7884297;-3.2999227;IRRE
this checks that lda implements fit and predict and returns correct;2.4791877;0.7055199;-4.329574;3.2179406;1.9224075;-0.89985144;CODE
values for simple toy data;5.4465265;1.6636306;3.5745757;-4.0858884;1.7344024;-5.43529;IRRE
assert that it works with 1d data;3.900112;6.426406;-3.8853538;0.23509428;0.18241319;-1.1957392;CODE
test probability estimates;3.2649324;2.738684;0.6780853;6.38209;-0.14565437;-3.0777302;IRRE
primarily test for commit 2f34950 reuse of priors;-2.0287275;1.1177269;-2.9853249;6.4833713;2.0467541;-1.3735881;IRRE
lda shouldn t be able to separate those;-1.5050585;0.23243226;-2.2435725;-0.9156596;5.41908;2.9083376;CODE
test bad solver with covariance estimator;2.2373474;3.744959;-6.044812;3.6053276;-4.945031;0.73234427;IRRE
test bad covariance estimator;0.94486475;4.97062;-5.1903315;4.45021;-5.3337736;-1.0768462;IRRE
check that the empirical means and covariances are close enough to the;4.6761756;2.7672853;-1.5672394;2.940098;-3.2656004;-1.3991992;CODE
one used to generate the data;2.6453524;-4.3278317;3.4123223;-1.3109511;1.9676168;-3.3642726;OUTD
implement the method to compute the probability given in the elements;2.3797646;0.6231654;4.1022844;-0.477449;2.7390954;-3.031052;TASK
of statistical learning cf p 127 sect 4 4 5 logistic regression;2.82705;-4.807034;-2.2143962;1.4269884;1.6455606;-0.6767171;IRRE
or lda;-0.9651476;-2.7028425;-0.57800007;1.0253118;4.5206947;0.5435213;-
check the consistency of the computed probability;0.9391343;4.764693;-0.54119426;4.1407623;-0.28061247;-1.4113749;-
all probabilities should sum to one;1.3687348;0.89459175;2.1548696;0.816418;2.0542989;-2.0546634;-
check that the probability of lda are close to the theoretical;2.391742;2.2335525;-2.73235;2.7872686;1.4579796;0.1549773;IRRE
probabilities;0.60932934;-1.024056;5.80363;0.97315395;2.4179318;-5.866532;-
test priors negative priors;-0.13326864;3.617503;-0.61709106;4.341045;0.36411986;0.64515007;IRRE
test that priors passed as a list are correctly handled run to see if;0.28419006;7.367809;-1.9568266;7.44515;1.500859;-4.30312;IRRE
failure;-3.0488188;2.1328783;3.913504;4.005306;-1.7102624;-4.817565;-
test that priors always sum to 1;1.5781366;6.6577096;-0.052024;4.3321285;2.0382643;-3.940124;IRRE
test if the coefficients of the solvers are approximately the same;3.0448673;4.4733696;-1.8265535;1.5930266;-2.2597158;-1.2195799;IRRE
test lda transform;1.517963;2.2293785;-3.1599724;-0.042867657;0.10769556;-1.3777671;IRRE
test if the sum of the normalized eigen vectors values equals 1;2.5409167;3.3224561;-2.3948958;-1.5218939;-2.3877158;-0.54700893;IRRE
also tests whether the explained variance ratio formed by the;2.693655;1.3905655;-1.0568985;2.5548396;-1.6243001;-1.4466735;CODE
eigen solver is the same as the explained variance ratio formed;0.8758811;-1.428636;-2.2532547;-0.8586917;-3.0206282;4.553538;CODE
by the svd solver;4.330733;-4.1229873;-2.1149776;-3.4036524;-0.101363294;0.96460295;-
arrange four classes with their means in a kite shaped pattern;3.0802085;0.2733942;4.308799;-3.6812606;3.108893;-0.6824279;IRRE
the longer distance should be transformed to the first component and;1.8674572;1.1772348;4.144727;-4.569446;-0.9208966;4.7826962;CODE
the shorter distance to the second component;2.3213582;0.62071663;3.9600525;-3.7159688;0.84192497;2.6353183;-
we construct perfectly symmetric distributions so the lda can estimate;1.676527;-1.3173676;-2.5009792;1.2975391;3.619788;4.068167;CODE
precise means;2.4433155;1.1323841;3.5159633;0.6271974;-0.6593831;-1.0926366;-
fit lda and transform the means;4.138826;1.6407738;-0.19409966;-1.9839557;0.14766109;3.2263923;CODE
the transformed within class covariance should be the identity matrix;0.09654085;-1.2467054;-3.396194;-2.6497118;-0.21611053;4.2474437;CODE
the means of classes 0 and 3 should lie on the first component;2.2882793;2.308753;-1.6797382;-3.814775;3.362898;1.2473863;IRRE
the means of classes 1 and 2 should lie on the second component;3.4276562;1.3943186;-0.27227655;-1.4741656;4.297436;2.4739718;IRRE
test if classification works correctly with differently scaled features;5.159337;2.0572784;-3.0686324;2.0186863;0.23962884;-0.5949228;IRRE
use uniform distribution of features to make sure there is absolutely no;3.6871643;2.166445;-0.058815606;1.048953;1.634627;-0.8785913;TASK
overlap between classes;0.9410391;0.3401956;1.7834886;0.16596651;5.707717;0.09307644;IRRE
should be able to separate the data perfectly;3.5632718;1.1768858;2.5422356;-1.4418824;3.9769232;2.0813115;CODE
test for solver lsqr and eigen;0.6554523;3.4741762;-2.0201147;0.7690038;-1.3199612;-1.3129389;IRRE
store covariance has no effect on lsqr and eigen solvers;0.13235238;0.4606968;-5.378836;0.41681117;-2.4036152;6.570492;IRRE
test the actual attribute;1.2522085;4.999798;-0.1450102;3.8896878;2.0795271;-5.498751;IRRE
test for svd solver the default is to not set the covariances attribute;1.8536136;0.5827489;-7.4999275;1.469086;-2.9547985;2.6630998;CODE
test the actual attribute;1.2522085;4.999798;-0.1450102;3.8896878;2.0795271;-5.498751;IRRE
test that shrunk covariance estimator and shrinkage parameter behave the;2.644778;3.0703833;-3.7754526;3.8746037;-3.95178;2.9089494;IRRE
same;-2.970426;-1.5172942;2.8265855;1.9994456;-2.1783886;-0.47579575;-
when shrinkage auto current implementation uses ledoitwolf estimation;1.5942514;-0.37649167;-2.828998;1.1501609;-1.1596332;5.6821613;TASK
of covariance after standardizing the data this checks that it is indeed;2.3828566;1.8973399;-3.0066674;0.642253;-2.7368135;3.1386232;CODE
the case;-2.6398394;-1.4212574;5.9303617;1.2890185;0.6542482;-1.6974206;CODE
c standardscaler standardize features;0.82718146;-0.8297719;-3.0624473;-1.6019214;-0.61408955;3.7655373;TASK
rescale;0.6620898;-0.12557663;6.080179;-2.3040724;-2.467202;0.949646;-
we create n classes labels by repeating and truncating a;2.2754347;-1.1446658;0.90547925;-2.644308;6.6354265;-1.1251982;IRRE
range n classes until n samples;5.244111;0.8521647;1.2009724;-0.6757933;5.045191;-2.7724361;IRRE
if n components min n classes 1 n features no warning;1.2663314;1.2577348;-3.66731;1.1801702;4.2886815;-0.7760215;TASK
if n components min n classes 1 n features raise error;2.300812;2.1226466;-5.1109824;0.077169344;3.4452024;-0.27708963;CODE
we test one unit higher than max components and then something;3.0075195;3.590326;0.042478614;2.465934;1.8563302;-2.8271275;IRRE
larger than both n features and n classes 1 to ensure the test;4.605093;1.5668607;-3.3286617;2.4841185;3.1535485;-3.7146573;IRRE
works for any value of n component;-2.3148654;3.500312;0.18574572;-2.8336868;2.0648408;0.38583547;IRRE
check value consistency between types;1.4415219;6.805628;-2.6904414;2.9708219;3.4532816;-1.915944;IRRE
qda classification;4.4078794;-4.925574;-0.9399565;-1.1239887;4.1812735;0.40237874;IRRE
this checks that qda implements fit and predict and returns;3.3421044;-1.0655044;-3.4117458;2.7867966;-0.28436235;-0.9284962;CODE
correct values for a simple toy dataset;6.740987;0.6079014;1.2540215;-2.8662357;0.62566096;-4.875294;IRRE
assure that it works with 1d data;2.507644;1.7283723;-0.46653062;-2.6975555;-1.0035751;2.3436513;-
test probas estimates;1.5578177;2.4103813;-2.0329673;3.7882216;-0.8225354;-3.0865;IRRE
qda shouldn t be able to separate those;-1.700858;-0.8199232;-1.8734251;-1.6260587;1.6268264;3.002367;CODE
classes should have at least 2 elements;-0.067862906;0.9644849;0.1993802;-1.0958389;7.210169;-1.9109303;IRRE
test that the correct errors are raised when using inappropriate;-0.43744478;6.17148;-3.4688673;6.1322904;-0.4266807;-5.7811055;IRRE
covariance estimators or shrinkage parameters with qda;3.4039764;-2.3001463;-1.5381106;0.14920655;-1.6183474;6.346723;IRRE
test bad solver with covariance estimator;2.2373474;3.744959;-6.044812;3.6053276;-4.945031;0.73234427;IRRE
test bad covariance estimator;0.94486475;4.97062;-5.1903315;4.45021;-5.3337736;-1.0768462;IRRE
when shrinkage auto current implementation uses ledoitwolf estimation;1.5942514;-0.37649167;-2.828998;1.1501609;-1.1596332;5.6821613;TASK
of covariance after standardizing the data this checks that it is indeed;2.3828566;1.8973399;-3.0066674;0.642253;-2.7368135;3.1386232;CODE
the case;-2.6398394;-1.4212574;5.9303617;1.2890185;0.6542482;-1.6974206;CODE
c standardscaler standardize features;0.82718146;-0.8297719;-3.0624473;-1.6019214;-0.61408955;3.7655373;TASK
rescale;0.6620898;-0.12557663;6.080179;-2.3040724;-2.467202;0.949646;-
test if the coefficients of the solvers are approximately the same;3.0448673;4.4733696;-1.8265535;1.5930266;-2.2597158;-1.2195799;IRRE
we expect the following;-1.2108841;0.352171;5.35884;4.0593686;-0.060634583;-1.5998696;-
altering priors without fit should not change priors;1.3703103;2.9549434;-1.1145265;3.7375777;0.42288604;5.710588;-
the default is to not set the covariances attribute;-1.4219556;1.0511332;-4.009183;1.167317;-2.8165925;6.1732683;CODE
test the actual attribute;1.2522085;4.999798;-0.1450102;3.8896878;2.0795271;-5.498751;IRRE
the default is reg param 0 and will cause issues when there is a;-6.5190344;4.003152;-3.2989378;1.2808069;-0.9519661;2.515576;CODE
constant variable;-2.1419253;2.8542078;3.6906629;-1.3780738;-0.45658383;-1.8224205;CODE
fitting on data with constant variable without regularization;6.809683;1.7437365;0.12312888;-1.8199886;-1.5721977;5.232071;CODE
triggers a linalgerror;-4.5738716;-0.69949096;-1.3871586;2.872139;-1.1901327;2.210156;-
adding a little regularization fixes the fit time error;3.5824795;0.9675429;-4.610962;0.39215314;-3.658322;5.2481875;TASK
linalgerror should also be there for the n samples in a class;3.1627588;-1.5689683;-2.83627;-1.529076;2.5641086;-1.3796772;CODE
n features case;1.6666079;-2.33633;1.5208966;-1.9861602;6.6024704;-2.1337569;TASK
the error will persist even with regularization for svd;0.3877545;0.83776265;-6.975585;-0.42077088;-2.6508963;5.065481;CODE
because the number of singular values is limited by n samples in a class;5.5923204;1.4520401;-4.475318;-1.5589585;1.6171321;-0.31455296;IRRE
the warning will be gone for eigen with regularization because;0.7622228;0.18314426;-6.9456015;1.6920664;-2.6913571;5.6023917;CODE
the covariance matrix will be full rank;1.5821179;-0.20018096;-1.956474;-2.0268233;-2.0562627;4.447067;CODE
make features correlated;4.6876526;-1.0718488;1.1782899;-0.95802546;2.6922066;2.872453;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
make it possible to discover experimental estimators when calling all estimators;3.0270011;-1.0634358;-0.9201475;6.2451954;-1.9835361;1.7491254;IRRE
enable halving search cv noqa f401;-0.52849144;2.3556967;-3.3079474;0.049634967;-0.82690346;1.2772957;-
enable iterative imputer noqa f401;-2.1103415;-0.32210362;-1.8927861;-0.113631755;-0.6608635;1.4015111;-
walk packages ignores deprecationwarnings now we need to ignore;-3.3421068;0.45360908;-3.9872186;4.334657;-2.268391;2.1863012;TASK
futurewarnings;-1.8459764;-3.5570428;3.1376379;5.128891;-1.1474519;-1.294715;TASK
mypy error module has no attribute path;-4.2499647;0.65475404;-4.31234;-1.0926439;-4.7564697;-0.680663;META
functions to ignore args docstring of;-3.392565;2.492592;-1.3854816;3.1497984;-0.09494062;-0.26782617;CODE
methods where y param should be ignored if y none by default;-0.5564323;4.816793;-1.0292188;3.4312131;-1.1208221;3.2877097;CODE
test module docstring formatting;-4.7640333;1.8895576;-2.506972;1.8463856;0.71777964;-3.6836395;CODE
skip test if numpydoc is not found;0.5637892;4.8395824;-4.730692;0.9284896;-4.6030087;-4.1808844;IRRE
xxx unreached code as of v0 22;-7.177685;2.1495874;-3.896303;-0.051122066;-1.9903537;-0.8256172;-
pytest tooling not part of the scikit learn api;-2.5889704;-8.371965;-5.0668526;1.5518329;-5.3555994;-0.89392734;IRRE
we cannot always control these docstrings;-5.9674845;-1.1431868;-0.0028229419;3.2151127;1.1090698;0.34792495;CODE
exclude non scikit learn classes;0.9699359;-6.6578;-6.130934;2.5913913;0.053348023;-1.7951311;IRRE
skip checks on deprecated classes;-2.0676758;2.1393263;-4.076486;5.842953;1.5649445;-0.44005913;IRRE
now skip docstring test for y when y is none;-1.3374866;5.886431;-2.3707814;3.6174269;-1.147201;-5.215884;CODE
by default for api reason;-6.565671;-1.17083;0.1060554;5.541861;-0.4449912;2.369235;CODE
param ignore y ignore y for fit and score;2.5510242;5.3391385;-0.3324721;1.7307999;-1.3270892;0.08379944;CODE
exclude imported functions;-0.20118782;1.847079;-0.8648047;1.759006;-0.6278701;0.94817024;CODE
don t test private methods functions;-1.3556963;4.929975;-1.9055129;5.69424;-1.677786;-3.2329016;CODE
minimal degenerate instances only useful to test the docstrings;-0.8423989;0.9809523;-3.734457;5.0178714;4.4197583;-0.3497099;CODE
xxx hard coded assumption that n features 3;0.4746125;0.61119646;-3.9968092;-1.7060751;4.6836796;-1.3406082;TASK
todo 1 10 remove copy warning filter;-3.8294814;3.3889735;-2.7480166;2.7861457;-1.7294077;1.2189375;TASK
todo devtools use tested estimators instead of all estimators in the;-0.0044808406;0.56760496;-4.0038414;5.627601;-4.068148;2.1201956;CODE
decorator;-4.1423903;-2.9015825;4.0902023;1.6526208;0.4813935;0.19458982;CODE
default 2 is invalid for single target;-4.178808;2.52545;-3.247731;0.95786065;-0.7772901;1.8836666;CODE
default auto raises an error with the shape of x;-2.9687717;2.959911;-2.8541906;-1.3691525;-3.7591937;2.0553963;CODE
default raises an error perplexity must be less than n samples;2.3027205;4.6148863;-6.8928804;0.96875924;-1.4196112;0.2680389;CODE
todo 1 9 remove;-3.8011727;2.5783017;2.8172538;-0.61260426;0.7241015;-2.6205137;TASK
default raises a futurewarning if quantile method is at default warn;-0.59021556;2.7742932;-2.8815353;5.3750796;-3.6910732;2.5428262;CODE
todo 1 10 remove;-4.2360096;2.7419758;3.1437685;-0.0066302237;-0.0970523;-1.9662911;TASK
default raises a futurewarning;-2.9269295;-0.92871314;0.16329458;4.892744;-2.4450474;3.1259117;CODE
low max iter to speed up tests we are only interested in checking the existence;2.5035813;3.4134824;-2.2445781;5.9114633;0.23417476;-3.296024;IRRE
of fitted attributes this should be invariant to whether it has converged or not;4.4489937;3.4018846;-2.1799934;2.1814628;0.353689;4.15915;CODE
min value for tsne is 250;0.8521538;3.534611;-1.1447294;-2.2183104;-0.13986479;-1.2608219;IRRE
in case we want to deprecate some attributes in the future;-1.5759535;0.09193245;0.5182567;3.5157623;4.5002413;2.3110244;CODE
vectorizer require some specific input data;4.921199;0.19126417;-3.5940492;-2.1957452;0.800799;2.847622;CODE
as certain attributes are present only if a certain parameter is;-0.07672781;5.3220334;-1.2018738;1.9430522;4.554046;0.9391595;IRRE
provided this checks if the word only is present in the attribute;-1.5755252;4.3114076;-0.26966864;2.2032194;5.283169;-3.0506582;CODE
description and if not the attribute is required to be present;-2.9557817;-0.50337225;0.39309764;1.9270707;5.9010177;1.0751784;META
ignore deprecation warnings;-2.3616483;2.5779297;-3.982414;6.0955315;-1.9875536;0.84758323;-
attributes;0.2576558;-3.22067;3.3483093;0.8768757;4.9077525;-1.3673276;META
properties;-1.6438527;-0.56832975;4.6443586;1.6928638;3.3379152;-1.85997;-
ignore properties that raises an attributeerror and deprecated;-1.7363437;3.1113904;-5.316409;5.9588404;-1.4126749;1.9507277;IRRE
properties;-1.6438527;-0.56832975;4.6443586;1.6928638;3.3379152;-1.85997;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
r s w optionally match additional sentence;-0.85996675;1.7542902;0.010310882;0.50204927;3.6960642;-0.8552639;TASK
make it possible to discover experimental estimators when calling all estimators;3.0270011;-1.0634358;-0.9201475;6.2451954;-1.9835361;1.7491254;IRRE
enable halving search cv noqa f401;-0.5284911;2.3556976;-3.3079474;0.049635503;-0.8269041;1.2772952;-
enable iterative imputer noqa f401;-2.1103415;-0.32210302;-1.8927876;-0.11363155;-0.6608632;1.4015113;-
skip private classes;-2.3560216;-0.0199913;-1.0829558;2.874672;2.6828644;0.7815054;CODE
exclude functions from utils fixex since they come from external packages;-4.1343265;-0.064363144;-3.4467928;3.2133667;-0.38552445;2.319161;CODE
we ignore following error code;-4.8865867;6.2314296;-4.614009;1.1180586;-2.1708207;-1.9607117;-
rt02 the first line of the returns section;-4.102094;0.65798193;-0.8665182;-0.3741623;-0.17633669;-2.2088208;IRRE
should contain only the type;-3.3132036;1.4291208;-3.090471;1.1819248;3.8159258;-0.7849298;-
as we may need refer to the name of the returned;-4.1994295;0.8303017;3.3468072;3.6929612;2.256367;-0.6560046;IRRE
object;-1.8805845;-0.88943505;7.8202753;0.21439439;2.50908;-3.2306476;IRRE
gl01 docstring text summary should start in the line;-5.447298;1.3531208;-0.7862679;-0.5491824;-0.90543056;0.5553915;CODE
immediately after the opening quotes not in the same line;-4.8976216;2.9087908;0.2939807;0.81946844;-1.3448606;-1.834298;CODE
or leaving a blank line in between;-2.9903708;3.2175863;3.4639728;-0.05102205;0.004719292;-0.83625466;-
gl02 if there s a blank line it should be before the;-5.2614174;3.5210533;-0.48677027;-2.467067;-1.6734637;-0.27596354;CODE
first line of the returns section not after it allows to have;-5.543376;4.4610424;-1.1695814;1.744613;0.00794283;-1.0124362;IRRE
short docstrings for properties;-2.5600812;-1.3875701;0.34093004;1.3169593;5.620638;-0.370567;CODE
ignore pr02 unknown parameters for properties we sometimes use;-0.87348145;2.902237;-4.643504;2.3654609;1.401881;2.0111253;CODE
properties for ducktyping i e sgdclassifier predict proba;3.9715388;-3.0867622;-2.346207;3.6017153;2.114271;0.3325617;CODE
ignore gl08 parsing of the method signature failed possibly because this is;-4.1907206;3.3054855;-6.6371603;2.6198163;-1.9441397;1.0969387;IRRE
a property properties are sometimes used for deprecated attributes and the;-3.1376224;-1.6315606;-0.86672986;3.5257435;3.4063346;2.1547174;OUTD
attribute is already documented in the class docstring;-5.441822;-2.2918732;-3.6479402;2.6512954;2.8528993;1.5483553;CODE
all error codes;-4.899295;0.11487319;-2.0215685;0.07847257;-1.2749063;-3.7651699;-
https numpydoc readthedocs io en latest validation html built in validation checks;-3.585241;-0.16203314;-4.4812207;0.003061119;-3.981233;-1.4652301;CODE
following codes are only taken into account for the;-3.1256924;1.5466179;-2.1000996;-2.055097;2.2718766;-2.435067;CODE
top level class docstrings;-2.5023754;-4.8182125;-0.0788826;1.7426294;5.4785604;-1.471223;CODE
es01 no extended summary found;-4.7443204;-1.5946784;-1.7991388;1.7556666;-1.9491167;0.4417559;CODE
sa01 see also section not found;-6.494638;-1.6092179;-1.4492577;-1.3151405;-0.7771754;1.1064919;-
ex01 no examples section found;-6.8181977;-1.8617547;-2.8556845;-1.4806579;-0.1103948;-1.4759173;-
in particular we can t parse the signature of properties;-2.425416;0.7061766;-2.5884454;1.3853726;3.655051;0.5334036;IRRE
errors;-4.4719553;1.5922806;1.1482804;0.5820376;-1.8410668;-5.0572658;-
we know that we can have division by zero;-0.84616137;1.8301846;1.4887689;-2.1117697;-0.2547248;-2.722948;-
we know that we can have division by zero;-0.84616137;1.8301846;1.4887689;-2.1117697;-0.2547248;-2.722948;-
1d case;-1.1592708;0.75447017;3.8101046;-3.3361669;2.0327673;-1.0426539;CODE
x np array 0 0 0 0 ignored;0.07886016;4.035532;-4.76587;-6.568371;-4.4862795;-1.3813955;-
2d case;-0.046078924;0.09984208;6.1303396;-4.5545607;2.2606792;-1.3400552;CODE
2d case only;-1.3055258;0.17866462;5.342817;-4.3132167;2.150329;-0.040225416;CODE
x np array 0 0 0 0 ignored;0.07886016;4.035532;-4.76587;-6.568371;-4.4862795;-1.3813955;-
x 0 0 0 0 ignored;-2.2862108;4.5183334;-1.5517048;-4.6766458;-2.9343073;-0.99642444;-
non regression test added in;0.21632963;3.5547848;-2.4938402;5.039451;-2.2760599;-4.2859197;TASK
https github com scikit learn scikit learn pull 13545;-3.2784855;-10.38238;-3.0556192;-0.5587595;-4.338501;-5.197542;CODE
x 0 0 0 0 ignored;-2.2862108;4.5183334;-1.5517048;-4.6766458;-2.9343073;-0.99642444;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
x 0 4 ignored;-3.3219938;4.900121;-0.57106715;-3.5192485;-2.3947458;-0.7822672;-
x 0 4 ignored;-3.3219917;4.900122;-0.5710656;-3.5192509;-2.3947482;-0.7822685;-
x 0 4 ignored;-3.3219917;4.900122;-0.5710656;-3.5192509;-2.3947482;-0.7822685;-
correctness oracle;-0.85575616;2.6582634;-1.40648;1.1225747;4.028347;-4.8845196;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
correctness oracle;-0.85575616;2.6582634;-1.40648;1.1225747;4.028347;-4.8845196;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
correctness oracle;-0.85575616;2.6582634;-1.40648;1.1225747;4.028347;-4.8845196;-
correctness oracle;-0.85575616;2.6582634;-1.40648;1.1225747;4.028347;-4.8845196;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
y 0 5 ignored;-2.2350225;3.3646858;0.19806564;-2.658339;-4.98288;-2.1583002;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
non regression test for 22478;1.2214153;3.908045;-3.640672;1.925074;-2.4820764;-5.7862477;IRRE
test with 2d array;3.8301432;6.2279534;1.2091824;-2.5162487;-2.1068594;-6.627066;IRRE
correctness oracle;-0.85575616;2.6582634;-1.40648;1.1225747;4.028347;-4.8845196;-
when strategy mean;-0.62942237;0.02941049;5.1935186;4.189228;0.62707514;0.08352758;-
x 0 0 0 0 ignored;-2.2862117;4.518335;-1.5517054;-4.6766443;-2.9343066;-0.9964239;-
x 0 0 0 0 ignored;-2.2862117;4.518335;-1.5517054;-4.6766443;-2.9343066;-0.9964239;-
x 0 0 0 0 ignored;-2.2862117;4.518335;-1.5517054;-4.6766443;-2.9343066;-0.9964239;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
x 0 5 ignored;-2.959051;4.4840207;-0.3450397;-3.6298919;-3.051542;-1.1321429;-
x 0 3 ignored;-3.8906953;4.5131707;-0.79915017;-4.893973;-1.8595147;-1.277562;-
there should be two elements when return std is true;-2.1608794;6.771549;-1.3081793;-1.8773941;0.5299881;-5.449455;CODE
the second element should be all zeros;-1.4966515;5.0358424;0.5202096;-7.2412195;-1.1681072;-3.9250255;-
basic unittests to test functioning of module s top level;0.045065578;3.6510937;-2.27335;3.7929747;0.5487068;-3.8591707;IRRE
from sklearn import noqa f403;-1.9154711;-4.5471997;-4.0357137;-3.8373508;-2.9635026;-2.9763846;CODE
test either above import has failed for some reason;-2.674299;3.6586022;-5.683676;2.7081296;-3.961066;-5.8266206;CODE
import is discouraged outside of the module level hence we;-5.248591;-2.5452197;-4.602858;0.4511109;-0.7598774;1.8233706;CODE
rely on setting up the variable above;-1.9631093;4.5643873;1.7674564;0.040896613;-0.4581847;-1.5400097;IRRE
check that fit is permutation invariant;3.0632708;4.106162;-1.7590506;-0.67642194;1.1460412;-0.26938874;CODE
regression test of missing sorting of sample weights;4.404497;4.198156;-1.758611;3.2459147;-1.8504555;-1.6422843;IRRE
check that we got increasing true and no warnings;-1.7388963;2.9548953;-1.8903753;5.483972;-3.1496646;-3.5995595;-
check that we got increasing true and no warnings;-1.7388963;2.9548953;-1.8903753;5.483972;-3.1496646;-3.5995595;-
check that we got increasing false and no warnings;-2.1312325;3.3070726;-2.6515925;5.585134;-3.336548;-3.9426012;-
check that we got increasing false and no warnings;-2.1312325;3.3070726;-2.6515925;5.585134;-3.336548;-3.9426012;-
check that we got increasing false and ci interval warning;-0.7083296;5.5704446;-1.72873;2.394895;-2.2680335;-4.3180118;CODE
check that it is immune to permutation;-1.1009564;5.5682826;-0.96658546;1.641284;3.6378791;-4.847321;-
check we don t crash when all x are equal;0.6869161;5.9006248;0.3873307;1.1718655;0.21660502;-5.2173066;CODE
setup examples with ties on minimum;2.516022;0.55990714;2.84725;-2.7176015;4.2217455;0.21425833;IRRE
check that we get identical results for fit transform and fit transform;5.441782;3.4684546;-0.9400069;-0.5580488;-2.005758;0.7763948;CODE
setup examples with ties on maximum;2.86401;0.81954163;3.535281;-2.8109097;4.299263;-0.30512363;IRRE
check that we get identical results for fit transform and fit transform;5.441782;3.4684546;-0.9400069;-0.5580488;-2.005758;0.7763948;CODE
check fit transform and fit transform;3.880437;3.284137;0.0016565261;-2.0188658;-2.3612535;1.058406;CODE
set y and x for decreasing;0.5894323;2.9662416;4.6508985;-3.3037333;-1.4683608;-2.6152596;IRRE
create model and fit transform;4.25169;-0.2928079;2.1478407;-3.01932;-0.46777308;2.862523;IRRE
check that relationship decreases;0.859977;5.2300353;2.5046344;1.5634536;-1.9109823;-2.7041192;-
set y and x for decreasing;0.5894323;2.9662416;4.6508985;-3.3037333;-1.4683608;-2.6152596;IRRE
create model and fit transform;4.25169;-0.2928079;2.1478407;-3.01932;-0.46777308;2.862523;IRRE
check that relationship increases;1.0016392;3.6289322;3.6052268;2.1463556;-0.29036835;-3.3804355;-
check if default value of sample weight parameter is one;3.3589003;5.624741;-2.763594;2.1231391;0.9915926;1.6915745;IRRE
random test data;5.5165462;2.1977525;1.5097109;3.146329;1.8280189;-6.208589;IRRE
check if value is correctly used;0.43565094;8.7046795;0.37231046;2.1379051;0.5386232;-7.3242364;IRRE
check if min value is used correctly;2.8370297;7.3599753;0.32021713;0.094091915;0.102185585;-4.8760242;IRRE
set y and x;-2.1981866;1.6269119;5.3923073;-4.3736086;-0.3952091;-2.401824;IRRE
create model and fit;3.5878386;-0.61307234;3.1065755;-0.8001638;2.3281994;0.98462427;IRRE
check that an exception is thrown;-2.082413;5.4867945;-0.4191746;5.8075595;-0.6898772;-3.8618183;CODE
set y and x;-2.1981866;1.6269119;5.3923073;-4.3736086;-0.3952091;-2.401824;IRRE
create model and fit;3.5878386;-0.61307234;3.1065755;-0.8001638;2.3281994;0.98462427;IRRE
predict from training and test x and check that min max match;5.458333;2.6915743;0.6638675;1.8784376;1.1975081;-3.1914227;IRRE
set y and x;-2.1981854;1.6269116;5.3923063;-4.373609;-0.39520928;-2.4018228;IRRE
create model and fit;3.5878386;-0.61307234;3.1065755;-0.8001638;2.3281994;0.98462427;IRRE
predict from training and test x and check that we have two nans;5.0325165;3.1076918;-1.0896522;1.0024437;-0.45493606;-4.124019;IRRE
create model and fit;3.5878386;-0.61307234;3.1065755;-0.8001638;2.3281994;0.98462427;IRRE
test from nellev s issue;0.38504303;5.908342;-2.922169;-0.29955322;-2.046665;-4.8430886;IRRE
https github com scikit learn scikit learn issues 6921;-3.446744;-9.319892;-5.782509;-0.662011;-5.179927;-5.238816;CODE
also test decreasing case since the logic there is different;0.7658258;7.8060384;-1.4870936;3.0489492;0.33891952;-5.6322846;CODE
finally test with only one bound;0.9330704;7.2735305;0.2601471;5.4507265;-0.26181158;-5.6886334;CODE
test from ogrisel s issue;-2.198879;3.6634996;-4.07459;2.3614159;-1.8004206;-4.766163;IRRE
https github com scikit learn scikit learn issues 4297;-3.0661693;-9.737228;-6.032673;-0.24073234;-4.8330607;-5.1907773;CODE
get deterministic rng with seed;1.924008;0.28310975;-1.0380124;1.3846345;0.64290494;-1.07;-
create regression and samples;5.122179;-0.2555942;3.623257;0.51402026;0.67447305;-2.3761027;IRRE
get some random weights and zero out;5.043828;1.1330031;1.0977836;-0.09083691;-0.032038357;-0.6715877;IRRE
this will hang in failure case;-4.1871223;2.563946;1.9753662;4.014965;0.7826137;0.28382677;CODE
test that the faster prediction change doesn t;5.0703716;2.279367;-0.46346414;8.800122;-2.0507421;-2.8799686;IRRE
affect out of sample predictions;4.756735;-0.48157206;1.8497962;6.5222306;-0.36851132;0.41645432;-
https github com scikit learn scikit learn pull 6206;-3.1903613;-9.641478;-3.8632245;-0.8204447;-4.4632063;-3.6705666;CODE
x values over the 10 10 range;2.8114777;3.4578023;2.8929307;-5.429395;-0.6582175;-2.846902;IRRE
we also want to test that everything still works when some weights are 0;0.940331;3.381013;-1.0285879;5.5679917;-2.4871604;-1.7982963;TASK
build interpolation function with all input data not just the;5.3641353;1.7910209;2.0824635;-3.4637008;-1.7280573;0.76419646;CODE
non redundant subset the following 2 lines are taken from the;0.41384378;3.3092604;1.7377577;-3.0761886;3.5857415;-0.9190122;IRRE
fit method without removing unnecessary points;6.563759;2.7477996;1.5211779;-1.5201427;-0.9372015;3.6490483;IRRE
fit with just the necessary data;6.8949423;0.8812483;3.4384983;-0.9802779;1.71836;-0.5696242;-
https github com scikit learn scikit learn issues 6628;-3.3284266;-9.359358;-5.381114;-0.901926;-4.9926896;-5.544495;CODE
regression test for 15004;1.5842863;2.7582984;-0.04495532;3.2185607;-3.4848852;-5.78013;IRRE
check that data are converted when x and y dtype differ;4.0528383;3.5266712;-3.767083;-2.3562322;-2.4068372;-3.8820047;-
check that equality takes account of np finfo tolerance;0.5630364;3.9056637;-5.430682;-0.5233962;-1.6123457;0.29053587;-
check that averaging of targets for duplicate x is done correctly;5.1267104;4.0800433;0.4205029;1.8391771;-0.8206944;-0.06157489;CODE
taking into account tolerance;0.33259994;2.6613114;1.6890942;4.7596393;-0.6915774;0.20398985;CODE
non regression test to ensure that inf values are not returned;2.5761743;7.278795;-3.6906178;4.563951;-3.1531172;-3.5279253;IRRE
see https github com scikit learn scikit learn issues 10903;-2.2047088;-10.987541;-7.4891376;-0.78707665;-4.6970654;-4.2597117;CODE
input thresholds are a strict subset of the training set unless;3.5311782;0.38642088;-3.2326138;2.2916536;1.366307;1.8371398;IRRE
the data is already strictly monotonic which is not the case with;4.4598484;3.9239337;-0.84409505;-1.1809366;-0.9494805;0.97047174;CODE
this random data;4.4905925;-0.4496459;4.8980026;-1.6329545;1.2349691;-4.753718;IRRE
output thresholds lie in the range of the training set;4.836326;-0.46017528;-1.6484985;1.1760716;-0.92803895;1.8384541;IRRE
test from 15012;0.37339824;2.705145;-0.701353;2.4399662;-1.960747;-8.926662;IRRE
check that isotonicregression can handle 2darray with only 1 feature;3.8693469;3.1451857;-3.5294225;-2.588057;-0.51741254;2.7591286;TASK
ensure isotonicregression raises error if input has more than 1 feature;3.1446955;4.0981135;-4.905356;1.7032846;-0.40420762;1.0272374;CODE
generate data;3.5066159;-0.7332337;4.43081;-2.3223333;2.8341296;-3.9849672;-
make sure x and y are not writable to avoid introducing dependencies between;-4.5121326;2.0458035;-2.9703054;0.15523832;1.3615208;-0.61509025;CODE
tests;0.88049054;1.2949181;4.1925097;6.4629726;0.08019503;-9.306;IRRE
test that polynomialcountsketch approximates polynomial;2.7080295;2.874539;-2.7771604;1.9987527;-1.5199713;-0.82080954;IRRE
kernel on random data;5.0886908;-2.9811208;0.076259725;-0.34526798;1.7547925;2.0191667;IRRE
compute exact kernel;1.891968;-1.3915546;-1.2455846;-3.5131464;0.19218226;0.22729057;-
approximate kernel mapping;6.5994453;-2.3615115;1.0909333;-2.490634;-0.39484605;4.2245603;-
assert np abs np mean error 0 05 close to unbiased;3.4115727;3.6045258;-6.974353;0.9656756;-4.2485795;-2.8478262;CODE
assert np max error 0 1 nothing too far off;1.7902566;5.487604;-7.582182;1.37359;-3.7965283;-3.8137317;CODE
assert np mean error 0 05 mean is fairly close;3.62506;4.125359;-6.778797;1.5969152;-4.786478;-3.8904526;CODE
test that additivechi2sampler approximates kernel on random data;6.149891;0.16548501;-4.024033;2.947916;0.005054836;0.95798165;IRRE
compute exact kernel;1.891968;-1.3915546;-1.2455846;-3.5131464;0.19218226;0.22729057;-
abbreviations for easier formula;0.30707574;-0.4140581;2.0455623;-1.427375;4.087639;-3.5213315;CODE
reduce to n samples x x n samples y by summing over features;5.759233;-0.63644105;0.17199677;-2.0832567;0.5962026;0.78345656;TASK
approximate kernel mapping;6.5994453;-2.3615115;1.0909333;-2.490634;-0.39484605;4.2245603;-
test error is raised on negative input;-0.7959701;7.4077973;-4.0249634;2.3774428;-4.132516;-6.6075387;CODE
test that rbfsampler approximates kernel on random data;5.6116786;0.4781591;-3.8959658;2.8728778;-1.3383152;-0.35035738;IRRE
compute exact kernel;1.891968;-1.3915546;-1.2455846;-3.5131464;0.19218226;0.22729057;-
approximate kernel mapping;6.5994453;-2.3615115;1.0909333;-2.490634;-0.39484605;4.2245603;-
assert np abs np mean error 0 01 close to unbiased;3.0740538;3.909481;-7.0175776;0.6123666;-3.9871304;-2.638197;CODE
assert np max error 0 1 nothing too far off;1.7902566;5.487604;-7.582182;1.37359;-3.7965283;-3.8137317;CODE
assert np mean error 0 05 mean is fairly close;3.62506;4.125359;-6.778797;1.5969152;-4.786478;-3.8904526;CODE
x list x test input validation;2.0012507;5.0977936;-0.4077425;1.1189225;1.8075666;-6.160195;IRRE
if degree gamma or coef0 is passed we raise a valueerror;0.8323583;2.9261436;-6.281067;1.7128121;-2.1540866;-1.9889203;IRRE
non regression test nystroem on precomputed kernel;3.0540893;1.3461485;-5.3257856;2.3089266;-2.1331038;0.22935297;IRRE
pr 14706;-3.9152472;-1.3913093;0.4557223;-0.33940566;0.64513034;-5.815083;-
if degree gamma or coef0 is passed we raise a valueerror;0.8323583;2.9261436;-6.281067;1.7128121;-2.1540866;-1.9889203;IRRE
alpha 0 causes a linalgerror in computing the dual coefficients;-0.50395;-0.20594993;-5.6704445;-2.6687691;-2.103886;2.5389183;-
which causes a fallback to a lstsq solver this is tested here;-1.3451136;2.629923;-4.634365;1.9958376;-1.7477437;1.7770635;IRRE
k np dot x x t precomputed kernel;2.0907228;-3.8884814;-3.5494363;-4.055755;-1.4136409;3.3629298;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this should still work since none is the default value;-4.7732973;6.0819087;-1.5952946;-0.19289845;-0.020399291;2.7521079;CODE
now requests is no more empty;-5.764958;2.1301315;2.4361413;2.8255835;-2.4419458;0.7963415;CODE
but one can exclude a method;-2.8733606;2.3552208;0.044490106;6.0196557;1.8415426;0.06717673;META
excluding fit is not enough;2.473529;4.5416374;-1.3136644;1.5077348;-0.4481782;1.0689154;TASK
and excluding both fit and score would avoid an exception;2.608261;4.6714396;-2.7444062;5.120215;3.2934306;0.032319263;CODE
test if a router is empty;-1.0417827;5.409881;0.28193712;2.6990829;-0.81956226;-2.1703122;IRRE
fit in this class or a parent requests prop but we don t want;-4.0806246;1.0627961;2.2996066;4.312577;4.0880017;2.4513106;CODE
it requested at all;-5.6503563;-2.9823484;2.3995817;1.278297;-0.769161;1.0035352;CODE
return self pragma no cover;-4.4821234;3.228721;0.15677875;3.0714993;-1.2876406;1.3863777;CODE
having it here instead of parametrizing the test since set fit request;1.750412;5.4974613;-2.1255999;5.4441686;-1.3156259;0.7544274;IRRE
is not available while collecting the tests;-2.6639388;0.9539977;-1.4779674;5.1067004;-1.9541042;-5.0147223;IRRE
adding a metadatarequest as self adds a copy;-4.5744267;0.37376496;-1.7991308;3.015459;-0.44151232;4.011184;TASK
should be a copy not the same object;-4.0725985;2.3167603;-1.2318974;1.4085387;-0.40296924;0.07341404;IRRE
one can add an estimator as self;0.9869905;-0.38652053;0.57593834;3.9405856;-0.39608365;4.6277394;TASK
adding a consumer router as self should only add the consumer part;-2.9753869;1.2989554;-0.4840716;1.7294184;2.4286222;5.366904;TASK
get metadata request returns the consumer part of the requests;-2.9715784;0.5774166;-0.17875119;3.1641011;0.39571032;3.2977118;CODE
get metadata routing returns the complete request set consumer and;-2.4332502;0.21565323;-0.78756833;2.5221524;0.3760078;4.9079657;IRRE
router included;-3.1418421;-1.9309425;2.8299248;-1.0445147;0.7507418;1.3638421;CODE
it should be a copy not the same object;-5.306682;1.3338356;-1.2598476;1.030705;-0.5879947;0.5743381;IRRE
adding one with a string method mapping;-2.504975;2.3865595;0.7180866;1.1594268;3.6789825;-0.13037027;CODE
adding one with an instance of methodmapping;-1.8894653;0.85400784;1.8387257;3.9710264;2.5115845;3.2373881;TASK
return alias false will return original names for self;-3.684649;3.7456276;-2.1107538;1.7422508;-0.60689396;-0.38524443;CODE
ignoring self would remove sample weight;2.0001037;4.0951886;-1.7985325;4.225551;-0.3748609;2.3204148;CODE
return alias is ignored when ignore self request true;-4.3280315;4.858629;-1.7061136;3.504118;-2.0069392;2.5783358;CODE
test if all required request methods are generated;-0.8886411;5.20429;-1.41951;8.110089;1.6186677;-1.54935;CODE
todo these test classes can be moved to sklearn utils testing once we;0.8827603;-4.1727915;-4.7186804;4.0265927;-0.52512795;-3.2235043;IRRE
have a better idea of what the commonly used classes are;0.36394933;-6.949846;0.6250754;2.4814138;4.921118;-0.34576505;IRRE
this class should have no set method request;-5.40162;2.091455;-0.0788848;2.9475203;-0.55186665;0.39091057;CODE
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
this class should have every set method request;-2.2783124;1.1704232;2.0057316;4.815032;2.648296;1.317786;CODE
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
composite methods shouldn t have a corresponding set method;-0.3766845;2.2208369;-1.3190503;3.6398025;2.0002031;1.605518;IRRE
simple methods should have a corresponding set method;1.8561807;0.7182145;1.5533366;1.8981489;2.6863754;-0.55269563;IRRE
test the behavior and the values of methods composite methods whose;0.6072353;1.6507189;0.1586954;7.5035663;0.58417064;-2.400512;IRRE
request values are a union of requests by other methods simple methods;-0.54193985;1.5703845;0.9361877;2.3582096;3.173552;0.00960695;IRRE
fit transform and fit predict are the only composite methods we have in;5.2754526;-3.6988175;-0.112665005;2.9768355;-0.79412776;3.2610826;CODE
scikit learn;2.6275342;-11.857208;-1.3952904;-0.05143707;-4.145873;-5.693253;-
this class should have every set method request;-2.2783124;1.1704232;2.0057316;4.815032;2.648296;1.317786;CODE
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134483;1.9219068;1.2293149;1.7572418;1.1100707;-0.64726907;-
pass pragma no cover;-2.7134476;1.9219079;1.2293152;1.7572418;1.110071;-0.64726776;-
since no request is set for fit or predict or transform the request for;-1.3893566;1.0331233;-0.957939;5.3883986;-1.7043132;3.290195;CODE
fit transform and fit predict should also be empty;3.0790055;1.8391206;-2.618119;-0.16874754;-3.5209303;1.5348556;CODE
setting the request on only one of them should raise an error;-3.304991;6.0363317;-0.65410095;5.094106;1.1536993;2.4500427;CODE
setting the request on the other one should fail if not the same as the;-5.0716515;5.876719;1.2543042;6.7110577;0.53581184;3.8910518;IRRE
first method;-1.5923364;0.98183835;4.7452517;2.0250232;1.2860945;-2.5796082;-
now the requests are consistent and getting the requests for fit predict;2.70587;-0.9298716;-1.2154658;6.747523;-1.6987445;2.6777592;CODE
shouldn t raise;-2.2815669;1.7890302;2.5472615;1.3238431;-1.6313752;-0.520375;CODE
setting the request for a none overlapping parameter would merge them;-2.8646052;6.111136;0.14360732;1.2589673;3.0908;4.305247;IRRE
together;-1.8154242;-1.9608039;7.379566;-0.27506253;1.2080839;-2.9334545;-
this passes since no metadata is passed;-6.3061;0.81182534;-2.5318549;4.5909114;0.9882433;2.7016623;CODE
this fails since metadata is passed but estimator does not support it;-1.6552937;2.0787387;-4.769264;3.5914745;-2.900548;4.2914653;CODE
test positional arguments error before making the descriptor method unbound;-1.5767365;5.7241483;-3.7764537;1.862562;-1.0440474;0.29664052;CODE
this somehow makes the descriptor method unbound which results in the instance;-1.7649528;2.7213702;-2.675185;3.0751848;0.20061323;3.7773705;CODE
argument being none and instead self being passed as a positional argument;-4.4196134;4.529779;-0.6602028;0.21249424;0.7201111;-0.84862584;CODE
to the descriptor method;2.1991303;-1.8902853;1.5689427;0.19014895;3.731455;1.8139418;CODE
this should pass as usual;-3.8072996;0.057329934;2.9714975;2.3973742;0.9845297;0.12407793;CODE
test positional arguments error after making the descriptor method unbound;-1.931663;5.80105;-3.6987321;1.5454819;-1.3204163;0.047286734;IRRE
searchcv estimators;5.7813377;-2.1838024;-2.3460445;1.6665659;-1.2564273;1.9158853;-
featureunion;0.92018604;-4.2618375;0.13728896;1.5010179;2.4040842;-0.99997795;TASK
stacking voting;-0.0009239931;-1.9673543;5.4585676;0.2696532;2.755627;-1.1141118;-
todo remove data validation for the following estimators;3.5859966;4.58254;-2.6585681;3.4481163;-1.6431079;0.7537906;CODE
they should be able to work on any data and delegate data validation to;0.73036635;-3.2877681;-1.6070228;4.542647;2.4510543;1.9124476;CODE
their inner estimator s;3.5568767;-1.5432475;0.42315367;1.1731961;-0.4518052;4.07986;-
classifierchain data validation is necessary;1.4862012;-0.96956474;-4.3887987;3.9060192;4.659807;-0.55737954;IRRE
frozenestimator this estimator cannot be tested like others;0.37375835;4.208884;-4.0469995;3.9401128;-5.4060616;0.8353667;IRRE
onevsoneclassifier input validation can t be avoided;0.78278923;1.4332241;-4.2028203;3.0587006;1.2380816;0.2782268;CODE
regressorchain data validation is necessary;0.9875039;2.4182909;-4.3055453;2.0846353;1.3460867;1.4567543;-
sequentialfeatureselector not applicable 2d data mandatory;-0.4489839;1.7090672;-2.8441703;-1.1674103;0.87169623;2.620989;TASK
check that meta estimators delegate data validation to the inner;1.7755495;2.734389;-3.6205025;6.2305694;-0.3367451;3.2449589;-
estimator s;0.871338;0.35073262;2.4986386;2.382739;-1.3177478;0.58505094;-
clone to avoid side effects and ensure thread safe test execution;-2.0721867;2.251074;-1.333119;5.9918895;-1.0081885;0.096974954;CODE
we convert to lists to make sure it works on array like;1.2529784;2.5275986;1.3221381;-1.4939123;0.6014631;-4.001003;-
calling fit should not raise any data validation exception since x is a;3.4096568;6.326608;-6.0402765;2.5092514;-0.79428047;0.2410176;CODE
valid input datastructure for the first step of the pipeline passed as;-0.3444405;2.6077013;-2.6251903;1.6939323;3.8400917;1.0549406;CODE
base estimator to the meta estimator;0.31106186;0.49486065;-0.50718415;2.5480585;-0.9439934;4.16984;-
n features in should not be defined since data is not tabular data;1.8986056;1.9684348;-2.955523;-3.5273647;2.2446241;-1.2396878;CODE
enable halving search cv noqa f401;-0.5284911;2.3556976;-3.3079474;0.049635503;-0.8269041;1.2772952;-
enable iterative imputer noqa f401;-2.1103415;-0.32210302;-1.8927876;-0.11363155;-0.6608632;1.4015113;-
ids used by pytest to get meaningful verbose messages when running the tests;-1.1899474;1.7292082;-3.789459;3.1840653;-0.69989085;-3.3993175;IRRE
avoid mutating the original init args dict to keep the test execution;-1.3795304;3.8058612;-3.029557;4.8533254;-2.06166;-0.9955157;IRRE
thread safe;-2.8768477;-0.28741512;4.9131756;3.3267484;-0.9103858;-1.8437922;CODE
raise valueerror unpermitted sub estimator type pragma nocover;1.7854092;4.0180516;-6.015536;1.8683388;-3.0661707;2.0023303;CODE
raise valueerror unpermitted sub estimator type pragma nocover;1.785409;4.0180507;-6.0155354;1.8683378;-3.066172;2.0023303;CODE
not all meta estimators in the list support sample weight;2.2806373;0.43013462;-3.5504534;3.5339956;-1.3273792;2.345481;CODE
and for those we skip this test;0.51708895;1.9349965;-0.7795311;6.4944205;-0.40566105;-5.373923;CODE
test that registry is not copied into a new instance;-2.9377546;3.3456914;-2.4251938;4.178159;-0.78037333;-0.5159181;CODE
check that by default request is empty and the right type;-4.777502;5.23723;-1.7704905;3.7243195;-1.0303289;1.1389049;CODE
our groupcv splitters request groups by default which we should;0.5748617;0.48236403;0.0642289;1.1026056;1.7577095;4.4423733;CODE
ignore in this test;0.5737772;7.6915884;-0.75518805;4.9119954;-1.0427729;-6.482528;CODE
test that a unsetmetadatapassederror is raised when the sub estimator s;1.9193623;4.9307766;-3.0444448;4.493142;-1.5491977;1.1079041;IRRE
requests are not set;-5.187084;2.1067376;2.951634;2.0672655;-3.3866508;0.69530284;IRRE
this test only makes sense for metaestimators which have a;1.6289093;3.6258836;-2.8707807;4.6736965;-0.88665617;-1.4073535;CODE
sub estimator e g mymetaestimator estimator mysubestimator;2.3967535;2.196089;-1.5527838;1.2310747;-0.49311113;4.1443605;-
set request on fit;-0.23333538;2.3492851;2.070009;3.045711;-0.9954709;4.3849044;IRRE
making sure the requests are unset in case they were set as a;-4.224181;3.3069422;0.5658587;5.86056;-0.029478807;2.6730459;IRRE
side effect of setting them for fit for instance if method;3.0333726;3.471184;-0.6490416;5.7411;-0.49325344;1.5696679;CODE
mapping for fit is fit fit score that would mean;3.308871;0.792384;-0.101517476;-0.19235359;1.6658208;-0.26393968;CODE
calling score here would not raise because we have already;-1.2678517;2.6226094;1.1985523;2.455021;-0.32166544;-1.491564;CODE
set request value for child estimator s score;0.8958277;3.360228;0.5351253;2.8566122;0.48405364;2.3315048;IRRE
fit partial fit score accept y others don t;2.8663926;2.2466142;-2.6539013;1.0583314;0.049388457;0.65511155;CODE
when the metadata is explicitly requested on the sub estimator there;-0.010884525;0.44653508;-2.3533869;4.186939;0.52451664;5.870929;CODE
should be no errors;-5.507626;2.5087006;-2.4783776;2.228214;-3.4759886;-2.4517179;-
this test only makes sense for metaestimators which have a;1.6289093;3.6258836;-2.8707807;4.6736965;-0.88665617;-1.4073535;CODE
sub estimator e g mymetaestimator estimator mysubestimator;2.3967535;2.196089;-1.5527838;1.2310747;-0.49311113;4.1443605;-
set method request metadata true on the underlying objects;-2.34431;1.7085263;-1.1759481;6.2986846;1.7759855;5.3383565;IRRE
fit before calling method;2.7282188;5.689885;0.754227;3.2644768;-0.79589474;1.2391678;IRRE
fit and partial fit accept y others don t;0.5216883;1.4858732;-0.79388624;0.11502279;0.39448795;1.8972805;CODE
sanity check that registry is not empty or else the test passes;-4.056395;4.3045077;-4.6289124;4.1424265;-1.0907311;-2.7029889;IRRE
trivially;-1.0290222;-1.5493429;4.164883;1.6313674;-0.6691248;0.30509;IRRE
test that when a non consuming estimator is given the meta estimator;0.9019336;5.6467695;-2.2856019;8.041949;-1.7879965;0.70835614;IRRE
works w o setting any requests;-6.8810406;1.0743388;0.88213277;3.8299608;-2.2898738;1.8748668;IRRE
regression test for https github com scikit learn scikit learn issues 28239;0.742039;-5.0281568;-7.786292;3.5083432;-6.560585;-6.455146;CODE
this test only makes sense for metaestimators which have a;1.6289093;3.6258836;-2.8707807;4.6736965;-0.88665617;-1.4073535;CODE
sub estimator e g mymetaestimator estimator mysubestimator;2.3967535;2.196089;-1.5527838;1.2310747;-0.49311113;4.1443605;-
e g call set fit request on estimator;2.1331902;1.4807361;0.09686928;3.9139013;-1.4618237;5.177227;IRRE
the following should pass w o raising a routing error;-3.6848788;3.4034836;-1.1551126;1.0279201;-0.38384664;0.6438904;-
fit and partial fit accept y others don t;0.5216883;1.4858732;-0.79388624;0.11502279;0.39448795;1.8972805;CODE
this test only makes sense for cv estimators;2.3745286;2.92764;-5.0285673;4.588906;-2.981425;-1.9645263;CODE
this test is only for metaestimators accepting a cv splitter;2.1460383;2.2321696;-5.952345;3.667323;-0.5328261;0.7475541;CODE
this test is only for metaestimators accepting a cv splitter;2.1460383;2.2321696;-5.952345;3.667323;-0.5328261;0.7475541;CODE
remove consumingsplitter from kwargs so cv param isn t passed twice;-1.3763838;3.1809874;-2.8934338;3.6641898;-0.53645754;4.4885087;IRRE
numpy is more complex because build time 1 25 and run time 1 19 5;1.8845687;-2.4431043;-0.7023214;-3.0199873;-5.6209536;-1.839913;META
requirement currently don t match;-2.4046552;3.535733;-2.6419325;1.15628;3.413323;-0.8908373;CODE
test predicting without fitting;7.079108;2.3308198;-0.9840936;6.4476676;-2.3465254;-2.9424238;IRRE
fail on multioutput data;2.4268053;3.6622746;-1.5767437;1.0758269;-1.1934606;-3.3102129;IRRE
test that check classification target return correct type 5782;2.2909644;3.2044382;-5.8479156;4.0190783;1.598158;-5.722387;IRRE
a classifier which implements decision function;4.0209208;-4.1131654;1.2792119;1.9419221;5.3064713;-1.2730309;CODE
a classifier which implements predict proba;5.02053;-5.690615;0.84854513;3.9123282;3.8243883;-1.2845047;TASK
test if partial fit is working as intended;3.4055426;7.278709;-1.4645237;4.564336;-1.593073;-1.3329474;CODE
test when mini batches doesn t have all classes;2.0525975;3.0444806;-2.3958213;4.4732656;1.8501806;-1.9252077;IRRE
with sgdclassifier;3.6680381;-4.5167623;-1.8613397;-0.6009788;4.94391;0.5680096;IRRE
test partial fit only exists if estimator has it;1.4985281;6.544645;-4.5653424;5.033609;-2.8276026;1.246463;IRRE
if a new class that was not in the first call of partial fit is seen;1.5293491;2.8277423;-1.9269475;5.2092896;3.4478831;1.5967879;CODE
it should raise valueerror;-2.4860098;4.1336555;-4.8355684;3.3354206;-4.4290457;-1.8952283;IRRE
test that ovr and ovo work on regressors which don t have a decision;2.4327786;2.695979;-2.353439;3.7712452;-0.49715295;-0.30569088;IRRE
function;-1.2390599;1.4956939;6.532339;-1.7183864;-0.46752357;-4.8876433;CODE
we are doing something sensible;-2.9122956;-2.1981182;4.2535973;3.6142392;-0.70716685;-0.99849844;CODE
we are doing something sensible;-2.9122956;-2.1981182;4.2535973;3.6142392;-0.70716685;-0.99849844;CODE
test predict proba;4.0656295;1.5291378;0.23063722;5.831268;-0.035129484;-6.1489167;IRRE
predict assigns a label if the probability that the;3.2504814;-1.6838934;1.0093255;2.6662967;3.5724537;-1.1249238;IRRE
sample has the label is greater than 0 5;1.3400795;4.2190685;-1.0512216;-1.759415;0.13444588;-4.572692;-
test decision function;2.6341703;4.384603;0.23746186;4.855202;2.0733967;-6.499647;CODE
test that ovr works with classes that are always present or absent;-0.36584207;2.5555189;-3.3144305;5.655087;3.5190504;-2.735046;IRRE
note tests is the case where constantpredictor is utilised;0.35726744;1.2715254;-3.086601;5.3500824;-0.5882955;-1.8298943;CODE
build an indicator matrix where two features are always on;4.0708575;0.847562;2.594683;-3.3384962;2.182817;2.1689224;TASK
as list of lists it would be int i 5 2 3 for i in range 10;0.43616545;1.3274832;2.3569627;-5.2581515;1.9783862;-5.2648325;CODE
y has a constantly absent label;-1.8867291;1.6914532;-0.06562824;0.19487886;-1.204101;-1.4206101;CODE
y 5 0 1 variable label;0.6847042;0.77392966;2.3003237;-6.0484257;-0.19504142;-2.5437593;IRRE
toy dataset where features correspond directly to labels;4.9820223;-4.915149;0.99002606;-1.7110085;4.739508;-0.18476962;TASK
test input as label indicator matrix;5.141683;3.5071416;-0.47372693;-2.8750298;0.7851037;-2.8461905;IRRE
toy dataset where features correspond directly to labels;4.9820223;-4.915149;0.99002606;-1.7110085;4.739508;-0.18476962;TASK
test input as label indicator matrix;5.141683;3.5071416;-0.47372693;-2.8750298;0.7851037;-2.8461905;IRRE
toy dataset where features correspond directly to labels;4.9820223;-4.915149;0.99002606;-1.7110085;4.739508;-0.18476962;TASK
decision function only estimator;1.8884113;1.18424;-0.64882946;2.8782039;-0.13229814;2.7874775;CODE
estimator with predict proba disabled depending on parameters;2.2612002;3.1084464;-2.2766411;4.1618376;-2.3829992;3.813355;TASK
estimator which can get predict proba enabled after fitting;3.6180882;-0.7293938;0.098203294;4.245021;-2.2857015;4.261723;-
predict assigns a label if the probability that the;3.2504814;-1.6838934;1.0093255;2.6662967;3.5724537;-1.1249238;IRRE
sample has the label is greater than 0 5;1.3400795;4.2190685;-1.0512216;-1.759415;0.13444588;-4.572692;-
decision function only estimator;1.8884113;1.18424;-0.64882946;2.8782039;-0.13229814;2.7874775;CODE
predict assigns a label if the probability that the;3.2504814;-1.6838934;1.0093255;2.6662967;3.5724537;-1.1249238;IRRE
sample has the label with the greatest predictive probability;3.8707914;-0.97062796;1.2171627;2.1371782;2.96992;-0.2510042;IRRE
probability of being the positive class is always 0;-0.49454194;1.5489943;-1.4130025;0.014937195;1.8542739;-1.5158926;IRRE
x y iris data iris target three class problem with 150 samples;3.0413344;1.6117456;-3.4320056;-2.7292042;-0.09020691;-2.4238913;IRRE
test with pipeline of length one;2.1458628;5.4179215;-0.29296225;2.9269679;0.40020165;-4.649177;IRRE
this test is needed because the multiclass estimators may fail to detect;2.4943283;2.2702253;-6.148163;5.441447;1.4177027;-1.158477;IRRE
the presence of predict proba or decision function;3.5923774;-1.1464945;0.5737285;4.917379;2.400066;-0.40186203;CODE
test that onevsone fitting works with a list of targets and yields the;4.7228;2.7227957;-2.3391128;2.7465305;-1.6227622;0.33625308;IRRE
same output as predict from an array;5.5619087;1.4298757;1.9139224;0.30601376;-0.780984;-2.6964588;IRRE
a classifier which implements decision function;4.0209208;-4.1131654;1.2792119;1.9419221;5.3064713;-1.2730309;CODE
a classifier which implements predict proba;5.02053;-5.690615;0.848547;3.9123278;3.8243892;-1.2845057;TASK
test when mini batches have binary target classes;1.9317758;2.3575552;-3.709925;3.3959346;2.3826568;-1.2632393;IRRE
raises error when mini batch does not have classes from all classes;-0.08641437;1.8555586;-4.878194;2.9154625;0.43474996;0.5723244;CODE
test partial fit only exists if estimator has it;1.4985281;6.544645;-4.5653424;5.033609;-2.8276026;1.246463;IRRE
first binary;-2.6369488;0.2666635;1.0227889;-4.603004;2.6080008;-5.816855;-
then multi class;-0.79942524;-1.8792796;2.2670724;1.5800182;5.640363;-0.6565268;IRRE
compute the votes;2.1640947;0.054982644;4.3933883;-2.1591725;2.783375;-5.2080483;-
extract votes and verify;1.7345188;1.0578477;1.6194512;1.6211469;3.9207792;-4.5949273;-
for each sample and each class there only 3 possible vote levels;3.0919466;0.07692997;0.9329742;-1.7067468;7.145897;-2.0515246;CODE
because they are only 3 distinct class pairs thus 3 distinct;-0.8962883;0.46999478;-2.1000085;-2.9099438;4.8918686;-1.7960671;IRRE
binary classifiers;4.8689165;-5.248405;-0.7738628;-0.7454744;6.388533;-3.8143353;IRRE
therefore sorting predictions based on votes would yield;4.719118;-1.0588803;2.6374493;3.0532289;3.0310814;-0.3767049;CODE
mostly tied predictions;2.9896579;-2.6654794;4.9805045;3.5096111;0.0045094835;-0.43183428;-
the ovo decision function on the other hand is able to resolve;0.23739082;-0.32794172;-0.23836754;3.0212185;2.0888965;2.2848516;CODE
most of the ties on this data as it combines both the vote counts;3.3197525;-1.0043896;2.9212244;-0.55635923;2.939524;-0.32543117;CODE
and the aggregated confidence levels of the binary classifiers;5.5046597;-4.7858844;-1.489895;2.4306602;5.2910137;-0.7491487;IRRE
to compute the aggregate decision function the iris dataset;5.5700054;-2.4517314;-0.23810951;-1.9270333;2.8623574;-1.4646313;IRRE
has 150 samples with a couple of duplicates the ovo decisions;4.046859;-0.4248224;0.22982533;3.527193;3.755197;-2.3404436;IRRE
can resolve most of the ties;-1.8528912;-0.32911083;4.1623077;2.1238866;1.2959437;0.6072148;-
test that ties are broken using the decision function;2.9846296;4.861434;-0.08061362;4.4546475;1.4526663;-5.178828;IRRE
not defaulting to the smallest label;0.17443347;2.9289472;0.52404743;-0.6122044;1.5870085;2.9526103;CODE
classifiers are in order 0 1 0 2 1 2;3.1407535;-1.8563671;-3.3501723;-3.1705842;4.1104136;-2.5877852;IRRE
use decision function to compute the votes and the normalized;3.8752162;0.6616902;1.7639765;-1.1026056;3.5005548;-0.2376567;CODE
sum of confidences which is used to disambiguate when there is a tie in;2.6556423;1.4194814;3.0554688;2.8458443;3.7105095;-1.9517748;OUTD
votes;-1.2495112;-2.406773;5.750062;-0.079065934;2.4250624;-4.2241244;-
for the first point there is one vote per class;0.9974723;-1.6558135;1.1138893;1.4365072;6.0867925;-1.182492;CODE
for the rest there is no tie and the prediction is the argmax;2.4363866;-0.09385585;2.8248038;1.8823146;-0.35379967;0.051138476;CODE
for the tie the prediction is the class with the highest score;2.283753;-1.4867723;2.9962916;3.467911;2.290572;-2.9843569;CODE
test that ties can not only be won by the first two labels;2.2472732;3.3586388;1.5846161;1.6495849;3.3914886;-4.797541;IRRE
cycle through labels so that each label wins once;1.1607351;0.9641884;4.8594055;-0.42635414;3.7440498;-0.91615504;CODE
test that the ovo doesn t mess up the encoding of string labels;0.7508354;2.0649626;-3.2971885;-0.70898193;-0.16287765;-1.5954424;CODE
test error for ovo with one class;-0.50010455;3.8332765;-4.520062;2.4640975;-0.2221748;-4.0244894;IRRE
test that the ovo errors on float targets;2.4484134;3.8213327;-3.9605374;1.3489702;-4.1093206;-1.0372466;IRRE
a classifier which implements decision function;4.0209208;-4.1131654;1.2792119;1.9419221;5.3064713;-1.2730309;CODE
a classifier which implements predict proba;5.02053;-5.690615;0.848547;3.9123278;3.8243892;-1.2845057;TASK
test that the occ errors on float targets;1.7476227;3.217288;-5.0135603;1.139789;-3.092057;-2.423589;IRRE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 17218;-3.9040854;-9.716917;-6.1739826;-0.811122;-5.134209;-5.3478518;CODE
create an estimator that does not support sparse input;5.5021224;1.6028651;-2.0915549;1.5861512;-1.3719144;5.4034038;IRRE
smoke test to check when sparse input should be supported;4.292951;3.9720173;-2.9456515;4.30324;-0.47261527;-0.14962654;IRRE
remove the last sample to make the classes not exactly balanced and make;3.5582774;3.246847;-0.27991986;0.722742;2.9732091;-2.168387;CODE
the test more interesting;0.6972854;0.705445;2.7843814;5.161679;0.083184846;-6.826493;IRRE
fitting directly on the design matrix;4.157031;-1.5137227;-1.8668379;-2.8750067;0.33359197;5.70013;-
when working with precomputed kernels we have one feature per training;3.0770593;-4.1058617;-1.9605515;2.29357;2.71053;3.4081473;TASK
sample;1.7340889;-0.29218516;6.123778;1.5984565;2.6697383;-5.329025;-
this becomes really interesting with ovo and precomputed kernel together;0.4849082;-5.0180736;-0.65268594;0.5002064;-0.016707685;4.149342;CODE
internally ovo will drop the samples of the classes not part of the pair;2.0070097;1.2610534;-4.0778265;1.8264234;1.8315761;1.8114319;CODE
of classes under consideration for a given binary classifier since we;2.430165;-4.038883;-1.6016315;1.2354137;6.7598515;-1.1483047;CODE
use a precomputed kernel it will also drop the matching columns of the;3.9084914;0.4914343;-1.0451285;-4.054499;0.23778637;3.647809;-
kernel matrix and therefore we have fewer features as result;3.8745575;-2.537994;-0.46640036;-2.5087652;0.54703695;3.1190789;TASK
since class 0 has 49 samples and class 1 and 2 have 50 samples each a;3.9705298;1.6300958;-0.91736144;-1.095348;4.339468;-3.4092636;IRRE
single ovo binary classifier works with a sub kernel matrix of shape;3.2982752;-2.6561959;-5.186132;-3.277517;0.103576876;3.3693473;IRRE
either 99 99 or 100 100;-1.8464699;0.5802131;2.7157683;-1.7799975;1.0581554;-3.4680133;-
assert ovo precomputed estimators 0 n features in 99 class 0 vs class 1;3.2182434;1.4845237;-7.09629;2.694585;0.30889216;-1.2159729;CODE
assert ovo precomputed estimators 1 n features in 99 class 0 vs class 2;3.5899975;1.0194813;-6.50052;2.9693224;0.88547933;-1.2123204;CODE
assert ovo precomputed estimators 2 n features in 100 class 1 vs class 2;4.06423;0.9545513;-5.9222555;3.8983119;0.9949656;-1.0334023;CODE
fixme we should move this test in estimator checks once we are able;0.8696925;4.9389224;-4.515658;6.2542768;-4.459895;-0.49102986;IRRE
to construct meta estimator instances;2.4575126;0.07199714;-0.49830437;4.6748548;2.4948182;3.538597;CODE
smoke test to check that pipeline ovr and ovo classifiers are letting;2.1001565;0.8432179;-4.223234;4.171148;0.9470487;-0.21912314;CODE
the validation of missing values to;2.4650238;5.4513226;-1.7479554;2.2562666;2.0603476;-4.5155144;IRRE
the underlying pipeline or classifiers;4.5564075;-7.3133445;-0.3585608;4.853895;5.599167;0.46365333;CODE
x np copy x copy to avoid that the original data is modified;1.9426936;1.8306708;-2.3759038;-2.1116672;-2.1475177;1.502621;CODE
logisticregression does not implement partial fit and should raise an;1.516934;2.8665483;-4.8597517;2.4927015;-1.4297067;1.3839334;CODE
attributeerror;-2.6384718;1.6531335;-2.5732567;-0.2505034;-3.9445484;-3.6376987;META
test multi target regression raises;3.1647363;3.5636919;-1.043027;4.6715336;-0.5771227;-1.8494519;IRRE
no exception should be raised if the base estimator supports weights;1.970398;3.2405663;-4.468527;4.61085;-0.30583227;4.7320294;CODE
weighted regressor;3.5566266;0.924344;0.754412;-2.3599591;-1.0684996;2.9824991;-
weighted with different weights;4.530518;1.6198533;2.8521469;-0.80851066;1.7065246;1.4964606;-
weighted regressor;3.5566266;0.924344;0.754412;-2.3599591;-1.0684996;2.9824991;-
unweighted but with repeated samples;5.2374916;2.6917458;0.8958161;1.0336255;1.8153536;-0.6441742;META
import the data;1.0612681;-1.895989;2.233528;-2.8180823;0.43710425;-3.0328593;CODE
create a multiple targets by randomized shuffling and concatenating y;1.9621688;1.0554357;2.1038792;-1.9974446;2.016282;0.4880944;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
parallelism requires this to be the case for a sane implementation;0.174581;-1.9342866;0.8609544;3.0908751;2.963363;2.2634394;CODE
check multioutput has predict proba;4.127475;0.16496141;-0.6460564;3.3255095;0.10921242;-3.129066;IRRE
default sgdclassifier has loss hinge;-0.7062894;-2.2873943;-4.249499;0.6499514;-0.6024345;4.178627;CODE
which does not expose a predict proba method;2.309167;-3.3183088;-0.56554353;6.4825974;0.011717134;0.3067463;TASK
case where predict proba attribute exists;4.135431;0.96091455;-0.99562293;4.798887;3.5800807;0.016735889;META
check predict proba passes;3.1267421;2.2734828;-0.37739784;4.524097;-0.21157199;-4.399692;-
inner function for custom scoring;3.4110072;1.2017802;1.0985032;-0.22842872;3.056354;-0.958673;CODE
sgdclassifier defaults to loss hinge which is not a probabilistic;2.0043747;-2.756791;-4.4847217;3.1758761;1.3834105;4.6424613;CODE
loss function therefore it does not expose a predict proba method;1.6990271;-1.0030798;-2.722253;3.134181;-2.1339436;2.0185535;CODE
test if multi target initializes correctly with base estimator and fit;3.8016577;5.8506827;-2.1517386;4.063664;-1.0715635;1.5218941;IRRE
assert predictions work as expected for predict;2.8402483;3.5911963;-5.2121572;7.6451125;-1.5191302;-2.4760041;CODE
train the multi target linear and also get the predictions;5.672273;-1.4078474;1.600561;2.1635878;0.07746402;1.1413232;IRRE
train the linear classification with each column and assert that;6.55169;-0.53327686;-2.0492456;-0.29918414;3.225035;-2.3759437;CODE
predictions are equal after first partial fit and second partial fit;3.9274914;2.2201712;0.044912957;3.5001788;-1.0806749;2.3609545;-
create a clone with the same state;-2.8722115;1.9853826;2.7298596;1.3011354;2.7561302;1.8138928;IRRE
test if multi target initializes correctly with base estimator and fit;3.8016577;5.8506827;-2.1517386;4.063664;-1.0715635;1.5218941;IRRE
assert predictions work as expected for predict prodict proba and score;2.605416;1.0235971;-5.8098655;5.808167;-2.069043;-3.58954;CODE
train the multi target forest and also get the predictions;3.6341395;-3.9155064;1.7510036;4.277774;2.424235;0.4631513;CODE
train the forest with each column and assert that predictions are equal;5.7364044;-0.31987664;-0.24664679;3.217146;2.113593;-2.5237176;CODE
forest clone forest create a clone with the same state;-2.0149004;-0.048697237;0.91684586;1.5451199;2.7954497;1.8573996;CODE
test to check meta of meta estimators;0.59923506;3.7809231;-1.6118773;5.440106;-1.478301;-2.2336917;IRRE
train the forest with each column and assert that predictions are equal;5.7364044;-0.31987664;-0.24664679;3.217146;2.113593;-2.5237176;CODE
multi class svc clone multi class svc create a clone;0.32205516;-2.3595512;-1.8698596;-1.0093086;3.474857;1.9925393;IRRE
make test deterministic;2.629542;4.30961;-3.3245757;5.7921805;0.22005555;-3.7450957;IRRE
random features;5.3675146;-3.9382856;2.7753694;1.0274179;3.1246312;-1.6333755;IRRE
random labels;3.5453131;-1.8339758;3.4384234;-0.71869314;4.1078734;-1.8141752;IRRE
y1 np array b a a b a reshape 5 1 2 classes;4.3961377;-0.69160223;-0.96104103;-5.5859976;-0.4674924;0.91950977;IRRE
y2 np array d e f e d reshape 5 1 3 classes;3.7762632;-0.66987044;-1.0404567;-6.603234;-0.5815937;0.98656154;CODE
weighted classifier;7.162788;-3.7401311;0.47892222;0.5930978;4.1699123;-0.12029274;IRRE
unweighted but with repeated samples;5.2374916;2.6917458;0.8958161;1.0336255;1.8153536;-0.6441742;META
weighted classifier;7.162788;-3.7401311;0.47892222;0.5930978;4.1699123;-0.12029274;IRRE
unweighted but with repeated samples;5.2374916;2.6917458;0.8958161;1.0336255;1.8153536;-0.6441742;META
notfittederror when fit is not done but score predict and;3.558438;3.099251;-4.11747;3.702423;-4.8892374;-1.9062622;TASK
and predict proba are called;3.972494;-2.9453447;2.8757513;4.5081587;2.0069325;-1.9818528;IRRE
valueerror when number of outputs is different;3.352215;4.69653;-2.510639;-0.65004754;-2.7484386;-4.523968;IRRE
for fit and score;3.237717;-1.0403069;2.7172809;2.0678978;1.7292665;-4.3010535;CODE
valueerror when y is continuous;-0.34679738;3.149598;-0.83633494;-0.2930066;-6.7019053;-2.606698;IRRE
data is just 6 separable points in the plane;4.791708;1.1315448;1.2070886;-5.946531;-0.47807148;-0.073499665;CODE
a bit more random tests;2.840739;-0.14219494;1.0728065;5.8338046;0.5134234;-6.1522927;IRRE
data is 6 random integer points in a 100 dimensional space classified to;5.9062815;-0.7465518;1.3463856;-5.2198243;2.3799229;-1.4274756;CODE
three classes;-0.5559859;-3.0488155;2.885741;-0.50344783;7.0950184;-2.9705253;IRRE
gaussian naive bayes classification;4.0643873;-4.154863;-0.19094288;0.4127979;2.962444;-0.13341333;IRRE
this checks that gaussiannb implements fit and predict and returns;5.6107;-1.7721715;-4.311955;1.4063895;-0.41788137;0.23712836;CODE
correct values for a simple toy dataset;6.740987;0.6079014;1.2540215;-2.8662357;0.62566096;-4.875294;IRRE
test whether label mismatch between target y and classes raises;3.060458;3.2343132;-2.8775861;3.0924249;1.7359359;-3.4962401;IRRE
an error;-4.8327703;2.535416;1.70518;0.48802167;-0.93818873;-5.0259643;-
fixme remove this test once the more general partial fit tests are merged;0.0335589;4.9064755;-4.354072;4.425671;-1.5192838;0.37667933;IRRE
test whether class priors are properly set;2.020386;4.5368056;-1.3491887;5.7143974;3.8394945;-2.0543728;IRRE
check that the class priors sum to 1;1.5860264;4.1602006;-0.32334974;2.4895148;4.2034907;-3.4746256;IRRE
smoke test for issue 9633;-0.6469563;4.2091703;-2.610776;2.301248;-1.2738147;-4.2359204;IRRE
load a shared tests data sets for the tests in this module mark them;0.6931859;0.8350513;-1.9419898;2.837253;0.7869703;-0.8041466;CODE
read only to avoid unintentional in place modifications that would introduce;-2.7821524;0.9873133;-0.13003832;3.3589535;1.4310683;1.8451208;CODE
side effects between tests;-1.0627749;3.1248157;0.7363321;6.552963;-2.203627;-3.0259376;IRRE
test the various init parameters of the pipeline in fit;2.0439825;2.9928026;-2.805516;3.7110038;-0.77403533;0.09476838;IRRE
method;-1.0682498;-0.007665863;5.7642107;3.6788619;1.4956282;-4.1532536;-
check that we can t fit pipelines with objects without fit;2.3454645;2.2261016;-2.3682282;2.824664;0.43815222;1.6502811;CODE
method;-1.0682498;-0.007665863;5.7642107;3.6788619;1.4956282;-4.1532536;-
smoke test with only an estimator;1.586998;5.254544;-0.8192323;4.5601444;-2.5010402;0.90969235;IRRE
check that params are set;-1.5060538;6.3803663;1.4401747;1.2788562;0.0076638954;-1.4572266;IRRE
smoke test the repr;0.2968437;2.7159798;1.4050583;4.6910944;-0.23087735;-2.0273957;IRRE
test with two objects;1.5959889;5.55178;1.7932968;3.8589816;1.7849977;-6.502362;IRRE
check that estimators are not cloned on pipeline construction;0.6195576;2.0694227;-4.125849;3.9513838;-2.73864;1.9156553;CODE
check that we can t fit with non transformers on the way;-0.78706694;3.3812177;0.07189768;0.8345861;-1.6501501;1.2212757;CODE
note that notrans implements fit but not transform;2.1578124;1.7190764;-3.1071436;-2.773643;-2.2965028;2.7378957;TASK
check that params are set;-1.5060539;6.380367;1.4401737;1.2788558;0.0076615857;-1.457225;IRRE
smoke test the repr;0.2968437;2.7159798;1.4050583;4.6910944;-0.23087735;-2.0273957;IRRE
check that params are not set when naming them wrong;-2.0442731;4.8189883;-2.050213;0.9055089;1.0954462;-1.6560373;IRRE
test clone;-1.50811;1.5860248;1.0998253;3.986487;-0.104878984;-5.7875514;IRRE
check that apart from estimators the parameters are the same;2.755559;5.1023545;-1.6409491;1.7483052;-4.401208;1.3539104;IRRE
remove estimators that where copied;1.6797643;2.2477207;-2.1575506;2.4130962;-3.117295;3.386755;-
pipeline accepts steps as tuple;-1.4124732;1.4453835;-1.4097515;1.1570853;0.9398662;0.8144061;CODE
test the various methods of the pipeline anova;2.2182817;-0.17997237;1.1956311;4.9423585;-0.2891762;-2.6265688;CODE
test with anova logisticregression;0.0050036293;1.9008361;-0.8775512;4.040967;-0.9714249;-3.6951308;IRRE
test that the pipeline can take fit parameters;3.26106;3.8611467;-2.750862;4.35568;-0.8450596;0.22633117;IRRE
classifier should return true;2.1758947;0.8653634;-2.4769692;3.1426153;1.3657402;-3.2419662;IRRE
and transformer params should not be changed;-4.33285;3.187436;-0.45573795;0.50578684;-1.7824893;4.789867;CODE
invalid parameters should raise an error message;-3.7672164;6.4131665;-4.0773497;1.5210692;-1.4386438;-0.1625457;IRRE
pipeline should pass sample weight;3.0871384;2.2851663;-2.151994;2.3527913;0.802291;3.0570145;CODE
when sample weight is none it shouldn t be passed;2.252548;6.046713;-3.2193544;1.977325;-1.0438834;-0.29847485;-
test pipeline raises set params error message for nested models;-0.29355425;3.6293461;-4.7829638;4.781905;-0.4133779;0.34307384;CODE
expected error message;-4.1317024;5.0030236;-1.1752443;-0.7543876;-1.4937594;-4.514959;-
invalid outer parameter name for compound parameter the expected error message;-2.612984;3.7631555;-4.950746;-1.5443451;0.41161826;-0.05560161;IRRE
is the same as above;-2.627885;0.017855296;4.321265;-2.2503;2.6102533;-1.4798833;-
expected error message for invalid inner parameter;-2.8119848;5.3691783;-4.1912365;-0.4229226;-0.6277775;0.07743923;IRRE
test the various methods of the pipeline pca svm;4.9690228;-3.7169154;-2.3743713;1.2561399;1.3184216;0.9854231;CODE
test with pca svc;3.0652597;0.06271771;-3.126808;0.12194199;0.19578442;-1.573146;IRRE
test that the score samples method is implemented on a pipeline;3.9726083;1.724082;-1.8315101;6.8902545;2.1648722;-3.2273974;CODE
test that the score samples method on pipeline yields same results as;3.8412077;3.5114458;-3.0528276;5.830748;0.44092855;-3.0101933;IRRE
applying transform and score samples steps separately;3.76168;1.2764157;0.47944602;0.25962758;1.6890459;0.8434376;CODE
check the shapes;1.1669943;-0.10064507;6.050781;-2.556052;-0.1182537;-3.6183028;-
check the values;1.7465384;6.303021;3.682711;-2.443048;0.46825892;-8.927923;IRRE
test that a pipeline does not have score samples method when the final;2.2742581;4.2764854;-3.1214736;7.084041;0.7855962;-2.6739075;CODE
step of the pipeline does not have score samples defined;0.41964477;0.4879161;-4.5049953;2.7651749;0.15878984;-0.07924859;CODE
test the various methods of the pipeline preprocessing svm;3.1531074;-3.0228665;-2.2955325;2.3546062;1.2117285;0.70899606;CODE
check shapes of various prediction functions;7.159734;-1.2526627;1.4963027;1.1395148;-0.54701334;-0.9388175;CODE
test that the fit predict method is implemented on a pipeline;4.6341953;0.44442824;-2.9275396;7.3010855;-1.2857977;-0.6401013;CODE
test that the fit predict on pipeline yields same results as applying;4.471301;1.889008;-3.0606143;5.876655;-1.51739;-0.5937673;IRRE
transform and clustering steps separately;4.5288258;-1.1710649;1.9304454;-2.8368826;0.67364854;4.6595945;CODE
as pipeline doesn t clone estimators on construction;-0.1375688;-0.53149533;-2.9392238;4.3295865;-1.1935182;3.5330482;CODE
it must have its own estimators;1.9741633;-1.2535478;0.9239703;3.4327376;-1.505418;3.4059565;-
first compute the transform and clustering step separately;4.0724163;-0.86892724;0.37826246;-3.8943756;-0.1494332;3.6486344;CODE
use a pipeline to do the transform and clustering in one step;4.579036;-1.0195428;0.8601343;-1.9999017;0.60384583;3.4829578;CODE
tests that a pipeline does not have fit predict method when final;3.0832448;2.0287533;-4.0351954;7.8770823;-2.5005648;-0.57372856;CODE
step of pipeline does not have fit predict defined;1.2462965;0.07875536;-4.385393;2.311673;-2.8815315;1.7265233;CODE
tests that pipeline passes fit params to intermediate steps;1.8209026;3.1025097;-2.2836978;5.5882854;-0.18142834;0.58406603;IRRE
when fit predict is invoked;3.7489812;0.2925086;-1.5424685;6.0665607;-2.3272927;1.9647952;-
tests that pipeline passes predict to the final estimator;2.1707342;1.2273002;-2.3144295;8.48339;-1.9250096;-0.15187404;CODE
when predict is invoked;2.052706;-0.905321;-0.17938122;7.5619645;-0.7332935;0.41188905;-
basic sanity check for feature union;1.5899432;0.5793708;-1.1053416;4.0674973;4.719021;-2.1116679;TASK
check if it does the expected thing;-2.7191844;6.681661;1.3788847;4.4417067;-2.837228;-5.064724;IRRE
test if it also works for sparse input;4.789897;3.3356102;-2.4672835;1.3732926;-1.4582813;-0.7378856;IRRE
we use a different svd object to control the random state stream;1.5130202;-3.4376504;0.538047;1.2416757;2.5012598;5.0708165;IRRE
test clone;-1.50811;1.5860248;1.0998253;3.986487;-0.104878984;-5.7875514;IRRE
test setting parameters;0.78231573;5.1571774;-0.5222965;4.1558447;0.10593952;-1.7503774;IRRE
test it works with transformers missing fit transform;-0.06989359;3.807189;-2.3911698;1.1201736;-3.169926;0.7289459;CODE
test error if some elements do not support transform;0.6567068;7.304643;-3.5166945;0.11266234;-2.269099;-4.055164;CODE
test that init accepts tuples;0.83744466;4.7853045;-2.8221693;2.4572716;1.1413267;-5.552496;IRRE
test that make union passes verbose feature names out;1.018235;2.8490226;-4.119416;4.8067813;3.4374073;-2.7528486;IRRE
to the featureunion;1.7427351;-5.0287604;1.0782977;2.5381799;2.8431146;-0.33723524;TASK
test whether pipeline works with a transformer at the end;-0.646912;4.592923;-1.488902;4.6078873;-1.787592;-0.9463043;CODE
also test pipeline transform and pipeline inverse transform;0.6815556;0.27558967;-1.9720527;1.9071907;-0.86234504;-0.46680343;CODE
test transform and fit transform;4.477098;4.52575;-0.6578242;0.3407598;-2.6400378;-1.6029412;CODE
test whether pipeline works with a transformer missing fit transform;1.1255668;4.6459904;-3.9679892;2.7563214;-3.1874223;0.7648325;CODE
test fit transform;5.2509274;3.4688818;-0.89479244;-0.14223525;-2.9574573;-1.7965223;IRRE
test class;0.46585387;2.5090485;2.1912525;3.45782;2.4691405;-9.125647;IRRE
test steps;0.93557924;3.157223;2.5015962;3.983048;0.2118944;-7.503329;IRRE
test named steps attribute;-0.65294755;4.914361;-1.0390211;3.9831302;1.1506622;-3.2844467;IRRE
test the rest of the parameters;2.8535202;6.867176;1.7374896;2.5677142;-0.0077578677;-5.3366942;IRRE
test exception;-2.2771645;6.9470553;-0.7149615;4.5468783;-0.7794279;-8.230802;CODE
should raise an error if slicing out of range;2.0289495;5.704135;-3.0497873;-0.2733723;-0.82009417;-2.0429778;CODE
should raise an error if indexing with wrong element name;-2.075279;5.539412;-2.6252096;1.4093069;0.25560948;-0.3506794;META
directly setting attr;-4.1824074;0.6097427;1.9247488;-0.51302665;-0.33828127;3.5717504;IRRE
using set params;0.24440372;3.6173332;3.3591554;-0.68471545;3.1322079;-0.48703754;IRRE
using set params to replace single step;-0.0911473;4.3410587;2.1723468;-0.25512674;1.8201119;1.0707114;IRRE
with invalid data;1.4791651;4.721193;0.3260587;0.97606605;1.6699907;-4.605067;OUTD
test access via named steps bunch object;-1.6662062;4.0961437;-0.47687906;4.2523136;0.9832523;-3.309177;IRRE
test bunch with conflict attribute of dict;-0.55162925;4.49501;-2.2970068;2.9159074;0.91174495;-4.665691;IRRE
for other methods ensure no attributeerrors on none;-1.034542;4.353347;-5.2412834;5.311669;-1.9970284;-1.5659599;META
mult2 and mult3 are active;-4.159159;1.1919558;0.053467743;-1.6545466;-1.2000186;0.08605945;-
check passthrough step at construction time;-2.8487208;2.5245042;-1.0256053;5.095988;1.6225117;-0.93341434;CODE
smoke test the repr;0.2968437;2.7159798;1.4050583;4.6910944;-0.23087735;-2.0273957;IRRE
test feature union with transformer weights;4.8640456;1.9312975;-2.9586663;2.9047446;1.6797613;0.4514913;TASK
test using fit followed by transform;4.350339;5.622238;-0.495552;0.9360866;-2.2191133;-2.518863;IRRE
test using fit transform;4.9315414;4.9468527;-0.73081;0.63110876;-3.0374832;-2.5905063;IRRE
test it works with transformers missing fit transform;-0.06989359;3.807189;-2.3911698;1.1201736;-3.169926;0.7289459;CODE
check against expected result;1.9724065;8.638151;1.6619343;4.1482496;-0.61573815;-7.92105;IRRE
we use a different pca object to control the random state stream;2.0635762;-2.3671706;0.9555276;1.2987158;3.1846285;5.537466;IRRE
todo remove mark once loky bug is fixed;-5.863761;1.7962036;-1.2213115;2.4669976;-1.3744891;2.2256222;TASK
https github com joblib loky issues 458;-5.9445934;-3.3966906;-3.400748;-0.1323502;-4.297158;-1.9892545;CODE
test that n jobs work for featureunion;1.7313485;0.29630068;-1.4922032;5.21341;1.0844074;-3.9179788;TASK
fit transform should behave the same;3.495381;2.3889835;-0.6142251;-2.0285747;-3.8103;5.072285;CODE
transformers should stay fit after fit transform;0.06357448;2.6680906;0.44752413;0.4612847;-2.3833907;4.4684615;CODE
directly setting attr;-4.1824074;0.6097427;1.9247488;-0.51302665;-0.33828127;3.5717504;IRRE
using set params;0.24440372;3.6173332;3.3591554;-0.68471545;3.1322079;-0.48703754;IRRE
using set params to replace single step;-0.0911473;4.3410587;2.1723468;-0.25512674;1.8201119;1.0707114;IRRE
check we can change back;-4.375354;1.9312706;2.6652896;2.99683;-1.7317071;-1.5466968;-
check drop step at construction time;-0.851295;3.2686448;1.2022196;4.369802;-0.21804914;-0.89311504;CODE
passthrough is stateless;-4.995269;2.9950645;-0.780214;3.8962367;0.078298576;1.7852312;-
featureunion should have the feature names in attribute if the;-1.5415949;-0.46857646;-2.4202409;2.210084;1.7130283;0.15080704;TASK
first transformer also has it;-4.1060705;-0.9735024;1.5802268;-0.794139;0.44237497;1.885627;CODE
fit with pandas dataframe;2.657212;-0.33715636;-0.24523365;-3.3932137;-5.003679;0.35077876;-
fit with numpy array;5.8087378;0.510392;-0.6743438;-6.800525;-6.007525;0.8741506;-
method split fit transform if fit transform fit otherwise;4.980233;3.3268435;-1.6859368;-0.8040181;-1.1644458;3.1184537;CODE
test that metadata is routed correctly for pipelines when requested;-1.706487;2.6144767;-3.9824994;6.869573;0.42095417;1.4803873;CODE
some methods don t accept y;-2.6863582;2.0142787;-1.0795853;2.4434166;-2.8678677;-2.3394113;CODE
make sure the transformer has received the metadata;-4.2039857;0.44696668;-2.2666707;1.1520516;-1.6129861;2.3374872;CODE
for the transformer always only fit and transform are called;-1.7850965;1.3338377;0.65849406;-1.4788113;0.18115243;3.7469697;CODE
split and partial fit not relevant for pipelines;2.580802;1.0337541;-2.794707;2.1734364;0.19653986;3.4091792;CODE
sorted is here needed to make pytest nx work w o it tests are collected;-0.99453354;1.45453;-3.7393134;0.2889461;-1.4333577;-1.8483607;IRRE
in different orders between workers and that makes it fail;-2.8941038;2.962808;1.0813009;3.507082;0.9921619;-0.9651319;-
access sub transformer in name trans with transformer 1;-2.6570141;1.1621478;-0.038363345;-1.0139612;0.6545742;2.5808554;CODE
end of routing tests;-0.30803326;2.701596;1.652701;5.8366446;-1.0417191;-2.267333;CODE
the parameters args and kwargs are ignored since we cannot generate;-1.5930209;0.8444447;-3.729054;-0.08304453;-2.224834;1.8562628;IRRE
constraints;1.125938;0.697066;2.6427748;-1.0685596;3.2708;0.23862366;CODE
generate valid values for the required parameters;3.894192;4.8929477;-0.5813295;-1.7579006;3.8252285;-2.9423156;IRRE
check that there is a constraint for each parameter;0.74743104;6.652405;-1.865563;-0.09747526;2.2761014;-1.0183605;CODE
this object does not have a valid type for sure for all params;-4.1770363;4.177879;-2.9650445;-0.22610588;0.30778378;-0.900066;CODE
this parameter is not validated;-4.549326;6.0823307;-3.768274;0.19855922;-0.54998857;-1.9265033;IRRE
mixing an interval of reals and an interval of integers must be avoided;-0.40016428;4.3738704;1.6583529;-1.4433957;-0.56339586;-0.23574217;CODE
first check that the error is raised if param doesn t match any valid type;-2.904097;6.8730345;-6.672676;1.1259537;0.15982288;-1.6395994;CODE
then for constraints that are more than a type constraint check that the;0.3369097;3.620695;-3.5266492;1.1380119;4.856494;-0.6759249;CODE
error is raised if param does match a valid type but does not match any valid;-2.0968635;7.605536;-6.858817;1.6768442;0.38706753;-1.7127208;CODE
value for this type;-0.48301297;2.9042594;2.1724322;-3.1873145;3.257727;-4.7911286;CODE
test on jl lemma;-1.4818543;5.16588;-1.0375633;3.7498243;1.2308973;-0.60013056;IRRE
tests random matrix generation;5.9371142;1.6695597;-1.187972;1.3082883;0.14772184;-3.5031097;IRRE
all random matrix should produce a transformation matrix;2.2648118;-0.11419936;0.24398494;-2.7047133;-0.49163553;3.0121074;IRRE
with zero mean and unit norm for each columns;4.7253213;1.1636403;1.0261401;-5.7026916;-2.019057;2.1702068;CODE
check basic properties of random matrix generation;4.0190516;-0.13994162;-0.4126881;-0.6448867;1.3161334;-0.5557523;IRRE
check some statical properties of gaussian random matrix;2.7818544;0.24070218;-1.4585892;-1.2820503;-0.3560629;2.7943068;IRRE
check that the random matrix follow the proper distribution;1.9935379;2.9569366;-1.2012894;-0.7752518;-1.4773875;1.2177744;IRRE
let s say that each element of a ij of a is taken from;-0.31338757;0.47120973;2.1732566;-2.7732859;3.6610801;-0.8576707;CODE
a ij n 0 0 1 n components;1.5788095;0.362514;-0.6999399;-6.526177;1.6009569;-0.05006431;-
check some statical properties of sparse random matrix;4.3846226;-1.1225364;-2.4198735;-0.906851;0.72089684;3.2207134;IRRE
check possible values;3.9162343;6.5045047;2.4172423;-1.135513;2.965618;-9.045572;IRRE
check that the random matrix follow the proper distribution;1.9935379;2.9569366;-1.2012894;-0.7752518;-1.4773875;1.2177744;IRRE
let s say that each element of a ij of a is taken from;-0.31338757;0.47120973;2.1732566;-2.7732859;3.6610801;-0.8576707;CODE
sqrt s sqrt n components with probability 1 2s;-0.20144239;-0.38038477;0.2731778;-2.5072753;0.3379154;0.13491018;-
0 with probability 1 1 s;-0.9053626;2.058345;2.1872752;-1.8541157;0.49747613;-3.4297457;-
sqrt s sqrt n components with probability 1 2s;-0.2014425;-0.3803852;0.273178;-2.5072749;0.33791474;0.1349103;-
tests on random projection transformer;2.8527849;2.0640366;-1.8112465;2.716867;-1.2456715;0.24090235;IRRE
remove 0 distances to avoid division by 0;2.312556;4.959269;0.6413304;-5.627938;-1.9495943;-0.77629286;OUTD
remove 0 distances to avoid division by 0;2.312556;4.959269;0.6413304;-5.627938;-1.9495943;-0.77629286;OUTD
check that the automatically tuned values for the density respect the;3.5161538;3.8657684;-3.6828735;0.52263343;-3.4162009;1.4162356;IRRE
contract for eps pairwise distances are preserved according to the;1.0886996;1.3778689;-0.56095916;-2.9112823;1.0793815;4.7705865;CODE
johnson lindenstrauss lemma;4.0380926;-1.2018223;-1.5329394;-2.1935184;0.9538041;4.976091;-
when using sparse input the projected data can be forced to be a;5.8669367;0.2876798;-2.6082213;0.34102958;-0.5791596;4.7869797;CODE
dense numpy array;4.437745;-0.6552412;-1.4435693;-6.1411123;-5.001063;-0.5296927;-
the output can be left to a sparse matrix instead;5.2557507;1.3451513;-2.525046;-4.890769;-4.2092505;3.5007102;IRRE
output for dense input will stay dense;1.7757084;2.0327456;-1.0574515;-0.88171935;-3.3612401;0.14821313;CODE
output for sparse output will be sparse;3.990546;0.45622775;-1.587291;-1.2419503;-2.431102;2.8775241;IRRE
the number of components is adjusted from the shape of the training;4.534045;-3.6475942;3.0424802;-0.5694154;3.5623376;1.313912;CODE
set;-1.4280705;0.15607189;7.4121943;-1.1588911;1.308024;-3.1926973;IRRE
once the rp is fitted the projection is always the same;1.2201878;2.2960367;-0.07079796;-0.15886891;-1.4771066;7.5736294;-
fit transform with same random seed will lead to the same results;4.593579;1.5673077;-1.2293621;-0.025756404;-1.5771052;2.7973242;IRRE
try to transform with an input x of size different from fitted;2.8683953;3.7060177;0.0485956;-5.3928256;-5.3371143;2.6950958;CODE
it is also possible to fix the number of components and the density;2.917024;-0.67762905;1.1774002;-1.8673373;1.3278292;3.4396024;CODE
level;-2.330566;-2.191926;4.64252;-1.8583341;1.4155381;-3.691862;-
assert rp components nnz 115 close to 1 density;2.3859196;4.355662;-4.967931;-0.56160295;-1.5823863;0.039626732;CODE
assert 85 rp components nnz close to 1 density;2.454725;4.3006353;-4.3347335;-1.271535;-1.464417;0.058931723;CODE
verify output matrix dtype;3.1928108;1.5827572;-5.6710334;-4.4639525;-2.1224058;-2.62021;IRRE
verify numerical consistency among np float32 and np float64;2.0929685;2.7404416;-6.330892;-2.5587137;-3.6086843;-1.5528214;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
types and constants;-1.2903183;0.49283183;0.121631764;-2.690435;1.4704635;-1.6663593;CODE
base decision tree;2.5432634;-2.7070272;1.7627556;-0.014048812;6.705146;-1.8522334;-
check input is used for optimisation and isn t something to be passed;0.3628075;4.907901;-2.0805662;3.2418733;-0.14226434;-3.3614538;CODE
around in a pipeline;-0.7061259;-1.7293218;4.836078;2.5719156;0.32400727;-0.5010201;CODE
raise a valueerror in case of the presence of an infinite element;0.12661685;6.8125515;-2.2175038;2.0069714;-2.4638727;-2.5267158;IRRE
if the sum is not nan then there are no missing values;1.8904401;4.4807143;-2.5129302;-2.638858;-3.9537919;-3.6970353;IRRE
need to validate separately here;-0.7260246;5.3709903;-0.069048524;2.0399764;5.1109104;-4.4836025;TASK
we can t pass multi output true because that would allow y to be;0.05413386;4.4601183;-0.47079703;-1.5231687;-1.1784915;-2.3778305;IRRE
csr;-1.9517441;-2.1731985;2.3376567;0.095433205;1.0228496;-3.156976;-
compute missing values in feature mask will check for finite values and;4.5423994;4.2136097;-2.6406562;-2.2341108;-0.48206952;-2.0200303;IRRE
compute the missing mask if the tree supports missing values;2.827214;3.402065;-1.794567;-1.7006234;1.8010263;-1.0483711;IRRE
determine output settings;1.679366;1.0453707;1.5457959;-0.19319311;0.041005272;-0.73580384;IRRE
reshape is necessary to preserve the data contiguity against vs;1.4835404;-0.5861336;-0.6574447;-1.0544254;0.69500864;5.6920056;-
np newaxis that does not;-2.9079926;-0.11009505;-0.009353316;-2.4536536;-0.82501876;-0.07860063;CODE
else float;-1.5627816;3.0578258;3.5757935;-2.9302845;-2.1748374;-4.182749;CODE
else float;-1.5627816;3.0578258;3.5757935;-2.9302845;-2.1748374;-4.182749;CODE
else float;-1.5627816;3.0578258;3.5757935;-2.9302845;-2.1748374;-4.182749;CODE
set min weight leaf from min weight fraction leaf;2.1115751;2.4865315;1.6271464;-2.2553906;0.06014577;2.8601186;IRRE
build tree;-2.406555;-3.3117192;3.2873929;0.27933812;2.0903955;-2.2585628;-
make a deepcopy in case the criterion has mutable attributes that;4.524424;1.6472394;-2.5174146;2.540915;3.9020379;1.1838704;IRRE
might be shared and modified concurrently during parallel fitting;2.7945993;0.78444636;-2.7672746;1.6538852;-3.1298535;4.4624677;-
check to correct monotonicity constraint specification;-0.27917293;4.8359876;-3.3013651;0.8579225;1.4170377;0.7108474;CODE
by applying element wise logical conjunction;-1.6791952;2.7938974;1.8015648;-1.310005;5.0725756;-4.4353175;-
note we do not cast np asarray self monotonic cst dtype np int8;0.34495795;0.04407945;-6.391935;-3.2258072;-0.7720632;0.18367071;CODE
straight away here so as to generate error messages for invalid;-3.7864678;3.342226;-2.6154263;2.2102187;-0.020037908;-3.8444223;OUTD
values using the original values prior to any dtype related conversion;4.2873173;2.1420748;-3.202937;-2.767066;0.31956244;-1.6153203;IRRE
binary classification trees are built by constraining probabilities;3.379637;-5.678745;-0.74148136;1.508932;5.9219427;0.20043363;CODE
of the negative class in order to make the implementation similar;0.68478525;0.39303914;-0.40417767;-0.009254095;3.3554232;2.0741725;TASK
to regression trees;5.37344;-4.9031043;2.3540833;1.6732069;2.448644;-1.460205;-
since self monotonic cst encodes constraints on probabilities of the;0.955206;-0.22577311;-1.6925515;2.0157247;1.9000916;1.7591954;CODE
positive class all signs must be flipped;-1.1510456;1.9490383;-1.1240569;-0.42832536;2.5972197;-2.621049;TASK
todo tree shouldn t need this in this case;-4.56257;-0.6218116;1.5932721;4.5700483;2.5075095;2.1825938;CODE
use bestfirst if max leaf nodes given use depthfirst otherwise;1.8874223;3.3053315;1.9204642;-0.6208183;1.754608;1.6025072;-
build pruned tree;-1.1516109;-1.2697073;1.6761411;-0.7875619;1.8223288;0.1524293;CODE
todo the tree shouldn t need this param;-4.4344406;0.93504405;2.0127232;2.6931615;1.5599403;0.80061334;CODE
public estimators;2.0078492;-0.41504437;1.9299687;4.0816426;-0.011434521;1.5095562;CODE
check input is used for optimisation and isn t something to be passed;0.3628075;4.907901;-2.0805662;3.2418733;-0.14226434;-3.3614538;CODE
around in a pipeline;-0.7061259;-1.7293218;4.836078;2.5719156;0.32400727;-0.5010201;CODE
xxx nan is only supported for dense arrays but we set this for;1.0485264;3.0832078;-5.497473;-5.5550337;-3.9256556;0.35050172;CODE
common test to pass specifically check estimators nan inf;3.0241358;5.296508;-4.6704173;3.5369678;-2.8360205;-1.7224747;IRRE
check input is used for optimisation and isn t something to be passed;0.3628075;4.907901;-2.0805662;3.2418733;-0.14226434;-3.3614538;CODE
around in a pipeline;-0.7061259;-1.7293218;4.836078;2.5719156;0.32400727;-0.5010201;CODE
xxx nan is only supported for dense arrays but we set this for;1.0485264;3.0832078;-5.497473;-5.5550337;-3.9256556;0.35050172;CODE
common test to pass specifically check estimators nan inf;3.0241358;5.296508;-4.6704173;3.5369678;-2.8360205;-1.7224747;IRRE
xxx nan is only supported for dense arrays but we set this for the;1.1174523;2.850757;-5.44468;-5.763202;-3.893019;0.47021514;CODE
common test to pass specifically check estimators nan inf;3.0241358;5.296508;-4.6704173;3.5369678;-2.8360205;-1.7224747;IRRE
xxx nan is only supported for dense arrays but we set this for the;1.1174523;2.850757;-5.44468;-5.763202;-3.893019;0.47021514;CODE
common test to pass specifically check estimators nan inf;3.0241358;5.296508;-4.6704173;3.5369678;-2.8360205;-1.7224747;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
initialize saturation value calculate chroma value shift;-0.6726198;3.4959652;-1.1631047;-4.2867436;-2.1237738;0.30637178;IRRE
calculate some intermediate values;1.732721;4.8730555;4.053588;-3.7963588;-0.24894276;-3.7046127;IRRE
initialize rgb with same hue chroma as our color;-0.7901846;1.0153711;1.2112727;-1.5296502;0.29628882;2.9856086;IRRE
shift the initial rgb values to match value and store;0.5595392;3.1903498;2.2822177;-3.8425758;-0.5045947;1.6917533;IRRE
ax no validation delegate validation to matplotlib;0.5544861;-0.23154624;-3.812795;-0.6866538;-5.832793;1.7857114;OUTD
find the appropriate color intensity for a node;2.9637325;0.79962176;1.7573223;-4.0967975;0.0065217363;-1.0984565;CODE
classification tree;3.841367;-5.688561;2.4601614;-0.15125431;6.517706;-3.1460073;IRRE
regression tree or multi output;3.5556953;-1.4533719;3.2764163;0.09453242;2.1854165;-1.2252;IRRE
compute the color as alpha against white;0.37749213;1.3221774;1.688027;-3.6555023;-0.98406976;-2.5697427;-
return html color code in rrggbb format;-3.0136945;0.24493282;0.037451826;-2.2211852;0.053465817;-1.3466121;CODE
return 2x 2x 2x tuple color;0.019223658;2.1628625;0.21989097;-5.351815;1.28744;-1.0227096;IRRE
fetch appropriate color for node;-0.70647275;1.0291089;1.0525004;-0.556091;0.6332653;-0.9926878;CODE
initialize colors and bounds if required;-0.8762285;3.3643048;1.8410376;-1.3206593;1.8387988;-0.5216487;IRRE
find max and min impurities for multi output;4.1934414;3.0442832;1.5410527;-4.405557;-0.54193115;-1.4882612;IRRE
the next line uses max impurity instead of min impurity;-2.4025607;2.5747468;-2.966957;-3.599068;-1.4123981;0.7015517;CODE
and min impurity instead of max impurity on purpose in;-1.2635291;0.63867265;-1.5420642;-0.31725535;2.1617858;3.361206;CODE
order to avoid what looks like an issue with simd on non;-2.9222722;4.2165165;-2.0143297;1.3528371;0.23449829;0.7094536;CODE
memory aligned arrays on 32bit os for more details see;-0.61914283;-0.1264546;-0.74121755;-5.014164;-0.08801415;0.99249005;CODE
https github com scikit learn scikit learn issues 27506;-2.8816836;-9.678642;-5.945251;-0.6727778;-5.201195;-5.6576347;CODE
find max and min values in leaf nodes for regression;4.3932614;1.2187647;1.7281235;-2.7016413;-1.4191848;0.22658367;IRRE
unpack the float only for the regression tree case;2.6419532;0.85823154;-2.629192;-2.4732683;-1.9102142;0.14435367;CODE
classification tree requires an iterable in get color;0.15617698;-1.8978512;-1.8941945;1.6924794;2.7778342;-0.69872665;CODE
if multi output color node by impurity;1.1694427;4.0825963;-0.602614;-2.1117933;2.2517931;-0.8644428;IRRE
generate the node content string;-2.5165703;0.6000478;1.8222626;-2.0414631;1.8700598;-0.6176714;CODE
should labels be shown;-0.48841444;-1.2013775;2.4815385;-0.26654482;2.210522;1.4499927;-
write node id;-3.450691;0.4243748;0.74387276;-3.384781;3.1336732;-0.67637396;TASK
write decision criteria;1.2155896;0.8694622;2.1691113;3.3734374;5.86716;-2.4586802;TASK
always write node decision criteria except for leaves;1.0098251;2.3152463;-0.738753;2.7760706;4.8257895;1.0761809;CODE
write impurity;-3.1483724;0.011283438;1.4936861;-0.6877499;0.963843;-2.2900848;TASK
write node sample count;2.828346;1.0366647;1.483431;-0.88438815;1.9655974;-3.071058;TASK
write node class distribution regression value;2.6945868;-1.011945;-2.5782664;-1.0139631;0.85818565;-0.9968924;IRRE
for classification this will show the proportion of samples;3.740538;-2.1897051;2.747735;0.024617616;3.5691836;-3.0536873;CODE
regression;4.8113813;-1.4023851;5.968424;1.4558641;-1.5940726;-2.9783654;-
classification;5.668271;-5.8220553;4.2595444;1.7214531;6.909542;-2.19592;IRRE
classification without floating point weights;6.9680624;-2.620581;-1.2105702;-0.50192285;1.977375;0.3895563;CODE
classification with floating point weights;7.2703815;-2.8132198;-1.297799;-1.2857956;2.0103343;-0.4947861;CODE
strip whitespace;-2.207197;1.7847855;1.8032981;-2.3354921;-0.68606323;-0.031523034;-
write node majority class;0.14563018;-0.3202696;0.035966687;0.24675226;4.1134815;-0.86284035;CODE
only done for single output classification trees;3.142183;-4.519382;-0.7738417;1.8048594;4.1361527;0.07797372;CODE
clean up any trailing newlines;-2.448106;1.624162;0.15239394;-0.89690983;-1.4049385;-0.3591201;TASK
postscript compatibility for special characters;-5.1754985;0.0165085;-2.0686018;0.007986466;1.2338271;-0.5129667;CODE
elf characters 35 sub sub le br;-1.9883304;-0.27376243;2.2157166;-2.1781871;1.4910548;-3.0950809;CODE
elf characters n;-3.1983204;-2.7855413;2.6309817;-2.4083617;0.11856232;-4.291825;CODE
the depth of each node for plotting with leaf option;1.344381;-0.2649923;3.7874312;-3.9724367;-3.0192306;2.5723746;CODE
the colors to render each node with;0.028950842;-0.7588908;3.6624734;-3.2198775;0.84209555;0.14813684;CODE
check length of feature names before getting into the tree node;-0.69914;1.2536706;-0.05477514;1.5604975;3.095388;-1.6361593;CODE
raise error if length of feature names does not match;0.24271181;3.7167985;-3.8986504;3.9461212;1.5556026;-1.8027803;CODE
n features in in the decision tree;4.320312;-3.790281;-0.3740096;-2.0930605;6.5331335;-1.6873795;TASK
each part writes to out file;-1.0964761;-0.35308006;2.4472463;-1.0336664;-0.47235665;-0.89501894;TASK
now recurse the tree and add node edge attributes;-1.3030207;-1.542937;0.9339574;-1.5888212;2.6648238;1.7469682;TASK
if required draw leaf nodes at same depth as each other;1.5112988;2.812199;3.9701345;-2.5213559;0.9754619;1.9607364;CODE
specify node aesthetics;-2.8192928;-1.2562554;0.70494765;-1.1901867;3.740207;4.174966;-
specify graph edge aesthetics;-0.39284226;-2.1547318;2.8993542;-3.0910997;2.7229464;3.928948;-
add node with description;-2.8042748;-1.1502808;2.802087;-0.43042582;3.0393293;2.413178;TASK
collect ranks for leaf option in plot options;1.4871411;0.13217495;3.28242;-2.2852614;-0.247332;2.265262;CODE
add edge to parent;-3.942661;-0.040845353;4.9607034;-2.319828;0.29414105;3.676473;TASK
draw true false labels if parent is root node;-1.4990335;3.263735;1.6960331;-1.5931487;0.3189881;-0.57954955;-
color cropped nodes grey;-1.3370297;-0.37406337;0.5141282;-2.019466;-2.7963524;2.0873814;-
elf out file write fillcolor c0c0c0;-4.444019;-1.7779344;-1.7322204;-3.2577178;-1.731637;-1.3475262;TASK
add edge to parent;-3.942661;-0.040845353;4.9607034;-2.319828;0.29414105;3.676473;TASK
override default escaping for graphviz;-4.1771727;1.5389242;-0.8777337;-1.2841339;-1.7294084;2.9879243;CODE
the depth of each node for plotting with leaf option;1.344381;-0.2649923;3.7874312;-3.9724367;-3.0192306;2.5723746;CODE
the colors to render each node with;0.028950842;-0.7588908;3.6624734;-3.2198775;0.84209555;0.14813684;CODE
elf characters n;-3.1983204;-2.7855413;2.6309817;-2.4083617;0.11856232;-4.291825;CODE
traverses tree tree recursively builds intermediate;-2.4147499;-0.6143852;-0.17744613;1.5715418;1.9459869;-0.12115912;CODE
reingold tilford tree object;-2.505376;-1.288682;-0.24682909;-1.5444928;1.3606789;1.3776788;CODE
important to make sure we re still;-2.4397035;0.4171023;4.1271586;2.8679743;-1.1530402;-0.18897869;CODE
inside the axis after drawing the box;-2.436355;2.0376904;6.3213754;-5.2017684;-5.1199102;1.3489944;-
this makes sense because the width of a box;-1.3118954;1.6161281;3.1316745;-3.0649576;-0.7351986;1.106419;IRRE
is about the same as the distance between boxes;1.9599763;0.6741609;4.0623837;-3.3610275;-1.0351963;0.20895936;-
update sizes of all bboxes;0.21917133;2.414974;0.27509168;-2.4931316;1.4327017;0.8994133;CODE
get figure to data transform;2.3774338;0.69087166;4.0185356;-4.300514;-4.3347588;2.0307598;CODE
adjust fontsize to avoid overlap;0.41474664;2.2921114;2.3802054;-2.0436232;-0.3653988;4.328291;CODE
get max box width and height;-0.086886585;1.9384526;3.3288608;-4.334936;0.5202077;0.67516756;-
width should be around scale x in axis coordinates;1.097735;1.5270865;2.8210123;-5.920988;-5.626281;4.0111957;-
kwargs for annotations without a bounding box;0.12972158;-2.4635975;-0.43805563;0.45111555;0.85950834;4.068904;IRRE
kwargs for annotations with a bounding box;0.426113;-2.186718;-0.06547514;-0.32287446;0.9333013;3.5701754;IRRE
offset things by 5 to center them in plot;2.3929937;0.55062956;6.9469805;-5.021477;-5.991626;1.7357641;IRRE
root;-4.979902;-2.0713117;4.5406322;-0.22823495;-0.58503574;-3.7213576;-
draw true false labels if parent is root node;-1.4990335;3.263735;1.6960331;-1.5931487;0.3189881;-0.57954955;-
adjust the position for the text to be slightly above the arrow;-2.7704647;-0.33990893;3.6808355;-1.4154971;-2.4572792;2.9057963;CODE
annotate the arrow with the edge label to indicate the child;-1.7555308;-1.5303013;3.3546178;-0.7452866;1.2763733;2.31723;-
where the sample split condition is satisfied;3.105257;4.366044;0.59507173;0.15514123;3.623648;-0.47577152;-
else leaf;-2.8958075;0.7566935;4.251751;0.50661373;0.9227929;-2.098104;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this is the number of the node in its group of siblings 1 n;-1.6074867;-0.47378984;2.703618;-5.0290065;1.8983383;-3.0323668;IRRE
print finished v v tree children;-1.9914763;-0.86888367;2.4194787;-1.4684826;1.5047609;-1.3102002;CODE
in buchheim notation;-3.6143918;0.24165973;0.95161146;-2.1359215;2.2731824;-0.3384499;-
i inner o outer r right l left r l;-2.5733182;0.8037174;3.4984632;-4.6912723;0.7089135;-1.1740289;-
print wl tree is conflicted with wr tree moving subtrees;-3.2023354;0.53480023;-1.690078;-0.28289723;0.32087377;0.2840606;CODE
shift shift;-1.7907207;-0.0097825425;5.010585;-3.964683;-0.7836282;-0.19857965;-
print wl wr wr number wl number shift subtrees shift subtrees;-1.4522012;-0.10631847;-0.08430017;-4.865607;2.723516;-2.0987306;CODE
print shift w shift w change;-3.7105727;0.47533345;3.3740509;-4.3390517;-1.0265325;-1.1278784;CODE
the relevant text is at the bottom of page 7 of;-4.9381084;-3.3233383;0.97755957;1.6809554;1.1047829;2.7435389;-
improving walker s algorithm to run in linear time by buchheim et al;1.8440063;-0.6625849;-1.3519822;-0.6018316;0.5603549;1.4725506;CODE
2002;-2.1021912;-2.0316772;3.7209575;0.16173756;0.471811;-2.47595;-
https citeseerx ist psu edu doc view pid 1f41c3c2a4880dc49238e46d555f16d28da2940d;-4.4483104;-2.1844041;-4.0494537;-3.7830129;0.22556552;-0.57494956;CODE
toy sample;0.095309615;-1.126863;5.4498596;1.2328314;2.0021777;-3.6053288;-
check correctness of export graphviz;-1.8783267;2.3170967;-1.4823743;-1.4104291;-2.5608346;0.6160314;-
test export code;-1.7351718;2.7558002;-1.8634802;3.0911908;-1.0140438;-4.8193383;IRRE
test with feature names;1.4630713;1.5241947;-1.9856911;4.816637;2.7836971;-5.667013;TASK
test with feature names escaped;-1.5473335;2.3077872;-4.325429;4.571352;0.9701321;-4.5897164;TASK
test with class names;1.3436235;2.7005553;-1.5299182;3.5293138;4.090329;-6.87222;IRRE
test with class names escaped;-1.8186669;3.1608703;-3.9672427;3.9411936;2.3028553;-5.2790313;IRRE
test plot options;1.6390164;2.7830484;3.112511;1.3388081;-4.8423624;-2.9956944;IRRE
value 0 5 0 5 fillcolor ffffff n;0.42410457;2.8326185;2.0455592;-7.9476542;-0.45050964;-4.0034204;IRRE
fillcolor e58139 n;-3.633954;-0.64297056;2.5212958;-5.507528;2.1510723;-3.375269;-
fillcolor 399de5 n;-4.037845;-0.113239504;2.090733;-5.9076495;2.2787032;-3.5088494;-
test max depth;3.087259;4.4923196;1.1716367;1.5215278;0.55658436;-4.3163548;IRRE
test max depth with plot options;2.4073555;3.9475029;1.956265;-0.1825006;-3.2797701;-0.7949771;IRRE
0 label node 0 nx 0 0 0 ngini 0 5 n;-2.168351;2.0515714;-0.7971548;-6.9354978;1.0235244;-0.24698971;-
samples 6 nvalue 3 3 fillcolor ffffff n;1.357096;1.115776;1.7822276;-5.0927925;2.425203;-4.396049;IRRE
1 label fillcolor c0c0c0 n;-1.4071982;0.4270529;1.8679388;-6.9559684;3.8320653;-1.8550428;-
2 label fillcolor c0c0c0 n;-2.0203235;0.49572226;2.1543906;-6.451076;4.1555223;-1.3144271;-
test multi output with weighted samples;6.586113;3.8525584;-0.0013521226;1.9381917;1.300063;-2.4185224;IRRE
3 0 1 0 0 5 fillcolor ffffff n;-0.076426566;1.1364934;2.9406393;-8.707522;0.2437205;-3.705688;-
3 0 0 fillcolor e58139 n;-2.7266455;0.86437535;1.3021871;-8.548739;1.2366321;-4.6024785;-
0 0 1 0 0 5 fillcolor f1bd97 n;-0.4991495;1.3506489;1.3696167;-9.219567;1.2037486;-4.925994;-
0 1 0 fillcolor e58139 n;-2.365112;0.93195015;1.0947703;-8.271235;0.7779164;-4.73347;-
0 0 0 0 0 5 fillcolor e58139 n;-1.3260128;0.7788109;0.41681135;-8.8631735;0.5000942;-4.9604125;-
test regression output with plot options;2.7047985;3.2016168;1.7577552;1.3828717;-6.3490167;-1.9892355;IRRE
value 0 0 fillcolor f2c09c n;-2.0965478;3.4137354;-0.51058954;-7.184709;-0.10576665;-4.0715566;IRRE
fillcolor ffffff n;-1.3034763;0.11199067;4.1213484;-5.479935;0.11314628;-1.9505881;-
fillcolor e58139 n;-3.633954;-0.64297056;2.5212958;-5.507528;2.1510723;-3.375269;-
test classifier with degraded learning set;5.3462825;0.3052936;-3.8442452;4.222442;2.044102;-1.0435826;IRRE
fillcolor ffffff n;-1.3034763;0.11199067;4.1213484;-5.479935;0.11314628;-1.9505881;-
check that export graphviz treats feature names;-2.5124993;-0.89972144;-3.410504;-1.112936;-1.9312375;1.3146737;TASK
and class names correctly and supports arrays;-0.7005019;-2.1841433;-2.116196;-0.7383951;4.836936;-1.4134817;IRRE
test with feature names;1.4630713;1.5241947;-1.9856911;4.816637;2.7836971;-5.667013;TASK
test with class names;1.3436235;2.7005553;-1.5299182;3.5293138;4.090329;-6.87222;IRRE
check for errors of export graphviz;-2.0114236;2.0560508;-2.0028448;-0.64413756;-4.076327;-0.21940513;CODE
check not fitted decision tree error;1.356494;3.2458427;-5.056934;1.5159103;-0.73498076;-2.0033097;-
check if it errors when length of feature names;-0.48705903;2.1362102;-3.1019564;3.7381644;1.8331223;-3.511746;TASK
mismatches with number of features;3.2302716;0.56243676;-2.5619123;-0.5038174;2.925658;-2.968474;TASK
check error when feature names contains non string elements;-1.4441019;3.5506012;-4.6559105;2.4663663;2.306425;-3.5761755;TASK
check error when argument is not an estimator;0.98992324;6.409283;-3.3589246;4.368701;-3.332534;-0.25170884;-
check class names error;-2.9366252;1.986443;-3.5253153;1.6503397;1.4762098;-5.188033;IRRE
with the current random state the impurity and the threshold;0.5126155;0.523204;0.7151422;1.5017103;1.3483369;1.5542237;IRRE
will have the number of precision set in the export graphviz;1.3834313;0.709456;-0.6796781;-2.609959;-1.487602;0.87516993;IRRE
function we will check the number of precision with a strict;1.7806976;4.6921706;-1.1461684;0.03589267;-1.7509845;-4.465224;CODE
equality the value reported will have only 2 precision and;1.2441475;5.4858747;-2.9454644;-1.3165575;-1.8939927;-3.688089;IRRE
therefore only a less equal comparison will be done;1.877773;6.207128;1.022887;2.407269;1.0723634;-2.543547;CODE
check value;-0.82001954;7.497873;2.820367;0.20838943;0.61457735;-8.601886;IRRE
check impurity;-2.6961715;3.6433864;-0.08943368;1.3851413;-0.30426696;-4.2640767;-
check impurity;-2.6961715;3.6433864;-0.08943368;1.3851413;-0.30426696;-4.2640767;-
check threshold;2.4462194;4.799564;1.6346735;1.6956357;0.39085394;-4.8827186;-
testing that leaves at level 1 are not truncated;0.1037785;6.497543;-2.3400745;5.6080794;-0.3360115;-2.8043544;IRRE
testing that the rest of the tree is truncated;0.2166889;4.284279;-0.24587822;3.7979836;0.24812347;-2.9896924;IRRE
check that export graphviz treats feature names;-2.5124993;-0.89972144;-3.410504;-1.112936;-1.9312375;1.3146737;TASK
and class names correctly and supports arrays;-0.7005019;-2.1841433;-2.116196;-0.7383951;4.836936;-1.4134817;IRRE
mostly smoke tests;1.5590973;-0.16509195;2.3155525;5.2998395;-0.5773903;-4.419874;IRRE
check correctness of export graphviz for criterion entropy;1.0143583;1.2252328;-4.208108;-1.030454;-0.44316933;1.4052954;CODE
test export code;-1.7351718;2.7558002;-1.8634802;3.0911908;-1.0140438;-4.8193383;IRRE
mostly smoke tests;1.5590973;-0.16509195;2.3155525;5.2998395;-0.5773903;-4.419874;IRRE
check correctness of export graphviz for criterion gini;-0.0037121195;2.341511;-2.8505905;-0.28196165;-0.4834045;0.82925487;CODE
test export code;-1.7351718;2.7558002;-1.8634802;3.0911908;-1.0140438;-4.8193383;IRRE
testing if not fitted tree throws the correct error;0.37592164;6.1819882;-4.863078;3.7503724;-1.5062063;-3.0693588;IRRE
check the aggregates are consistent with the returned idx;2.3613605;7.1471057;-2.507526;0.5808891;1.879684;-1.4342846;IRRE
check if the cumulative weight is less than or equal to the target;3.7371485;4.6289086;0.6712126;1.1979717;-0.4168984;-1.9943482;IRRE
depending on t idx low and t idx;0.76549304;2.8522375;0.32210535;-1.7318;3.513552;0.6946183;TASK
check that if we add the next non null weight we are above the target;2.6528876;5.7202487;-0.43837184;1.6537179;-0.41658947;1.231426;TASK
and not below the target for t idx low;-1.3882074;1.5919955;-0.22430055;-0.31870508;-0.14636135;1.9765031;CODE
monotonic increase constraint it applies to the positive class;0.38570645;1.119585;-0.7268863;-0.554392;2.9231255;2.0085454;CODE
monotonic decrease constraint it applies to the positive class;0.9261177;1.609077;-0.9981613;-0.3712889;2.282544;2.5848956;CODE
build a regression task using 5 informative features;4.4020233;-2.9884005;2.867131;1.9427365;2.6431758;-0.75369453;TASK
monotonic increase constraint;-0.35652763;2.3248985;1.285932;-1.5285082;0.8391904;1.8865873;CODE
y incr should always be greater than y;-0.4642704;3.3112662;1.1349305;-2.2339745;-3.1197083;-2.7514029;-
monotonic decrease constraint;0.4107649;3.0918577;0.6531073;-1.4125338;0.27435407;2.7129707;CODE
y decr should always be lower than y;-0.32773596;3.4317496;-0.06638575;-1.8487278;-3.8255806;-2.0996075;-
check monotonicity on children;0.71614456;4.4006557;2.2081592;1.2231646;1.3675199;-2.731693;-
check bounds on grand children filtering out leaf nodes;1.9051155;2.7354815;1.1242555;-0.20067781;0.860048;0.302366;IRRE
check that positive monotonic data with negative monotonic constraint;2.7549627;4.437301;-1.0867376;-1.9611017;0.5737797;-0.32948646;CODE
yield constant predictions equal to the average of target values;7.2097354;0.03713725;0.32518774;2.7411406;-2.2733798;0.43595022;IRRE
swap monotonicity;-1.1473882;2.3772697;2.4029634;-2.0990422;1.109783;0.40002137;-
adaptation from test nodes values in test monotonic constraints py;3.1945498;2.1512337;-4.5203586;1.0301031;-0.43376952;0.01847364;IRRE
in sklearn ensemble hist gradient boosting;3.8445337;-5.7068124;-3.6757057;-0.64409965;-0.3678179;-0.12180701;-
build a single tree with only one feature and make sure the node;0.10110143;0.54502326;0.67170835;1.1967347;3.498156;0.4725544;TASK
values respect the monotonicity constraints;1.7101688;2.648324;-1.4185311;-1.2232226;1.8502107;2.8972492;IRRE
considering the following tree with a monotonic 1 constraint we;-0.28577363;2.6987216;0.6267499;-1.1875988;3.5406356;0.30600685;CODE
should have;-2.265133;0.7626931;2.3598242;2.177748;-1.4643421;-0.0074916035;-
root;-4.979902;-2.0713117;4.5406322;-0.22823495;-0.58503574;-3.7213576;-
a b;-1.3917359;0.4643205;5.588723;-0.6028424;2.287523;-4.6414313;-
c d e f;-0.90263724;-0.70562994;4.6731234;-0.011767921;-0.34517583;-2.8826332;CODE
a root b;-3.6445305;0.37533358;3.3839357;-1.7680765;1.638595;-4.024553;-
c d a b 2 e f;-0.7901678;0.47586814;3.7010472;-2.2276163;1.5148449;-3.2374644;-
no max leaf nodes default depth first tree builder;-2.1708434;1.4046384;-0.40313983;-1.4769129;0.19188264;3.2185764;CODE
max leaf nodes triggers best first tree builder;-0.2305222;0.616132;0.35608917;2.015523;1.8470871;2.301296;-
node value tree value i 0 0 unpack value from nx1x1 array;0.9672623;4.089434;-3.7883627;-6.9127913;0.7985527;-1.229154;IRRE
while building the tree the computed middle value is slightly;0.9446622;2.383891;0.24127874;-1.6205517;-1.7678692;-0.9680405;IRRE
different from the average of the siblings values because;2.2670906;2.3569038;3.0144496;-1.3312688;-0.26803246;-2.4720798;IRRE
sum right weighted n right;1.0187731;1.9146335;1.8001622;-2.5197115;-0.054911878;-1.9061711;-
is slightly different from the value of the right sibling;-1.0234683;2.8474658;2.7049367;-1.9654554;1.0803564;-2.605969;IRRE
this can cause a discrepancy up to numerical noise when clipping;2.2924373;2.0229087;-3.6037533;-0.6962861;-3.651732;1.2215514;CODE
which is resolved by comparing with some loss of precision;3.9151723;2.8242624;-2.709848;1.9657868;-1.5268086;-2.5060544;-
leaf nothing to do;-5.286601;1.1933944;2.7424061;1.5683924;-2.4384696;-0.90990126;TASK
split node check and update bounds for the children;1.0744877;3.6542675;1.8492557;-0.7373348;2.5860002;-0.7637623;CODE
unpack value from nx1x1 array;0.88757503;4.0137267;-1.9430534;-7.291035;0.3743544;-0.2863298;IRRE
feature without monotonicity constraint propagate bounds;2.9440973;0.0036044517;-1.7145241;-0.3509024;2.1140578;5.46938;CODE
down the tree to both children;-2.4778104;-0.6687867;6.079792;0.57562655;0.64485675;-0.8736233;CODE
otherwise with 2 features and a monotonic increase constraint;1.7324306;1.2835027;0.38151127;-0.7302429;3.0948288;2.780741;CODE
encoded by 1 on feature 0 the following tree can be accepted;-1.9225895;-0.09562629;-3.2477386;-1.5711846;4.721324;-0.80270714;TASK
although it does not respect the monotonic increase constraint;-1.2001922;2.8799798;-1.1015425;-0.38219562;0.29898566;3.9226723;CODE
x 0 0;-2.2664022;2.3470383;3.200267;-5.182199;-0.97615284;-3.8519342;-
value 100;-0.50751144;2.9738843;3.6514246;-2.2135882;0.44940343;-5.092613;IRRE
x 0 1 x 1 0;0.33542383;2.9852092;2.076045;-7.889361;0.19041118;-3.2939334;-
value 50 value 150;-0.046299104;3.464034;3.2025704;-2.8529797;0.85632;-4.6884036;IRRE
leaf leaf leaf leaf;-1.7165506;-0.3845943;3.6361039;-1.0792896;1.655555;-1.7788022;-
value 25 value 75 value 50 value 250;1.3955095;3.493608;2.369648;-3.4202552;1.9169886;-5.871076;IRRE
feature with constraint check monotonicity;2.0926325;2.9900243;-1.6349505;0.18336765;1.7178371;0.84497756;CODE
propagate bounds down the tree to both children;-1.2739924;0.14177544;3.0374553;0.73813266;2.6996005;1.9839753;CODE
feature with constraint check monotonicity;2.0926325;2.9900243;-1.6349505;0.18336765;1.7178371;0.84497756;CODE
update and propagate bounds down the tree to both children;-1.2776649;0.76570624;2.154998;0.90798116;2.7451696;1.9692801;CODE
else pragma no cover;-3.5999572;1.521687;2.0370367;1.7820296;0.29938146;-0.27886724;-
check that assert nd reg tree children monotonic bounded can detect;1.0787573;4.320746;-4.897021;1.4606283;3.8272119;-1.5595397;CODE
non monotonic tree predictions;3.6949065;-1.9095502;0.2538414;2.7324126;2.0613952;-0.9397398;-
check that assert nd reg tree children monotonic bounded raises;0.87626046;3.199547;-4.0109735;1.0885351;3.3011067;-1.0077438;CODE
when the data and therefore the model is naturally monotonic in the;3.7561224;0.26810217;1.7053097;2.587225;0.8282196;1.9871806;CODE
opposite direction;-2.768146;-0.37520006;6.08843;-1.1493927;-0.799826;-1.0793711;-
for completeness check that the converse holds when swapping the sign;-2.607403;5.078032;-1.310005;2.2236495;2.5992217;-1.0227927;CODE
build tree with several features and make sure the nodes;1.1380653;-1.4599783;1.5949265;0.111837186;4.692259;0.13776638;TASK
values respect the monotonicity constraints;1.7101688;2.648324;-1.4185311;-1.2232226;1.8502107;2.8972492;IRRE
considering the following tree with a monotonic increase constraint on x 0;-0.983088;1.9995801;0.32311365;-1.6508044;1.7439399;1.3718066;CODE
we should have;-1.7660123;0.32393333;2.2904606;2.6687212;-2.2507136;1.1321292;-
root;-4.979902;-2.0713117;4.5406322;-0.22823495;-0.58503574;-3.7213576;-
x 0 t;-1.2203418;1.7967412;3.6682909;-4.015764;-1.6785655;-3.0365255;-
a b;-1.3917359;0.4643205;5.588723;-0.6028424;2.287523;-4.6414313;-
x 0 u x 1 v;-2.3223903;0.9947395;1.9512435;-6.3555803;-0.051252134;-2.6177013;-
c d e f;-0.90263724;-0.70562994;4.6731234;-0.011767921;-0.34517583;-2.8826332;CODE
i a root b;-3.0507944;-0.26975906;2.482372;-1.5053741;0.94616073;-2.9477386;-
ii c a d a b 2;-1.7861843;1.0156647;3.0278146;-1.853531;2.6493163;-3.2183247;-
iii a b 2 min e f;-2.4781814;1.7215774;3.4607701;-1.0431116;1.9254555;-2.2249851;-
for iii we check that each node value is within the proper lower and;0.7960616;2.007639;-0.38626513;-2.0956254;2.089007;-1.7035751;IRRE
upper bounds;-1.2299852;1.7199814;4.5332704;-0.52370745;0.04139993;-3.4395766;-
no max leaf nodes default depth first tree builder;-2.1708434;1.4046384;-0.40313983;-1.4769129;0.19188264;3.2185764;CODE
max leaf nodes triggers best first tree builder;-0.2305222;0.616132;0.35608917;2.015523;1.8470871;2.301296;-
parents higher than children;-1.9130851;0.77983165;3.1755939;0.35901862;0.06831328;-1.9309341;-
these trees are always binary;-1.132962;-0.47924864;-1.1143099;-1.8022057;3.0385997;-3.1372092;IRRE
parents are centered above children;-2.1746762;0.6872703;4.979768;-0.7192022;-0.5711086;0.9325848;-
test that x values are unique per depth level;4.9137506;4.74773;0.6280604;-2.4784806;2.4911368;-2.1481261;IRRE
we could also do it quicker using defaultdicts;1.5980982;-2.95977;0.28435174;0.5183569;3.6627347;-0.98415864;CODE
reached all leafs;-0.5060724;1.3690603;3.5989645;1.1114596;-1.9016081;-1.2310375;-
toy sample;0.09531039;-1.1268612;5.4498596;1.2328323;2.0021768;-3.605327;-
also load the iris dataset;1.5464042;-4.3465104;-0.13598996;-1.1130621;-0.53984874;0.6428218;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
also load the diabetes dataset;3.756223;-3.7747552;1.0352626;0.72781825;0.2249242;0.34326255;IRRE
and randomly permute it;1.3034208;-0.78062826;4.5634737;-1.162895;3.7469428;-1.1495706;IRRE
nb despite their names x sparse are numpy arrays and not sparse matrices;3.1653414;-1.0741252;-5.304615;-5.8182797;-2.458588;1.318105;IRRE
check classification on a toy dataset;5.1126094;-2.951145;-0.18973042;2.355515;4.227479;-4.308819;IRRE
check classification on a weighted toy dataset;6.421837;-1.8419626;-0.9312348;2.303028;3.7475727;-2.1499596;IRRE
check regression on a toy dataset;5.150592;0.2063876;0.26282418;2.5565667;-1.4738402;-4.5264344;IRRE
make target positive while not touching the original y and;-0.85063046;3.7046163;2.7366238;0.36699024;-2.5834215;-0.20511545;CODE
true result;-1.3928273;2.3148544;3.4829438;2.4708986;-0.45267805;-4.1667686;IRRE
check on a xor problem;-1.4666467;3.4642107;-0.81545544;-2.4309764;-1.3119767;-2.3862526;-
check consistency on dataset iris;4.410563;1.6984775;-3.7309673;1.764228;0.5863222;-1.2973349;IRRE
check consistency of overfitted trees on the diabetes dataset;5.284501;-0.25291887;-1.725638;2.857648;0.8653386;-0.74524367;IRRE
since the trees will overfit we expect an mse of 0;-0.159527;-0.055023957;-1.7240828;3.1269948;-1.2007902;-0.77278346;-
check consistency of trees when the depth and the number of features are;3.5208619;1.1695166;-0.35404292;0.22114967;3.2508929;-0.85978746;TASK
limited;-2.9391248;-1.7561442;5.3315425;0.66198236;1.5351555;-2.0222106;-
less depth higher error;1.8347147;2.5743601;-1.0251052;0.620302;-0.559912;0.44741565;-
diabetes data shape 0 2 7 so it can t overfit to get a 0 error;3.5138361;4.372462;-2.620969;-2.8327007;-2.3165793;-1.9866911;-
predict probabilities using decisiontreeclassifier;3.563986;-4.0401855;-1.4967233;1.8637981;3.2505047;-1.4154991;IRRE
check the array representation;0.5167191;4.929946;0.7467875;-3.2048502;0.12997538;-6.3114066;-
check resize;-1.5501777;3.7885537;3.4166963;-0.1774779;-2.892483;-0.63986707;-
check when y is pure;0.16165513;3.7058432;-1.688578;-0.6183284;-0.5101512;-4.218058;-
check numerical stability;2.9296017;3.3752136;-1.2311392;-0.8599612;-3.0935752;-2.0030355;-
check variable importances;2.2828906;2.7918928;1.014699;2.1984897;0.9824502;-1.9348829;CODE
check on iris that importances are the same for all builders;-2.9190462;-1.0160848;-0.6790951;1.2561004;1.4865026;1.5007718;CODE
check if variable importance before fit raises valueerror;3.6156554;4.1501136;-4.138437;2.2076926;-3.443076;0.18707563;CODE
check that gini is equivalent to squared error for binary output variable;0.6985538;2.8458586;-3.8768182;-1.2864857;-2.0380607;-1.7897705;IRRE
the gini index and the mean square error variance might differ due;0.5529789;1.7987945;-1.2232318;0.5112672;-2.007764;0.8993134;CODE
to numerical instability since those instabilities mainly occurs at;1.7952384;0.12051449;-1.444606;-0.6001233;-2.7873013;2.011601;CODE
high tree depth we restrict this maximal depth;-0.19910973;-0.3625339;0.69416803;-0.5730917;2.4641688;2.2800772;CODE
check max features;2.2254531;1.3994093;-0.290914;2.4163222;2.0266683;-2.493034;TASK
test that it gives proper exception on deficient input;0.8835555;6.4445596;-3.6373036;5.851941;-0.16324186;-6.538132;CODE
predict before fit;5.8245707;0.074861325;1.4565655;3.8199458;-0.82856554;0.6626794;CODE
x2 2 1 1 wrong feature shape for sample;2.078521;1.2824807;-2.368883;-4.463514;-2.2094111;0.50616956;TASK
wrong dimensions;-1.3301921;1.4984231;2.1325836;-4.6654153;-3.1783528;-0.51336664;META
test with arrays that are non contiguous;3.723219;6.8825216;0.43302906;-0.08703756;-0.00723813;-4.5970235;IRRE
predict before fitting;6.0397005;0.16456704;1.0266533;3.2430177;-1.6042712;1.2899288;CODE
predict on vector with different dims;5.9016232;-0.69891286;-0.7759476;-3.193752;-0.56644696;1.7518512;-
wrong sample shape;2.756348;2.8180196;0.78306174;-3.6487699;-3.2565472;-1.7089007;META
apply before fitting;1.0095394;1.7962911;0.3329779;1.885419;-0.041620534;2.5256817;CODE
non positive target for poisson splitting criterion;2.9025233;2.7997162;-3.1435156;1.8578576;-0.0557031;3.572678;CODE
test that all class properties are maintained;0.88569766;2.9621108;-2.1470726;7.2731357;3.1398203;-1.952317;CODE
check estimators on multi output problems;5.0940294;3.5321567;-1.8352004;2.998097;-1.6540823;0.40711248;IRRE
poisson doesn t support negative y and ignores null y;-2.0009081;5.63123;-1.2183609;-0.23961806;-3.882871;-0.31316516;CODE
toy classification problem;3.2617123;-1.8673244;3.5578592;-0.2864546;4.6387258;-3.084535;IRRE
toy regression problem;3.1251667;0.85494334;3.1352963;0.12750182;-2.9496891;-3.4344988;-
test that n classes and classes have proper shape;4.293302;1.6689326;-0.76453894;1.0611542;3.2756467;-3.3880591;IRRE
classification single output;6.1762466;-2.9361827;1.4179972;0.3883535;4.957419;-1.6149068;IRRE
classification multi output;6.271925;-3.1803617;1.9575181;-0.90821844;5.6696854;-1.1859078;IRRE
check class rebalancing;2.0159194;4.309789;-0.12480557;3.5549254;1.5532365;-1.4736823;CODE
check that it works no matter the memory layout;-4.908209;2.2429755;-2.2566197;-1.2584411;-2.0457156;2.4444945;-
nothing;-3.8851964;-0.8987027;3.7201903;0.9519889;-2.8300657;-2.05024;-
c order;-3.1184838;0.86781794;4.539902;-2.8451579;2.3424346;-3.6906772;-
f order;-2.292825;0.71285135;4.6299286;-1.3533025;1.9866292;-2.4007716;CODE
contiguous;0.7975582;2.2487135;5.957218;-3.5392473;2.9711444;-1.4591526;-
csr;-1.9517441;-2.1731985;2.3376567;0.095433205;1.0228496;-3.156976;-
csc;-1.6857789;-3.0206583;2.599354;0.03915951;1.5310364;-3.5949159;-
strided;-2.3499353;-1.07886;2.6548412;0.6789499;0.7450382;-0.85803777;-
check sample weighting;5.8254833;3.3156736;0.29468358;2.3250077;0.8681744;-3.0887642;-
test that zero weighted samples are not taken into account;3.2537463;6.342941;-3.2627213;1.6213444;-1.4410359;-2.3330746;IRRE
test that low weighted samples are not taken into account at low depth;4.4327917;4.71062;-3.1075497;2.383555;-0.39716265;-1.0706233;IRRE
ample weight y 2 0 51 samples of class 2 are still weightier;2.6229079;1.072004;-2.9713304;0.8936563;-0.85124844;0.41733456;TASK
ample weight y 2 0 5 samples of class 2 are no longer weightier;2.4913652;1.6370296;-3.4145725;-0.111931816;-1.9215637;0.5038631;IRRE
assert clf tree threshold 0 49 5 threshold should have moved;1.3815178;4.0733123;-4.952693;2.726242;-1.0289488;-1.746591;CODE
test that sample weighting is the same as having duplicates;4.8944016;4.0523796;0.34815043;3.007413;2.583822;-2.7806816;IRRE
check sample weighting raises errors;4.925187;4.4187064;-4.6817236;4.375213;-1.3622944;-1.9309417;CODE
test that class weights resemble sample weights behavior;5.378125;1.9641204;-1.7014725;4.4699416;1.8347902;-1.2798078;IRRE
iris is balanced so no effect expected for using balanced weights;0.88794667;3.4332461;-2.1008587;0.110785276;-2.4686332;1.8834249;CODE
make a multi output problem with three copies of iris;1.1664597;2.882182;0.71608;-3.740641;2.201678;-1.4765903;IRRE
create user defined weights that should balance over the outputs;4.502186;1.9039869;1.4588318;-1.7463223;0.75755054;2.6221657;IRRE
check against multi output auto which should also have no effect;0.07785529;6.259376;-1.375619;2.7479906;-0.3695138;-2.1551023;IRRE
inflate importance of class 1 check against user defined weights;3.549155;2.7990115;-2.0915527;4.164784;1.9934494;2.2217896;CODE
check that sample weight and class weight are multiplicative;5.038449;3.0770671;-2.7447648;0.95371515;2.55848;-1.9821092;IRRE
test if class weight raises errors and warnings when expected;2.3898737;4.917046;-4.9707036;5.6684103;-0.5170775;-2.9963908;IRRE
incorrect length list for multi output;0.7581707;2.1517816;-1.3777115;-3.0345297;-0.6513333;-3.4852924;IRRE
test greedy trees with max depth 1 leafs;3.3218238;2.6263478;0.2662795;1.5018919;2.110157;-2.5927887;IRRE
test precedence of max leaf nodes over max depth;1.8660803;4.485045;0.053680383;1.8083799;2.0946486;-0.4783919;IRRE
ensure property arrays memory stays alive when tree disappears;-1.3468611;3.1944788;-0.18001792;4.2423615;1.1903518;3.35456;-
non regression for 2726;1.1020153;0.2658166;-2.9417164;-0.29203725;-1.7890962;-3.5771127;CODE
if pointing to freed memory contents may be arbitrary;-3.664708;1.173776;-1.8974819;2.1895509;1.6466036;2.7353776;CODE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn pull 32259;-3.0751693;-9.668662;-4.8922367;-1.9786463;-3.6258166;-5.1452813;CODE
make sure that almost constant features are discarded;1.6358094;1.1863769;-2.9238086;3.8535118;-0.071034096;3.5180516;TASK
feature treshold 1e 7 is defined in sklearn tree partitioner pxd but not;-2.111214;-1.8835467;-7.825136;-1.2604798;0.46673256;1.3166517;CODE
accessible from python;-3.808997;-6.2753615;0.6528256;-0.9941718;-2.5320446;-3.840342;CODE
x 0 feature threshold almost constant feature;3.4964182;0.40040016;-2.6989386;-1.4465318;-1.6277192;2.8529036;TASK
the almost constant feature should not be used;1.1373312;2.1001105;-2.5312612;2.210216;-2.9697182;3.1679397;TASK
other feature should be used;-3.053673;-3.0900903;3.3228624;4.205058;3.1041374;3.1067936;TASK
do not check extra random trees;0.27692202;1.1006613;-1.2988166;4.4261622;2.2877207;-2.3638628;IRRE
test if the warning for too large inputs is appropriate;2.0082517;4.760155;-1.5811272;3.876181;-1.5108278;-4.093327;CODE
sanity check we cannot request more memory than the size of the address;-3.701494;2.2462838;-0.8962265;1.2254131;-1.3075528;0.31772593;TASK
space currently raises overflowerror;0.055383664;2.2427652;-2.7533748;-0.020306405;-3.159249;-3.1932633;CODE
non regression test memoryerror used to be dropped by cython;0.72165143;2.554174;-5.6263094;2.6465049;-5.243265;-1.5623032;IRRE
because of missing except;-2.6924522;1.1282119;1.2880596;1.4861999;-0.11220994;-0.70996815;CODE
gain testing time;3.1373074;1.6641039;0.7303996;5.8330665;-0.69474876;-3.4125671;IRRE
check the default depth first search;-1.079684;3.5514164;1.3707315;-0.13877049;-0.11638638;0.7419514;CODE
due to numerical instability of mse and too strict test we limit the;3.286203;3.2696826;-4.8084745;3.8907385;-2.763178;-0.94460845;IRRE
maximal depth;0.6857025;0.06690442;4.9858246;-2.9583268;1.1656129;0.7790866;-
check max features;2.2254531;1.3994093;-0.290914;2.4163222;2.0266683;-2.493034;TASK
check min samples split;7.205019;4.9698606;-0.19147845;0.103793144;1.4793277;-3.3635063;-
check min samples leaf;4.0319576;3.5439909;-0.07318703;0.67301166;0.58846396;-2.2204518;-
check best first search;-0.60920084;-0.8530097;2.9947026;2.699346;1.2003677;-2.2080557;-
n samples set n feature to ease construction of a simultaneous;5.9385233;-0.93317866;1.9684744;-1.450543;4.533927;1.2043241;CODE
construction of a csr and csc matrix;3.105299;-1.0535357;-2.0691373;-5.0618367;1.8221542;1.4013737;CODE
generate x y;-0.15011641;0.48927674;2.9184213;-4.976393;-0.14241298;-3.975813;-
ensure that x sparse test owns its data indices and indptr array;3.977811;3.4156208;-5.906208;-0.008873609;-0.37115553;0.7372428;IRRE
ensure that we have explicit zeros;0.072493464;4.6367164;-2.147592;-2.630271;-0.9660227;-2.361895;-
perform the comparison;2.2927473;5.0827107;4.332525;2.5516388;0.593954;-7.642672;CODE
1st example;-1.5819685;-1.2373979;4.9861374;1.8349344;2.1229663;-2.1043172;-
2nd example toy dataset;4.7448173;-4.8429933;2.113434;-2.1613846;1.8984008;-2.8449616;IRRE
was failing before the fix in pr;-4.78719;1.3216704;-2.9985363;4.238301;-2.639825;-1.0448874;CODE
https github com scikit learn scikit learn pull 32280;-3.2047207;-10.180698;-4.4661207;-1.082522;-3.6152174;-4.760176;CODE
assert that leaves index are correct;1.6330441;6.8996625;-2.6570997;1.0966794;0.9156962;-3.7413895;CODE
ensure only one leave node per sample;3.3703241;4.3682976;1.6513797;0.96920913;2.819554;1.3800259;-
ensure max depth is consistent with sum of indicator;4.635993;4.6844907;0.7192126;-1.4916617;0.1570115;3.0996675;CODE
currently we don t support sparse y;0.9617135;-2.9819047;-1.6123086;-1.329089;-1.5835601;3.6702728;IRRE
test mae where sample weights are non uniform as illustrated above;4.3179073;3.733951;-3.280967;1.9787828;-0.093268834;-0.45188856;IRRE
test mae where all sample weights are uniform;4.9671607;3.3054888;-2.5872743;2.7473993;0.66348374;-0.30191523;IRRE
test mae where a sample weight is not explicitly provided;3.5448785;4.8677564;-4.2498;4.300554;-0.025794592;-1.2977501;TASK
this is equivalent to providing uniform sample weights though;5.050617;-0.20645662;0.15019834;1.7643842;3.751356;4.139245;CODE
the internal logic is different;-3.7136447;1.5899484;1.9190257;3.277326;1.6957071;-1.0075729;CODE
max depth 1 stop after one split;0.10104572;4.2921553;3.1205418;-1.6091759;0.73112017;-0.15425794;-
let s check whether copy of our criterion has the same type;1.1553271;5.4755826;-3.7562006;2.8794818;4.147195;-2.194267;CODE
and properties as original;-3.6534355;-2.0663555;2.460502;1.8387656;3.872348;0.6157676;-
try to make empty leaf by using near infinite value;-1.6638244;5.268905;2.1582813;-1.1755217;-1.9450517;-1.7484313;IRRE
single node tree;0.17089444;-1.427312;2.867164;-1.2605771;3.635297;0.32267272;-
pruned single node tree;-0.13050278;-0.054688428;1.0879524;-1.715002;1.7884047;1.3633126;CODE
generate trees with increasing alphas;0.83892214;-1.381495;1.3027735;-1.6869727;1.0657077;-0.9847521;-
a pruned tree must be a subtree of the previous tree which had a;-2.4986632;0.67843276;0.4053046;0.47303113;3.5190256;-0.056445643;TASK
smaller ccp alpha;-0.98526883;-0.54313695;0.65817976;-2.0435104;0.20864323;0.8771688;-
is a leaf;-2.2894065;-0.72119826;3.718221;1.0257537;1.1652256;-0.7340733;-
not a leaf;-2.6374116;-0.3259466;3.4364045;1.2237302;-0.03741103;-1.3008546;-
test that sum y pred sum y true on training set;5.0886116;2.5038993;-0.03452592;3.637576;1.9351635;-5.0821157;IRRE
this works if the mean is predicted should even be true for each leaf;4.210369;2.1622868;2.0042474;3.393108;-0.9470426;0.03299828;CODE
mae predicts the median and is therefore excluded from this test;2.345191;2.8907762;-2.9038289;4.92748;-2.7747388;-1.8140572;CODE
choose a training set with non negative targets for poisson;4.858689;0.8224451;0.19825098;2.4430492;1.2788182;2.5919414;IRRE
test that sum y 0 and therefore y pred 0 is forbidden on nodes;-0.25846657;5.45274;-2.9240987;0.21564552;-1.4169948;-4.913981;CODE
note that x 0 0 is a 100 indicator for y 0 the tree can;-1.2917593;1.4232714;0.022864157;-2.8781233;-0.22684583;-2.631065;TASK
easily learn that;0.63485014;-5.2776523;2.4814575;2.2678604;0.5702506;-0.8165817;-
whereas poisson must predict strictly positive numbers;1.9888029;2.0102303;0.2648438;2.252123;-0.60404897;-0.2516092;-
test additional dataset where something could go wrong;4.316285;4.186888;-2.0701694;4.8859277;0.38473967;-5.540433;IRRE
some excess zeros;-0.506035;2.6977744;1.2863759;-1.9660889;-1.7956321;-4.7862134;-
make sure the target is positive;-1.6334172;3.0172682;1.267523;3.9385777;-2.859409;-1.7611367;-
for a poisson distributed target poisson loss should give better results;3.5679288;1.0043685;0.07697495;3.9084883;-1.8955979;1.5947528;IRRE
than squared error measured in poisson deviance as metric;1.3667994;1.1492103;-1.6292604;1.2022321;-3.708637;2.6191926;-
we have a similar test test poisson in;1.69734;5.019711;2.0472314;4.4791083;0.008577143;-4.0311356;IRRE
sklearn ensemble hist gradient boosting tests test gradient boosting py;3.2348437;-3.5459917;-5.864527;2.1557574;-1.6047616;-1.810725;IRRE
we create a log linear poisson model and downscale coef as it will get;4.048758;0.33534473;2.8559458;0.5711905;-0.90210044;3.9947443;IRRE
exponentiated;-4.041523;-0.73016334;2.3329694;-1.4224738;0.75904506;-2.290021;-
we prevent some overfitting by setting min samples split 10;6.3322315;0.40127286;-2.0864456;2.789724;1.6521986;1.187921;IRRE
squared error might produce non positive predictions clip;1.7760448;0.96997863;-4.224978;2.7371223;-5.7971563;-0.15086433;CODE
as squared error might correctly predict 0 in train set its train;2.9287794;1.5248697;-2.8055127;1.355453;-2.7652636;-1.1636245;IRRE
score can be better than poisson this is no longer the case for the;1.4636216;2.8646142;1.4703192;4.444364;-0.37790743;-0.8174303;CODE
test set;3.2042842;3.4155014;2.6115146;2.4797702;2.3319228;-7.5599284;IRRE
min samples split 1 0 is valid;4.5028515;4.4453616;-3.480942;-2.433221;0.53637564;-2.210311;-
min samples split 1 is invalid;3.9873545;3.7887323;-3.8057458;-1.6950374;-0.06486627;-1.9727354;OUTD
missing values necessarily are associated to the observed class;3.3447835;3.9206145;-2.8983471;2.6007028;1.8848644;-0.39478287;IRRE
max depth is used to avoid overfitting and also improve the runtime;1.1984313;-1.7452341;0.45849693;0.43985015;1.8948262;2.5392191;CODE
of the test;0.58328503;0.903374;2.8214302;5.3150077;0.5478527;-6.8828216;IRRE
a single extratree will randomly send missing values down the left or right child;0.5806555;1.9170369;-0.31622806;1.0039384;2.4388;-0.9093261;IRRE
and therefore will not necessarily have the same performance as the greedy;2.2953963;1.8912823;2.049532;3.7300248;3.404517;1.5448542;CODE
handling of missing values;1.6153858;6.317785;-0.047970414;0.5203303;1.6979834;-2.9136531;IRRE
create dataset with missing values;5.0277915;1.5419114;-0.31941676;-2.2649596;1.4748728;-2.0261965;IRRE
zero sample weight is the same as removing the sample;1.9528203;4.325454;-1.9079556;-0.2438449;-1.376663;0.8790548;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 27268;-3.1559293;-9.862951;-5.9770837;-0.29151297;-5.13097;-5.272405;CODE
uninitialised memory would lead to the two pickle strings being different;-2.4775126;1.8094656;-2.1355865;0.94814044;0.3168548;-1.5815097;IRRE
missing values will go left for greedy splits;3.3453438;4.3881164;-0.19106165;-1.3635317;0.4006667;-1.5922457;IRRE
missing values will go right for greedy splits;4.299413;4.0822406;-0.15165344;-1.0085163;0.9476;-1.4712696;IRRE
assert all impurity 0 impurity min mse should always be positive;0.22566742;4.8748403;-5.3930836;2.6159601;-0.37577605;-1.2159184;CODE
note the impurity matches after the first split only on greedy trees;0.5435524;0.75706667;-1.834993;0.17488557;3.2214458;0.67868745;TASK
see https github com scikit learn scikit learn issues 32125;-1.9458388;-10.907395;-6.6179514;-1.0374107;-4.7001204;-4.912156;CODE
check the impurity match after the first split;0.4091053;5.2828846;-0.5245257;-0.19618237;2.4678206;-2.438973;-
find the leaves with a single sample where the mse should be 0;3.1490617;4.0422387;0.27497885;-1.5600642;-0.45536432;-2.3029716;-
assert all impurity 0 impurity mse should always be positive;-0.64246774;4.598377;-5.1305814;3.1628895;-0.49058732;-1.5238338;CODE
fmt off;-2.928697;0.5681491;1.6145159;0.77934104;-1.6590598;-1.6645807;-
no black reformatting for this specific array;-0.5047825;2.981518;-1.8179662;-5.299441;-1.452249;-1.3610208;CODE
fmt on;-3.0511034;-1.4836843;2.9995122;0.24887353;-0.54857504;-2.728102;-
create a tree with root and two children;-2.7357109;-0.42112342;3.1580076;-1.7318541;3.5313609;-1.2494285;IRRE
only keeping one child as a leaf results in an improper tree;-2.3369706;4.208983;0.9580332;2.56742;1.2128278;0.102541104;IRRE
fmt off;-2.928697;0.5681491;1.6145159;0.77934104;-1.6590598;-1.6645807;-
no black reformatting for this specific array;-0.5047825;2.981518;-1.8179662;-5.299441;-1.452249;-1.3610208;CODE
fmt on;-3.0511034;-1.4836843;2.9995122;0.24887353;-0.54857504;-2.728102;-
large number of zeros and otherwise continuous weights;3.4556305;1.1790338;-0.3666346;-1.3767666;-1.3774695;1.2869211;CODE
non regression test for https github com scikit learn scikit learn issues 32178;0.4088047;-4.512394;-8.796351;3.371613;-6.775419;-6.238337;CODE
the important thing here is that we try several trees where each one tries;-1.0528791;-1.4275857;2.9036205;3.079875;1.4997509;-1.647054;CODE
one of the two features first the resulting tree should be the same in all;-0.79954505;0.49764186;1.0606619;0.49031124;3.971939;0.523495;TASK
cases the way to control which feature is tried first is random state;-0.021050515;1.5580825;1.2096802;6.5315967;2.9170055;1.3210555;IRRE
twenty trees is a good guess for how many we need to try to make sure we get;0.70896804;-1.0943408;2.6541545;2.0325866;1.5996588;-3.6847348;CODE
both orders of features at least once;0.7285323;-0.31446174;1.4408981;0.21578372;6.389578;2.4891477;TASK
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
gives clearer ids for array api strict devices see 31042 for details;-1.8654629;1.1306229;-3.6173685;-1.8910646;2.2295616;0.57941955;CODE
none results in the default pytest representation;-2.806504;0.49731645;-4.548178;-2.3391664;-2.7380064;1.1817026;IRRE
avoid circular import;-1.1477929;1.0047145;0.059377603;0.4631124;-0.7464821;2.126593;CODE
the dlpack protocol is the future proof and library agnostic;-4.906877;-4.266174;-3.0956867;2.368523;1.6426867;1.0537708;TASK
method to transfer arrays across namespace and device boundaries;0.87683386;-0.38780496;0.6572151;-2.1668665;0.99583364;4.390403;-
hence this method is attempted first and going through numpy is;2.2176034;0.2527059;-2.0741549;-3.3321185;-6.084744;-1.5577852;CODE
only used as fallback in case of failure;-4.4766746;1.6993206;-0.08894686;4.9786;1.7854321;1.370844;CODE
note copy none is the default since array api 2023 12 namespace;-4.7283278;1.4370377;-3.6409514;-0.8068935;-2.202101;0.608198;CODE
libraries should only trigger a copy automatically if needed;-4.1254644;-0.5791186;-3.14765;4.704203;-0.52376646;3.0189219;IRRE
attributeerror occurs when dlpack and dlpack device;-3.9678843;-0.23773183;-6.4198704;-0.5000685;-2.2444065;0.45463783;META
methods are not present on the input array;-1.5171932;2.7317247;0.16641307;0.48925036;-2.530616;-2.5548356;CODE
typeerror and notimplementederror for packages that do not;-3.4196112;1.3466303;-5.9237766;2.2829063;-1.836407;-1.7040874;CODE
yet support dlpack 1 0;-5.738834;-1.7952185;-3.7676213;-0.85138243;-0.69147843;0.4302286;TASK
i e the device copy kwargs e g torch 2 8 0;-4.5123262;-3.997403;0.9667061;-2.6398005;-1.509105;1.0741265;IRRE
see https github com data apis array api pull 741 for;-1.4458609;-2.005119;-1.8338865;-1.3647152;-1.4578822;-0.37489977;CODE
more details about the introduction of the copy and device;-4.7856607;-5.920748;3.2496297;1.5820568;1.6869504;-0.2741477;CODE
kwargs in the from dlpack method and their expected;-1.5284593;-1.3813758;-5.26463;-0.4143868;-0.3587127;1.5881728;CODE
meaning by namespaces implementing the array api spec;-2.3666313;-2.0927818;-1.8701814;-0.007213619;2.2703683;1.316046;TASK
todo try removing this once dlpack v1 more widely supported;-6.597931;0.25051036;-5.925871;-0.83252364;-2.2849178;2.3963947;CODE
converting to numpy is tricky handle this via dedicated function;3.5380352;-0.17986782;-2.5518222;-5.276692;-6.7691026;-0.0047750026;CODE
convert from numpy all array libraries can do this;3.4035082;-1.3291103;-1.9300946;-5.965112;-5.5821505;-0.0045946985;CODE
there is no generic way to convert from namespace a to b;-2.860668;0.77972;-1.9218241;-1.9676667;2.6332483;2.4253113;CODE
so we first convert from a to numpy and then from numpy to b;2.4447525;-1.5056529;-0.24671778;-5.534342;-4.5903044;-1.2475113;CODE
the way to avoid this round trip is to lobby for dlpack;-4.6399007;-2.5298905;-0.8818929;2.02329;-0.32661164;1.8299097;CODE
support in libraries a and b;-3.4279459;-3.0383062;-1.2532245;0.95591164;3.1600037;0.8004713;-
todo update to use array namespace info from array api v2023 12;-3.2622325;0.5817378;-2.2660081;0.69647855;0.5771753;2.633857;CODE
when if that becomes more widespread;-1.7281029;-0.4526883;2.3029954;3.926275;-0.4309471;0.62456876;CODE
pragma no cover;-3.7499998;0.42159036;2.464259;1.0908369;-0.12944427;-0.99521214;-
return the floating dtype with the highest precision;3.2689202;1.4882518;-4.006305;-2.9065242;-3.2129662;-1.645136;CODE
if none of the input arrays have a floating point dtype they must be all;3.3104606;3.6149852;-5.254341;-4.186646;-2.627457;-3.5565443;CODE
integer arrays or containers of python scalars return the default;1.2195046;1.5547118;-3.869297;-3.3872147;-2.796074;-0.6849308;CODE
floating point dtype for the namespace implementation specific;-0.58486533;-1.3871553;-5.772236;-3.106277;-0.034906533;1.207551;CODE
if weights are 1d add singleton dimensions for broadcasting;2.8226588;1.8584411;-1.1421208;-3.0426455;2.1974742;6.330074;CODE
xxx median is not included in the array api spec but is implemented;-0.50015265;1.632906;-2.8046763;-1.7699372;-1.963404;1.7051862;CODE
in most array libraries and all that we support as of may 2025;-1.0352561;-3.751023;-1.4306422;-0.48430943;1.2566109;-0.7953725;-
todo consider simplifying this code to use scipy instead once the oldest;2.3135748;-0.7090923;-3.6434667;-4.628855;-5.066848;-4.5970116;CODE
supported scipy version provides scipy stats quantile with native array api;2.4598277;-3.736513;-4.391945;-3.1384914;-5.4321494;-2.5725465;META
support likely scipy 1 16 at the time of writing proper benchmarking of;3.0724936;-5.1968513;-5.266099;0.016743306;-4.4954486;-3.5636532;-
either option with popular array namespaces is required to evaluate the;-2.2614467;2.2193859;-3.2650988;-1.0617981;0.90528715;0.50169927;CODE
impact of this choice;-2.0151496;-1.2322227;4.6873674;4.2144866;1.9378742;0.51000607;CODE
torch median takes the lower of the two medians when x has even number;-0.33171818;2.8519874;1.5035859;-3.5953581;-3.480478;0.11098881;-
of elements thus we use torch quantile q 0 5 which gives mean of the two;0.6157867;1.7556636;1.8833834;-4.223265;-1.3156413;-1.2642063;IRRE
intended mostly for array api strict which as no median as per the spec;1.5897187;2.1771917;-2.152352;0.02747855;-0.5843922;1.1366142;CODE
as convert to numpy does not necessarily work for all array types;1.5988383;1.7996033;-5.4426847;-5.304313;-7.0543346;-1.0492238;CODE
todo remove this once https github com scipy scipy issues 21736 is fixed;-1.7375021;-3.7057683;-7.199286;-2.557537;-8.140884;-2.6092649;CODE
todo refactor once nan aware reductions are standardized;-0.24020344;1.2829025;-3.2540605;2.8357804;0.27578267;3.0383801;TASK
https github com data apis array api issues 621;-2.7905107;-0.3584092;-3.4579277;-1.5104668;-3.4507518;-1.1061215;CODE
replace infs from all nan slices with nan again;1.2821386;2.9277577;-0.8491151;-2.5657256;-3.4712608;-0.78470385;CODE
todo refactor once nan aware reductions are standardized;-0.24020344;1.2829025;-3.2540605;2.8357804;0.27578267;3.0383801;TASK
https github com data apis array api issues 621;-2.7905107;-0.3584092;-3.4579277;-1.5104668;-3.4507518;-1.1061215;CODE
replace infs from all nan slices with nan again;1.2821386;2.9277577;-0.8491151;-2.5657256;-3.4712608;-0.78470385;CODE
todo refactor once nan aware reductions are standardized;-0.24020344;1.2829025;-3.2540605;2.8357804;0.27578267;3.0383801;TASK
https github com data apis array api issues 621;-2.7905107;-0.3584092;-3.4579277;-1.5104668;-3.4507518;-1.1061215;CODE
todo refactor once nan aware reductions are standardized;-0.24020344;1.2829025;-3.2540605;2.8357804;0.27578267;3.0383801;TASK
https github com data apis array api issues 621;-2.7905107;-0.3584092;-3.4579277;-1.5104668;-3.4507518;-1.1061215;CODE
use numpy api to support order;0.013655303;-1.4891115;-1.5932392;-3.36447;-3.647351;0.9259949;CODE
at this point array is a numpy ndarray we convert it to an array;2.1315978;-1.1472088;-1.5831127;-7.563473;-5.5722337;-0.54849285;CODE
container that is consistent with the input s namespace;-2.9415464;1.0280122;0.19607323;0.22708705;2.4064002;2.8441997;CODE
if no dtype is specified when running tests for a given namespace we;-1.5179528;1.6832154;-7.0285444;3.0497048;0.22438797;-1.7453196;CODE
expect the same floating precision level as numpy s default floating;2.121872;0.25311926;-4.694696;-4.0390153;-7.3850403;0.12822728;CODE
point dtype;0.534354;-2.5053754;1.2652522;-2.7114058;-0.84474236;-1.2795463;CODE
currently this is implemented with simple hack that assumes that;-1.5355601;0.052336615;1.5722703;0.9230937;2.770086;4.783175;TASK
following may be statements in the array api spec always hold;-2.853099;4.19271;-2.7396762;2.5053844;-0.5118375;-0.49030566;CODE
the default integer data type should be the same across platforms but;-1.1605072;-0.17469336;-4.277733;-3.6469762;0.35073954;1.3418968;CODE
the default may vary depending on whether python is 32 bit or 64 bit;-3.7297707;-3.4108722;-3.8551977;-1.2875896;-2.9896176;0.060448185;CODE
the default array index data type may be int32 on 32 bit platforms but;-1.8054935;0.2800437;-4.429218;-5.5453944;-0.94381845;0.4491626;CODE
the default should be int64 otherwise;-7.26925;0.71106416;-3.3973558;-3.7645178;-2.8961895;0.7192931;CODE
https data apis org array api latest api specification data types html default data types;-2.188348;-0.76768094;-2.2651508;-0.8974359;-0.8281805;1.648052;CODE
todo once sufficiently adopted we might want to instead rely on the;-3.833987;-1.3242927;2.0780704;6.2845263;0.8709598;2.0537093;CODE
newer inspection api https github com data apis array api issues 640;-2.1186054;-0.30976743;-4.617461;0.3820601;-2.5724468;-0.7250012;CODE
note this is a helper for the function isin;-1.3181597;3.3150055;2.1160827;-2.7124748;-1.3623782;-3.1647859;CODE
it is not meant to be called directly;-7.0732956;-1.2935994;-0.23772958;1.8790628;1.1620781;2.4522195;IRRE
this code is run to make the code significantly faster;-0.21099642;0.3446059;1.0645362;1.2855834;-0.027647715;-3.0952787;CODE
we need this to be a stable sort;0.3890564;-0.4611805;4.0613875;2.0642679;1.3693345;1.0643786;CODE
indexing undefined in standard when sar is empty;-0.34607938;4.63259;-4.252987;-2.7021532;-2.1849737;2.3252568;CODE
todo update if bincount is ever adopted in a future version of the standard;-3.1684647;1.7701137;-1.2518156;1.8184611;1.2460111;-0.44220117;CODE
https github com data apis array api issues 812;-2.9364896;-0.3703048;-3.2330759;-1.2085153;-3.3216033;-0.7255848;CODE
todo replace by scipy special logsumexp when;-0.81820875;-0.1781814;-2.3514059;-1.4049671;-2.7777143;-3.235548;TASK
https github com scipy scipy pull 22683 is part of a release;-4.2704825;-6.818916;-4.3929243;-1.3044368;-4.6898246;-3.3963847;CODE
the following code is strongly inspired and simplified from;1.4354532;0.5949275;2.2080286;-3.4358094;0.7061034;-3.0150595;CODE
scipy special logsumexp logsumexp;-0.034092966;-2.6299088;-2.3189945;-4.7083907;-2.4359775;-3.669326;-
specifying device explicitly is the fix for https github com scipy scipy issues 22680;-2.8373554;-4.085894;-7.885135;-1.2971789;-6.8362875;-1.6345341;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
update the docstring of the descriptor;-5.8335776;-0.7582002;-1.8864927;1.536437;2.9186532;2.6605535;CODE
delegate only on instances not the classes;-2.1999626;-0.24132682;0.62389636;4.0319643;2.1613843;3.4623942;IRRE
this is to allow access to the docstrings;-8.302034;-4.0643682;0.7701993;1.4577037;2.5079172;0.29180607;CODE
this makes it possible to use the decorated method as an unbound method;-2.9559634;1.0210648;-0.23924363;2.7525313;2.467678;4.7812276;CODE
for instance when monkeypatching;-2.807307;-3.9864576;4.0154033;4.040264;-0.45688775;1.8622304;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
map from deprecated key to warning message;-4.286581;1.6085579;-2.5413644;1.2898933;-0.10661193;1.779414;OUTD
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
numerical;3.910176;1.5229433;3.1325638;-5.1343665;-0.016140815;-4.7487946;-
np unique will have duplicate missing values at the end of uniques;1.5698408;3.0717967;-3.554057;-2.1360161;-0.2672809;-1.0850273;IRRE
here we clip the nans and remove it from uniques;1.2938764;0.8049863;0.48243564;-3.1440015;0.4551791;-0.7942009;CODE
if there is more than one missing value then it has to be;-0.16296938;6.6980157;-1.0316073;-0.93076193;2.2825127;-5.0449433;IRRE
float nan or np nan;1.6743135;1.8410398;-0.70044726;-5.4151015;-3.0106432;-3.495408;CODE
create set without the missing values;1.6442204;4.813373;1.6098562;-2.45043;2.8762002;-2.2343361;IRRE
only used in uniques see docstring there for details;-2.8945348;-1.5099825;-1.4154444;-0.00056665816;6.697209;-0.7683668;CODE
check for nans in the known values;4.365873;5.1758947;-2.6261108;-1.763669;-2.1735866;-5.16025;IRRE
removes nan from valid mask;0.8749669;4.0793414;-2.3679016;-3.089871;-2.5703275;0.36007065;CODE
remove nan from diff;1.4738536;4.3171225;-1.2769011;-3.2940874;-3.4005072;-2.4709702;CODE
recorder unique values based on input uniques;3.9573343;3.3632994;2.2984707;-1.0075953;4.624859;-1.689554;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
using take instead of iloc ensures the return value is a proper;-0.2705871;3.7506192;-2.1231468;2.7949328;-0.6145274;0.6163143;CODE
copy that will not raise settingwithcopywarning;-2.8709586;1.2904792;-1.789702;3.5177276;-2.5592835;3.5750866;IRRE
check whether we should index with loc or iloc;2.723809;1.8990896;-1.5462278;-0.21649009;1.9917722;0.5414747;-
polars behavior is more consistent with lists;0.73873764;1.0762513;-0.051991366;-0.7732266;-0.38990542;-1.3103813;-
convert each element of the array to a python scalar;3.2642624;-0.49324346;-0.4790479;-5.2868495;-4.253847;-1.6173953;CODE
here we are certain to have a polars dataframe which can be indexed with;3.242801;-2.1503427;0.92653793;-4.1433687;-0.60442966;-0.17097764;CODE
integer and string scalar and list of integer string and boolean;0.75481683;3.269288;-0.4819644;-2.857933;2.4519718;-5.0488305;CODE
boolean mask can be indexed in the same way for series and dataframe axis 0;2.814376;2.6112084;-2.7510002;-5.0496497;-3.055802;1.5880767;CODE
integer scalar and list of integer can be indexed in the same way for series and;2.5850098;2.4473636;-1.4831107;-3.357119;-0.27607587;-0.5490347;CODE
dataframe axis 0;0.5286724;1.8101348;1.5909426;-7.7820616;-7.1331277;-0.5076841;-
x indexed is a dataframe with a single row we return a series to be;2.4117815;1.763957;-0.112880774;-4.3858304;-3.1787565;-0.83123326;IRRE
consistent with pandas;4.724741;-1.4092269;-0.9054199;-1.0792085;-3.6415188;-1.7250975;-
safe indexing data 0 axis 0 select the first row;3.2444165;4.0733376;1.60983;-5.9220715;-1.1262555;-0.26547164;CODE
safe indexing data 0 axis 1 select the first column;3.4651167;3.2795627;1.917554;-6.2010527;-1.3151807;-0.09704821;CODE
we get an empty list;-4.0393267;0.7607426;1.3483294;0.39664578;-1.7696215;-4.36442;-
code adapted from stratifiedshufflesplit;-0.09036344;-0.07518076;-2.4653673;0.12897183;1.9665264;-1.1566241;CODE
for multi label y map each distinct row to a string repr;3.8394916;0.39552674;1.3710836;-4.5687637;3.2183182;-0.6338654;CODE
using join because str row uses an ellipsis if len row 1000;0.66183746;2.6755803;-0.1068942;-1.8443497;-0.14400104;-3.496994;-
find the sorted list of instances for each class;2.0232444;-0.33528665;1.6263937;-0.8911725;3.4625814;-2.8589163;CODE
np unique above performs a sort so code is o n logn already;-0.18252166;1.6920857;-1.7532648;-2.451194;0.38810185;-2.1225178;CODE
convert sparse matrices to csr for row based indexing;6.0680523;-0.69965523;-2.529604;-4.801431;1.0909351;2.4757211;IRRE
syntactic sugar for the unit argument case;-0.8859388;0.978845;-1.2019295;0.48088744;5.095516;0.06147545;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we also suppress attributeerror because older versions of pandas do;-0.66755676;0.44528952;-7.125494;2.5789444;-5.1206737;0.33195877;META
not have na;-2.9182806;0.8258475;2.1020114;0.042473737;-0.5407253;-0.5758108;-
can t have nans in integer array;0.19614276;4.507323;-2.2957134;-6.3149304;-4.0289993;-4.28885;CODE
np isnan does not work on object dtypes;-2.7560613;0.74604094;-7.758095;-1.4800905;-3.52798;-1.3110021;CODE
for all cases apart of a sparse input where we need to reconstruct;5.676003;-1.0136584;0.5619043;-0.8682448;0.8109437;3.4894521;CODE
a sparse output;7.0926104;-1.1928535;1.9686967;-2.152566;0.12420487;1.7131692;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
only the following methods are supported in the routing mechanism adding new;-4.359448;-0.82898825;0.36242783;1.5469087;1.2481449;4.4539323;CODE
methods at the moment involves monkeypatching this list;1.5393083;-4.2494397;3.2084699;3.2442522;2.1529589;-0.6721187;CODE
note that if this list is changed or monkeypatched the corresponding method;1.4525093;0.49741152;1.5919932;2.5711005;2.8813283;-1.3888332;CODE
needs to be added under a type checking condition like the one done here in;-1.791041;7.13718;-3.6197345;2.229504;3.7059598;-3.1918683;TASK
metadatarequester;-4.709528;-1.99156;0.5786839;2.3831158;1.2505541;2.3919926;CODE
these methods are a composite of other methods and one cannot set their;-1.4365952;0.017461339;-1.0132836;3.0112042;0.888242;0.7823764;IRRE
requests directly instead they should be set by setting the requests of the;-5.010724;0.69219816;1.0590816;4.1052566;-1.4190239;4.943526;IRRE
simple methods which make the composite ones;1.2630534;-0.76796085;3.7087004;-0.36458778;3.6834173;0.41137654;-
request values;-1.9947685;3.2552643;3.5142848;-0.043805145;1.7872864;-1.1784593;IRRE
each request value needs to be one of the following values or an alias;-2.9574625;4.304628;0.8249753;0.31910586;3.2192085;1.85542;IRRE
this is used in metadata request attributes to indicate that a;-5.0378313;-2.213206;-0.31285286;-0.32239524;3.9714248;1.9667755;CODE
metadata is not present even though it may be present in the;-5.047037;-1.0206203;-3.328811;0.862478;-0.10764175;1.8804433;CODE
corresponding method s signature;-1.4584595;0.82919043;-2.435869;1.9472787;4.1795588;0.6783272;-
this is used whenever a default value is changed and therefore the user;-6.1731358;0.2852396;1.8097495;1.5349392;1.4735371;2.1362534;CODE
should explicitly set the value otherwise a warning is shown an example;-2.512886;5.5532427;-1.8915335;3.8253546;-1.5902617;-0.8859124;IRRE
is when a meta estimator is only a router but then becomes also a;-0.7315984;1.0564249;-0.60372245;4.164457;0.35870662;5.5882125;META
consumer in a new release;-2.5348172;-2.8786361;2.333371;3.3100314;1.4108144;0.014588594;CODE
this is the default used in set method request methods to indicate no;-4.978446;3.5785482;-1.1179157;3.692087;0.96361876;1.5812551;CODE
change requested by the user;-5.177123;0.7011687;4.1684556;2.771824;0.11477983;1.9083995;CODE
item is only an alias if it s a valid identifier;-4.812851;3.357835;-3.4102023;1.0084072;4.984785;0.38942593;-
metadata request for simple consumers;-3.1240706;-2.4509614;1.2540536;2.2728658;3.615947;3.1031928;CODE
this section includes methodmetadatarequest and metadatarequest which are;-5.4514866;-2.6943295;-0.24850138;3.6146703;0.9718556;3.020004;CODE
used in simple consumers;-2.433135;-2.1683724;3.843769;1.67219;2.6447928;0.6379938;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
have shape and length but don t support indexing;2.6981027;1.1757064;1.7219969;-4.8012447;2.2836287;1.4040816;META
ugly hack to make iloc work;-2.6624308;-1.8349439;-0.2070032;1.3386183;-0.290668;1.8029734;-
pandas data frames also are array like we want to make sure that;3.2023752;-0.67511606;-0.72362465;-3.9533753;-2.3122418;-0.96638477;-
input validation in cross validation does not try to call that;-1.1727074;4.061524;-2.485574;2.9166389;-1.6180817;-1.6523165;CODE
method;-1.0682498;-0.007665863;5.7642107;3.6788619;1.4956282;-4.1532536;-
for binary classifier the confidence score is related to;2.5048225;-1.393733;-2.6315434;0.05657512;3.0202844;-3.7400627;CODE
classes 1 and therefore should be null;-2.1113858;2.416159;-2.232328;0.8782327;3.6659367;-1.7987527;CODE
deactivate key validation for checkingclassifier because we want to be able to;-0.98494613;1.7954637;-3.9033375;4.421682;1.2263087;1.0153292;CODE
call fit with arbitrary fit params and record them without this change we;4.0060124;3.9506273;-0.8880437;1.6240764;1.4772325;4.4800754;IRRE
would get an error because those arbitrary params are not expected;-1.4172498;5.8641744;-2.7740443;-1.2780468;-0.23036532;-0.7657472;TASK
checkingclassifier set fit request requestmethod type ignore assignment method assign;1.3045006;2.8134582;-6.2922897;3.828811;1.7200748;2.5790052;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
import matplotlib noqa f401;-0.7200885;-3.190362;-1.8495036;-6.6406493;-7.1725445;0.121925995;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
inherits from valueerror and typeerror to keep backward compatibility;-1.978526;1.9128771;-7.1094;3.79759;0.57246363;1.7693669;IRRE
we allow parameters to not have a constraint so that third party estimators;1.1038152;1.0864713;-2.8306305;3.1043644;1.9600375;6.701204;CODE
can inherit from sklearn estimators without having to necessarily use the;1.6701443;-3.249107;-4.792216;3.3233004;-0.26084474;3.927784;IRRE
validation tools;0.3608297;-1.3039507;-0.33683822;3.6444263;1.856348;-3.7033148;-
this constraint is satisfied no need to check further;-1.6039637;6.169065;-1.3514603;-2.5126078;2.8384564;-0.11499773;CODE
no constraint is satisfied raise with an informative message;-1.6187496;3.204531;-0.8914586;1.3709164;2.429571;1.7593197;CODE
ignore constraints that we don t want to expose in the error message;-1.4199804;5.4596004;-4.435531;3.5455961;-0.11389763;4.0020037;CODE
i e options that are for internal purpose or not officially supported;-6.3328266;-4.3460307;1.2267141;2.4482965;1.5079675;3.2954946;CODE
the dict of parameter constraints is set as an attribute of the function;-1.6774664;0.9754852;-3.5439467;-0.83876693;0.944414;1.9918001;CODE
to make it possible to dynamically introspect the constraints for;1.6571884;0.7144766;0.5027703;1.0225393;5.2614813;2.6621823;CODE
automatic testing;1.6181449;0.5554567;1.3741349;7.924689;1.0758857;-6.1351566;IRRE
map args kwargs to the function signature;-1.0314173;0.36573774;-0.9715275;0.7973638;0.35692367;2.7506914;IRRE
ignore self cls and positional keyword markers;-2.9051938;0.69763756;-2.9168398;0.94356114;1.3563594;2.145389;CODE
when the function is just a wrapper around an estimator we allow;0.5190594;0.969215;-0.36727023;4.701201;-1.876737;4.9210515;CODE
the function to delegate validation to the estimator but we replace;0.91288483;2.0524127;-1.4566613;5.5785956;-0.8486755;3.2136297;META
the name of the estimator by the name of the function in the error;-0.2174418;0.85051936;-0.8188417;1.2411277;-1.8325726;1.3402818;CODE
message to avoid confusion;-3.4757884;1.5231439;3.7063496;1.8650968;4.319646;-3.1351023;CODE
we use an interval of real to ignore np nan that has its own constraint;2.9093883;3.0102012;-2.7613885;-1.9768832;-2.427361;1.4226428;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
display classes are in process of changing from estimator name to name;-1.3147278;-0.21145809;-1.2573079;2.2746677;1.4924407;2.877028;CODE
try old attr name estimator name first;-0.24637055;1.0907665;-3.3725092;1.3193722;-1.9645875;3.90017;CODE
note below code requires len param keys 2 which is the case for all;-3.125438;1.5459754;-1.3986855;-5.6432805;2.402918;-2.8937092;CODE
display classes;-1.8851652;-2.0609756;2.92042;-0.8657058;4.2378836;-1.1230743;IRRE
todo 1 10 remove after the end of the deprecation period of y pred;-4.1272855;3.7513387;0.51782584;1.4055947;-1.0142555;-0.21573867;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
copyright c 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010;-4.0984545;-2.8194067;0.10008948;-1.7148393;2.9956033;-2.1551378;-
2011 2012 2013 2014 2015 2016 2017 2018 python software foundation;-1.9644561;-6.528135;-4.0571766;0.12548345;-2.04417;-3.5458703;CODE
all rights reserved;-6.1172695;-1.7122531;2.8031313;-1.001879;1.5156415;-0.6406165;-
authors fred l drake jr fdrake acm org built in cpython pprint module;-3.6110315;-6.107515;-1.8281071;-1.1221361;-2.6707842;-1.9328898;CODE
nicolas hug scikit learn specific changes;-0.36900103;-9.953308;-0.9971328;2.0706112;-3.1524298;-1.9495224;-
license psf license version 2 see below;-5.118965;-3.0626297;-1.687564;-1.5981399;1.7098293;-0.98625875;META
python software foundation license version 2;-4.8513904;-5.143035;-4.413414;-1.6635154;-1.5572357;-1.7722696;META
1 this license agreement is between the python software foundation psf;-4.2756405;-5.9684253;-4.076495;-1.5647746;-0.7782777;-2.056596;CODE
and the individual or organization licensee accessing and otherwise;-3.7322152;-4.0169783;-0.639557;0.0025810036;4.8484764;1.1506621;CODE
using this software python in source or binary form and its associated;-3.2022996;-7.6055455;-2.5831463;-3.2749295;0.09143541;-3.330688;CODE
documentation;-5.275622;-7.480966;3.7151163;2.304026;2.9932058;-2.7141862;CODE
2 subject to the terms and conditions of this license agreement psf hereby;-5.1566043;-1.4655341;-1.6954049;-1.5000304;4.832735;-0.33915347;CODE
grants licensee a nonexclusive royalty free world wide license to;-4.584515;-2.0961974;-3.126266;-0.35215408;2.8614223;-0.75000775;IRRE
reproduce analyze test perform and or display publicly prepare;-0.31453556;0.6914942;-0.904362;5.7897134;0.7251116;-3.5248957;CODE
derivative works distribute and otherwise use python alone or in any;-1.3913785;-3.6698549;-2.988613;-0.7732496;-2.5560415;-1.0369548;CODE
derivative version provided however that psf s license agreement and;-5.8342943;-2.7541513;-3.487035;-0.16031894;1.4922557;1.1191055;META
psf s notice of copyright i e copyright c 2001 2002 2003 2004;-5.8618946;-2.406151;-0.93490326;-0.9666018;1.1721301;-1.7119278;-
2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016;-1.9461485;-1.0066029;0.029622758;-1.1721461;1.0607616;-1.4097133;-
2017 2018 python software foundation all rights reserved are retained in;-6.2560987;-3.962433;-4.3185043;-0.47124058;-2.8803194;-1.4159163;CODE
python alone or in any derivative version prepared by licensee;-3.6541793;-4.061083;-4.328538;-0.23632106;0.1402922;-0.42678684;META
3 in the event licensee prepares a derivative work that is based on or;-3.8683631;-2.8680687;-0.5492226;1.5262542;5.409848;-0.39566535;CODE
incorporates python or any part thereof and wants to make the derivative;-1.6282015;-4.357329;-0.26085594;-3.2897625;-2.4107554;-2.5835104;CODE
work available to others as provided herein then licensee hereby agrees to;-4.027817;-4.743843;-0.018752163;0.87209654;1.4086018;0.7890972;CODE
include in any such work a brief summary of the changes made to python;-2.6264257;-6.409511;-0.839804;1.2646015;-2.9359;-3.3470745;CODE
4 psf is making python available to licensee on an as is basis psf makes;-4.5392075;-4.541299;-4.901404;-0.97290474;-0.7973083;-0.888077;CODE
no representations or warranties express or implied by way of example but;-2.0876634;2.4767866;-1.3498869;1.3985662;2.6875498;-1.5306515;META
not limitation psf makes no and disclaims any representation or warranty of;-2.882324;0.86858195;-2.7880557;1.8224176;1.0029672;1.2705332;-
merchantability or fitness for any particular purpose or that the use of;-2.2307107;-2.5791137;1.7948684;2.4538436;3.848041;0.29557085;CODE
python will not infringe any third party rights;-6.752823;-1.398693;-5.101466;-0.34141266;-3.591615;-1.1366909;CODE
5 psf shall not be liable to licensee or any other users of python for any;-4.9060163;-3.163843;-4.9133644;-0.68167084;-1.391542;-2.7883627;CODE
incidental special or consequential damages or loss as a result of;-2.8435361;1.0204735;1.1441559;2.7817912;2.96151;0.19051553;IRRE
modifying distributing or otherwise using python or any derivative;-0.45841712;-1.8312151;-1.1707025;-1.3501478;0.86389;-0.84323096;META
thereof even if advised of the possibility thereof;-3.0237963;1.2726064;1.6313258;5.5242896;4.9643607;-0.48575908;CODE
6 this license agreement will automatically terminate upon a material;-5.109942;-0.94732934;-1.5633394;0.000372115;2.9872935;0.44757184;IRRE
breach of its terms and conditions;-4.3655334;0.7356654;1.5664146;2.7742572;1.904346;-0.8039665;-
7 nothing in this license agreement shall be deemed to create any;-4.3565564;0.6754912;-2.812176;-1.8178899;4.5224266;-0.7111776;CODE
relationship of agency partnership or joint venture between psf and;-2.9375112;-1.3670807;1.702366;-1.1769598;0.31958613;1.712591;CODE
licensee this license agreement does not grant permission to use psf;-5.54256;-1.7222519;-3.4248593;-1.3915797;0.19481708;0.8899575;CODE
trademarks or trade name in a trademark sense to endorse or promote products;-2.7866526;-2.7063124;1.5251626;-1.5342665;3.2419116;1.887042;CODE
or services of licensee or any third party;-3.8711302;-3.206806;-1.042471;0.020519394;3.8326747;2.540098;-
8 by copying installing or otherwise using python licensee agrees to be;-4.0331535;-3.4676807;-2.9370744;-0.8749756;-0.560333;-1.4872568;CODE
bound by the terms and conditions of this license agreement;-3.8088157;0.4172047;-0.8955551;-0.46594816;4.0895247;0.25036058;CODE
brief summary of changes to original code;-2.7500336;-2.9153588;0.52219194;1.8377581;0.8185306;-2.09127;-
compact parameter is supported for dicts not just lists or tuples;-0.367086;0.11986487;-3.5291069;-0.74225;-0.11027687;1.9130764;IRRE
estimators have a custom handler they re not just treated as objects;-1.0580379;1.0177028;-1.6104988;5.1718254;-1.0716411;5.9823804;IRRE
long sequences lists tuples dict items with more than n elements are;0.99967843;-0.79684395;-0.020199006;-3.5189905;1.030074;-3.7982118;-
shortened using ellipsis at the end;-1.7064534;0.027289027;3.171014;-0.4656332;-0.5855724;-0.89711905;CODE
if k not in init params happens if k is part of a kwargs;-0.8616047;2.2639022;-0.84553975;1.3664539;1.9657385;0.73140347;IRRE
if init params k inspect empty k has no default value;-3.3549066;5.773148;-2.8703945;2.256547;-1.1224946;-0.20278613;IRRE
try to avoid calling repr on nested estimators;1.6614966;2.5100932;-3.2769058;3.3741398;-0.867771;4.611962;CODE
use repr as a last resort it may be expensive;-1.8307747;0.35132605;0.3771628;2.4023943;-0.8993661;1.6280838;-
elf indent per level 1 ignore indent param;-2.769584;3.0115163;-2.6317868;-0.5538623;2.2219357;0.61305344;-
max number of elements in a list dict tuple until we start using;1.1421648;0.046056073;1.0888827;-2.021225;0.43028322;-2.689801;CODE
ellipsis this also affects the number of arguments of an estimators;2.438648;0.6734381;0.040695123;2.1782312;-0.86267954;2.8009777;CODE
they are treated as dicts;-2.165062;-2.1819909;0.03440827;-0.09785767;3.3951185;-1.0113697;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
construct the estimator s module name up to the first private submodule;-0.3475475;1.5998785;-1.8129455;0.8606742;0.3330476;5.055471;CODE
this works because in scikit learn all public estimators are exposed at;2.1489682;-5.8312263;-5.7901554;2.9477017;-4.503811;0.7083715;CODE
that level even if they actually live in a private sub module;-2.6803749;-0.45941254;-0.43887126;0.21047164;0.9418091;1.0001395;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
check if estimator looks like a meta estimator wraps estimators;-0.4298548;3.51522;-3.9011042;4.1904106;-4.0154657;2.1561658;IRRE
estimator can also be an instance of visualblock;1.0945642;-0.46378002;0.67732596;2.4750981;-1.059541;4.8831186;-
build the parameter prefix for nested estimators;1.9760866;1.3558166;-0.8822825;1.6611496;2.5613878;5.627565;IRRE
if we already have a prefix append the new component;-4.9636517;1.3812238;2.6397927;1.2293113;3.490319;5.0723934;CODE
if this is the first level start the prefix;-4.2968493;-0.022260537;3.1506162;0.740228;3.6325204;-0.4986872;CODE
else parallel;-0.67663336;1.7531571;4.8578606;-0.024173345;1.00182;-1.8936952;-
wrap element in a serial visualblock;-3.417235;2.02445;1.9292139;-1.345893;-0.46663174;2.8216813;-
out write div sk parallel item;-1.6252056;0.63330513;3.6679564;-3.3181791;0.117213495;1.7916667;TASK
the fallback message is shown by default and loading the css sets;-5.5303426;1.5757794;0.16811293;2.3953671;-3.0043142;3.3799226;CODE
div sk text repr fallback to display none to hide the fallback message;-3.3210404;2.7212293;-0.5159039;-0.6107339;-2.3129861;1.7590483;-
if the notebook is trusted the css is loaded which hides the fallback;-5.308317;0.29182965;0.8493053;2.7091553;-4.013632;3.105839;TASK
message if the notebook is not trusted then the css is not loaded and the;-5.759868;0.2186106;0.8434413;1.887132;-4.055121;0.02907367;TASK
fallback message is shown by default;-5.509226;3.0185595;-1.0016289;2.6968288;-3.8269293;2.9820986;CODE
the reverse logic applies to html repr div sk container;-4.6417427;1.1154684;-0.1662764;-0.7803682;-0.8401525;2.7152398;META
div sk container is hidden by default and the loading the css displays it;-4.243612;0.2867924;0.77090746;-1.1283262;-3.4592783;3.1369371;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
no match found in the docstring return none to indicate that we;-4.5413523;2.3023396;-5.808932;1.5149199;-0.6375008;-2.9068775;CODE
cannot link;-6.106514;-0.9226579;2.8697164;-1.0566772;-2.5665295;-0.9223474;-
extract the whole line of the type information up to the line break as;0.666835;1.6324694;-0.102865435;-1.2654666;1.28406;-2.2553833;CODE
disambiguation suffix to build the fragment;-1.9179301;-0.5956044;0.3506486;-0.22789085;5.0554304;2.7553322;-
return f doc link text text fragment;-4.8107862;0.32532522;0.6895811;0.6877125;-0.7290694;0.7329065;CODE
r maxlist 2 show only first 2 items of lists;1.0204504;3.4540658;2.281967;-2.3703785;0.05065925;-1.5061854;-
r maxtuple 1 show only first item of tuples;2.6334736;2.864319;1.8700479;-4.0429325;0.6253722;-2.067215;-
r maxstring 50 limit string length;0.11040795;2.3457973;1.1179922;-1.2159308;0.2548113;-1.9763615;CODE
create clickable parameter name with documentation link;-6.239522;-2.0496051;0.5373854;1.5974377;2.4809024;3.1176538;IRRE
just show the parameter name without link;-5.1327324;2.3535008;2.023472;0.56388587;-0.179746;2.9310436;IRRE
return x y pragma nocover;-1.5306829;5.1514134;0.9210698;-2.1769423;-1.4267596;-3.4842105;IRRE
test checking logic and labeling;0.6656792;5.86245;-0.48668423;4.8481297;4.585537;-7.4331717;IRRE
test estimators that are represented by strings;4.7458634;3.0251315;-1.3726388;2.8056421;0.85430324;-2.8331704;IRRE
top level estimators show estimator with changes;1.6608403;0.21394314;0.5277158;2.2955573;-3.0253015;4.074366;-
low level estimators do not show changes;0.9114226;1.4570332;-2.773769;1.759969;-4.5680256;4.65537;CODE
feature union;2.6476276;-2.9065025;1.5270847;1.4976887;5.4568677;-0.52208555;TASK
voting classifier;4.0347342;-3.7913249;1.0629891;-0.12960696;5.2514896;-2.4586742;IRRE
verify that prefers color scheme is implemented;-0.8490199;1.224582;-2.3635418;2.3411283;1.4898013;0.72218174;TASK
if final estimator s default changes from logisticregression;-0.35066712;2.535865;-2.4855974;4.8505864;-2.151741;3.9149733;CODE
this should be updated;-5.576292;-3.7460372;0.40937936;2.994132;-1.1654465;1.3053669;CODE
test duck typing meta estimators with birch;1.1928108;-0.1422356;-3.4204001;3.8399723;-0.44581148;-0.3712133;IRRE
inner estimators do not show changes;1.8586926;1.1953827;-1.518617;1.6291634;-4.1749797;5.3483844;CODE
outer estimator contains all changes;2.1696336;2.4943714;-1.0302993;2.2742734;-1.8214693;5.036781;-
test duck typing metaestimators with ovo;-0.29561737;-0.28938833;-2.7170498;3.100555;-0.8830314;0.52149045;IRRE
inner estimators do not show changes;1.8586926;1.1953827;-1.518617;1.6291634;-4.1749797;5.3483844;CODE
regex to match the start of the tag;-2.836272;1.362592;3.5003064;0.8961316;1.7743161;-0.19369726;CODE
outer estimator;2.4536219;0.9905636;0.16723442;0.68152803;-0.78968835;4.67331;-
test duck typing metaestimators with random search;2.2822554;-0.06578418;-1.8581004;5.3973966;0.99601424;-1.97076;IRRE
mock the version where the mixin is located;-2.1714969;1.3567231;-0.3410877;3.8566244;-0.5253818;-0.72057414;META
we need to parse the version manually to be sure that this test is passing in;-2.6186392;3.8366287;-6.9477243;5.9119925;-1.5405937;-4.7614093;IRRE
other branches than main that is dev;-4.2787466;-5.7769427;2.048392;1.4089528;0.13380674;-0.91646945;CODE
if the doc link module does not refer to the root module of the estimator;-3.8131244;-0.6038311;-2.7496502;2.7562373;-2.6064446;4.3132586;CODE
here the mixin then we should return an empty string;-2.9039528;6.869275;-0.13692999;1.0475723;0.28033465;-3.2113576;CODE
we can bypass the generation by providing our own callable;-4.4803543;-1.5475516;2.0806744;3.4260993;2.8095703;0.9744119;IRRE
we can bypass the generation by providing our own callable;-4.4803543;-1.5475516;2.0806744;3.4260993;2.8095703;0.9744119;IRRE
resets the locale to the original one python calls setlocale lc type;-3.413575;0.4480015;-3.0620098;-0.12034345;-4.850177;1.5137585;IRRE
at startup according to;-3.7871907;-1.6421814;4.2951736;1.6353632;1.3593745;0.44048133;-
https docs python org 3 library locale html background details hints tips and caveats;-5.5259995;-4.5762134;-0.91133326;0.15843043;-3.3501623;0.6947949;CODE
this assumes that no other locale changes have been made for some reason;-5.5582557;-0.7286676;-1.366528;3.182857;-1.6801217;2.505336;CODE
on some platforms trying to restore locale with something like;-4.163659;-3.4249198;-0.54048246;1.1181351;-2.398252;1.5954732;CODE
locale setlocale locale lc ctype locale getlocale raises a;-2.4536064;0.83018297;-1.7109492;0.33174098;-1.8081045;1.6714987;IRRE
locale error unsupported locale setting;-3.6799922;0.7347965;-2.6584215;-1.1200895;-3.553114;1.9059902;IRRE
test that function name is shown as the name and functiontransformer is shown;-2.8506453;4.0319796;-0.554135;0.97344893;-0.46226367;-2.374958;CODE
in the caption;-3.6007779;-2.6896307;5.34684;0.13152461;-0.5722495;-0.8846234;CODE
suppress logging;-3.2355316;2.482239;0.23137245;4.2076693;-2.189399;2.0193405;-
check non default parameters;-1.3300147;6.088202;-1.9110514;2.2520976;0.70985323;0.6032864;IRRE
check that we escape html tags;-5.4318085;1.5561824;0.29234064;1.4762774;-0.5803497;-1.1068143;-
quot lt script gt alert x27 xss x27 lt script gt quot;-5.6720924;1.3952172;1.0593178;-1.482364;-1.3859566;-2.8395596;CODE
r shref mock module mockestimator html text a int;-1.1767374;3.4479861;-1.0632861;1.213921;-3.0433676;-2.0362108;CODE
r shref mock module mockestimator html text b str;-1.5700855;2.9709535;-1.6539265;1.160241;-3.2161617;-1.5406516;CODE
assert url mock module mockestimator html text alpha float;-2.0960047;3.8837645;-1.6356672;2.6897917;-3.8738773;-0.9176731;CODE
assert url mock module mockestimator html text beta int;-2.88082;3.320324;-1.9716097;4.0508113;-2.0327744;-1.7128161;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
we don t handle classifiers trained on a single class;3.5470967;-3.1688297;-3.0975878;4.4489136;3.4349034;1.0524788;CODE
use a compress format of shape n samples n output;4.551692;0.37637448;-0.69293773;-5.687806;-0.102542065;0.5614113;IRRE
only mlpclassifier and ridgeclassifier return an array of shape;5.608315;-1.412743;-2.9315202;-2.2678223;-0.26991016;2.4300911;IRRE
n samples n outputs;4.799217;1.0256069;2.142573;-3.6883059;1.2223458;-4.424001;IRRE
list of arrays of shape n samples 2;6.284871;-0.018781682;1.560865;-5.064819;0.73405844;-2.3542564;-
array of shape n samples n outputs;6.4688635;0.29888567;1.9977964;-5.58164;0.2704684;-1.2680091;IRRE
else estimator is a regressor;-0.85601425;2.433212;-0.31095096;0.5358124;-2.5015328;1.8302348;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
show threadpoolctl results;-1.2308403;0.41526303;2.1218326;2.5344596;-1.2697265;0.18248884;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
happens when sklearn tags is implemented by calling;-2.6925657;-3.665229;-5.3865805;2.4354305;-3.4293902;-0.6785662;TASK
super sklearn tags but there is no sklearn tags;-0.7222939;-6.892835;-3.3435624;1.5066515;-1.2349414;0.07166101;META
method in the base class typically happens when only inheriting;-4.0961924;1.2160218;-2.1594186;2.8054261;0.99772197;1.3664242;IRRE
from mixins;-1.5256742;-2.9584656;2.8257601;0.5943628;0.3742024;-1.641409;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
from sklearn experimental import enable halving search cv noqa f401;1.9050133;-1.1410071;-6.8692355;-0.5317155;-4.109496;-0.66295934;CODE
the following dictionary is to indicate constructor arguments suitable for the test;-1.405832;1.5970473;-2.0445306;2.5795374;4.2015953;-4.489107;CODE
suite which uses very small datasets and is intended to run rather quickly;2.7562273;-4.6935406;0.22080879;1.3336488;0.6278419;0.10269196;CODE
the default strategy prior would output constant predictions and fail;1.4756091;1.6438141;-0.367624;6.2301726;-0.7287623;2.9320612;CODE
for check classifiers predictions;5.202157;-4.3884993;-0.7590786;4.995275;2.9896944;-4.142861;CODE
due to the jl lemma and often very few samples the number;2.4567707;2.8771055;-2.9500604;-0.255221;0.63076884;0.1490532;CODE
of components of the random matrix projection will be probably;4.273134;-1.662304;0.38637084;-1.3980302;0.33654502;5.525103;IRRE
greater than the number of features;3.531569;-1.6051373;1.0233966;-1.444881;2.1616719;-2.047291;TASK
so we impose a smaller number avoid auto mode;-0.58266664;1.8654246;1.0545621;1.0332569;1.026372;1.5321138;CODE
the default min samples leaf 20 isn t appropriate for small;0.4590288;2.0613294;-1.6964592;0.5904618;-0.8332209;1.0520266;CODE
datasets only very shallow trees are built that the checks use;3.1763847;-0.8553372;-3.2568595;3.5509155;2.3105602;-1.0337152;IRRE
noise variance estimation does not work when n samples n features;2.4220502;-0.87839943;-5.168024;-0.07869041;-2.063659;2.512715;CODE
we need to provide the noise variance explicitly;2.6626751;-1.4645865;-2.0917938;2.4549112;-0.29578695;4.650409;TASK
in the case of check fit2d 1sample bandwidth is set to none and;0.58823764;3.4756088;-4.6469545;0.46934214;-2.445688;2.9379315;CODE
is thus estimated de facto it is 0 0 as a single sample is provided;2.1613379;3.3429039;-2.508168;1.3119855;-0.8039424;0.016077206;CODE
and this makes the test fails hence we give it a placeholder value;-3.053078;5.255747;-3.972293;6.250735;-0.26113373;-3.94725;IRRE
ransacregressor will raise an error with any model other;-1.6649764;2.1236484;-5.587763;4.1473246;-1.3989923;0.87206256;CODE
than linearregression if we don t fix the min samples parameter;4.9588985;3.2329926;-2.2131016;0.10134411;-1.0525928;3.7807093;IRRE
for common tests we can enforce using linearregression that;4.3029633;2.6805713;-3.22383;6.1071253;1.509114;-0.75849897;CODE
is the default estimator in ransacregressor instead of ridge;0.8277316;0.095263995;-3.625393;0.5346373;-3.1547725;6.025493;CODE
be tolerant of noisy datasets not actually speed;5.777256;-3.3888826;-0.9004325;3.462968;0.017598372;1.6414422;IRRE
increases coverage because sgdregressor has partial fit;1.8358153;1.0667632;-3.094713;4.507881;0.5918767;3.7079844;-
selectkbest has a default of k 10;-2.9203024;-0.46822113;-1.3496292;-0.17183587;0.0368723;0.8078359;CODE
which is more feature than we have in most case;-1.1920466;-4.813881;2.6490395;3.4269476;2.449745;2.6648388;TASK
due to the jl lemma and often very few samples the number;2.4567707;2.8771055;-2.9500604;-0.255221;0.63076884;0.1490532;CODE
of components of the random matrix projection will be probably;4.273134;-1.662304;0.38637084;-1.3980302;0.33654502;5.525103;IRRE
greater than the number of features;3.531569;-1.6051373;1.0233966;-1.444881;2.1616719;-2.047291;TASK
so we impose a smaller number avoid auto mode;-0.58266664;1.8654246;1.0545621;1.0332569;1.026372;1.5321138;CODE
default auto parameter can lead to different ordering of eigenvalues on;-0.35666806;2.5409255;-3.7337983;-0.48525566;-1.9014933;5.372456;IRRE
windows 24105;-4.1728673;-1.8316725;0.071327776;-2.207598;0.81782526;-1.5271086;CODE
truncatedsvd doesn t run with n components n features;-0.9103888;0.15834318;-4.4016953;-3.494321;0.115116544;2.1808805;CODE
this dictionary stores parameters for specific checks it also enables running the;-2.7969177;-0.64956105;-2.2112873;2.6465652;2.3178298;-1.412125;CODE
same check with multiple instances of the same estimator with different parameters;2.6560905;6.2007923;-1.1464463;4.565666;0.8080452;2.4444695;IRRE
the special key allows to apply the parameters to all checks;-3.882912;1.3042128;-1.7071748;0.34326023;3.3345566;-0.39122286;IRRE
todo devtools allow third party developers to pass test specific params to checks;-4.326108;1.3224695;-3.974033;5.064901;0.03610084;-0.7103511;TASK
todo devtools check that function names here exist in checks for the estimator;-0.38952285;2.4812346;-3.8285978;3.8720865;-3.3127394;-0.0033836411;CODE
todo 1 9 simplify when averaged inverted cdf is the default;-0.7444631;2.8883827;-1.7184595;-0.049875375;-2.269748;1.0948807;CODE
using subsample none leads to a stochastic fit that is not;3.6453793;1.1728628;-2.6703622;2.995436;0.96366113;3.2231524;-
handled by the check sample weight equivalence on dense data test;5.7607813;3.713946;-4.1876497;3.9847808;1.7834146;-0.5289727;IRRE
the kmeans strategy leads to a stochastic fit that is not;3.5448496;-2.0756543;-0.8642786;2.9837017;-1.0986116;3.9759407;-
handled by the check sample weight equivalence test;4.018366;5.4937806;-2.7928572;4.5025034;2.2176445;-1.1850384;IRRE
todo dual true is a stochastic solver we cannot rely on;1.1553324;-2.1229284;-1.7178354;4.92897;0.75656056;3.3319914;TASK
check sample weight equivalence to check the correct handling of;4.4808884;5.2253556;-1.9699262;2.039786;1.7280631;-0.86802524;-
sample weight and we would need a statistical test instead see;4.6815343;2.2821043;2.0136724;3.9560587;1.8755729;-1.7025182;IRRE
meta issue 162298;-6.48059;0.45152333;-0.54835093;0.34309542;0.112297334;-1.435208;-
dict max iter 20 dual true tol 1e 12;-2.1139448;1.1822053;-3.9365683;-2.394289;0.35700175;-0.81280977;-
raise additional warning to be shown by pytest;-3.4815075;2.3363242;-2.8589787;2.819814;-2.8716218;1.0378679;TASK
todo devtools enable this behavior for third party estimators as well;-1.3959072;-1.4135251;-3.5037057;5.1728315;-2.6819224;5.971269;CODE
partial tests;2.379412;3.3451421;1.6680729;6.3900833;1.6341684;-5.1412215;IRRE
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo investigate failure see meta issue 16298;-6.538229;1.259825;-2.7562375;4.59205;-3.8700993;-1.666155;TASK
todo investigate failure see meta issue 16298;-6.538229;1.259825;-2.7562375;4.59205;-3.8700993;-1.666155;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test when dual true see meta issue 16298;-0.39646953;3.9777577;-4.469843;5.171942;0.49630827;-1.8633744;CODE
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo fix sample weight handling of this estimator see meta issue 16298;1.3925651;1.8894322;-4.8631544;2.862809;-2.9158013;3.8459616;CODE
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo fix sample weight handling of this estimator when probability false;3.3841984;4.2114434;-3.1517043;4.200997;-1.346665;2.621292;CODE
todo replace by a statistical test when probability true;1.8536065;4.255625;1.2182847;4.875652;0.7444322;-4.5761867;TASK
see meta issue 16298;-7.329501;-1.8045387;-1.6661128;1.2368091;-0.56835;-0.27686572;-
todo fix sample weight handling of this estimator see meta issue 16298;1.3925651;1.8894322;-4.8631544;2.862809;-2.9158013;3.8459616;CODE
todo fix sample weight handling of this estimator see meta issue 16298;1.3925651;1.8894322;-4.8631544;2.862809;-2.9158013;3.8459616;CODE
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
todo replace by a statistical test see meta issue 16298;-0.072205186;3.7684038;-2.5508235;4.013288;-0.43585402;-4.544643;TASK
valueerror found array with 0 feature s shape 23 0;0.9411863;1.6228989;-5.432606;-4.283193;-4.424752;-3.5008945;TASK
while a minimum of 1 is required;0.46532616;4.3788705;0.5372413;0.10450283;3.6608808;-3.6934514;CODE
todo fix sample weight handling of this estimator when probability false;3.3841984;4.2114434;-3.1517043;4.200997;-1.346665;2.621292;CODE
todo replace by a statistical test when probability true;1.8536065;4.255625;1.2182847;4.875652;0.7444322;-4.5761867;TASK
see meta issue 16298;-7.329501;-1.8045387;-1.6661128;1.2368091;-0.56835;-0.27686572;-
todo fix sample weight handling of this estimator see meta issue 16298;1.3925651;1.8894322;-4.8631544;2.862809;-2.9158013;3.8459616;CODE
todo remove when scipy min version 1 11;-3.084901;-1.7797967;-4.410206;-0.44590044;-5.1761847;-2.1440818;TASK
both dense;-1.0437796;-0.56868786;3.1699808;-0.35024554;-0.23913707;-1.5326593;-
import numpydoc noqa f401;-2.3600602;-2.0366197;-3.2038012;-6.013762;-3.874757;-2.3519816;CODE
decorator for tests involving both blas calls and multiprocessing;-1.0921683;0.852138;-2.9588;4.004164;0.3012717;0.90479565;IRRE
under posix e g linux or osx using multiprocessing in conjunction;-2.108343;-4.951454;-0.17222768;-0.19116184;0.86943454;1.9260595;-
with some implementation of blas or other libraries that manage an;-0.723057;-4.887227;0.1017684;-1.0024385;3.278831;1.4491355;TASK
internal posix thread pool can cause a crash or a freeze of the python;-3.9530451;-0.6978892;-2.377186;1.1473182;-4.6052237;-0.64087445;CODE
process;-2.272222;-1.9580925;6.6889133;2.5393014;1.2602227;-2.9893475;-
in practice all known packaged distributions from linux distros or;-1.5297582;-5.8894963;-0.123819955;-0.19695881;1.7483711;0.15418975;META
anaconda of blas under linux seems to be safe so we this problem seems;-3.6727135;-2.3603323;-3.608863;-0.82581663;-3.1231287;0.9676943;CODE
to only impact osx users;-2.9717224;-3.5756505;2.0025978;2.440692;-1.2362683;0.7986647;-
this wrapper makes it possible to skip tests that can possibly cause;-3.224048;1.1756549;-1.6004623;8.1833935;-0.46457255;-2.2317061;CODE
this crash under os x with;-4.496063;-2.7928424;-0.7037414;-0.9792591;-1.9339566;-1.7756716;CODE
under python 3 4 it is possible to use the forkserver start method;-5.132472;-1.39788;-0.19239908;1.347035;-2.7003288;1.9694461;CODE
for multiprocessing to avoid this issue however it can cause pickling;-1.9175992;-1.0204214;-2.3998418;2.3498452;-2.1590078;1.6856678;CODE
errors on interactively defined functions it therefore not enabled by;-6.444577;1.6508456;-2.320625;1.1678542;-3.0456681;-0.6133448;CODE
default;-5.2986646;-1.8012849;4.161423;0.8626395;-0.7494437;1.3156078;CODE
this can fail under windows;-5.934265;-0.7167335;-0.8132159;1.0765631;-2.3963802;-0.302052;CODE
but will succeed when called by atexit;-4.4015045;0.42744404;0.96764725;4.8148046;-0.9530408;-0.6469943;IRRE
utils to test docstrings;-2.2235558;0.27767923;-1.6141979;5.0439363;2.8523247;-5.923036;CODE
doctest skip;-2.5290146;2.3285568;-1.2707695;6.3460045;-0.75166583;-3.9705224;IRRE
include params y true y pred sample weight doctest skip;1.4064369;2.4750369;-3.9006546;4.9760904;1.03428;-0.8872247;CODE
include params true doctest skip;-2.587417;3.9152086;-2.9991624;6.2672753;0.6251794;-0.9058078;CODE
doctest skip;-2.5290146;2.3285568;-1.2707695;6.3460045;-0.75166583;-3.9705224;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
avoid recalculating unique in nested calls;1.277566;5.731664;0.72653526;2.6231842;3.1787646;0.34247702;IRRE
in case y is not a numpy array;3.175854;2.955795;-1.3778707;-5.9608645;-5.4896708;-2.7946725;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
adapted from joblib logger short format time without the windows 1s;-1.6865611;-3.6855798;-1.2283052;0.871129;-1.7030741;0.985399;CODE
adjustment;-0.57437694;0.07614712;6.6075516;0.24128884;-1.8211081;-0.2948251;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
adapted from https wiki python org moin pythondecoratorlibrary;-3.4508889;-5.8689694;-3.0068743;-1.1392393;-2.142909;-1.3704829;CODE
but with many changes;-1.5335767;-2.1030197;5.0211153;2.7938318;0.84935486;0.2382151;META
note that this is only triggered properly if the deprecated;-6.8558173;-0.67799145;-2.6582363;5.0226197;-0.7768289;3.0631373;TASK
decorator is placed before the property decorator like so;-6.341158;1.6879213;1.0586323;2.1509852;-0.019888248;4.967839;CODE
deprecated msg;-4.816001;-2.749227;-2.0277784;2.187816;-0.62600696;0.4516273;OUTD
property;-3.019564;0.5613889;4.9167747;2.5739522;2.8801267;-1.5725248;-
def deprecated attribute self;-4.1611295;0.43277165;-4.6963024;3.0310202;0.0639675;0.9825633;CODE
restore the original signature see pep 362;-5.81651;0.37835637;-1.8284203;-0.8888216;-0.90535897;0.6865157;-
estimator fit x y should pass;2.4219005;3.3997233;0.6850957;1.2232345;-3.8584135;3.2814054;-
estimator fit x y should fail with appropriate error;1.6096925;4.849984;-2.4262822;1.6065183;-5.597534;1.7076975;-
got the right error type and mentioning sparse issue;2.8587735;1.9206234;-5.556921;-0.9456523;-1.9601134;0.63686025;IRRE
catch deprecation warnings;-2.6472392;2.999204;-4.3090596;7.525603;-1.4931645;-1.0015578;CODE
catch deprecation warnings;-2.6472392;2.999204;-4.3090596;7.525603;-1.4931645;-1.0015578;CODE
fit and predict;6.491295;-1.4848835;4.1707144;2.990336;-0.7246302;-2.416236;-
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 23988;-3.4793544;-10.062437;-6.1857376;-0.51608545;-5.0070977;-5.316854;CODE
https github com scikit learn scikit learn issues 24013;-3.5453136;-10.025476;-6.1985626;-0.67776066;-5.1178646;-5.439552;CODE
check that estimators will accept a sample weight parameter of;2.5575297;4.5793657;-2.7716973;2.516819;-1.9238737;1.7586712;IRRE
type pandas series in the fit function;3.2922995;-0.5784437;-1.8590821;-3.505764;-5.25111;-0.35301256;CODE
check that estimators will accept a sample weight parameter of;2.5575297;4.5793657;-2.7716973;2.516819;-1.9238737;1.7586712;IRRE
type notanarray in the fit function;2.7621834;3.5157347;-2.6575518;-3.741919;-2.3789597;0.114022925;CODE
check that estimators will accept a sample weight parameter of;2.5575297;4.5793657;-2.7716973;2.516819;-1.9238737;1.7586712;IRRE
type list in the fit function;4.062105;1.6558356;0.29674256;-1.1967255;-0.38290063;-0.59566563;CODE
test that estimators don t raise any exception;1.5147291;6.9387164;-4.6019588;7.456841;-3.239595;-1.3468317;CODE
check that estimators raise an error if sample weight;3.3148687;5.447909;-3.1085722;4.643373;-3.2873688;0.71079123;IRRE
shape mismatches the input;0.8148997;2.2940178;0.44950724;-3.50909;-4.035988;-1.224805;CODE
check that setting sample weight to zero integer is equivalent;4.073671;5.8917584;-3.3136764;0.0020117494;-0.32166597;-0.37175608;IRRE
to removing repeating corresponding samples;6.133704;2.8469594;1.2593299;-1.8667831;3.2833436;-0.7449101;-
use random integers including zero as weights;3.230066;2.3829024;-0.38271308;-2.085278;0.9449197;-0.39230928;IRRE
repeat samples according to weights;6.797203;1.2556903;2.7209475;-0.12902957;1.9517577;0.70963997;-
when the estimator has an internal cv scheme;1.154532;0.24105905;-2.8976364;4.364962;-0.43103957;4.0773187;CODE
we only use weights repetitions in a specific cv group here group 0;3.0749557;1.4792323;-1.8995135;0.23766652;2.1047995;1.4302931;-
convert to sparse x if needed;5.1722007;2.6025875;-1.3305193;-4.576218;0.46581677;1.7041756;IRRE
check that estimators don t override the passed sample weight parameter;2.767479;4.3284206;-4.6171446;3.8140845;-2.6574469;3.181964;IRRE
check that estimators treat dtype object as numeric if possible;2.9611948;2.0520985;-6.384191;-0.16773576;-3.2784944;-0.46231622;IRRE
this error is raised by;-5.434346;2.786061;-3.8500526;0.5629176;-0.74244136;-2.7478971;CODE
np asarray in check array;0.40081632;3.8528826;-1.7785609;-3.0729122;-2.086179;-4.317998;-
unique python for encoders;1.7639177;-2.2468748;-2.4239938;-2.7205205;1.4124107;0.19327678;CODE
estimators supporting string will not call np asarray to convert the;0.4597045;2.2370408;-5.865141;-1.0567471;-4.470274;1.0859113;IRRE
data to numeric and therefore the error will not be raised;2.7008948;5.3150387;-4.202052;-1.1019571;-2.9483292;-3.81642;CODE
checking for each element dtype in the input array will be costly;4.77956;2.6194355;-2.6013436;-1.1039459;0.21012191;-3.974039;CODE
refer to 11401 for full discussion;-3.7171938;-3.5482028;1.3057946;0.9115741;0.97617155;-1.6101849;CODE
check that estimators raise an exception on providing complex data;3.5128102;5.427706;-3.4991114;4.8266187;-1.1403365;1.1952254;CODE
something both valid for classification and regression;4.4680796;-4.615242;1.1077198;4.5977902;3.4264143;-1.1022811;CODE
check that fit method only changes or sets private attributes;2.440142;4.119129;-2.0119402;4.576072;1.0094532;2.6108444;CODE
to not check deprecated classes;-2.2432444;0.79724556;-3.7772605;4.648886;1.0683038;-0.6514323;IRRE
check that fit doesn t add any public attribute;-0.2881469;4.802793;-3.9465854;2.3010707;0.7534599;1.4911399;CODE
check that fit doesn t change any public attribute;0.8126844;5.053629;-3.2364495;2.633159;0.7522988;2.0494776;CODE
check by fitting a 2d array and predicting with a 1d array;8.413454;2.67868;-0.2771058;-3.4222755;-2.8515825;-0.11573158;-
apply function on the whole set and on mini batches;3.613526;1.4901901;1.9947126;0.37979072;1.018548;2.0563128;CODE
func can output tuple e g score samples;4.788378;-0.3687411;0.1991752;0.46344507;2.5495214;-4.2973914;IRRE
check that method gives invariant results if applied;2.173587;5.0896573;-2.9480245;4.6381097;0.38594273;-0.69127834;IRRE
on mini batches or the whole set;2.9307525;-1.7202911;3.6417468;2.4766495;2.326373;2.0039756;IRRE
check that method gives invariant results if applied;2.173587;5.0896573;-2.9480245;4.6381097;0.38594273;-0.69127834;IRRE
on a subset with different sample order;2.5774186;2.843472;3.4791632;-0.6072502;4.582531;0.048360154;IRRE
check that fitting a 2d array with only one sample either works or;6.441888;6.1321816;-1.8471874;-3.1833277;-2.9998765;-1.110407;-
returns an informative message the error message should either mention;-4.5395756;3.2747455;-3.0554433;3.0063074;-0.013321544;-2.296904;CODE
the number of samples or the number of classes;4.002557;-1.744391;0.9595449;0.60353684;5.752869;-2.6437485;IRRE
min cluster size cannot be less than the data size for optics;3.4074266;0.4254879;-3.0491917;-2.5043144;-2.217653;4.6338077;CODE
perplexity cannot be more than the number of samples for tsne;2.1897304;2.3041446;-3.010434;-1.3899573;0.5568258;-0.17085735;CODE
check fitting a 2d array with only 1 feature either works or returns;5.5400743;5.5683074;-2.6608107;-2.7487702;-2.3907564;-1.4277022;TASK
informative message;-1.9174262;-3.1998007;4.9547257;2.4929528;3.1314557;-1.7187423;CODE
ensure two labels in subsample for randomizedlogisticregression;4.098525;0.4228405;-2.8929636;2.2400558;4.5207024;3.0506918;IRRE
ensure non skipped trials for ransacregressor;-0.12662196;4.2716064;-2.1612191;5.884897;1.1649754;0.069154486;CODE
check fitting 1d x array raises a valueerror;5.212883;5.3716664;-6.385507;-3.3344564;-6.1894684;-0.44983113;IRRE
try the same with some list;-1.403931;-0.35944948;0.6719537;2.0964732;-0.94711345;-1.137309;CODE
fit;0.26204967;0.27998868;4.9577327;0.11692925;0.031527434;-1.2871358;-
fit transform method should work on non fitted estimator;2.6353748;3.0249937;-2.9688184;-0.03304332;-4.9438553;5.808803;CODE
check for consistent n samples;6.504501;5.5737605;-1.440509;1.195609;1.7064288;-3.9191127;CODE
raises error on malformed input for transform;-0.8209678;2.8393364;-4.890381;-2.033406;-3.70507;-0.510261;CODE
if it s not an array it does not have a t property;-1.8299572;5.407389;0.18509537;-1.0814109;-1.1286621;-2.3927402;CODE
check that make pipeline est gives same score as est;0.096574366;2.0386565;-4.3253975;2.7015898;-1.7055098;-1.5325845;CODE
minibatchkmeans;-0.027570518;-3.2839143;2.7758482;-1.4953896;-0.24366143;-1.1523558;-
catch deprecation warnings;-2.6472392;2.999204;-4.3090596;7.525603;-1.4931645;-1.0015578;CODE
valueerror was raised with proper error message;-1.4708207;4.6707973;-5.53652;1.4867498;-3.9152822;-2.3324194;IRRE
x should be square for test on svc with precomputed kernel;2.194863;0.4682429;-4.7493663;-2.019463;-3.3947833;1.37071;IRRE
ample weight y copy select a single class;2.6334946;0.75767165;0.27460206;-0.711834;2.735897;1.439399;CODE
raise the proper error type with the proper error message;-3.6562994;5.654212;-4.2589874;2.3902097;-1.2728593;-0.9806777;IRRE
for estimators that do not fail they should be able to predict the only;3.7193363;-0.0007915696;-1.0791178;7.1754317;-2.104143;0.97648406;CODE
class remaining during fit;1.7038057;0.6455024;-0.26005572;2.3436365;1.6161661;0.54234225;CODE
ignore warnings warnings are raised by decision function;-0.779881;2.2946298;-4.0155993;5.2366767;-0.80750936;-0.20257251;CODE
generate binary problem from multi class one;1.4730971;0.58803403;-1.6274446;-2.1617365;5.613948;-3.8026578;CODE
raises error on malformed input for fit;1.4339316;2.8156261;-5.267189;0.6015565;-2.670551;-0.86925113;CODE
fit;0.26204967;0.27998868;4.9577327;0.11692925;0.031527434;-1.2871358;-
with lists;1.196336;-1.6646925;6.4251823;-1.1655153;2.9277132;-5.145351;-
training set performance;6.4382744;-3.1593978;2.0983136;3.248158;2.4762514;-0.2497591;IRRE
raises error on malformed input for predict;1.5125926;1.1475185;-5.19005;2.8103209;-2.5899582;-2.0810823;CODE
decision function agrees with predict;2.946058;-0.5665384;1.1546761;3.7092397;0.8137996;-1.1077201;CODE
raises error on malformed input for decision function;0.010600505;2.2222474;-3.9922116;1.7852367;-0.53646725;-2.657085;CODE
predict proba agrees with predict;2.5834951;-1.5120419;1.1059487;4.0515037;-0.10741664;-1.5748531;-
check that probas for all classes sum to one;0.4186462;2.2789884;-2.4582179;1.4448278;4.3762565;-4.282356;CODE
raises error on malformed input for predict proba;1.5827441;1.174364;-5.258593;3.0953956;-1.9351902;-2.535686;CODE
predict log proba is a transformation of predict proba;0.8533014;-1.5139569;-0.81130326;1.6972648;-0.77211976;0.49185437;CODE
check for deviation from the precise given contamination level that may;4.0119214;4.6619573;-1.2736048;2.1146324;-0.1805515;-4.200743;CODE
be due to ties in the anomaly scores;2.8857028;-0.037733633;0.44749624;2.4888678;1.3208528;-1.1570033;CODE
ensure that all values in the critical area are tied;3.8291724;4.7659416;1.0423611;-0.6457673;-0.60579157;0.31285203;IRRE
leading to the observed discrepancy between provided;1.3697271;3.4551804;-1.0703335;2.9835272;0.34266075;-1.4155415;-
and actual contamination levels;0.46536893;-0.30530655;0.5024434;2.817853;1.5768645;-1.5285299;-
fit;0.26204967;0.27998868;4.9577327;0.11692925;0.031527434;-1.2871358;-
with lists;1.196336;-1.6646925;6.4251823;-1.1655153;2.9277132;-5.145351;-
raises error on malformed input for predict;1.5125926;1.1475185;-5.19005;2.8103209;-2.5899582;-2.0810823;CODE
decision function agrees with predict;2.946058;-0.5665384;1.1546761;3.7092397;0.8137996;-1.1077201;CODE
raises error on malformed input for decision function;0.010600505;2.2222474;-3.9922116;1.7852367;-0.53646725;-2.657085;CODE
decision function is a translation of score samples;4.093269;-1.3163292;0.5824571;2.3490229;3.7983057;-1.6791015;CODE
raises error on malformed input for score samples;2.4120128;2.5097997;-5.2415485;2.587643;-0.5784301;-3.4049602;CODE
contamination parameter not for oneclasssvm which has the nu parameter;-0.06196085;2.1402903;-6.617944;0.18501359;1.1373911;1.890967;IRRE
proportion of outliers equal to contamination parameter when not;3.0796268;4.1817465;-1.2332536;1.5941485;-1.4370456;0.6843767;IRRE
set to auto this is true for the training set and cannot thus be;-0.95143753;0.08029873;-1.9641157;3.762022;0.7140177;0.6167945;IRRE
checked as follows for estimators with a novelty parameter such as;1.5732087;2.2192233;-1.4664042;2.4062977;0.86437887;3.5837798;IRRE
localoutlierfactor tested in check outliers fit predict;3.5378385;1.7224405;-5.4341564;3.4945674;-3.6779869;1.4794065;IRRE
num outliers should be equal to expected outliers unless;4.5262146;3.558965;-1.9649895;0.29184094;-0.8235708;0.13559757;CODE
there are ties in the decision function values this can;2.343568;0.73270315;1.0575755;0.18920985;3.9430325;-0.5434407;CODE
only be tested for estimators with a decision function;3.8906531;3.5438368;-1.9688425;7.0126214;-0.35904494;-0.09363586;CODE
method i e all estimators except lof which is already;2.6492093;0.8877921;-0.018616205;3.6130319;-0.93520653;3.0460513;CODE
excluded from this if branch;-3.5043418;5.172992;-0.056980886;2.646744;2.4843419;-2.5217624;CODE
check that the contamination parameter is in 0 0 0 5 when it is an;0.13747162;6.494964;-3.967282;1.1014866;-0.9654554;-3.5083742;IRRE
interval constraint;-0.46287566;3.5414836;2.8899796;-2.153106;-0.017597172;-0.3608539;CODE
only estimator implementing parameter constraints will be checked;0.3729365;4.3549685;-5.34891;3.5421238;-2.3615978;5.2336426;CODE
y pred shape y test shape with the same dtype;3.3553085;1.0066999;-2.3074112;-1.4490694;-1.5507076;-1.174836;IRRE
y pred shape 2 possibilities;0.85708296;0.46663946;4.8727493;-4.9398274;0.27028963;-1.8118;-
list of length n outputs of shape n samples 2;5.424569;0.26409367;1.5722803;-5.1970363;1.3647457;-3.161002;IRRE
ndarray of shape n samples n outputs;5.925548;-0.84497744;-0.64160085;-7.018869;-2.1705484;-0.31314403;IRRE
dtype should be floating;-2.1551418;-0.75643146;-3.4917214;-2.5788798;-4.379035;-1.7189678;CODE
check that we have the correct probabilities;1.3346995;3.221893;1.931317;3.3945312;0.69931865;-6.43333;-
y pred shape y test shape with floating dtype;2.9666324;1.2676134;-3.2062294;-3.1640038;-3.739628;-1.4592065;IRRE
this is run on classes not instances though this should be changed;-5.429863;1.1856805;-1.7310387;4.771969;2.0025778;2.6312804;CODE
this is a very small dataset default n iter are likely to prevent;0.382088;0.30006078;-2.8876371;0.43363836;-1.779691;1.811517;CODE
convergence;0.3073665;0.97739786;3.871022;3.6744318;-2.4856074;-1.161663;-
let the model compute the class frequencies;4.165449;-1.4151742;1.0263344;0.53622836;3.459284;-0.7633723;CODE
count each label occurrence to reweight manually;4.646449;0.47701558;1.6220139;-1.133286;1.7345426;0.0041214526;-
make a physical copy of the original estimator parameters before fitting;2.1036384;1.6311228;-2.0884757;2.374929;-3.180512;7.6307635;IRRE
fit the model;1.4823507;-1.8818413;3.3056061;0.78029215;0.8633571;-0.14115278;-
compare the state of the model parameters with the original parameters;3.7725406;4.419971;0.6445102;4.359139;0.40011388;1.4968098;IRRE
we should never change or mutate the internal state of input;-1.8537865;2.1284065;1.6110898;3.353423;-0.8474577;1.4697244;CODE
parameters by default to check this we use the joblib hash function;-3.4090097;1.9563148;-2.8350272;2.4894083;-1.1593027;-0.9870965;CODE
that introspects recursively any subobjects to compute a checksum;-1.9184101;0.4747739;-0.7100692;2.539246;4.2666197;-2.287515;CODE
the only exception to this rule of immutable constructor parameters;-3.2648408;2.2175;-3.0851138;1.9593672;3.279061;3.3209105;CODE
is possible randomstate instance but in this check we explicitly;-0.7629333;3.194193;-2.5814009;5.2247252;2.5960352;0.05322458;CODE
fixed the random state params recursively to be integer seeds;0.42831004;2.324629;-0.42789575;0.42802078;1.2854832;-0.55250764;IRRE
and it should have a default value for this test;-3.0489097;4.9541225;-2.8262107;3.4599428;-0.4618618;-2.3233047;CODE
here we check vars because we want to check if the method is;-3.3748631;4.816158;0.30820763;4.753326;-2.1233327;-4.8918934;IRRE
explicitly defined in the class instead of inherited from a parent class;-4.44553;0.6800769;-1.9187667;1.7411047;2.8970408;2.600146;CODE
check that calling fit does not raise any warnings about feature names;-0.5830701;1.3759365;-6.576467;4.7359776;-0.4634905;0.83567667;CODE
only check sklearn estimators for feature names in in docstring;1.3358171;-2.2533474;-6.4573607;3.6293612;-0.50392526;-1.4629402;CODE
method x works without userwarning for valid features;-1.9560516;2.5483744;-4.49493;6.7080865;-0.88737285;0.6500914;TASK
partial fit checks on second call;3.6563559;5.986112;-0.9187377;4.8482833;0.5826358;0.7964982;IRRE
do not call partial fit if early stopping is on;0.7245415;4.17695;0.67254084;5.266943;-0.91282195;3.5785098;IRRE
input features names is not the same length as n features in;-0.5075279;0.20143549;-1.9503032;-3.1152172;0.7898829;-2.4645402;TASK
error is raised when input features do not match feature names in;-1.9045289;1.541167;-5.4783087;1.6666689;-0.34357706;-2.0320458;CODE
check that an informative error is raised when the value of a constructor;-0.72895086;4.733537;-2.8268535;5.173407;1.8039488;-2.5984724;CODE
parameter does not have an appropriate type or value;-3.822443;5.807283;-2.335055;-1.3954176;-0.82883805;-1.5751898;IRRE
check that there is a constraint for each parameter;0.74743104;6.652405;-1.865563;-0.09747526;2.2761014;-1.0183605;CODE
this object does not have a valid type for sure for all params;-4.1770363;4.177879;-2.9650445;-0.22610588;0.30778378;-0.900066;CODE
this parameter is not validated;-4.549326;6.0823307;-3.768274;0.19855922;-0.54998857;-1.9265033;IRRE
mixing an interval of reals and an interval of integers must be avoided;-0.40016428;4.3738704;1.6583529;-1.4433957;-0.56339586;-0.23574217;CODE
first check that the error is raised if param doesn t match any valid type;-2.904097;6.8730345;-6.672676;1.1259537;0.15982288;-1.6395994;CODE
the method is not accessible with the current set of parameters;-3.303953;3.7557628;-1.6563555;2.6823559;-2.1534967;0.7204844;IRRE
the estimator is a label transformer and take only y;1.999845;0.9184279;-0.61277443;-1.0622231;-2.1463737;3.3925018;IRRE
then for constraints that are more than a type constraint check that the;0.3369097;3.620695;-3.5266492;1.1380119;4.856494;-0.6759249;CODE
error is raised if param does match a valid type but does not match any valid;-2.0968637;7.605538;-6.858815;1.6768448;0.38706696;-1.71272;CODE
value for this type;-0.48301297;2.9042594;2.1724322;-3.1873145;3.257727;-4.7911286;CODE
the method is not accessible with the current set of parameters;-3.303953;3.7557628;-1.6563555;2.6823559;-2.1534967;0.7204844;IRRE
the estimator is a label transformer and take only y;1.999845;0.9184279;-0.61277443;-1.0622231;-2.1463737;3.3925018;IRRE
check transformer set output with the default configuration does not;-1.1427695;4.6239705;-2.1574233;1.3542241;-2.8096893;0.9292816;CODE
change the transform output;-1.2112877;1.576194;2.9425106;-3.9299657;-2.6098735;0.5075335;IRRE
auto wrapping only wraps the first array;-1.3707008;3.5601356;1.2745144;-0.030009598;-1.7009858;1.5905386;-
default and no setting returns the same transformation;-2.6096272;3.0458014;-0.7909896;-1.7400929;-3.178256;3.8605456;CODE
fit then transform case;1.1001117;1.7125885;2.3633022;-3.0656693;0.68328017;3.1531308;CODE
fit transform case;1.1509719;0.561601;1.6545465;-3.531887;-0.111237936;3.4535058;CODE
we always rely on the output of get feature names out of the;-2.217046;-2.6186583;-1.823193;4.980669;1.9919;0.38751122;TASK
transformer used to generate the dataframe as a ground truth of the;2.215575;-1.5153576;-0.6148928;-2.7980454;-2.9493566;0.45031184;OUTD
columns;2.9453604;-0.8405486;5.620917;-6.0069814;2.320245;-2.1489592;-
if a dataframe is passed into transform then the output should have the same;1.7869139;2.787794;-1.2459371;-2.2807128;-3.847142;0.07205309;CODE
index;0.29790318;1.256712;4.503265;-2.879716;2.5969608;-3.2702115;-
check transformer set output configures the output of transform pandas;1.5889959;0.80178994;-3.5046852;-1.6579258;-4.606903;-0.574886;IRRE
else global;-3.1191795;-0.047123466;3.8423913;1.4803561;1.2574177;-0.13067685;-
transformer does not support sparse data;2.1854422;-0.027317276;-3.288649;-2.094461;-2.5763123;4.0767407;CODE
except importerror pragma no cover;-3.753929;0.38586035;-4.3403754;1.4779485;-4.3509793;-1.1542615;CODE
except importerror pragma no cover;-3.753929;0.38586035;-4.3403754;1.4779485;-4.3509793;-1.1542615;CODE
these estimators can only work inplace with fortran ordered input;2.5448215;2.7416594;-5.285335;-2.0211706;-5.099844;2.512435;CODE
add a missing value for imputers so that transform has to do something;-1.1616496;3.1191735;-1.2580149;-2.381544;-1.1868317;-0.6580576;CODE
make x read only;-2.9927154;2.4400122;0.9705381;0.039953787;-1.0341232;0.83049095;CODE
generating normal random vectors with shape a shape 1 size;3.8718183;-1.3783413;1.1846782;-5.889752;-0.4939063;3.1699774;IRRE
xxx generate random number directly from xp if it s possible;-1.2865872;0.7246851;0.20955557;-2.3021345;3.200918;-1.0158502;IRRE
one day;-1.2387277;-1.4215972;5.020358;1.606552;-0.22077456;-1.8997167;-
use float32 computation and components if a has a float32 dtype;0.39343953;0.38840768;-5.008091;-3.890781;0.4628264;0.3966875;CODE
move q to device if needed only after converting to float32 if needed to;-2.4165647;2.8675492;-1.0251504;-2.207;-1.446425;2.7415848;CODE
avoid allocating unnecessary memory on the device;-1.0129347;0.762306;0.5278006;0.9199487;0.6269865;4.059115;IRRE
note we cannot combine the astype and to device operations in one go;-3.149256;-1.2798241;-1.571863;0.23108818;3.3822658;2.3163545;TASK
using xp asarray dtype dtype device device because downcasting;-1.437125;-0.8614736;-4.051526;-1.0996951;-0.8812815;3.1107416;CODE
from float64 to float32 in asarray might not always be accepted as only;-3.5636923;2.4702413;-5.129373;-3.4479468;-2.7478359;1.1788526;CODE
casts following type promotion rules are guarateed to work;-2.123823;1.5555068;-2.3435223;0.6324106;4.531601;0.7462923;-
https github com data apis array api issues 647;-3.0957434;-0.43531552;-3.621534;-1.5241681;-3.4661913;-0.67751575;CODE
deal with auto mode;-3.0287673;0.43459842;2.7136748;2.0822544;-0.82434905;3.4290085;-
xxx https github com data apis array api issues 627;-2.973029;-0.07555952;-3.8866205;-1.5038126;-3.4814353;-0.75531995;CODE
use scipy linalg instead of numpy linalg when not explicitly;1.0638962;-1.8060395;-6.534643;-3.2757766;-5.8598237;2.6057796;TASK
using the array api;-0.93342817;1.3141131;2.5796192;-0.7920972;-0.12718433;-1.5898561;CODE
perform power iterations with q to further imprint the top;0.88732463;1.6690143;4.2015853;-1.1063085;1.6369569;1.2920736;CODE
singular vectors of a in q;-0.33630455;0.9981733;-1.2165043;-3.806717;-0.7576564;0.90494144;-
sample the range of a using by linear projection of q;4.0276403;3.708453;1.828715;-3.2950253;-1.2872782;1.0831515;CODE
extract an orthonormal basis;1.9457371;-0.466835;-0.4728095;-5.3645024;0.63027304;2.6845448;-
weights 1 3 0 5 1 5 1 2 deweight the 4 s;2.7007215;0.091555364;2.8946896;-4.9382367;0.37058905;-1.8146248;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
todo we can consider removing the containers and importing;-3.7483602;-2.3306308;0.15992045;1.2609005;0.086702324;2.876379;CODE
directly from scipy when sparse matrices will be deprecated;3.9523053;-4.0359974;-5.9209743;-0.8140859;-3.825885;1.5986457;IRRE
remove when minimum scipy version is 1 11 0;0.061300155;-0.44651952;-6.162018;-2.0878227;-4.1613317;-2.3881967;META
from scipy sparse import sparray noqa f401;2.3640823;-2.8180788;-4.417139;-5.2614913;-4.2597528;0.2896469;CODE
todo remove when scipy 1 11 is the minimum supported version;-2.1839526;-2.555145;-6.2061257;-0.41952643;-4.3196425;-1.475176;TASK
scipy stats mode has changed returned array shape with axis none;3.0236971;0.36695296;-2.9797752;-4.783109;-8.104031;-0.56690127;IRRE
and keepdims true see https github com scipy scipy pull 17561;3.2100656;-2.5903664;-5.262304;-5.1087365;-4.0270615;0.036649384;CODE
todo remove when scipy 1 12 is the minimum supported version;-2.0316124;-2.712415;-5.9703617;-0.49076992;-4.4025555;-1.5485364;TASK
todo fuse the modern implementations of sparse min max and sparse nan min max;3.9627273;-1.0453336;-3.0863674;-3.3718631;-0.11744388;2.6607938;TASK
into the public min max axis function when scipy 1 11 is the minimum supported;3.4030414;-0.6999575;-4.3449264;-5.675629;-4.450603;1.109971;CODE
version and delete the backport in the else branch below;-6.9777203;1.3804041;1.6941606;0.12868893;0.73248816;2.0862617;CODE
this code is mostly taken from scipy 0 14 and extended to handle nans see;0.6774499;-1.4255186;-4.4943423;-6.254156;-4.990679;-4.210299;CODE
https github com scikit learn scikit learn pull 11196;-2.7906435;-10.287288;-3.9939272;-1.4929237;-3.987596;-4.660592;CODE
reduceat tries casts x indptr to intp which errors;-0.45775658;3.007979;-5.5341578;0.41906792;-2.7753334;0.25769758;CODE
if it is int64 on a 32 bit system;-5.364697;0.61813945;-0.6514047;-3.341082;0.053014968;-1.9329466;CODE
reinitializing prevents this where possible see 13737;-6.3948526;0.080221154;-0.69834816;3.6392486;-1.1115477;0.93203497;IRRE
for 1 25 numpy versions exceptions and warnings are being moved;-1.4450455;0.30790117;-6.705409;-0.7963641;-7.1355953;-0.70108634;CODE
to a dedicated submodule;-2.1136663;-0.59292656;2.03084;0.9994483;0.46261397;3.2309256;CODE
from numpy import noqa f401;-0.18088822;-1.6151878;-2.7084827;-6.8712983;-5.5109844;-1.2984432;CODE
todo adapt when pandas 2 2 is the minimum supported version;-1.1770723;-2.1901937;-3.90526;0.3235241;-2.92019;1.9064789;TASK
todo remove when scipy 1 12 is the minimum supported version;-2.0316124;-2.712415;-5.9703617;-0.49076992;-4.4025555;-1.5485364;TASK
else requested sparse format coo;-0.06776881;0.06601492;-2.155784;-3.0530467;2.0917778;0.007938147;CODE
todo remove when scipy 1 12 is the minimum supported version;-2.0316124;-2.712415;-5.9703617;-0.49076992;-4.4025555;-1.5485364;TASK
when check contents is false we stay on the safe side and return;-5.1667647;4.9900374;0.44678128;5.0266423;-2.20827;-2.333483;IRRE
np int64;-2.6980793;-0.9483686;-1.394056;-6.000698;-2.0000918;-4.4942036;CODE
a bigger type not needed yet let s look at the next array;0.6966075;2.3841817;2.4800847;-3.4816742;1.7867332;-2.976543;TASK
a big index type is actually needed;2.5870016;-0.9337038;-1.1395298;0.024193037;4.1551332;0.6355728;META
todo remove when scipy 1 12 is the minimum supported version;-2.0316124;-2.712415;-5.9703617;-0.49076992;-4.4025555;-1.5485364;TASK
laplacian noqa f401 pragma no cover;-1.1209781;0.10566928;-0.21870288;-2.672045;-0.41571704;2.151517;-
todo remove when python min version 3 12;-5.9168262;0.11922214;-2.38064;1.0075144;-3.4163973;-0.58133733;CODE
use filter data to prevent the most dangerous security issues;0.6599166;0.9172841;0.702572;1.281123;2.1504393;0.24706051;CODE
for more details see;-3.8513157;-2.7091296;3.7665563;0.5036314;0.3860323;-1.7852823;CODE
https docs python org 3 library tarfile html tarfile tarfile extractall;-4.0512257;-2.2297032;-2.3160706;-0.9768469;-2.8045254;-0.65768063;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
this is a modified file from scipy optimize;2.008856;-3.5429854;-2.8166833;-4.433356;-4.3552103;-1.803017;CODE
original authors travis oliphant eric jones;-1.8154012;-3.987365;-1.3456243;-0.13038127;-1.0694929;-0.2063425;META
have a look at the line search method of our newtonsolver class we borrow;4.4148583;-1.0671823;0.40941897;-1.8821405;-2.2012665;0.9427243;CODE
the logic from there;-2.0853095;-0.089134775;3.1734045;2.4296274;0.22108845;-3.187973;CODE
deal with relative loss differences around machine precision;6.0191116;1.6659722;-2.9599328;1.1646955;-1.5642803;1.4134854;-
2 1 check sum of absolute gradients as alternative condition;2.2688084;3.2996688;-0.6830469;-1.4745361;-0.125523;1.0706837;-
1 0 step size;1.1065298;2.7170582;1.1182351;-4.12391;-1.5240872;-0.7857854;-
ret 1 1 number of function evaluations;1.6155999;1.1878636;0.61845213;0.23016891;0.42085052;-2.8109233;CODE
ret 2 1 number of gradient evaluations;4.0277305;-1.9349084;-1.4317205;-0.39182687;0.11908668;0.95002955;-
line search failed try different one;-3.4553616;2.8973699;-1.1715182;0.61144406;-1.9979475;-2.5689297;CODE
todo it seems that the new check for the sum of absolute gradients above;1.746686;-0.13517486;-3.1877334;0.01090348;-2.5107224;3.6392164;CODE
catches all cases that earlier ended up here in fact our tests never;-0.35853583;2.5711281;-1.8253547;7.4250617;-1.086901;-4.787044;CODE
trigger this if branch here and we can consider to remove it;-6.773074;0.5548581;0.93326813;3.1636505;1.2333975;0.5181867;CODE
ri np copy fgrad residual fgrad fhess p xsupi;1.5536737;-0.8784829;-4.109277;-3.0671659;-2.0770016;1.8678147;-
we also keep track of p i 2;-0.85534275;-1.5643251;2.3703845;3.2756028;1.1912345;0.3185821;-
check curvature;1.1789563;0.8409705;0.7160312;-1.4866056;-3.433633;-0.84008634;-
see https arxiv org abs 1803 02924 algo 1 capped conjugate gradient;-0.8152839;-2.7566688;-4.598261;-2.3939838;-1.1701877;4.662558;CODE
fall back to steepest descent direction;1.2913381;0.7374564;1.6933309;0.8496718;-1.8665309;2.455771;CODE
we use p i 2 r i 2 beta i 2 p i 1 2;-2.281348;-1.5503113;1.2210127;-1.5032808;2.6237671;-1.766991;-
dri0 dri1 update np dot ri ri for next time;-2.561648;0.2056389;-2.5280912;-0.9571876;-0.27194276;0.5096035;CODE
outer loop our newton iteration;1.8691144;0.52585024;2.4838762;-0.97372895;-2.5173955;-0.94597113;IRRE
compute a search direction pk by applying the cg method to;1.6874905;0.7148545;-0.86395395;-1.2741662;-0.058747504;-0.690941;-
del2 f xk p fgrad f xk starting from 0;-0.7783961;2.0025146;-0.9644751;-5.144942;-1.9149809;-2.8419666;CODE
inner loop solve the newton update by conjugate gradient to;1.1974295;-0.88962364;-0.6364543;-1.1807749;-3.1421852;2.232493;CODE
avoid inverting the hessian;0.78534365;-0.0634624;-1.4411246;-1.0784534;-4.1702213;4.119388;CODE
xk alphak xsupi upcast if necessary;-3.2391756;-1.740931;1.1534339;-1.0528675;-0.4165292;1.3465539;-
handle both scipy and scikit learn solver names;-1.1370686;-7.6365004;-5.6108756;0.32553837;-2.76653;-2.8820996;-
in scipy 1 0 0 nit may exceed maxiter for lbfgs;1.9302866;-0.46873716;-7.0828724;-2.8760843;-4.145513;-0.842191;CODE
see https github com scipy scipy issues 7854;-1.3019043;-4.8941483;-6.7491655;-3.2388258;-7.838766;-2.8643327;CODE
append a recommendation to increase iterations only when the;1.1429726;2.1574438;4.2555447;3.3339255;2.3089457;0.8071003;CODE
number of iterations reaches the maximum allowed max iter;0.2875259;2.0261674;1.2026879;0.767067;-0.5605998;-1.3882471;-
as this suggests the optimization may have been prematurely;2.8257039;1.1641121;-2.0871356;1.2959031;-2.3311021;2.7153802;CODE
terminated due to the iteration limit;-0.7278746;3.8362873;-0.060622014;2.0786443;-3.5429347;-2.6842945;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
global threadpool controller instance that can be used to locally limit the number of;-0.41768607;0.51482064;1.6454672;2.5779722;0.20904776;3.6119957;IRRE
threads without looping through all shared libraries every time;-0.7319931;-1.8855271;0.70168275;2.5330234;-0.26512292;2.4755087;IRRE
it should not be accessed directly and get threadpool controller should be used;-4.88354;-0.6257867;0.32029927;1.1166826;-2.8474934;3.5854218;CODE
instead;-3.4498208;-1.8747259;4.7573843;1.0487124;-1.2410853;-0.27382374;-
todo is there a simpler way that resetwarnings filterwarnings;-1.5914235;0.49854258;0.06927151;3.74727;-1.4455016;4.2119527;TASK
some small discrepancy between warnings filters and what;-0.5983218;0.29490831;-4.515544;3.6406898;-1.040672;0.33082005;-
filterwarnings expect simplefilter is more lenient e g;1.6119518;1.2228534;-2.0864558;5.0854936;-0.98088646;1.6266308;-
accepts a tuple as category we try simplefilter first and;-0.17495012;0.2932187;-1.0068209;1.3627818;2.590191;0.06052412;CODE
use filterwarnings in more complicated cases;2.626281;0.6480088;-0.39719787;4.233928;1.3342855;3.783785;CODE
message and module are most of the time regex pattern but;-3.854155;0.7647612;-1.660257;1.4818128;0.6282283;-0.27363235;CODE
can be str as well and filterwarnings wants a str;-2.3892682;-0.51850647;-0.24020779;0.205148;1.0845759;0.23089851;-
else axis 0;-0.72887516;4.6166444;4.0672607;-8.010833;-4.4065504;-2.006741;-
the following swapping makes life easier since m is assumed to be the;-1.8042058;1.9053538;1.1351806;0.45248228;1.8773605;1.8068743;-
smaller integer below;-0.57165766;3.1276696;2.302366;-3.5618896;-0.12263352;-3.9033802;CODE
modify indptr first;-3.3137887;1.0583926;0.16692372;-0.41718203;0.057883654;1.2616118;-
we rely here on the fact that np diff y indptr for a csr;0.72142386;-0.71287155;-4.4967227;0.028984334;-0.112183;-0.9377994;CODE
will return the number of nonzero entries in each row;3.3741412;4.06445;1.741918;-3.4570723;2.6695487;-5.694912;IRRE
a bincount over y indices will return the number of nonzeros;0.99902093;3.340233;-1.1624092;-5.294569;-0.27485177;-4.4764695;IRRE
in each column see csr matrix getnnz in scipy 0 14;3.2234287;-0.28631532;-2.5838902;-7.8213735;-3.6174014;-2.9841046;-
astype here is for consistency with axis 0 dtype;1.0213141;0.7270649;-3.5897875;-5.11467;-1.925729;1.2935797;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
sample weight should follow array for dtypes;5.820154;1.2885767;-3.976042;-2.4963722;-0.8440782;0.9034176;CODE
when sample weight 1d repeat for each array shape 1;7.0765057;2.7926018;0.53480625;-3.4613547;0.10037652;1.3756537;CODE
sort array and sample weight along axis 0;6.099628;3.0951564;1.4240508;-4.2504563;-2.7157762;1.0228983;-
set nan values in sample weight to 0 only perform this operation if nan;3.5722892;5.606027;-1.926443;-1.2787824;-2.649079;-0.7176574;IRRE
values present to avoid temporary allocations of size n samples n features;7.3176723;0.11146597;-1.8671083;-0.40023333;3.183547;0.8535859;IRRE
nan values get sorted to end largest value;2.9886024;3.4892514;-0.28280067;-4.443292;-4.5800066;-2.2784925;IRRE
compute the weighted cumulative distribution function cdf based on;0.21976013;0.67297;0.5156363;-1.3552594;-1.1442311;-0.24390548;CODE
sample weight and scale percentile rank along it;4.5097475;0.73288506;1.8496333;-1.0661663;0.4373803;1.9684922;-
note we call xp cumulative sum on the transposed sorted weights to;3.3284779;-0.78914285;-0.2186085;-3.528786;1.2726656;2.9084067;TASK
ensure that the result is of shape n features n samples so;6.306258;1.6641967;-0.8727446;-1.2568023;1.9707361;-0.67793214;TASK
xp searchsorted calls take contiguous inputs as a result for;0.4036022;4.1158056;-0.5717271;-0.9890031;1.9830151;0.33082497;IRRE
performance reasons;1.3525753;-1.3455973;4.0526147;4.999657;0.8064087;-0.13032968;CODE
ignore leading sample weight 0 observations;4.4857473;4.9866276;-1.3348645;0.9336368;-1.4428291;1.5248141;-
when percentile rank 0 20528;1.5150278;-0.896571;-0.4340529;-1.9487389;0.05961061;-3.0539072;-
for each feature with index j find sample index i of the scalar value;5.889234;1.188832;-0.38062093;-3.7683277;1.4793802;-0.7292363;CODE
adjusted percentile rank j in 1d array weight cdf j such that;5.195316;1.863155;-0.027541524;-3.6822462;-1.1254493;2.4267027;-
weight cdf j i 1 adjusted percentile rank j weight cdf j i;3.7934635;0.94420415;-0.39263391;-2.0170112;-0.2784948;1.3231233;-
note searchsorted defaults to equality on the right whereas hyndman and fan;-1.3493645;-0.07919832;-1.6943103;1.1056627;0.43822762;2.2678566;TASK
reference equation has equality on the left;-3.5359364;3.0027463;0.53221744;-2.5313616;-1.6170115;1.0370249;CODE
percentile indices may be equal to sorted idx shape 0 due to floating;2.1250536;3.9999096;-2.886654;-5.900968;-3.7648752;0.9674863;CODE
point error see 11813;-2.3559997;2.774356;-3.0288632;-3.2545826;-3.2509658;-2.7117758;CODE
from hyndman and fan 1996 fraction above is g;-0.07205653;0.95231223;0.36574656;-4.075085;-0.93126684;-1.9388367;CODE
handle case when next index plus one has sample weight of 0;3.361359;6.3146653;-0.778997;-0.73066413;2.5666122;0.012295708;CODE
search for next index where weighted cdf is greater;2.7651622;2.8103027;0.44322228;-0.3411485;0.3600636;0.118557304;CODE
handle case where there are trailing 0 sample weight samples;4.1965895;5.4722357;-2.9643772;0.6413918;0.6582186;0.9242186;CODE
and percentile indices is already max index;1.5554836;1.8865416;-0.8678544;-2.4073048;-0.7059041;1.4097236;CODE
use original percentile indices again;1.4177879;3.0757425;0.34506845;-2.4082007;-1.5143671;1.4475398;-
check that the initialization a sampling from an uniform distribution;-0.25477996;3.9466712;0.41343027;1.8044475;-0.8734723;-0.3239941;CODE
where we can fix the random state;-0.2578153;-0.6396453;1.6049979;3.9230542;-0.2925307;-1.184593;IRRE
sparse and none to numpy;4.5950565;-0.6014483;-2.3198903;-5.9044995;-4.180171;0.49916977;IRRE
sparse to non numpy;6.566741;-1.5515819;-1.6171743;-5.8681846;-3.5799334;2.430119;IRRE
def test convert to numpy gpu library pragma nocover;0.9174105;-0.16382764;-6.3177795;-2.2360666;-5.215241;-2.722496;CODE
use torch as a library with custom device objects;-4.077851;-4.410414;-0.40108413;-0.85296506;-0.017637994;4.129969;IRRE
when dispatch is disabled get namespace and device should return the;-6.580779;0.43272042;-0.8060164;2.668928;-0.6137555;3.8626237;CODE
default numpy wrapper namespace and cpu device our code will handle such;-1.0658612;-2.7667558;-3.9946415;-2.8395727;-3.392902;1.9404639;CODE
inputs via the usual array interface without attempting to dispatch;-0.81828517;2.038878;1.0474501;0.08116725;0.8715087;1.1223568;CODE
via the array api;-1.0077996;-0.9677126;3.0664709;-1.0042022;1.075457;-0.97572625;CODE
otherwise expose the torch namespace and device via array api compat;-4.587553;-2.5361187;-0.539028;-1.2502313;-1.2221489;4.737942;IRRE
wrapper;-3.09708;-2.489132;4.462807;1.9273549;0.9155511;-1.2431828;-
numpy 2 0 has a problem with the device attribute of scalar arrays;1.6230524;0.1743894;-5.4939027;-4.8980412;-6.3880067;0.92846745;META
https github com numpy numpy issues 26850;-2.6675432;-3.3775895;-5.9018745;-4.586438;-9.033847;-2.1360133;CODE
for numpy 2 the device attribute is not available on numpy arrays;-0.12789443;-0.42914134;-5.344466;-4.6642985;-5.8049107;0.8532674;META
note depending on the value of axis this test will compare median;2.4799402;4.572877;1.4760778;-1.2549908;-4.105929;-2.663898;IRRE
computations on arrays of even 4 or odd 5 numbers of elements hence;1.2330569;1.4517527;0.5066897;-4.2247;0.72702295;-3.9272652;-
will test for median computation with and without interpolation to check;4.7302046;4.270803;-0.13287085;2.4161723;-2.003471;-2.227508;CODE
that array api namespaces yield consistent results even when the median is;1.6090765;2.0439289;-3.703952;-0.43200818;-1.3323619;1.5227741;IRRE
not mathematically uniquely defined;-0.03764247;1.3782284;0.13014358;-2.6872115;3.1118;-0.70994484;IRRE
we convert array api strict arrays to numpy arrays as median is not;3.1715686;1.9045871;-3.5128713;-4.0492415;-5.534464;0.07504086;CODE
part of the array api spec;-1.113915;-0.60854644;-0.5081653;0.044375304;2.1206343;-0.2764331;CODE
if torch on cpu or array api strict on default device;-2.540365;1.4063038;-2.7574186;1.5657092;-2.1833158;2.702149;CODE
check that logsumexp works when array api dispatch is disabled;-3.9087765;4.0130725;-1.7214265;2.479439;-1.7987895;1.5096852;CODE
test with nans and np inf;2.9336321;4.9105077;-3.8446405;-0.33034363;-3.2782617;-5.521325;IRRE
check that min pos returns a positive value and that it s consistent;2.7950194;6.412411;-0.95945686;0.29473057;-2.0362327;-3.0814335;IRRE
between float and double;0.5432228;1.7389069;2.6346629;-3.5293102;-1.5780805;-1.7481834;CODE
check that the return value of min pos is the maximum representable;3.7425787;5.1001296;-1.611654;-1.8786217;1.7116493;-0.8074136;IRRE
value of the input dtype when all input elements are 0 19328;1.8279834;2.6596265;-3.346258;-5.325646;-1.512062;-4.633143;CODE
check that return value is false when there is no row equal to value;1.7338636;8.945272;-0.46533826;-0.022549566;-0.94205654;-5.891125;IRRE
make a row equal to value;2.9585984;4.744718;4.2021413;-4.782451;1.2146523;-4.4613905;IRRE
check that gen even slices contains all samples;1.9331678;3.729968;-3.2015054;0.15154296;0.7488426;-3.1955307;-
test and demo compute class weight;3.8656685;1.5416893;-3.2462766;1.9846432;1.1262388;-3.2849748;IRRE
total effect of samples is preserved;3.00185;1.8074524;2.1515307;1.7105495;0.924107;2.6491811;-
non regression for https github com scikit learn scikit learn issues 8312;-0.13489985;-7.163997;-7.9056106;2.030137;-6.8731027;-3.3324294;CODE
raise error when y does not contain all class labels;1.2229941;3.3189998;-3.634405;1.7680085;1.3943698;-1.2109045;CODE
when the user specifies class weights compute class weights should just;1.5132976;0.05294321;-2.328033;2.9645033;1.6377748;3.2212038;IRRE
return them;-2.2742088;2.795334;2.6786308;1.1868789;-1.6940086;-2.1032214;IRRE
when a class weight is specified that isn t in classes the weight is ignored;1.1166948;2.8811145;-3.4415848;2.2356539;0.8676606;1.7534231;IRRE
test that results with class weight balanced is invariant wrt;3.350692;3.4941404;-4.997163;3.69876;1.4424866;-1.3271648;IRRE
class imbalance if the number of samples is identical;5.057267;3.2989;-0.44660515;1.7845291;3.7988274;-2.9396524;IRRE
the test uses a balanced two class dataset with 100 datapoints;6.2420053;2.7979023;-2.7081816;2.2703001;1.2469212;-4.266937;IRRE
it creates three versions one where class 1 is duplicated;-4.293811;-0.5106115;-1.5499197;1.3158989;5.298349;-0.43050814;IRRE
resulting in 150 points of class 1 and 50 of class 0;2.4061034;2.156166;-0.95223653;-1.2819942;0.6780404;-3.0833259;CODE
one where there are 50 points in class 1 and 150 in class 0;1.9462327;-1.8270661;1.8907005;-1.3160917;2.9025335;-4.2285733;CODE
and one where there are 100 points of each class this one is balanced;3.3496068;-0.58181363;2.449834;-0.2766732;4.916361;-2.7041144;CODE
again;-3.2608151;-1.0276685;3.6217077;0.9600814;-0.111803465;-2.5749447;-
with balancing class weights all three should give the same model;3.0718713;1.2950691;0.44587848;0.7819442;3.6906035;0.916021;CODE
create dataset where class 1 is duplicated twice;4.044216;0.69454926;0.03432793;-0.4613491;4.568187;-0.9092408;IRRE
create dataset where class 0 is duplicated twice;4.418885;1.3111349;-0.8866198;-1.1342616;3.9646032;-1.370453;IRRE
duplicate everything;-2.2239325;-0.7527957;5.7076006;2.2125833;3.0439126;-0.5061358;-
results should be identical;3.1067522;3.350458;0.7158576;2.5727463;1.02733;-3.5179112;IRRE
test compute class weight when labels are negative;4.1368027;3.3232782;-3.1207633;-0.2131502;0.8218097;-2.3427234;IRRE
test with balanced class labels;3.9018896;3.5765269;-1.4761603;1.5124973;4.0238714;-5.086002;IRRE
test with unbalanced and negative class labels for;3.6724098;3.788265;-2.1460383;0.83434457;2.1489756;-4.620665;IRRE
equivalence between repeated and weighted samples;4.243205;1.2502946;1.0105361;1.4050637;2.4777486;1.7707322;-
test compute class weight when classes are unordered;4.156904;3.0368803;-2.1541798;1.2828006;3.3631847;-2.602541;IRRE
test for the case where no weight is given for a present class;2.0506668;4.956994;-0.51093966;3.405264;2.739586;-3.8566184;CODE
current behaviour is to assign the unweighted classes a weight of 1;2.4514892;1.4660188;-2.424701;1.2481911;2.3086174;2.6653643;IRRE
test for non specified weights;4.4808326;5.6713886;-2.1705008;2.8042681;0.4003232;-3.1011577;IRRE
tests for partly specified weights;5.7828846;4.5779405;-1.890793;3.9910815;0.67531973;-1.9169997;IRRE
test and demo compute sample weight;3.9241014;3.2118068;-1.6436878;1.9483284;-0.050352138;-3.290605;IRRE
test with balanced classes;3.054167;4.2905436;-0.9335015;3.1987214;3.6146095;-5.848011;IRRE
test with user defined weights;4.0703;4.908694;-1.1890212;3.898844;0.17616497;-2.800113;IRRE
test with column vector of balanced classes;4.971978;3.192993;-2.7072675;-1.3413656;2.7218938;-3.9296072;IRRE
test with unbalanced classes;3.639007;4.5273705;-1.5949504;3.5851774;2.448511;-5.7889333;IRRE
test with none weights;3.8696668;6.090944;-1.606745;3.1040244;-0.8746753;-4.487502;IRRE
test with multi output of balanced classes;3.6375887;4.588915;-0.8810974;2.3279147;3.8908494;-5.3530326;IRRE
test with multi output with user defined weights;5.2045317;4.794907;-0.98105717;2.5346918;0.61998326;-2.4070213;IRRE
test with multi output of unbalanced classes;4.4149055;4.4230027;-1.2012767;2.3923664;3.268858;-5.2740445;IRRE
test compute sample weight with subsamples specified;5.5969005;4.122311;-2.1445787;0.7623461;1.8718832;-2.4788165;IRRE
test with balanced classes and all samples present;3.5588486;3.784162;-1.3055168;2.4635096;3.9099617;-4.6488595;IRRE
test with column vector of balanced classes and all samples present;5.504524;2.7376578;-2.5271108;-0.91465074;2.8783703;-3.5997455;IRRE
test with a subsample;3.3926182;5.6748257;0.00047861907;4.5313263;2.8747494;-5.231611;IRRE
test with a bootstrap subsample;3.2453444;3.5474563;-0.92758584;4.6187644;3.1339018;-2.0983667;IRRE
test with a bootstrap subsample for multi output;4.674635;3.6793234;-1.1117122;3.424252;3.389757;-1.939362;IRRE
test with a missing class;0.01507063;4.2639494;-1.9837488;3.7153735;1.6784618;-7.1573386;IRRE
test with a missing class for multi output;2.082158;5.038647;-2.3351452;3.2310796;2.409408;-6.249318;IRRE
test compute sample weight raises errors expected;4.065338;5.030389;-5.8987284;3.125334;-3.4809492;-2.363243;IRRE
invalid preset string;-3.5577078;3.2785213;-1.9698547;0.65418905;-0.81672853;-1.7730237;IRRE
non regression smoke test for 12146;1.0996879;3.846853;-3.359348;2.9050565;-2.0955575;-3.7226233;IRRE
y np arange 50 more than 32 distinct classes;1.0818071;-0.5944408;-1.5142438;-2.336162;3.3661263;-2.6842537;IRRE
indices np arange 50 use subsampling;4.50937;1.4823098;-2.689029;-3.5295653;-0.23975775;2.1764653;-
does not raise;-3.9978693;2.110138;2.6024492;0.5077656;-2.0819256;-1.3762244;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.037616;-0.2815502;-8.332158;-5.3351135;10.930536;0.44712412;-
deprecated n features is deprecated type ignore prop decorator;-4.554452;0.33082363;-5.630139;2.546208;0.25352314;2.7559838;OUTD
test for the check unknown parameter of encode;-0.029684642;6.15778;-4.55721;0.37088776;0.29420996;-4.0976973;IRRE
default is true raise error;-3.7690516;3.8623435;-3.0702734;1.7759916;-2.9642622;1.453828;CODE
dont raise error if false;-1.3882866;8.561136;-2.3883266;5.7046356;-1.1827915;-3.3150487;CODE
parameter is ignored for object dtype;-2.8126018;1.614774;-5.4453955;-0.2732311;-1.9746075;0.8714975;IRRE
check for check unknown with missing values with object dtypes;1.3937166;4.0820603;-5.9062395;0.89654833;-0.10764458;-4.8462186;IRRE
check for unique and encode with missing values with object dtypes;3.3625903;2.649399;-5.178033;-1.1148713;2.1508832;-3.226128;IRRE
else missing value np nan;1.392399;4.0651555;-3.4860082;-4.758271;-3.7405093;-4.9212594;IRRE
check missing values in numerical values;4.6428547;7.030309;-1.6972308;-1.857262;-1.1623299;-5.682322;IRRE
test for all types of missing values for object dtype;2.28807;3.3771176;-5.160713;1.4035338;0.28850183;-4.666734;IRRE
last value is nan;0.3497004;4.503324;0.61161494;-5.4103327;-3.9342368;-6.1073117;IRRE
test for both types of missing values for object dtype;2.2193215;4.022062;-5.2462707;1.2454653;0.5817009;-4.7555614;IRRE
we can not use pytest here because we run;-4.8850727;-1.713657;-1.0296457;0.96853155;-3.9318717;-0.4851693;IRRE
build tools azure test pytest soft dependency sh on these;-2.8323276;-1.0770565;-3.6455364;3.006122;-1.8189279;0.74290407;IRRE
tests to make sure estimator checks works without pytest;1.6536438;4.9103456;-4.963527;6.912847;-4.1409216;-1.0988728;IRRE
note that object is an uninitialized class thus immutable;-4.1071243;1.8192255;-1.6552404;0.53396934;1.6911187;1.6379266;IRRE
raise for type str expects sparse array or sparse matrix;2.1747713;1.5660783;-6.2466145;-3.408278;-1.6209676;1.4969767;IRRE
convert data;3.4583275;1.7953041;3.2347634;-5.340973;0.31145278;-3.96531;-
function is only called after we verify that pandas is installed;-1.8962146;0.0974553;-4.935673;0.6293604;-5.761286;-2.3537407;IRRE
intentionally modify the balanced class weight;1.9164562;1.2356528;-1.439654;3.2317445;2.4953172;2.1805582;CODE
to simulate a bug and raise an exception;-2.3895433;4.217856;-0.78207797;6.973823;-0.71361655;-2.4814963;CODE
simply assigning coef to the class weight;2.8243332;-0.43133676;-2.6341105;0.7599105;2.507569;2.5321875;IRRE
convert data;3.4583275;1.7953041;3.2347634;-5.340973;0.31145278;-3.96531;-
return 1 if x has more than one element else return 0;-0.56843597;6.801001;1.2169167;-3.41337;1.6167321;-6.9968114;IRRE
store the original x to check for sample order later;0.777631;5.0555215;2.0330293;0.86944515;2.8442776;0.3657623;CODE
if the input contains the same elements but different sample order;4.2147107;5.5940633;2.911654;-1.3133752;3.8441133;-4.2596464;META
then just return zeros;0.019994734;5.542721;0.7616349;-2.8088493;-2.2544653;-3.9223337;IRRE
find the number of class after trimming;0.9313477;1.0693675;0.43726045;-0.71390533;4.1259193;-4.217501;IRRE
raise for type str expects sparse array or sparse matrix;2.1747713;1.5660783;-6.2466145;-3.408278;-1.6209676;1.4969767;IRRE
toy classifier that only supports binary classification will fail tests;1.1751648;-0.95923275;-4.7580776;4.240687;2.5911148;-3.3505988;IRRE
toy classifier that only supports binary classification;1.2950654;-5.053722;-1.870421;0.17412607;4.7989383;-1.0743928;IRRE
reject sparse x to be able to call x 0 any;0.8987502;3.5346768;-4.228877;-1.0830938;0.32667747;1.6448618;IRRE
reject sparse x to be able to call x 0 any;0.8987502;3.5346768;-4.228877;-1.0830938;0.32667747;1.6448618;IRRE
check that values returned by get params match set params;2.3083081;7.01912;-0.37729958;1.1598748;1.0703129;-3.412302;IRRE
check that predict does input validation doesn t accept dicts in input;1.606798;1.8576753;-4.343428;3.5597672;-0.6112135;-3.1332016;CODE
check that estimator state does not change;0.8426582;5.963445;-1.9995723;4.4441104;-3.641564;1.7880576;IRRE
at transform predict predict proba time;4.0355544;-2.0472443;-0.48479253;1.5366027;-1.2007457;1.576246;CODE
check that sample weights in fit accepts pandas series type;3.4557326;1.5163816;-4.5123253;-0.3226378;-3.921041;-0.42361555;-
from pandas import series noqa f401;0.31845313;-1.3596954;-2.5171921;-5.7040076;-4.6637526;-2.4566495;CODE
check that fit only changes attributes that;2.8398266;4.4137106;-0.37304142;3.067885;0.7295932;2.1989093;IRRE
are private start with an or end with a;-4.6077766;0.7466612;1.2429129;-0.08202803;3.3149855;-1.0430995;CODE
check that fit doesn t add any public attribute;-0.2881469;4.802793;-3.9465854;2.3010707;0.7534599;1.4911399;CODE
check for sample order invariance;3.5942366;4.402865;-0.5835637;0.012580412;0.8755546;0.044594362;CODE
check for invariant method;0.3863458;3.4771597;-2.188957;2.0897193;-0.48708758;0.74014235;CODE
check for sparse data input handling;6.3697176;2.1608913;-2.360294;1.2562762;1.1130372;-0.77751726;CODE
large indices test on bad estimator;3.5096095;4.1331506;-3.663976;4.235061;-3.556874;-0.115437284;IRRE
check for classifiers reducing to less than two classes via sample weights;6.9434366;0.34042546;-4.1681113;3.2544234;3.1935432;-0.5735365;CODE
some tests are expected to fail some are expected to pass;0.029033778;4.9275513;-2.1087327;6.7013507;-1.2248819;-5.707328;IRRE
some estimator checks rely on warnings in deep functions calls this is not;1.0324521;1.1812761;-5.647464;5.704985;-2.9790165;1.345139;CODE
automatically detected by pytest run parallel shallow ast inspection so we;1.0453675;1.2286301;-3.342789;2.7492335;-1.2372352;0.8449974;IRRE
need to mark the test function as thread unsafe;-1.7423072;4.1911;-2.9661343;4.3761287;-1.5364624;-2.2267673;CODE
tests that the estimator actually fails on bad estimators;1.1638502;4.891368;-3.9754655;6.967723;-5.5311203;-1.6873211;IRRE
not a complete test of all checks which are very extensive;0.55430424;3.0786178;-1.8584436;4.6595473;1.5946615;-6.7263494;CODE
check that we have a fit method;4.7719135;4.480309;-0.10001003;3.0116668;-1.2190244;-2.3441648;-
does error on binary only untagged estimator;-0.058572087;2.7441278;-6.1704826;1.1466008;-1.0309403;1.8989785;CODE
non regression test for estimators transforming to sparse data;5.079235;1.7757808;-3.0300446;3.3599553;-3.2373526;1.4891046;IRRE
doesn t error on actual estimator;-0.75036365;3.4513288;-3.1581922;1.9715849;-5.781767;-0.009403035;CODE
doesn t error on binary only tagged estimator;-0.70166385;2.5764296;-6.271346;1.2966691;-1.2948124;1.2307774;CODE
check regressor with requires positive y estimator tag;-0.48317364;5.032619;-3.311898;1.1576656;-2.762923;0.7353826;CODE
does not raise error on classifier with poor score tag;1.6627173;1.0613229;-4.8322973;3.7607539;1.3690034;-1.3592579;CODE
should raise assertionerror;0.117849104;4.724522;-6.423455;5.944519;-2.6487644;-2.1479485;CODE
should pass;-2.3277156;1.2147968;2.8984246;0.88974416;1.3044572;-2.3106637;-
estimator tag sparse accept sparse false fails on sparse data;3.162105;0.59649545;-5.8078423;1.6775484;-1.6644593;3.947972;IRRE
but does not raise the appropriate error;-5.1893682;5.13113;-2.6640053;2.2443757;-1.0056808;-4.4989376;CODE
check that transformermixin is not required for transformer tests to run;-1.819353;3.517451;-5.2682033;4.043853;-3.279693;-0.81633663;CODE
but it fails since the tag is not set;-6.991152;2.1991775;0.24107382;4.635553;-1.6597545;0.6625748;IRRE
check that check estimator doesn t modify the estimator it receives;0.11390698;6.2783003;-4.069803;4.6879807;-5.806319;0.46719563;CODE
without fitting;1.99267;0.6292839;5.275757;0.23566635;-1.3381469;1.5603473;-
with fitting;1.8480947;-0.6214822;5.4704;0.4214266;-1.4504654;1.398511;-
check that a valueerror attributeerror is raised when calling predict;2.335337;2.6267905;-5.690469;5.0126276;-4.706629;-1.7113835;IRRE
on an unfitted estimator;1.7306254;2.7029395;-1.4414216;5.215775;-0.8195023;2.7554328;-
check that correctnotfittederror inherit from either valueerror;-1.3377233;5.844216;-7.510148;4.301155;-2.0988493;-2.035763;IRRE
or attributeerror;-2.5653172;1.673687;-3.392469;1.9559548;-0.86183804;-4.464044;META
making sure our metadata request class attributes are okay;-2.1108649;-1.0438708;-3.3349223;3.5352316;3.2216194;3.4726386;CODE
return self pragma no cover;-4.4821224;3.2287204;0.15677899;3.071499;-1.2876407;1.3863785;CODE
a private class attribute is okay;-2.1845963;-0.40020287;-1.6263591;1.2720889;3.711335;2.0616984;CODE
also check if cloning an estimator which has non default set requests is;0.31492072;4.2067213;-3.9615388;5.8515587;-2.5166821;2.6561422;IRRE
fine setting a non default value via set method request sets the;-1.9625075;4.5739446;-0.32414916;3.7811756;-0.15187556;2.5905545;IRRE
private metadata request instance attribute which is copied in clone;-3.5627508;0.223742;-2.064499;2.0966132;-0.17250213;4.092844;CODE
some estimator checks rely on warnings in deep functions calls this is not;1.0324521;1.1812761;-5.647464;5.704985;-2.9790165;1.345139;CODE
automatically detected by pytest run parallel shallow ast inspection so we;1.0453675;1.2286301;-3.342789;2.7492335;-1.2372352;0.8449974;IRRE
need to mark the test function as thread unsafe;-1.7423072;4.1911;-2.9661343;4.3761287;-1.5364624;-2.2267673;CODE
check that check estimator works on estimator with pairwise;1.6979578;5.979545;-3.9376743;2.478986;-3.953467;0.30949026;-
kernel or metric;3.4242287;-3.6773472;2.167063;-1.5002452;1.0352912;0.8860553;-
test precomputed kernel;1.9010539;1.8264835;-2.8946793;2.8742042;-0.5437523;-1.9997289;IRRE
test precomputed metric;3.286558;2.8469226;-0.9264186;2.3789852;-0.9082043;-2.286618;IRRE
1 inconsistent array type;-0.051331315;5.7371974;-2.2318861;-2.9876883;-0.9699054;-3.4857461;META
2 inconsistent shape;0.47690013;3.5645714;1.9121281;-3.0142016;-1.8107135;-0.18434803;META
3 inconsistent dtype;-0.57581156;0.99977833;-3.8144426;-1.6780108;0.06471919;-3.1039436;META
1 unknown output type;-1.6676463;1.9688991;-2.175721;-3.2905326;-0.107234456;-4.177613;IRRE
2 for list output;1.4048707;1.3316367;2.9075432;-3.0806103;1.898983;-5.873784;IRRE
2 1 inconsistent length;-0.8810756;4.840264;-0.07177041;-2.4506803;-1.164291;-3.5816336;META
2 2 array of inconsistent shape;2.8608487;4.284165;1.649454;-4.931961;-1.0019134;-1.1133885;META
2 3 array of inconsistent dtype;1.5850022;3.3942902;-4.5680246;-4.7712584;-0.6697986;-3.0210912;META
2 4 array does not contain probability each row should sum to 1;1.2744528;3.396797;-0.74531895;-2.437808;-0.72549933;-2.5259576;CODE
3 for array output;0.68568206;2.6229408;2.940324;-5.4624143;1.3337854;-5.415302;IRRE
3 1 array of inconsistent shape;2.9736056;3.8852031;1.5191959;-5.750939;-0.76125056;-1.1401695;META
3 2 array of inconsistent dtype;1.5914412;3.247494;-4.641353;-4.6948123;-0.964093;-2.9184299;META
4 array does not contain probabilities;0.20417982;3.5224445;-0.85020226;-1.4857211;-0.007542844;-3.3967004;CODE
1 inconsistent array type;-0.051331315;5.7371974;-2.2318861;-2.9876883;-0.9699054;-3.4857461;META
2 inconsistent shape;0.47690013;3.5645714;1.9121281;-3.0142016;-1.8107135;-0.18434803;META
3 inconsistent dtype;-0.57581156;0.99977833;-3.8144426;-1.6780108;0.06471919;-3.1039436;META
this is to make sure we test a class that has some expected failures;0.5386824;3.4148488;-0.6016483;8.06045;1.7157904;-6.081513;IRRE
fixme this test should be uncommented when the checks will be granular;-0.19219244;5.6827273;-5.7417064;5.8980947;-0.7978488;-4.2039385;IRRE
enough in 0 24 these tests fail due to low estimator performance;3.0037951;4.81669;-4.9258747;4.263972;-4.236518;-3.5145917;IRRE
check that third party library can run tests without inheriting from;-4.5902386;2.17246;-5.498942;5.360153;0.18639645;-1.8432423;CODE
baseestimator;1.5318227;0.13747491;2.8189714;-0.979373;-0.18115994;1.1769083;-
fixme;-3.8509557;-1.3406411;3.207323;2.4430208;-0.8963127;-1.2272774;-
no warnings are raised;-4.3407;1.4317452;-2.394789;4.1579413;-2.5919235;-0.96621174;CODE
make an estimator that throws the wrong error to make sure we catch it;1.0550513;5.2528734;-2.3638291;5.7728534;-3.8743818;0.06223552;CODE
this assertion is just to make sure we are catching the value error;-1.2572287;5.715362;-4.0622754;4.9068956;0.0134144025;-0.6036313;CODE
that comes from wrong y none and not some other value error;-1.7658789;4.764297;-4.509826;-3.0190089;-3.4715817;-5.3061557;IRRE
override the error message force fail;-4.843484;4.287624;-3.1667106;4.8990684;-2.7949278;1.5231558;CODE
check estimators with non deterministic tag set to true;2.2442288;3.5939925;-3.2350776;5.497466;0.6874077;1.4349427;IRRE
will skip certain tests refer to issue 22313 for details;-2.660644;2.0708842;-4.4317765;6.3447757;-0.0129815;-2.7948713;CODE
return self pragma no cover;-4.4821224;3.2287204;0.15677899;3.071499;-1.2876407;1.3863785;CODE
now we check that with the parameter constraints the test should only be valid;0.1658083;6.7409625;-7.0232587;5.108172;0.5757507;-0.68276113;CODE
if an interval constraint with bound in 0 1 is provided;-0.29783878;4.194594;0.21987593;-1.8378919;-0.5261466;-0.20385359;CODE
add a correct interval constraint and check that the test passes;1.4195586;8.097597;-2.0146725;3.2100987;-0.45505756;-3.223256;CODE
interval integral 0 1 closed right not an integral interval;-3.5793383;2.1010401;-0.30792302;-2.1680331;-2.2318711;-0.9777301;CODE
interval real 1 1 closed right lower bound is negative;-1.9451134;2.304381;0.62048227;-0.99134946;-2.751345;-1.8683101;CODE
interval real 0 2 closed right upper bound is greater than 1;-2.578509;2.3257134;0.5066309;-1.4968542;-2.0340533;-2.6355352;CODE
interval real 0 0 5 closed left lower bound include 0;-1.4430094;3.2466753;0.38033003;-3.0109797;-1.968958;-3.0035193;CODE
test that yield all checks with legacy true returns more checks;1.0035557;5.229238;-3.293338;5.9204783;0.5541382;-3.8231006;IRRE
check that all non legacy checks are included in legacy checks;-1.9395869;3.8024595;-4.756688;3.049634;2.9031897;-0.35030198;CODE
return none pragma no cover;-2.874611;5.879848;-0.34010485;2.072727;-0.45680162;-0.89432037;IRRE
return none pragma no cover;-2.874611;5.879848;-0.34010485;2.072727;-0.45680162;-0.89432037;IRRE
return none pragma no cover;-2.874611;5.879848;-0.34010485;2.072727;-0.45680162;-0.89432037;IRRE
return none pragma no cover;-2.874611;5.879848;-0.34010485;2.072727;-0.45680162;-0.89432037;IRRE
this shouldn t fail since we allow both sklearn tags and more tags;-0.06556773;-4.4059815;-3.784428;4.092065;0.1265691;0.48148277;CODE
to exist so that third party estimators can easily support multiple sklearn;3.8534768;-5.973351;-3.1209126;3.4971907;0.33650744;2.9549823;-
versions;-3.4024818;-4.063949;3.6365564;1.1371632;1.261031;-2.4615967;META
we don t actually need to define the tag here since we re running the test;-3.3349965;0.4234372;-2.0944955;5.527429;1.7592583;-1.8672398;CODE
manually and baseestimator defaults to multi output false;0.461094;4.040361;-2.070205;0.748594;-1.9738427;4.0417304;IRRE
test that set output doesn t make the tests to fail;1.3380026;7.71053;-2.5719635;5.4412837;-2.843897;-6.5793595;IRRE
doing this since pytest is not available for this file;-3.9577973;-1.1739126;-0.99267036;-1.1752882;-3.2773588;0.6239897;CODE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
with uniform weights results should be identical to stats mode;4.86611;2.4602396;-0.87825996;1.1932782;-0.69237196;2.7512653;IRRE
set this up so that each row should have a weighted mode of 6;4.141571;2.3735602;3.0576947;-4.6725388;2.2015347;1.0056387;IRRE
with a score that is easily reproduced;3.8682902;-1.7222131;3.969162;4.4940553;2.7088864;-2.5719151;-
check that extmath randomized svd is consistent with linalg svd;3.5318477;0.4730128;-5.347946;0.24451774;-1.4665111;3.781969;IRRE
generate a matrix x of approximate effective rank rank and no noise;5.3529;0.26562986;-2.273777;-2.0930831;-0.8929772;4.3355174;-
component very structured signal;3.5443459;0.76014334;2.5531223;-3.9070678;1.6211412;5.040874;CODE
compute the singular values of x using the slow exact method;3.3852978;1.3219371;-2.651469;-2.6226385;-3.5128891;1.4376644;IRRE
convert the singular values to the specific dtype;3.6382873;0.57493013;-4.5388956;-5.24471;-2.0300198;-0.20351656;IRRE
for normalizer in auto lu qr none would not be stable;-1.3918638;1.7967079;-2.0179644;0.0864303;-1.8637555;5.8088613;CODE
compute the singular values of x using the fast approximate method;4.532012;0.6306892;-1.7740933;-3.5253673;-4.104703;1.7575749;IRRE
if the input dtype is float then the output dtype is float of the;0.8928379;1.1880689;-3.162976;-4.9229045;-3.2945502;-3.2780552;CODE
same bit size f32 is not upcast to f64;-4.3528943;1.5830781;-2.5077612;-3.811067;-2.5589676;0.87518525;-
but if the input dtype is int the output dtype is float64;-1.2287589;1.4403925;-4.1545625;-4.951569;-2.8883512;-3.3624797;CODE
ensure that the singular values of both methods are equal up to the;2.9117901;4.44226;-3.7542408;0.8008354;-1.5996966;1.1973884;IRRE
real rank of the matrix;0.62776756;0.467645;1.1933111;-3.2143154;-1.7257541;0.3331648;-
check the singular vectors too while not checking the sign;1.7093694;3.8566763;-4.240833;-4.136934;-3.3677619;-1.5389562;CODE
check the sparse matrix representation;4.859935;-0.3659267;-2.3890743;-4.055928;-0.79742527;0.85212284;IRRE
compute the singular values of x using the fast approximate method;4.532012;0.6306892;-1.7740933;-3.5253673;-4.104703;1.7575749;IRRE
the attributes like mean and var are computed and set with respect to the;1.7461169;0.092063464;1.3984318;-0.04488677;1.9000764;-0.021247022;IRRE
maximum supported float dtype;1.1270322;-0.97253615;-4.506795;-3.4909816;-0.6142557;0.82237864;CODE
testing of correctness and numerical stability;3.0876071;3.3215282;-1.7006619;4.0216417;-1.9610915;-4.1825967;IRRE
compare to weighted average np average;5.7743773;0.94391155;-0.25149792;-0.18408717;-1.7964177;-1.0056578;IRRE
compare to unweighted mean np mean;4.373353;1.7704686;-1.106904;0.3191302;-2.300328;-0.24125941;IRRE
test youngs and cramer incremental variance formulas;2.4735355;2.4106243;-1.8145881;2.6102507;-0.3908356;-1.7091796;CODE
doggie data from https www mathsisfun com data standard deviation html;1.1227068;-0.26680273;1.0262585;-4.035285;-1.8459879;-2.174504;CODE
test youngs and cramer incremental variance formulas;2.4735355;2.4106243;-1.8145881;2.6102507;-0.3908356;-1.7091796;CODE
naive one pass variance computation not numerically stable;4.164091;0.18204053;-5.846977;1.0305636;-2.5053432;0.28105372;IRRE
https en wikipedia org wiki algorithms for calculating variance;2.0507348;-4.159492;-0.9067777;-0.6462688;-0.41977724;-0.5920283;CODE
two pass algorithm stable;1.8780813;2.7136743;-0.8542991;1.3463182;2.444457;0.35185865;-
we use it as a benchmark it is not an online algorithm;3.6325054;-3.8884387;0.5096868;3.2226233;0.35580158;-0.09910481;-
https en wikipedia org wiki algorithms for calculating variance two pass algorithm;1.0624272;-1.940489;-1.9877673;-0.58952016;0.75772566;0.0427824;CODE
naive online implementation;0.1621266;-5.1048465;0.6014285;1.6513153;2.922598;-0.9247365;TASK
https en wikipedia org wiki algorithms for calculating variance online algorithm;1.3958942;-4.0425253;-1.0741526;-0.5291062;-0.26740864;-0.023571938;CODE
this works only for chunks for size 1;-1.0391226;1.8024468;0.6592351;-1.2757319;-0.7857614;1.4923276;CODE
we want to show a case when one pass var has error 1e 3 while;-2.55668;7.765497;-0.22522888;2.2225869;1.1618018;-3.925326;CODE
batch mean variance update has less;2.1319659;1.8153676;-1.3056073;1.8736019;-3.8198366;1.3845593;CODE
naive one pass var tol 1063;-2.7522974;2.1924736;-3.6813195;-0.89394164;2.2331433;-3.983164;CODE
starting point for online algorithms after a0;0.96497506;-2.263578;1.2789989;-0.43924573;1.2903619;-1.1529485;CODE
naive implementation tol 436;-2.7071302;-1.4653897;-3.9490955;-1.638231;3.701989;-1.185446;TASK
the mean is also slightly unstable;2.3589258;2.7869205;-0.24057475;1.3728608;-5.799928;0.56334424;-
robust implementation tol 177;-1.4716462;0.7666257;-3.272731;-0.3210612;0.44651407;-0.52720493;TASK
test that degrees of freedom parameter for calculations are correct;2.6069584;5.098802;-4.1665325;-0.47337776;-2.477814;-3.8436146;IRRE
assign this twice so that the test logic is consistent;0.9008348;8.769563;-1.8379983;4.7481513;2.6593466;-4.0555634;IRRE
testing that sign flip is working largest value has positive sign;0.3694625;5.581119;-0.8634601;0.9678938;-1.8718572;-3.6364336;IRRE
dense nd sparse;4.621049;-2.5207143;-1.9441524;-3.8186712;0.35398087;3.3802037;IRRE
sparse dense nd;4.0888257;-2.3399076;-1.7086982;-4.0916853;0.6780275;3.4871416;IRRE
2d 1d;0.36573917;-0.19410871;5.0410776;-6.2197223;-0.92876965;-1.1208637;-
1d 2d;0.6119053;-0.6228757;4.134954;-6.4933505;-0.95047283;-0.5246063;-
draws 25 of the total population so in this case a fair draw means;0.8884789;2.770683;4.634427;1.4392053;0.619648;-2.0508697;CODE
25 99 000 24 750;-0.86334276;0.6322165;1.6116157;-3.1008282;-1.2796681;-4.3929873;-
25 1 000 250;-0.29292795;-0.24527927;1.7331868;-2.742854;-1.3226712;-4.1044855;-
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
np int32 default behaviour;-3.581048;1.0917562;-5.1665726;-2.5844557;-3.0102813;0.85700846;CODE
arrays dtype is int64 and thus should not be downcasted to int32 without;-1.2262106;1.6693592;-5.9574986;-4.150697;-4.294012;-0.5748327;CODE
checking the content of providing maxval;1.276914;6.016191;-0.2593062;0.98829305;1.4984376;-3.0767603;-
one of the array is int64 and should not be downcasted to int32;-2.9099183;3.4154596;-3.1049294;-3.579885;-3.539169;-0.97863394;CODE
for the same reasons;-2.5753098;-1.512536;1.533286;1.4383495;-2.8898485;1.0502005;CODE
both arrays are already int32 we can just keep this dtype;-0.24309057;1.3219892;-3.5033677;-4.933619;-0.012523855;-1.221951;CODE
arrays should be upcasted to at least int32 precision;2.2739623;2.8379076;-4.7573404;-2.6575556;-3.1686635;0.61928;CODE
check that maxval takes precedence over the arrays and thus upcast to;2.6272173;5.2545695;-1.1993423;-0.40031514;-1.1771772;0.27977347;-
int64;-4.4750814;-1.1526837;1.6276864;-3.485859;-0.27617708;-3.885262;CODE
empty arrays should always be converted to int32 indices;-0.11462617;3.9478278;-4.895018;-4.3252397;-2.5939164;-0.87451667;CODE
arrays respecting np iinfo np int32 min x np iinfo np int32 max should;1.5534847;2.4987748;-5.7927837;-6.1927867;-0.47153056;0.7728278;CODE
be converted to int32;-3.0676692;-0.28679022;-1.3008722;-4.436552;0.24500617;-1.2120408;CODE
otherwise it should be converted to int64 we need to create a uint32;-6.109909;0.38537562;-3.5738552;-5.0053687;-2.8033261;-0.43250313;CODE
arrays to accommodate a value np iinfo np int32 max;2.0037475;1.7654511;-2.8155382;-6.2911706;-0.22433683;-0.51091534;IRRE
maxval should take precedence over the arrays contents and thus upcast to;1.7697031;3.6361113;-1.0787209;-0.91797507;-0.8911901;1.8561425;-
int64;-4.4750814;-1.1526837;1.6276864;-3.485859;-0.27617708;-3.885262;CODE
when maxval is small but check contents is true and the contents;1.2438139;6.4464345;0.3306446;1.5331248;-0.793246;-2.0973866;META
require np int64 we still require np int64 indexing in the end;-1.737755;0.4828915;-5.4239955;-3.9909887;-0.9127537;-0.113507435;CODE
test that fix connected components reduces the number of component to 1;1.6646985;5.5282636;-0.7366878;2.0172346;0.395685;-1.6980083;IRRE
test that fix connected components accepts precomputed distance matrix;4.5926876;3.2447536;-1.9594504;-0.41055262;-1.3901186;2.1978025;IRRE
but it does not work with precomputed neighbors graph;0.7975749;0.4358146;0.81042725;-2.8947206;-2.2730951;1.3272097;META
test that the an error is raised if the mode string is incorrect;-0.9144796;7.843517;-3.602573;3.9325757;-0.99661607;-3.9821286;CODE
test that the connectivity mode fill new connections with ones;0.2454347;2.676005;1.1004332;2.8830268;-0.34106514;0.5853877;CODE
test that the distance mode does not fill new connections with ones;0.33557266;3.7984717;-0.43416417;2.1221137;-1.5256772;0.07515891;CODE
toy array;0.259382;0.67682475;5.822288;-3.0629873;1.3994501;-4.073916;-
polars dataframes go down the interchange path;0.08004832;0.50693107;-0.15424752;-2.48824;-4.7235017;1.1417795;CODE
border case not worth mentioning in doctests;-3.67398;1.1304839;-0.68226147;2.1640735;1.5145044;-1.8619407;CODE
check that invalid arguments yield valueerror;-0.8192162;5.72405;-5.441579;1.3809973;-3.907532;-5.334942;IRRE
issue 6581 n samples can be more when replace is true default;0.59383035;4.081115;-4.6644516;-0.019563254;-0.65093833;-1.4427919;CODE
check that sampling with replacement with integer weights yields the;3.9743533;4.389617;-2.417744;-0.3044329;0.60894203;-1.302619;CODE
samples from the same distribution as sampling uniformly with;1.9667437;2.5893834;2.7207696;0.22220778;1.2139559;-0.01877065;CODE
repeated data points;6.626688;0.8224368;4.548771;-2.9638138;0.94636697;-0.3848989;CODE
should never be negative because 1 has a 0 weight;0.033194657;4.7552466;-0.62699497;-0.93670815;-2.3275964;-1.7684698;-
the null hypothesis the computed means are identically distributed;0.7675602;3.8756645;-0.8440948;1.7205656;-2.9023004;0.077247694;IRRE
cannot be rejected;-3.4685597;1.9174623;-0.6248946;2.686632;-0.79658395;-2.6286988;-
make sure resample can stratify;2.6718223;2.0899448;-1.3474644;0.16509897;-1.9743198;2.0824594;-
assert np sum y stratified 9 all 1s one 0;2.7651405;4.4432054;-3.7631834;-2.0062034;-0.3978078;-5.9463115;CODE
make sure stratified resampling supports the replace parameter;2.6898723;3.0210059;-4.753951;-0.44916412;-2.0147643;2.3848724;IRRE
make sure n samples can be greater than x shape 0 if we sample with;5.27305;4.60434;-1.9522103;-3.5211124;-0.47561395;-1.7158893;-
replacement;-3.113526;0.21769981;5.342127;0.015103045;2.13798;-3.3967738;-
make sure y can be 2d when stratifying;2.1420488;0.6404547;0.47632664;-4.405926;-2.2150137;1.8793856;-
resample must be ndarray;2.3595746;-0.24464907;-2.47314;-3.7124128;-4.1267495;1.4217889;TASK
def to tuple a to make the inner arrays hashable;0.8140918;1.16737;-0.47075087;-2.7317402;1.7125006;-1.4998149;CODE
a np array 1 2 3 4 5 6 7 8 a shape 2 2 2;3.0475233;-0.13950844;1.0596306;-8.278276;-0.9104591;-2.8711162;-
huffle a shouldn t raise a valueerror for dim 3;-0.48658165;3.510317;-5.7958336;-1.4046115;-1.7820196;-2.048286;CODE
check that shuffle does not try to convert to numpy arrays with float;2.799753;2.307739;-3.8915517;-4.32408;-5.5817814;-2.3679833;CODE
dtypes can let any indexable datastructure pass through;0.8632788;-0.83090967;-4.407538;-0.8629334;3.4411016;2.5385425;CODE
this is a non regression test for;1.5283768;2.784218;-0.2450962;3.7354817;-1.4746058;-6.0187435;CODE
https github com scikit learn scikit learn issues 20614;-3.6907995;-9.523439;-6.149317;-0.65565544;-5.344893;-5.1712623;CODE
to make sure that decorated functions can be used as an unbound method;-2.912887;1.1845319;-0.6332734;2.0337033;1.082668;3.301293;CODE
for instance when monkeypatching;-2.8073072;-3.986457;4.0154023;4.0402627;-0.4568887;1.8622314;CODE
9867966753463435747313673 false python int that overflows with c type;-1.7978884;1.1776102;-3.5956204;-3.6575608;-4.5692787;-6.185632;CODE
make sure that we are returning a python bool;-3.9745562;3.9758115;-3.904432;1.9876037;-3.7654808;-5.5078635;CODE
check that the checkingclassifier outputs what we expect;0.27273673;2.800492;-4.460473;4.569112;1.0642477;-4.6602864;IRRE
check the shape in case of binary classification;4.462538;0.036167067;-0.70995903;-2.7364984;3.8333163;-3.2061841;CODE
check the error raised when the number of samples is not the one expected;4.674941;7.5650487;-2.5226605;3.1819892;-0.7593295;-5.4799275;CODE
check that methods to check allows to bypass checks;-3.0234535;4.8894744;-2.3015933;6.2553773;0.13809451;-3.4074733;-
valid when the data is formatted as sparse or dense identified;6.2806253;1.5857296;-4.723048;-1.2216319;1.8834505;1.1488276;IRRE
by csr format when the testing takes place;0.39015946;2.5241222;-2.5303438;3.2618327;1.5561867;-4.0821223;IRRE
only valid when data is dense;3.842487;3.7470717;-3.7076647;0.9934965;0.32176653;-0.08930695;CODE
sequence of sequences that weren t supported even before deprecation;-0.41378295;1.7282423;-2.89067;1.8248228;0.8041559;-0.7618513;CODE
and also confusable as sequences of sequences;-0.42110768;-1.3685625;2.129438;0.011253747;4.422021;-1.3503615;-
ndim 0;-0.8347305;0.5993736;1.0127804;-6.7155404;-0.07887047;-2.324393;-
empty second dimension;-0.1105935;2.48441;0.9461796;-5.4866805;0.46352875;0.8954345;-
empty iterable;-2.117307;3.997823;2.0898995;0.9483853;0.17113401;-3.7721775;-
multiclass problem;-0.32742348;0.14766203;0.062948816;-0.7873451;5.0296187;-1.2435716;IRRE
multilabel indicator;1.5898851;-0.23505995;3.2127821;-3.1027284;4.85357;0.48643678;-
several arrays passed;2.2117407;3.5920374;2.820974;-2.06479;2.3017092;-3.000572;-
border line case with binary indicator matrix;2.7716596;1.6138484;0.33136648;-7.9641128;1.3119833;0.45328265;CODE
create array of unique labels except 0 which appears twice;2.380667;3.7137024;1.6097517;-4.3900247;2.909654;-2.4775562;IRRE
this does raise a warning;-4.331685;0.7967598;0.36232775;5.7640414;-1.2246819;0.051581457;CODE
note warning would not be raised if we passed only unique;-1.1230755;4.75755;-2.9754636;3.6208181;2.9694133;-0.86793804;CODE
labels which happens when type of target is passed classes;-0.2884617;-0.63882685;-0.37646574;3.2019148;5.4631577;1.0298752;IRRE
less than 20 samples no warning should be raised;1.8011656;4.1032166;-2.7962973;4.329376;-0.61652315;-3.2987866;CODE
more than 20 samples but only unique classes simulating passing;4.487902;2.28914;-1.3412999;2.641829;3.8579772;-1.6113223;IRRE
classes to type of target when number of classes is large;3.8690088;-1.4586543;-0.25551233;2.672904;4.9258933;0.34863445;IRRE
no warning should be raised;-3.566971;1.7973078;-0.9137727;4.1033845;-1.9570057;-0.7217157;CODE
test unique labels with a variety of collected examples;5.5829973;0.5009467;-0.297695;0.99553293;5.9870005;-4.0310917;IRRE
smoke test for all supported format;-0.48680943;2.0527844;-3.488551;2.441953;0.6725171;-2.0737183;CODE
we don t support those format at the moment;-3.2788894;-3.851147;-1.9120375;-1.4913503;0.18032444;1.2138923;CODE
mix with binary or multiclass and multilabel;1.1157458;-1.7549548;-0.8605932;-2.1555123;7.152691;-0.5874741;IRRE
only mark explicitly defined sparse examples as valid sparse;3.1796467;-0.84488696;-5.998701;-0.09946031;1.7760893;3.5100212;IRRE
multilabel indicators;2.7966025;-1.6710095;2.7437081;-2.40861;4.9905357;0.20890285;-
densify sparse examples before testing;5.224122;0.7345471;-5.047213;1.9898266;1.1163486;1.0529712;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
test that newton cg gives same result as scipy s fmin ncg;1.2032057;0.9907135;-4.339986;0.46962312;-4.228574;-3.1888852;IRRE
func is a definite positive quadratic form so the minimum is at x 0;-1.3726299;1.4904782;-1.7673284;-3.4080248;-2.3813498;1.0879685;CODE
hence the use of absolute tolerance;-1.3548281;1.5378419;1.8748266;3.7625897;-0.55143285;1.9017142;-
tests that the global global configuration is passed to joblib jobs;-2.0650058;-0.7886799;-2.770552;4.868472;-2.6284091;0.50013167;IRRE
in free threading python 3 14 warnings filters are managed through a;-1.7546141;-0.664674;-4.062706;1.8729198;-1.5980062;-0.29812282;CODE
contextvar and warnings filters is not modified inside a;-2.5951421;2.923178;-4.0530148;3.0372438;-1.5695921;3.6387846;IRRE
warnings catch warnings context you need to use warnings get filters;-3.2330866;1.9548527;-3.0372767;4.576093;-0.9144632;1.044477;TASK
for more details see;-3.8513157;-2.7091296;3.7665563;0.5036314;0.3860323;-1.7852823;CODE
https docs python org 3 14 whatsnew 3 14 html concurrent safe warnings control;-6.703985;-0.8023831;-2.619542;1.5884392;-2.786914;-1.8682015;CODE
some helpers for the tests;1.6091387;-1.1255074;1.8749541;4.5723248;-0.5026223;-7.516153;IRRE
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
pass pragma no cover;-2.713448;1.9219074;1.2293164;1.7572416;1.1100708;-0.64726764;-
check in the presence of extra positional and keyword args;-2.2626278;4.6119156;-1.2501973;2.2689753;2.3383198;-3.577663;IRRE
validated method can be decorated;-1.414943;2.0529463;-1.8002343;5.1441593;4.2377048;0.26706433;-
auto and warn are valid params;-4.5139856;2.8419988;-2.5924351;3.0778208;-0.570105;0.22468542;-
the warn option is not exposed in the error message;-5.511945;3.084209;-4.204627;3.6214576;-3.6710513;0.980934;TASK
true false and np bool true false are valid params;-0.74180263;4.499554;-4.7199183;-0.31859478;-0.24776769;-2.4337234;CODE
does not raise;-3.9978683;2.1101387;2.602449;0.5077654;-2.0819254;-1.3762228;CODE
check name is handled correctly;-3.7505782;5.1371374;-1.1642967;3.4116726;0.8177512;-3.4487393;-
check name is handled correctly;-3.7505782;5.1371374;-1.1642967;3.4116726;0.8177512;-3.4487393;-
check pos label is handled correctly;-1.9115937;4.899403;-1.1212786;2.2651463;0.9677171;-2.3985252;-
missing indices key;-2.05887;1.2403545;-3.1960547;-5.270635;-1.0927731;-2.045547;-
x wrong length;-2.3824713;3.503968;1.7572426;-4.2208014;-3.6355894;-2.897214;META
y not binary;-2.9167478;0.43360388;-0.6869489;-5.376485;-1.1177971;-6.265288;-
sample weight wrong length;2.33339;3.7161558;-1.3412052;-0.15188977;-3.1314285;-1.4416101;META
todo 1 9 remove;-3.8011737;2.5783026;2.8172524;-0.61260444;0.7241024;-2.6205127;TASK
name is none;-4.11667;0.30216452;0.56896174;-0.56908995;-0.13602284;-4.067242;-
in the following test we check the value of the max to min ratio;1.9771595;5.580401;-0.11888004;0.45236254;-1.3338444;-4.779379;IRRE
for parameter value intervals to check that using a decision threshold;5.175085;3.6463976;0.006757179;1.176097;2.0093465;-1.5230846;IRRE
of 5 is a good heuristic to decide between linear and log scales on;3.591501;0.17282255;1.6351925;-0.3987502;0.017458592;-1.0049989;IRRE
common ranges of parameter values;3.6771774;4.168924;1.041793;-3.173236;2.0186787;0.012967363;IRRE
such a range could be clearly displayed with either log scale or linear;3.2730377;1.6982807;2.3213751;-3.9138248;-2.2015939;-0.050467387;CODE
scale;2.7350285;-0.18313088;6.790365;-1.8021256;-2.4313195;-1.2581645;-
checking that the ratio is still positive on a negative log scale;0.031829473;4.7115593;-0.41342318;0.074807405;-3.6795046;-1.292827;TASK
evenly spaced parameter values lead to a ratio of 1;4.980336;4.5207267;0.38518825;-4.580261;-3.43585;0.60874647;IRRE
this is not exactly spaced on a log scale but we will benefit from treating;1.3443409;0.7999445;2.3163378;0.42986816;-1.8956239;1.4685531;CODE
it as such for visualization;-0.7743918;-6.341121;7.1621013;-1.6942012;-0.2923938;0.5837575;CODE
constructors excerpted to test pprinting;-1.8889583;0.48285618;-2.258013;4.9586167;3.9775198;-1.2141497;CODE
basic pprint test;0.44896162;2.794997;0.6420555;2.7440898;0.27046132;-6.3174233;IRRE
expected expected 1 remove first n;-1.2531407;4.5340195;1.2425;-1.9659013;-0.4644713;-4.564114;-
make sure the changed only param is correctly used when true default;-3.7524526;5.6801867;-0.6968604;3.4991453;-1.7740049;4.424128;CODE
defaults to np nan trying with float nan;0.3428266;2.0158558;-3.3767767;-4.8559146;-5.64847;-0.7612588;CODE
test custom sampling without replacement algorithm;3.7619166;5.305586;-0.8741124;4.119454;2.8966472;-1.8283776;IRRE
n population n sample;1.5221608;1.727216;2.7724097;-1.3943594;1.4025416;-3.3311849;-
n population n samples;3.0586026;1.608392;2.4831169;-1.4596336;1.4526614;-3.561462;-
n population n samples;3.0586026;1.608392;2.4831169;-1.4596336;1.4526614;-3.561462;-
n population 0 or n samples 0;1.4242402;3.6635036;0.20192364;-1.9066733;0.13627473;-3.9867716;-
this test is heavily inspired from test random py of python core;1.5791668;-1.4288495;-3.1664512;3.721836;-3.3123927;-5.1310306;IRRE
for the entire allowable range of 0 k n validate that;0.45140114;4.0471454;-2.3153968;-0.27776122;3.369158;-3.9627755;CODE
the sample is of the correct length and contains only unique items;3.2934763;4.485404;-0.21778828;-0.3619894;3.8574207;-3.3703327;-
test edge case n population n samples 0;1.6087239;4.595961;-0.35161713;-1.3318009;0.38485822;-4.562686;IRRE
this test is heavily inspired from test random py of python core;1.5791668;-1.4288495;-3.1664512;3.721836;-3.3123927;-5.1310306;IRRE
for the entire allowable range of 0 k n validate that;0.45140114;4.0471454;-2.3153968;-0.27776122;3.369158;-3.9627755;CODE
sample generates all possible permutations;3.4558833;0.3918975;1.2515727;-0.8516179;2.9718745;-3.5330944;-
a large number of trials prevents false negatives without slowing normal;2.0641234;2.913519;-1.4527131;5.5290265;-0.83381826;-0.48397538;-
case;-2.6828632;-0.2710421;5.503106;1.1309046;1.3903546;-2.8265493;CODE
counting the number of combinations is not as good as counting the;0.28117353;0.47008714;0.8505417;0.3370255;1.026921;-3.8892484;-
the number of permutations however it works with sampling algorithm;1.7052606;0.73263943;2.2786186;-0.98894006;2.8673007;-2.3083224;-
that does not provide a random permutation of the subset of integer;-0.10081363;2.511391;0.43915185;-0.5435428;3.3760822;-2.442295;IRRE
explicit class probabilities;1.659582;-2.6700306;-0.15022579;1.0457715;4.9483004;-1.3566116;IRRE
implicit class probabilities;1.9223751;-2.2930744;-0.6355284;1.2385167;3.4967194;-0.37249744;IRRE
classes 0 1 1 2 test for array like support;2.8684075;3.262021;-1.6743369;0.50153327;3.5881395;-5.156296;IRRE
edge case probabilities 1 0 and 0 0;-0.38536483;1.8977109;0.5670917;-3.546424;1.465654;-1.0086724;CODE
one class target data;4.069394;-0.02583768;1.0409056;1.8093053;5.200246;-0.4964018;IRRE
classes 1 0 test for array like support;1.9838786;3.2259583;-2.2701936;1.8845967;2.7562346;-4.58364;IRRE
the length of an array in classes and class probabilities is mismatched;1.818263;1.4656446;-2.234008;-0.53427297;0.45943075;-2.6695175;IRRE
the class dtype is not supported;-3.167253;-2.7726252;-5.898549;-1.6494921;-1.9357427;-1.2740028;IRRE
the class dtype is not supported;-3.167253;-2.7726252;-5.898549;-1.6494921;-1.9357427;-1.2740028;IRRE
given probabilities don t sum to 1;-0.6561297;1.3718319;0.5160149;0.24996306;-1.2837279;-3.5039563;CODE
scale the data to avoid convergencewarning with logisticregression;5.830557;0.567346;-1.4668325;3.8645;-1.8340731;3.5987601;CODE
provide a pos label which is not in y;-0.5288694;2.4730053;0.116428904;-1.5018559;2.9908962;-1.2902881;-
default pos label;-3.1512206;-1.0681312;0.39134544;-0.8290158;2.7819154;1.5475155;CODE
when forcing pos label classifier classes 0;0.0037175808;-0.63126373;-4.6336584;1.4897786;2.537514;1.660893;CODE
default pos label;-3.1512206;-1.0681312;0.39134544;-0.8290158;2.7819154;1.5475155;CODE
when forcing pos label classifier classes 0;0.0037175808;-0.63126373;-4.6336584;1.4897786;2.537514;1.660893;CODE
it should use predict proba;2.7968538;-1.7688403;1.3820142;3.8635077;0.10151624;-3.575399;-
it should use decision function;-0.7618493;-0.15024398;2.9009764;1.5348023;2.782265;-2.3178165;CODE
values returned by decision function are not bounded in 0 1;1.8931587;3.1961133;-2.2217684;0.15088627;-1.1464261;-0.9807042;IRRE
else response method predict;1.9630208;2.2440794;2.2089515;5.001702;-1.0624375;-2.3704875;CODE
30 classes less than 50 of number of samples;4.8724604;0.7747535;-0.9033269;0.5780112;3.0318403;-3.5733414;IRRE
authors the scikit learn developers;-1.7465241;-15.178335;-2.834631;1.6718649;-4.591528;-6.428468;META
spdx license identifier bsd 3 clause;-7.0376153;-0.28155068;-8.332157;-5.335113;10.930536;0.44712478;-
group dataset by array types to get a tuple float32 float64;4.1342106;0.055087443;-2.4665172;-5.0422816;-0.49732137;-0.72652805;CODE
next sample;2.6511521;1.4507681;5.592348;1.7397038;2.9610379;-4.4126797;-
random sample;2.613217;0.6630102;4.9748526;1.1381143;2.719349;-5.017815;IRRE
not shuffled;0.22148612;1.6607515;4.0244207;-1.8958234;1.3847609;-2.9990742;-
next sample;2.6511521;1.4507681;5.592348;1.7397038;2.9610379;-4.4126797;-
update columns with create container;-0.50425553;1.1399504;1.3930881;-1.7098817;0.5168033;2.1800628;IRRE
adapter update columns updates the columns;0.07186816;0.5401184;0.60615534;-1.1356775;-1.4904013;2.545296;CODE
adapter hstack stacks the dataframes horizontally;1.5347233;-0.9888499;0.14232665;-2.313437;-4.199548;3.189299;-
check the behavior of the inplace parameter in create container;-3.7975528;5.7912383;-0.7681741;1.2486322;-0.74449354;3.0561023;IRRE
we should trigger a copy;-4.0209107;-1.9697094;2.098281;4.7436085;-0.13251683;0.22170337;-
the operation is inplace;-5.069705;0.9423679;3.5080318;0.20322831;1.0422719;0.4129246;-
estimator without transform will not raise when setting set output for transform;0.7900711;3.5155547;-1.7751207;1.2640449;-5.226618;4.6339216;CODE
estimator with transform but without set output will raise;1.7248464;3.739284;-0.20894226;1.2111588;-4.044506;3.2570312;IRRE
transform is none is a no op so the config remains default;-5.2104044;2.073849;-1.3995389;-1.7673247;-3.2640903;5.2442274;CODE
return x pragma no cover;-3.5057342;4.457776;0.2255005;0.89003927;-0.6081267;-0.27642798;IRRE
set nonzero entries to infinity;0.7046694;5.693707;2.791578;-1.1680778;0.81619984;-0.5856439;IRRE
set diagonal to zero;-0.61028504;3.4623992;1.7921242;-5.5803037;-1.8297414;1.3616927;IRRE
sparse grid of distances;6.0938377;-1.3758674;2.0048945;-5.193998;-1.0282956;3.746716;IRRE
make symmetric distances are not direction dependent;2.5388916;1.6893039;0.9978107;-2.6878772;-0.077048056;2.883553;CODE
make graph sparse;5.2086883;-0.7764586;1.8775839;-4.399891;-0.8868999;3.6676567;IRRE
set diagonal to zero;-0.61028504;3.4623992;1.7921242;-5.5803037;-1.8297414;1.3616927;IRRE
we compare path length and not costs set distances to 0 or 1;3.1074345;1.8114077;0.50477076;0.68147767;0.059502695;0.9256906;IRRE
non reachable nodes have distance 0 in graph py;-1.1720606;1.510308;-2.1573284;-2.8903623;-4.4564214;0.6417255;-
sparsify the array a little bit;0.5018546;3.254814;1.2136103;0.60811204;-2.3110244;0.38222557;-
check that there s no big loss of precision when the real variance is;3.699073;4.1886535;-3.8700876;3.3805332;-4.73137;-1.6178107;CODE
exactly 0 19766;-0.8625022;3.3814406;1.0318701;-2.9939265;-2.0966873;-4.256383;-
add some missing records which should be ignored;0.83701354;4.7706876;1.1689028;1.0119996;2.8121293;-0.5678601;TASK
random positive weights;3.791064;-0.4357814;0.5145503;0.8782675;0.92875075;0.43170038;IRRE
sparsify the array a little bit;0.5018546;3.254814;1.2136103;0.60811204;-2.3110244;0.38222557;-
check second round for incremental;1.556839;4.527221;2.0117617;2.5383549;0.989317;-3.1197438;CODE
check second round for incremental;1.556839;4.527221;2.0117617;2.5383549;0.989317;-3.1197438;CODE
default params for incr mean variance;-0.16341597;2.2084975;-2.4088442;-0.3401463;-1.3181458;3.657603;CODE
test errors;-1.1076348;4.9923453;-1.3579322;3.1123261;-2.09155;-9.479029;IRRE
test incr mean and var with a 1 row input;3.1302915;5.9549575;0.33394444;-1.2509707;-1.5381515;-5.0165105;CODE
x shape axis picks samples;5.5966434;0.6324527;1.4614462;-4.5976386;-2.271821;1.2735485;-
test incremental mean and var with whole data;3.5561504;5.2754483;1.2489489;2.2720373;-0.879307;-2.584074;IRRE
test valueerror if axis 1 and last mean size n features;4.35483;4.8754077;-2.26838;-1.9378635;-5.288827;-2.5129209;IRRE
test inconsistent shapes of last mean last var last n;3.7504818;6.2772746;0.53270215;-1.2631785;-1.5729136;-2.6617842;IRRE
non regression test for;1.8054143;4.1764536;-1.8249325;4.6637588;-1.9162;-6.385861;IRRE
https github com scikit learn scikit learn issues 16448;-3.237456;-9.931004;-4.556136;-0.8223328;-5.313216;-5.136461;CODE
check that computing the incremental mean and variance is equivalent to;2.0841982;3.800619;-0.02449741;1.3920463;-2.1371593;-1.1101755;CODE
computing the mean and variance on the stacked dataset;6.506813;-1.8283973;1.3756857;-0.34444338;0.23844367;1.2038326;IRRE
check the behaviour when we update the variance with an empty matrix;2.2274625;4.478762;-1.741208;0.8326245;-3.50012;1.4645942;CODE
update statistic with a column which should ignored;1.6835552;3.4468172;0.1355969;1.0211985;-1.1173135;-0.31754053;IRRE
check the behaviour when last n is just a number;-0.13237965;5.2374415;2.1394393;-0.48513356;0.5691395;-5.513535;-
we avoid creating specific data for axis 0 and 1 translating the data is;3.5379906;1.4206239;0.03041281;-6.0226045;-2.2512934;2.700179;CODE
enough;-2.7935376;-1.3708216;5.041791;0.76486135;-1.0430962;-3.222884;-
take a copy of the old statistics since they are modified in place;1.8735348;-0.5918032;0.13665354;1.7834018;-2.3016768;0.032595202;-
sparsify the array a little bit;0.5018546;3.254814;1.2136103;0.60811204;-2.3110244;0.38222557;-
check dtypes with large sparse matrices too;4.8973274;-0.49108317;-6.167327;-1.8783456;-1.3113598;-0.18897007;IRRE
xxx test fails on 32bit windows linux;-3.7755454;2.8540347;-4.9330506;-0.6648813;-3.1318781;-2.9801233;IRRE
test csc row median actually calculates the median;2.7335722;3.0110528;-1.9791118;0.2048133;-2.4389496;-2.5708637;IRRE
test that it gives the same output when x is dense;2.0473502;5.068498;-1.4094069;0.008906367;-1.9143605;-3.1903706;IRRE
test that it gives the same output when x is sparse;5.1159215;4.82954;-2.3244598;0.46219495;-1.2777836;-1.5344504;IRRE
test for toy data;4.295836;1.2624779;2.694226;2.9072561;1.3049628;-7.224966;IRRE
test that it raises an error for non csc matrices;3.6461103;5.275088;-6.34639;0.9755741;-1.9120331;-2.2645464;CODE
csr matrix will use int32 indices by default;0.0176388;1.4777136;-5.641156;-5.4090734;-1.7585053;1.9668909;CODE
up casting those to int64 when necessary;-2.4727743;1.092279;-2.0175586;-2.1175473;0.8679581;-0.30948758;IRRE
checks that csr row norms returns the same output as;3.891785;5.3448973;-3.6150877;-2.2348688;-1.3811736;-1.4892107;IRRE
scipy sparse linalg norm and that the dype is the same as x dtype;2.990183;-2.6627524;-6.1249685;-4.7010036;-2.8876936;2.9822624;IRRE
weighted percentile average false does not match median when n is even;2.1718378;4.3927674;-2.7907152;-0.870799;-3.276302;-0.49724075;CODE
note for both percentile rank s 50 and 100 percentile indices is already at;0.5778218;0.30023444;-1.5837193;-2.1308076;-1.3577179;-0.26865146;CODE
max index;2.2397919;1.9015193;2.870361;-3.167569;1.8097564;-1.2184924;-
check for when array 2d and sample weight 1d;6.1975546;4.93737;-0.8313358;-2.9179292;-1.1131233;-0.9772755;CODE
percentile rank is scalar;2.5505645;0.4492478;-0.20117322;-2.8594894;-1.6000779;0.6606666;-
check when array and sample weight both 2d;5.83374;4.928352;0.22578204;-2.1533127;-0.9535349;-0.39585695;-
percentile rank is scalar;2.5505645;0.4492478;-0.20117322;-2.8594894;-1.6000779;0.6606666;-
numpy scalars input handled as 0d arrays on array api;2.313358;0.7647216;-4.7155437;-5.2201524;-5.3314753;0.50878274;CODE
random 1d array constant weights;4.3065753;1.5532242;-0.08009445;-2.9390402;-0.040092494;2.3039026;IRRE
random 2d array and random 1d weights;4.6688633;0.10597599;0.92177004;-4.410188;-0.41705778;1.847813;IRRE
random 2d array and random 2d weights;4.4636645;-0.09409159;1.5634595;-4.0783997;-0.30855036;1.1442701;IRRE
zero weights and rank percentile 0 20528 sample weight dtype int64;3.0360932;0.20455188;-5.8346267;-3.4693213;-2.400845;-1.3462125;CODE
np nan s in data and some zero weights sample weight dtype int64;4.0243344;0.54046935;-6.4760427;-4.534752;-3.8571222;-1.0370117;CODE
sample weight dtype int32;2.3562186;-0.576533;-4.632061;-2.808591;-0.72994345;-0.70344055;CODE
the percentile of the second column should be 5 even though there are many nan;2.975477;3.3462117;-0.30495054;-4.180777;-2.4034395;-2.6642437;-
values present the percentile of the first column can only be nan since there;2.067928;3.9170606;-2.0178223;-4.7825556;-4.9234533;-1.9718865;IRRE
are no other possible values;0.5694955;5.0713162;0.33075744;-2.6172333;1.5572217;-5.6628156;IRRE
todo remove the following skip once no longer applicable;-5.508195;5.353582;0.28720042;3.4466074;-0.031871166;0.43088698;TASK
return requires y true pragma no cover;-3.7780826;4.8687844;-1.5649527;2.9904842;-1.9556133;-1.6249784;CODE
my tag bool true type ignore annotation unchecked;-3.3254378;3.0933359;-3.4167392;4.4789014;-0.9414467;1.1747072;CODE
1st case the estimator inherits from a class that only implements;-0.2786539;0.9886333;-1.7347388;4.218635;1.248191;4.382344;CODE
sklearn tags by calling super sklearn tags;0.2558692;-5.301829;-3.7547214;2.017938;-0.7616305;0.592899;IRRE
2nd case the estimator doesn t implement sklearn tags at all;1.6015952;-3.4155319;-6.2764015;3.1582649;-3.1768754;2.3293912;CODE
check that we still raise an error if it is not an attributeerror or related to;-2.4573634;5.612695;-5.3254247;6.071966;-3.0444;-2.7848084;TASK
sklearn tags;1.0242324;-7.5239043;-2.0936208;1.1111115;-0.4163187;-1.3073124;-
linear discriminant analysis doesn t have random state smoke test;3.8684773;1.700411;-5.840435;0.8539809;-1.0579383;0.56983876;IRRE
basic compare;1.7995611;1.7131302;3.3227189;1.9897308;1.6043241;-6.827431;IRRE
this check that ignore warning decorator and context manager are working;-6.078966;3.2427518;-3.9382374;5.4263945;-2.3976934;3.9411087;CODE
as expected;-2.371796;0.57346886;3.4745014;2.0142345;-1.3120157;-1.268221;-
check the function directly;-2.1597438;4.8843546;2.0933635;0.64528733;-2.4581864;-5.900662;CODE
check the decorator;-5.2669125;-0.4991506;2.2541933;2.560302;0.26712218;-0.32880616;CODE
check the context manager;-6.526549;-1.9674935;1.8923122;2.71463;-0.4318044;2.9110434;-
check that passing warning class as first positional argument;-2.9417737;5.561026;-2.7122042;3.3973355;1.3392189;-1.1259323;IRRE
tests for docstrings;-0.8811435;0.41927037;-1.3521004;5.350598;1.779149;-5.797424;CODE
def f one a b pragma no cover;-1.8005868;0.9080212;2.690882;0.863969;1.4109797;-1.1590346;CODE
def f two a b pragma no cover;-2.2066252;1.1582079;2.586589;0.29301825;1.505354;-1.393628;CODE
def f three a b pragma no cover;-2.920686;1.0569966;2.2600567;-0.2951498;2.3627322;-1.6394323;CODE
test that data frames with homogeneous dtype are not upcast;3.0426476;2.3483698;-5.737094;-0.19783023;-2.5091488;-0.13616641;IRRE
float16 int16 float32 casts to float32;-2.5048726;2.2155128;-3.8688562;-4.2341886;-2.0903647;1.1631439;CODE
float16 int16 float16 casts to float32;-2.469772;2.3114123;-3.7981775;-4.1961613;-2.0771477;1.087366;CODE
we re not using upcasting rules for determining;-0.27657625;0.8697435;-1.1540666;3.9401789;2.6191506;0.58507764;CODE
the target type yet so we cast to the default of float64;-3.7486594;1.338577;-2.8109396;-1.537167;-2.7912884;2.1342256;CODE
check that we handle pandas dtypes in a semi reasonable way;2.4866912;-1.0915364;-5.7543707;0.03371728;-2.2671983;-2.2433019;-
this is actually tricky because we can t really know that this;-1.7312901;0.9631867;3.9245727;-1.6818663;0.2052522;-2.0972774;CODE
should be integer ahead of converting it;-1.7445822;3.9138865;-1.856489;-4.3566427;-1.0792842;-4.3615623;CODE
test that lists with ints don t get converted to floats;2.4996142;5.099509;-2.154841;-0.91973215;-3.4192917;-5.3791976;CODE
for scipy 1 13 coords is a new attribute and is a tuple the;0.60424775;-2.6487324;-2.4980707;-5.779055;-2.1623683;-2.8694243;CODE
col and row attributes do not seem to be able to change the;-0.66273856;0.4753411;0.3835831;-3.000032;-0.9696968;0.4337429;CODE
dtype for more details see https github com scipy scipy pull 18530;0.802363;-6.111696;-5.666855;-3.8227196;-3.350218;-2.8811822;CODE
and https github com scipy scipy pull 20003 where indices was;-0.83906907;-6.4992743;-5.7031646;-3.1663191;-5.2069073;-2.602098;CODE
renamed to coords;-3.0394392;-1.7856033;3.8768084;-2.507639;-0.4302949;0.7984118;-
scipy 1 13;-0.49055275;-4.5258956;-0.7342026;-5.398086;-4.6723785;-6.7434754;-
when large sparse are allowed;4.250532;-0.6251738;-1.3050692;0.37055928;1.366182;2.9904938;IRRE
when large sparse are not allowed;3.5940719;0.13311304;-2.4607613;0.4925697;0.3907372;2.8377504;IRRE
empty list is considered 2d by default;-1.4161066;3.1843946;0.038788337;-4.97846;-1.8774668;-0.0066269785;CODE
if considered a 1d collection when ensure 2d false then the minimum;4.6520405;4.879322;-0.8469072;-2.4052083;1.5925896;1.3828079;IRRE
number of samples will break;3.5988941;3.538029;-0.34981865;2.4987497;-0.056559145;-3.5162258;CODE
invalid edge case when checking the default minimum sample of a scalar;2.5804594;3.6376383;-4.866332;-1.223969;-0.3576758;2.119044;CODE
simulate a model that would need at least 2 samples to be well defined;4.6535616;2.5344675;0.2148104;2.183581;3.4262257;0.048882768;CODE
the same message is raised if the data has 2 dimensions even if this is;1.2323499;3.3812952;-2.8293626;-3.2356439;-0.6323515;1.1958295;CODE
not mandatory;-3.3192687;0.1647548;1.2206166;3.5655046;2.0723426;0.7764074;-
simulate a model that would require at least 3 features e g selectkbest;2.7197943;-2.007611;0.28662086;1.6343414;4.592044;-0.32436934;CODE
with k 3;-1.8698281;-2.0633893;4.474488;-1.2296559;0.4849146;-1.4775351;-
only the feature check is enabled whenever the number of dimensions is 2;-1.2009903;2.4104478;-2.722927;0.11303651;-1.0115622;1.5495394;TASK
even if allow nd is enabled;-5.924323;0.6343792;-2.268395;0.027121056;-0.05217835;2.143399;-
simulate a case where a pipeline stage as trimmed all the features of a;2.9059632;1.4971334;0.61384463;2.0183969;2.8694615;2.399945;CODE
2d dataset;6.2758822;-4.372425;3.822139;-5.5779138;-0.17293838;-0.21264796;IRRE
nd data is not checked for any minimum number of features by default;1.0696462;2.7842913;-5.2883816;-0.60662293;0.8338798;0.96507776;CODE
list of lists;0.5553265;-0.9968038;4.6713543;-1.2380747;2.1160862;-4.456369;-
tuple of tuples;0.4564883;-0.6581375;1.7778238;-3.173831;1.1512127;-3.3595638;-
list of np arrays;2.3925798;-0.53867453;-0.6125882;-4.520922;-0.8089116;-2.9514136;-
tuple of np arrays;3.489672;-0.26085272;-1.3154389;-5.1704993;-0.7422878;-1.7921548;-
dataframe;2.6411922;-1.1982472;3.9908125;-4.479976;-2.7822006;-4.686107;-
sparse matrix;5.675845;-1.4944562;0.692235;-5.229802;-0.19213772;2.3508759;IRRE
target variable does not always go through check array but should;-1.4513218;6.288827;-1.555309;2.849197;-2.154218;-2.0112891;CODE
never accept complex data either;1.5402132;1.8954003;-1.1993781;0.044242833;1.090125;-0.89088595;META
check error for bad inputs;-0.4412098;5.3952727;-2.4114416;2.2691264;-2.457562;-5.9523654;CODE
check that asymmetric arrays are properly symmetrized;2.2876747;4.736348;-3.2885072;-2.5161347;-0.5086883;-1.5589436;-
check for warnings and errors;-2.0571673;2.8468268;-2.1515515;5.068776;-1.8141625;-4.733029;CODE
check pandas dataframe with fit column does not raise error;1.8776655;3.3763487;-5.3301754;0.2510979;-6.5252;-1.3828787;CODE
https github com scikit learn scikit learn issues 8415;-3.4186432;-9.54781;-5.803643;-0.54463595;-5.4817653;-4.8826346;CODE
regression test that check array works on pandas series;3.621637;4.194815;-3.4011662;1.4304434;-6.080722;-4.0941453;IRRE
with categorical dtype not a numpy dtype gh12699;1.3191818;-1.6825438;-6.073805;-5.721476;-3.3410008;-2.9737754;-
pandas dataframe will coerce a boolean into a object this is a mismatch;-0.41986567;2.2154074;-4.403594;-0.9955953;-3.771762;-3.073884;CODE
with np result type which will return a float;2.48761;3.0518842;-1.7837409;-3.4993033;-2.4248283;-3.714709;IRRE
check array needs to explicitly check for bool dtype in a dataframe for;1.7927107;3.1176724;-6.080001;-2.1158772;-4.448757;-3.561893;CODE
this situation;-2.5999162;0.10784934;5.6338205;2.5531013;0.41152817;-2.0288825;CODE
https github com scikit learn scikit learn issues 15787;-3.4466393;-9.251532;-6.223048;0.05680852;-5.412107;-5.1207104;CODE
none default delegates estimator estimator;-1.6904035;0.7511821;-2.556116;2.7449446;-2.3009894;4.1047506;CODE
true expected result is true b c delegate and attribute are present;-1.9668157;3.004076;-1.2562873;2.7749214;0.7837077;-0.9722719;IRRE
none expected exception not relevant for this case;-3.927959;6.6417384;-3.0147054;4.255202;0.51939136;-2.1070225;CODE
none default delegates estimator estimator;-1.6904035;0.7511821;-2.556116;2.7449446;-2.3009894;4.1047506;CODE
true expected result is true b c delegate and attribute are present;-1.9668157;3.004076;-1.2562873;2.7749214;0.7837077;-0.9722719;IRRE
none expected exception not relevant for this case;-3.927959;6.6417384;-3.0147054;4.255202;0.51939136;-2.1070225;CODE
list of sub estimators;3.2543135;-1.1743125;1.3065618;0.98260564;0.63966715;0.67182624;-
true expected result is true b c delegate and attribute are present;-1.9668157;3.004076;-1.2562873;2.7749214;0.7837077;-0.9722719;IRRE
none expected exception not relevant for this case;-3.927959;6.6417384;-3.0147054;4.255202;0.51939136;-2.1070225;CODE
custom estimator custom estimator attribute name;-0.23640251;0.0556211;-1.5448333;0.80768996;0.34301075;4.88366;META
custom estimator custom delegates;0.5287191;1.0747254;-0.21410769;3.115672;0.30324134;4.9401135;-
true expected result is true b c delegate and attribute are present;-1.9668157;3.004076;-1.2562873;2.7749214;0.7837077;-0.9722719;IRRE
none expected exception not relevant for this case;-3.927959;6.6417384;-3.0147054;4.255202;0.51939136;-2.1070225;CODE
no estimator no estimator attribute name;-1.9396286;0.6271769;-3.0778434;0.72551674;-3.630485;2.6945837;META
none default delegates estimator estimator;-1.6904035;0.7511821;-2.556116;2.7449446;-2.3009894;4.1047506;CODE
none expected result is not relevant for this case;-0.55136764;8.502049;-2.0940776;0.64070195;-0.55725557;-4.54025;CODE
valueerror should raise valueerror b c no estimator found from delegates;0.23006532;3.4226887;-5.126189;3.7603424;-3.7662687;1.0485346;IRRE
type subestimator attribute absent true attribute absent;0.093886495;3.7901714;-3.1017592;1.2351257;0.6400755;2.6249163;META
none default delegates estimator estimator;-1.6904035;0.7511821;-2.556116;2.7449446;-2.3009894;4.1047506;CODE
none expected result is not relevant for this case;-0.55136764;8.502049;-2.0940776;0.64070195;-0.55725557;-4.54025;CODE
attributeerror should raise attributeerror b c attribute is absent;-1.6617922;3.4545264;-5.4639263;2.4054415;-3.545247;-1.2131524;META
always checks for attribute attribute present;-1.0956736;3.657134;-0.64440143;4.8968296;1.8327539;0.51622003;META
estimator estimator is default value for delegates;-1.3436673;1.843159;-1.9032422;2.7097726;-2.5570607;4.69039;CODE
check that it gives a good error if there s no len;-4.468772;2.8412392;-3.0351782;-2.0915732;-2.2030995;-4.4183526;-
test that check psd eigenvalues returns the right output for valid;1.3801675;5.066011;-4.9804797;1.0393167;-1.8709168;-2.241712;IRRE
input possibly raising the right warning;-4.1988487;3.7413437;-1.071465;2.2709131;-2.554386;-3.811208;CODE
test that check psd eigenvalues raises the right error for invalid;0.54928386;5.4028163;-6.69139;1.6635824;-2.1835048;-1.5569565;IRRE
input;-1.1542308;-1.1880628;7.5048885;-0.5764628;1.1853256;-4.9827194;CODE
common checks between numpy array api tests;2.5591202;4.1027193;-5.132354;1.6720142;-4.17714;-3.8452306;IRRE
for check sample weight;3.9123607;2.7823606;0.87585187;2.2928977;1.0764513;-4.082401;CODE
check none input;-3.0415568;6.0444617;0.5387087;0.9496102;-1.0848857;-6.028091;CODE
check numbers input;0.08758193;5.0006886;2.7849572;-1.2044871;-0.037609126;-8.422556;CODE
check wrong number of dimensions;1.8064705;4.6676517;-0.5545911;-4.8410153;-1.0703223;-3.5117648;META
check incorrect n samples;5.3002553;5.473805;-1.8384143;0.43729028;0.49241978;-6.85111;-
float32 dtype is preserved;-2.409633;0.27286762;-5.4780636;-3.521818;-2.4487562;1.1160198;CODE
check negative weight when ensure non negative true;1.677294;5.763532;-1.840251;1.1817174;-0.95066017;-0.55573916;-
check array order;0.22587918;5.8007007;2.2716036;-1.0665779;0.4592279;-4.9946957;-
int dtype will be converted to float64 instead;-1.6397102;0.6984772;-5.2459097;-4.943091;-4.6224365;-1.7212812;CODE
check array order;0.22587918;5.8007007;2.2716036;-1.0665779;0.4592279;-4.9946957;-
make sure we only raise if pos label is none;-0.5570545;2.1558344;0.6066483;1.8526186;2.0136957;-0.81185186;CODE
make sure we only raise if pos label is none;-0.5570545;2.1558344;0.6066483;1.8526186;2.0136957;-0.81185186;CODE
the is place before a keyword only argument without a default value;-6.0768557;3.9566138;-1.8354155;1.8206531;0.8327404;1.168504;CODE
check array converts pandas dataframe with only sparse arrays into;4.3954563;2.3637798;-4.7057643;-1.6554114;-5.410257;-1.4300073;IRRE
sparse matrix;5.675845;-1.4944562;0.692235;-5.229802;-0.19213772;2.3508759;IRRE
by default pandas converts to coo when accept sparse is true;2.7143786;0.07003767;-5.7072763;-2.362757;-4.4227266;1.2546265;IRRE
check that we support the conversion of sparse dataframe with mixed;6.176715;0.7030057;-4.5811563;-1.1355301;-2.0740368;1.7706481;IRRE
type which can be converted safely;-2.1577935;-0.038942017;-2.1457806;-0.05191204;1.7397254;-0.5925288;-
raise an error when no methods are defined;-2.8154945;5.0058684;-2.8934536;6.471023;-1.0262188;-0.70333076;CODE
check that we don t get issue when one of the method is defined;-2.469194;7.047789;-2.0126214;5.7978816;-0.112959884;-3.0437486;CODE
check the order of the methods returned;-0.49332154;4.711372;1.3253883;4.65428;1.087256;-3.4181623;IRRE
x is already writeable no copy is needed;-6.6585484;1.6502116;-2.3986394;-0.83221245;-1.248843;0.050616845;CODE
x is not writeable a copy is made;-6.298928;0.5023149;-2.1930606;-1.5634557;-2.1030734;-1.7496489;TASK
mmap is already writeable no copy is needed;-5.0914845;-0.6874873;-2.8300698;1.3639588;-0.7006703;2.327145;CODE
mmap is read only a copy is made;-4.2741623;-1.1571395;-2.3403108;1.9053428;-0.9974304;1.3827472;CODE
df is backed by a writeable array no copy is needed;0.75264716;2.1127326;-3.3708317;-1.8728416;-4.888577;0.24393727;TASK
df is backed by a read only array a copy is made;1.5091703;2.5189703;-2.9637742;-1.0475658;-5.192856;0.004680112;CODE
for object dtype data we only check for nans gh 13254;1.8400311;1.3734801;-7.165392;-2.5270307;-2.7972245;-3.4942636;CODE
we need only consider float arrays hence can early return for all else;2.8699644;5.2353783;-0.04318708;-1.1886576;-0.6731144;-0.11799841;CODE
first try an o n time o 1 space solution for the common case that;2.3346622;1.8231188;-0.8407979;-4.684012;-0.74507034;-0.6452763;CODE
everything is finite fall back to o n space np isinf isnan or custom;-1.4366001;1.1464778;-3.4814236;-1.6022985;-0.57061845;1.1645217;IRRE
cython implementation to prevent false positives and provide a detailed;-0.03109967;2.5979402;-2.3271766;1.1759658;-0.090322636;-3.858698;TASK
error message;-5.811274;2.6788962;0.24466947;-1.1488322;-1.4854857;-3.393149;-
cython implementation doesn t support fp16 or complex numbers;-2.6992738;0.7481397;-3.7912512;-3.6925564;-3.0570252;0.035968736;TASK
improve the error message on how to handle missing values in;-0.67712307;6.45558;-2.3615286;-0.112351;-0.13160406;-3.194561;IRRE
scikit learn;2.6275342;-11.857208;-1.3952904;-0.05143707;-4.145873;-5.693253;-
estimators that handle nan values;3.6255524;2.2418811;-0.5857076;0.25515658;-2.3132968;1.7739881;IRRE
elif x dtype in np float32 np float64 is numpy array;0.10083994;-0.88872796;-6.897707;-7.2789445;-5.7881746;-1.5152774;CODE
only convert x to a numpy array if there is no cheaper heuristic;4.81653;0.77081764;-0.6559962;-6.2092566;-4.5097923;0.67515135;-
option;-3.8225517;-0.8791506;7.2907867;1.2090216;0.7346304;-0.981287;-
do not consider an array like of strings or dicts to be a 2d array;1.2700201;1.0909419;0.34099367;-5.356512;0.14346424;-1.4011523;CODE
if x is a list of lists for instance we assume that all nested;0.096402586;2.053342;1.2248356;0.9545306;2.8148813;-1.9192873;CODE
lists have the same length without checking or converting to;1.2652391;4.0177197;-0.2680385;-1.4301926;-0.70562774;-4.1942406;-
a numpy array to keep this function call as cheap as possible;4.727504;0.75166386;-0.14753729;-4.5101385;-4.9416137;0.6260449;CODE
check these early for pandas versions without extension dtypes;-0.034850944;-1.798045;-6.193327;-0.034952465;-3.2278743;-1.9811709;META
bool and extension booleans need early conversion because array;-0.41923648;5.45231;-3.452968;-0.06735015;0.080849566;-1.4626945;CODE
converts mixed dtype dataframes into object dtypes;2.4749172;-2.5087423;-4.077221;-2.9568505;-2.1252434;-0.18400814;CODE
sparse arrays will be converted later in check array;3.3076224;5.0336018;-3.2765925;0.3836666;-2.2284179;-0.8965696;IRRE
sparse arrays will be converted later in check array;3.3076224;5.0336018;-3.2765925;0.3836666;-2.2284179;-0.8965696;IRRE
only handle extension arrays for integer and floats;0.9572691;4.853722;-1.757087;-2.528351;-0.03214104;0.98185027;CODE
float ndarrays can normally support nans they need to be converted;2.2926216;0.5796423;-4.0333557;-6.132258;-4.99741;0.41597396;TASK
first to map pd na to np nan;1.3621613;0.24605118;-1.7773132;-4.6332593;-1.583127;0.9409122;-
xxx warn when converting from a high integer to a float;-1.188149;5.1371837;-3.2705429;-2.7459023;-3.4101882;-2.3126812;CODE
pandas extension arrays have a dtype with an na value;2.1081896;0.06322745;-5.021386;-3.9923644;-4.041059;-0.32878822;IRRE
store reference to original array to check if copy is needed when;0.47661704;4.993173;0.027299756;1.3552517;1.2965645;-0.20361407;IRRE
function returns;-1.0212697;4.3292055;3.0718281;-0.50596684;-2.7510197;-5.5491624;CODE
store whether originally we wanted numeric dtype;1.428049;0.42639074;-2.5256622;-2.7872853;1.9372078;-2.329089;-
not a data type e g a column named dtype in a pandas dataframe;0.21829051;-1.6411457;-3.8149297;-3.9332829;-2.279301;-2.023998;-
check if the object contains several dtypes typically a pandas;2.3080802;0.3899285;-4.6580086;-0.46260577;0.12482045;-3.5361595;IRRE
dataframe and store them if not store none;2.0484698;4.162623;0.21582174;-2.3617442;-1.7302516;-2.6547039;-
track if we have a series like object to raise a better error message;1.451775;3.6863687;-0.41888246;5.980743;0.16571516;-2.8009925;CODE
throw warning if columns are sparse if all columns are sparse then;4.6361003;3.0508406;-2.5466897;-0.06869677;-0.3059759;1.2717234;IRRE
array sparse exists and sparsity will be preserved later;3.5856755;2.5784903;-2.1525784;-0.15008461;0.40258217;2.7154212;IRRE
force object if any of the dtypes is an object;-0.9685907;1.256908;-2.622408;2.0126019;1.1319987;-0.5101629;CODE
array is a pandas series;1.6517234;-0.07318624;-0.60649997;-4.693938;-5.315358;-3.532875;-
set to none to let array astype work out the best dtype;1.7862706;2.9627326;-4.32627;-1.5356822;-0.5286081;-0.9893008;CODE
if input is object convert to float;1.0031345;4.3191037;1.3124968;-2.3085723;-2.0619204;-4.1218286;CODE
no dtype conversion required;-1.765203;-1.0318481;-6.584878;-3.049284;-1.6359527;-1.987362;META
dtype conversion required let s select the first element of the;0.13987803;1.7354789;-1.1854919;-4.6556954;1.7785578;-4.041291;CODE
list of accepted types;-0.69260305;-0.8686798;0.15023944;1.3590509;3.4180183;-2.5152078;-
pandas dataframe requires conversion earlier to handle extension dtypes with;-0.20525447;-0.9186596;-6.2745376;-1.668188;-4.6336684;1.0154287;META
nans;0.053640563;0.7104172;2.4443867;-1.9757384;-2.5415983;-4.000433;-
use the original dtype for conversion if dtype is none;-0.03612868;3.1277301;-5.298291;-2.051478;-0.51044095;-2.488428;IRRE
since we converted here we do not need to convert again later;-3.1292803;0.7290409;0.05086326;-0.08497155;-1.2222567;-0.1216431;TASK
convert to dtype object to conform to array api to be use xp isdtype later;-0.25271118;1.0674024;-5.331772;-2.3914075;1.0742998;0.85681164;CODE
when all dataframe columns are sparse convert to a sparse array;5.609272;-0.25524536;-2.709298;-2.352547;-3.1704452;2.806599;IRRE
dataframe sparse only supports to coo;3.029575;-1.025497;-4.2334948;-2.3092976;-3.5490296;2.6953037;IRRE
if np array gives complexwarning then we convert the warning;1.5056078;2.4885986;-4.688546;0.25860113;-2.277192;-1.0894303;META
to an error this is needed because specifying a non complex;-3.8426158;4.4684224;-2.6018884;-1.3586181;0.9492213;0.36383203;META
dtype to the function converts complex to real dtype;-0.44675186;-0.5894628;-2.9952462;-1.8971812;-2.3887208;0.30557737;META
thereby passing the test made in the lines following the scope;0.064692885;4.746694;1.3029774;3.6616044;1.4828781;-2.3179345;IRRE
of warnings context manager;-3.939597;-2.0610871;-0.5805309;5.032763;0.5599867;2.614885;-
conversion float int should not contain nan or;0.34683383;4.3189464;-3.3363225;-5.0160656;-4.7941356;-3.364126;CODE
inf numpy 14412 we cannot use casting safe because;-1.0680556;0.3571287;-5.094222;-2.8397074;-5.588027;0.0008011012;-
then conversion float int would be disallowed;-0.8696178;4.4726577;-2.748812;-3.2509718;-0.9225897;-0.8878007;CODE
it is possible that the np array gave no warning this happens;-1.9668155;2.3216531;-4.5689316;0.0069831046;-3.900727;-2.0692556;CODE
when no dtype conversion happened for example dtype none the;-0.91862106;-0.106911935;-5.594618;-0.87744933;-1.15202;-2.4345505;META
result is that np array produces an array of complex dtype;1.4361702;-0.62510455;-5.11831;-4.9131417;-1.5956793;-1.9384502;IRRE
and we need to catch and raise exception for such cases;-2.449975;3.2223065;-0.1077287;6.71252;2.8332098;-0.6373384;CODE
if input is scalar raise error;1.2283775;4.7485785;-3.05109;0.62147015;-2.2861526;-3.0613875;CODE
if input is 1d raise error;0.16481528;6.3490577;-2.5994422;-1.0680494;-1.9952109;-3.3226;CODE
if input is a series like object eg pandas series or polars series;3.3429272;0.6300059;0.25153008;-2.70254;-0.56249654;-5.105471;CODE
only make a copy if array and array orig may share memory;0.49158913;3.5162685;-0.19094367;0.7287485;0.63365436;0.4297844;-
always make a copy for non numpy arrays;2.6982324;0.28168595;-3.2927961;-2.181767;-4.803116;1.6138706;CODE
by default array copy creates a c ordered copy we set order k to;-0.63642913;1.0799744;-0.27178106;-2.7212214;-1.6733098;0.48944792;IRRE
preserve the order of the array;-0.1138493;4.0760407;3.439349;-2.145809;-0.419991;-0.056423977;-
this situation can only happen when copy false the array is read only and;-2.5509126;6.695267;-1.9318268;1.215933;-3.2636988;-1.6268853;CODE
a writeable output is requested this is an ambiguous setting so we chose;-2.8928053;2.0796058;-0.9141745;1.5615314;1.3046252;2.030923;CODE
to always except for one specific setting see below make a copy to;-2.6294577;2.5655131;0.8441382;3.3249426;0.8256765;4.4329267;CODE
ensure that the output is writeable even if avoidable to not overwrite;-1.5038104;4.136572;-1.9077841;3.2027693;-0.8509771;0.14378782;CODE
the user s data by surprise;3.051695;-1.5559056;4.38109;1.9214709;2.205393;-3.8898654;-
in pandas 3 np asarray df called earlier in check array;0.004664628;1.6347082;-2.5427241;-1.92124;-4.1469793;-1.3607008;IRRE
returns a read only intermediate array it can be made writeable;-1.2694745;5.040332;-0.31044188;-0.25581604;0.005781268;-1.0954906;CODE
safely without copy because if the original dataframe was backed;0.6285339;1.6504717;-0.7139564;1.1641489;-3.097072;0.60222214;-
by a read only array trying to change the flag would raise an;-1.766889;5.3305297;0.16703415;1.2219766;0.40601864;-1.6457189;CODE
error in which case we make a copy;-4.9673624;1.8225613;-2.3221755;0.8331557;-0.61812776;-3.2433505;CODE
this is used during test collection in common tests the;-1.667795;-0.54104865;0.23778597;3.5125065;3.2497597;-2.2664883;IRRE
hasattr estimator fit makes it so that we don t fail for an estimator;2.0022092;3.4489377;-3.8456097;3.8681026;-3.2493808;5.079336;CODE
that does not have a fit method during collection of checks the right;2.757447;4.729732;-2.394453;3.324432;1.8851881;-0.17569576;CODE
checks will fail later;-2.1523507;3.460189;0.08885079;5.897534;-0.17223296;-3.747355;-
only csr csc and coo have data attribute;-0.5653857;0.4559205;-2.6105244;-0.84127825;1.5043175;1.7753943;META
in meta estimators with multiple sub estimators;2.0291936;0.26238897;0.058112912;2.9979506;1.1511246;3.7975564;-
only the attribute of the first sub estimator is checked;1.346221;5.1675363;-2.2892742;2.6040945;-0.84621936;2.805153;META
assuming uniformity across all sub estimators;2.964377;1.9775958;-0.16113138;2.3774235;-0.1714938;4.457398;CODE
avoid x min on sparse matrix since it also sorts the indices;4.9291043;1.1909347;-2.6818488;-4.507533;-1.4874691;4.5282702;IRRE
check psd eigenvalues 1 2 nominal case;0.51152337;3.2907605;-3.3414214;-2.5247602;2.149388;-1.4021279;IRRE
check psd eigenvalues 5 5j significant imag part;0.9612863;2.7381525;-3.464102;-2.1652226;-0.93378645;-1.4248313;IRRE
check psd eigenvalues 5 5e 5j insignificant imag part;0.98597735;3.4735115;-4.0366282;-1.936232;-1.3616108;-0.59612197;IRRE
check psd eigenvalues 5 1 all negative;0.6160028;3.5995486;-2.7174137;-3.096714;-1.3973911;-1.6999015;IRRE
check psd eigenvalues 5 1 significant negative;0.95353967;3.3746707;-3.0827556;-2.5461671;-1.8531884;-2.2243407;IRRE
check psd eigenvalues 5 5e 5 insignificant negative;1.1548554;3.487695;-3.680926;-2.0896819;-1.9888196;-1.2895995;IRRE
check psd eigenvalues 5 4e 12 bad conditioning too small;1.2334013;3.7198195;-5.1663923;-0.08902693;-1.8776209;1.1499685;IRRE
extract feature names for support array containers;0.5444454;-2.1423;-2.2885664;0.4738338;3.1390817;1.3943875;TASK
make sure we can inspect columns names from pandas even with;0.02669364;-1.6446985;-4.1901417;-2.7512255;-3.7060845;-2.096289;CODE
versions too old to expose a working implementation of;-4.0414724;-4.188371;-0.9709907;2.5130548;-0.06078204;0.708462;TASK
dataframe column names and avoid introducing any;1.2042046;-0.6878411;-1.333136;-1.9582511;-0.14212276;-0.60003626;CODE
additional copy;-5.008734;-2.6132383;2.426432;0.63085645;1.8447688;-0.40605843;TASK
todo remove the pandas specific branch once the minimum supported;-0.9848099;0.9325409;-2.8428671;-0.14364845;-2.6355915;1.8196493;TASK
version of pandas has a working implementation of;2.4547884;-5.2791595;-2.7365983;-3.0171962;-3.2913182;-0.038075794;TASK
dataframe column names that is guaranteed to not introduce any;0.99981123;1.0849643;-2.8527792;-0.41743177;-0.5114497;0.09379567;CODE
additional copy of the data without having to impose allow copy false;1.0759655;3.5411642;-1.0877732;1.2398653;1.9786073;1.8572178;TASK
that could fail with other libraries note in the longer term we;-4.8716574;-3.2951343;-3.457186;2.9409661;-0.29882726;0.8814855;TASK
could decide to instead rely on the dataframe namespace api once;-0.84700096;-3.534183;-2.8649774;0.6673854;-2.0868502;2.2683651;CODE
adopted by our minimally supported pandas version;0.3581493;-5.4093995;-4.2658587;-1.0717379;-3.2310905;0.52889884;META
mixed type of string and non string is not supported;-3.9899035;3.6461046;-4.5204244;-1.351787;0.6536949;-1.7214133;CODE
only feature names of all strings are supported;-3.8844278;-2.1342843;-4.478215;1.2903659;2.4779117;-0.41684276;TASK
generates feature names if n features in is defined;1.6689706;0.23476712;-1.2049911;0.060920898;5.0177736;-2.3214812;TASK
unexpected feature names sort deterministic error message;-0.9635925;-0.6427271;-5.0589375;1.0272188;-0.097164415;-1.24886;TASK
ensure binary classification if pos label is not specified;1.1948261;1.8862355;-4.8651695;0.75865275;5.734559;-0.5040216;IRRE
classes dtype kind in o u s is required to avoid;-1.4860861;-2.5639331;-6.5137405;1.0119905;2.8708127;-0.33476824;CODE
triggering a futurewarning by calling np array equal a b;1.401609;2.0571573;-1.7838964;1.6937109;-1.9346373;-0.8640175;TASK
when elements in the two arrays are not comparable;4.280161;5.4532666;0.34893396;-2.8054266;-1.1650983;-2.080086;CODE
compute classes only if pos label is not specified;1.9068977;2.158166;-2.5531864;-0.23175247;5.321369;-1.528145;IRRE
delete the attribute when the estimator is fitted on a new dataset;2.3097332;2.3869236;-1.9878953;1.9042764;-1.3023698;4.6340723;CODE
that has no feature names;-4.4461327;-5.75149;1.1249899;1.152463;1.0590948;0.36542496;TASK
no feature names seen in fit and in x;-1.5261705;-2.4647849;-2.9745324;-0.04585677;-0.36785728;1.1351639;TASK
validate the feature names against the feature names in attribute;0.49258354;0.86891854;-2.8738441;2.8293421;3.407534;-1.3458203;TASK
if the number of features is not defined and reset true;0.6883081;3.3374412;-0.8712231;2.5815694;3.2134216;-1.3666096;IRRE
then we skip this check;-1.3944966;3.8096113;0.4372217;4.821382;0.16837677;-2.7231293;CODE
skip this check if the expected number of expected input features;1.9856789;3.9917529;-0.07104535;3.5447056;1.0034972;-3.634398;CODE
was not recorded by calling fit first this is typically the case;0.034737285;2.1281703;-1.8704376;2.535278;0.71835476;1.567515;IRRE
for stateless transformers;-1.7917113;-0.633425;2.9582555;1.247817;1.4960866;1.1551845;CODE
we need this because some estimators validate x and y;2.3821616;1.3663208;1.9787319;2.5137522;-0.18295829;-0.3530217;CODE
separately and in general separately calling check array;-0.3667347;5.4528184;1.3586657;0.747194;2.584141;-2.685204;IRRE
on x and y isn t equivalent to just calling check x y;-4.309766;3.947183;0.212408;2.1469579;-0.28335056;-2.8911448;IRRE
may need extra deps;-2.5659683;0.90587574;0.7268906;1.0773679;1.3530256;1.0940756;-
not a test but looks like a test;-0.8658673;3.7962294;0.6335409;4.017236;-0.8510123;-7.175844;IRRE
contains scripts to be run by tests test crawler py asynccrawlerprocesssubprocess;-2.6433172;0.789313;-4.2601695;4.168623;-3.7417588;-0.81247306;IRRE
contains scripts to be run by tests test crawler py asynccrawlerrunnersubprocess;-2.8449886;0.47237444;-4.242697;4.770659;-3.1217592;-1.2050837;CODE
contains scripts to be run by tests test crawler py crawlerprocesssubprocess;-2.457992;0.64146054;-4.1342535;3.6789637;-3.2123291;-0.8613854;IRRE
contains scripts to be run by tests test crawler py crawlerrunnersubprocess;-2.6586978;0.47853157;-4.1363997;4.3549685;-2.6574929;-1.3963271;CODE
if file path and file path 0;-3.4543388;4.5138364;0.45709097;-0.055213507;-1.3155086;-2.9961834;-
import uvloop noqa plc0415;-4.666383;-1.6540349;-3.4169838;-3.7049656;-0.36814716;-0.05555515;CODE
import botocore noqa plc0415;-4.223664;-0.65904015;-3.270954;-2.458434;0.3170973;-0.97793543;CODE
import boto3 noqa plc0415;-4.9498663;-0.6729047;-3.094251;-3.7485895;0.4496092;-0.65974677;CODE
import mitmproxy noqa f401 plc0415;-4.2944183;-0.55643594;-3.875727;-3.5821767;-0.77261305;0.6614037;CODE
needed on windows to switch from proactor to selector for twisted reactor compatibility;-5.2761006;-2.3719525;-1.1837279;1.0970359;1.2545024;4.0110765;CODE
if we decide to run tests with both we will need to add a new option and check it here;-2.7572184;0.4226965;-2.408499;5.0039096;-0.7396968;-2.724809;TASK
generate localhost certificate files needed by some tests;-0.6395849;-0.0010029463;-2.4832077;2.018468;0.2958382;-1.7922527;IRRE
pylint disable import error;-6.004324;0.23748718;-4.603804;0.66394484;-4.4944234;1.5386161;CODE
if node tagname index and node entries type ignore index attr defined;-1.3518046;4.68059;-3.5099761;0.19354318;2.0862653;1.8870727;CODE
index entries for setting directives look like;-2.7064092;1.5249933;0.22035584;-0.6661646;2.0604331;3.9784982;IRRE
pair setting name setting std setting setting name;-2.9833288;0.06561086;-1.2453657;-1.59474;2.9599662;2.488202;IRRE
entry type info node entries 0 3 type ignore index;-0.5336788;3.1970146;-3.8448455;-2.9611413;2.3993056;0.37874472;CODE
pylint disable import error;-6.004324;0.23748718;-4.603804;0.66394484;-4.4944234;1.5386161;CODE
autodocs was generating a text alias of for the following members;-4.082489;-2.6942117;-1.4384494;0.10867469;1.9765581;-1.482039;CODE
configuration file for the sphinx documentation builder;-5.2197504;-3.0851662;-0.7035803;-0.19872318;0.8615704;1.823181;CODE
for the full list of built in configuration values see the documentation;-3.3174179;-2.5683665;0.049656697;-0.6304464;2.3400867;2.0245905;IRRE
https www sphinx doc org en master usage configuration html;-6.459731;-1.8835652;0.5294807;-1.2299151;0.435167;2.2857432;CODE
if your extensions are in another directory add it here if the directory;-6.695442;-0.8333636;0.82858115;-0.41198504;-1.0354707;2.3236432;TASK
is relative to the documentation root use path absolute to make it absolute;-6.106884;-1.6850832;0.290847;0.7413735;-0.90470886;3.2361073;CODE
project information;-1.7306768;-6.672315;5.2071495;1.4779983;1.2614344;-1.5908712;CODE
https www sphinx doc org en master usage configuration html project information;-5.39237;-3.7755868;0.17805026;-0.26175708;0.52203536;1.4868242;CODE
general configuration;-1.6665144;-1.8953097;4.9528403;-0.7313499;3.1215398;2.6917934;-
https www sphinx doc org en master usage configuration html general configuration;-5.9625883;-1.348815;0.11213695;-1.1764001;0.35706016;2.9692795;CODE
scrapyfixautodoc must be after sphinx ext autodoc;-6.7996125;-1.417376;-3.4719918;1.4172771;-1.810722;1.6891074;TASK
the version info for the project you re documenting acts as replacement for;-5.883998;-5.21452;-0.67450833;2.3348181;2.6026688;1.2096146;CODE
version and release also used in various other places throughout the;-4.962456;-4.996021;2.37299;1.880815;2.145131;1.6651074;META
built documents;-3.4950507;-5.586781;2.6183264;0.99918884;4.256336;-1.3302522;CODE
the short x y version;-1.4770324;-2.670388;3.2004483;-2.1971877;0.5981427;-1.4319657;META
options for html output;-2.103958;-1.6871557;3.9995558;-0.3469148;0.12951207;0.301062;IRRE
https www sphinx doc org en master usage configuration html options for html output;-5.6035275;-1.1660345;-0.28672445;-0.95702386;-0.44502947;2.3796387;CODE
set canonical url from the read the docs domain;-4.7101555;-2.634667;1.13624;0.5449935;-0.122059606;2.6713843;CODE
options for latex output;-0.77418816;-2.2475126;3.2142375;-1.305479;1.1200848;-0.64711857;IRRE
https www sphinx doc org en master usage configuration html options for latex output;-5.5833225;-1.7739909;-0.7711662;-0.7957587;0.198495;2.215559;CODE
grouping the document tree into latex files list of tuples;2.3023336;-3.2386596;1.6762784;-1.7814533;2.390899;-0.30725157;CODE
source start file target name title author document class howto manual;-4.880213;-4.4734807;-1.8872176;1.1996955;1.6517706;0.39616016;CODE
options for the linkcheck builder;-4.379194;-1.7491034;2.0159001;2.782632;1.3646364;3.6369958;CODE
https www sphinx doc org en master usage configuration html options for the linkcheck builder;-6.4756937;-1.4294374;-0.54384273;0.88846886;0.69603586;3.1096904;CODE
options for the coverage extension;-1.323524;-0.8877599;1.0797857;4.272942;3.235503;1.3957255;CODE
https www sphinx doc org en master usage extensions coverage html configuration;-6.336378;-0.81912476;-1.5619359;0.981298;1.1417623;1.691528;CODE
contract s add pre hook and add post hook are not documented because;-4.929962;-0.88207465;-1.5155331;3.0763712;-0.62769204;1.5190295;TASK
they should be transparent to contract developers for whom pre hook and;-4.9828706;-3.0733352;0.11360752;3.8981805;0.10010439;2.4503908;CODE
post hook should be the actual concern;-3.7210236;1.5378109;3.127502;4.766281;-0.008417795;1.4465913;-
contractsmanager is an internal class developers are not expected to;-4.6557326;-1.3276876;-2.5107405;2.1992197;-0.06183445;1.764682;CODE
interact with it directly in any way;-6.241704;-3.5712469;4.633256;1.4499578;-1.0606055;1.3413237;CODE
for default contracts we only want to document their general purpose in;-3.6295388;-2.3106992;-0.6508692;1.8117753;3.82553;3.9884572;CODE
their init method the methods they reimplement to achieve that purpose;-1.2684654;-3.6020606;2.6128962;3.3507996;2.2437687;1.979166;TASK
should be irrelevant to developers using those contracts;-4.1047053;-2.9475274;-0.854675;2.3132505;1.323426;2.248057;-
methods of downloader middlewares are not documented only the classes;-5.288795;-4.192691;-2.809336;3.1388965;-0.19466394;2.8105664;CODE
themselves since downloader middlewares are controlled through scrapy;-5.86885;-4.6046433;-0.66033703;1.8553686;-1.6026832;2.2658782;CODE
settings;-4.2340403;-1.8681971;6.994803;0.2633829;-1.2244998;1.7592822;IRRE
base classes of downloader middlewares are implementation details that;-4.231151;-4.6258445;-0.15938523;1.4283692;2.9525743;2.7149062;CODE
are not meant for users;-5.037762;-0.72392154;-0.60479254;2.0717075;0.043621305;-1.3745799;CODE
the interface methods of duplicate request filtering classes are already;-2.5227535;-0.65990144;-1.7336811;4.5246873;3.9568598;3.837041;CODE
covered in the interface documentation part of the dupefilter class;-2.6774747;-0.15119703;-2.0745177;2.3587337;3.007735;3.3253913;CODE
setting documentation;-6.0406184;-3.6438694;1.5088592;2.4318326;1.5934926;1.5078986;IRRE
private exception used by the command line interface implementation;-5.9222507;1.4341493;-3.0852816;1.3482411;-0.8193634;-0.32061923;CODE
methods of baseitemexporter subclasses are only documented in;-4.0943456;-2.5169392;-3.9748368;0.58522207;1.9194204;4.030846;CODE
baseitemexporter;-5.248663;-0.7187431;0.2463218;-1.8019614;-0.33631447;3.6743846;-
extension behavior is only modified through settings methods of;-5.4470453;1.8720974;-2.031502;3.5334814;-0.7358749;5.683877;IRRE
extension classes as well as helper functions are implementation;-3.230581;-3.7523148;-0.10298955;1.8345191;3.1734416;2.4889812;TASK
details that are not documented;-2.8312762;-3.7344823;-0.09424857;2.5001397;1.9608152;-1.2728022;CODE
r scrapy extensions a z w a z w methods;-2.4478772;-1.1604133;-1.2216774;-0.1439428;1.4807012;-0.11005771;-
r scrapy extensions a z w a z helper functions;-3.611776;-0.31734914;-0.060239293;-1.7199504;0.47124568;-0.6604413;CODE
never documented before and deprecated now;-7.0805054;-4.474175;-2.3868806;3.8102372;0.5250726;-0.63927436;CODE
implementation detail of lxmllinkextractor;-3.3672237;-1.1401572;-0.6258736;-0.557553;3.7771819;3.5586128;TASK
options for the intersphinx extension;-4.083821;-2.3256977;1.4404662;0.13298354;3.084582;4.2872;CODE
https www sphinx doc org en master usage extensions intersphinx html configuration;-6.967374;-1.521982;-0.81258947;-0.99118096;0.80176336;3.1738343;CODE
other options;-3.5196326;-1.6351225;5.3606057;1.5564047;1.198905;0.45853496;-
2 0 1;-1.9425448;1.6171137;3.1982942;-3.2083378;0.24967171;-4.6859913;-
usr bin python;-3.5545459;-3.613773;-1.9954647;-2.9699547;-3.8459384;-5.1681304;CODE
used for remembering the file and its contents;-4.653703;-4.3389726;3.6761296;0.9864678;1.4598876;-0.16220696;CODE
so we don t have to open the same file again;-5.85775;-0.7114957;2.5995848;3.2467883;0.113854505;2.937581;CODE
a regex that matches standard linkcheck output lines;-1.773053;1.8824897;0.17890325;0.74380785;1.3665494;-0.18254821;IRRE
read lines from the linkcheck output file;-2.123253;0.92260754;0.65319866;1.0291668;-1.8419145;-0.1759709;CODE
for every line fix the respective file;-0.9206822;0.98481566;1.1105344;-1.9479214;-1.6769496;-1.8787857;CODE
broken links can t be fixed and;-5.5748534;-0.14874466;1.6699227;0.7587101;-2.247475;0.859676;-
i am not sure what do with the local ones;-2.654406;-2.6156929;0.9206131;0.84859544;0.33918592;0.7870593;META
if this is a new file;-6.68845;-0.25077513;2.0874517;1.1903654;0.28880063;-1.6288482;CODE
update the previous file;-3.6888964;1.1386377;3.648533;1.0403514;-1.3595806;-0.20580024;CODE
read the new file to memory;-2.638708;-0.71369517;2.4917336;0.5025505;-1.4339571;0.41585535;CODE
we don t understand what the current line means;-3.7495005;-0.092556186;3.8369486;-1.169504;-2.171871;-1.0733314;CODE
usr bin env python;-4.4434032;-3.2804277;-2.2293892;-2.929091;-3.9376152;-3.5718482;CODE
from twisted internet import reactor noqa tid253;-5.0968485;-2.145232;-1.9052069;-2.8853607;-1.5108135;-0.6746596;CODE
reset stats on high iter request times caused by client restarts;-0.48631555;1.7724208;0.49682295;4.1064234;-2.874365;2.8507187;CODE
if delta 3 seconds;-0.48577747;3.2171261;4.040699;0.22707102;-1.1432998;-3.8499336;-
max concurrency is limited by global concurrent requests setting;-2.4313395;1.540083;0.56689316;2.5550559;-0.5007544;3.5763073;IRRE
requests per second goal;-0.85640484;1.2530224;4.4586906;3.9759698;-0.48647717;1.3109797;CODE
qps none same as 1 download delay;-2.6041272;1.5305606;0.14174643;1.2755693;-1.5407822;2.701888;CODE
time in seconds to delay server responses;-1.9137017;0.8522884;3.0241745;2.6945236;-1.8932288;0.5616298;CODE
number of slots to create;-1.2247522;0.5061875;4.3450723;-3.8352432;5.596825;-2.4256;IRRE
declare top level shortcuts;-4.067124;-1.3508902;0.4133579;-0.12405789;4.0804048;2.8113985;-
scrapy and twisted versions;-4.8961563;-3.8818824;-0.014827854;-0.57456684;-0.8783249;-0.2913196;META
ignore noisy twisted deprecation warnings;0.012991464;2.5653694;-4.591003;5.749023;-1.7173307;2.122887;-
support something like o json where json is a value for;0.28234887;0.7121151;1.7010798;0.5858535;3.0926683;0.4147759;IRRE
o not another parameter;-3.1866648;4.751657;0.64868253;-1.8296304;0.10508304;-2.1706243;IRRE
todo add name attribute to commands and merge this function with;-3.3411238;1.5613973;1.8001218;0.85850114;1.0298212;0.8189102;CODE
scrapy utils spider iter spider classes;-4.926335;-2.878017;-0.44917047;-0.031699236;1.3341026;-0.3046846;IRRE
set editor from environment if available;-5.0505166;0.5028916;1.0281003;2.965002;-0.7947425;2.5269036;IRRE
twisted prints errors in debuginfo del but pypy does not run gc collect on exit;-4.6054897;0.25010744;-4.5039344;0.2424165;-5.055815;0.8314041;CODE
http doc pypy org en latest cpython differences html;-6.3422303;-3.6218622;-2.022074;-0.34340942;-4.264188;0.31545496;CODE
highlight gc collect differences related to garbage collection strategies;1.5457344;-0.6981483;-0.3711661;3.8809376;1.9511406;0.060799226;-
crawler process crawlerprocessbase none none set in scrapy cmdline;-6.9081426;-0.57752484;-4.0315347;-0.19277513;-4.5487704;0.8388989;IRRE
default settings to be used for this command instead of global defaults;-4.59939;1.1439716;0.40737697;0.6344475;-1.3161049;4.7506337;CODE
elf settings settings none none set in scrapy cmdline;-7.4243717;-1.2873338;-2.8982782;-0.59225386;-3.5672004;1.1063336;IRRE
scrapy commands list shadows builtins list;-5.9591656;-2.2419877;-1.0996242;-0.46146268;-0.7627604;0.12491894;CODE
elf proc subprocess popen noqa s603;-4.7327538;-4.054765;-3.0731614;-0.3292523;-1.1145865;-1.029694;CODE
load contracts;-2.0862477;-0.9118797;3.2426732;1.3573062;2.614208;2.2114406;CODE
contract requests;-3.482467;0.052412253;5.7914457;1.944653;1.587794;-0.82396084;CODE
pidercls start start type ignore assignment method assign return value;-2.260599;4.3240385;-3.1690707;0.8032064;-0.6626935;1.1768497;IRRE
start checks;-1.9594958;2.0213563;2.3490865;2.3965404;0.7503778;-2.7275343;-
elf exitcode os system f editor sfile noqa s605;-6.00245;-3.0952623;-3.4454262;-1.3239996;-1.8706907;-0.89764535;CODE
from argparse import namespace noqa tc003;-4.100397;-0.23839359;-5.0884495;-1.6921335;-1.0971748;-0.14702545;CODE
by default let the framework handle redirects;-5.9349813;-0.010781658;0.65593946;4.6473966;-3.0766513;3.7518744;CODE
i e command handles all codes expect 3xx;-5.93068;0.61069113;-2.9425344;-1.7254481;0.38878635;-3.5107522;CODE
pidercls start start type ignore method assign attr defined;-4.153718;3.5686402;-3.0391448;1.5680883;-1.5817513;3.6454062;IRRE
elf exitcode os system f scrapy edit name noqa s605;-8.141432;-2.6996434;-3.0352175;-2.1622407;-0.6802807;-1.170349;CODE
print scraped items 60;-1.0619546;-0.045868594;2.5229337;-2.685722;-0.48575103;-2.5495062;CODE
print requests 65;-4.435265;0.75802577;2.1885233;-0.8657947;-0.9286527;-2.5079703;CODE
for rule in spider rules type ignore attr defined;-3.5960743;3.6376681;-3.0016756;0.67092556;1.8708088;1.1980331;CODE
elf spidercls start start type ignore assignment method assign;-4.713542;2.265803;-3.841183;1.6446213;0.9874399;1.8250161;IRRE
memorize first request;-2.2562501;-0.7585627;4.0171;5.0399003;3.3620217;-0.22706869;CODE
parse items and requests;-2.3196638;1.2883582;3.1671834;2.4713347;3.7469263;-0.7872846;IRRE
update request meta if any extra meta was passed through the meta m opts;-2.7025163;2.329809;-0.054163285;4.391606;0.91120225;4.086262;CODE
update cb kwargs if any extra values were was passed through the cbkwargs option;-1.3661612;2.2241;-3.3120587;1.1970378;0.44017273;0.7541641;IRRE
parse arguments;-1.2161262;1.4105024;1.2207721;-0.66414607;2.657101;-2.8372045;IRRE
prepare spidercls;-3.9683464;-0.85863674;1.022206;0.7789938;0.61242545;0.5227182;-
def update vars self vars dict str any none noqa a002;-4.1823435;0.27025756;-2.211169;-0.7986773;-0.7960176;-4.1398067;CODE
first argument may be a local file;-5.9009843;1.4135611;-2.0549972;0.2060465;-2.0955198;-0.9220483;-
the crawler is created this way since the shell manually handles the;-6.0400877;-2.2136798;0.27875134;1.9387276;-1.8330817;2.5027537;CODE
crawling engine so the set up in the crawl method won t work;-4.8807592;-0.17056383;-0.89868075;1.1144916;-2.3715456;0.18698312;IRRE
the shell class needs a persistent engine in the crawler;-5.7352877;-1.8692682;-1.2621566;2.7081032;-0.588105;1.6929423;CODE
pider method self name type ignore attr defined;-3.229966;3.4404657;-3.980623;1.3989372;-0.33697504;3.2373178;CODE
def str self str pylint disable no self argument;-5.915343;2.5651348;-4.096884;1.7819499;-2.197265;0.5831509;CODE
contracts;-2.7902174;-1.6832026;5.8199244;1.1309904;2.838898;-1.8414179;-
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
return cls type ignore misc;-1.5737152;4.4565377;-5.6512146;1.6096418;-0.6875014;-0.92502296;IRRE
setting verify true will require you to provide cas;-4.4162455;3.515298;-3.6725624;3.3743238;0.40834352;-0.59884715;IRRE
to verify against in other words it s not that simple;-1.2728074;1.9818225;0.68096155;3.8885984;2.1004617;-5.6413035;-
kept for old style http 1 0 downloader context twisted calls;-6.6392317;0.6383626;-0.7499426;2.0689638;0.041996066;3.9176872;CODE
e g connectssl;-4.8641095;-5.1014094;3.6590974;-1.1456133;1.2334602;0.53452957;-
ctx set options 0x4 op legacy server connect;-4.803381;1.9411981;-0.39116487;-2.7706804;0.5750876;4.4941096;IRRE
trustroot set to platformtrust will use the platform s root cas;-4.447974;-2.5302255;-2.0052326;0.73256725;-0.953286;1.5565461;IRRE
this means that a website like https www cacert org will be rejected;-4.674966;-0.73168707;0.8079013;2.9637084;-0.5603679;-0.75722915;CODE
by default since cacert org ca certificate is seldom shipped;-4.7209926;-1.5017717;-1.8756415;0.8843512;-0.40568262;0.8814765;CODE
try method aware context factory;-3.0280902;0.021323046;1.7626027;5.402766;2.4677331;4.484517;CODE
use context factory defaults;-4.7470684;0.581631;0.6324068;3.2124152;1.7526953;6.364762;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
hints for headers related types may need to be fixed to not use anystr;-5.7522426;0.9157029;-4.8723273;0.10957514;0.45434192;0.891116;CODE
return respcls url request url status 200 body body headers headers type ignore arg type;-4.0160446;3.1187928;-1.3921247;1.7193145;-1.678282;1.6793505;CODE
closecachedconnections will hang on network or server issues so;-3.0585518;-0.75341237;0.8639591;2.3978057;-2.531876;2.5401654;CODE
we ll manually timeout the deferred;-3.5751543;0.7493785;0.9199371;6.016851;-1.0331728;2.1523268;CODE
twisted issue addressing this problem can be found here;-4.626672;1.3225818;-2.470077;-0.76626015;-2.8046453;0.5872468;TASK
https twistedmatrix com trac ticket 7738;-3.311552;-0.54188436;-0.6830356;-3.2698998;-2.1432364;-0.6472253;CODE
closecachedconnections doesn t handle external errbacks so we ll;-4.1466074;-1.3232133;0.87545615;3.8613515;-1.2132465;4.78091;CODE
issue a callback after disconnect timeout seconds;-3.2602587;2.321057;1.5243976;3.1478844;-3.0402057;2.6186619;IRRE
protocol datareceived self processproxyresponse type ignore method assign;-3.4731624;2.9965231;-4.725221;3.4740212;-0.5492758;4.6484904;IRRE
make sure that enough all bytes are consumed;-1.4997687;3.1377096;-1.7770392;1.2344325;-0.72229487;1.1702214;-
and that we ve got all http headers ending with a blank line;-6.6106186;-0.28645885;1.0569655;0.6573009;-1.13112;0.46051908;CODE
from the proxy so that we don t send those bytes to the tls layer;-4.174384;1.3717593;0.18494648;-0.009041903;-1.4183707;3.712192;CODE
see https github com scrapy scrapy issues 2491;-7.169607;-3.102824;-2.267197;-0.96371883;-2.8707483;0.07649635;CODE
elf protocol datareceived self protocoldatareceived type ignore method assign;-3.466501;2.1828842;-6.3717937;1.8936917;0.7876559;2.320148;IRRE
set proper server name indication extension;-4.408185;1.9105662;-0.8881891;1.2589916;1.3646622;2.5120692;IRRE
loptions self contextfactory creatorfornetloc type ignore call arg misc;-4.685176;1.4203396;-5.0472355;3.100287;-1.1674016;4.8575244;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
todo;-3.4879296;-1.2275677;4.9053526;0.9818142;-0.81314033;-1.7930582;TASK
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
if no credentials could be found anywhere;-3.6595495;-1.7349262;-1.3894986;0.15941587;-0.5307906;-1.2976269;-
consider this an anonymous connection request by default;-4.1192966;0.028574416;0.7165696;2.3859744;-0.32206842;3.2969327;CODE
unless anon was set explicitly true false;-1.6702514;6.504894;-1.4914802;3.7500746;-1.2544534;-2.9047961;IRRE
import botocore auth noqa plc0415;-4.614854;-1.2179531;-4.3663135;-2.156909;-0.61212146;-0.3217355;CODE
import botocore credentials noqa plc0415;-4.1892138;-1.6344322;-4.4693832;-1.8689138;-0.26774642;-0.6301203;CODE
botocore auth basesigner doesn t have an init with args only subclasses do;-3.5943747;0.29946446;-4.784167;1.8173673;-0.13924548;2.0182714;IRRE
elf signer signercls type ignore call arg;-4.9827614;2.4451632;-4.452716;1.3936385;-0.2062678;0.9886829;IRRE
import botocore awsrequest noqa plc0415;-4.307518;-0.40885633;-3.819008;-1.3701454;-0.18964145;-0.5909418;CODE
return yield download func request self spider type ignore call arg;-4.4518785;2.776399;-2.8140259;4.335732;-1.5251291;1.1917454;CODE
either returns a request or response which we pass to process response;-4.708064;2.3669717;3.0474586;3.4651759;-0.026504692;-0.006990269;CODE
or reraises the exception;-3.710096;2.9205644;-0.560759;6.5408998;1.6285945;1.41889;CODE
method tls ssl sslv23 method protocol negotiation recommended;-3.893247;-0.035507936;-1.2829841;-0.101676166;-0.11814555;0.632391;CODE
method tlsv10 ssl tlsv1 method tls 1 0 only;-2.975578;2.750501;-3.682514;-0.6077316;-0.70162296;0.35384947;-
method tlsv11 ssl tlsv1 1 method tls 1 1 only;-3.3434167;1.7050905;-3.2638166;-0.8147699;0.36571416;0.7057954;-
method tlsv12 ssl tlsv1 2 method tls 1 2 only;-3.258201;1.6732498;-2.9144804;-0.474846;0.20373234;0.3741701;-
require an opened spider when not run in scrapy shell;-6.7536345;1.3400996;-1.0965825;2.6025887;-1.3990133;2.4960003;CODE
not wrapping in a deferred here to avoid https github com twisted twisted issues 12470;-4.966221;0.4931857;-3.1311395;2.2133603;-3.1852314;1.8298907;CODE
can happen when this is cancelled e g in test close during start iteration;-3.0042295;4.870582;-1.9323906;5.6511903;-2.009425;-2.358119;CODE
await self stop async will also close spider and downloader;-5.6626554;1.373365;0.7779883;5.0537305;-2.493612;3.157236;CODE
will also close downloader;-5.266163;-1.6932323;2.546794;2.0737665;-0.89726955;1.5531343;CODE
return spider already closed;-5.1125784;3.3200405;1.9456102;3.5650892;-0.92797303;1.25204;CODE
starts the processing of scheduled requests as well as a periodic;-2.8147917;-0.91477996;4.6812925;3.8156478;0.68695277;2.4373465;CODE
call to that processing method for scenarios where the scheduler;-1.5593063;0.083685674;2.177312;4.639217;2.7408144;1.9694825;IRRE
reports having pending requests but returns none;-3.189173;2.5741394;-0.7035391;2.6866033;-2.9292648;-0.58878136;CODE
assert self slot is not none typing;-4.4098535;5.285394;-4.5836153;3.7388625;-0.35211378;-3.2232838;CODE
give room for the outcome of self process start next to be;-2.3649032;1.421813;3.752427;4.306771;0.9763818;0.56098455;CODE
processed before continuing with the next iteration;-0.59686154;2.31472;4.029471;4.050913;2.1497178;-0.8313359;CODE
self stop has cancelled us nothing to do;-4.886076;1.3359495;1.1673274;2.2395093;-4.422028;-0.06791191;CODE
an error happened log it and stop the engine;-5.0803623;1.8119067;0.8346115;1.7199869;-2.8015194;-1.7962083;-
assert self scraper slot is not none typing;-5.0403686;3.7078044;-5.0293026;3.4398582;-1.9127399;-2.2131274;CODE
assert self slot is not none typing;-4.4098535;5.285394;-4.5836153;3.7388625;-0.35211378;-3.2232838;CODE
assert self spider is not none typing;-5.3870106;4.6007915;-4.332228;4.644875;-0.29368785;-2.0467875;CODE
downloader middleware can return requests for example redirects;-4.824691;0.31506217;-0.63466626;3.0007496;-3.4319003;3.5077274;CODE
if not self scraper slot is idle type ignore union attr;-3.7960892;3.1196744;-2.6575387;1.2848315;-0.4110196;1.8015363;CODE
if self downloader active downloader has pending requests;-3.8656905;1.4447234;-0.49352378;3.8579917;-1.2345082;2.9875414;CODE
if self start is not none not all start requests are handled;-5.174135;3.5954323;1.0893782;4.7651052;-1.3909336;1.2200917;CODE
assert self slot is not none typing;-4.4098535;5.285394;-4.5836153;3.7388625;-0.35211378;-3.2232838;CODE
assert self spider is not none typing;-5.3870106;4.6007915;-4.332228;4.644875;-0.29368785;-2.0467875;CODE
assert isinstance ex closespider typing;-4.313237;3.8216608;-4.9467373;7.041479;-0.48711863;-1.2935182;CODE
logger error msg exc info true extra spider spider noqa log014;-5.2953143;1.7884634;-3.7308502;0.15071034;-1.2186147;1.2046858;CODE
store a dictionary which is used to get the respective;0.7582355;-0.056152124;1.9562691;-0.9200357;4.1636333;-0.8032484;OUTD
h2clientprotocolinstance using the key as tuple scheme hostname port;-3.8629441;-1.102752;-3.5531223;-1.2051871;0.28567496;2.2314715;CODE
save all requests that arrive before the connection is established;-1.9655325;1.9585656;4.1287985;5.7101607;-0.13914737;3.9392946;CODE
received a request while connecting to remote;-4.4833126;-0.16428857;2.625696;-0.26120564;-3.5184898;-0.6449063;CODE
create a deferred which will fire with the h2clientprotocol;-4.1218624;0.6164722;-0.9423492;4.014718;-0.65453535;4.94231;CODE
instance;-1.9973047;-3.1490536;5.224779;3.382616;2.1316023;-2.1267405;-
check if we already have a connection to the remote;-3.085158;1.6881676;2.2258162;2.7371082;-1.8096185;-1.761577;CODE
return this connection instance wrapped inside a deferred;-3.3920991;2.8159006;0.754497;4.3834825;-0.085225575;3.9999223;CODE
no connection is established for the given uri;-4.046033;2.1224272;1.6569555;-0.85970086;-2.5283804;-0.10853027;CODE
now as we have established a proper http 2 connection;-4.6029253;0.40616396;3.2784874;1.7276367;-1.8788228;1.7016491;CODE
we fire all the deferred s with the connection instance;-3.1728442;-0.64548194;1.0024914;5.8828835;1.0785003;4.0801187;CODE
call the errback of all the pending requests for this connection;-4.2713313;-0.28132388;2.102795;2.310854;-2.0730429;2.2374103;CODE
assert conn transport is not none typing;-2.5668855;4.662544;-5.886759;4.0098987;-1.1652943;-0.7488369;CODE
id of the next request stream;-3.5669324;1.1991991;3.4112096;1.9120505;2.3708448;1.4124161;CODE
following the convention streams initiated by a client must;-4.0870566;-0.4652221;1.001486;3.088129;4.457036;3.939527;IRRE
use odd numbered stream identifiers rfc 7540 section 5 1 1;-3.7197344;0.26670745;-2.5721552;-2.586299;6.206241;-0.99594426;-
streams are stored in a dictionary keyed off their stream ids;-1.0980521;-1.4980154;-1.5142317;-0.42900112;2.493066;2.0189157;CODE
if requests are received before connection is made we keep;-3.3435597;1.966257;3.9520805;5.331192;-1.744369;1.8113207;CODE
all requests in a pool and send them as the connection is made;-1.8550925;1.1320528;4.027128;3.2369108;-0.045107637;2.2779658;CODE
save an instance of errors raised which lead to losing the connection;-1.6474619;3.373844;-0.16613916;5.3769975;-1.8697647;1.1552225;CODE
we pass these instances to the streams responsefailed failure;-2.290099;1.7663302;-1.9788333;5.505024;0.68716747;1.9077067;CODE
some meta data of this connection;-0.25830004;-1.731956;3.4319131;-1.1102473;0.3777703;-0.5414414;CODE
initialized when connection is successfully made;-3.9835293;2.4716573;1.8944011;3.6822903;-0.81923;1.2038867;IRRE
peer certificate instance;-3.233205;-2.0876248;-0.33132827;-1.0295984;2.4054883;-0.42789742;-
address of the server we are connected to which;-3.6960638;-0.7439452;5.52248;-2.0716887;-0.60199445;0.73297966;TASK
is updated when http 2 connection is made successfully;-3.2921574;1.6688519;3.0101392;4.9152303;-2.2335267;1.5809538;CODE
uri of the peer http 2 connection is made;-5.095281;-0.5391343;2.363521;-0.91742015;-0.6450819;1.9394635;CODE
both ip address and uri are used by the stream before;-4.9789977;0.23129375;1.3357888;0.015329811;-0.6444108;2.7221434;TASK
initiating the request to verify that the base address;-4.0853806;3.9319355;1.1219143;2.5407038;0.9331484;-1.9258001;TASK
variables taken from project settings;-3.1316369;-1.9603584;1.4198085;0.13250399;-0.06844682;1.4942741;IRRE
counter to keep track of opened streams this counter;-0.32883632;0.02248911;4.200613;1.4026165;0.98320025;-0.19216733;CODE
is used to make sure that not more than max concurrent streams;-0.81189084;-0.5247255;1.9552876;2.4500988;3.523494;1.8189362;OUTD
streams are opened which leads to protocolerror;-3.8266625;0.32903972;-2.4200063;2.2107856;-3.4373662;0.30669767;CODE
we use simple fifo policy to handle pending requests;-5.167535;-0.34288436;1.409156;5.791021;0.42519468;3.345437;CODE
flag to keep track if settings were acknowledged by the remote;-2.5135715;2.6508923;0.7345823;4.6463294;-0.42036963;2.552197;IRRE
this ensures that we have established a http 2 connection;-4.8515563;-0.76487666;3.540917;2.390359;-0.54576993;3.1413102;CODE
assert self transport is not none typing;-4.276468;4.67437;-5.0866604;5.543798;-1.3770059;-1.7410854;CODE
assert self transport is not none typing;-4.276468;4.67437;-5.0866604;5.543798;-1.3770059;-1.7410854;CODE
reset the idle timeout as connection is still actively sending data;-1.5101795;0.91815764;1.5311464;1.3132414;-3.3385804;2.845254;CODE
add the stream to the request pool;-4.4639196;-0.034076523;3.0646207;3.0402608;-0.4699815;3.8483076;TASK
if we receive a request when connection is idle;-3.838967;0.9071876;3.0379074;3.3481464;-2.252531;1.8958302;CODE
we need to initiate pending requests;-6.4940004;-0.9096468;3.7413461;3.913628;-0.8929326;1.3275117;TASK
initialize the timeout;-3.3656075;2.5393767;2.898845;2.6192417;-1.2410483;-0.9711817;IRRE
assert self transport is not none typing;-4.276468;4.67437;-5.0866604;5.543798;-1.3770059;-1.7410854;CODE
initiate h2 connection;-5.4599276;-1.0082488;2.5334008;-0.1658867;-0.7818906;0.7017176;IRRE
assert self transport is not none typing;-4.276468;4.67437;-5.0866604;5.543798;-1.3770059;-1.7410854;CODE
assert self transport is not none typing;-4.2764688;4.6743693;-5.0866613;5.543797;-1.3770075;-1.7410843;CODE
we have not initiated the connection yet no need to send a goaway frame to the remote peer;-5.5381145;-0.7845858;1.4441559;0.009735945;-2.7526944;3.1767862;TASK
reset the idle timeout as connection is still actively receiving data;-1.3619431;0.6836215;1.4023246;1.4226978;-2.5805185;2.9300134;CODE
hyper h2 does not drop the connection in this scenario we;-2.5202348;1.279067;0.016140008;0.7420994;-2.0544283;2.044083;CODE
need to abort the connection manually;-3.2835836;1.9197011;2.0005357;1.9877006;-1.9011333;1.8206129;TASK
assert self transport is not none typing;-4.2764688;4.6743693;-5.0866613;5.543797;-1.3770075;-1.7410843;CODE
save this error as ultimately the connection will be dropped;-4.7794304;1.9986125;-1.1739479;2.691141;-2.8223903;1.5320977;CODE
internally by hyper h2 saved error will be passed to all the streams;-3.397872;1.7030814;-4.6638975;1.976775;-1.4440098;2.2859416;CODE
closed with the connection;-4.553095;0.45672554;4.459532;0.4431735;-0.7658438;-1.1269574;CODE
check whether there are open streams if there are we re going to;-1.964308;0.12056599;1.9756504;3.4630017;-0.65438676;-0.24857832;CODE
want to use the error code protocol error if there aren t use;-6.175045;2.9397933;-3.6002076;2.3380003;-0.9927019;-2.1403913;IRRE
no error;-5.884342;2.4395564;-0.39530978;0.04724649;-3.420438;-3.2771664;-
cancel the timeout if not done yet;-4.131952;2.8148885;1.9534504;4.741141;-2.1942594;0.20461287;TASK
notify the connection pool instance such that no new requests are;-2.2752845;1.6044254;1.684543;5.3021073;-1.2171714;2.4134727;CODE
sent over current connection;-3.0660293;0.4922788;4.9331656;1.0758196;-2.154558;0.02894248;CODE
event handler functions starts here;-6.380622;0.6462485;4.2519045;1.7337486;-2.3586586;-0.1992948;CODE
pass we ignore server initiated events;-4.262601;3.9608996;3.302859;4.935509;-0.7373418;2.858386;IRRE
pass we ignore server initiated events;-4.262601;3.9608996;3.302859;4.935509;-0.7373418;2.858386;IRRE
send off all the pending requests as now we have;-4.523584;0.2362837;3.463064;3.1271763;-1.2986956;1.487877;CODE
established a proper http 2 connection;-3.5232694;1.3043864;2.4955628;1.1662343;-1.715803;1.3454984;CODE
update certificate when our http 2 connection is established;-2.82442;0.07664004;2.0573096;1.4826483;-0.18109843;2.3700144;CODE
assert self transport is not none typing;-4.2764688;4.6743693;-5.0866613;5.543797;-1.3770075;-1.7410843;CODE
pass we ignore server initiated events;-4.262601;3.9608996;3.302859;4.935509;-0.7373418;2.858386;IRRE
pass we ignore server initiated events;-4.262601;3.9608996;3.302859;4.935509;-0.7373418;2.858386;IRRE
send leftover data for all the streams;1.0653862;1.1933997;3.6515996;1.3347503;0.624287;2.7793813;CODE
received a streamended event from the remote;-6.006277;-0.6871305;2.2317946;1.8029276;-2.155578;0.8861185;CODE
received a streamreset event ended abruptly;-3.95562;0.5943628;0.029923992;2.7357461;-2.4439116;1.8521432;IRRE
transport connection was lost;-3.1429718;0.58763784;1.5831662;-0.5908752;-2.9875684;1.0832071;CODE
expected response body size is more than allowed limit;-0.9672307;3.893822;-0.6345255;2.7101579;-2.616583;1.0382978;CODE
response deferred is cancelled by the client;-4.181879;3.909376;0.33268163;3.876112;-3.6595657;2.6235023;CODE
happens when client called response deferred cancel;-4.8630223;3.9997375;-0.1723418;3.5552733;-3.702863;2.0695376;CODE
connection lost and the stream was not initiated;-3.7605937;0.40142834;2.14656;0.8803417;-3.2162454;0.49727884;IRRE
the hostname of the request is not same as of connected peer hostname;-4.8648014;0.70353884;-0.94043255;-0.46879017;-1.6363943;0.90766835;CODE
as a result sending this request will the end the connection;-4.204185;1.6559943;4.4533954;3.060655;-1.2782601;1.7207863;CODE
metadata of an http 2 connection stream;-2.579104;-1.7179023;1.2491828;0.9981315;2.134075;3.8219388;CODE
initialized when stream is instantiated;-4.4589386;0.9304882;1.2765408;2.652803;0.30671108;3.7291493;IRRE
flag to keep track whether the stream has initiated the request;-2.8642397;2.9617627;2.651456;5.4577575;-0.16017367;2.6141653;IRRE
flag to track whether we have logged about exceeding download warnsize;-1.5352358;2.7098038;-0.3496421;5.1266685;-1.6198382;0.7146123;CODE
each time we send a data frame we will decrease value by the amount send;3.0268261;2.6015136;3.4107902;-0.69758666;-2.6538625;1.0147854;CODE
flag to keep track whether client self have closed this stream;-2.757733;2.5134268;1.2909437;4.244746;-0.70750165;1.4900956;CODE
flag to keep track whether the server has closed the stream;-2.0704844;2.396559;2.829088;3.9238274;-1.2307369;1.175355;CODE
private variable used to build the response;-4.499766;1.5863649;1.9641874;2.1938658;-0.5197945;-0.92619514;CODE
this response is then converted to appropriate response class;-2.7764046;2.2175698;0.07056954;2.4912963;0.7483019;-0.4866609;CODE
passed to the response deferred callback;-4.213035;3.3670728;1.5458616;4.4572577;-2.3978035;2.5200386;CODE
data received frame by frame from the server is appended;-2.2566347;2.1465585;2.350592;-1.2545953;-3.1550257;2.0690937;CODE
and passed to the response deferred when completely received;-4.9942455;3.0695903;0.23850793;5.5761566;-0.35351798;2.315283;CODE
the amount of data received that counts against the;2.5436342;0.3523571;2.7854025;1.7944576;2.277083;-2.70364;-
flow control window;-4.50096;-1.2022313;4.092474;-0.15049773;-0.49156067;3.0059917;CODE
headers received after sending the request;-4.9954963;1.6223123;1.8719367;1.1417114;-2.0124476;1.4494073;CODE
close this stream as gracefully as possible;-4.140684;0.6527799;2.1614304;4.1714664;-0.5516482;2.9749882;CODE
if the associated request is initiated we reset this stream;-4.973268;2.1086814;2.543825;4.665032;-0.7875835;3.8846793;IRRE
else we directly call close method;-3.5340674;2.577161;2.0315168;5.047151;0.5987046;1.2766917;IRRE
make sure that we are sending the request to the correct url;-5.497118;0.2653391;1.1075009;1.9786576;-3.9420795;1.5435202;CODE
this pseudo header field must not be empty for http or https;-5.3076;2.6421235;-1.7316711;-1.0594562;-1.3003167;1.0867414;CODE
uris http or https uris that do not contain a path component;-3.6508791;0.44379702;0.051948838;1.0816349;-0.7009132;3.5035837;CODE
must include a value of the exception to this rule is an;-3.2538383;4.1714883;-3.1014836;3.0695758;3.0217812;-1.3694178;CODE
options request for an http or https uri that does not include;-3.8906217;1.4281629;0.49366862;1.5745761;-0.9229386;3.19656;CODE
a path component these must include a path pseudo header field;-4.686038;-0.5873504;-1.1914783;-1.485058;2.35864;4.6978827;CODE
with a value of refer rfc 7540 section 8 1 2 3;-3.6761253;1.3564265;-2.2092004;-1.4240276;5.404827;-0.6664008;IRRE
make sure pseudo headers comes before all the other headers;-4.0045667;2.8866296;-2.138129;-0.31001434;0.52613515;2.2203236;CODE
the scheme and path pseudo header fields must;-4.8607874;-1.6835374;-2.8920002;-0.43259388;2.4559894;3.4799438;CODE
be omitted for connect method refer rfc 7540 section 8 3;-3.4441109;1.8481176;-2.6001694;0.4939354;1.8829436;0.5256181;CODE
close this stream calling the response errback;-4.633092;-0.26746815;2.1633902;3.37326;-1.3858819;0.4634669;CODE
note that we have not sent any headers;-6.554634;-1.3977473;1.1548699;0.91366446;-1.2953731;-0.2638024;TASK
firstly check what the flow control window is for current stream;-4.789093;1.1585261;0.019723112;0.9107116;-2.2445035;2.4395332;CODE
next check what the maximum frame size is;-2.2388358;2.276501;0.51683396;-2.0789993;-1.4655457;0.96787345;-
we will send no more than the window size or the remaining file size;-4.1731553;-0.9090851;2.4274564;0.2278662;-0.8132784;1.6317596;CODE
of data in this call whichever is smaller;4.7430606;3.3776166;2.670119;-2.2636926;2.6224875;-1.8671478;CODE
we now need to send a number of data frames;-0.0031903405;-1.5757395;3.985095;-1.917682;-0.41644403;-0.18086515;TASK
end the stream if no more data needs to be send;-1.7369211;3.4383461;3.5516665;2.6993852;-0.64843535;1.0574497;CODE
q what about the rest of the data;5.2757425;-1.1514916;5.159424;-1.2303663;2.3512924;-1.8307923;-
ans remaining data frames will be sent when we get a windowupdate frame;-3.0932686;0.33460093;1.919695;1.2419106;-2.9463394;3.1986644;CODE
we check maxsize here in case the content length header was not received;-4.3427887;2.1393168;-1.78762;0.5424395;-1.9481181;2.6904883;CODE
acknowledge the data received;-0.023099529;-0.027336327;3.271249;1.3835824;0.84079367;-0.63451976;-
check if we exceed the allowed max data size which can be received;1.2000648;4.922711;0.002869853;0.8235286;1.3468065;-1.3688514;IRRE
have default value of errors as an empty list as;-0.6677711;6.2483644;-1.7561849;2.555488;-0.1423341;-1.4664834;IRRE
some cases can add a list of exceptions;-2.6693885;1.8407705;0.22341803;3.897066;3.729379;-2.7377262;CODE
we do not check for content length or transfer encoding in response headers;-3.1630802;2.818011;-2.7238932;1.6096551;-1.0493199;0.53263944;CODE
and add partial flag as in http 1 1 as a request or response that includes;-4.251974;3.685476;1.609586;2.9531174;2.222355;4.170594;CODE
a payload body can include a content length header field rfc 7540 section 8 1 2 6;-3.4935722;-0.0999158;-0.73866934;-1.8152846;2.9591248;1.3460776;CODE
note order of handling the events is important here;-3.0726795;0.99883085;5.0931644;3.4467916;2.2870114;1.0941564;CODE
as we immediately cancel the request when maxsize is exceeded while;-3.3859508;3.589141;0.75392294;4.3339386;-1.1050911;4.0295835;CODE
receiving data frame s when we have received the headers not;-0.8451046;1.5266551;0.14474022;-1.6122636;-1.101874;0.16216607;CODE
having content length;-0.5831968;1.4639686;3.3215687;-1.9260079;3.1173835;-1.0482384;-
stream was abruptly ended here;-3.4487827;0.11426545;1.512584;1.5970762;-2.7496526;0.41640013;CODE
client has cancelled the request remove all the data;-3.360245;4.111552;1.0877323;1.5462778;-3.7682128;1.2233871;CODE
received and fire the response deferred with no flags set;-3.4534152;4.632105;0.5420106;4.4898076;-2.413717;1.7866902;CODE
note the data is already flushed in stream reset stream called;-4.307644;1.6998165;0.2433343;1.7865055;-2.5576584;2.2091143;IRRE
immediately when the stream needs to be cancelled;-4.1673527;0.2041416;3.3055742;3.026149;-1.1489196;2.2104576;TASK
there maybe no status in headers we make;-6.8315144;-0.13725196;-0.14220911;1.8092117;-1.6062913;-0.08489975;CODE
http status code 499 client closed request;-5.243539;1.0513616;-1.1695607;0.56391406;-1.110092;-0.8351965;CODE
working around https github com sphinx doc sphinx issues 10400;-5.531756;-1.3758801;-4.1094484;-0.22186396;-3.3667643;-0.20079987;CODE
from twisted internet defer import deferred noqa tc002;-5.161692;1.1259872;-3.2239554;-0.27414033;-2.127159;1.6976227;CODE
from scrapy spiders import spider noqa tc001;-5.370121;-2.2071202;-0.70971614;-3.013952;0.31538612;-1.4631895;CODE
requires queuelib 1 6 2;-5.0630946;-0.74354476;-1.9812896;-0.1477246;-0.122791685;-0.64015317;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
except valueerror as e non serializable request;-3.5888617;4.678457;-4.833418;3.145483;-1.6962872;1.0299157;CODE
assert self slot is not none typing;-4.4098535;5.285394;-4.5836153;3.7388625;-0.35211378;-3.2232838;CODE
yield dfd fired in wait for processing;-1.0968187;0.12831648;-2.3110573;2.20863;-2.2066371;0.8797256;CODE
assert self slot is not none typing;-4.4098535;5.285394;-4.5836153;3.7388625;-0.35211378;-3.2232838;CODE
assert self crawler engine is not none typing;-4.086703;2.9948494;-6.498375;5.058475;-1.5534145;-2.1768177;CODE
don t handle invalidoutput exception;-2.8646982;5.479536;-2.2286525;5.8090568;-1.8858073;-0.7755797;CODE
stop exception handling by handing control over to the;-4.8037405;4.341741;0.9689941;6.710419;-0.6168843;1.2761024;CODE
process spider output chain if an iterable has been returned;-2.4586103;3.4921005;0.7781354;4.0194297;0.41365466;0.8386827;IRRE
process spider output returns a deferred only because of downgrading so this can be;-3.0192747;3.254834;-2.712871;3.7648494;-2.137818;3.4123693;CODE
simplified when downgrading is removed;-0.9015452;1.267818;-0.22799194;0.7463738;1.1398864;2.6295345;CODE
the result is available immediately if process spider output didn t do downgrading;-2.1314487;2.4462752;-1.9438235;5.019318;-1.4795189;2.1756878;IRRE
we forbid waiting here because otherwise we would need to return a deferred from;-4.010947;2.0204127;0.32864803;4.100871;-0.9727003;2.3635702;CODE
process spider exception too which complicates the architecture;-5.4351034;1.5231544;-1.8594031;3.5216866;1.5051925;2.330437;CODE
this method cannot be made async def as process spider exception relies on the deferred result;-3.454908;2.475609;-2.7847521;4.909833;-2.3765378;2.3012059;CODE
being available immediately which doesn t work when it s a wrapped coroutine;-5.0235033;1.2069182;2.3080251;4.8532777;-1.0436921;2.8053174;CODE
it also needs inlinecallbacks only because of downgrading so it can be removed when downgrading is removed;-7.167675;0.016480723;-3.3133705;1.4756922;-1.2022011;7.8682685;CODE
items in this iterable do not need to go through the process spider output;-3.1586826;2.1023724;0.29735386;2.8458989;1.0114255;0.5833783;CODE
chain they went through it already from the process spider exception method;-5.5852995;2.7910173;-1.4692838;4.6862206;-0.26547724;1.555101;CODE
there are three cases for the middleware def foo async def foo def foo async def foo async;-4.3553534;-0.9694676;-1.5023117;4.1998687;-1.081527;1.7490596;CODE
1 def foo sync iterables are passed as is async ones are downgraded;-1.7069526;2.073682;-3.1821773;3.6912794;-1.6615528;0.33492708;CODE
2 async def foo sync iterables are upgraded async ones are passed as is;-1.9094093;1.4442341;-2.565646;3.6324058;-1.0665119;0.68363035;TASK
3 def foo async def foo async iterables are passed to the respective method;-1.9715183;1.4464104;-1.2002643;4.023871;-0.17250037;-0.000691563;IRRE
storing methods and method tuples in the same list is weird but we should be able to roll this back;-0.48561102;0.45339912;-1.0000902;2.5603895;1.0910734;-0.3187652;CODE
when we drop this compatibility feature;-4.496022;-4.10649;-0.6258705;3.924634;0.37122497;2.552034;TASK
this tuple handling is only needed until async compatibility methods are removed;-3.716711;1.5170116;-4.0947633;3.9733267;1.0905695;4.4133554;OUTD
iterable asynciterator;-0.8811021;0.798195;1.7889886;3.2372482;1.3631687;1.6383932;-
f https docs scrapy org en latest topics coroutines html for middleware users;-6.670845;-3.893246;0.09417396;0.90972894;-3.6242375;1.1450535;CODE
asynciterator iterable;-1.2609484;1.0044607;1.7551098;3.8467276;1.2724283;1.294702;-
might fail directly if the output value is not a generator;-0.2523072;5.148602;-2.9744327;2.6481962;-1.7561804;-3.3826613;IRRE
result close silence warning about not awaiting;-2.8073313;3.162729;-1.5089427;5.0506206;-2.4573967;-0.22058417;IRRE
return mutablechain result recovered type ignore arg type;-0.16457033;5.674194;-4.3677864;1.7371761;0.12634769;0.0813836;IRRE
spider defines both start requests and start;-6.698653;1.3025098;1.7945696;3.398992;1.7571692;3.0979683;CODE
this method is only needed until async compatibility methods are removed;-4.7908516;0.9835678;-3.337557;5.5928097;-0.68652135;6.64265;OUTD
f https docs scrapy org en latest topics coroutines html for middleware users;-6.670845;-3.893246;0.09417396;0.90972894;-3.6242375;1.1450535;CODE
scrapy root handler already installed update it with new settings;-7.3088408;-1.9862276;-1.3171407;1.7733582;-3.6066725;3.1558383;CODE
this needs to be done after the spider settings are merged;-6.1589355;-0.107705705;2.0150063;1.5914115;0.6946466;7.4051394;TASK
but before something imports twisted internet reactor;-5.5837817;-2.1159375;0.38330463;1.438609;-1.68101;0.6807753;CODE
from twisted internet import reactor noqa f401;-4.7276173;-2.1395953;-0.9700106;-1.9780787;-1.3317357;0.01801394;CODE
cannot use deferred f from coro f because that relies on the reactor;-3.7165747;1.431996;-2.413544;2.2507753;-2.6830232;2.5309148;CODE
being installed already which is done within apply settings inside;-4.8077354;0.21689226;1.0953044;2.1001225;1.4969013;3.934559;CODE
this method;-0.8229144;0.5282911;6.332445;1.994936;2.0175798;-2.2900324;CODE
at this point the asyncio loop has been installed either by the user;-4.636227;-2.10521;-0.36554152;1.6634876;-4.6193876;0.8855027;CODE
or by asynccrawlerprocess but it isn t running yet so no asyncio create task;-4.128887;-1.7877512;-1.0206915;4.127713;-3.5702608;3.4555326;TASK
we pass self which is crawlerprocess instead of crawler here;-6.5243177;-1.586567;-2.0345356;2.9938877;-2.295465;1.2943664;CODE
which works because the default resolvers only use crawler settings;-4.1903677;-0.4088164;-2.1093361;3.1081018;-1.6514121;5.4694657;IRRE
resolver build from crawler resolver class self reactor reactor type ignore arg type;-3.361197;0.5666097;-5.4632616;2.0108166;-0.64693624;3.454609;CODE
raised if already stopped or in shutdown stage;-2.2145107;3.5090077;3.1407082;4.210611;1.6539974;-0.78467846;CODE
don t start the reactor if the deferreds are already fired;-4.289689;1.6606343;0.23475939;4.351832;-1.3401885;1.7942493;CODE
reactor run installsignalhandlers install signal handlers blocking call;-5.5861006;-0.5045355;-2.4916265;3.10785;-1.6297866;2.7855797;IRRE
we want the asyncio event loop to be installed early so that it s;-4.2026434;-1.8599634;1.3209153;3.852951;-2.1367598;3.0639563;IRRE
always the correct one and as we do that we can also install the;-3.8243473;-1.4697219;1.7250551;1.0797354;2.5007572;2.0313764;CODE
reactor here;-3.4486287;-2.915795;2.5112476;1.0393312;-2.2781136;-1.3212262;-
the asyncio event loop setting cannot be overridden by add ons and;-4.3025064;1.0671216;-0.93230337;2.608511;-3.8657663;2.6238787;IRRE
spiders when using asynccrawlerprocess;-4.805239;-0.48589924;-1.5317711;3.7311404;-2.4232907;3.4097376;-
the user could install a reactor before this class is instantiated;-5.041521;-1.8791535;-1.2088801;4.123571;2.200796;1.576996;CODE
we need to make sure the reactor is the correct one and the loop;-2.409679;0.5566101;0.54943997;1.4750918;-2.7037313;-2.2091718;TASK
type matches the setting;-3.097728;1.9893453;0.8140075;0.15045622;3.1225529;1.2026612;IRRE
reactor run installsignalhandlers install signal handlers blocking call;-5.5861006;-0.5045355;-2.4916265;3.10785;-1.6297866;2.7855797;IRRE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
xxx google parses at least first 100k bytes scrapy s redirect;-3.8525083;0.41175357;-1.5182103;-0.05422255;-1.5094699;0.30164838;IRRE
middleware parses first 4k 4k turns out to be insufficient;-2.6390572;1.0618155;-3.362312;0.6199829;-2.459019;1.5930653;IRRE
for this middleware and parsing 100k could be slow;-0.28324547;-1.672053;-0.6866822;1.3618422;-0.6567016;-0.8643638;CODE
we use something in between 32k by default;-2.635268;-2.4144313;0.026642257;0.16319269;1.0563743;2.2960303;CODE
other http methods are either not safe or don t have a body;-5.385954;1.1383896;1.0771431;4.1842513;-1.9578129;0.5834237;CODE
if ajax crawlable in request meta prevent loops;-2.0391266;3.7870824;0.95083416;5.069391;-1.2390984;2.598312;IRRE
ajax crawl request request replace url escape ajax request url;-3.9099004;0.7318718;1.0049794;0.5692566;-1.9081436;3.202201;CODE
stripping scripts and comments is slow about 20x slower than;-1.4552855;0.18342927;0.02838623;2.1788604;-2.8081095;0.6941298;CODE
just checking if a string is in text this is a quick fail fast;-1.6941657;3.8664706;0.72873014;3.7877774;0.6115988;-5.942723;CODE
path that should work for most pages;-2.6973484;-2.0376196;3.288689;1.2495121;1.282516;3.4636047;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
elf domain spider http auth domain type ignore attr defined;-4.9471636;1.6318929;-4.116762;0.24206029;-0.5399993;3.0985694;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
skip uncacheable requests;-3.6589444;3.8786147;0.17350316;6.3563514;-1.7226624;2.718327;CODE
request meta dont cache true flag as uncacheable;-3.7687848;4.422757;-1.7720264;2.9546974;-3.0136554;3.410411;CODE
look for cached response and check if expired;-3.3622508;3.787491;0.70448095;4.396579;-2.8255508;0.06064578;CODE
return none first time request;-4.278169;6.3003325;1.3178478;4.947284;-0.99170804;0.49756044;CODE
return cached response only if not expired;-2.238183;4.8035536;1.1482646;4.6476793;-2.3599992;2.0586104;CODE
keep a reference to cached response to avoid a second cache lookup on;-1.1128912;3.3845003;0.3414458;4.8036675;0.96089077;4.2457166;CODE
process response hook;-4.010108;2.7391036;2.6214082;4.060529;-1.585862;0.2719165;CODE
skip cached responses and uncacheable requests;-2.1735156;3.0947893;0.31539136;6.0398417;-1.3175482;2.966537;CODE
rfc2616 requires origin server to set date header;-5.100517;0.5382633;-2.1962914;-0.40671763;-2.6545148;2.535021;CODE
https www w3 org protocols rfc2616 rfc2616 sec14 html sec14 18;-6.2961273;-2.4681454;-0.21926616;-2.0771594;-0.51333094;-1.4136316;CODE
do not validate first hand responses;-2.3523417;4.228804;-0.8556788;5.621053;0.4103543;-3.2332256;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
except attributeerror pragma no cover;-3.1889262;2.2526443;-4.2725115;2.662467;-3.4597514;-1.1671277;META
import zstandard noqa f401;-4.4073753;0.60240424;-1.6795472;-3.2617702;-0.16801707;0.5422487;CODE
force recalculating the encoding until we make sure the;-0.68208516;2.969466;-2.8132548;-0.79505104;-0.6056681;-0.52339345;CODE
responsetypes guessing is reliable;0.38198686;0.32195592;-2.1184812;6.6354127;-0.5930303;-0.74468917;IRRE
shouldn t be reached;-5.20572;2.987361;2.852278;2.6336253;-3.374901;-2.9110646;-
return body pragma no cover;-4.431216;3.0306478;0.9523801;3.0277112;-1.0200719;1.3420224;IRRE
from urllib request import type ignore attr defined;-4.309967;1.466167;-4.5553064;1.8804069;-1.4505765;2.287854;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
some values such as var run docker sock can t be parsed;-4.0369153;3.313009;-2.400973;-0.29486364;-1.8153937;-0.1972826;IRRE
by parse proxy and as such should be skipped;-4.61944;2.9084187;-1.5175053;2.5658126;-0.14890634;2.3649352;IRRE
no proxy is only supported by http schemes;-3.7884817;-0.6446527;-0.6068001;0.60589486;-2.254265;2.5870926;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
hostname can be none for wrong urls like javascript links;-5.2340055;1.3201978;-0.36453182;-0.17660207;-2.4112895;-0.18276693;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
https fetch spec whatwg org ref for cors non wildcard request header name;-4.423545;0.060307287;-2.1852493;1.6422101;0.11212899;1.113218;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
check if parser dependencies are met this should throw an error otherwise;-2.967025;3.1860187;-4.576291;2.701272;1.6050901;-1.7832237;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
resp status b r n b http 1 1 100 599;-3.8553126;1.5800291;0.35328782;-1.4388036;0.47456393;-2.118212;CODE
response body b r n response header b r n response status;-2.852868;2.257774;1.0085105;0.84752697;1.3569638;-0.8030708;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
internal;-4.3479714;-2.1410604;5.6249447;1.7275206;1.4071658;-1.545764;CODE
items;-2.4500973;-1.0134436;7.5080404;0.31605875;3.2009318;-2.964334;-
commands;-4.754962;-2.820942;5.544158;0.092354655;1.8483114;-3.8778195;CODE
def start exporting self none noqa b027;-6.1221333;-0.59035736;-2.1743062;-1.355487;-2.3126223;-1.1134458;CODE
def finish exporting self none noqa b027;-5.546154;-0.3715302;-0.7892836;-0.29359657;-1.6968058;-1.4251448;CODE
there is a small difference between the behaviour or jsonitemexporter indent;-4.3930497;2.1274784;-0.8870692;1.6356323;-2.3673365;4.408213;-
and scrapyjsonencoder indent scrapyjsonencoder indent none is needed to prevent;-6.497629;0.6382301;-2.0271487;-0.019619044;0.33886853;1.6178691;CODE
the addition of newlines everywhere;-1.9071124;-1.2893;2.5972297;-1.3478931;0.40014005;-0.18533121;TASK
newline windows needs this https github com scrapy scrapy issues 3034;-7.6733694;-2.3897636;-2.4989865;-1.5371281;-3.3390694;1.0065715;CODE
except typeerror list in value may not contain strings;-0.31514755;4.476492;-4.8993907;2.148495;-2.4229686;-4.091361;CODE
elf stream detach avoid closing the wrapped file;-4.8259096;0.5047989;-0.6569058;1.6597445;-2.211651;3.2985973;CODE
use declared field names or keys if the item is a dict;-2.391883;0.4644036;-2.1572616;-0.4592456;3.2667596;-1.5164024;-
def export item self item any dict str bytes any type ignore override;-3.4143198;1.4703004;-4.864969;-0.2543592;-0.39412525;0.87108374;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
for closespider timeout;-4.0975995;-1.0356393;2.334843;3.0137105;0.032073263;-0.2685877;CODE
for closespider timeout no item;-6.384963;1.2608292;1.2456149;2.8268445;-0.32075083;1.4662546;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
ignal signal signal sigusr2 self dump stacktrace type ignore attr defined;-1.9776378;2.7337344;-5.821604;0.08601546;-1.8670914;2.3710835;CODE
ignal signal signal sigquit self dump stacktrace type ignore attr defined;-1.3150697;3.3231544;-5.5816817;0.41427523;-1.7508988;2.5625584;CODE
win32 platforms don t support sigusr signals;-3.580259;-1.4004611;-3.9459388;-1.1197382;-3.0842729;1.9422122;CODE
dumps f thread name id n dump n;-3.2103872;0.10233418;0.43073407;-1.4318534;-0.7241485;-2.1467216;CODE
win32 platforms don t support sigusr signals;-3.580259;-1.4004611;-3.9459388;-1.1197382;-3.0842729;1.9422122;CODE
ignal signal signal sigusr2 self enter debugger type ignore attr defined;-3.5654795;2.8522966;-5.8000116;0.7373824;-2.237475;1.4656321;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
return true accept all items by default;-2.2561824;5.4545646;1.3021425;2.823398;0.058226082;1.461727;CODE
import boto3 session noqa plc0415;-5.5228043;-0.8488498;-3.183724;-2.6990376;0.12267069;-0.26609203;CODE
elf keyname str u path 1 remove first;-6.8758574;0.38017848;-0.8256821;-2.4984136;0.39506269;-1.0477332;-
elf blob name str u path 1 remove first;-5.2260303;0.32020667;-0.3914608;-2.0480447;-0.2746602;-1.1042479;-
from google cloud storage import client noqa plc0415;-3.8139505;-0.48161933;-2.1521568;-2.7472224;-0.38640693;0.98235154;CODE
format str noqa a002;-3.4323332;1.7806515;-1.8926266;-6.671743;1.2647729;-3.7794304;CODE
filter itemfilter noqa a002;-0.3896801;4.0101323;-0.89241403;-0.8902591;1.6475608;0.6266935;-
feed params;-1.0722054;-0.90786344;3.845885;1.5532757;0.84878165;2.4453433;-
exporter params;-3.645821;0.62993103;0.60194016;0.00096577726;0.24682337;2.4076574;-
flags;-2.3233228;0.7143679;5.356156;0.47056496;1.7960608;-2.58008;-
begin backward compatibility for feed uri and feed format settings;-4.371433;-1.1167336;-2.3482926;1.1563208;-0.7904199;4.7574925;CODE
handle pathlib path objects;-4.622626;-2.3969276;-1.2898895;1.7639196;-1.2821224;1.9203815;IRRE
end backward compatibility for feed uri and feed format settings;-4.591365;-1.1675029;-2.5140827;1.7080775;-0.86361223;4.859127;CODE
feeds setting takes precedence over feed uri;-2.9217823;0.97426367;-0.7611926;1.4520676;-1.0487105;4.48136;IRRE
handle pathlib path objects;-4.622626;-2.3969276;-1.2898895;1.7639196;-1.2821224;1.9203815;IRRE
await all deferreds;-3.2848608;1.5569336;1.3110458;4.7243066;-0.5919458;1.1829432;CODE
send feed exporter closed signal;-3.3129036;0.8457714;-0.0043131174;1.057687;-3.312939;3.1106508;CODE
normal case;-2.4815557;1.7821295;4.1564193;-0.8103582;2.6566498;-1.9000652;CODE
need to store the empty file;-3.3775647;2.5994785;1.6670983;-1.0754825;-0.8178039;-0.22983848;TASK
in this case the file is not stored so no processing is required;-4.956538;1.379761;-1.7139231;1.6951548;-1.7705953;2.2807233;CODE
d deferred none maybedeferred slot storage store get file slot type ignore call overload;-3.012354;3.818703;-4.1500816;1.6970385;0.32583362;2.854462;CODE
if slot doesn t accept item continue with next slot;-2.898302;5.577685;3.6125195;1.0280464;1.9657359;-1.6396571;CODE
create new slot for each slot with itemcount feed export batch item count and close the old one;-0.3851812;1.7763524;2.255257;-0.5683164;1.6852616;2.1019037;CODE
https docs scrapy org en latest topics feed exports html feed export batch item count;-2.9332345;-2.3191433;-0.76138324;0.7738811;-3.101373;1.2694508;CODE
load the item filter if declared else load the default filter class;-2.2895548;3.125717;-0.4319217;3.042207;2.0986772;2.1388822;CODE
maxage 3600 24 365 one year;-0.61055154;0.6393054;1.7065299;-1.751763;0.26140678;-1.9065595;-
obey user agent directive cache control no store;-4.9284277;1.3391861;-0.5344847;2.1615293;-1.1069307;4.600392;-
what is cacheable https www w3 org protocols rfc2616 rfc2616 sec14 html sec14 9 1;-4.9276724;-1.5035579;-0.57234794;0.058894698;0.2588052;0.6415841;CODE
response cacheability https www w3 org protocols rfc2616 rfc2616 sec13 html sec13 4;-4.3339567;-1.1571034;-0.55630857;1.5487733;-0.51071733;-0.12728895;CODE
status code 206 is not included because cache can not deal with partial contents;-5.9206543;2.1011543;-2.461082;2.645014;-0.23216848;1.5412464;CODE
obey directive cache control no store;-4.8057346;2.5422509;0.22918466;1.7989212;-1.2017902;4.858274;-
never cache 304 not modified responses;-2.9178393;2.2677298;-0.83857304;3.6578288;-3.063583;2.249866;CODE
cache unconditionally if configured to do so;-3.0813203;3.6358354;-0.030774599;4.6742654;-0.46724504;4.5917954;TASK
any hint on response expiration is good;-3.8109548;3.1783001;0.5771496;3.8848047;-2.7505345;-1.0958605;CODE
firefox fallbacks this statuses to one year expiration if none is set;-4.3432364;3.3839543;-1.889571;2.833621;-2.3569539;1.3985707;IRRE
other statuses without expiration requires at least one validator;-2.8097603;4.4304442;-4.059515;2.6174612;3.6141732;1.1509901;CODE
any other is probably not eligible for caching;-4.442377;-1.4235063;-0.62291175;3.1662567;-0.26345438;2.2173834;TASK
makes no sense to cache responses that does not contain expiration;-3.272014;3.1498127;-1.1609843;4.385745;-1.564678;2.052116;CODE
info and can not be revalidated;-5.6200066;0.5441931;1.4261254;0.92654395;-0.47760898;-0.09855695;-
from rfc2616 indicates that the client is willing to;-4.25067;-2.0658166;0.6977811;2.0161867;0.64796317;-0.47065407;CODE
accept a response that has exceeded its expiration time;-3.432266;4.327387;0.9689279;4.0460596;-1.5869141;-0.23069742;IRRE
if max stale is assigned a value then the client is;-1.1291859;5.167955;0.41468152;3.2310052;0.54712456;0.58784354;IRRE
willing to accept a response that has exceeded its;-2.8323386;0.40142593;4.678894;3.6126235;-1.022456;-2.7779832;IRRE
expiration time by no more than the specified number of;-1.3671905;4.4369307;1.0761427;-1.1098827;0.6567692;-2.7584796;-
seconds if no value is assigned to max stale then the;0.27508965;4.8002186;2.1407347;2.609211;0.039992128;-1.5074794;IRRE
client is willing to accept a stale response of any age;-3.20104;1.7538586;1.3842582;3.5542688;-1.3830857;0.14781703;CODE
cached response is stale try to set validators if any;-2.2428262;4.6674447;-2.283866;4.742769;-2.205632;1.904884;CODE
use the cached response if the new response is a server error;-2.8623173;5.1020484;1.2383965;5.431396;-2.2693222;1.7928427;CODE
as long as the old response didn t specify must revalidate;-4.8844924;3.1000583;0.16104656;4.590388;-0.8158824;2.190345;CODE
use the cached response if the server says it hasn t changed;-3.3063786;3.839765;2.5299194;5.297377;-2.6242964;2.4273405;IRRE
return max 0 int cc b max age type ignore arg type;-0.049048845;5.737181;-2.6146624;-2.3586714;1.5441742;-1.6869673;CODE
reference nshttpresponsehead computefreshnesslifetime;-2.2245493;-1.4744242;-0.7810703;2.2158408;-2.074517;2.317089;CODE
https dxr mozilla org mozilla central source netwerk protocol http nshttpresponsehead cpp 706;-5.519455;-1.1402988;-0.77959615;-1.9115332;-1.2385163;1.2025189;CODE
parse date header or synthesize it if none exists;-1.9085782;2.426173;-1.2564481;0.8249096;1.5826054;-2.1266267;IRRE
try http 1 0 expires header;-6.077984;1.4700352;0.03810721;0.9916405;-2.8984797;1.5963272;CODE
when parsing expires header fails rfc 2616 section 14 21 says we;-5.9178925;1.5191393;-4.674296;1.1000143;-0.19909242;-0.056946382;CODE
should treat this as an expiration time in the past;-4.3223443;2.6852624;0.64730114;3.003704;-0.028680246;1.2168747;CODE
fallback to heuristic using last modified header;-1.3346674;1.7829238;-0.47899118;3.8585188;2.2959454;1.9053798;CODE
this is not in rfc but on firefox caching implementation;-5.088732;0.4811909;0.5171932;1.8126863;1.3849814;3.4429984;TASK
this request can be cached indefinitely;-6.0432453;0.0874391;2.5452302;3.6045241;-0.8607016;1.7291049;CODE
insufficient information to compute freshness lifetime;1.1426542;0.9081682;-1.8150356;3.0239468;0.1742802;-1.1041819;CODE
reference nshttpresponsehead computecurrentage;-3.8390434;-1.5312407;-1.4305398;1.1027329;-1.4613252;1.5102555;CODE
https dxr mozilla org mozilla central source netwerk protocol http nshttpresponsehead cpp 658;-5.592289;-1.1244489;-0.8209677;-2.0588994;-1.2822275;1.1317848;CODE
if date header is not set we assume it is a fast connection and;-3.0294435;0.31337842;0.7552527;2.1108694;-1.7136966;1.5172609;CODE
clock is in sync with the server;-3.7457979;0.73648226;1.9435086;-0.08291626;-3.3555;0.3159159;-
age int response headers b age type ignore arg type;-2.603773;4.3872943;-2.622988;0.10451382;1.3136549;0.57381356;CODE
elf db any none the real type is private;-5.65929;-2.5864964;-2.4318051;-0.9612963;1.9147916;-2.3205771;CODE
return none not cached;-3.4420612;5.953225;-1.0191628;3.0173824;-2.4038818;-0.57184327;IRRE
return none not found;-4.9202223;6.6319327;-2.0858428;2.9328744;-2.241735;-3.965932;IRRE
return none expired;-3.7378929;5.3007936;-0.16507512;2.2211764;-1.3155266;-1.5755076;IRRE
return cast dict str any pickle loads db f key data noqa s301;-2.0585968;1.088553;-4.5148635;-1.7080858;-0.2785464;-2.837065;CODE
https github com python mypy issues 10740;-4.518432;-2.8101246;-3.4720864;-1.4636153;-6.5519323;-2.2602477;CODE
gzip open if self use gzip else open type ignore assignment;-3.419318;4.1242194;-3.2293603;1.2437785;0.57752496;0.69568044;CODE
return none not found;-4.9202223;6.6319327;-2.0858428;2.9328744;-2.241735;-3.965932;IRRE
return none expired;-3.737892;5.3007917;-0.16507387;2.2211757;-1.315526;-1.5755084;IRRE
return cast dict str any pickle load f noqa s301;-2.1887138;1.7604785;-3.6979563;-1.7109112;-0.31082228;-2.2944298;CODE
date str to unicode date str encoding ascii type ignore arg type;-2.5514574;1.3843541;-2.6580224;-1.3086036;-2.096716;1.148802;IRRE
return mktime tz parsedate tz date str type ignore arg type;-2.1186497;3.0724213;-3.7103126;0.28170252;-0.6597313;-0.5802701;IRRE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
stdlib s resource module is only available on unix platforms;-4.9982443;-3.5298612;-3.6466272;-1.5706071;-2.8931544;1.087792;CODE
on macos ru maxrss is in bytes on linux it is in kb;-2.5717146;-0.9452451;-3.12148;-3.624857;-0.8848896;0.972332;-
if self warned warn only once;-2.6554015;2.3132768;0.73792624;5.4333158;-0.6592037;-0.9890017;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
io iobase is subclassed here so that exporters can use the postprocessingmanager;-4.90069;-1.7909826;-2.854961;2.2898145;-0.015354837;3.039135;IRRE
instance as a file like writable object this could be needed by some exporters;-3.8895433;-1.9148006;-0.3443898;2.0573373;3.038376;3.165235;CODE
such as csvitemexporter which wraps the feed storage with io textiowrapper;-3.6212597;-3.1668994;0.05749821;0.5250967;0.145421;4.5014167;-
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
signal to update telnet variables;-1.3927184;1.3599331;1.3193859;0.090865575;-0.75500077;1.0566788;CODE
args telnet vars;-3.4013603;1.3459389;0.83420306;0.084911525;-1.6629493;-1.3648322;IRRE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
pider download delay self start delay spider type ignore attr defined;-5.2184324;1.9941723;-2.767058;1.8596414;-1.1400411;4.791571;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
defined in the http cookiejar module but undocumented;-6.0815535;-1.5229445;-1.393478;0.19863597;0.09873674;1.5872782;CODE
https github com python cpython blob v3 9 0 lib http cookiejar py l527;-5.8496475;-4.211107;-3.4787333;-2.9369287;-4.6294813;-2.5753293;CODE
elf jar cookies lock dummylock type ignore attr defined;-5.647829;1.8876679;-4.665516;1.2625631;0.3985719;2.01342;CODE
elf jar extract cookies wrsp wreq type ignore arg type;-3.311484;0.8161494;-4.1798205;1.0907575;0.6337053;0.83462536;-
elf policy now self jar now int time time type ignore attr defined;-5.7952037;1.2149243;-3.9474556;3.0631177;-0.011000003;2.0198348;CODE
the cookiejar implementation iterates through all domains;-2.2798107;-1.8653324;1.3503854;1.2416165;1.0984653;1.1828872;TASK
instead we restrict to potential matches on the domain;-1.0460978;0.5754704;0.8827749;3.6798763;3.174213;2.0490012;CODE
if host in self jar cookies type ignore attr defined;-4.21134;3.9488554;-3.2612493;2.318338;-0.52542335;2.00319;CODE
cookies self jar cookies for domain host wreq type ignore attr defined;-3.6827226;2.0330727;-3.9166148;1.2007153;-0.46979412;3.176052;CODE
attrs self jar cookie attrs cookies type ignore attr defined;-4.8291183;2.3674588;-3.5167239;1.2277122;-0.8372911;3.0913758;CODE
this is still quite inefficient for large number of cookies;-1.3027632;-0.37778842;2.11083;1.0727905;-0.47374442;3.2111154;CODE
return self jar cookies type ignore attr defined no any return;-4.375576;3.7849114;-3.499199;2.5517213;-1.8725874;1.5247482;CODE
return self jar make cookies wrsp wreq type ignore arg type;-4.065182;1.8860376;-3.3582168;2.3009543;-0.20430993;1.4440273;CODE
elf jar set cookie if ok cookie wrappedrequest request type ignore arg type;-4.133986;2.8320858;-2.5141325;2.5031486;-1.0370485;2.6496072;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
isn t fully compatible typing wise with either dict or caselessdict;-3.1370034;-1.093997;-5.014156;-0.38872388;-0.7603017;-0.81354815;CODE
but it needs refactoring anyway see also https github com scrapy scrapy pull 5146;-7.3055973;-3.7016866;-2.7808292;0.98914784;0.37655413;1.0606898;TASK
a workaround for the docs more than one target found problem;-4.325001;-1.5853243;-4.2091517;4.7342644;-0.90007156;2.3586955;CODE
import scrapy noqa tc001;-5.896724;-1.4355304;-3.087515;-3.3882341;-2.0109475;-1.1428443;CODE
typing notrequired and typing self require python 3 11;-5.507226;-2.798978;-3.4547992;-0.73789585;-1.9738607;-2.4771857;CODE
circular import;-1.2639219;-1.1371967;2.3101718;-1.7522137;0.075745516;-0.33959985;CODE
elf encoding str encoding this one has to be set first;-3.8514817;0.5148575;-2.2741807;-2.353351;-0.2655138;-0.30916664;IRRE
default 0;-4.9465256;2.3547928;0.6378427;-2.5061207;-1.9609077;-1.4102932;CODE
value that the ref scheduler topics scheduler may use for;-1.7131253;-1.1777499;1.6833214;3.7657657;1.6577561;2.3375819;IRRE
request prioritization;-1.0276477;1.0551863;3.3449223;6.0172067;3.913387;4.1720223;CODE
built in schedulers prioritize requests with a higher priority;-1.3709763;0.31056985;2.1616728;4.6268477;2.515081;4.9714565;CODE
value;-0.69988436;2.4135733;5.148833;-1.763415;2.0859022;-6.1452317;IRRE
negative values are allowed;-1.7479777;5.12083;-0.5100667;-2.5984206;-1.118181;-3.5817842;IRRE
class collections abc callable to parse the;-1.5736839;0.071766235;0.35869986;1.5075742;4.5111213;-2.0971117;IRRE
class scrapy http response to this request once received;-5.232738;-0.35831916;0.38461423;2.8898697;-1.017645;0.490809;CODE
the callable must expect the response as its first parameter and;-3.677219;4.0515347;-0.3793266;4.1181865;-0.621693;2.8071132;IRRE
support any additional keyword arguments set through;-3.6966074;-0.18007086;-2.6136482;1.9992841;4.487805;2.1145153;TASK
attr cb kwargs;-1.9059483;-1.6939175;1.9250885;-0.3332268;1.257895;-0.17168073;IRRE
in addition to an arbitrary callable the following values are also;-1.3891168;3.6043966;1.3122014;-2.9429624;5.1657014;-1.6589886;IRRE
supported;-4.929468;-3.8329413;2.6012824;1.1891209;0.33778575;-0.031595215;-
none default which indicates that the;-6.5007296;1.1274714;-0.5177899;-0.03399926;0.16605073;0.89864695;IRRE
meth scrapy spider parse method of the spider must be used;-3.275914;0.42900667;-0.072509475;0.43989617;-0.22978482;1.1079769;TASK
func scrapy http request no callback;-6.859376;0.03295971;-1.0407381;2.4371574;-4.293895;0.97768176;CODE
if an unhandled exception is raised during request or response;-3.4707878;5.5071416;-0.3461373;7.789498;-0.6532995;0.8217883;CODE
processing i e by a ref spider middleware;-3.763685;-2.1747475;1.4887726;1.608548;1.8570896;1.410571;-
topics spider middleware ref downloader middleware;-5.1926527;-3.741258;0.38654107;3.4111347;0.7175735;3.6125193;CODE
topics downloader middleware or download handler;-4.0231113;-3.7448983;2.3046083;3.7080007;-0.021028783;4.5666747;CODE
setting download handlers attr errback is called instead;-7.1268425;-0.34535906;-0.59424716;3.4176702;-2.046814;5.2198467;IRRE
tip;-2.9625428;-0.024970492;5.27324;2.7125676;-2.0449183;-2.3606048;-
class scrapy spidermiddlewares httperror httperrormiddleware;-5.5158486;-1.5074217;-3.408029;0.3118841;-2.2719822;0.17779575;CODE
raises exceptions for non 2xx responses by default sending them;-2.7320096;5.30275;-3.3028727;3.139831;0.009147455;0.97830427;CODE
to the attr errback instead;-3.407738;-1.470806;1.2996243;2.7578197;-0.98035437;2.0786836;-
seealso;-3.3378189;-0.845601;4.2762947;-1.0148152;0.24893856;-0.5595246;-
ref topics request response ref request callback arguments;-4.0833464;0.22617877;1.3284224;3.4727635;-0.5308861;2.9421542;CODE
class collections abc callable to handle exceptions raised;-1.7092514;1.9724941;-1.1035484;5.36078;3.3213778;-0.76222694;CODE
during request or response processing;-2.6342208;0.25438502;4.7572956;4.7989535;1.7615128;1.5240322;CODE
the callable must expect a exc twisted python failure failure as;-5.025737;-0.28864694;-4.513675;1.7138528;-4.19382;-0.5189303;IRRE
its first parameter;-4.2879634;1.540346;2.1504383;-0.38321447;1.7213206;-0.1592656;IRRE
seealso ref topics request response ref errbacks;-4.286749;-1.7529459;1.2628244;4.349673;0.6415875;1.5653139;CODE
whether this request may be filtered out by ref components;-3.0383558;3.4774215;-0.6284682;5.851834;1.193433;4.2325597;CODE
topics components that support filtering out requests false;-2.2714381;-0.13049214;-0.6370074;4.760302;0.19101898;3.7218063;CODE
default or those components should not filter out this request;-4.33873;2.268648;-0.27964434;3.048884;0.22269759;5.3662;CODE
true;-0.6604863;-0.90942127;1.8119599;3.378718;0.206395;-0.28846526;-
this attribute is commonly set to true to prevent duplicate;-1.6071352;2.4149177;-1.1193208;2.8178926;4.3368273;1.57777;IRRE
requests from being filtered out;-2.5837295;2.2983406;1.1154982;3.9654984;-1.265462;2.1850584;CODE
when defining the start urls of a spider through;-5.70728;0.12066306;3.0049527;1.3504242;2.33091;3.642623;CODE
attr scrapy spider start urls this attribute is enabled by;-7.55517;-0.9382799;-0.83407587;0.8675024;-1.072602;3.5264103;META
default see meth scrapy spider start;-5.255743;-1.1639893;1.5806494;0.7346409;-2.3658373;2.1239312;CODE
only instance methods contain func;-2.4544253;0.40654567;-1.4788151;4.3130045;0.114638336;-0.27771914;-
we need to use func to access the original function object because instance;-2.8100498;1.511885;1.5692228;2.7145653;-0.4571719;0.8573587;CODE
method objects are generated each time attribute is retrieved from instance;-0.8557211;0.79991746;0.10938441;5.3564963;1.8697982;2.1484337;CODE
reference the standard type hierarchy;-2.6308746;-1.8576494;-1.9399978;-0.048604082;5.2811036;1.2746447;CODE
https docs python org 3 reference datamodel html;-3.2921264;-3.0087607;-3.4388077;-0.20946819;-2.3074553;0.76734704;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
assert form base url is not none typing;-4.564904;4.671048;-2.888223;3.4658551;-1.5614774;-1.1787025;CODE
match browser behaviour on simple select tag without options selected;-3.2370846;2.2253633;0.9686423;3.0099368;0.22036439;2.8858693;CODE
and for select tags without options;-2.931723;-1.9966968;2.2150624;0.8319269;4.657424;0.77699375;CODE
if we don t have clickdata we just use the first clickable element;-4.068142;0.11715279;4.113098;1.7132455;0.5029424;4.7136626;CODE
if clickdata is given we compare it to the clickable elements to find a;-0.50178814;2.1959987;2.3002114;2.9092178;1.2902952;-0.24309324;CODE
match we first look to see if the number is specified in clickdata;-1.117063;4.6633687;0.5721919;0.666385;1.5401225;-1.8915557;CODE
because that uniquely identifies the element;-2.6348324;0.82082355;0.3835234;-2.4115844;3.3234813;0.106735684;IRRE
we didn t find it so now we build an xpath expression out of the other;-4.4448676;-1.2737553;0.49700972;-0.3355183;2.7387784;-0.015774637;-
arguments because they can be used as such;-2.7982957;-0.7095302;0.8164058;1.9275923;1.245397;0.42938584;IRRE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
spec defines that requests must use post method;-4.391923;1.1785693;-0.21102588;5.108962;0.7984626;1.5191828;CODE
xmlrpc query multiples times over the same url;-1.395905;1.514542;1.8793312;2.2296205;2.2898672;2.6422625;CODE
restore encoding;-3.180825;-0.26747456;-0.4769948;-2.6097355;-1.33575;0.6440666;-
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
return self request cb kwargs type ignore union attr;-2.208274;4.1388917;-2.7720606;2.1281295;1.2597966;2.3258607;CODE
return self request meta type ignore union attr;-2.5180871;4.632132;-1.6622664;2.8809462;0.7737673;2.605085;CODE
elf body bytes b used by encoding detection;-1.7098402;-0.33975783;-2.1482756;-2.3918462;0.904564;-0.9270798;-
pylint disable no method argument no self argument;-6.293521;3.1422625;-4.3197875;3.0200539;-2.8147461;2.170664;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
common file extensions that are not followed if they occur in links;-3.915417;0.70606357;-0.66669506;1.836804;1.6865625;2.7743397;-
archives;-2.4996178;-3.6305544;4.6462183;0.8276528;2.166908;-1.9936001;-
images;0.25060183;-3.6193693;8.883973;-1.4410268;0.945009;-0.7603151;-
audio;-1.5312738;-4.213248;5.6740723;-0.104189694;0.76831824;-2.113448;-
video;-2.3334544;-1.9342921;6.9784403;0.22784483;-0.57268256;-1.7574888;-
office suites;-3.2995672;-1.1424029;4.593622;-0.4017254;1.8264229;-1.1174289;-
other;-2.9724238;-3.8820531;4.947025;1.1824225;1.3158734;-1.3568438;-
top level imports;-1.118096;-4.777858;1.1058019;0.4576941;2.5837767;-0.10935743;CODE
from lxml src lxml html init py;-5.0126653;-1.0718298;-1.8969911;-1.8275626;-1.0970638;2.5127177;IRRE
mypy doesn t infer types for operator and also for partial;-0.6846088;1.8146651;-5.711138;-3.2936957;-1.5245082;-0.16302784;CODE
hacky way to get the underlying lxml parsed document;-3.3426738;0.119692445;-0.92561346;0.9903523;3.0298872;2.3071692;IRRE
pseudo lxml html htmlelement make links absolute base url;-3.2947223;1.6134565;1.2093683;-0.7486574;0.6445314;4.7905593;CODE
continue skipping bogus links;-3.1791704;3.0277264;0.5457343;3.4393907;-1.1265256;1.2934698;CODE
to fix relative links after process value;-3.9603975;3.0567966;1.484028;1.5722495;-1.101776;3.5080233;IRRE
working around https github com sphinx doc sphinx issues 10400;-5.531756;-1.3758801;-4.1094484;-0.22186396;-3.3667643;-0.20079987;CODE
from scrapy import request spider noqa tc001;-6.953017;-1.0549233;-2.4782808;-1.9098753;-1.4925541;-0.0876832;CODE
from scrapy http import response noqa tc001;-5.858688;-0.2230183;-2.85757;-1.0509359;-3.1294868;-0.95557314;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
imports twisted internet reactor;-4.4954224;-2.8847268;-0.36086637;-0.9347297;-1.6870046;0.85157245;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
defined in the email utils module but undocumented;-6.2973213;-1.3699144;-2.996613;1.3068783;1.5674555;-0.0414484;CODE
https github com python cpython blob v3 9 0 lib email utils py l42;-5.389515;-4.2431846;-3.5244656;-2.8390462;-4.1316724;-2.7297406;CODE
imports twisted internet reactor;-4.4954224;-2.8847268;-0.36086637;-0.9347297;-1.6870046;0.85157245;CODE
from twisted mail smtp import esmtpsenderfactory noqa plc0415;-3.7795022;-0.7181737;-1.9103781;-1.115738;-1.9542011;0.0033625215;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
return str path convert a path object to string;-3.1139572;1.0966934;0.6221662;0.2392511;-1.1230336;-0.27311382;CODE
m hashlib md5 noqa s324;-3.1951292;-0.646255;-1.7200928;-4.1437325;1.7374663;-1.7165133;-
elf s3 client put object type ignore attr defined;-5.580697;1.5246342;-4.491815;0.46536288;-0.078923695;2.8915489;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
uppercase attributes kept for backward compatibility with code that subclasses;-3.0662744;-0.85959595;-4.794835;2.082852;3.5004427;2.333858;CODE
imagespipeline they may be overridden by settings;-5.9074607;0.7896529;-0.4267508;0.098162025;-2.7395673;6.2168555;IRRE
from pil import image imageops noqa plc0415;-3.8721325;-0.38555554;-1.6082064;-4.0277033;-2.0704756;1.1044667;CODE
image resampling lanczos was added in pillow 9 1 0;0.00223401;-0.9453589;-2.8097003;-2.9574366;-4.182324;3.3010645;TASK
remove this try except block;-5.114311;5.9184995;0.124980025;3.1299658;-2.1960466;-2.4946413;CODE
when updating the minimum requirements for pillow;-2.1110413;0.5550143;-1.1580657;2.09551;0.49465647;2.6882386;CODE
resampling filter self image antialias type ignore attr defined;0.9275393;2.9046824;-3.3419437;-1.0744084;-1.6683606;5.350636;CODE
image guid hashlib sha1 to bytes request url hexdigest noqa s324;-5.0188713;0.8739055;-1.1592038;-3.9282694;-0.41525277;2.149228;CODE
thumb guid hashlib sha1 to bytes request url hexdigest noqa s324;-5.6641855;0.5403825;-1.4219618;-3.3904786;-0.4064667;1.2029246;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
return cached result if request was already seen;-1.7368953;5.489662;2.1951993;5.6432176;-1.3544827;1.0752615;CODE
otherwise wait for result;-1.2551808;3.3319457;2.403917;4.7234025;-0.3996564;-2.8483253;IRRE
check if request is downloading right now to avoid doing it twice;-2.9363797;3.6435397;1.6258655;6.07419;-1.0499688;1.5442332;CODE
download request checking media to download hook output first;-3.2833183;1.8233759;1.141616;4.0616565;-0.9003119;1.7993778;CODE
got a result without downloading;-2.3265135;-0.5767325;1.2108059;1.7651728;-2.7136657;-3.646474;CODE
download the result;-1.3688515;-2.9239728;2.7956877;-0.76229334;-1.6533899;-4.945762;CODE
return yield wad it must return wad at last;-1.3982322;3.7678564;1.0902436;1.5090474;-0.91961694;-3.274684;IRRE
def check media to download pylint disable inconsistent return statements;-4.6353936;2.7841504;-3.276166;4.7768736;-2.609905;-0.15118417;CODE
this ugly code was left only to support tests todo remove;-4.759063;3.7436364;-2.1601183;4.92744;-2.312699;-2.926406;CODE
minimize cached information for failure;0.47313458;2.166201;0.9354442;6.5329695;2.173735;2.4034476;CODE
result stack type ignore method assign;-0.6203349;5.0401845;-2.1612244;4.214874;0.2940279;0.48282176;IRRE
this code fixes a memory leak by avoiding to keep references to;-2.9211786;1.3997048;-2.1652231;2.9924994;0.8241347;0.5516746;CODE
the request and response objects on the media pipeline cache;-3.1726763;-3.4163392;0.9727382;4.5409026;0.8228068;3.9883828;CODE
what happens when the media downloaded callback raises an;-5.763253;-1.4091278;2.0703847;3.1707635;-1.804528;3.4820256;CODE
exception for example a fileexception download error when;-5.036488;1.6670717;-1.3693019;2.4906454;-1.3949531;-0.44830745;CODE
the response status code is not 200 ok is that the original;-5.3544464;2.894221;-0.9679892;2.2008274;-1.889077;-1.7114612;CODE
stopiteration exception which in turn contains the failed;-4.432821;5.181689;-1.3619936;4.9026513;-0.6251194;-2.9503407;CODE
response and by extension the original request gets encapsulated;-4.946369;3.3901882;0.34355262;3.8542678;0.6770159;3.3847537;CODE
within the fileexception context;-5.3698235;1.9006892;-0.82440144;3.7700553;0.26011375;0.16818924;CODE
originally scrapy was using twisted internet defer returnvalue;-6.634509;0.34508392;-2.5535145;1.2811842;-2.585546;0.5210528;CODE
inside functions decorated with twisted internet defer inlinecallbacks;-4.718626;1.3838176;0.33372197;0.5738033;-2.1399755;3.480402;CODE
encapsulating the returned response in a defgen return exception;-1.627279;4.177482;-2.4533668;4.4199104;0.85460466;1.6055228;CODE
instead of a stopiteration;-3.9621089;1.4155977;3.0875847;3.7707038;1.2550082;-1.1861962;CODE
to avoid keeping references to the response and therefore request;-4.4143887;2.0202272;2.2536182;5.867987;1.3632435;2.2223341;CODE
objects on the media pipeline cache we should wipe the context of;-4.2202272;-2.681176;0.10240208;4.6717086;1.1117696;5.4076114;CODE
the encapsulated exception when it is a stopiteration instance;-4.0373926;3.2149186;-1.405326;6.2694144;1.659471;1.1803656;CODE
info downloaded fp result cache result;-1.6294361;-0.9313022;-1.3318485;1.6496767;-2.647823;-0.6400795;IRRE
overridable interface;-5.157565;0.7008637;1.698191;1.939576;2.2301295;3.3913245;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
as we replace some letters we can get collision for different slots;-3.2439153;-0.8591715;3.759886;-1.3160619;5.2433352;-1.412575;CODE
add we add unique part;-2.2247858;0.6071863;4.7612133;-1.8157896;5.662674;0.14732094;TASK
unique slot hashlib md5 text encode utf8 hexdigest noqa s324;-4.081299;-0.18292846;-3.4801702;-4.3244753;2.207124;-0.9491756;-
elf pqueues dict str scrapypriorityqueue slot priority queue;-3.4168134;0.9436114;-2.465161;-0.21668944;1.7781376;1.0858107;-
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
todo cache misses;-3.8688834;2.2531898;0.76558656;3.5604444;-3.266724;1.5197266;TASK
in twisted 16 6 gethostbyname is always called with;-5.743761;0.40139428;-2.0268154;1.0345088;-1.7567253;1.619542;IRRE
a default timeout of 60s actually passed as 1 3 11 45 tuple;-1.5011694;1.1573802;-0.07752835;0.9345661;-1.2745584;-2.0215733;META
so the input argument above is simply overridden;-4.5216985;2.923632;-1.4012444;-0.030058082;0.44381478;-0.64954525;CODE
to enforce scrapy s dns timeout setting s value;-4.1745086;1.6397238;-1.2724234;1.381723;-1.401479;1.5258921;IRRE
the timeout arg is typed as sequence int but supports floats;-2.6064012;2.827481;-2.1794393;-1.4165641;-3.619147;-1.8022518;CODE
timeout self timeout type ignore assignment;-0.9850257;3.9451058;-2.3791559;2.7351646;-0.10840168;-1.0840315;IRRE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
if we found garbage or robots txt in an encoding other than utf 8 disregard it;-2.8161764;0.2741977;-3.0599096;0.5853198;-1.3930104;-1.8774163;-
switch to allow all state;-5.1387005;3.2197332;2.312743;1.1987691;0.67901367;2.3358374;CODE
from robotexclusionrulesparser import robotexclusionrulesparser noqa plc0415;-3.2613356;-1.0607257;-3.394513;-3.3072932;0.28810164;1.0773774;CODE
top level imports;-1.118096;-4.777858;1.1058019;0.4576941;2.5837767;-0.10935743;CODE
type str none none noqa a002;-4.491278;1.4884124;-1.428727;-4.504096;1.5861834;-4.7668824;-
the key types are restricted in basesettings get key to ones supported by json;-5.0478683;-0.063681;-3.046543;-1.5785403;-1.6925855;2.5927148;IRRE
see https github com scrapy scrapy issues 5383;-7.376959;-3.0375807;-2.5592368;-1.2526538;-2.9686902;-0.19678941;CODE
https github com python typing issues 445 issuecomment 1131458824;-6.037872;-2.98117;-5.3440375;-0.4458827;-4.254213;-3.7097242;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
download maxsize 1024 1024 1024 1024m;-1.7598577;-0.07296862;-0.32621357;-2.0708656;-1.3795316;1.9329833;CODE
download warnsize 32 1024 1024 32m;-3.761774;0.621607;-3.2791278;1.0679901;-2.8908203;-0.26741502;CODE
download timeout 180 3mins;-3.8114557;-1.2490482;2.0709112;0.74318844;-2.4649308;-0.2878694;CODE
use highest tls ssl protocol version supported by the platform also allowing negotiation;-4.403979;-0.40815738;-1.6725717;-0.69988257;-0.62404525;1.4740732;META
engine side;-4.078807;-1.9627264;5.1650057;-0.640459;1.2935731;-1.2134017;-
downloader side;-4.623352;-3.224034;3.622651;0.7680408;0.39685285;1.7514378;CODE
feed uri params none a function to extend uri arguments;-4.749975;1.9528277;-0.0983016;1.7523034;-0.46354714;4.0686545;CODE
ftp password guest noqa s105;-4.4606194;-0.8062565;-1.5031329;-2.0140595;0.14575662;-0.84355974;-
memdebug enabled false enable memory debugging;-4.4689884;0.48972774;-3.1430256;1.2754112;-2.9242713;1.2214012;-
memdebug notify send memory debugging report by mail at engine shutdown;-3.8091629;-0.53223926;-0.788088;2.623003;-1.6489503;0.6042458;CODE
redirect max times 20 uses firefox default setting;-3.271116;2.199236;1.6002887;2.7446394;-2.493938;2.572123;IRRE
oserror is raised by the httpcompression middleware when trying to;-4.5688267;0.45895305;-4.685676;2.5055118;-4.4840174;1.434865;CODE
decompress an empty response;-2.770069;4.9103775;-0.9979725;1.0742875;-1.8242283;0.5545266;CODE
retry times 2 initial response 2 retries 3 requests;-2.9240353;3.3894503;0.9182449;3.2551363;-1.941898;-0.4249601;CODE
engine side;-4.078807;-1.962728;5.165006;-0.6404575;1.293573;-1.213402;-
spider side;-4.4249644;-0.72738636;5.7172027;-0.30310315;0.20517008;-0.9067763;-
import warnings noqa plc0415;-4.3457847;0.76258475;-5.458192;-1.0615542;-1.3081405;-1.8196672;CODE
from scrapy exceptions import scrapydeprecationwarning noqa plc0415;-6.095716;0.5308734;-5.7779202;0.26258314;-2.0741246;-0.036427952;CODE
disable accidental ctrl c key press from shutting down the engine;-4.2530465;0.39544123;0.2496464;0.67894286;-0.86341166;1.768338;CODE
pylint disable next eval used;-5.388481;3.78158;-2.8996437;2.9515748;-1.7544254;1.9480915;CODE
print eval self code globals self vars noqa s307;-3.940566;1.3970649;-2.908332;-1.120551;0.45022997;-2.567988;CODE
detect interactive shell setting in scrapy cfg;-5.0834494;-0.5002698;-0.8145429;1.8863283;-1.4350959;0.70647496;CODE
e g config scrapy cfg or scrapy cfg;-5.2047625;-5.13495;0.103557386;-0.059933838;0.6104508;0.98262024;-
settings;-4.234039;-1.868197;6.9948034;0.26338285;-1.224498;1.7592815;IRRE
shell can be one of ipython bpython or python;-4.337201;-3.9711392;-0.09267727;-2.0035324;-3.3210695;-2.3205104;CODE
to be used as the interactive python console if available;-5.1392193;-2.8147564;1.3878304;0.90164155;-3.4741151;-2.1623564;CODE
default is ipython fallbacks in the order listed above;-4.4898243;-0.921609;-1.8290355;-0.0158537;-2.3188572;0.79980105;CODE
shell python;-3.279877;-3.757542;2.1915128;-2.0574315;-4.092285;-5.093759;CODE
else try all by default;-3.8240645;3.142693;-0.099008866;3.8452232;-1.7445009;-0.7774852;CODE
always add standard shell as fallback;-5.1744957;1.9778086;-0.65874773;2.4541783;-0.7629917;4.2924643;TASK
set the asyncio event loop for the current thread;-2.3953798;0.17754243;2.0343091;3.3585422;-3.1659865;2.638782;IRRE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
def init pylint disable super init not called;-6.3725667;2.1565583;-2.8515553;2.5862818;-3.1680334;2.530342;IRRE
base case depth 0;-2.2344046;2.2592318;1.1765432;-4.6528015;1.8174329;0.06936513;CODE
start requests;-5.59694;-0.13271235;5.8418937;3.462826;-0.53727686;0.020586208;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
https www w3 org tr referrer policy strip url;-4.584466;0.8081201;0.5104092;-0.7301947;-1.4476414;1.8189539;CODE
note this does not follow https w3c github io webappsec secure contexts is url trustworthy;-5.691086;-2.8921254;-2.1156707;1.2532251;-1.4801812;2.097869;CODE
reference https www w3 org tr referrer policy referrer policy empty string;-5.1095295;2.1250846;-2.282863;-0.94061923;-1.4735268;0.96635365;CODE
https www w3 org tr referrer policy parse referrer policy from header;-4.3040123;0.82247674;-0.8118699;-0.36630836;-0.16380581;1.8167862;CODE
def init self settings basesettings none none pylint disable super init not called;-5.710786;1.1481713;-1.9022754;2.327748;-3.0703814;3.1780825;IRRE
note this hook is a bit of a hack to intercept redirections;-5.0911975;2.2473733;1.9689497;4.3701053;-2.4120345;1.6979201;CODE
start requests;-5.59694;-0.13271235;5.8418937;3.462826;-0.53727686;0.020586208;CODE
check redirected request to patch referer header if necessary;-4.713251;2.2853508;-1.7607247;4.3466363;-0.5912958;1.522891;CODE
we don t patch the referrer value if there is none;-4.553408;1.5372005;-1.7569159;2.9485264;-0.07212735;2.9866295;IRRE
the request s referrer header value acts as a surrogate;-4.058052;0.6980396;-1.0684391;1.682397;0.846892;3.5855334;CODE
for the parent response url;-5.174157;-0.5400066;5.585763;1.3726437;0.40785408;1.3312762;CODE
note if the 3xx response contained a referrer policy header;-5.602358;2.3336911;-1.7465125;1.261301;0.29298225;1.7992784;CODE
the information is not available using this hook;-4.544837;1.3876743;0.9961446;1.5701785;-1.3731065;0.43133748;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
def init self maxlength int pylint disable super init not called;-4.93594;3.0228336;-2.6025386;0.47797614;-2.8157427;1.4387697;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
start urls see meth start;-2.8118806;-1.3126574;4.420293;0.46640202;-1.8649677;1.223034;-
circular import;-1.2639219;-1.1371967;2.3101718;-1.7522137;0.075745516;-0.33959985;CODE
from scrapy utils log import spiderloggeradapter noqa plc0415;-6.0197477;-1.7058451;-2.4407594;-0.82751644;-1.1845223;-0.5192435;CODE
top level imports;-1.118096;-4.777858;1.1058019;0.4576941;2.5837767;-0.10935743;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
this replaces method names with methods and we can t express this in type hints;-3.8253856;0.43948638;-0.8571158;2.370728;1.253624;-0.3936084;CODE
rule self rules cast int failure request meta rule type ignore attr defined;-3.993717;4.7455435;-5.6995764;2.253122;0.7811244;1.7826521;CODE
iterable is needed at the run time for the sitemapspider parse sitemap annotation;-2.3534243;-0.7066545;-2.1792345;2.6350605;2.3254044;2.435705;CODE
from collections abc import asynciterator iterable sequence noqa tc003;-1.0916078;1.3320799;-2.6953514;0.3445059;1.5399187;-1.198557;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
actual gzipped sitemap files are decompressed above;-2.815109;0.9400737;-2.4691463;-1.4105263;-1.309501;3.2147164;-
if we are here response body is not gzipped;-5.2929683;0.66272557;0.8330173;1.3138655;-1.5469781;0.025856033;CODE
and have a response for xml gz;-4.6196775;-1.5742012;2.7976048;1.4693162;2.4895213;0.6503858;CODE
it usually means that it was already gunzipped;-4.5644894;-0.06763924;0.19570932;1.4337136;0.47756213;1.294921;CODE
by httpcompression middleware;-4.3702273;-2.8777597;1.4393264;1.3925146;-0.07706811;2.6564546;CODE
the http response being sent with content encoding gzip;-3.9323628;0.7074411;-0.90481657;-0.85772216;-2.249719;1.002767;CODE
without actually being a xml gz file in the first place;-3.1453946;-1.3412616;1.3912698;-0.5937456;2.572914;3.77181;META
merely xml gzip compressed on the fly;-2.4062595;-0.9060789;0.15580958;-0.26028007;1.2032102;2.254333;CODE
in other word here we have plain xml;-5.0698814;-1.444448;1.2393451;-1.9836632;4.005435;0.9976624;-
also consider alternate urls xhtml link rel alternate;-4.810004;0.35688245;3.081195;0.889636;1.3171387;4.217813;-
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
class directoriescreated queue class type ignore valid type misc;-1.5361686;2.3584397;-5.074089;2.5150726;2.5416105;1.481062;IRRE
class serializablequeue queue class type ignore valid type misc;-1.6764823;2.6939836;-5.0802326;2.415514;2.7755926;3.3214629;IRRE
class scrapyrequestqueue queue class type ignore valid type misc;-3.2339113;2.4628532;-4.4318757;2.954444;1.9918374;1.7044705;CODE
class scrapyrequestqueue queue class type ignore valid type misc;-3.2339113;2.4628532;-4.4318757;2.954444;1.9918374;1.7044705;CODE
both pickle picklingerror and attributeerror can be raised by pickle dump s;-0.8418631;0.36539087;-5.872133;2.9087288;-1.4028691;-1.0959496;IRRE
typeerror is raised from parsel selector;-2.6594505;2.1099951;-3.8503711;1.2713246;-1.784526;-1.3271668;CODE
queue queue aren t subclasses of queue basequeue;-2.1456134;0.07745228;-0.8106827;1.3787397;3.3957171;2.983345;IRRE
with mkdir queue fifodiskqueue type ignore arg type;-2.7244585;1.9899263;-3.430711;1.8588237;1.2297184;2.2850971;-
with mkdir queue lifodiskqueue type ignore arg type;-3.3929977;1.6047194;-3.5752225;1.6637986;1.8425093;2.5939078;-
with mkdir queue fifodiskqueue type ignore arg type;-2.7244575;1.989927;-3.4307096;1.8588233;1.229718;2.2850978;-
with mkdir queue lifodiskqueue type ignore arg type;-3.3929977;1.6047194;-3.5752225;1.6637986;1.8425093;2.5939078;-
public queue classes;-2.4793198;-2.1369138;2.5864222;2.3948803;4.609908;1.737337;CODE
fifomemoryqueue scrapy non serialization queue queue fifomemoryqueue type ignore arg type;-3.1555543;2.500448;-4.9331245;2.293252;-0.27289015;3.7230453;-
lifomemoryqueue scrapy non serialization queue queue lifomemoryqueue type ignore arg type;-3.9713247;2.1875317;-4.741522;2.3681772;0.4781545;4.1325088;-
this package will contain the spiders of your scrapy project;-4.8874054;-4.462675;0.60752064;0.37093216;0.7382586;-0.80559355;CODE
please refer to the documentation for information on how to create and manage;-4.700383;-4.9304147;4.2460546;-1.4655186;3.5520895;2.8307443;CODE
your spiders;-3.1277351;-0.87944293;4.590704;0.5026131;0.81569535;-2.0547705;-
chunk size 65536 64 kib;-0.38757437;-0.06796845;-0.035626985;-3.513326;0.7234332;-0.87976927;-
to work with raw deflate content that may be sent by microsoft servers;-1.6154455;-0.6947369;-0.17223218;0.23960721;-0.3877705;3.58741;CODE
nlist random randint 1 total for in range show noqa s311;2.6586082;1.3386846;-0.98796827;-2.6937141;1.0009207;-4.13407;IRRE
feeds setting should take precedence over the matching cli options;-2.657749;0.1507184;-3.4448638;1.7723504;0.09365167;5.2966523;IRRE
import bpython noqa plc0415;-4.4949903;-1.4521244;-4.1523867;-4.1389213;-2.7202308;-1.6479228;CODE
try readline module is only available on unix systems;-5.3686523;-0.61436564;-3.7098677;-1.4600978;-3.6730783;-1.8984278;CODE
import readline noqa plc0415;-4.646829;0.26479575;-3.8348162;-4.3984866;-1.2041608;-1.569492;CODE
import rlcompleter noqa f401 plc0415;-3.9052103;-0.102566384;-3.3937924;-3.295313;-0.59049577;-0.0028580278;CODE
readline parse and bind tab complete type ignore attr defined;-3.7924893;3.8761923;-2.9445498;0.7219816;0.27066973;2.2028751;CODE
if shells is none list preference order of shells;-1.4346302;3.652066;0.11504415;0.1607468;2.065084;0.14290859;CODE
if known shells is none available embeddable shells;-3.573812;-0.022151893;-1.1737283;-0.32313645;0.3845779;1.324629;CODE
function test run all setup code imports;-1.6216999;3.1827934;-2.7861536;3.4295297;-1.8052686;-3.2615604;CODE
but dont fall into the shell;-3.7257998;0.50723726;2.8015473;1.9848897;-1.6784977;-1.0117098;CODE
except systemexit raised when using exit in python code interact;-5.0003624;2.7657766;-2.846905;2.835051;-3.8902993;-1.5587014;CODE
compressed argument is not safe to ignore but it s included here;-2.3116872;2.3017807;-4.6108623;0.8233404;0.114917375;1.2513801;CODE
because the httpcompressionmiddleware is enabled by default;-6.9429164;-1.3302729;-2.0447161;1.8846225;-3.010142;3.3532577;CODE
progress bar;-1.6301398;-1.0926994;6.592863;-0.3655231;-1.232862;-0.28169957;IRRE
curl can treat this parameter as either key value key2 value2 pairs or a filename;-2.7446012;1.1882211;-0.8986055;-2.540546;2.0318491;0.8941778;IRRE
scrapy will only support key value pairs;-4.267411;-0.3428854;-3.9380589;-1.9453162;-0.32521215;-0.6782911;IRRE
curl automatically prepends http if the scheme is missing but request;-3.8687701;2.635032;-0.97902936;3.2766752;-2.8338263;1.9627057;CODE
needs the scheme to work;-2.123522;-0.16195418;3.5370529;2.0405178;1.6643778;-0.8430624;TASK
if the data is specified but the method is not specified;0.74983793;6.061586;-1.0802501;3.338988;0.74221206;-3.1922164;META
the default method is post;-5.9099736;0.571501;3.0003793;3.2419271;-1.0602418;1.2226983;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
circular import;-1.2639219;-1.1371967;2.3101718;-1.7522137;0.075745516;-0.33959985;CODE
from scrapy http headers import headers noqa plc0415;-6.94261;-1.7837918;-2.2935107;-2.5564394;-1.3032137;0.17902115;CODE
def contains self key anystr bool type ignore override;-4.6839347;3.4348094;-6.16814;1.7854177;0.37738448;-0.13420185;CODE
return dict setdefault self self normkey key self normvalue def val type ignore arg type;-0.06831832;2.2532077;-4.8737392;-1.6011233;-1.8007612;1.4541065;CODE
doesn t fully implement mutablemapping update;-1.7029474;0.5202737;-1.9396902;1.9220573;-1.4513191;3.3896046;CODE
def update self seq mapping anystr any iterable tuple anystr any none type ignore override;-2.1056511;2.2611783;-4.4839163;0.8135195;1.4096427;-0.8555789;CODE
def fromkeys cls keys iterable anystr value any none self type ignore override;-2.8610885;1.4911746;-4.632393;0.15004286;0.26595688;-1.1374782;CODE
return cls k value for k in keys type ignore misc;1.2365768;3.2543414;-3.639116;-2.2012494;0.27744815;-2.2439048;IRRE
def contains self key anystr bool type ignore override;-4.6839347;3.4348094;-6.16814;1.7854177;0.37738448;-0.13420185;CODE
if raised key is not weak referenceable skip caching;-1.724541;3.1194513;-2.6752524;4.5662274;0.9878525;3.9932134;CODE
def getitem self key kt vt none type ignore override;-3.5777504;0.8045152;-2.9870794;0.8625687;-1.3612612;1.4614576;CODE
return none key is either not weak referenceable or not cached;-4.02669;4.128922;-4.302083;2.9765453;-0.09676797;0.7041968;CODE
callable callable concatenate t p t2 noqa a002;-3.8722763;3.4564083;-0.14003469;-3.2901106;1.7652512;-0.75161886;IRRE
this gets called when the result from aiterator anext is available;-3.8253944;1.4994437;0.54190975;5.0875573;0.8417567;0.4488864;IRRE
it calls the callable on it and sends the result to the oldest waiting deferred;-4.308655;0.76621336;2.517194;4.3946166;1.6935441;0.9795262;IRRE
by chaining if the result is a deferred too or by firing if not;-1.5978268;4.880817;1.2472999;5.3083777;1.3860692;0.773953;IRRE
this gets called on any exceptions in aiterator anext;-5.6898904;3.2018523;-1.5481832;5.507194;0.3759273;0.9981763;CODE
it handles stopasynciteration by stopping the iteration and reraises all others;-0.25492042;0.26150507;2.9353411;4.8710465;0.5874799;2.2143438;CODE
this starts waiting for the next result from aiterator;-2.7588198;1.0241027;1.8851625;4.080537;-1.2429066;-0.73644304;CODE
if aiterator is exhausted errback will be called;-3.3819134;0.21779458;1.4398316;5.534707;-0.3958426;1.6909037;IRRE
this puts a new deferred into self waiting deferreds and returns it;-4.4782553;2.4598687;0.9017109;4.6561923;0.9107652;1.3283795;CODE
it also calls anext if needed;-5.9187193;-0.5135857;1.2270819;2.3598428;0.89553815;0.56650805;IRRE
callable callable concatenate t p deferred any none noqa a002;-4.4626136;5.30371;-1.0880306;-0.7662983;1.32325;-0.42188284;IRRE
input t noqa a002;-1.7138624;1.996455;1.9778765;-5.7115335;-0.03944471;-4.926745;CODE
deferred list t2 pragma no cover;-3.492134;2.2211404;-1.4365331;3.2060337;0.44294167;1.3045619;CODE
wrapping the coroutine directly into a deferred this doesn t work correctly with coroutines;-3.354212;3.1661398;-0.75175345;2.4428644;-2.452168;3.0362062;CODE
that use asyncio e g await asyncio sleep 1;-3.2596996;-3.534187;0.8940774;2.3495502;-2.0345278;0.9026312;-
wrapping the coroutine into a future and then into a deferred this requires asyncioselectorreactor;-2.2923965;0.8018036;-0.96867454;4.331416;-1.9490271;4.357105;CODE
https stackoverflow com a 36760881;-4.8960357;-0.81423306;2.272833;-2.265532;-1.5183504;-2.4238954;CODE
kernel32 ctypes windll kernel32 type ignore attr defined;-3.2486274;0.13214035;-8.302913;-1.5591913;-0.5078157;2.59192;CODE
windows 10 0 14393 interprets ansi escape sequences providing terminal;-6.2905073;0.6814927;-3.5108461;-2.5153236;-1.4956138;-0.00031124067;CODE
processing is enabled;-5.2097483;-0.78752273;1.7571777;1.9322596;-1.949955;0.7036886;-
pylint disable no name in module;-7.2539215;1.6542691;-3.9723098;1.0134834;-2.0538905;2.25156;CODE
from pygments import highlight noqa plc0415;-3.7830777;-1.4647996;-3.8828328;-4.737025;-2.5467262;-0.090330705;CODE
from pygments formatters import terminalformatter noqa plc0415;-3.2678988;-1.4373543;-4.540736;-5.669166;-3.135215;0.37594804;CODE
from pygments lexers import pythonlexer noqa plc0415;-5.0796328;-2.5339024;-5.3830733;-4.703877;-2.2118702;-0.058734953;CODE
checks test eval test noqa s307 pylint disable eval used;-4.1985455;5.1151714;-7.0883174;2.9864907;-1.5931597;-2.2420688;IRRE
complete only if there is some data otherwise re raise;1.9612632;3.035186;2.2803023;3.7186024;1.8077266;-0.17815067;CODE
see issue 87 about catching struct error;-4.66964;5.0416455;-4.3210073;1.3662535;-1.1480674;-2.6132393;CODE
some pages are quite small so output stream is empty;-3.3486714;1.813037;0.51279074;0.40054357;-3.021746;0.8927679;IRRE
instance objcls from crawler crawler args kwargs type ignore attr defined;-3.4624407;0.77926654;-6.1344733;1.7396797;-0.984456;2.71561;IRRE
def is generator with return value callable callable any bool noqa a002;-3.1125042;3.8810666;-2.27413;0.11067471;1.5902232;-4.1995096;IRRE
match pattern match src finds indentation;-2.438513;2.1982284;-1.5664861;-0.567375;1.5447651;-0.724638;-
code re sub f n match group 0 n code remove indentation;-1.9987035;2.7237651;-0.06284303;-3.9055333;1.7998941;-3.9373257;-
callable callable any noqa a002;-4.2523885;1.2470478;1.0955812;-1.1491557;1.8054379;-1.2713296;IRRE
https docs python org 3 reference simple stmts html the return statement;-6.004694;0.038200628;-2.4976373;-0.5583947;-2.489353;-2.9634116;CODE
copy of handler from typeshed stdlib signal pyi;-5.0759916;-0.18701597;-2.5291898;1.0898751;-1.4824427;4.0781565;CODE
ignal getsignal signal sigint pylint disable comparison with callable;-2.6444914;3.213677;-3.323814;2.6250408;-1.9430709;2.7322333;CODE
catch ctrl break in windows;-3.4070327;0.8905204;1.5345873;2.9255984;-2.2676458;0.29765865;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
elif hasattr func call noqa b004;-4.1652956;1.1458937;-2.4336226;-0.21040228;-0.059878718;-2.5779645;IRRE
the iterable init must take another iterable;-3.494726;2.7656245;-1.1523546;1.6323966;0.20161846;-0.24917679;IRRE
return type iterable v for v in iterable if v is not none type ignore call arg;-0.71010697;4.627398;-2.3079393;1.2374213;-0.13810003;-1.4456438;IRRE
collecting weakreferences can take two collections on pypy;0.36751616;-0.299516;-3.2406995;3.5082796;1.9917655;2.691409;CODE
def listen tcp portrange list int host str factory serverfactory port type ignore return pylint disable inconsistent return statements noqa ret503;-3.2577527;2.7253382;-3.571922;0.8993948;-0.49192387;-1.6231618;CODE
in python 3 10 9 3 11 1 3 12 and 3 13 a deprecationwarning;-0.3681426;-0.20216943;-1.896218;-2.1421993;-1.3909756;-4.5109854;CODE
is emitted about the lack of a current event loop because in;-2.914811;1.4527969;1.9589082;4.2776337;-0.16638318;-0.56184375;IRRE
python 3 14 and later get event loop will raise a;-3.4875042;1.1434457;1.2037294;1.6812277;-3.7787101;-2.3514495;CODE
runtimeerror in that event because our code is already;-4.0668383;2.6913397;-1.8241137;5.7057786;-2.6001623;-2.1004806;CODE
prepared for that future behavior we ignore the deprecation;-2.934522;0.2217314;0.33550984;7.2004194;-0.076410465;1.1246382;TASK
warning;-3.0231862;-0.29702285;2.0558126;3.4345493;-1.4731644;-1.9746032;-
get event loop raises runtimeerror when called with no asyncio;-2.697344;1.889303;-2.5827258;4.564282;-5.05602;0.69043833;IRRE
event loop yet installed in the following scenarios;-3.3945472;1.0390676;3.5810788;4.5820394;0.87828547;-0.7189906;TASK
previsibly on python 3 14 and later;-3.6638756;-4.1000524;-1.413572;0.7563127;-2.1607711;-2.2016788;CODE
https github com python cpython issues 100160 issuecomment 1345581902;-4.910359;-2.6755831;-5.557414;-1.1615114;-7.259533;-2.9046378;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
to decode bytes reliably json does not support bytes regardless of;-2.1903574;1.5102817;-4.598861;-0.30165535;-2.6934762;1.655528;CODE
character encoding we use bytes hex;-2.7848597;-0.3317471;-0.162633;-5.4619565;0.83210814;0.035971627;CODE
cache cache key hashlib sha1 noqa s324;-3.7426841;0.12040029;-2.536556;-2.0386295;-0.36202663;1.2101171;-
https stackoverflow com questions 60222982;-5.000986;-0.7329386;1.4349045;-1.9942123;-1.3345773;-2.0833964;CODE
def iterate spider output result asyncgenerator t asyncgenerator t type ignore overload overlap;-0.2176029;2.0525885;-2.54429;2.075106;0.32578057;2.4798276;CODE
from openssl crypto x509name repr;-5.336469;-1.9123942;-2.6788056;-2.7032824;0.7110252;-0.8347024;CODE
adapted from openssl apps s cb c ssl print tmp key;-4.2546015;-1.8101313;-1.4676925;-4.1865687;-0.11679276;-1.1239355;CODE
removed in cryptography 40 0 0;-5.403376;0.7942441;-2.112494;-2.8729615;-0.6375603;-1.681357;OUTD
from google cloud import storage noqa plc0415;-3.6591225;-0.1648631;-1.698305;-3.0925465;-0.025474276;0.44758946;CODE
acl list blob acl loads acl before it will be deleted;-3.7477672;1.6080258;-1.5465449;1.1094412;0.3917378;1.1450356;CODE
when needed useful settings can be added here e g ones that prevent;-4.9511647;-2.09832;1.9944097;4.400219;-0.53380966;4.56997;TASK
deprecation warnings;-2.7911453;1.4939483;-3.2201614;5.6616435;-1.8092849;-0.93375295;-
from google cloud storage import blob bucket client noqa plc0415;-3.347583;-0.68505156;-2.419116;-3.580586;-0.66010004;0.426831;CODE
cwd os getcwd trial chdirs to temp dir noqa pth109;-4.0005875;-1.0954028;-2.1598291;-1.2445742;0.32758194;-1.7579838;CODE
from twisted internet import reactor pylint disable ungrouped imports;-5.3597565;-0.018286994;-3.7368662;1.2055357;-1.9275564;3.1863165;CODE
typing self requires python 3 11;-6.587663;-2.8557603;-3.781317;-1.0482798;-2.514468;-2.8600297;CODE
escape ajax www example com ajax html key value;-4.0491366;2.3297334;1.2943813;-2.3115277;-1.5770414;0.6885202;IRRE
escape ajax www example com ajax html k1 v1 k2 v2 key value;-4.3341417;2.0029705;0.89257187;-3.2692428;-0.6357383;0.32996607;IRRE
escape ajax www example com ajax html key value;-4.0491366;2.3297334;1.2943813;-2.3115277;-1.5770414;0.6885202;IRRE
escape ajax www example com ajax html;-4.0640945;1.6018387;2.650741;-1.1461356;-2.0764577;0.97240907;-
escape ajax www example com ajax html key value;-4.0491366;2.3297334;1.2943813;-2.3115277;-1.5770414;0.6885202;IRRE
www example com ajax html key value;-3.9580514;1.7599276;2.420749;-3.080352;-0.90063405;-0.24404272;IRRE
escape ajax www example com ajax html;-4.0640945;1.6018387;2.650741;-1.1461356;-2.0764577;0.97240907;-
www example com ajax html;-3.9432623;0.3301411;4.953097;-1.4706392;-1.5137835;0.61021644;-
from twisted internet import reactor noqa f401 tid253;-4.762231;-1.8190813;-2.1961884;-2.904895;-1.7631335;-0.037176028;CODE
logging exception crawl task failed noqa log015;-4.195304;1.4230188;-3.5563407;1.1962692;-3.0407178;0.023604318;CODE
from twisted internet import reactor noqa f401 tid253;-4.762231;-1.8190813;-2.1961884;-2.904895;-1.7631335;-0.037176028;CODE
from twisted internet import reactor noqa f401 tid253;-4.762231;-1.8190813;-2.1961884;-2.904895;-1.7631335;-0.037176028;CODE
from scrapy utils reactor import install reactor noqa e402;-5.274206;-2.1012013;-2.4959707;-2.1003256;-1.776792;-0.82883525;CODE
from twisted internet import reactor noqa e402 tid253;-4.992893;-1.8605698;-1.9402478;-2.7353735;-1.651794;0.029611662;CODE
ruff noqa e402;-3.5972726;0.051055353;0.8350689;-3.2117414;2.0107784;-1.0135889;-
https stackoverflow com a 32784190;-5.02949;-0.37081456;2.2663333;-2.5514927;-1.1960874;-2.608626;CODE
ignore system wide proxies for tests;-1.0572486;2.5096219;-2.349097;5.8408837;-2.0463955;1.4817867;CODE
which would send requests to a totally unsuspecting server;-4.4227757;-0.56020766;4.1201053;3.9795437;-1.2280109;0.76607096;CODE
e g because urllib does not fully understand the proxy spec;-4.975093;-4.013837;-0.8048534;4.5029683;-1.2382609;0.013457075;CODE
in some environments accessing a non existing host doesn t raise an;-4.0985465;1.5307939;-1.7036786;2.681407;-1.7344406;0.7496913;CODE
error in such cases we re going to skip tests which rely on it;-0.94234765;5.016859;-2.9043086;8.416241;-0.8137767;-4.1693854;IRRE
https cryptography io en latest x509 tutorial creating a self signed certificate;-4.7590303;-1.9465798;-0.95873225;-2.0019612;-0.036285605;-0.998516;CODE
def open file flag r mode 0o666 noqa a001;-5.2475114;2.0654385;-2.109705;-2.8485837;-1.5147529;-1.8481455;CODE
return same instance for same file argument;-1.6753426;4.6313243;1.0456856;3.1515021;1.4981656;0.74361205;CODE
we have to force a disconnection for http 1 1 clients otherwise;-2.4556444;1.781689;2.1718647;2.4419417;-0.8955503;4.1622567;CODE
client keeps the connection open waiting for more data;-1.6302369;1.4914824;3.1522017;1.2928602;-2.8435009;1.4664897;CODE
most of the following resources are copied from twisted web test test webclient;-3.9509492;-3.079409;-1.1627244;2.6371052;-1.0204623;-1.616221;IRRE
silence cancellederror;-3.8487236;1.7924237;-2.3527122;1.7798511;-4.401565;-1.240645;-
else order desc;-2.7395844;2.0230906;2.1954076;-0.48840636;3.1693432;-2.2569876;-
send headers now and delay body;-5.426548;1.7978975;3.4828246;2.691976;-0.5058877;1.9812636;CODE
we force the body content otherwise twisted redirectto;-5.7618837;2.3013756;2.8780506;4.00864;-1.5495341;3.4986172;IRRE
returns html with meta http equiv refresh;-4.7882433;2.0970254;2.7656746;2.6775367;-3.0342562;2.5895953;CODE
disable terminating chunk on finish;-3.9047034;3.2885988;0.2401563;2.8711033;-1.2810076;1.77475;TASK
this is only used by tests test downloader handlers http base testhttpproxybase;-5.6235466;1.7115481;-1.9478561;4.108326;-0.6406398;0.6261975;CODE
this is only used by tests test downloader handlers http base testsimplehttpsbase;-5.079952;1.7226706;-2.5917685;5.3167424;-0.9861899;-1.2714239;CODE
disabling tls1 3 because it unconditionally enables some strong ciphers;-4.0426264;2.6710196;-2.8596504;0.61253244;-0.6183906;1.6439759;-
1st response is fast;-1.6305835;1.4703441;4.074785;3.008945;-0.91351926;-2.0415602;CODE
2nd response is slow;-1.5909823;2.8531418;2.7342992;3.5965507;-2.697126;-0.36265898;CODE
elf pages crawled 1 account for the start url;-4.893402;-1.7495493;-0.23453492;0.50345266;-1.3826215;1.0593785;CODE
retry http codes no need to retry;-3.704489;2.3456442;0.15366468;3.5365095;-1.2550784;0.63992167;CODE
get three addons with different settings;-3.9422505;1.6981887;2.6471598;-0.88651043;3.1382344;2.6744978;TASK
test for every possible ordering;2.5039175;4.903368;1.8297487;2.4590697;3.1448705;-6.659923;IRRE
key 15 priority addon;-5.4266033;0.053702675;1.48471;-0.16868867;2.2309268;0.97874963;TASK
key 20 priority project;-2.8671207;-2.5149443;1.9747444;1.3120645;2.583433;0.22659764;-
xxx there s gotta be a smarter way to do this;-1.6287806;0.35832542;5.034166;-3.0343897;1.1247433;0.87253624;CODE
an unhandled exception in a pipeline should not stop the crawl;-4.2091208;2.3275707;-3.0563881;5.176988;-2.574789;0.6867702;CODE
out out replace r required on win32;-3.7542903;2.3728614;-2.8337955;-1.6018955;0.19857398;-0.044140026;CODE
assert re search r scraped items r n out;0.16707228;4.159;-1.3756424;1.3859411;0.23581281;-4.5402694;CODE
assert re search r scraped items r n out;0.16707228;4.159;-1.3756424;1.3859411;0.23581281;-4.5402694;CODE
see https github com scrapy scrapy issues 2811;-7.1511974;-2.9782398;-2.6251497;-0.828972;-3.1452794;-0.076086864;CODE
the spider below should not be able to connect to localhost 12345;-5.95555;0.49661112;0.99273837;-0.86719614;-1.9114451;0.70112365;CODE
which is intended;-3.9810734;-2.1837475;2.8790417;4.2658777;3.0100029;1.2877423;CODE
but this should not be because of dns lookup error;-2.909034;3.6413238;-2.199475;0.11054379;-0.75993353;-0.17526613;META
assumption localhost will resolve in all cases true;-3.8495686;3.8234856;-1.2297008;4.396287;-1.2774768;1.9829265;CODE
https github com python typeshed issues 14915;-5.5084434;-3.4380782;-5.0385976;-0.12685728;-5.7355256;-3.1021776;CODE
with no dir argument creates the project in the self project name subdir of cwd;-5.1263065;-0.96326226;-2.7369351;0.31555402;-1.4578382;0.80781865;IRRE
with a dir arg creates the project in the specified dir;-4.800784;-1.4305385;-0.12798458;1.0689487;-0.47297382;1.955114;IRRE
extract contracts correctly;-0.50529194;0.33063668;-1.2872379;0.5755089;2.9453254;0.2183535;-
returns request for valid method;-2.691891;5.898746;-1.2737714;4.5262465;0.46732882;-3.12369;CODE
no request for missing url;-6.0027957;0.4207592;0.88249516;0.353674;-3.4022226;0.8213592;CODE
extract contracts correctly;-0.50529194;0.33063668;-1.2872379;0.5755089;2.9453254;0.2183535;-
returns request;-4.305277;3.932061;3.602064;1.7816087;-0.9064768;-2.5238233;CODE
returns item;-2.6522796;4.687756;4.261565;1.2033721;1.568366;-2.9137545;IRRE
returns item error callback doesn t take keyword arguments;-4.769535;4.488178;-2.5394475;3.5868623;-1.9991078;0.39084125;IRRE
returns item error contract doesn t provide keyword arguments;-4.3721075;4.9064755;-4.05877;1.8650419;0.6054488;-0.14577048;CODE
extract contracts correctly;-0.50529194;0.33063668;-1.2872379;0.5755089;2.9453254;0.2183535;-
returns request;-4.305277;3.932061;3.602064;1.7816087;-0.9064768;-2.5238233;CODE
returns item;-2.6522796;4.687756;4.261565;1.2033721;1.568366;-2.9137545;IRRE
returns item;-2.6522796;4.687756;4.261565;1.2033721;1.568366;-2.9137545;IRRE
returns dict item;-2.8224013;1.765183;0.11110998;-0.51693976;-1.1405224;-3.677785;IRRE
returns request;-4.305277;3.932061;3.602064;1.7816087;-0.9064768;-2.5238233;CODE
returns fail;-1.7864381;6.8596;-1.1003047;2.3699036;-3.4359796;-6.479067;IRRE
returns dict fail;-2.3729124;2.9746473;-2.9288576;1.1625091;-3.058787;-5.527583;IRRE
scrapes item ok;-4.4452167;0.13107209;1.4562126;1.1740718;-1.8998426;-1.0943972;-
scrapes dict item ok;-3.9898784;-0.4695159;-0.573199;-0.04393172;-2.142564;-1.797837;-
scrapes item fail;-4.246108;2.4888928;-1.1444315;2.3808851;-3.1868324;-1.2321057;-
scrapes dict item fail;-3.7267194;1.1254975;-2.433587;0.9438706;-3.618108;-1.6847787;-
scrapes multiple missing fields;-2.0473487;1.1825285;-0.45934373;-0.13225974;-0.6644964;-1.106447;-
invalid regex;-4.2012386;2.8621666;-1.3504558;-0.65544736;-0.4833874;-3.733674;OUTD
invalid regex with valid contract;-3.735461;4.158769;-2.9141517;-0.15925726;0.13479267;-1.3710147;OUTD
async def start self pylint disable no self argument;-6.000083;2.0051649;-2.998038;4.1550064;-3.87002;2.5264282;CODE
https github com twisted twisted issues 8227;-5.7391167;-2.0706267;-2.0695126;-0.58931607;-3.940213;-0.37640184;CODE
d deferred bytes readbody response type ignore arg type;-1.7686718;4.2365727;-4.255126;1.4919055;-0.9976987;3.0011904;CODE
the setting is ignored;-5.789946;2.2261567;2.0392568;1.4049282;-3.7700884;4.38913;IRRE
def fetch self request spider pylint disable signature differs;-6.425774;2.3213036;-4.4748316;2.939637;-1.4681176;2.0980673;CODE
assert len crawler spider urls visited 11 10 start url;-3.9363203;2.8636565;-1.054164;2.9736767;-0.9099712;-1.4342622;CODE
ensure that the same test parameters would cause a failure if no;0.51614445;9.142783;-3.104406;7.0327616;0.8189774;-2.7101433;IRRE
download delay is set otherwise it means we are using a combination;-3.7730725;0.6386601;0.628298;2.379231;-0.6219141;2.396376;CODE
of total and delay values that are too small for the test;3.8576543;5.680635;-1.0872787;3.1827474;-1.7279494;-3.8449826;IRRE
code above to have any meaning;-5.5211;1.1143966;1.9782636;-0.8579075;3.8733714;-4.173634;-
server hangs after receiving response headers;-3.3871949;1.8396516;0.98282933;1.2773073;-3.7028937;-0.24052231;CODE
try to fetch the homepage of a nonexistent domain;-4.0471315;1.3078439;0.983494;0.3190748;-3.2341838;-0.12224662;CODE
completeness of responses without content length or transfer encoding;1.0889171;0.8830752;0.30070978;2.1815042;1.296386;0.4334833;CODE
can not be determined we treat them as valid but flagged as partial;-1.8205743;5.045526;-4.2803116;2.7936478;4.94866;0.1301143;META
connection lost after receiving data;-0.7863745;1.0133052;2.6133773;-0.6315546;-3.4543653;-0.104339406;CODE
connection lost before receiving data;-0.79801476;1.3844209;2.570642;0.34675157;-3.5759823;0.2605043;CODE
logging debug debug message noqa log015;-4.7331;1.5941987;-2.5454495;-0.5347078;-2.6417112;-1.047312;-
logging info info message noqa log015;-4.5326347;1.1776768;-0.6059057;-1.2408124;-0.49565005;-1.0047045;-
logging warning warning message noqa log015;-4.475108;2.2650099;-3.6609542;-0.21552613;-1.8430119;-1.2036825;-
logging error error message noqa log015;-4.4511805;2.3298018;-2.7520947;-1.725772;-1.8812602;-0.97232485;-
logging debug debug message noqa log015;-4.7331;1.5941987;-2.5454495;-0.5347078;-2.6417112;-1.047312;-
sending the second signal too fast often causes problems;-0.4956263;3.4032786;0.93361765;2.7460024;-2.1531286;2.0587876;CODE
the goal of this test function is to test that when a reactor is;-0.31357938;2.611831;-0.78941464;4.269641;-1.7568605;-4.240447;IRRE
installed the default one here and a different reactor is;-4.585808;-1.6414946;-0.41058183;0.77369356;-0.7345203;1.1913248;CODE
configured select here an error raises;-2.9310844;3.5215192;-1.5378491;0.87588054;-0.08831265;-0.53597635;CODE
in windows the default reactor is the select reactor so that;-3.546716;-3.056908;0.1300708;0.28357857;0.5942902;1.8834851;CODE
error does not raise;-4.0672464;5.057238;-2.184921;1.1200999;-3.689575;-2.4412837;CODE
if that ever becomes the case on more platforms i e if linux;-4.18315;-4.081638;-0.84377265;1.0586792;-2.2215247;0.6596087;CODE
also starts using the select reactor by default in a future;-3.9814763;-3.43329;-0.9518462;3.4532256;-0.1932162;1.9435862;CODE
version of twisted then we will need to rethink this test;-1.5889931;-0.6121603;-1.1425264;4.4071856;-1.4644246;-2.6383028;TASK
if the test was skipped there will be no client attribute;-2.956323;4.483316;-2.9672873;6.2225795;-1.7526547;-1.1343088;IRRE
assert type r is response class pylint disable unidiomatic typecheck;-2.3936813;4.821795;-7.308128;4.2778907;-2.462599;-1.0738552;CODE
send a request to mock resource that gzip encodes the data url parameter;-2.2928793;2.8668602;-0.6110479;2.999042;-0.9987467;1.004106;CODE
check that the content encoding header is gzip;-5.3717923;1.2035613;-3.3593633;-1.1189842;-2.1864572;-0.009597853;CODE
check that the response is still encoded;-3.5476298;5.2223516;-0.68694574;2.6927018;-2.455918;-1.3188299;TASK
by checking for the magic number that is always included at the start of a gzip encoding;-2.6959891;2.3143358;-3.2320764;-0.8431336;0.84234625;-1.1797693;CODE
see https datatracker ietf org doc html rfc1952 page 5 section 2 3 1;-2.932884;-2.3979275;-1.1833771;-2.2878535;-0.07485088;-0.47423354;CODE
check that a gzip decoding matches the data sent in the request;-1.9251606;4.0585704;-2.0728314;1.6543632;-0.8941454;-1.0200404;CODE
check that cookies are not modified;-2.5166054;2.659315;-0.021881407;2.7440891;-2.3456829;-0.12244026;-
check that cookies are not sent in the next request;-2.9829671;4.078449;1.0820086;3.579805;-2.6170213;-0.55115366;CODE
need to use self host instead of what mockserver returns;-1.6993546;3.1382487;-0.05202017;3.340713;-2.5417614;-0.9702937;CODE
above tests use a server certificate for localhost;-2.2208438;1.0877259;-2.0510464;2.0623512;-1.6154729;-1.753245;IRRE
client connection to localhost too;-2.9018447;-1.1081424;2.3913715;-0.49334046;-3.5127497;1.0923177;CODE
here we test that even if the server certificate is for another domain;-1.6730883;1.9842092;-0.227384;2.3620949;-1.2343032;-0.59998834;CODE
www example com in this case;-4.42509;-0.4242665;3.7003398;-1.190621;1.1723164;-0.64301467;CODE
the tests still pass;-0.5393505;2.2669456;-0.32688534;5.966438;-1.2377298;-5.201182;TASK
http localhost 8998 partial set content length to 1024 use download maxsize 1000 to avoid;-1.898189;1.8148841;-0.19631653;0.91327554;-0.7473929;2.77139;CODE
download it;-4.2756414;-4.975678;1.7840165;0.41677052;-1.9688888;-0.25587967;CODE
failure crawler spider meta failure type ignore attr defined;-5.0216894;3.0262196;-5.0328417;3.2296045;-0.49269894;2.9645796;CODE
failure crawler spider meta get failure type ignore attr defined;-4.88826;3.431223;-4.903769;3.5285375;-0.58657527;2.6552799;CODE
reason crawler spider meta close reason type ignore attr defined;-5.1084948;1.9039485;-4.450012;2.3157048;0.26495168;2.874013;CODE
should be a fixture but async fixtures that use futures are problematic with pytest twisted;-3.8188581;-0.17907543;-1.5670244;3.5866852;-2.3401437;2.931055;TASK
for key value in decoded items path domain;-2.0900838;1.9323108;-1.3459762;-2.1442225;3.2632825;1.2028131;CODE
merge some cookies into jar;-2.7798584;-0.7417731;2.6904867;0.6720939;0.5282107;1.4455875;CODE
test cookie header is not seted to request;-3.9488823;4.0052667;-0.3966497;2.5406404;-2.9989636;-0.8296763;IRRE
check that returned cookies are not merged back to jar;-3.2237177;3.1009703;0.13063282;3.9263792;-1.5308163;-0.5127676;IRRE
check that cookies are merged back;-3.4570713;3.0254946;1.3504251;1.355356;-1.83097;0.13865505;-
check that cookies are merged when dont merge cookies is passed as 0;-2.7820687;5.2868075;-0.7359594;0.9604425;-1.2245781;-0.34037334;CODE
merge some cookies into jar;-2.7798584;-0.7417731;2.6904867;0.6720939;0.5282107;1.4455875;CODE
embed c1 and c3 for scrapytest org foo;-4.339609;0.124736376;-1.890143;-1.2223853;-0.03427836;1.7664431;IRRE
embed c2 for scrapytest org bar;-4.7649374;-1.7532204;0.061270054;-1.8719112;-1.0783412;3.0412176;IRRE
embed nothing for scrapytest org baz;-6.673828;-0.83903545;-1.7387571;-0.76139313;-1.482889;1.6614491;IRRE
cookies from hosts with port;-2.7651296;0.3036764;2.6147845;-1.3611153;-1.8662629;-0.07870744;CODE
skip cookie retrieval for not http request;-1.8698742;3.855027;0.15400189;3.4984343;-0.6469864;2.4602337;CODE
overwrite with values from cookies request argument;-2.7551863;4.353153;1.0667845;1.0966552;-0.41021726;1.6140989;CODE
keep both;-2.1546676;0.8645264;3.0233843;1.0637764;0.55480665;-0.30324143;-
keep only cookies from cookie request header;-2.7785985;2.1473117;1.6476952;0.8999637;-0.7794675;3.3240972;CODE
keep cookies from both cookie request header and cookies keyword;-3.757036;1.6449262;0.3303155;1.1631612;1.036374;3.8188105;CODE
overwrite values from cookie request header with cookies keyword;-3.4680579;2.8146625;-0.14017698;-0.13331476;0.35203937;2.1239398;CODE
1 utf8 encoded bytes;-1.4664881;0.98492277;-0.27586657;-4.6136613;0.3298765;-1.5822328;META
2 non utf8 encoded bytes;-1.7976925;1.519013;-1.3357633;-4.753205;1.0004901;-1.3703207;META
3 string;-3.1315033;2.2836258;5.3410063;-3.928681;2.6014297;-6.0578146;CODE
1 utf8 encoded bytes;-1.4664881;0.98492277;-0.27586657;-4.6136613;0.3298765;-1.5822328;META
2 non utf8 encoded bytes;-1.7976925;1.519013;-1.3357633;-4.753205;1.0004901;-1.3703207;META
3 string;-3.1315033;2.2836258;5.3410063;-3.928681;2.6014297;-6.0578146;CODE
boolean;-0.9816488;1.0791367;3.3288553;0.2778453;2.5337746;-6.2463527;CODE
float;-1.0541303;1.0756284;5.3590784;-3.6649418;-2.2376776;-4.663955;CODE
integer;-1.9968137;2.0383642;3.629917;-3.4943144;1.239549;-6.506533;CODE
string;-2.8593917;0.9291754;5.480163;-1.709622;1.6928406;-6.498518;CODE
assert isinstance response2 htmlresponse content type header;-2.5497177;4.8712983;-3.3187983;5.128281;-0.37387142;-0.18742631;CODE
time sleep 2 wait for cache to expire;-3.4980853;1.5945297;1.3953339;1.5485474;-1.6254611;1.698187;CODE
time sleep 0 5 give the chance to expire;-2.4665506;1.1183083;1.666347;0.61605275;-1.5702915;-1.5500354;-
http responses are cached by default;-3.1953924;1.7920164;1.3363259;3.3281655;-3.0783951;2.978602;CODE
file response is not cached by default;-3.8045228;1.9806832;0.028358513;3.2117057;-4.357725;3.0669909;CODE
s3 scheme response is cached by default;-3.3761518;1.2007958;-2.024049;2.0645561;-2.5233357;3.3433993;CODE
ignore s3 scheme;-3.2210267;0.6994156;-2.029621;0.47386885;-0.2556828;3.3335614;-
test response is not cached;-2.0959833;4.7121053;-0.48414016;5.452106;-3.9030316;-1.5264773;IRRE
test response is cached;-1.9029515;4.9023037;-0.22824222;5.834231;-3.4265003;-1.5638527;IRRE
zstd raw html content size o html zstd static content size bin;-1.9192132;1.4764607;-0.8979791;-2.2929077;0.6848995;2.5283446;CODE
zstd raw html no content size o html zstd static no content size bin;-3.7633402;1.539998;-1.5730315;-1.8340485;-0.63794494;1.9406512;CODE
cat raw html zstd o html zstd streaming no content size bin;-3.3934991;0.370249;-0.97539103;-1.9496256;-0.7969092;2.208933;CODE
br 34 11 511 612;-3.1225655;-0.52224183;1.332244;-4.107507;2.3893902;-3.9962997;-
deflate 27 968 11 511 612;-1.8840947;1.3214742;0.29907867;-3.792757;-0.018555727;-2.7985985;CODE
gzip 27 988 11 511 612;-4.4513445;-1.1843667;-0.46841866;-3.9586172;-0.202055;-3.34691;-
zstd 1 096 11 511 612;-3.357745;0.46545544;0.1945213;-4.4638467;3.1484785;-3.7671525;CODE
import brotli noqa plc0415;-4.787326;-0.052904982;-2.2262537;-3.1979325;-0.14835368;-0.8766367;CODE
import zstandard noqa f401 plc0415;-4.4257574;1.1331046;-2.6041527;-4.1576285;0.17690468;0.86020666;CODE
import brotli noqa f401 plc0415;-4.2449226;0.019053737;-2.2888448;-3.1595993;-0.5559783;-0.45086545;CODE
import zstandard noqa f401 plc0415;-4.4257574;1.1331046;-2.6041527;-4.1576285;0.17690468;0.86020666;CODE
build a gzipped file here a sitemap;-3.0210865;-0.8582772;1.0527915;-1.3180861;0.36642554;1.8050454;-
build a gzipped response body containing this gzipped file;-3.4032834;1.5143485;-0.73213655;0.7536868;-0.81823844;1.3036882;CODE
response self getresponse f bomb compression id 11 511 612 b;-3.931284;0.4916648;-2.0345678;-1.0964332;-0.37972817;-2.0533016;CODE
failureexception assertionerror type ignore assignment;-0.38657698;5.8908334;-7.4045763;3.979851;-0.97817343;-2.7119505;CODE
proxy from request meta;-4.4383183;-0.29726335;3.389547;1.615031;-0.756247;3.5632584;CODE
proxy from request meta;-4.4383183;-0.29726335;3.389547;1.615031;-0.756247;3.5632584;CODE
utf 8 encoding;-2.9971101;-0.5278808;0.56508607;-2.6299143;-1.3298488;-0.9430478;-
proxy from request meta;-4.4383183;-0.29726335;3.389547;1.615031;-0.756247;3.5632584;CODE
default latin 1 encoding;-3.0901997;-0.5901733;-1.833501;-3.0875728;0.89766955;0.2010164;CODE
proxy from request meta latin 1 encoding;-4.70704;0.050531816;-0.32322967;-0.72433656;0.51344866;2.259064;CODE
proxy from meta proxy takes precedence;-3.6405804;1.9035859;0.6525246;2.5033345;-0.23316595;4.018141;CODE
var run docker sock may be used by the user for;-5.7860627;0.5913709;0.11344787;1.0880356;-2.1115818;1.2318659;CODE
no proxy value but is not parseable and should be skipped;-4.531288;4.252668;-2.9186728;2.4950314;-1.5905104;1.385527;IRRE
make sure indirectly that auth proxy is updated;-2.9902945;0.72408;-0.57158834;4.503715;-2.4482176;3.3787415;CODE
test that it redirects when dont redirect is false;-2.757119;7.190924;-0.7662558;6.3335004;-3.152745;-3.9688876;CODE
redirects to the same origin same scheme same domain same port;-2.675102;2.4413824;1.6286068;-0.018388564;-3.477791;1.5498143;CODE
keep all headers;-3.7536132;1.2596599;3.4526453;0.96432346;1.8663797;2.7447054;CODE
redirects to the same origin same scheme same domain same port;-2.675102;2.4413824;1.6286068;-0.018388564;-3.477791;1.5498143;CODE
keep all headers also when the scheme is http;-3.3025727;2.3961112;1.7655197;2.8429732;0.5399641;4.3578634;CODE
for default ports whether the port is explicit or implicit does not;-2.1759214;2.1398818;-1.2419561;0.057581965;0.4862874;0.92197835;CODE
affect the outcome it is still the same origin;-1.8428471;2.129144;3.9868176;3.0022721;0.06953601;1.6800748;TASK
for default ports whether the port is explicit or implicit does not;-2.1759214;2.1398818;-1.2419561;0.057581965;0.4862874;0.92197835;CODE
affect the outcome it is still the same origin;-1.8428471;2.129144;3.9868176;3.0022721;0.06953601;1.6800748;TASK
a port change drops the authorization header because the origin;-5.4089975;0.9326101;-0.6700543;0.15505862;-2.9244494;3.261173;IRRE
changes but keeps the cookie header because the domain remains the;-4.837289;1.9460304;2.7824576;1.6456103;-2.2438476;3.1835594;CODE
same;-2.970426;-1.5172942;2.8265855;1.9994456;-2.1783886;-0.47579575;-
a domain change drops both the authorization and the cookie header;-3.6912925;0.8985749;0.8448938;0.5898801;-2.4508893;2.9864545;CODE
a scheme upgrade http https drops the authorization header;-4.2734976;0.30735925;-1.9104279;1.8140146;-2.4957159;1.8671404;CODE
because the origin changes but keeps the cookie header because the;-6.562239;0.9344206;1.3897214;-0.435426;-2.7237606;3.6531682;IRRE
domain remains the same;-4.2796354;1.1215701;2.5080006;0.39151165;-1.1150199;0.9505686;CODE
a scheme downgrade https http drops the authorization header;-3.553393;1.226013;-1.8479702;1.4814085;-2.9612887;2.0917768;CODE
because the origin changes and the cookie header because its value;-5.801773;1.8792337;1.1824383;-0.82369846;-2.5144129;2.6100004;IRRE
cannot indicate whether the cookies were secure https only or not;-2.4306562;1.1699889;-0.91694725;-0.5275361;-3.3574076;-0.18289417;CODE
note if the cookie header is set by the cookie management;-5.863181;2.9466147;0.13417856;0.8098287;-2.178761;2.665567;TASK
middleware as recommended in the docs the dropping of cookie on;-4.483635;-0.5034847;1.4156452;2.3703988;-2.124642;2.5114212;CODE
scheme downgrade is not an issue because the cookie management;-2.9797204;2.4532783;-1.9946495;2.7503514;-1.7612972;3.4565125;IRRE
middleware will add again the cookie header to the new request if;-5.485401;2.6236644;0.838928;2.9291327;-1.8995506;3.1629748;CODE
appropriate;-3.2493393;-2.4071653;5.182203;1.4443761;0.6831737;-1.5550843;-
response without location header but with status code is 3xx should be ignored;-5.178929;5.528277;-1.3272996;1.1481376;-1.688256;1.8803011;CODE
latin1 location a o encode latin1 http historically supports latin1;-4.51099;-1.5673553;-0.28897232;-1.3710003;2.3920455;0.6710594;IRRE
utf8 location a o encode header using utf 8 encoding;-3.419922;0.2552344;-0.15874058;-2.9051235;-0.5024584;1.1597819;CODE
http https http https redirects;-2.5466683;0.3999529;1.4101225;0.13285293;-4.5053024;-0.64463675;CODE
http https data file ftp s3 foo does not redirect;-3.8906965;0.6672673;-1.7039583;-0.5045585;-3.013026;0.3178689;CODE
http https relative redirects;-2.010308;0.7926491;1.7884325;0.39244935;-3.7127717;1.138596;CODE
note we do not test data file ftp s3 schemes for the initial url;-2.741462;0.39955813;-2.829123;2.2908833;-0.042147007;0.5840168;CODE
because their download handlers cannot return a status code of 3xx;-7.180725;1.4605963;-3.1412263;1.4860693;-0.89986455;0.04263188;CODE
data file ftp s3 foo does not redirect;-4.337299;0.34736198;-1.7632726;-0.70203686;-2.19839;0.73572713;IRRE
data file ftp s3 foo relative does not redirect;-3.782253;0.36880827;-1.5533329;-0.75594145;-1.5777758;1.6609867;IRRE
dont retry 404s;-3.740009;1.6046772;1.2492304;4.7277484;-3.4248993;1.0596915;CODE
first retry;-3.843077;1.7525616;2.063402;2.8690863;-1.4646051;-2.1196306;CODE
test retry when dont retry set to false;-0.55163103;6.084991;-1.3935792;6.636045;-2.71965;-2.5241697;CODE
first retry;-3.843077;1.7525616;2.063402;2.8690863;-1.4646051;-2.1196306;CODE
first retry;-3.843077;1.7525616;2.063402;2.8690863;-1.4646051;-2.1196306;CODE
second retry;-3.524944;2.0093913;2.3404214;3.6440783;-1.1063541;-1.4257616;CODE
discard it;-5.2376094;2.1852586;2.6398635;1.8302387;-1.3067493;0.065738514;-
first retry;-3.843077;1.7525616;2.063402;2.8690863;-1.4646051;-2.1196306;CODE
second retry;-3.524944;2.0093913;2.3404214;3.6440783;-1.1063541;-1.4257616;CODE
discard it;-5.2376094;2.1852586;2.6398635;1.8302387;-1.3067493;0.065738514;-
discard it;-5.2376094;2.1852586;2.6398635;1.8302387;-1.3067493;0.065738514;-
get retry request request pylint disable missing kwoa;-5.2732363;1.8524238;-2.7666361;3.1290941;-3.7975261;3.2989388;CODE
garbage response should be discarded equal allow all;-2.033412;5.7489734;-2.7176986;4.181316;-0.10985493;0.6622101;CODE
empty response should equal allow all;-2.848516;7.0713406;-0.12072373;2.574555;-0.67087346;-1.0733836;CODE
settings user agent to none should remove the user agent;-4.4261875;1.0613663;-0.53861463;0.59996897;-1.3028578;3.3890424;IRRE
downloader slot gc loop stop prevent an unclean reactor;-3.987231;1.2467325;-0.92420095;2.119874;-2.0496635;2.772603;CODE
yield request url no dont filter true;-3.375826;2.5767543;-0.84876055;4.4973755;-2.0618784;1.2777503;CODE
response tests;0.64102525;2.647126;3.0821714;6.7601075;-0.67170984;-6.7040405;IRRE
b body bgcolor ffffff text 000000 n;-3.411429;-0.19579281;1.3907843;-5.385325;1.0496937;-3.400021;-
signal was fired multiple times;-1.7104285;2.969454;1.2889273;2.4892762;-0.90813005;-0.39215493;CODE
bytes were received in order;-1.9789401;2.3590653;0.8975648;-2.4472663;1.116947;-1.4256121;-
raise valueerror to make scheduler enqueue request fail;-3.0166943;4.2605805;-2.9235086;4.423769;-2.9358776;1.6268913;CODE
during this time the scheduler reports having requests but;-4.2714047;0.34586126;0.6720831;3.9276233;-1.2146819;2.0274596;CODE
returns none;-3.9347785;6.1661015;-0.038072385;-0.23762447;-2.2146184;-6.47438;IRRE
the scheduler request is processed;-4.969669;0.03110511;1.8298762;2.7512257;-0.13458773;1.9950787;CODE
the last start request is processed during the time until the;-4.8461895;1.770782;3.0961072;4.350538;-0.44837084;2.2165825;CODE
delayed call below proving that the start iteration can;-1.0845045;4.653602;2.4455078;3.5554633;-0.8129851;-0.8277767;IRRE
finish before a scheduler sleep without causing the;-2.6873412;1.6824346;2.0314429;3.9343977;-0.016445365;2.0827765;TASK
scheduler to finish;-2.483663;-0.35118666;4.158561;2.8673897;0.20691815;-0.89352137;TASK
econds 0 1 increase if flaky;-0.7460773;1.9669148;-0.034235783;-0.11144829;-3.816295;-1.984014;-
cls mockserver exit none none none increase if flaky;-3.3678424;4.407059;-3.0437295;6.158913;-5.0049677;-2.8575497;-
the first concurrent requests start requests are sent;-3.9731073;1.9348896;3.0431166;3.1655712;-0.96280676;1.4428624;CODE
immediately;-3.1539557;-2.0178535;6.027871;1.9000701;-0.07689248;-1.3011312;-
the first concurrent requests start requests are sent;-3.9731073;1.9348896;3.0431166;3.1655712;-0.96280676;1.4428624;CODE
immediately;-3.1539557;-2.0178535;6.027871;1.9000701;-0.07689248;-1.3011312;-
the first concurrent requests start requests are sent;-3.9731073;1.9348896;3.0431166;3.1655712;-0.96280676;1.4428624;CODE
immediately;-3.1539557;-2.0178535;6.027871;1.9000701;-0.07689248;-1.3011312;-
below priority 1 requests are sent first and requests are sent;-3.3868785;3.6226566;2.9494736;2.6412804;0.49503997;1.7828672;CODE
in lifo order;-3.644738;-0.83206254;3.206504;-0.18699685;4.209862;-1.2081892;IRRE
examples from the start requests section of the documentation about;-5.363084;-5.0932345;2.5676942;3.2019482;2.4830341;0.87605417;CODE
spiders;-2.9861472;-1.8436191;4.580721;0.63052493;1.0100107;-2.2115088;-
response seconds self seconds 2 1 increase if flaky;-1.0394366;2.5902674;1.1560667;3.8841095;-3.301285;-1.5891861;CODE
assert len data 1 signal was fired only once;2.0860713;6.998468;-3.5591762;3.9568684;-0.79065996;-3.9101686;CODE
received bytes are not the complete response the exact amount depends;-1.4989414;2.810262;-0.21220694;-0.1399654;-2.2440276;-0.8840264;CODE
on the buffer size which can vary so we only check that the amount;0.6084973;2.1644418;0.2812606;2.0329666;-1.6793762;0.24512587;CODE
of received bytes is strictly less than the full response;-0.91662776;3.7712038;-0.4731958;-0.10577339;-2.0376751;-0.06465684;CODE
def check output self noqa b027;-2.3246417;3.9517457;-3.43126;-1.0785298;-1.244681;-7.1093917;CODE
delete the item exporter object so that if it causes the output;-2.7509234;4.041975;0.040766858;2.338839;-0.8796175;1.684666;CODE
file handle to be closed which should not be the case follow up;-6.934099;2.0357275;1.2602175;1.6719003;-1.3251429;1.9598672;CODE
interactions with the output file handle will surface the issue;-4.379952;0.94045895;-2.8302085;2.310685;-3.3785257;1.3528079;IRRE
eval self output getvalue pylint disable eval used;-3.1694787;4.8168473;-4.6882486;2.0887115;-1.8444221;0.6540101;IRRE
del ie see the first del self ie in this file for context;-6.839317;1.0917436;1.907313;-0.51264745;0.3812593;2.578782;CODE
del ie see the first del self ie in this file for context;-6.839317;1.0917436;1.907313;-0.51264745;0.3812593;2.578782;CODE
item pop time datetime is not marshallable;-3.7009737;1.0268629;-0.84926397;1.4929136;-1.7580163;3.1014564;-
del ie see the first del self ie in this file for context;-6.839317;1.0917436;1.907313;-0.51264745;0.3812593;2.578782;CODE
del ie see the first del self ie in this file for context;-6.839317;1.0917436;1.907313;-0.51264745;0.3812593;2.578782;CODE
del ie see the first del self ie in this file for context;-6.839317;1.0917436;1.907313;-0.51264745;0.3812593;2.578782;CODE
expected w 629 8203 rd r n;-3.0288303;1.9235119;0.12172132;-3.2414868;1.2304511;-3.6085577;-
del ie see the first del self ie in this file for context;-6.839317;1.0917436;1.907313;-0.51264745;0.3812593;2.578782;CODE
del self ie see the first del self ie in this file for context;-6.2131796;0.8646872;1.5845292;-0.6407438;0.5407847;2.416453;CODE
del self ie see the first del self ie in this file for context;-6.2131796;0.8646872;1.5845292;-0.6407438;0.5407847;2.416453;CODE
del self ie see the first del self ie in this file for context;-6.2131796;0.8646872;1.5845292;-0.6407438;0.5407847;2.416453;CODE
invalid datetimes didn t consistently fail between python versions;-1.4272159;0.79655844;-6.570676;1.695824;-6.0906076;-1.2328922;OUTD
del self ie see the first del self ie in this file for context;-6.2131796;0.8646872;1.5845292;-0.6407438;0.5407847;2.416453;CODE
del self ie see the first del self ie in this file for context;-6.2131796;0.8646872;1.5845292;-0.6407438;0.5407847;2.416453;CODE
del self ie see the first del self ie in this file for context;-6.2131796;0.8646872;1.5845292;-0.6407438;0.5407847;2.416453;CODE
expected that settings for this extension loaded successfully;-5.607538;2.342265;-0.97229964;2.8216147;-2.8282213;4.9842257;CODE
and on certain conditions extension raising notconfigured;-4.465384;3.498864;-1.9369599;4.692125;2.0371432;4.300801;CODE
periodic log stats true set to enabled true;0.9480537;2.1557863;0.3440101;3.4477;-1.9645948;1.3139313;IRRE
due to typeerror exception from settings getdict;-3.6073124;0.6936154;-3.2646644;1.0360434;-3.7655814;-0.3448224;CODE
periodic log stats true set to enabled true;0.948055;2.1557863;0.3440102;3.4476995;-1.9645942;1.3139335;IRRE
due to jsondecodeerror valueerror exception from settings getdict;-2.628367;0.55040526;-3.9433334;0.245481;-4.3557663;0.93419605;CODE
the ame for periodic log delta;1.0869963;-0.06771963;1.2583741;-0.15711063;-2.197926;0.78052646;CODE
including all;-0.58637893;-2.311096;3.7832248;2.7789176;1.3298309;-0.62569904;-
include;-2.4227505;-2.510121;3.5607784;1.6659685;3.8076105;-0.7956139;CODE
include multiple;-1.9071035;-0.13430406;2.3230174;0.05660756;6.7246437;-0.31559998;CODE
exclude;-1.0560968;3.3700864;2.4876432;2.705146;2.285588;-2.0457227;-
exclude multiple;1.2330502;4.986428;1.7813535;0.4256999;4.295614;-2.3742812;-
include exclude combined;0.012734888;3.319247;0.2846796;1.47828;2.6063833;0.74154663;CODE
including all;-0.58637965;-2.3110979;3.7832248;2.778917;1.3298304;-0.62569916;-
include;-2.4227505;-2.510121;3.5607784;1.6659685;3.8076105;-0.7956139;CODE
include multiple;-1.9071035;-0.13430406;2.3230174;0.05660756;6.7246437;-0.31559998;CODE
exclude;-1.0560968;3.3700864;2.4876432;2.705146;2.285588;-2.0457227;-
exclude multiple;1.2330502;4.986428;1.7813535;0.4256999;4.295614;-2.3742812;-
include exclude combined;0.012734888;3.319247;0.2846796;1.47828;2.6063833;0.74154663;CODE
pylint disable super init not called;-6.975637;2.4318452;-2.5906923;2.593401;-3.4764335;3.5981646;IRRE
this function has some side effects we don t need for this test;-1.6178536;4.084724;-1.6891388;3.0262542;-3.2006998;-4.231819;CODE
at adjust delay none raise exception if called;-3.2744296;6.3829145;-2.4229622;5.6997;-2.3311298;2.0682428;CODE
expected adjustment without limits with these values 1 0;1.3653966;3.548711;0.7442164;-0.6191085;-3.3682897;0.10886507;IRRE
1 0 2 0 1 0 1 0 instead of 0 75;-0.28665122;2.9136515;0.26359928;-4.987711;-1.8600692;-3.5148678;CODE
from google cloud storage import blob bucket client noqa plc0415;-3.3475826;-0.6850515;-2.4191167;-3.5805848;-0.6600999;0.4268301;CODE
rfc3986 3 2 1 user information;-4.1129556;-2.3284578;-0.2668855;-1.2840987;3.485706;-1.8304309;CODE
instantiate with crawler;-4.0187554;-1.1412477;0.7575117;2.6536908;-0.14518097;1.4899639;-
instantiate directly;-4.925621;-1.6731758;2.9876955;2.7354128;2.0106456;1.0588624;-
uri priority settings priority;-3.0495837;1.306226;2.303696;2.4269156;1.3866315;6.2756543;IRRE
from google cloud storage import client noqa f401 plc0415;-3.47987;-0.53544027;-2.0984726;-2.7828398;-0.6875553;1.0511847;CODE
from google cloud storage import client noqa f401 plc0415;-3.47987;-0.53544027;-2.0984726;-2.7828398;-0.6875553;1.0511847;CODE
from google cloud storage import client noqa f401 plc0415;-3.47987;-0.53544027;-2.0984726;-2.7828398;-0.6875553;1.0511847;CODE
async def assertexportedcsv noqa b027;-1.3386059;2.1294897;-6.0780373;2.7642045;-2.8834488;-0.89234376;CODE
async def assertexportedjsonlines noqa b027;-2.8716443;3.4834034;-3.489588;4.5520887;-3.2239654;-0.47014752;CODE
async def assertexportedxml noqa b027;-4.168765;3.8620212;-5.771412;3.6538148;-0.77540475;-0.42015642;CODE
async def assertexportedmultiple noqa b027;-3.333285;3.47778;-5.1879616;5.372598;-1.7569813;-1.073005;CODE
async def assertexportedpickle noqa b027;-2.8079078;2.6053145;-5.12151;5.4316955;-1.6457766;-1.2149439;CODE
async def assertexportedmarshal noqa b027;-3.131851;2.724971;-5.406913;5.6617064;-2.17229;-1.6338178;CODE
xml;-3.4897792;-0.797327;4.201396;-1.3835993;4.6107597;-0.27313185;-
json;-1.4256761;-1.5285673;6.679203;0.124978095;1.0443649;-3.4324534;-
feed exporters use field names from item;-2.4185104;-0.6593386;-1.6250466;1.2602363;0.625434;3.5270767;CODE
https foss heptapod net pypy pypy issues 3527;-5.632656;-1.1730075;-1.8713918;-0.8097071;-3.9182184;-1.2613864;CODE
empty plugin to activate postprocessing postprocessingmanager;-5.62644;0.48056123;-1.1296984;2.4740303;-2.654989;2.871788;CODE
file mark batch time s batch id 02d;-1.8434731;0.8212951;0.47810432;-2.6360016;1.6537614;-1.4946808;-
small size 1024 1 kb;-0.81402475;-0.3707822;-0.12505388;-3.1599689;-1.1677897;1.1672453;-
large size 1024 2 1 mb;-0.6596788;-0.3421537;1.4097196;-2.9830613;0.15244615;1.0045774;-
get all result must be native string;-1.5070652;3.5064952;-0.89020735;1.7938393;0.18335152;-3.165023;TASK
request requires url in the init method;-6.2530437;2.0711193;0.7343756;2.6648803;-1.7185832;3.0165036;CODE
url argument must be basestring;-6.2403345;1.664722;-0.26003247;0.27202904;-0.72247666;-0.7211393;TASK
this test passes by not raising any valueerror exception;-0.56424975;7.7523184;-6.7076387;5.882482;-2.3521833;-5.9657545;CODE
different ways of setting headers attribute;-4.244072;-0.477602;0.5511587;-0.079753086;3.1228473;4.122333;IRRE
headers must not be unicode;-6.299281;0.45978144;-2.2808573;-2.4549315;-0.75893646;0.21332636;CODE
encoding affects only query part of uri not path;-3.7441409;1.5883608;-2.293064;-0.33813375;-0.23392868;2.7369254;CODE
path part should always be utf 8 encoded before percent escaping;-3.267676;1.2568939;-1.8200264;-0.7367952;-2.175588;1.3028532;CODE
should be same as above;-4.5728016;0.72203594;1.7145139;-2.5110497;1.7800097;-0.9970535;-
encoding is used for encoding query string before percent escaping;-2.7284856;1.325183;-1.584722;-1.2009703;1.2130814;0.2591486;CODE
path is still utf 8 encoded before percent escaping;-3.484953;1.4085674;-1.4635116;-0.61849284;-3.057622;0.96919715;CODE
percent escaping sequences that do not match valid utf 8 sequences;0.42802957;2.0475848;-1.3093545;-0.5152495;0.53779227;-2.534447;CODE
should be kept untouched just upper cased perhaps;-4.3671885;3.997731;-0.66533977;2.1370163;3.1038702;2.6149518;CODE
see https datatracker ietf org doc html rfc3987 section 3 2;-2.6130881;-2.2803895;-0.6838868;-2.0265071;-0.08317258;-0.49707514;CODE
conversions from uris to iris must not use any character encoding;-3.5392692;0.9897515;-3.6531436;-2.335474;-1.2438966;0.9274128;CODE
other than utf 8 in steps 3 and 4 even if it might be possible to;-3.9558818;-1.057165;0.5576171;-1.5422474;2.5986743;-1.2375895;CODE
guess from the context that another character encoding than utf 8 was;-1.5894415;-0.14384674;-0.66811013;1.3809048;-1.5127981;-1.0273982;CODE
used in the uri for example the uri;-6.3827906;-2.664158;3.163472;-1.0248938;2.6360543;1.7970102;CODE
http www example org r e9sum e9 html might with some guessing be;-4.1384053;-1.8762591;2.0863214;-0.2640012;1.4812279;-1.010914;CODE
interpreted to contain two e acute characters encoded as iso 8859 1;-3.5744784;1.97487;-3.2206447;-3.214478;0.5816608;-2.06214;CODE
it must not be converted to an iri containing these e acute;-3.5561664;1.9889531;-3.0529962;-0.77409166;1.0220187;0.21914595;-
characters otherwise in the future the iri will be mapped to;-3.9514945;-1.5841577;0.51299614;0.5296586;2.9362931;2.0173948;CODE
http www example org r c3 a9sum c3 a9 html which is a different;-5.267706;0.04094849;1.7991316;-1.4644331;2.2373624;-0.4252211;CODE
uri from http www example org r e9sum e9 html;-4.7824755;0.14817692;3.0865705;-1.76925;0.37172672;0.4704779;CODE
assert r2 encoding utf 8 default encoding;-1.6150463;3.7153625;-5.5723534;1.3367453;-1.2432694;-1.4572455;CODE
empty data;-0.99059635;3.52129;1.3068646;-1.1406648;-0.93971366;-2.9658427;-
data is not passed;-1.6697781;4.491278;0.8859765;0.82286507;-1.1822362;-2.706945;-
method passed explicitly;-3.022942;2.903847;-0.55120766;4.4322596;0.64083606;-0.31243527;-
response requires url in the constructor;-6.023529;2.1967657;0.82600975;2.6198215;-0.09443239;1.1015844;CODE
body can be str or none;-4.4110703;2.0434036;-0.0086438125;0.72246027;-0.13785279;-2.2166858;-
test presence of all optional parameters;0.19134757;7.784634;-2.5478337;4.12168;2.3121352;-2.0861304;IRRE
response follow;-2.6057372;0.41254506;5.127759;2.7926977;-0.6633708;-2.074154;CODE
response follow all;-2.7244284;-0.09182789;4.4528446;2.7743723;-1.1435952;-1.389683;CODE
instantiate with unicode url without encoding should set default encoding;-4.125349;1.0926615;-1.6655236;-0.5273957;-0.9267592;3.5956912;IRRE
make sure urls are converted to str;-5.2861423;1.4636122;-2.20411;-0.34521562;-3.0089304;-0.3057481;-
check response text;-3.6953747;4.5006847;2.0819805;3.3465805;-1.0910698;-4.3683515;IRRE
textresponse and subclasses must be passed a encoding when instantiating with unicode bodies;-3.46962;0.65913063;-3.4779842;0.6630531;-0.20362525;3.2413352;CODE
word ufffd ufffd w3lib 1 19 0;-4.0433764;0.05030508;-0.7353349;-4.2874417;0.03237583;-4.06249;-
word ufffd w3lib 1 19 0;-4.346999;-0.059542675;-0.8598318;-4.2917175;-0.28818813;-3.97091;-
inferring encoding from body also cache decoded body as sideeffect;-1.2582694;0.3314866;-1.859595;1.6990705;0.65533435;3.1849647;CODE
this test tries to ensure that calling response encoding and;-2.9116194;4.6979513;-3.9369652;4.6844482;-1.4432626;-5.115401;IRRE
response text in indistinct order doesn t affect final;-3.146087;3.7950385;-0.34588745;3.2203376;-0.6918315;0.8793538;CODE
response text in indistinct order doesn t affect final;-3.146087;3.7950385;-0.34588745;3.2203376;-0.6918315;0.8793538;CODE
values for encoding and decoded body;0.7055448;0.7940744;0.10900753;-3.082224;1.7552435;-1.1719221;IRRE
test response without content type and bom encoding;-1.4495132;4.407749;-3.5637007;2.8693435;0.2007004;-1.7965451;IRRE
body caching sideeffect isn t triggered when encoding is declared in;-4.141047;2.1353753;-3.0891984;0.9753622;-1.8210527;3.132853;-
content type header but bom still need to be removed from decoded;-5.0009384;1.2849807;-2.9931126;0.120520234;1.9730492;4.0435386;TASK
body;-3.2369964;-1.2094003;5.8777647;1.3195382;0.08804917;-2.9638696;-
http example com sample3 html foo;-5.2092533;0.80851454;1.1804985;-0.05217948;1.49948;-0.14991586;IRRE
select a elements;0.23157528;1.6615348;5.22855;-2.5740573;3.8345973;-2.4377732;CODE
select link elements;-2.1071959;0.61682636;4.5166245;-2.1764061;2.5761762;0.073615976;CODE
href attributes should work;-3.9295557;-1.0306822;2.1867654;-0.25437972;-1.765969;1.9263643;META
non a elements are not supported;-4.897882;3.1417887;-2.699442;-2.1809835;-0.6181768;-1.2139988;-
for conflicting declarations headers must take precedence;-6.0824146;2.3799622;-3.4868677;1.2816781;3.4028442;0.5949102;CODE
make sure replace preserves the encoding of the original response;-2.7956717;3.6251314;-2.31592;1.2354552;-2.5899343;0.82936186;CODE
make sure replace preserves the explicit encoding passed in the init method;-4.028904;2.535368;-5.4150705;-0.14224975;-1.4142869;1.7136043;IRRE
i2 eval itemrepr pylint disable eval used;-4.430927;4.190603;-4.504301;2.4844298;-0.6789753;2.3779871;CODE
d class inverted;-0.08811259;0.58194524;-1.0539206;-3.3167877;1.7595876;-1.473338;IRRE
d class inverted;-0.08811259;0.58194524;-1.0539206;-3.3167877;1.7595876;-1.473338;IRRE
d class inverted;-0.08811259;0.58194524;-1.0539206;-3.3167877;1.7595876;-1.473338;IRRE
for rationale of this see;-3.0509179;-0.21722217;2.6019914;0.90636593;0.072684236;-2.1720726;CODE
https github com python cpython blob ee1a81b77444c6715cbe610e951c655b6adab88b lib test test super py l222;-4.005904;-2.4635923;-6.233803;-3.130213;-4.552085;-4.382894;CODE
def init self args kwargs pylint disable useless parent delegation;-6.7319384;1.2866875;-3.3047702;2.917708;-1.456922;2.8160248;IRRE
this call to super trigger the classcell propagation;-0.7244222;-0.27121297;0.7277715;1.3530334;1.2025236;3.8744273;CODE
requirement when not done properly raises an error;-2.6227925;6.25242;-3.8651304;4.2251606;0.8039252;-2.119818;CODE
typeerror class set to class main myitem;-3.0160415;1.0028756;-1.9156579;1.4904263;-1.5218868;-0.71919507;IRRE
defining myitem as class main myitem;-3.8530877;-0.29893285;0.46390107;0.6049623;3.886767;2.4565034;CODE
l2 eval repr l1 pylint disable eval used;-4.486504;2.544294;-5.291158;1.9818405;-1.3544741;1.7005242;CODE
a hack to skip base class tests in pytest;-0.538188;2.144767;-4.27667;4.402988;-0.9143757;-1.1407652;IRRE
url http example com sample3 html foo;-5.032242;1.2226202;1.6169045;-0.15657857;0.75266606;0.21614577;IRRE
lx self extractor cls restrict css subwrapper a;-3.5072396;0.82418805;-2.9552374;0.27344143;1.8873353;4.2483687;CODE
restrict css subwrapper a;-3.2396853;1.6158023;0.36907917;1.3568745;1.4657377;2.827263;-
override denied extensions;-5.826397;1.5251477;-1.7865182;2.104884;-1.2231731;2.0862844;CODE
div id item1 data url get id 1 a href item 1 a div;-1.8721194;0.85809386;4.382108;-2.7844563;0.6078297;1.0027283;-
div id item2 data url get id 2 a href item 2 a div;-2.2701974;0.88592035;4.141081;-2.597886;0.4766008;0.9095503;-
test items;-0.29910085;3.6424897;2.7076488;5.873626;2.253166;-6.590428;IRRE
test item loaders;-0.3059528;3.2585301;0.44313458;5.4296937;1.2157509;-1.4332922;IRRE
test processors;1.3715373;-0.20331682;0.26964292;3.8742266;-0.90684533;-4.8652124;IRRE
l add css name name text;-4.387329;-1.4253813;3.1827233;-2.1788588;1.4503715;0.7157311;TASK
l replace css name name text;-3.7410133;-0.5503953;2.649238;-1.4513048;0.88272864;1.1721319;-
l get css name text;-3.9123857;-0.9073434;3.757984;-1.9317375;1.3393757;-0.9032845;-
logging log logkws level message noqa log015;-3.8700464;0.3424759;-2.2958806;-0.7394983;-0.7572408;-0.5053679;-
in practice the complete traceback is shown by passing the;-2.9126518;-1.6439941;0.30453306;3.2451303;-0.70306396;1.3933165;CODE
exc info argument to the logging function;-3.181697;0.82241154;-1.1369773;1.1981627;-0.20024806;1.2332063;CODE
in practice the complete traceback is shown by passing the;-2.9126518;-1.6439941;0.30453306;3.2451303;-0.70306396;1.3933165;CODE
exc info argument to the logging function;-3.1816967;0.82241076;-1.1369783;1.1981632;-0.20024754;1.2332054;CODE
in practice the complete traceback is shown by passing the;-2.9126518;-1.6439941;0.30453306;3.2451303;-0.70306396;1.3933165;CODE
exc info argument to the logging function;-3.1816967;0.82241076;-1.1369783;1.1981632;-0.20024754;1.2332054;CODE
in practice the complete traceback is shown by passing the;-2.9126518;-1.6439941;0.30453306;3.2451303;-0.70306396;1.3933165;CODE
exc info argument to the logging function;-3.181697;0.82241154;-1.1369773;1.1981627;-0.20024806;1.2332063;CODE
simulate what happens after a minute;0.16492689;0.13033967;6.7483683;1.9059958;-2.1578681;-1.640545;-
simulate when spider closes after running for 30 mins;-2.8651617;1.8317566;3.4846678;4.6401763;-1.1931528;0.84030783;CODE
assert x self class for x in mwman methods open spider m1 m2 type ignore union attr;-1.1488848;4.044767;-5.149769;3.1276596;2.1291273;1.9251603;CODE
assert x self class for x in mwman methods close spider m2 m1 type ignore union attr;-0.97265095;4.0477242;-5.074211;3.5613518;2.2134135;2.2605205;CODE
assert x self class for x in mwman methods process m1 m3 type ignore union attr;-0.02806312;4.4567375;-6.078475;2.8402784;1.76736;1.4253906;CODE
prepare a directory for storing files;-0.7089376;-1.009607;2.8226862;-0.29830295;0.86653805;-0.11742237;CODE
check that logs show the expected number of successful file downloads;-0.8653207;1.9542614;1.3582915;3.6912198;-2.2349896;-2.9687023;CODE
check that the images files status is downloaded;-2.8136373;0.94916815;1.291623;1.2803837;-2.1851013;0.60977507;CODE
check that the images files checksums are what we know they should be;-4.0767884;1.7007582;-1.8827798;-0.8142184;-2.2708778;0.4570213;-
check that the image files where actually written to the media store;-2.4536216;1.6100408;-0.6839265;0.6623682;-2.5798786;1.2139837;META
check that the item does not have the images files field populated;-3.2812889;3.9268024;-0.13055767;1.802209;-2.3761945;1.0217446;CODE
check that there was 1 successful fetch and 3 other responses with non 200 code;-1.6044086;4.9732585;0.2654436;4.7085576;-0.050172832;-3.978423;CODE
check that logs do show the failure on the file downloads;-3.2563303;1.3081721;-1.1858226;2.6644998;-3.6994872;-1.3065358;CODE
check that no files were written to the media store;-3.5212984;2.2282684;-1.1659013;1.7299162;-3.1272314;-0.5577535;-
from pil import image noqa f401;-3.686888;-0.3381541;-0.23434255;-4.2041774;-3.1680822;0.9557405;CODE
somehow checksums for images are different for python 3 3;-2.7876065;2.5198696;-2.9981258;-0.7896294;-2.683483;-1.1856228;CODE
from google cloud import storage noqa plc0415;-3.6591225;-0.1648631;-1.698305;-3.0925465;-0.025474276;0.44758946;CODE
acl list blob acl loads acl before it will be deleted;-3.7477672;1.6080258;-1.5465449;1.1094412;0.3917378;1.1450356;CODE
default fields;-2.7409203;-0.6348509;2.7940016;-0.96730036;1.8569884;1.9380322;CODE
overridden fields;-3.6334074;0.771897;1.1829125;0.89257056;3.1151962;1.9784604;-
default fields;-2.7409184;-0.634851;2.7940028;-0.9673;1.8569882;1.9380325;CODE
overridden fields;-3.6334074;0.771897;1.1829125;0.89257056;3.1151962;1.9784604;-
default fields;-2.7409184;-0.634851;2.7940028;-0.9673;1.8569882;1.9380325;CODE
overridden fields;-3.6334074;0.771897;1.1829125;0.89257056;3.1151962;1.9784604;-
values from settings for custom pipeline should be set on pipeline instance;-0.78942466;1.8526635;-1.2150145;1.144163;-0.30287537;3.348114;IRRE
values from settings for custom pipeline should be set on pipeline instance;-0.78942466;1.8526635;-1.2150145;1.144163;-0.30287537;3.348114;IRRE
from botocore stub import stubber noqa plc0415;-3.886934;-0.68697864;-2.9200492;-1.9238626;-1.046011;-1.3261445;CODE
the call to read does not happen with stubber;-4.7522197;2.0046656;-0.27471423;3.245193;-4.3376327;0.34931898;CODE
from botocore stub import stubber noqa plc0415;-3.886934;-0.68697864;-2.9200492;-1.9238626;-1.046011;-1.3261445;CODE
import google cloud storage noqa f401 plc0415;-3.0377686;-0.11646778;-2.3364651;-2.7998962;-0.655117;0.4888453;CODE
this is separate from the one in test pipeline media py to specifically test filespipeline subclasses;-1.7383068;-2.3258502;-3.7563138;3.3039408;0.86811846;0.8107077;CODE
if not encoders issubset set image core dict type ignore attr defined;-1.6123277;2.3491585;-5.62171;-1.066463;-2.0421379;3.6146393;IRRE
straight forward case rgb and jpeg;-0.9174241;0.12581746;2.3783023;-2.7106872;1.2349496;2.424312;CODE
check that we don t convert jpegs again;-2.4776506;1.820846;-0.9136991;0.47974384;-4.4243937;0.51447475;CODE
check that thumbnail keep image ratio;0.50638515;3.5346954;1.404858;-0.048190173;-3.2946956;1.4263568;-
transparency case rgba and png;-3.3680665;1.5493419;0.87192047;-2.7224538;-0.70451224;2.6172283;CODE
transparency case with palette p and png;-3.6518862;1.2741721;2.1028924;-1.7350045;-0.1768721;3.8146791;CODE
default fields;-2.7409184;-0.63485014;2.7940018;-0.96729994;1.8569894;1.9380318;CODE
overridden fields;-3.6334074;0.771897;1.1829125;0.89257056;3.1151962;1.9784604;-
default fields;-2.7409184;-0.63485014;2.7940018;-0.96729994;1.8569894;1.9380318;CODE
overridden fields;-3.6334074;0.771897;1.1829125;0.89257056;3.1151962;1.9784604;-
default fields;-2.7409184;-0.63485014;2.7940018;-0.96729994;1.8569894;1.9380318;CODE
overridden fields;-3.6334074;0.771897;1.1829125;0.89257056;3.1151962;1.9784604;-
pipeline attribute names with corresponding setting names;0.027502654;-0.525966;-1.509364;0.5516353;4.13911;3.8129063;IRRE
this should match what is defined in imagespipeline;-4.8649983;0.8033072;0.3389598;-1.7886187;0.5856679;4.913809;CODE
values should be in different range than fake settings;0.9838928;6.210773;-1.05447;-0.47651893;-2.5388205;0.737564;IRRE
instance attribute lowercase must be equal to class attribute uppercase;-2.3541605;1.3969957;-3.813976;1.0091579;2.6068199;1.0765933;CODE
instance attribute lowercase must be equal to;-2.7837448;2.9311697;-2.991359;0.7773826;2.1826808;0.30285364;TASK
value defined in settings;-2.7249935;2.7664928;1.7261612;-0.65765584;2.1127558;0.9228852;IRRE
values from settings for custom pipeline should be set on pipeline instance;-0.78942466;1.8526635;-1.2150145;1.144163;-0.30287537;3.348114;IRRE
values from settings for custom pipeline should be set on pipeline instance;-0.78942466;1.8526635;-1.2150145;1.144163;-0.30287537;3.348114;IRRE
create sample pair of request and response objects;0.46583492;1.4956588;2.5420468;1.7708361;4.7122746;0.6231518;CODE
simulate the media pipeline behavior to produce a twisted failure;-1.3514645;0.6225651;0.12812868;3.014104;-2.8190315;2.5554762;CODE
simulate a twisted inline callback returning a response;-2.749778;3.2444134;1.3052572;3.234084;-2.336509;1.4792081;IRRE
simulate the media downloaded callback raising a fileexception;-4.503978;1.6953322;-0.34156048;4.632993;-2.8532662;2.7988837;CODE
this usually happens when the status code is not 200 ok;-6.3379993;2.703752;-2.1464186;1.8934397;-2.919619;-0.42851344;CODE
simulate twisted capturing the fileexception;-2.541959;2.8642764;-0.98594815;2.5317364;-2.4061706;0.39984852;CODE
it encapsulates the exception inside a twisted failure;-4.583828;0.7360833;-1.8675689;4.5189605;0.9799186;1.6151274;CODE
the failure should encapsulate a fileexception;-4.141008;3.4421225;-2.4841874;3.948184;-0.53336054;-0.27583325;CODE
and it should have the stopiteration exception set as its context;-6.213931;1.8298848;-1.222378;5.273558;1.1074207;1.91418;CODE
let s calculate the request fingerprint and fake some runtime data;-0.14042076;3.289042;0.056268074;2.8487313;1.5588264;-1.996639;CODE
when calling the method that caches the request s result;-3.3821774;3.2668536;1.8465756;5.3145747;-1.7138683;2.3688567;IRRE
it should store the twisted failure;-3.3740263;1.002237;1.0276169;2.3655052;-0.51771706;1.5936047;-
encapsulating the original fileexception;-4.5149765;2.9400804;-2.1201174;3.2272997;0.35164735;1.5633134;CODE
but it should not store the stopiteration exception on its context;-5.412408;3.7300937;0.06554987;6.4108663;1.0687349;2.5301633;CODE
check that failures are logged by default;-2.0027046;4.9336123;-0.8811571;5.800518;-2.2986057;-1.4270102;CODE
disable failure logging and check again;-4.034777;4.3385797;-0.071619965;5.884298;-3.1345685;-0.12912123;-
only once;-2.2686808;-0.06602516;3.2405708;2.727303;-0.08632643;-1.7307167;-
assert m 0 get media requests first hook called;-3.023683;4.483559;-0.7222126;5.753123;-1.8738585;0.616479;CODE
assert m 1 item completed last hook called;-1.712069;6.549214;-1.2147588;6.243809;0.25364736;-1.3202684;CODE
twice one per request;-2.9508388;3.0552993;3.7261157;2.9698937;3.3384159;1.4586943;CODE
one to handle success and other for failure;-3.1116245;-0.44042763;4.429898;6.2142715;1.0393245;-2.652193;CODE
returns single request without callback;-3.389743;4.729978;2.782605;5.0740585;-1.2472427;2.174395;IRRE
item requests req pass a single item;-2.4627624;5.054615;2.6377287;2.5621607;3.2041097;2.2561278;CODE
returns iterable of requests;-1.4464583;2.6478965;3.4414926;3.948327;0.73525965;-1.6845357;CODE
rsp2 is ignored rsp1 must be in results because request fingerprints are the same;-1.9616627;3.2385736;-3.5227067;1.2451843;-0.80556464;0.7853657;CODE
these are the status codes we want;-4.4571834;-1.3541272;1.3167971;0.21633223;3.2891521;-1.5795311;-
the downloader to handle itself;-4.420059;-2.327881;3.0650828;3.5454795;0.17363185;3.4732647;CODE
we still want to get 4xx and 5xx;-2.1286871;1.2805568;2.0257056;-2.4638574;1.8671541;-0.21814065;TASK
this and the next assert will fail as mediapipeline from crawler wasn t called;-5.2640796;1.7852914;-3.246573;6.1629243;-1.9370401;0.69927096;CODE
return failure deprecated;-4.622788;3.0076814;-3.9332404;4.8205547;-3.395479;-1.8180376;IRRE
def process item self item spider pylint disable useless parent delegation;-7.598873;2.3506727;-1.8353897;3.467835;0.8145251;3.2895885;CODE
by default start requests are fifo other requests are lifo;-6.253058;-0.27765214;0.34397054;3.0983725;0.010024984;2.3717375;CODE
priority matters;-1.4004107;0.7438189;4.8348093;3.8499756;1.9722941;1.3217258;-
for the same priority start requests pop last;-4.470304;2.3597982;3.8225179;5.2426257;-0.66223985;2.9423814;CODE
the proxy returns a 407 error code but it does not reach the client;-4.186062;1.2005163;-1.4267488;0.94082254;-2.8989685;0.4063186;CODE
he just sees a tunnelerror;-3.8196242;0.74095064;0.6404566;1.7929795;-4.261061;-1.758104;-
kwargs pylint disable use implicit booleaness not comparison;-2.8883412;3.1116853;-5.2939124;2.850345;-2.2853053;1.4338205;CODE
check exceptions for argument mismatch;-2.0638826;7.686112;-4.15075;4.295156;-1.0922763;-4.108507;CODE
def mixin callback self response pylint disable unused private member;-4.9017873;2.4224012;-3.233486;2.9061584;-1.6566176;2.82264;CODE
def parse item private self response pylint disable unused private member;-4.406269;2.9767454;-3.4579117;2.8103228;-0.30452135;1.0549965;CODE
https codersblock com blog the smallest valid html5 page;-4.5296364;1.0144433;0.49952054;0.5786899;-0.862266;1.0304279;CODE
todo add more tests that check precedence between the different arguments;-1.5626647;6.7981405;-0.9102574;5.9402947;2.9983008;-2.982511;TASK
headers takes precedence over url;-5.740386;1.7376053;1.1366175;1.1699284;-0.3759055;2.5803213;CODE
check that mime types files shipped with scrapy are loaded;-4.669936;-0.4766499;-3.4593647;1.6942271;-3.3426373;0.3558503;CODE
check if robotexclusionrulesparser is installed;-3.7662003;0.495646;-3.0145133;2.6339042;1.3465922;1.109375;IRRE
from robotexclusionrulesparser import noqa plc0415;-3.6173265;-0.5368089;-3.4017794;-3.3378448;0.006559328;0.8396028;CODE
robotexclusionrulesparser noqa f401;-3.5498927;-0.4397169;-0.14683276;-1.8329517;1.0081482;0.7775776;IRRE
utf 8 bom at the beginning of the file ignored;-4.1778975;1.9115393;-2.4148781;-1.1363999;-3.509445;0.58278036;-
from scrapy settings default settings import noqa plc0415;-6.2544746;-0.24607898;-3.3047683;-1.8931679;-2.8915722;1.2745501;CODE
pylint disable unsubscriptable object unsupported membership test use implicit booleaness not comparison;-3.533625;3.52403;-6.9896708;4.3136845;0.15425952;-0.70947605;CODE
too many false positives;0.48896235;3.8271277;-1.8079823;3.2508533;1.035986;-5.2880015;-
attribute set new settings 0 insufficient priority;-2.7750173;3.240114;-0.3089322;1.7575461;0.5283229;4.3610826;IRRE
myattr settingsattribute 0 30 note priority 30;-3.2732027;2.6654336;-1.7051321;-0.06233413;0.40318766;2.7484012;TASK
ettings update key 1 pylint disable unexpected keyword arg;-6.857285;0.5618368;-4.490965;1.6142722;-2.4877067;1.3510213;CODE
match r dictionary update sequence element 0 has length 3 2 is required sequence of pairs expected;0.2554083;2.5604334;-3.4900672;-3.6427126;0.1768887;-3.8438957;CODE
empty settings should return default;-3.9435983;3.9361527;0.3643024;1.3410746;-2.4314837;2.9670224;IRRE
if old cls has none as value raise keyerror;-3.3722699;4.1403446;-6.2006044;-0.21029761;-2.9483979;-2.18483;IRRE
unrelated components are kept as is as expected;-2.4337075;1.6014166;-0.15852952;0.7707738;1.8112824;4.368783;IRRE
set;-1.4280705;0.15607189;7.4121943;-1.1588911;1.308024;-3.1926973;IRRE
add;-4.309576;-1.6364306;3.6666858;-2.361919;-0.18180183;-2.79792;TASK
replace;-3.2587688;1.1411715;4.9056053;-0.5527098;0.6154155;-3.8553429;-
string based setting values;0.9803606;2.8986146;2.4659107;-1.0713645;3.6872332;-1.2435994;IRRE
set;-1.4280705;0.15607189;7.4121943;-1.1588911;1.308024;-3.1926973;IRRE
add;-4.309576;-1.6364306;3.6666858;-2.361919;-0.18180183;-2.79792;TASK
keep;-2.4858894;0.13452113;3.906674;1.5352963;-0.8791254;-1.7240416;-
string based setting values;0.9803606;2.8986146;2.4659107;-1.0713645;3.6872332;-1.2435994;IRRE
assert spider start urls pylint disable use implicit booleaness not comparison;-4.7773924;5.299704;-4.2937527;6.3565145;-0.7077101;1.1012655;CODE
xml gz but body decoded by httpcompression middleware already;-5.135625;0.7958792;-1.4294796;1.1402711;-0.7580461;4.5740705;META
the warning must be about the base class and not the subclass;-4.1297193;0.9189042;-4.090092;3.1655328;1.3447838;0.612991;IRRE
exceptions;-3.007008;1.9451993;2.0586464;5.458023;0.88136214;-2.9776647;CODE
ugly hack to avoid cyclic imports of scrapy spiders when running this test;-2.6639187;1.1528606;-2.925104;4.475756;-0.9467641;-1.904054;CODE
alone;-0.9808191;-0.60511285;4.11896;-0.28559822;-0.8553671;-0.41109487;-
needed on 3 10 because of https github com benjaminp six issues 349;-7.1489315;-2.495306;-3.371404;-0.97440386;-1.5779414;-0.9102986;CODE
at least until all six versions we can import including botocore vendored six;-3.5621936;-3.643191;-2.0146787;1.0897633;2.075506;1.0395306;CODE
are updated to 1 16 0;-3.3634384;-0.3589308;-0.22984025;-0.6777349;-1.7867174;-1.3721474;CODE
needed on 3 10 because of https github com benjaminp six issues 349;-7.1489315;-2.495306;-3.371404;-0.97440386;-1.5779414;-0.9102986;CODE
at least until all six versions we can import including botocore vendored six;-3.5621936;-3.643191;-2.0146787;1.0897633;2.075506;1.0395306;CODE
are updated to 1 16 0;-3.3634384;-0.3589308;-0.22984025;-0.6777349;-1.7867174;-1.3721474;CODE
copy 1 spider module so as to have duplicate spider name;-4.510363;0.87812454;-0.0048101307;-0.37058246;2.9226766;2.7496824;CODE
copy 2 spider modules so as to have duplicate spider name;-4.178595;0.18401727;-0.21073179;-0.42181954;3.2660675;3.0380318;CODE
this should issue 2 warning 1 for each duplicate spider name;-4.1064386;1.9876637;-1.8845392;2.3775666;2.6080968;0.7114747;CODE
result count 3 to simplify checks let everything return 3 objects;0.9929048;5.365085;0.8473727;0.96750546;3.2160833;-5.47481;IRRE
mwman methods process spider output 0 mw process spider output pylint disable comparison with callable;-3.1011744;3.2604692;-3.662514;4.1805425;-1.5404158;3.2271585;IRRE
mwman methods process spider output 0 mw process spider output pylint disable comparison with callable;-3.1011744;3.2604692;-3.662514;4.1805425;-1.5404158;3.2271585;IRRE
mwman methods process spider output 0 mw process spider output pylint disable comparison with callable;-3.1011744;3.2604692;-3.662514;4.1805425;-1.5404158;3.2271585;IRRE
list mw process start requests spider output none type ignore arg type;-4.175864;3.0458202;-2.911588;3.336393;-1.0213002;2.7098193;IRRE
list mw process start requests spider output none type ignore arg type;-4.175864;3.0458202;-2.911588;3.336393;-1.0213002;2.7098193;IRRE
list mw process start requests spider output none type ignore arg type;-4.175864;3.0458202;-2.911588;3.336393;-1.0213002;2.7098193;IRRE
list mw process start requests spider output none type ignore arg type;-4.175864;3.0458202;-2.911588;3.336393;-1.0213002;2.7098193;IRRE
it assumes there is a response attached to failure;-3.9334948;3.1335452;1.1804422;7.757323;-0.6455548;-0.13144915;CODE
mw crawler spider handle httpstatus list 404 type ignore attr defined;-3.8984685;2.5259094;-3.354292;2.639708;-2.1025856;3.9113622;CODE
0 recover from an exception on a spider callback;-4.9871807;5.1305814;-0.95751685;3.9090538;-1.9543278;1.2204301;CODE
1 exceptions from a spider middleware s process spider input method;-4.759948;2.4185417;-2.1539767;3.817217;-0.50455767;-0.090882376;CODE
spider;-3.7590134;-1.1048701;5.1287622;1.1816822;0.75690025;-1.5913191;-
engine;-3.3627195;-2.889867;5.6051817;0.96210474;1.2453312;-3.0318348;-
2 exceptions from a spider callback generator;-5.7057137;3.659107;-1.4462489;4.149536;0.52217776;0.025376007;CODE
2 1 exceptions from a spider callback generator middleware right after callback;-6.0579395;3.0897782;-1.9062629;4.375667;-1.4485023;1.8605746;CODE
3 exceptions from a spider callback not a generator;-5.940311;3.398517;-1.8154489;4.281774;0.2706462;-0.1436312;CODE
3 1 exceptions from a spider callback not a generator middleware right after callback;-6.0402794;2.7852676;-2.3706043;3.9840562;-1.4430909;1.7039689;CODE
4 exceptions from a middleware process spider output method generator;-4.1889677;1.7059708;-3.1643975;4.1239676;-0.97742695;-0.21013062;CODE
5 exceptions from a middleware process spider output method not generator;-4.3327785;2.2306085;-3.2312052;4.0584383;-1.2612721;-0.55611753;CODE
spiders and spider middlewares for testmain test wrap;-3.3887622;0.7108774;0.2501083;3.7242358;1.1146837;-0.9561163;CODE
no credentials leak;-3.662082;-1.7612479;-0.8615034;1.2527081;-3.349095;-0.40239373;-
no referrer leak for local schemes;-3.3162675;0.080926634;-2.3491025;3.1898227;-1.439573;4.0053525;CODE
no referrer leak for s3 origins;-4.6058345;-1.5690143;-1.2617067;1.4833065;-1.476507;3.9650035;CODE
tls to tls send non empty referrer;-2.8274891;2.4744284;-1.2897178;0.3237051;-1.8258277;1.4665588;CODE
tls to non tls do not send referrer;-2.9915345;1.5047352;-2.5402489;-0.11196633;-3.3125722;2.0407135;CODE
non tls to tls or non tls send referrer;-2.5565705;0.2781566;-1.2513655;0.032555968;-1.5920103;2.1894493;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
same origin protocol host port send referrer;-4.455504;0.7444499;0.48501223;-0.5281143;-3.0046904;2.3677685;CODE
different host do not send referrer;-3.083893;1.4905027;-0.45771745;0.5750372;-3.7112541;2.2942717;CODE
different port do not send referrer;-3.7547033;1.8387518;0.408063;-0.07133636;-2.664437;1.7468134;CODE
different protocols do not send referrer;-3.9696605;1.1340345;-1.2831422;1.1506264;-2.865677;2.9324567;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
tls or non tls to tls or non tls referrer origin is sent yes even for downgrades;-3.987745;1.66747;-2.8643322;0.4383065;-1.947115;2.8854747;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
tls or non tls to tls or non tls referrer origin is sent but not for downgrades;-3.5989945;1.7199616;-3.269507;0.6170136;-2.3861606;3.2531052;CODE
downgrade send nothing;-4.339072;1.967516;-1.0091089;1.4950136;-3.892171;0.45776963;CODE
upgrade send origin;-5.7187138;-0.17524855;1.3489122;-0.29997543;-2.5543303;2.655036;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
same origin protocol host port send referrer;-4.4555044;0.7444496;0.48501322;-0.52811486;-3.00469;2.3677697;CODE
different host send origin as referrer;-3.7207258;1.230453;0.9012241;0.048219766;-2.7811902;3.6870246;CODE
exact match required;-2.3271382;1.7138569;2.2265227;-0.73470616;2.3373663;-2.4870567;CODE
different port send origin as referrer;-4.4146523;1.4175856;1.5159116;-0.6585554;-2.4803345;3.166328;CODE
different protocols send origin as referrer;-4.6365967;0.056659143;0.1556082;0.5454232;-1.9364716;3.8829875;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
tls to non tls downgrade send origin;-3.3707714;2.2845533;-1.2765529;-0.34699422;-3.0152924;3.5018682;CODE
same origin protocol host port send referrer;-4.4555044;0.7444496;0.48501322;-0.52811486;-3.00469;2.3677697;CODE
different host send origin as referrer;-3.7207258;1.230453;0.9012241;0.048219766;-2.7811902;3.6870246;CODE
exact match required;-2.3271382;1.7138569;2.2265227;-0.73470616;2.3373663;-2.4870567;CODE
different port send origin as referrer;-4.4146523;1.4175856;1.5159116;-0.6585554;-2.4803345;3.166328;CODE
downgrade;-2.4775565;-0.36465248;1.5926275;0.38108927;-1.2694819;-1.0955558;CODE
non tls to non tls;-2.7356746;0.8021584;-1.1067694;-0.8776705;-0.19457874;0.5282559;-
upgrade;-2.900451;-1.5100836;4.112404;0.8803038;0.6453991;-2.172802;TASK
different protocols send origin as referrer;-4.6365967;0.056659143;0.1556082;0.5454232;-1.9364716;3.8829875;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
tls to non tls downgrade send nothing;-3.322359;2.9100902;-2.3767607;0.5567661;-3.64019;1.0093092;CODE
tls to tls send referrer;-2.7783897;0.23335229;0.13045466;0.30248302;-1.9654726;1.8286514;CODE
tls to non tls send referrer yes it s unsafe;-3.5536292;0.30248064;-0.823938;0.36811998;-1.4524295;1.8539135;CODE
non tls to tls or non tls send referrer yes it s unsafe;-3.59144;-0.011168976;-1.0957028;0.102758914;-1.2166482;1.8470296;CODE
test for user password stripping;-0.64160573;2.9721706;-0.27372536;2.9845002;-1.7175298;-5.4502554;IRRE
tests using settings to set policy using class path;-2.6236236;1.8326519;-0.95582885;5.586033;0.55772805;-0.4448228;IRRE
tests using request meta dict to set policy;-3.743418;3.0028415;-2.85937;5.959021;-0.3829062;-2.080063;IRRE
when an unknown policy is referenced in request meta;-5.8167553;1.4258492;-0.9284119;5.9003844;0.7670627;4.0496893;CODE
here a typo error;-5.2775464;2.2164462;0.29505616;-1.0671409;-1.9682987;-3.791742;-
the policy defined in settings takes precedence;-4.9049754;2.2732997;0.024348373;2.8728986;0.29335782;4.801866;IRRE
same as above but with string value for settings policy;-5.265373;1.8111062;0.66461813;1.008973;2.8669226;2.5255592;IRRE
request meta references a wrong policy but it is set;-5.885727;1.434145;-1.2588097;4.1232705;-1.1864405;3.7591465;META
so the referrer policy header in response is not used;-5.67268;1.3788689;-1.2087978;2.1908169;-2.0841782;3.4534495;CODE
and the settings policy is applied;-4.982281;-1.4427805;2.0744207;2.788234;-0.10533094;5.584354;IRRE
here request meta does not set the policy;-6.414591;0.4330877;0.4482282;2.6528435;-2.5625508;3.4442785;CODE
so response headers take precedence;-4.8033323;2.6672711;0.66680145;3.1614358;-0.06273907;2.0279927;CODE
here request meta does not set the policy;-6.414591;0.4330877;0.4482282;2.6528435;-2.5625508;3.4442785;CODE
but response headers also use an unknown policy;-6.2432156;1.3810816;-1.5126;4.6317353;-0.10285994;2.983654;CODE
so the settings policy is used;-4.935544;-1.2692723;2.969869;3.1483955;0.11855634;5.1395307;IRRE
test parsing without space s after the comma;-0.4651211;3.5222847;-1.0792958;1.2550689;0.69884497;-5.1241493;IRRE
test parsing with space s after the comma;-0.29431602;2.9493554;-0.5203116;0.6171247;0.9637072;-5.1614428;IRRE
type ignore assignment;-0.23417613;4.5768676;-2.1790879;1.5046756;2.0121882;-2.3168907;IRRE
http scrapytest org 1 parent;-6.166422;-0.33384714;0.81751806;0.64803934;-0.3712732;2.224309;IRRE
http scrapytest org 2 target;-5.149197;-1.2371681;0.35609016;1.4385246;-0.90873975;1.6642368;IRRE
redirections code url;-5.820015;0.54403186;2.572595;0.23082227;-0.7812659;-0.7977317;-
b http scrapytest org 1 expected initial referer;-6.155051;1.2723737;-2.2482166;0.8961543;-0.50992477;1.6008743;IRRE
b http scrapytest org 1 expected referer for the redirection request;-6.183742;0.75363255;-2.0780458;1.2499927;-1.9854735;2.0180247;CODE
redirecting to non secure url;-3.6050985;1.044992;1.0601331;0.48598856;-2.942787;0.44038028;-
redirecting to non secure url different origin;-3.834278;1.7751242;1.3252519;-0.04950906;-2.9658005;2.2277274;-
def test type ignore override;-1.1247199;4.974821;-4.448441;6.051376;-0.49121863;-2.4277987;CODE
http scrapytest org 1 parent;-6.166422;-0.33384714;0.81751806;0.64803934;-0.3712732;2.224309;IRRE
http scrapytest org 2 target;-5.149197;-1.2371681;0.35609016;1.4385246;-0.90873975;1.6642368;IRRE
redirections code url;-5.820015;0.5440318;2.5725951;0.23082209;-0.7812668;-0.7977317;-
none expected initial referer;-5.265715;2.2900069;-1.9381386;0.9430728;0.27151123;0.9672346;IRRE
none expected referer for the redirection request;-5.243129;1.2698839;-0.732784;1.5840865;-2.384848;1.8460492;CODE
https example com 2 different origin;-4.5627427;1.7181202;1.7591654;-1.6790699;-3.0334473;1.0511988;CODE
http scrapytest org 101 origin;-6.3044505;-2.8607867;0.3987938;-0.99726397;-1.0184007;0.07039201;IRRE
http scrapytest org 102 target;-5.8228483;-1.8023592;-0.529782;0.7344623;-1.1147817;0.514771;IRRE
redirections code url;-5.820015;0.54403186;2.572595;0.23082227;-0.7812659;-0.7977317;-
b http scrapytest org 101 expected initial referer;-6.2939878;0.47974506;-2.6780298;0.5760573;-0.49289793;0.5506707;IRRE
b http scrapytest org 101 expected referer for the redirection request;-6.363901;0.24638423;-2.352803;1.1440145;-2.043343;1.3374084;CODE
redirecting from secure to non secure url different origin;-3.615567;1.5276487;1.2248901;-0.12214958;-2.7663302;2.558511;CODE
different domain different origin;-3.3890903;1.7546463;2.463433;-1.8888246;-2.0648067;1.5320362;CODE
b http scrapytest org send origin;-6.5408735;-0.75981873;0.5058319;-1.1336675;-2.4151804;0.9801741;CODE
b http scrapytest org redirects to same origin send origin;-5.494628;1.5393839;-0.578105;-0.18118685;-4.049647;2.3862362;CODE
redirecting to non secure url no referrer;-3.557783;1.3105826;-0.49343908;0.3707359;-3.3579667;1.2212559;-
redirecting to non secure url different domain no referrer;-2.1784894;1.2254324;0.23774299;-0.21524999;-2.9734857;1.5645686;CODE
https all along so origin referrer is kept as is;-4.441345;-0.27471006;2.2012494;0.5811782;-2.1906562;3.8826032;CODE
http scrapytest org 602 tls to non tls no referrer;-5.42564;-0.3359774;-2.811848;0.42716116;-1.8237321;1.291529;IRRE
tls url again still no referrer;-4.433535;0.7926928;-0.54762983;0.677124;-3.157378;1.5624527;TASK
http scrapytest org 101 origin;-6.3044505;-2.8607867;0.3987938;-0.99726397;-1.0184007;0.07039201;IRRE
http scrapytest org 102 target redirection;-5.938419;-0.088424206;-0.72536963;1.7522416;-2.3615885;1.5627273;IRRE
redirections code url;-5.820015;0.54403186;2.572595;0.23082227;-0.7812659;-0.7977317;-
b http scrapytest org 101 expected initial referer;-6.2939878;0.47974506;-2.6780298;0.5760573;-0.49289793;0.5506707;IRRE
b http scrapytest org 101 expected referer for the redirection request;-6.363901;0.24638423;-2.352803;1.1440145;-2.043343;1.3374084;CODE
redirecting to non secure url send origin;-4.583001;1.6511881;1.2997545;0.1254875;-4.5601053;1.6687204;CODE
redirecting to non secure url different domain send origin;-3.1118839;1.6534584;1.2964895;-0.41312936;-3.9933379;1.8577741;CODE
all different domains send origin;-2.6229951;0.8852451;1.7407805;-1.7096077;-2.449231;2.5649393;CODE
http scrapytest org 302 tls to non tls send origin;-5.4068747;0.7855478;-1.8212255;-0.12253708;-3.5957787;1.6342179;CODE
301 https scrapytest org 303 tls url again send origin also;-5.7235155;1.2452666;-0.39527684;-0.71439266;-3.9016297;1.4831355;CODE
http scrapytest org 101 origin;-6.3044505;-2.8607867;0.3987938;-0.99726397;-1.0184007;0.07039201;IRRE
http scrapytest org 102 target redirection;-5.938419;-0.088424206;-0.72536963;1.7522416;-2.3615885;1.5627273;IRRE
redirections code url;-5.820015;0.5440318;2.5725951;0.23082209;-0.7812668;-0.7977317;-
b http scrapytest org 101 expected initial referer;-6.2939878;0.47974506;-2.6780298;0.5760573;-0.49289793;0.5506707;IRRE
b http scrapytest org 101 expected referer for the redirection request;-6.3639016;0.24638475;-2.352802;1.1440152;-2.043343;1.3374078;CODE
redirecting to non secure url do not send the referer header;-4.225218;1.3939006;-1.0592617;0.6031684;-3.2415893;2.6575093;CODE
redirecting to non secure url different domain send origin;-3.1118839;1.6534584;1.2964895;-0.41312936;-3.9933379;1.8577741;CODE
all different domains send origin;-2.6229951;0.8852451;1.7407805;-1.7096077;-2.449231;2.5649393;CODE
http scrapytest org 602 tls to non tls do not send referer;-5.5215473;0.35596573;-3.4919739;0.35935795;-2.733415;1.9786159;CODE
tls url again still send nothing;-4.572852;1.8207586;0.4706751;0.7073191;-4.8413916;-0.45858225;TASK
state attribute must be present if jobdir is not set to provide a;-3.412319;2.395951;-3.60981;2.4458961;0.89217144;1.7872771;TASK
consistent interface;-0.91346043;1.0461011;1.5198102;1.8781754;2.375943;3.4564047;CODE
selectors should fail lxml html htmlelement objects can t be pickled;-3.8226254;1.3526192;-1.6385218;1.0141292;1.6256592;1.8605918;CODE
from scrapy http import formrequest request noqa plc0415;-6.2597737;-0.894262;-2.4249582;-1.079285;-1.8592969;0.42968497;CODE
from scrapy spiders import spider noqa plc0415;-5.4791255;-1.8757081;-0.42084354;-3.1797318;0.9910957;-1.0329164;CODE
from scrapy selector import selector noqa plc0415;-5.63603;-0.7714617;-2.8316867;-1.8140271;0.060623173;0.28833923;CODE
from scrapy item import field item noqa plc0415;-5.303132;-0.005308827;-2.11291;-3.1929202;-0.5950396;0.012067243;CODE
the result should depend only on the pytest reactor argument;-0.9780502;1.5788203;-4.2338023;0.9928803;-2.3863676;1.1852926;IRRE
higher priority takes precedence;-1.7240275;2.8164144;2.1527693;2.6493893;1.8539824;2.2215683;-
same priority raises valueerror;-0.59826285;4.2368283;-2.6191704;1.5721585;-2.0587559;-0.3848684;IRRE
work well with none and numeric values;4.1928024;4.8837457;-1.1150556;-4.9284205;0.19642967;-4.699052;IRRE
default shell should be ipython;-4.897365;-1.0760847;-1.0786295;-1.30389;-5.8246403;0.34315312;CODE
case 1 ignore unknown options true;-1.6645689;5.971831;-1.0270168;3.6461072;2.2625568;-0.39088833;CODE
with warnings catch warnings avoid warning when executing tests;-1.7855549;4.27876;-4.3026714;7.5527735;-2.03789;-1.8942378;CODE
case 2 ignore unknown options false raise exception;-3.5149422;7.008164;-3.2500916;4.6100645;1.125965;-0.020796478;CODE
normkey normkey deprecated caselessdict class;-1.3175459;-0.74704236;-5.712649;-1.6668295;-0.42466787;2.115623;CODE
normvalue normvalue deprecated caselessdict class;-0.23163527;1.0224913;-6.472162;-1.1598654;-1.1824394;2.4701385;IRRE
assert v 1 2 it is 1 with maybedeferred;-0.42026392;6.4261794;-4.649147;4.485887;0.9233288;-4.555717;CODE
teps append 2 add another value that should be caught by assertequal;-0.9407318;7.803484;-3.0663905;2.8926172;0.7377555;-4.1237183;CODE
teps append 2 add another value that should be caught by assertequal;-0.9407318;7.803484;-3.0663905;2.8926172;0.7377555;-4.1237183;CODE
simulate async processing;0.10017365;1.1142603;2.2901995;3.6883893;-1.0709906;1.333964;-
simulate trivial sync processing;1.3773757;0.5289306;1.6572465;2.6014595;-0.9205859;1.8894688;IRRE
simulate a simple callback without delays between results;0.020062683;3.5103796;3.334717;5.4368796;-1.3810437;0.44207856;IRRE
simulate a callback with delays between some of the results;0.8192946;3.36116;3.6064608;4.907486;-0.60548025;-0.05269201;IRRE
ignore subclassing warnings;-1.4973367;1.6884431;-5.0871935;4.8808684;1.3048768;0.72246754;IRRE
userclass subclass instances don t warn;-2.6885095;0.34150663;-3.344744;4.910105;0.93694454;0.01133164;CODE
https github com pygments pygments issues 2313;-5.4726386;-2.8978026;-4.6423855;-2.38949;-5.609355;0.17606337;CODE
n pygments 2 13;-2.6027381;-1.9086287;1.3645942;-5.6664877;-1.2749274;-4.294738;-
x1b 37m x1b 39 49 00m n pygments 2 14;-0.63901687;0.36370587;0.647696;-9.118104;0.93284255;-3.5841293;-
example taken from https github com scrapy scrapy issues 1665;-7.3571825;-2.029897;-2.196958;-1.3611635;-2.0626574;-0.8196554;CODE
with bytes;-1.1591159;-0.7655345;3.5952673;-3.71732;1.7738594;-4.55127;-
unicode body needs encoding information;-3.53115;0.56007314;-1.4088598;-3.2581568;0.26164055;0.45370224;TASK
explicit type check cuz we no like stinkin autocasting yarrr;-3.0994623;0.71661854;-3.5022414;0.0932394;1.9770536;-1.5472261;-
check usage of correct constructor using 2 mocks;-0.8792608;5.400875;-1.1920301;4.2750287;1.1907591;-3.080453;CODE
1 with no alternative constructors;-2.3662393;1.0144129;0.12613976;-0.60439247;5.580614;-1.5936608;CODE
2 with from crawler constructor;-4.44756;-0.033196528;-1.4156382;0.91559273;4.3236985;-0.16322456;CODE
check adoption of crawler;-3.5370266;-2.432028;-0.35529053;2.7584138;-0.3045067;-0.34340024;CODE
assert not is generator with return value j2 not recursive;-0.82910866;7.561165;-3.6424997;4.162327;-0.47147056;-4.365919;CODE
assert not is generator with return value k2 not recursive;-0.09565319;6.493646;-4.3984947;3.2080283;-0.75222796;-4.6910157;CODE
assert not is generator with return value j3 not recursive;-1.4906927;7.700831;-3.7406774;3.8937254;-0.027290922;-4.260564;CODE
assert not is generator with return value k3 not recursive;-0.79319197;6.6796546;-4.584447;2.803794;-0.06760662;-4.768473;CODE
assert get func args object pylint disable use implicit booleaness not comparison;-2.7347572;5.8270383;-5.812171;5.3286586;-2.063816;-1.5529472;CODE
the correct and correctly extracted signature;-2.160249;0.71511775;-3.4011261;-1.1815784;4.595035;-1.1564515;-
args kwargs is a correct result for the pre 3 13 incorrect function signature;-2.8706665;0.93362254;-4.3387494;-0.63251513;-1.7567093;-1.3506423;IRRE
is an incorrect result on even older cpython https github com python cpython issues 86951;-3.5250323;-1.1863116;-6.3218126;-0.89915305;-6.6697416;-3.6727362;CODE
the result should depend only on the pytest reactor argument;-0.9780502;1.5788203;-4.2338023;0.9928803;-2.3863676;1.1852926;IRRE
from twisted internet import reactor pylint disable reimported;-5.88198;-0.14037366;-4.700612;0.579634;-3.052814;2.7344785;CODE
the representation is not important but it must not fail;-1.9477417;1.8435142;-0.7817375;1.475368;2.2594426;0.30329746;CODE
request https example org a headers a b b;-4.3256264;1.5890558;1.5161675;-0.8471907;0.45895836;0.39739847;CODE
request https example org a headers a b b;-4.3256264;1.5890558;1.5161675;-0.8471907;0.45895836;0.39739847;CODE
request https example org a headers a b b;-4.3256264;1.589057;1.5161682;-0.84718984;0.45895776;0.39739853;CODE
request https example org a headers a b b;-4.3256264;1.5890558;1.5161675;-0.8471907;0.45895836;0.39739847;CODE
r2 request http www example com test html fragment;-4.37258;3.1331227;1.1161834;0.96319973;-1.7354616;-0.49950475;CODE
cached fingerprint must be cleared on request copy;-4.3061676;3.0647724;-1.3434627;2.6209226;-2.394942;3.5116;CODE
an old implementation used to serialize request data in a way that;-2.2505028;-1.4504935;0.6904839;1.8711013;2.9732354;2.6597838;TASK
would put the body right after the url;-5.722413;0.040555436;6.391102;1.419394;-0.24747032;2.1991148;-
open in browser resp debug true pylint disable unexpected keyword arg;-7.937456;1.3666003;-3.8670735;2.4829233;-3.6440961;1.0244395;CODE
exploit input from;-3.13846;1.2962341;2.4428995;1.2911139;-0.41116393;-3.295702;CODE
https makenowjust labs github io recheck playground;-5.399613;-5.193533;-0.2976681;1.596452;-3.6182609;-1.8316114;CODE
for old pattern to remove comments;-2.2184677;0.9375303;2.1782062;0.69314593;2.608185;-0.040414944;CODE
exploit input from;-3.13846;1.2962341;2.4428995;1.2911139;-0.41116393;-3.295702;CODE
https makenowjust labs github io recheck playground;-5.399613;-5.193533;-0.2976681;1.596452;-3.6182609;-1.8316114;CODE
for head s old pattern to find the head element;-0.77075315;0.9461335;3.3368275;-4.1189294;3.1247082;-1.0293611;CODE
assert result 0 0 self error handler pylint disable comparison with callable;-2.32757;6.8438745;-5.991913;6.4435;-2.9522045;-1.405203;CODE
import tests test utils spider noqa plw0406 plc0415 pylint disable import self;-5.691743;1.3012096;-5.7188673;0.9017542;-2.3471444;-0.99045014;CODE
assert template path is file failure of test itself;-2.737611;4.4995217;-3.7539613;4.358597;-2.628392;-1.9293245;CODE
assert not render path exists failure of test itself;-3.049352;5.715339;-4.0438004;4.9740868;-3.1307905;-1.5886;CODE
o1 foo noqa f841;-3.3399448;1.2411194;-0.13329485;-3.097097;1.8187611;-3.3753333;IRRE
o2 bar noqa f841;-2.9669058;-0.23150091;1.1005862;-4.2740383;1.1112534;-1.8301126;IRRE
o3 foo noqa f841;-3.8998706;0.95710224;0.07951084;-3.5048656;2.2540274;-3.1560647;IRRE
o1 foo noqa f841;-3.3399448;1.2411194;-0.13329485;-3.097097;1.8187611;-3.3753333;IRRE
o3 foo noqa f841;-3.8998706;0.95710224;0.07951084;-3.5048656;2.2540274;-3.1560647;IRRE
o2 bar noqa f841;-2.9669058;-0.23150091;1.1005862;-4.2740383;1.1112534;-1.8301126;IRRE
from scrapy utils url import type ignore attr defined;-5.2749953;0.6800212;-4.4443274;1.0342671;-1.6499932;1.9856368;CODE
www example com some page frag http www example com some page frag;-4.3018565;-0.04710741;3.3774698;-1.5828967;2.3245618;-0.41405687;CODE
username password www example com 80 some page do a 1 b 2 c 3 frag;-4.2698426;0.6129989;3.563084;-2.8694518;0.636162;-2.9581528;CODE
http username password www example com 80 some page do a 1 b 2 c 3 frag;-4.0657444;0.4706747;3.3017147;-2.5553203;0.75331557;-2.402557;CODE
http www example com some page frag;-3.9310987;-1.6190546;4.1773224;-0.6843316;1.2053355;0.16122887;CODE
http www example com some page frag;-3.9310987;-1.6190546;4.1773224;-0.6843316;1.2053355;0.16122887;CODE
http username password www example com 80 some page do a 1 b 2 c 3 frag;-4.0657444;0.4706747;3.3017147;-2.5553203;0.75331557;-2.402557;CODE
http username password www example com 80 some page do a 1 b 2 c 3 frag;-4.0657444;0.4706747;3.3017147;-2.5553203;0.75331557;-2.402557;CODE
www example com some page frag http www example com some page frag;-4.3018565;-0.04710741;3.3774698;-1.5828967;2.3245618;-0.41405687;CODE
username password www example com 80 some page do a 1 b 2 c 3 frag;-4.269844;0.6129984;3.563084;-2.8694522;0.6361618;-2.9581513;CODE
http username password www example com 80 some page do a 1 b 2 c 3 frag;-4.0657444;0.4706747;3.3017147;-2.5553203;0.75331557;-2.402557;CODE
some corner cases default to http;-5.9141655;1.7786864;2.0810413;-0.26280174;-1.7092915;3.5192494;CODE
http www example com index html somekey somevalue section;-4.4405346;0.7110275;1.8810283;-1.2100613;2.2974308;0.7940515;IRRE
http www example com index html somekey somevalue section;-4.4405346;0.7110275;1.8810283;-1.2100613;2.2974308;0.7940515;IRRE
http username www example com index html somekey somevalue section;-4.568607;-0.08381717;1.8491764;-1.4779156;1.6088723;0.2608053;IRRE
https username www example com index html somekey somevalue section;-4.0756483;0.23195978;1.4082893;-1.5302391;0.3955563;0.123336144;IRRE
ftp username password www example com index html somekey somevalue section;-4.651696;-0.8407517;-0.14936502;-1.853542;1.0452908;-0.74426717;IRRE
user username password none;-4.383108;0.29968968;0.36159563;-1.7111305;-3.624912;-3.6448593;-
http username 40 www example com index html somekey somevalue section;-4.885719;0.16179186;1.8766533;-1.5147356;1.8177669;-0.17598459;IRRE
user username pass password;-2.5315187;-1.461307;2.7163532;-1.2622997;-1.0583332;-2.4940605;-
https username 3apass www example com index html somekey somevalue section;-4.8928466;1.1746627;0.33284634;-1.9541649;0.98731476;-0.4615664;IRRE
user me password user domain com;-2.8769705;-1.4794555;3.540395;-2.48909;-1.91041;-1.7013198;CODE
ftp me user 40domain com www example com index html somekey somevalue section;-4.638687;0.6593049;0.56543005;-1.8577682;1.4824905;0.25263366;IRRE
http username password www example com 80 index html somekey somevalue section;-4.139583;0.33273488;1.6450883;-1.7548492;0.7335537;-0.30265862;IRRE
http username password www example com 8080 index html section;-3.8972228;-0.15757753;2.5815887;-1.7722688;-1.1344945;0.6729057;CODE
http username password www example com 443 index html somekey somevalue someotherkey sov section;-4.13143;0.2326141;0.14029089;-2.963886;0.30617133;-0.35553318;IRRE
http username password www example com 80 index html somekey somevalue someotherkey sov section;-4.501395;0.022975702;0.99344176;-2.1026855;0.26872966;-0.47227776;IRRE
http username password www example com 8080 index html somekey somevalue someotherkey sov section;-4.287691;0.28411338;1.1043923;-2.0816572;0.3218116;0.2969907;IRRE
http username password www example com 80 foo bar query value somefrag;-3.5971727;2.3271525;1.2479984;-0.8385681;0.3113669;-1.2631315;IRRE
http username password www example com 8008 foo bar query value somefrag;-3.3463235;2.3754056;0.930225;-1.6469873;-0.095267735;-1.5830146;IRRE
https en wikipedia org wiki path computing representations of paths by operating system and shell;-3.389644;-6.1551375;0.68186545;-1.1669265;0.42457697;-0.092459664;CODE
unix like os microsoft windows cmd exe;-3.957988;-4.3489013;1.6818548;-2.295965;-0.4136143;-1.0562681;CODE
